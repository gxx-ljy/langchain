{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56384247-47bd-4e9f-a485-e1e11dee3f28",
   "metadata": {},
   "source": [
    "langchain加载pdf的方法较多，这里尝试了PDFPlumberLoader、UnstructuredPDFLoader、PyPDFLoader\n",
    "\n",
    "要识别图片的话，处理太慢，就不处理了\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473d7cd-e445-4013-ac53-6fd399282c63",
   "metadata": {},
   "source": [
    "# PDFPlumberLoader\n",
    "\n",
    "按页读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4eb9b63b-3750-434a-b01f-8375d894583b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T06:39:21.527457Z",
     "iopub.status.busy": "2023-11-30T06:39:21.527457Z",
     "iopub.status.idle": "2023-11-30T06:40:11.120375Z",
     "shell.execute_reply": "2023-11-30T06:40:11.120375Z",
     "shell.execute_reply.started": "2023-11-30T06:39:21.527457Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 0\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 0, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 1\\n说明\\n本电子书为书籍原稿的开源版本，基本上没有进行什么排版，纸质书籍估计要2021 年3\\n月后才能购买。\\n本书虽然为开源电子书，但仅供个人学习使用。未经许可不能用于个人或企业的商业用\\n途，违法盗版和销售，必究其法律责任。\\n本书主页，以及源代码，资料下载：\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2\\n本书配套免费视频教程可以到免费学习人工智能的慕课平台 AI MOOC学习：\\nhttps://mooc.ai-xlab.com\\n提交错误或意见反馈可以到Github Issues页面提交：\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2/issues\\n我的B 站主页：\\nhttps://space.bilibili.com/390756902\\n我的微信公众号：\\nAI MOOC人工智能平台\\n联系邮箱：\\nqinbf@ai-xlab.com\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 1, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 2\\n本书谨献给我的妻子刘露斯，以及正在阅读此书的各位读者朋友。\\n愿人工智能给我们带来更美好的未来。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 2, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 3\\n序言\\n本书的由来\\n本书的序言可能有点长，因为这是我和大家的第一次见面，我希望可以把关于我和这本书\\n的故事讲清楚，让大家对我有一个更好的了解，说不定哪天我们会成为朋友。\\n大约在3 年前的某个下午，电子工业出版社的张迪编辑联系到我，让我写一本关于人工智\\n能的书。第一次有人找我写书，不免还是有些小激动，想象中写书是一件很酷的事情，真正写\\n的时候才知道写书是一件很苦的事情。\\n我毕业于上海大学物理系本科，大学期间做过很多嵌入式软硬件相关的开发项目。由于觉\\n得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用，所以我在大学校内开过\\n一年的嵌入式培训班，以更通俗易懂的方式和切合实际应用的内容给几百个本校同学（包括本\\n科/硕士/博士）上过课。\\n我最早是从2015 年开始接触人工智能技术，公司内部刚好需要开发人工智能相关的产品。\\n当时谷歌的深度学习框架Tensorflow 都还没有开源，我主要是学习了一些机器学习相关的算\\n法和应用。随着 Tensorflow 在 2015 年 11 月开源，AlphaGo在 2016 年 3 月战胜人类顶级\\n围棋选手，我知道新的人工智能的时代就要到来。2016 年我学习了当时最热门的两个深度学\\n习框架Tensorflow 和Caffe并用这两个框架完成了公司里面的一些深度学习项目。\\n当时市面上关于深度学习的书籍和学习资料都非常少，所以在 2017 年的时候我录制了一\\n些深度学习相关的视频教程放到了网上，就有了后来出版社找我写书的故事。几乎每个月都会\\n有出版社的人联系我出书，我才知道原来获得出书的机会不难，真正难的是认真坚持把一本书\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 3, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 4\\n给写完。这本书历时3 年，不过也不是真的写了3 年，写的过程中断断续续也暂停了很多次。\\n我估算了一下真正写书的时间大概是用了 1200 个小时。\\n最近两年我做了很多场人工智能的线下培训，给中国移动，中国电信，中国银行，华夏银\\n行，太平洋保险，国家电网，中海油，格力电器等企业以及多个研究所的科研人员和多个高校\\n的老师上过课，大家学完后的反馈基本上都是挺好的。虽然我这两年一直在从事人工智能的教\\n育培训工作，但是我也一直没有真正下定决心要做人工智能教育培训这件事。因为现如今人工\\n智能的各种学习资料已经很多了，网上也有各种人工智能专家大师的课程，这些专家大师基本\\n上都是博士，教授或来自名企。并且从课程的包装上看，内容还是不错的。\\n不过长期以来，我一直在关注人工智能技术和教育培训的发展。人工智能目前还处于高速\\n发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分\\n令人满意，还存在着许多问题。这些问题并不是几个专家大师所能解决的，而是需要更多人的\\n努力和付出。\\n人工智能教育是一件很有意义的事情，因为它有可能关乎国家，甚至人类的未来。尽管将\\n会面临无数困难，我还是决定加入其中，以这本书作为开始。\\n免费人工智能慕课平台 AI MOOC\\nAI MOOC是我自己创办的一个免费的人工智能慕课平台，网站地址为 https://mooc.ai-\\nxlab.com。以后我会在上面不断更新最新的人工智能课程。我的目标是让所有人都能有机会\\n学习到最前沿最好的人工智能课程。\\n如果大家觉得我创作的内容不错，可以帮我多多宣传，感谢。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 4, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 5\\n人工智能的学习\\n这里想跟大家简单聊一下关于人工智能的学习，人工智能是一门需要“内外兼修”的学科，\\n既要修炼外功招式，又要进行内功修行。这里的外功招式主要指的是使用编程语言去实现一些\\n人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。\\n很多时候武功招式是很容易学的，可以短时间内快速提升，但同时也很容易达到一定的上\\n限。如果想要突破上限更进一步，就要把内功给修炼好。所以我们在学习人工智能相关技术的\\n时候，尽量把相关算法理论理解清楚，同时要多写代码提高编程能力，并在实践过程中加深对\\n算法的理解。\\n本书的特色\\n本书的脉络框架主要是根据深度学习知识由浅入深的发展来编写的，对于 Tensorflow 的\\n使用技巧基本上不会单独讲解，而是会结合深度学习理论知识或实际应用案例来讲解。所以很\\n多 Tensorflow 的使用技巧在目录上可能没有得到很好的体现，这些 Tensorflow 使用技巧的\\n彩蛋在书里的程序中等着大家发现哦！相信大家看完这本书以后就可以熟练掌握 Tensorflow\\n的使用了。\\n本书是一本“内外兼修”的书，既包含详细的算法理论的介绍，又包括详细的代码讲解。\\n我一直在思考人工智能技术的教学方式，所以也形成了自己的教学风格和对教育的理解。这一\\n套方式方法收到过很多同学的积极反馈，但也不一定适合所有人。我觉得不同的教学风格就像\\n是不同类型的音乐，每个人喜欢的音乐类型可能都会不一样。AI 教育的发展需要各种类型的\\n教学方式百花齐放。\\n本书的主要特色总结如下：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 5, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 6\\n一.所有公式推导都有详细步骤，并解释每个符号。数学公式是算法的根本，要理解算法的\\n本质就要理解数学公式的含义，所以掌握一些基础的深度学习相关的数学内容也是很重要的。\\n大家看到数学一般都会比较头疼，所以本书中所有数学公式都会列出详细推导步骤，并解释每\\n个相关符号的含义，帮助大家理解。\\n二.注释每一行代码。我一直觉得我在教学中使用的代码具有一定个人风格，代码逻辑结构\\n清晰，程序在容易理解的基础上尽量精简，最大的特点可能就是注释比代码多。我给这种代码\\n风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得\\n对于初学者而言，最好是可以理解每一行代码，每个函数，函数中所使用的每个参数，这样学\\n习会感觉比较扎实。所以本书中所有代码都是全注释代码。\\n三. 程序皆为完整程序。本书一共 82 个代码应用案例，所有的代码都是可以从头到尾运\\n行的完整程序，并附带真实运行结果，不存在程序片段样例。我觉得程序片段对于初学者的学\\n习不太友好，大家拿到一个程序片段往往还是不知道如何使用，或者用起来的时候出现很多错\\n误，所以我在书中使用的所有程序都是可以从头到尾直接运行的完整程序。\\n四.一图胜千言。深度学习中很多模型结构，计算流程之类的内容很难用公式或者语言表达\\n清楚，但往往一张好的图片就可以说明一切。本书一共使用了约 500 张图片，在本书的创作\\n过程中，大约有200 个小时是花在画图以及思考如何画图上。\\n五.逻辑结构清晰，讲解细致。这个不需要多介绍，大家看的时候就知道了。\\n勘误和支持\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 6, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 7\\n本书很多思想和知识体系都是我基于自己的理解建立的，由于本人水平有限，本书一定存\\n在不少理解不当或者不准确的地方，恳请大家批评指正。如果大家有更多宝贵意见，欢迎发送\\n邮件至邮箱qinbf@ai-xlab.com\\n， 或 者 到 我 的 Github 留言 ： https://github.com/Qinbf/Deep-Learning-\\nTensorflow2/issues。期待大家的真挚反馈和支持。\\n致谢\\n在本书的撰写和研究期间，感谢我的妻子刘露斯对我的支持和鼓励。感谢我的朋友王惠东\\n对本书部分章节的校阅。感谢电子工业出版社张迪编辑的耐心等待，感谢出版社对本书的耐心\\n修订和整理。最后感谢各位读者朋友选择了这本书，感谢大家的信任。\\n覃秉丰\\n2020 年9 月于上海\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 7, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 8\\n目录\\n前言\\n第1章 深度学习背景介绍\\n1.1 人工智能\\n1.2 机器学习\\n1.2.1 训练数据，验证数据和测试数据\\n1.2.2 学习方式\\n1.2.3 机器学习常用算法\\n1.3 人工智能，机器学习，神经网络以及深度学习之间的关系\\n1.4 深度学习应用\\n1.5 神经网络深度学习发展史\\n1.5.1 神经网络诞生-20时间40-60年代\\n1.5.2 神经网络复兴-20时间80-90年代\\n1.5.3 深度学习-2006年至今\\n1.6 深度学习领域重要人物\\n1.7 新一轮人工智能爆发的三要素\\n第2章 搭建Python编程环境\\n2.1 Python 介绍\\n2.2 Anaconda 安装\\n2.3 Jupyter Notebook 的简单使用\\n2.3.1 启动Jupyter Notebook\\n2.3.2 修改Jupyter Notebook 默认启动路径\\n2.3.3 Jupyter Notebook 浏览器无法打开\\n2.3.4 Jupyter Notebook 基本操作\\n第3章 单层感知器与线性神经网络\\n3.1 生物神经网络\\n3.2 单层感知器\\n3.2.1 单层感知器介绍\\n3.2.2 单层感知器计算举例\\n3.2.3 单层感知器的另一种表达形式\\n3.3 单层感知器的学习规则\\n3.3.1 单层感知器的学习规则介绍\\n3.3.2 单层感知器的学习规则计算举例\\n3.4 学习率\\n3.5 模型的收敛条件\\n3.6 模型的超参数和参数的区别\\n3.7 单层感知器分类案例\\n3.8 线性神经网络\\n3.8.1 线性神经网络介绍\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 8, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 9\\n3.8.2 线性神经网络分类案例\\n3.9 线性神经网络处理异或问题\\n第4章 单层感知器与线性神经网络\\n4.1 BP神经网络介绍及发展背景\\n4.2 代价函数\\n4.3 梯度下降法\\n4.3.1 梯度下降法（Gradient Descent）介绍\\n4.3.2 梯度下降法（Gradient Descent）二维例子\\n4.3.3 梯度下降法（Gradient Descent）三维例子\\n4.4 Delta学习规则\\n4.5 常用激活函数讲解\\n4.5.1 Sigmoid 函数\\n4.5.2 Tanh 函数\\n4.5.3 Softsign 函数\\n4.5.4 ReLU 函数\\n4.6 BP网络模型和公式推导\\n4.6.1 BP 网络模型\\n4.6.2 BP 算法推导\\n4.6.3 BP 算法推导补充说明\\n4.7 BP算法推导结论总结\\n4.8 梯度消失与梯度爆炸\\n4.8.1 梯度消失\\n4.8.2 梯度爆炸\\n4.8.3 使用ReLU 函数解决梯度消失和梯度爆炸的问题\\n4.9 使用 BP神经网络解决异或问题\\n4.10 分类模型评估方法\\n4.10.1 准确率/精确率/召回率/F1值\\n4.10.2 混淆矩阵\\n4.11 独热编码（One-Hot Encoding）\\n4.12 BP神经网络完成手写数字识别\\n4.13 Sklearn 手写数字识别\\n第5章 深度学习框架Tensorflow基础使用\\n5.1 Tensorflow 介绍\\n5.1.1 Tensorflow 简介\\n5.1.2 静态图和动态图机制Eager Execution\\n5.1.3 tf.keras\\n5.2 Tensorflow-cpu安装\\n5.2.1 Tensorflow-cpu在线安装\\n5.2.2 安装过程中可能遇到的问题汇总\\n5.2.3 Tensorflow-cpu卸载\\n5.2.4 Tensorflow-cpu更新\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 9, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 10\\n5.2.5 Tensorflow-cpu指定版本的安装\\n5.3 Tensorflow-gpu 安装\\n5.3.1 Tensorflow-gpu 了解最新版本情况\\n5.3.2 Tensorflow-gpu 安装CUDA\\n5.3.3 Tensorflow-gpu 安装cuDNN库\\n5.3.4 Tensorflow-gpu 在线安装\\n5.3.5 Tensorflow-gpu 卸载\\n5.3.6 Tensorflow-gpu 更新\\n5.4 Tensorflow 基本概念\\n5.5 Tensorflow 基础使用\\n5.5.1 TF1转TF2工具\\n5.5.2 Tensorflow 基本操作\\n5.5.3 拟合线性函数\\n5.5.4 拟合非线性函数\\n5.6 手写数字图片分类任务\\n5.6.1 MNIST 数据集介绍\\n5.6.2 Softmax 函数介绍\\n5.6.3 简单MNIST数据集分类模型-没有高级封装\\n5.6.4 简单MNIST数据集分类模型-keras 高级封装\\n第6章 网络优化方法\\n6.1 交叉熵代价函数\\n6.1.1 均方差代价函数的缺点\\n6.1.2 引入交叉熵代价函数\\n6.1.3 交叉熵代价函数推导过程\\n6.1.4 Softmax 与对数似然代价函数\\n6.1.5 交叉熵程序\\n6.2 过拟合（Over-Fitting）\\n6.2.1 什么是过拟合\\n6.2.2 抵抗过拟合的方法\\n6.3 数据增强（Data Augmentation）\\n6.4 提前停止训练（Early-Stopping）\\n6.5 Dropout\\n6.5.1 Dropout 介绍\\n6.5.2 Dropout 程序\\n6.6 正则化（Regularization）\\n6.6.1 正则化介绍\\n6.6.2 正则化程序\\n6.7 标签平滑（Label Smoothing）\\n6.7.1 标签平滑（Label Smoothing）介绍\\n6.7.2 标签平滑（Label Smoothing）程序\\n6.8 优化器（Optimizer）\\n6.8.1 梯度下降法SGD\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 10, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 11\\n6.8.2 Momentum\\n6.8.3 NAG（Nesterov Accelerated Gradient）\\n6.8.4 Adagrad\\n6.8.5 Adadelta\\n6.8.6 RMRprop\\n6.8.7 Adam\\n6.8.8 优化器程序\\n第7章 Tensorflow模型的保存和载入\\n7.1 交叉熵代价函数\\n7.1.1 Keras 保存模型\\n7.1.2 Keras 载入模型\\n7.2 SavedModel模型保存和载入\\n7.2.1 SavedModel保存模型\\n7.2.2 SavedModel载入模型\\n7.3 单独保存模型结构\\n7.3.1 保存模型结构\\n7.3.2 载入模型结构\\n7.4 单独保存模型参数\\n7.4.1 保存模型参数\\n7.4.2 载入模型参数\\n7.5 ModelCheckpoint 自动保存模型\\n7.6 Checkpoint 模型保存和载入\\n7.6.1 Checkpoint 模型保存\\n7.6.2 Checkpoint 模型载入\\n第8章 卷积神经网络CNN\\n8.1 计算机视觉介绍\\n8.1.1 计算机视觉应用介绍\\n8.1.2 计算机视觉技术介绍\\n8.2 卷积神经网络简介\\n8.2.1 BP 神经网络存在的问题\\n8.2.2 局部感受野和权值共享\\n8.3 卷积的具体计算\\n8.4 卷积的步长\\n8.5 不同的卷积核\\n8.6 池化（Pooling）\\n8.7 Padding\\n8.8 常见的卷积计算总结\\n8.8.1 对1张图像进行卷积生成1张特征图\\n8.8.2 对1张图像进行卷积生成多张特征图\\n8.8.3 对多张图像进行卷积生成 1张特征图\\n8.8.4 对多张图像进行卷积生成多张特征图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 11, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 12\\n8.9 经典的卷积神经网络\\n8.10 卷积神经网络应用于MNIST数据集分类\\n8.11 识别自己写的数字图片\\n8.12CIFAR-10数据集分类\\n第9章 序列模型\\n9.1 序列模型应用\\n9.2 循环神经网络RNN\\n9.2.1 循环神经网络介绍\\n9.2.2 Elman network 和Jordan network\\n9.3 RNN的不同架构\\n9.3.1 一对一架构\\n9.3.2 多对一架构\\n9.3.3 多对多架构\\n9.3.4 一对多架构\\n9.3.5 Seq2Seq 架构\\n9.4 传统 RNN的缺点\\n9.5 长短时记忆网络LSTM\\n9.6 Peephole LSTM和FC-LSTM\\n9.6.1 Peephole LSTM介绍\\n9.6.2 FC-LSTM 介绍\\n9.7 其他 RNN模型\\n9.7.1 门控循环单元GRU\\n9.7.2 双向RNN（Bidirectional RNN）\\n9.7.3 Stacked Bidirectional RNN\\n9.8 LSTM 网络应用于MNIST数据集分类\\n第10章 经典图像识别模型介绍（上）\\n10.1 图像数据集ImageNet\\n10.1.1 ImageNet介绍\\n10.1.2 李飞飞简介\\n10.1.3 ImageNet的深远影响\\n10.1.4 ImageNet Challenge历年优秀作品\\n10.2 AlexNet\\n10.3 VGGNet\\n10.4 GoogleNet\\n10.4.1 1×1卷积介绍\\n10.4.2 Inception 结构\\n10.4.3 GoogleNet 网络结构\\n10.5 Batch Normalization\\n10.5.1 Batch Normalization 提出背景\\n10.5.2 数据标准化（Normalization）\\n10.5.3 Batch Normalization 模型训练阶段\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 12, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 13\\n10.5.4 Batch Normalization 模型预测阶段\\n10.5.5 Batch Normalization 作用分析\\n10.6 ResNet\\n10.6.1 ResNet背景介绍\\n10.6.2 残差块（Residual Block）介绍\\n10.6.3 ResNet网络介绍\\n10.6.4 ResNet-V2\\n第11章 经典图像识别模型介绍（下）\\n11.1 Inception 模型系列\\n11.1.1 Inception-v2/v3优化策略\\n11.1.2 Inception-v2/v3模型结构\\n11.1.3 Inception-v4和Inception-ResNet介绍\\n11.2 ResNeXt\\n11.2.1 分组卷积（Group Convolution）介绍\\n11.2.2 ResNeXt中的分组卷积\\n11.2.3 ResNeXt的网络结构\\n11.3 SENet\\n11.3.1 SENet 介绍\\n11.3.2 SENet 结果分析\\n第12章 图像识别项目实战\\n12.1 图像数据准备\\n12.1.1 数据集介绍\\n12.1.2 数据集准备\\n12.1.3 切分数据集程序\\n12.2 AlexNet图像识别\\n12.3 VGGNet图像识别\\n12.4 函数式（functional）模型\\n12.4.1 函数式（functional）模型介绍\\n12.4.2 使用函数式模型进行MNIST图像识别\\n12.5 模型可视化plot_model\\n12.5.1 使用plot_model进行模型可视化\\n12.5.2 plot_model升级版\\n12.6 GoolgeNet 图像识别\\n12.7 Batch Normalization 使用\\n12.8 ResNet图像识别\\n12.9 ResNeXt图像识别\\n12.10 SENet图像识别\\n12.11 使用预训练模型进行迁移学习\\n12.11.1 使用训练好的模型进行图像识别\\n12.11.2 使用训练好的模型进行迁移学习\\n12.11.3 载入训练好的模型进行预测\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 13, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 14\\n第13章 验证码识别项目实战\\n13.1 多任务学习介绍\\n13.2 验证码数据集生成\\n13.3 tf.data介绍\\n13.4 使用tf.data完成多任务学习-验证码识别\\n13.4.1 使用tf.data完成多任务学习模型训练\\n13.4.2 使用tf.data完成多任务学习模型预测\\n13.5 使用自定义数据生成器完成验证码识别\\n13.5.1 使用自定义数据生成器完成模型训练\\n13.5.2 使用自定义数据生成器完成模型预测\\n13.6 挑战变长验证码识别\\n13.6.1 挑战变长验证码识别模型训练\\n13.6.2 挑战变长验证码识别模型预测\\n13.7 CTC 算法\\n13.7.1 CTC 算法介绍\\n13.7.2 贪心算法（Greedy Search）和集束搜索算法（Beam Search）\\n13.7.3 CTC 存在的问题\\n13.8 CTC 算法-验证码识别\\n13.8.1 使用CTC 算法训练验证码模型\\n13.8.2 使用CTC 算法训练验证码预测\\n第14章 自然语言处理NLP发展历程（上）\\n14.1 多任务学习介绍\\n14.1.1 文本分类/情感分类\\n14.1.2 分词标注\\n14.1.3 机器翻译\\n14.1.4 聊天机器人\\n14.1.5 自动摘要\\n14.1.6 文章生成\\n14.1.7 图片描述\\n14.2 从传统语言模型到神经语言模型\\n14.2.1 规则模型\\n14.2.2 统计语言模型\\n14.2.3 词向量（word embedding）\\n14.2.4 神经语言模型\\n14.3 word2vec\\n14.3.1 word2vec 介绍\\n14.3.2 word2vec 模型训练\\n14.3.3 word2vec 训练trick和可视化效果\\n14.4 CNN在NLP领域的使用\\n14.5 RNN在NLP领域的使用\\n14.5.1 使用RNN进行文本分类\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 14, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 15\\n14.5.2 使用RNN进行中文分词标注\\n14.6 Seq2Seq 模型在NLP领域的使用\\n14.7 Attention 机制\\n14.7.1 Attention思想的介绍\\n14.7.2 Bahdanau Attention 介绍\\n14.7.3 Luong Attention 介绍\\n14.7.4 谷歌机器翻译系统GNMT介绍\\n14.7.5 Attention 机制在视觉和语音领域的应用\\n第15章 自然语言处理NLP发展历程（下）\\n15.1 NLP新的开始-Transformer模型\\n15.1.1 Transformer模型结构和输入数据介绍\\n15.1.2 Self-Attention 介绍\\n15.1.3 Multi-Head Attention 介绍\\n15.1.4 Layer Normalization 介绍\\n15.1.5 Decoder 结构介绍\\n15.1.6 Decoder 中的Multi-Head Attention 和模型训练\\n15.2 BERT模型\\n15.2.1 BERT模型介绍\\n15.2.2 BERT模型训练\\n15.2.3 BERT模型应用\\n第16章 NLP任务项目实战\\n16.1 Python 介绍\\n16.1.1 项目数据和模型说明\\n16.1.2 一维卷积英语电影评论情感分类程序\\n16.2 二维卷积中文微博情感分类项目\\n16.3 双向LSTM 中文微博情感分类项目\\n16.4 堆叠双向LSTM 中文分词标注项目\\n16.4.1 中文分词标注模型训练\\n16.4.2 维特比算法（Viterbi Algorithm）\\n16.4.3 中文分词标注模型预测\\n16.5 最新的一些激活函数介绍\\n16.5.1 Leaky ReLU\\n16.5.2 ELU\\n16.5.3 SELU\\n16.5.4 GELU\\n16.5.5 Swish\\n16.6 BERT模型简单使用\\n16.6.1 安装tf2-bert 模块并准备预训练模型\\n16.6.2 使用BERT进行文本特征提取\\n16.6.3 使用BERT进行完形填空\\n16.7 BERT电商用户多情绪判断项目\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 15, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 16\\n16.7.1 项目背景介绍\\n16.7.2 模型训练\\n16.7.3 模型预测\\n第17章 音频信号处理\\n17.1 深度学习在声音领域的应用介绍\\n17.1.1 音频分类\\n17.1.2 音频事件检测\\n17.1.3 语音识别\\n17.1.4 音乐检索\\n17.1.5 音乐生成\\n17.1.6 语音合成\\n17.1.7 语音克隆\\n17.2 MFCC 和Mel Filter Banks\\n17.2.1 音频数据采集\\n17.2.2 分帧加窗\\n17.2.3 傅里叶变换\\n17.2.4 梅尔滤波器（Mel Filter Banks）\\n17.2.5 梅尔频率倒谱系数MFCC\\n17.3 语音分类项目\\n17.3.1 音频处理库librosa介绍\\n17.3.2 音频分类项目-模型训练\\n17.3.3 音频分类项目-模型预测\\n第18章 图像风格转换\\n18.1 图像风格转换实现原理\\n18.1.1 代价函数的定义\\n18.1.2 格拉姆矩阵（Gram Matrix）介绍\\n18.2 图像风格转换项目实战\\n18.3 遮挡图像风格转换项目实战\\n第19章 生成对抗网络GANs\\n19.1 生成对抗网络的应用\\n19.1.1 图像生成\\n19.1.2 向量空间运算\\n19.1.3 改变年龄或美颜\\n19.1.4 图像转换\\n19.1.5 文本转图像\\n19.1.6 超分辨率\\n19.1.7 换脸\\n19.2 DCGAN介绍\\n19.2.1 DCGAN 原理\\n19.2.2 转置卷积（Transposed Convolution）介绍\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 16, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 17\\n19.2.3 DCGAN 模型结构\\n19.3 手写数字图像生成\\n第20章 模型部署\\n20.1 Tensorflow Serving 环境部署\\n20.1.1 安装Docker\\n20.1.2 拉取Tensorflow Serving镜像\\n20.2 运行客户端和服务器程序\\n20.2.1 准备SavedModel模型\\n20.2.2 启动Tensorflow Serving服务器程序\\n20.2.3 Tensorflow Serving 客户端 gRPC 程序\\n20.2.4 Tensorflow Serving 客户端 REST API程序\\n专业术语汇总\\n结束语\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 17, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 18\\n第 1 章-深度学习背景介绍\\n本章主要介绍人工智能，机器学习，神经网络，深度学习相关的一些概念，应用，发展史\\n以及重要人物等背景信息。这些背景知识虽然对我们的实际应用没有直接帮助，但是可以加深\\n我们对人工智能这个行业的理解，属于内功修行的范畴。\\n1.1 人工智能\\n1997 年 5 月 3 日-1997 年 5 月 11 日一场别开生面的比赛在纽约的公平大厦举行，吸引\\n了全世界的关注。对垒的双方分别是世界国际象棋冠军卡斯帕罗夫和 IBM 的超级计算机“深\\n蓝”。经过六场激烈的比赛，“深蓝”最终战胜了卡斯帕罗夫，赢得了具有特殊意义的胜利。\\n而这一次比赛也载入了人类的史册。\\n而另一场可以载入人类史册的人机大战发生在 2016 年3 月9 日-2016 年3 月15 日。这\\n一次比赛双方是世界顶级围棋棋手李世石和 Google 的人工智能 AlphaGo。赛前有很多人并\\n不看好 AlphaGo，认为 AlphaGo会惨败。没想到 AlphaGo最终以 4:1 大胜李世石，从而一\\n战成名。由于 AlphaGo 的胜利，AlphaGo 用到的深度学习（Deep Learning）技术以及人\\n工智能（Artificial Intelligence）也成为了当下最热门的技术话题。\\n人工智能（Artificial Intelligence），英文缩写 AI。AI 第一次被提出来是在 1956 年，是\\n由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议 （Dartmouth\\nConference）上一同定义出来的。人工智能只是一个抽象概念，它不是任何具体的机器或算\\n法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。比如几年前我们\\n去洗车的时候会看到洗车店写着自动化洗车，看起来很高级。今天我们再去看，可能它改成了\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 18, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 19\\n人工智能洗车，看起来更高级。实际上它的技术并没有改变，只是改了一个名字。随着人工智\\n能技术的大热，很多商品都挂上了人工智能的标签，实际上任何看起来有一点智能的算法和机\\n器都可以称为人工智能，所以人工智能这个标签并不能代表某个商品的技术水平。\\n提到人工智能，不得不说到一个非常著名的关于人工智能的测试，图灵测试（Turing Test）。\\n图灵测试是由计算机科学之父图灵提出来的，指的是测试者和被测试者（被测试者有可能是人\\n或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之\\n后，如果有30%的测试者不能确定被测试者是人还是机器，那么说明这台机器通过了测试。\\n虽然图灵测试早在1950 年被提出，但是至今没有机器能够很好地通过图灵测试。偶尔会\\n有一些新闻报道说某某机器通过了图灵测试，但是这些通过图灵测试的机器往往会受到很多人\\n质疑，并且经不住多次实验。\\n人工智能早期阶段，迅速解决了一些对于人类来说比较困难，但是对于计算机来说相对容\\n易的问题，比如下棋，推理，路径规划等等。我们下象棋的时候，通常需要思考很久才能推算\\n出几步棋之后棋盘战局的变化，并且经常还会有看错看漏的情况。而计算机能在一瞬间计算出\\n七八步棋甚至十几步棋之后棋盘的情况，并从中选出对自己最有利的下法来与对手对弈。面对\\n如此强大的对手，人类早在 20 年前就已经输了。可能有人会想到人工智能在象棋领域早就战\\n胜了人类最顶尖的选手，为什么在围棋领域一直到 2016 年才出了个 AlphaGo 把人类顶级棋\\n手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋 AI 的时候可\\n以使用暴力计算的方法，把几步之内所有可能的走法都遍历一次，然后选一个最优下法。同样\\n的方法放到围棋上就行不通了，围棋每一步的可能性都太多了，用暴力计算法设计出来的围棋\\nAI，它的棋力是很差的。虽然 AlphaGo 的计算非常快，可以在短时间完成大量运算，但是\\nAlphaGo比其他棋类AI强的地方并不是计算能力，而是它的算法，也可以理解为它拥有更强\\n大的“智慧”。就像是进行小学速算比赛，题目是 100 以内的加减法，10 个小学生为一队，\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 19, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 20\\n1 个数学系的博士为另一队。如果比赛内容是 1 分钟哪个队做的正确题目多，小学生队肯定是\\n能够战胜数学博士的。如果是进行大学生数学建模比赛，那 10000 个小学生也赢不了 1 个数\\n学博士。对于解决复杂的问题，需要的往往不只是计算速度，更多的应该是智慧。\\n对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完\\n成得很差。人类的视觉从眼睛采集信息开始，但起到主要作用的是大脑。人类的每个脑半球中\\n都有着非常复杂的视觉皮层，包含着上亿个神经元以及几百亿条神经元之间的连接。人类的大\\n脑就像是一台超级计算机，可以轻松处理非常复杂的图像问题。神经元之间的电信号可以快速\\n传递，但是就像前面说到的，对于复杂的问题，计算速度只是一方面。人类的视觉能力是通过\\n几亿年地不断进化，不断演变最终才得到的，更强的视觉和听觉能力使得人类可以拥有更强的\\n生存能力。\\n在人工智能的早期阶段，计算机的智能通常是基于人工制定的“规则”，我们可以通过详\\n细的规则去定义下棋的套路，推理的方法，以及路径规划的方案。但是我们却很难用规则去详\\n细描述图片中的物体，比如我们要判断一张图片中是否存在猫。那我们首先要通过规则去定义\\n一只猫，如图1.1 所示。\\n图1.1 猫（Cat）\\n观察图1.1 中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身\\n体，和一条长尾巴，然后可以定义一套规则在图片中寻找猫。这看起来好像是可行的，但是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 20, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 21\\n如果我们遇到的是图1.2，图1.3 中的猫该怎么办？（我家领养的猫，刚来的时候上厕所比较\\n臭，故取名“臭臭”）\\n图1.2 藏起来的“臭臭”\\n图 1.3 盘成一团的“臭臭”\\n猫可能只露出身体的一部分，可能会摆出奇怪的造型，那么我们又要针对这些情况定义\\n新的规则。从这个例子中大家应该能看得出来，即使是一只很普通的家养宠物，都可能会出\\n现无数种不同的外形。如果我们使用人工定义的规则去定义这个物体，那么可能需要设置非\\n常大量的规则，并且效果也不一定会很好。仅仅一个物体就这么复杂，而现实中常见的各种\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 21, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 22\\n物体成千上万，所以在图像识别领域，使用使用人为定义的规则去做识别肯定是行不通的。\\n很多其他的领域也同样存在这种问题。\\n1.2 机器学习\\n由于人们没有办法设计出足够复杂的规则来精确描述世界，所以 AI 系统需要具备自我学\\n习的能力，即从原始数据中获取有用的知识。这种能力被称为机器学习（Machine Learning）。\\n人工智能是抽象的概念，而机器学习是具体的可以落地的算法。机器学习不是一个算法，\\n而是一大类具体智能算法的统称。使用机器学习算法我们可以解决生活中如人脸识别，垃圾邮\\n件分类，语音识别等具体问题。\\n机器学习其实与人类学习的过程类似。打个比方：假如我们现在都是原始人，并不知道太\\n阳和月亮是什么东西。但是我们可以观察天上的太阳和月亮，并且把太阳出来时候的光线和温\\n度记录下来，把月亮出来时候的光线和温度记录下来（这就相当于是收集数据）。观察了 100\\n天之后，我们进行思考，总结这 100 天的规律我们可以发现，太阳和月亮是交替出现的（偶尔\\n同时出现可以忽略）。出太阳的时候光线比较亮，温度比较高。月亮出来的时候光线比较暗，\\n温度比较低（这相当于是分析数据，建立模型）。之后我们看到太阳准备落山，月亮准备出来\\n的时候我们就知道温度要降低可能要多穿树叶或毛皮（原始人没有衣服），光线也准备要变暗\\n了（预测未来的情况）。机器学习也可以利用已有的数据进行学习，获得一个训练好的模型，\\n然后可以利用此模型预测未来的情况。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 22, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 23\\n图1.4 中表现了机器学习与人类思维的对比。我们可以使用历史数据来训练一个机器学习\\n的模型，模型训练好之后，再放入新的数据，模型就可以对新的数据进行预测分析。人类也善\\n于从以往的经验中总结规律，当遇到新的问题时，我们可以根据之前的经验来预测未来的结果。\\n图1.4 机器学习与人类思维的对比\\n1.2.1 训练数据，验证数据和测试数据\\n通常我们在做机器学习分析的时候，会把数据分成两大部分。一部分是训练数据（Training\\nData），可以用来训练，构建模型。另一部分是测试数据（Testing Data），可以用来验证模\\n型的好坏。这两部分就有点像我们上学时课本中的习题。正文中的例题是训练数据，有答案和\\n详细讲解，是用来教我们学习新知识的，可以看作是用来对我们进行训练。而课后习题是测试\\n数据，我们要先做题，做完之后再对答案，是用来检查我们学习效果的。\\n有时我们会把数据分成三部分，即训练集（Training Set）、验证集（Validation Set）\\n和测试集（Testing Set）。训练集还是用来训练模型。验证集是在模型的训练阶段评估模型的\\n好坏，可以用于确定模型的参数或结构。等模型训练好，并且结构和参数都调整好之后，再用\\n测试集来评估模型的好坏。通常我们可以把所有数据的 60%分配给训练集，20%分配的验证\\n集，20%分配给测试集。或者 80%分配给训练集，10%分配给验证集，10%分配给测试集。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 23, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 24\\n不过这个数据划分不是绝对的，还需要看具体情况。有时候我们只划分训练集和测试集，训练\\n集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。\\nK 折交叉检验(K-fold Cross-Validation) —— K 折交叉检验的大致思想是把数据集分\\n成 K 份，每次取一份作为测试集，取余下的 K-1 份作为训练集。重复训练 K 次，每次训练都\\n从K个部分中选一个不同的部分作为测试集（要保证 K个部分的数据都分别做过测试），剩下\\n的K-1 份做训练集。最后把得到的 K个结果做平均。\\n1.2.2 学习方式\\n在机器学习或者人工智能领域，不同的问题可能会有不同的学习方式。主要的学习方法有：\\n监督学习（Supervised Learning） —— 监督学习也称为有监督学习，通常可以用于\\n分类（Classification）以及回归（Regression）的问题。它的主要特点是，所有的数据都有\\n与之相对应的标签（Label）。比如我们想做一个识别手写数字的模型，那么我们的数据集就是\\n大量手写数字的图片，并且每一张图片都有对应的标签，如图 1.5：\\n图1.5 标签为3\\n图片是一个手写数字3，所以这张图片的标签可以设置为 3。同样的，如果是一张手写\\n数字8 的图片，那么该图片的标签就可以是 8。或者我们要建立一个判别垃圾邮件的模型，\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 24, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 25\\n那我们先要对邮件进行标记，标记出哪些属于垃圾邮件，哪些不属于垃圾邮件，然后建立模\\n型。\\n监督学习在建模过程中，会将预测结果与训练数据的实际结果（也就是标签）做对比，\\n如果预测结果跟实际结果不符合，将通过一些方式去调整模型的参数，直到模型的预测结果\\n能达到比较高的准确率。\\n非监督学习（Unsupervised Learning)）—— 非监督学习也称为无监督学习，通常可\\n以用于聚类（Clustering）的问题。非监督学习中，所有的数据都是没有标签的。可以使用\\n机器学习的方法让数据自动聚类。例如许多公司都拥有庞大的客户信息数据库，使用非监督\\n学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我\\n们对不同细分市场的客户进行更有效的销售或者广告推送。或许我们事先并不知道有哪些细\\n分市场，也不知道哪些客户属于细分市场 A，哪些客户属于细分市场B。不过没关系，我们\\n可以让非监督学习算法在数据中挖掘这一切信息。\\n半监督学习（Semi-Supervised Learning）—— 半监督学习是监督学习和非监督学\\n习相结合的一种学习方式，通常可以用于分类以及回归问题。主要是用来解决使用少量带标\\n签的数据和大量没有标签的数据进行训练和分类的问题。此类算法首先试图对没有标签的数\\n据进行建模，然后再对带有标签的数据进行预测。说个题外话，半监督学习一般用得比较\\n少，原因很简单，因为标签不足的情况通常很容易解决，只要找很多人来打标签就可以了。\\n大型AI公司可能会有几百人的数据标注团队，每天的工作就是给各种数据打标签。因为顶尖\\n大公司AI技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所\\n以现在有一句叫做人工智能，先有人工，后有智能，有多少人工，就有多少智能。这是玩笑\\n话，大家看看就好，标签很重要，不过人工智能的核心还是算法，说不定以后有一天我们可\\n以开发出不需要标签就可以什么都学会的算法。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 25, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 26\\n强化学习（Reinforcement Learning）—— 强化学习灵感来源于心理学中的行为主\\n义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能\\n够获得最大利益的习惯性行为。强化学习没有任何的标签来告诉算法应该怎么做，它会先去\\n尝试做一些动作，然后得到一个结果，通过判断这个结果是对还是错来对之前的动作进行反\\n馈。AlphaGo中就用到了强化学习。不过目前强化学习的落地应用还比较少，大部分的应用\\n还都只是用于打游戏。\\n1.2.3 机器学习常用算法\\n机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n所示。\\n图1.6 决策树(Decision Tree)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 26, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 27\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n这些数据来建立回归模型，如图1.7 所示。\\n图1.7 线性回归(Linear Regreesion)\\n模型建立好之后，我们可以得到一条最符合房屋面积跟房屋价格关系的直线。根据这个\\n模型，我们可以把一个新的房屋面积输入，就能得到该房屋的价格预测值。\\nKNN（K-Nearest Neighbor） —— KNN算法又称为k 近邻分类(k-nearest neighbor\\nclassification)算法，是一种监督学习算法。最简单的最近邻算法就是遍历所有已知标签的样\\n本集中的数据，计算它们和需要分类的样本之间的距离（这里的距离一般指的是 欧氏距离\\n（Euclidean Distance)），同时记录目前的最近点。KNN查找的是已知标签的样本集中跟需\\n要分类的样本最邻近的K个样本，需要分类的样本最终的标签是由这K个样本的标签决定的，\\n采用的方式是“多数表决”。也就是在这 K个样本中哪种标签最多，那么需要分类的样本就归\\n为哪一类。下图中，方形表示分类 1，圆形表示分类 2，图中正中心的五角星表示需要分类的\\n样本。当K等于1 时，其实就是计算距离五角星最近的样本属于哪一个分类。图1.8 中，我们\\n可以看到距离五角星最近的是方形，属于分类 1，所以我们可以把五角星归为分类1。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 27, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 28\\n图1.8 KNN分类，K等于1\\n当我们取K=5 时，其实就是找出距离五角星最近的5 个样本，然后统计这5 个样本哪\\n种分类比较多。图1.9 中我们可以看到，有1 个方形和4 个圆形，那么圆形比较多，所以我\\n们可以把五角星归为分类2。\\n图1.9 KNN 分类，K等于5\\n这里我们可以看到，五角星最终的分类跟 K的取值有很大关系。K值取多少，模型的效\\n果才比较好呢？这可能需要对模型进一步调试，才能得到答案，比如我们可以不断改变 K\\n值，然后用测试集来做测试，最终选取一个可以使得测试误差比较小的 K值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 28, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 29\\nK-Means —— K-Means是一种无监督学习算法，通常可以用于聚类分析。所谓聚类\\n问题，就是给定一个元素集合A，集合中的每个元素有n 个可观测的属性。我们需要使用某\\n种方法把A划分为k 个子集，并且要使得每个子集内部元素之间的差异尽可能小，不同子集\\n之间元素的差异尽可能大。K-Means算法的计算过程比较直观也比较简单：\\n（1）先从没有标签的元素集合 A中随机取k 个元素，作为k 个子集各自的重心。\\n（2）分别计算剩下的元素到 k 个子集重心的距离（这里的距离也可以使用欧氏距离），\\n根据距离将这些元素分别划归到最近的子集。\\n（3）根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的\\n算数平均数）。\\n（4）将集合 A中全部元素按照新的重心然后再重新聚类。\\n（5）重复第（4）步，直到聚类结果不再发生变化。\\nK-Means运行过程如图1.10~图1.12 所示。\\n图1.10 K-Means算法，第1 次迭代\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 29, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 30\\n图1.11 K-Means算法，第5 次迭代\\n图1.12 K-Means算法，第9 次迭代\\n聚类模型一共迭代了9 次，最终收敛。从图中我们可以看得出来第 1 次迭代的时候，模\\n型的聚类效果是很差的，一看就不太合理。迭代了 5 次之后，模型有了一些改善，聚类的效\\n果已经不错了，不过看得出来还有一些提高的空间。迭代 9 次之后，模型就训练好了，很好\\n地把没有标签的数据分成了4 类。相同类别之间的差距比较小，不同类别之间的差距比较\\n大。\\n神经网络（Neural Network）—— 神经网络是一种模拟人类大脑神经网络结构构建\\n出来的算法。神经网络的结构可以有多层，多层的神经网络可以由输入层（Input Layer），\\n隐藏层（Hidden Layers）以及输出层（Output Layer）组成。其中隐藏层可能有0 到多\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 30, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 31\\n个，所以最简单的神经网络就只有输入层和输出层。神经网络的每一层都由若干个神经元\\n（Neuron）节点组成。\\n信号从输出层传入网络，与神经元的权值（Weights）作用后再经过激活函数\\n（Activation Function）传入下一层。每一层信号的输出都是下一层的输入，直到把信号\\n传到输出层得出结果。网络结构如图1.13 所示：\\n图1.13 神经网络（Neural Network）\\n神经网络是深度学习的重要基础，在后面的章节中我们会从头开始详细学习神经网络的\\n搭建以及应用，这里只是先做一个简单介绍。\\n除了上面介绍的这些算法以外，机器学习领域还有很多其他的算法，如朴素贝叶斯\\n(Naive Bayes)，支持向量机SVM(Support Vector Machine)， Adaboost 等。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 31, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 32\\n1.3 人工智能、机器学习，神经网络以及深度学\\n习之间的关系\\n新闻媒体在报道AlphaGo的时候，可能人工智能，机器学习，神经网络和深度学习这\\n几个词都有用到过。对于初学者来说，难免容易混淆。\\n人工智能 —— 我们先说说人工智能，人工智能是这几个词中最早出现的。1956 年，\\n在美国达特茅斯会议（Dartmouth Conference）上被提出。人工智能其实是一种抽象的概\\n念，并不是指任何实际的算法。人工智能可以对人的意识、思维进行模拟，但又不是人的智\\n能。有时候我们还会把人工智能分为弱人工智能（Weak AI）和强人工智能（Strong AI）。\\n弱人工智能是擅长于单个方面技能的人工智能。比如 AlphaGo能战胜了众多世界围棋\\n冠军的，在围棋领域所向披靡，但它只会下围棋，做不了其他事情。我们目前的人工智能相\\n关的技术，比如图像识别，语言识别，自然语言处理等等，基本都是处于弱人工智能阶段。\\n强人工智能指的是在各方面都能和人类智能差不多的人工智能，人类能干的脑力劳动它\\n都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一\\n些科幻电影中才能看到。著名的教育心理学教授 Linda Gottfredson 把智能定义为“一种宽\\n泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从\\n经验中学习等操作。”强人工智能在进行这些操作时应该跟人类一样得心应手。\\n机器学习 —— 机器学习是最近20 多年兴起的一门多领域交叉学科，涉及概率论、统\\n计学、逼近学、凸分析、计算复杂性理论等多门学科。关于机器学习，上一小节我们已经做\\n了一些讨论说明，我们可以发现机器学习包含很多具体的算法。既然人工智能是飘在天上的\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 32, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 33\\n概念，那我们就需要一些具体的算法使得人工智能可以落地应用，而一般来说，这些具体的\\n智能算法可以统称为机器学习算法。\\n神经网络 —— 神经网络是众多机器学习算法中的其中一个，是模仿人类大脑神经结构\\n构建出来的一种算法，构建出来的网络称为人工神经网络（Artificial Neural Networks，\\nANN）。神经网络算法在机器学习中并不算特别出色，所以一开始的时候并没有引起人们的\\n特别关注。神经网络的发展已经经历了三次发展浪潮：20 世纪40 年代到60 年代神经网络\\n的雏形出现在控制论（Cybernetics）中，20 世纪80 年代到90 年代表现为联结主\\n（Connectionism）。直到2006 年神经网络重新命名为深度学习，再次兴起。\\n深度学习 —— 深度学习的基础其实就是神经网络，之所以后来换了一种叫法，主要是\\n由于之前的神经网络算法中网络的层数不能太深，也就是不能有太多层网络，网络层数过多\\n会使得网络无法训练。随着神经网络理论的发展，科学家研究出了多种方式使得训练深层的\\n网络也成为可能，深度学习由此诞生。如卷积神经网络（Convolutional Neural\\nNetwork, CNN），长短时记忆网络（Long Short Term Memory Network, LSTM），深\\n度残差网络（Deep Residual Network）等都属于深度学习，其中深度残差网络的深度可\\n以到达1000 层，甚至更多。深层的网络有助于挖掘数据中深层的特征，可以使得网络拥有\\n更强大的性能。\\n图1.14 描绘了人工智能、机器学习、神经网络和深度学习之间的关系。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 33, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 34\\n图1.14 人工智能、机器学习、神经网络和深度学习之间的关系\\n1.4 深度学习应用\\n深度学习最早兴起于图像识别，在最近几年可以说是已经深入各行各业。深度学习在计算\\n机视觉，语音识别，自然语言处理，机器人控制，生物信息，医疗，法律，金融，推荐系统，\\n搜索引擎，电脑游戏，娱乐等领域均有应用。\\n图像识别 —— 图像识别可以说是深度学习最早实现突破性成就的领域。如今计算机对\\n图片的识别能力已经跟人类不相上下。我们把一张图片输入神经网络，经过网络的运算，最后\\n可以得到图片的分类。如图 1.15 所示，我们可以看到，对于每一张图片，神经网络都给出了\\n5 个最有可能的分类，排在最上面的可能性最大。图中的置信度表示的就是该图片的概率值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 34, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 35\\n图1.15 图像识别\\n目标检测 —— 利用深度学习我们还可以识别图片中的特定物体，然后对该物体进行标\\n注，如图1.16 所示。\\n图1.16 目标检测[1]\\n人脸识别 —— 深度学习还可以识别图像中的人脸，判断是男人还是女人，判断人的年龄，\\n判断图像中的人是谁等，如图1.17 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 35, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 36\\n图1.17 人脸识别\\n目标分割 —— 目标分割识别出图中的物体，并且可以划分出物体的边界，如图1.18 所\\n示。\\n图1.18 目标分割[2]\\n描述图片 —— 把一张图片输入神经网络中，就可以输出对这张图片的文字描述，如图\\n1.19 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 36, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 37\\n图1.19 图片描述\\n图片风格转换 —— 利用深度学习实现一张图片加上另一张图片的风格，然后生成一张\\n新的图片，如图1.20 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 37, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 38\\n图 1.20 图片风格转换[3]\\n语音识别 —— 深度学习还可以用来识别人说的话，把语音数据转换为文本数据，如图\\n1.21 所示。\\n图1.21 语音识别\\n文本分类 —— 使用深度学习对多个文本进行分类，比如判断一个评论是好评还是差评，\\n或者判断一篇新闻是属于娱乐新闻，体育新闻还是科技新闻，如图 1.22 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 38, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 39\\n图1.22 文本分类\\n机器翻译 —— 使用深度学习进行机器翻译，如图1.23 所示。\\n图1.23 机器翻译\\n诗词生成 —— 把一个诗词的题目传入神经网络，就可以生成一篇诗词，如图1.24所示，\\n其就是AI写的一首诗。虽然这首诗有些看不太懂，但是已经“有内味了”。\\n图1.24 诗句生成\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 39, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 40\\n图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站\\nhttps://make.girls.moe/#/，设置好动漫人物的头发颜色，头发长度，眼睛颜色，是否戴帽\\n子等信息就可以生成符合条件的动漫人物。并且可以生成无数张不重复的照片，如图 1.25 所\\n示。\\n图1.25 图像生成\\n这里只是列举了非常少量的例子，深度学习的已经逐渐深入各行各业，深入我们的生活\\n中。\\n1.5 神经网络深度学习发展史\\n神经网络的发展历史中有过三次热潮，分别发展在 20 世纪 40 年代到 60 年代，20 世纪\\n80 年代到90 年代，以及 2006 年至今。每一次神经网络的热潮都伴随着人工智能的兴起，人\\n工智能和神经网络一直以来都有着非常密切的关系。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 40, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 41\\n1.5.1 神经网络诞生-20 世纪 40-60 年代\\n1943 年，神经病学家和神经元解剖学家 W.S.McCulloch 和数学家W.A.Pitts在生物物理\\n学期刊发表文章提出神经元的数学描述和结构。并且证明了只要有足够的简单神经元，在这些\\n神经元互相连接并同步运行的情况下，可以模拟任何计算函数，这种神经元的数学模型称为M-\\nP 模型。该模型把神经元的动作描述为：1.神经元的活动表现为兴奋或抑制的二值变化；2.任\\n何兴奋性突触输入激励后，使神经元兴奋；3.任何抑制性突触有输入激励后，使神经元抑制；\\n4.突触的值不随时间改变；5.突触从感知输入到传送出一个输出脉冲的延时时间是0.5ms。\\n尽管现在看来 M-P 模型过于简单，并且观点也不是完全正确，不过这个模型被认为是第\\n一个仿生学的神经网络模型，他们提出的很多观点一直沿用至今，比如说他们认为神经元有两\\n种状态，要不就是兴奋，要不就是抑制。这跟后面要提到的单层感知器非常类似，单层感知器\\n的输出要不就是0 要不就是1。他们最重要的贡献就是开创了神经网络这个研究方向，为今天\\n神经网络的发展奠定了基础。\\n1949 年 ，另一 位心 理学 家 Donald Olding Hebb 在他的 一 本名为\\n《The organization of behavior: A neuropsychological theory》[4]的书提出了 Hebb 算\\n法。他也是首先提出“连接主义”（connectionism）这一名词的人之一，这个名词的含义是\\n大脑的活动是靠脑细胞的组合连接实现的。Hebb 认为，如果源和目的神经元均被激活兴奋时，\\n它们之间突触的连接强度将会增强。他指出在神经网络中，信息存储在连接权值中。并提出假\\n设神经元A到神经元B 连接权与从B 到A的连接权是相同的。他这里提到的这个权值的思想\\n也被应用到了我们目前所使用的神经网络中，我们通过调节神经元之间的连接权值来得到不同\\n的神经网络模型，实现不同的应用。虽然这些理论在今天看来是理所当然的，不过在当时看来\\n这是一种全新的想法，算得上是开创性的理论。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 41, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 42\\n1958 年，计算机学家 Frank Rosenblatt 提出了一种神经网络结构，称为 感知器\\n(Perceptron)。他提出的这个感知器可能是世界上第一个真正意义上的人工神经网络。感知\\n器提出之后在60 年代就掀起了神经网络研究的第一次热潮。很多人都认为只要使用成千上万\\n的神经元，他们就能解决一切问题。现在看来可能会让人感觉too young too naive，不过感\\n知器在当时确实是影响非凡。\\n这股感知器热潮持续了 10 年，直到 1969 年，人工智能的创始人之一的 M.Minsky 和\\nS.Papert出版了一本名为《感知器》[5]的书，书中指出简单神经网络只能运用于线性问题的求\\n解，能够求解非线性问题的网络应具有隐层，而从理论上还不能证明将感知器模型扩展到多层\\n网络是有意义的。由于Minsky 在学术界的地位和影响，其悲观论点极大地影响了当时的人工\\n神经网络研究，为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。这本书出版不不久之后，\\n几乎所有为神经网络提供的研究基金都枯竭了，没有人愿意把钱浪费在没有意义的事情上。\\n1.5.2 神经网络复兴-20 世纪 80-90 年代\\n1982 年，美国加州理工学院的优秀物理学家 John J.Hopfield 博士提出了 Hopfield 神\\n经网络。Hopfield 神经网络引用了物理力学的分析方法，把网络作为一种动态系统并研究这\\n种网络动态系统的稳定性。\\n1985 年，G.E.Hinton 和 T.J.Sejnowsk借i 助统计物理学的概念和方法提出了一种随机神\\n经网络模型——玻尔兹曼机(Boltzmann Machine)。一年后他们又改进了模型，提出了受限\\n玻尔兹曼机(Restricted Boltzmann Machine)。\\n1986 年，Rumelhart，Hinton，Williams提出了BP(Back Propagation)算法[6]（多层\\n感知器的误差反向传播算法）。到今天为止，这种多层感知器的误差反向传播算法还是非常基\\n础的算法，凡是学神经网络的人，必然要学习 BP 算法。我们现在的深度网络模型基本上都是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 42, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 43\\n在这个算法的基础上发展出来的。使用 BP 算法的多层神经网络也称为 BP 神经网络（Back\\nPropagation Neural network）。BP 神经网络主要指的是 20 世纪 80-90 年代使用 BP 算\\n法的神经网络，虽然现在的深度学习也用 BP 算法，不过网络名称已经不叫 BP 神经网络了。\\n早期的BP 神经网络的神经元层数不能太多，一旦网络层数过多，就会使得网络无法训练，具\\n体原因在后面的章节中会详细说明。\\nHopfield 神经网络，玻尔兹曼机以及受限玻尔兹曼机由于目前已经较少使用，所以本书\\n后面章节不再详细介绍这三种网络。\\n1.5.3 深度学习-2006 年至今\\n2006 年，多伦多大学的教授Geoffrey Hinton 提出了深度学习。他在世界顶级学术期刊\\n《Science》上发表了一篇论文《 Reducing the dimensionality of data with neural\\nnetworks》[7]，论文中提出了两个观点：①多层人工神经网络模型有很强的特征学习能力，深\\n度学习模型学习得到的特征数据对原始数据有更本质的代表性，这将大大便于分类和可视化问\\n题；②对于深度神经网络很难训练达到最优的问题，可以采用逐层训练方法解决。将上层训练\\n好的结果作为下层训练过程中的初始化参数。在这一文献中深度模型的训练过程中逐层初始化\\n采用无监督学习方式。\\nHinton 在论文中提出了一种新的网络结构深度置信网络（Deep Belief Net：DBN），这\\n种网络使得训练深层的神经网络成为可能。深度置信网络由于目前已经较少使用，所以本书后\\n面章节不再详细介绍这种网络。\\n2012 年，Hinton 课题组为了证明深度学习的潜力，首次参加 ImageNet图像识别比赛，\\n通过CNN网络AlexNet一举夺得冠军。也正是由于该比赛，CNN吸引了众多研究者的注意。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 43, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 44\\n2014 年，香港中文大学教授汤晓鸥领导的计算机视觉研究组开发了名为 DeepID的深度\\n学习模型， 在LFW (Labeled Faces in the Wild，人脸识别使用非常广泛的测试基准)数据库\\n上获得了99.15%的识别率，人用肉眼在LFW上的识别率为97.52%，深度学习在学术研究层\\n面上已经超过了人用肉眼的识别。\\n2016 年3 月人工智能围棋比赛，由位于英国伦敦的谷歌（Google）旗下 DeepMind公\\n司的开发的AlphaGo战胜了世界围棋冠军、职业九段选手李世石，并以4:1 的总比分获胜。\\n2018 年6 月，OpenAI的研究人员开发了一种技术，可以在未标记的文本上训练 AI，可\\n以大量减少人工标注的时间。几个月后谷歌推出了一个名为 BERT 的模型，该模型在学习了几\\n百万个句子以后学会了如何预测漏掉的单词。在多项 NLP (Natural Language\\nProcessing) 测试中，它的表现都接近人类。\\n2020 年 6 月，OpenAI 发布了有史以来最大的 NLP 模型 GPT-3，GPT-3 模型参数达到\\n了 1750 亿个参数，模型训练花费了上千万美元。GPT-3 训练方法很简单，但是却非常全能，\\n可以完成填空，翻译，问答，阅读理解，数学计算，语法纠错等多项任务。随着 NLP 技术的\\n发展，相信在将来 AI 可以逐渐理解我们的语言，跟我们进行顺畅的对话，甚至成为我们的保\\n姆，老师或朋友。\\n今天，人脸识别技术已经应用在了我们生活的方方面面，比如上下班打卡，飞机高铁出行，\\n出门住酒店，刷脸支付等。我们已经离不开深度学习技术，而深度学习技术仍在快速发展中。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 44, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 45\\n1.6 深度学习领域重要人物\\n深度学习领域有很多做出过卓越贡献的大师，下面简单介绍几位。前面的 3 位大师\\nGeoffrey Hinton、Yann LeCun、Yoshua Bengio江湖人称“深度学习三巨头”，为了表彰3\\n位大师对于神经网络深度学习领域的贡献，2018 年计算机领域最高奖项图灵奖颁给了他们。\\n1.Geoffrey Hinton\\n英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。Hinton 是反向传\\n播算法和对比散度算法的发明人之一，也是深度学习的积极推动者。目前担任多伦多大学计\\n算机科学系教授。\\n2013 年3 月加入Google，领导Google Brain 项目。\\nHinton 被人们称为“深度学习教父”，可以说是目前对深度学习领域影响最大的人。而\\n且如今在深度学习领域活跃的大师，有很多都是他的弟子，可以说是桃李满天下。\\n2.Yann LeCun\\n法国出生的计算机科学家，他最著名的工作是光学字符识别和计算机视觉上使用卷积神经\\n网络（CNN），他也被称为卷积网络之父。\\n曾在多伦多大学跟随Geoffrey Hinton 做博士后。1988 年加入贝尔实验室，在贝尔实验\\n室工作期间开发了一套能够识别手写数字的卷积神经网络系统，并把它命名为 LeNet。这个系\\n统能自动识别银行支票。\\n2003 年去了纽约大学担任教授，现在是纽约大学终身教授。\\n2013 年12 月加入了Facebook，成为Facebook人工智能实验室的第一任主任。\\n3.Yoshua Bengio\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 45, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 46\\n毕业于麦吉尔大学，在MIT 和贝尔实验室做过博士后研究员，自1993 年之后就在蒙特\\n利尔大学任教。在预训练问题，自动编码器降噪等领域做出重大贡献。\\n这“三巨头”中的前两人早已投身工业界，而 Bengio仍留在学术界教书，他曾说过：\\n“我留在学术圈是为全人类作贡献，而不是为某一公司赚钱”。他说这句话一定是因为他很有\\n钱，开个玩笑。每个领域的发展不仅需要做前沿的研究，还需要不断培养新的新鲜血液加入\\n到这个行业中，所以如果大学教授都去工作的话，上课教书的人就少了。所以 Bengio能留\\n在学术圈，对行业的发展也是一件好事。\\n2017 年初 Bengio选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他\\n指的显然是Google 和Facebook）成为人工智能变革中的唯一大玩家，这对研究社区没有\\n好处，对人类也没有好处。\\n4.Andrew Ng（吴恩达）\\nAndrew Ng是美籍华人，曾经是斯坦福大学计算机科学系和电气工程系的副教授，斯\\n坦福人工智能实验室主任。他还与Daphne Koller一起创建了在线教育平台Coursera。\\n2011 年，Andrew Ng在Google 创建了Google Brain 项目，通过分布式集群计算机\\n开发超大规模的人工神经网络。\\n2014 年5 月，Andrew Ng加入百度，负责百度大脑计划，并担任百度公司首席科学\\n家。\\n2017 年3 月，Andrew Ng从百度离职，目前自己创业。\\nLeCun 是Hinton 的 博士生，另一位人工智能大师 Jordan 曾经申请过Hinton 的博士\\n生，Bengio是Jordan 的博士后，Andrew Ng是Jordan 的博士生，LeCun 与Bengio曾\\n经是同事。这个圈子很小，大家都认识，这几位大师互相之间有着很深的渊源。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 46, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 47\\n曾经神经网络的圈子很小，基本上入了这个圈以后就没什么前途了。正是由于这个圈子\\n里的这些大师前辈们的不懈努力，把神经网络算法不断优化，才有了今天的深度学习和今天\\n人工智能的新局面。\\n1.7 新一轮人工智能爆发的三要素\\n这一轮人工智能大爆发的主要原因有 3 个，深度学习算法，大数据，以及高性能计算。\\n深度学习算法 —— 之前人工智能领域的实际应用主要是使用传统的机器学习算法，虽\\n然这些传统的机器学习算法在很多领域都取得了不错的效果，不过仍然有非常大的提升空间。\\n深度学习出现后，计算机视觉，自然语言处理，语音识别等领域都取得了非常大的进步。\\n大数据 —— 如果把人工智能比喻成一个火箭，那么这个火箭需要发射升空，它的燃料就\\n是大数据。以前在实验室环境下很难收集到足够多的样本，现在的数据相对以前在数量、覆盖\\n性和全面性方面都获得了大幅提升。一般来说深度学习模型想要获得好的效果，就需要把大量\\n的数据放到模型中进行训练。\\n高性能计算 —— 以前高性能计算大家 用的是 CPU 集群，现在做深度学习都是 用\\nGPU(Graphics Processing Unit)或TPU(Tensor Processing Unit)。想要使用大量的数据\\n来训练复杂的深度学习模型那就必须要具备高性能计算能力。GPU就是我们日常所说的显卡，\\n平时主要用于打游戏。但是 GPU 不仅可以用于打游戏，还可以用来训练模型，性价比很高，\\n买显卡的理由又多了一个。如果只是使用几个 CPU 来训练一个复杂模型可能会需要花费几周\\n甚至几个月的时间。把数百块 GPU 连接起来做成集群，用这些集群来训练模型，原来一个月\\n才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 47, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 48\\n间。TPU是谷歌专门为机器学习量身定做的处理器，执行每个操作所需的晶体管数量更少，效\\n率更高。\\n工欲善其事，必先利其器。下一章节我们将介绍如何搭建 python开发环境，为我们后续\\n的学习做准。\\n1.8 参考文献\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\narXiv:1804.02767, 2018.\\n[2] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\ninternational conference on computer vision. 2017: 2961-2969.\\n[3] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint\\narXiv:1508.06576, 2015.\\n[4] Hebb D O. The organization of behavior: A neuropsychological theory[M].\\nPsychology Press, 2005.\\n[5] Minsky M, Papert S A. Perceptrons: An introduction to computational\\ngeometry[M]. MIT press, 2017.\\n[6] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-\\npropagating errors[J]. nature, 1986, 323(6088): 533-536.\\n[7] Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets[J].\\nNeural computation, 2006, 18(7): 1527-1554.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 48, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 49\\n第 2 章-搭建 Python 编程环境\\n本章节内容与深度学习没有直接关系，不过随着人工智能技术的发展，Python 已经成为\\n时下最热门的编程语言之一，广泛应用于机器学习和深度学习的应用中。目前大多数深度学习\\n框架的主要编程语言都是 Python，Python 可谓是目前人工智能领域的第一语言。本书中使\\n用的所有代码都是python程序，所以这一章节我们主要学习python编程环境的搭建。\\n如果大家之前有python基础那这一章节的内容就比较简单了，直接跳过也可以。如果大\\n家之前完全没有学过 python，那么建议大家还是先学习 python 的使用，不然后续编程实践\\n的内容可能会碰到很多问题。\\n2.1 Python 介绍\\nPython 是一种面向对象的解释型计算机程序设计语言，由荷兰人 Guido van Rossum于\\n1989 年发明。Python 具有丰富强大的库，常被称为“胶水语言”，因为它能够把其他语言（尤\\n其是C/C++）制作各种模块轻松联结在一起。\\nPython 的主要优点是开发效率高，可移植性强，可拓展性强，应用广泛等，主要的缺点\\n是程序运行效率相比C/C++来说比较慢。\\nPython 的主要应用领域有系统编程，网络爬虫，人工智能，科学计算，WEB 开发，系统\\n运维，大数据，云计算，量化交易，金融分析，图形界面。\\n谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google\\n广告等项目都在大量使用Python 开发。\\nCIA: 美国中情局网站就是用Python 开发的。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 49, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 50\\nNASA: 美国航天局(NASA)大量使用Python 进行数据分析和运算。\\nYouTube:世界上最大的视频网站 YouTube就是用Python 开发的。\\nDropbox:美国最大的在线云存储网站，全部用 Python 实现，每天网站处理10 亿个文件\\n的上传和下载。\\nInstagram:美国最大的图片分享社交网站，每天超过3千万张照片被分享，全部用python\\n开发。\\nFacebook:大量的基础库均通过Python 实现的。\\nRedhat: 世界上最流行的Linux发行版本中的 yum 包管理工具就是用python开发的。\\n豆瓣: 公司几乎所有的业务均是通过 Python 开发的。\\n知乎: 国内最大的问答社区，通过 Python 开发。\\n2.2 Anaconda 安装\\n推荐的Python 安装方式是使用Anaconda对Python 进行安装。Anaconda是一个开源\\n的 Python 发行版本，其中包含了 Numpy,Pandas,Matplotlib 等多个常用的 Python 包和依\\n赖项。Anaconda的官方下载地址为：https://www.anaconda.com/download/。官方下载\\n地址上大家看到的是最新的 python 安装包的下载，如果想下载之前版本的 python，可以通\\n过下面这个地址：https://repo.continuum.io/archive/。\\n目前Python 常用的版本有2.7 和3.6/3.7/3.8 版本，python官方已经宣布以后python2\\n将会停止维护，python 以后会逐渐往 python3 的方向发展，所以推荐大家学习 python3。\\n之后python的版本还会不断更新，可能还会继续推出3.9/3.10/4.0 等。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 50, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 51\\nPython2 和 python3 稍微有些差异，python3.6/3.7/3.8 之间的差异就不大了，所以我\\n们不一定要安装最新的 python，因为有些软件可能跟最新的 python 会不兼容。比如现在\\npython的最新版本是3.8，那么我们可以安装 3.6/3.7 的版本，这样兼容性会稍微好一些。\\nPython 程序在Windows,Linux,MacOS 下基本是差不多的，所以在Windows上可以运\\n行的Python 程序，在其他系统一般也能运行。\\n下面我们主要讲解 Anaconda 在 Windows 环境下的安装，其他系统的安装方式略有不\\n同，如果你熟悉其他系统的话，安装起来应该也是很简单的。如果我们要安装最新版本的\\nAnaconda，首先打开 Anaconda 下载网址，根据系统选择相应的 Anaconda 安装包。选择\\nPython3.7 版本、64 位的安装包进行下载，如图 2.1 所示。\\n图2.1 Anaconda 下载\\n如果我 们 要安装之前 版 本 的 Anaconda ， 可 以打开网 址\\nhttps://repo.continuum.io/archive/，出现如图2.2 所示的界面。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 51, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 52\\n图2.2 各种版本的Anaconda\\nAnaconda2 表示安装python2，Anaconda3 表示安装python3，具体是python3.X，\\n从安装包的文件名是看不出来的。Windows/MacOSX/Linux 表示对应的操作系统。有64 表\\n示64 位的系统，没有64 表示32 位的系统。\\n安装包下载好之后，双击安装包进行安装。如图 2.3 所示，单击Next按钮,。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 52, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 53\\n图2.3 Anaconda 安装流程（1）\\n然后单击I Agree 按钮，如图2.4 所示。\\n图2.4 Anaconda 安装流程（2）\\n接下来可以选择All Users，单击 Next按钮，如图2.5 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 53, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 54\\n图2.5 Anaconda 安装流程（3）\\n接下来选择一个Anaconda的安装路径，如图2.6 所示，可以是任何路径，不一定要跟\\n图中的路径一致。\\n图2.6 Anaconda 安装流程（4）\\n最后勾选“Add Anaconda to the system PATH environment variable”和\\n“Register Anaconda as the system Python3.6”，然后单击Install 按钮，Anaconda就\\n开始安装了。这里注意，一定要勾选相应选项，其目的是让软件帮我们自动配置环境变量，\\n如图2.7 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 54, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 55\\n图2.7 Anaconda 安装流程（5）\\n安装的过程大家不要心急，耐心等待，不要随意关闭软件的窗口，等确认软件已经安装\\n完毕再关闭窗口。后面软件会有提示是否要安装 VSCode，VSCode是一款很好用的编译\\n器，可以用于开发各种编程语言写的程序，包括 python。大家感兴趣的话可以安装，不安\\n装也可以。\\n2.3 Jupyter Notebook 的简单使用\\nPython 有非常多的集成开发环境可以使用，比如Jupyter Notebook，Spyder，\\nPyCharm，Eclipse，VSCode等等，每种开发环境都各有优缺点，这里就不一一介绍了。如\\n果大家之前已经有熟悉并喜欢的开发环境可以继续使用，如果大家是初学者对各种开发环境\\n不了解的话推荐大家可以先使用Jupyter Notebook。Jupyter Notebook的优点是界面和\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 55, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 56\\n功能都比较简洁，并且可以实时运行查看程序结果，还可以把程序运行的结果保存在文件\\n中。缺点是不太好开发大型程序，不过对于初学者来说，我们可能暂时还不会接触到大型程\\n序，Jupyter Notebook基本就够用了。本书中的程序基本都是在 Jupyter Notebook中完\\n成的，它是安装完Anaconda后自带的一个Python 开发环境。界面简洁，使用简单，适合\\n快速实验和用于学习。\\n我会给大家提供书中Jupyter Notebook 的程序文件以及python的程序文件。Jupyter\\nNotebook 的程序文件是以“.ipynb”结尾，只能在Jupyter Notebook 中运行，不能在命\\n令提示符/终端运行；python的程序文件是以“.py”结尾，不能在Jupyter Notebook 中运\\n行，可以在其他python集成开发环境或者命令提示符/终端运行。Jupyter Notebook 的程\\n序文件可以在Jupyter Notebook 环境中转成 python程序文件。\\n2.3.1 启动 Jupyter Notebook\\nAnaconda安装完成后桌面上不会增加新的图标，我们需要搜索Jupyter Notebook，\\n找到这个开发环境，Jupyter的图标如图 2.8 所示，找到后可以右键单击图标，然后发送到\\n桌面快捷方式。\\n图2.8 Jupyter Notebook\\n双击Jupyter Notebook，打开后可以看到 Jupyter 是在网页中进行编程的，在Jupyter\\n的界面中我们可以对我们电脑本地的文件进行新建，删除和修改，如图 2.9 所示\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 56, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 57\\n图2.9 Jupyter 主界面\\n2.3.2 修改 Jupyter Notebook 默认启动路径\\n大家打开Jupyter后，可能会在的主界面中看到一些熟悉的文件，这些文件正是我们电\\n脑本地的一些文件，其实Jupyter的主界面对应的是我们电脑中的一个路径，这个路径是可\\n以修改的，我们可以创建一个新的文件夹，专门用于写 python程序。\\nJupyter Notebook 的默认启动路径为：”C:\\\\User\\\\你的用户名\\\\”。所以第一次打开\\nJupyter Notebook 我们会看到”C:\\\\User\\\\你的用户名\\\\”这个路径的文件出现在Jupyter\\nNotebook 的主界面。其实Jupyter Notebook 的启动路径不一定要修改，如果你想使\\n用”C:\\\\User\\\\你的用户名\\\\”或者你觉得修改 Jupyter Notebook 默认路径比较麻烦，那么你\\n可以使用默认的”C:\\\\User\\\\你的用户名\\\\”路径作为Jupyter Notebook 的工作路径。只要把\\npython相关的程序（比如书中代码）复制到”C:\\\\User\\\\你的用户名\\\\”路径下，在Jupyter\\nNotebook 的主界面就可以看到你复制的程序，然后在 Jupyter Notebook 环境中就可以对\\n这些程序进行修改和运行了。\\n如果希望把程序存放在其他路径，使用其他路径作为 Jupyter Notebook 的工作路径，\\n那么就进行下面的操作：\\n首先我们要右键Jupyter Notebook 的图标，查看属性，然后看到目标，目标最后如果\\n有%USERPROFILE%，则把后面的%USERPROFILE%删掉，如图2.10 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 57, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 58\\n图2.10 删除%USERPROFILE%\\n下一步需要生成配置文件，打开命令提示符执行：jupyter notebook --generate-config，\\n我们会看到如图2.11 所示的结果。\\n图 2.11 生成配置文件\\n我 们 可 以看到 配置文件生成 的 位置， 本 书例子中配置文件生成 的 位置\\n是 C:\\\\Users\\\\qin\\\\.jupyter\\\\jupyter_notebook_config.py，进入系统盘，用户文件下，可以看\\n到一个.jupyter的文件，如图2.12 所示\\n图2.12 .jupyter文件\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 58, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 59\\n进入.jupyter文件夹中找到jupyter_notebook_config.py 文件，用文本工具打开\\njupyter_notebook_config.py 文件，找c.NotebookApp.notebook_dir 配置，“#”为注\\n释，先把它前面的“#”给去掉，然后填入你想要的 Python 程序存放路径。如图2.13 所\\n示。\\n图 2.13 修改Jupyter工作路径\\n图中的例子是在“E/test”，大家不一定要使用这个路径，可以任意设置其他路径。注意\\n这里设置的路径必须是本地已经存在的路径。注意路径最好是全英文，如果路径有中文需要\\n把jupyter_notebook_config.py 文件另存为UTF-8 的格式。注意路径中的斜杠是“/”不是\\n“\\\\”。\\n顺利的话，重新启动Jupyter Notebook 就可以看到Jupyter的主界面跳转到了你设置\\n的路径。\\n如果是使用Linux或者MacOS 的话可以先在终端用cd 命令跳转到你的程序所在路径，\\n然后使用命令：\\njupyter notebook\\n打开Jupyter Notebook 软件，这时你会看到你的程序所在路径已经成为你的 Jupyter\\nNotebook 的工作路径。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 59, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 60\\n2.3.3 Jupyter Notebook 浏览器无法打开\\n如果电脑的浏览器太老，有可能会出现 Jupyter Notebook 无法打开的情况，Jupyter\\nNotebook 闪退，或者是浏览器一片空白。这个时候可以下载安装一个新的谷歌浏览器，然\\n后再打开Jupyter Notebook 的配置文件，在任意位置加入如下命令：\\nimport webbrowser\\nwebbrowser.register(\"chrome\",None,webbrowser.GenericBrowser(u\"C:/ProgramFile\\ns(x86)/Google/Chrome/Application/chrome.exe\"))\\nc.NotebookApp.browser = \\'chrome\\'\\n该命令的作用是把Jupyter Notebook 的默认浏览器设置为谷歌浏览器，其中\\n\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\"为谷歌浏览器的执行\\n文件所在位置，每台电脑位置可能不同，需要自己查看修改。\\n2.3.4 Jupyter Notebook 基本操作\\n接下来新建一个文件，单击右上角的 New按钮，然后单击Python 选项，这样就可以创\\n建一个新的文件，如图2.14所示。\\n图2.14 创建新文件\\n创建好文件之后，可以看到如图2.15 所示的界面。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 60, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 61\\n图2.15 Jupyter 编译界面\\n单击Untitled的位置可以修改文件名字，如图2.16 所示。\\n图2.16 Jupyter 修改文件名\\n然后就可以开始编程了，按照惯例，我们先来写一个“hello world”，写完之后，按\\n“Shift+Enter”组合键执行程序，按住 Shift不要放手，然后按Enter。如图2.17 所示。\\n图2.17 执行hello world\\n一个框内可以执行多行代码，如图 2.18所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 61, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 62\\n图2.18 执行多行代码\\n把光标移动到函数的内部，然后按“Shift+Tab”组合键可以查看该函数的使用方法，先按\\n住Shift不要放手，然后按两下Tab，如图 2.19 所示。\\n图2.19 查看函数说明\\nJupyter还有很多神奇的用法，大家有兴趣可以去探索，这里就不过多介绍了。\\n下一章我们将正式开始进入神经网络深度学习的大门。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 62, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 63\\n第 3 章-单层感知器与线性神经网络\\n本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络ANN 的设\\n计实际上是从生物体的神经网络结构获得的灵感。模仿生物神经网络我们构造出了单层感知器，\\n在单层感知器的基础上经过不断地优化才得到了后来的神经网络算法。\\n3.1 生物神经网络\\n生物神经网络一般是指生物的大脑神经元，细胞等组成的网络，用于产生生物的意识，帮\\n助生物进行思考和行动。\\n神经细胞构是构成神经系统的基本单元，简称为神经元。神经元主要由三部分构成：①细\\n胞体；②轴突；③树突。如3.1 图所示。\\n图 3.1 生物神经元结构\\n每个神经元伸出的突起分 2 种，树突和轴突。树突分支比较多，每个分支还可以再分支，\\n长度一般比较短，作用是接受信号。轴突只有一个，从细胞体的一个凸出部分伸出，长度一般\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 63, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 64\\n比较长，作用是把从树突和细胞表面传入细胞体的神经信号传出到其他神经元。轴突的末端分\\n为许多小支，连接到其他神经元的树突上。\\n大脑可视作为1000 多亿神经元组成的神经网络。神经元的信息传递和处理是一种电化学\\n活动。树突由于电化学作用接受外界的刺激，通过胞体内的活动体现为轴突电位，当轴突电位\\n达到一定的值则形成神经脉冲或动作电位；再通过轴突末梢传递给其它的神经元。从控制论的\\n观点来看，这一过程可以看作一个多输入单输出非线性系统的动态过程。\\n3.2 单层感知器\\n3.2.1 单层感知器介绍\\n受到生物神经网络的启发，计算机学家 Frank Rosenblatt在20 世纪60 年代提出了一种\\n模拟生物神经网络的的人工神经网络结构，称为感知器（Perceptron）。图 3.1 为单层感知器\\n结构图。\\n图3.1 单层感知器\\n图中𝑥 ，𝑥 ，𝑥 为输入信号，类似于生物神经网络中的树突。\\n\" # $\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 64, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 65\\n𝑤 ，𝑤 ，𝑤 分别为𝑥 ，𝑥 ，𝑥 的权值，它可以调节输入信号的值的大小，让输入信号变大\\n\" # $ \" # $\\n(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突\\n传递到细胞核的过程中信号会发生变化。\\n公式∑ (𝑤 𝑥 )+𝑏表示细胞的输入信号在细胞核的位置进行汇总∑ 𝑤 𝑥 ，然后再加上该细\\n( ( ( ( ( (\\n胞本身自带的信号b。b一般称为偏置值（Bias），相当于是神经元内部自带的信号。\\nf(x)称为激活函数，可以理解为信号在轴突上进行的线性或非线性变化。在单层感知器中\\n最开始使用的激活函数是 sign(x)激活函数。该函数的特点是当 x＞0 时，输出值为 1；当x＝\\n0 时，输出值为 0,；当x＜0 时，输出值为-1。sign(x)函数图像如图3.2 所示。\\n图3.2 sign 函数图像\\ny 就是𝑓(∑ (𝑤 𝑥 )+𝑏)，为单层感知器的输出结果。\\n( ( (\\n3.2.2 单层感知器计算举例\\n假如有一个单层感知器有 3 个输入𝑥 ，𝑥 ，𝑥 ，同时已知 b=-0.6，𝑤 =𝑤 =𝑤 =0.5，那\\n\" # $ \" # $\\n么根据单层感知器的计算公式𝑓(∑ (𝑤 𝑥 )+𝑏)我们就可以得到如图3.3 计算结果。\\n( ( (\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 65, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 66\\n图 3.3 单层感知器计算\\n𝑥 =0, 𝑥 =0, 𝑥 =0：sign(0.5×0+0.5×0+0.5×0−0.6) = −1\\n\" # $\\n𝑥 =0, 𝑥 =0, 𝑥 =1：sign(0.5×0+0.5×0+0.5×1−0.6) = −1\\n\" # $\\n𝑥 =0, 𝑥 =1, 𝑥 =0：sign(0.5×0+0.5×1+0.5×0−0.6) = −1\\n\" # $\\n𝑥 =0, 𝑥 =1, 𝑥 =1：sign(0.5×0+0.5×1+0.5×1−0.6) = 1\\n\" # $\\n𝑥 =1, 𝑥 =0, 𝑥 =0：sign(0.5×1+0.5×0+0.5×0−0.6) = −1\\n\" # $\\n𝑥 =1, 𝑥 =0, 𝑥 =1：sign(0.5×1+0.5×0+0.5×1−0.6) = 1\\n\" # $\\n𝑥 =1, 𝑥 =1, 𝑥 =0：sign(0.5×1+0.5×1+0.5×0−0.6) = 1\\n\" # $\\n𝑥 =1, 𝑥 =1, 𝑥 =1：sign(0.5×1+0.5×1+0.5×1−0.6) = 1\\n\" # $\\n3.2.3 单层感知器的另一种表达形式\\n单层感知器的另一种表达形式如图 3.4。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 66, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 67\\n图3.4 单层感知器的另一种表达形式\\n其实这种表达形式跟 3.2.1 中的单层感知器是一样的。只不过是把偏置值 b 变成了输入\\n𝑤 ×𝑥 ，其中𝑥 =1。所以𝑤 ×𝑥 实际上就是𝑤 ，把∑ (𝑤 𝑥 )公式展开得到：𝑤 ×𝑥 +𝑤 ×𝑥 +\\n< < < < < < ( ( ( \" \" # #\\n𝑤 ×𝑥 +𝑤 。所以这两个单层感知器的表达不一样，但是计算结果是一样的。如图 3.4 的表\\n$ $ <\\n达形式更加简洁，更适合使用矩阵来进行运算。\\n3.3 单层感知器的学习规则\\n3.3.1 单层感知器的学习规则介绍\\n感知器的学习规则就是指感知器中的权值参数训练的方法，在本章节中我们暂时先不解释\\n这个学习规则是怎么推导出来的。等第 4 章我们讲到 Delta 学习规则的时候我们再来解释感\\n知器的学习规则是如何推导的。在这里我们可以先接受下面的公式即可。\\n在3.2.3 中我们已知单层感知器表达式可以写成：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 67, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 68\\n@\\n𝑦 = 𝑓>?(𝑤 𝑥 )B (3.1)\\n( (\\n(A<\\n公式(3.1)中：y 表示感知器的输出；f是sign 激活函数；n 是输入信号的个数i=0,1,2...\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 (3.2)\\n( (\\n公式(3.2)中：∆𝑤 表示第i 个权值的变化；𝜂表示学习率(Learning Rate)，用来调节权值\\n(\\n变化的大小；t是正确的标签(target)。\\n因为单层感知器的激活函数为 sign 函数，所以t和y 的取值都为±1\\nt=y时，∆𝑤 为0；t=1，y=-1 时，∆𝑤 为2；t=-1，y=1 时，∆𝑤 为-2。由式(3.2)可以推\\n( ( (\\n出：\\n∆𝑤 = ±2𝜂𝑥 (3.3)\\n( (\\n权值的调整公式为：\\n𝑤 = 𝑤 + ∆𝑤 (3.4)\\n( ( (\\n3.3.2 单层感知器的学习规则计算举例\\n假设有一个单层感知器如图3.1 所示，已知有三个输入x0=1，x1=0，x2=-1，权值\\nw0=-5，w1=0，w2=0，学习率𝜂=1，正确的标签t=1。(注意在这个例子中偏置值b用\\n𝑤 ×𝑥 来表示，x0 的值固定为1)\\n< <\\nStep1：我们首先计算感知器的输出。\\n@\\n𝑦 = 𝑓>?(𝑤 𝑥 )B\\n( (\\n(A<\\n= sign(−5 × 1 + 0 × 0 + 0 × (−1) + 0)\\n= sign(−5)\\n= −1\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 68, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 69\\n由于y=-1 与正确的标签t=1 不相同，所以需要对感知器中的权值进行调节。\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × 1 = 2\\n< <\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × 0 = 0\\n\" \"\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × (−1) = −2\\n# #\\n𝑤 = 𝑤 + ∆𝑤 = −5 + 2 = −3\\n< < <\\n𝑤 = 𝑤 + ∆𝑤 = 0 + 0 = 0\\n\" \" \"\\n𝑤 = 𝑤 + ∆𝑤 = 0 − 2 = −2\\n# # #\\nStep2：重新计算感知器的输出。\\n@\\n𝑦 = 𝑓>?(𝑤 𝑥 )B\\n( (\\n(A<\\n= sign(−3 × 1 + 0 × 0 + (−2) × (−1) + 0)\\n= sign(−1)\\n= −1\\n由于y=-1 与正确的标签t=1 不相同，所以需要对感知器中的权值进行调节。\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × 1 = 2\\n< <\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × 0 = 0\\n\" \"\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 = 1 × (1 + 1) × (−1) = −2\\n# #\\n𝑤 = 𝑤 + ∆𝑤 = −3 + 2 = −1\\n< < <\\n𝑤 = 𝑤 + ∆𝑤 = 0 + 0 = 0\\n\" \" \"\\n𝑤 = 𝑤 + ∆𝑤 = −2 − 2 = −4\\n# # #\\nStep3：重新计算感知器的输出。\\n@\\n𝑦 = 𝑓>?(𝑤 𝑥 )B\\n( (\\n(A<\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 69, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 70\\n= sign(−1 × 1 + 0 × 0 + (−4) × (−1) + 0)\\n= sign(3)\\n= 1\\n由于 y=1 与正确的标签 t=1 相同，说明感知器经过训练后得到了我们想要的结果，我们\\n就可以结束训练了。\\n把上面的例子写成python程序的话，可以得到代码3-1。\\n代码3-1：单层感知器学习规则计算举例\\n# 导入numpy 科学计算包\\nimport numpy as np\\n# 定义输入\\nx0 = 1\\nx1 = 0\\nx2 = -1\\n# 定义权值\\nw0 = -5\\nw1 = 0\\nw2 = 0\\n# 定义正确的标签\\nt = 1\\n# 定义学习率lr(learning rate)\\nlr = 1\\n# 定义偏置值\\nb = 0\\n# 循环一个比较大的次数，比如100\\nfor i in range(100):\\n# 打印权值\\nprint(w0,w1,w2)\\n# 计算感知器的输出\\ny = np.sign(w0 * x0 + w1 * x1 + w2*x2)\\n# 如果感知器输出不等于正确的标签\\nif(y != t):\\n# 更新权值\\nw0 = w0 + lr * (t-y) * x0\\nw1 = w1 + lr * (t-y) * x1\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 70, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 71\\nw2 = w2 + lr * (t-y) * x2\\n# 如果感知器输出等于正确的标签\\nelse:\\n# 训练结束\\nprint('done')\\n# 退出循环\\nbreak\\n运行结果如下：\\n-5 0 0\\n-3 0 -2\\n-1 0 -4\\ndone\\n下面我们还可以用矩阵运算的方式来完成同样的计算，代码 3-2 为矩阵运算的方式来进\\n行单层感知器学习规则的计算。\\n代码3-2：单层感知器学习规则计算举例(矩阵计算)\\n# 导入numpy 科学计算包\\nimport numpy as np\\n# 定义输入，用大写字母表示矩阵\\n# 一般我们习惯用一行来表示一个数据，如果存在多个数据就用多行来表示\\nX = np.array([[1,0,-1]])\\n# 定义权值，用大写字母表示矩阵\\n# 神经网络中权值的定义可以参考神经网络的输入是输出神经元的个数\\n# 在本例子中输入神经元个数为3 个，输出神经元个数为1 个，所以可以定义3 行1 列的W\\nW = np.array([[-5],\\n[0],\\n[0]])\\n# 定义正确的标签\\nt = 1\\n# 定义学习率lr(learning rate)\\nlr = 1\\n# 定义偏置值\\nb = 0\\n# 循环一个比较大的次数，比如100\\nfor i in range(100):\\n# 打印权值\\nprint(W)\\n# 计算感知器的输出，np.dot可以看做是矩阵乘法\\ny = np.sign(np.dot(X,W))\\n# 如果感知器输出不等于正确的标签\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 71, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 72\\nif(y != t):\\n# 更新权值\\n# X.T表示X矩阵的转置\\n# 这里一个步骤可以完成代码3-1 中下面3 行代码完成的事情\\n# w0 = w0 + lr * (t-y) * x0\\n# w1 = w1 + lr * (t-y) * x1\\n# w2 = w2 + lr * (t-y) * x2\\nW = W + lr * (t - y) * X.T\\n# 如果感知器输出等于正确的标签\\nelse:\\n# 训练结束\\nprint('done')\\n# 退出循环\\nbreak\\n运行结果如下：\\n[[-5]\\n[ 0]\\n[ 0]]\\n[[-3]\\n[ 0]\\n[-2]]\\n[[-1]\\n[ 0]\\n[-4]]\\ndone\\n3.4 学习率\\n学习率是人为设定的一个超参数，主要是在训练阶段用来控制模型参数调整的快慢。关于\\n学习率主要有3 个要点需要注意：\\n（1）学习率𝜼取值一般取0-1之间；\\n（𝟐）学习率太大容易造成权值调整不稳定；\\n（3）学习率太小，模型参数调整太慢，迭代次数太多。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 72, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 73\\n你可以想象一下在洗热水澡的时候：如果每次调节的幅度很大，那水温要不就是太热，\\n要不就是太冷，很难得到一个合适的水温；如果一开始的时候水很冷，每次调节的幅度都非\\n常小，那么需要调节很多次，花很长时间才能得到一个合适的水温。学习率的调整也是这样\\n一个道理。图3.5 表示不同大小的学习率对模型训练的影响。\\n图3.5 不同大小的学习率对模型训练的影响\\n图中的纵坐标loss代表代价函数（Loss Function），在后面的章节中有更详细的介\\n绍，这里我们可以把它近似理解为模型的预测值与真实值之间的误差。我们训练模型的主要\\n目的就是为了降低loss值，减少模型预测值与真实值之间的误差。横坐标Epoch代表模型\\n的迭代周期，把所有训练数据都训练一遍可以称为迭代了一个周期。\\n从图中我们可以看到，如果使用非常大的学习率（very high lr）来训练模型，loss会一\\n直处于一个比较大的位置，模型不能收敛，这肯定不是我们想要的结果。如果使用比较大的\\n学习率（high lr）来训练模型，loss会下降很快，但是最后loss最终不能得到比较比较小的\\n值，所以结果也不理想。如果使用比较小的学习率（low lr）来训练模型，模型收敛的速度\\n会很慢，需要等待很长时间模型才能收敛。最理想的结果是使用合适的学习率（good lr）来\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 73, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 74\\n训练模型，使用合适的学习率，模型的 loss值下降得比较快，并且最后的loss也能够下降\\n到一个比较小的位置，结果最理想。\\n看到这里大家可能会有一个疑问，学习率的值到底取多少比较合适？这个问题其实是没\\n有明确答案的，需要根据建模的经验以及测试才能找到合适的学习率。不过学习率的选择也\\n有一些小的trick可以使用，比如说最开始我们设置一个学习率为0.01，经过测试我们发现\\n学习率太小了需要调大一点，那么我们可以改成 0.03。如果0.03 还需要调大，我们可以调\\n到0.1。同理，如果0.01 太大了，需要调小，那么我们可以调到0.003。如果0.003还需要\\n调小，我们可以调到0.001。所以常用的学习率可以选择：\\n1，0.3，0.1，0.03，0.01，0.003，0.001，0.0003，0.0001 ...\\n当然这也不是绝对的，其他的学习率的取值你也可以去尝试。\\n3.5 模型的收敛条件\\n通常模型的收敛条件可以有以下3 个：\\n（1）loss小于某个预先设定的较小的值；\\n（2）两次迭代之间权值的变化已经很小了；\\n（3）设定最大迭代次数，当迭代超过最大次数就停止。\\n第一种很容易理解，模型的训练目的就是为了减少 loss 值，那么我们可以设定一个比较\\n小的数值，每一次训练的时候我们都同时计算一下 loss值的大小，当 loss值小于某个预先设\\n定的阈值，就可以认为模型收敛了。那么就可以结束训练。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 74, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 75\\n第二种的意思是，每一次训练我们可以记录模型权值的变化，如果我们发现两次迭代之间\\n模型的权值变化已经很小，那么说明模型已经几乎不需要做权值地调整了，那么就可以认为模\\n型收敛，可以结束训练。\\n第三种是用得最多的方式。我们可以预先设定一个比较大的模型迭代周期，比如迭代 100\\n次，或者 10000 次，或者 1000000 次等（需要根据实际情况来选择）。模型完成规定次数的\\n训练之后我们就可以认为模型训练完毕。如果达到我们设置的训练次数以后我们发现模型还没\\n有训练好的话，我们可以继续增加训练次数，让模型继续训练就可以了。\\n3.6 模型的超参数和参数的区别\\n模型的超参数（Hyperparameters）是机器学习或者深度学习中经常用到的一个概念，\\n我们可以认为是根据经验来人为设置的一些模型相关的参数。比如说前面提到的学习率，学习\\n率需要根据经验来人为设置。比如模型的迭代次数，也是需要在模型训练之前预先进行人为设\\n置。\\n而前面提到的权值和偏置值则是参数（Parameters），一般指的是模型中需要训练的变量。\\n我们会给权值和偏置值进行随机初始化赋值，模型在训练过程中会不断调节这些参数，进行模\\n型优化。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 75, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 76\\n3.7 单层感知器分类案例\\n题目：假设我们有 4 个 2 维的数据，数据的特征分别是(3,3),(4,3),(1,1),(2,1)。(3,3),(4,3)\\n这两个数据的标签为1，(1,1),(2,1)这两个数据的标签为-1。构建神经网络来进行分类。\\n思路：我们要分类的数据是2 维数据，所以只需要2 个输入节点（一般输入数据有几个特\\n征，我们就设置几个输入神经元），我们可以把神经元的偏置值也设置成一个输入节点，使用\\n3.2.3 中的方式。这样我们需要3 个输入节点。\\n输入数据有4 个(1,3,3),(1,4,3),(1,1,1),(1,2,1)\\n数据对应的标签为(1,1,-1,-1)\\n初始化权值w1,w2,w3 取0 到1 的随机数\\n学习率lr(learning rate)设置为0.1\\n激活函数为sign 函数\\n我们可以构建一个单层感知器如图 3.6 所示。\\n图3.6 单层感知器\\n代码3-3 为单层感知器应用案例。\\n代码3-3：单层感知器案例\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 76, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 77\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# 定义输入，我们习惯上用一行代表一个数据\\nX = np.array([[1,3,3],\\n[1,4,3],\\n[1,1,1],\\n[1,2,1]])\\n# 定义标签，我们习惯上用一行表示一个数据的标签\\nT = np.array([[1],\\n[1],\\n[-1],\\n[-1]])\\n# 权值初始化，3 行1 列\\n# np.random.random可以生成0-1 的随机数\\nW = np.random.random([3,1])\\n# 学习率设置\\nlr = 0.1\\n# 神经网络输出\\nY = 0\\n# 更新一次权值\\ndef train():\\n# 使用全局变量W\\nglobal W\\n# 同时计算4 个数据的预测值\\n# Y的形状为(4,1)-4 行1 列\\nY = np.sign(np.dot(X,W))\\n# T - Y得到4 个的标签值与预测值的误差E。形状为(4,1)\\nE = T - Y\\n# X.T表示X的转置矩阵，形状为(3,4)\\n# 我们一共有4 个数据，每个数据3 个值。定义第i 个数据的第j 个特征值为xij\\n# 如第1 个数据，第 2 个值为x12\\n# X.T.dot(T - Y)为一个3 行1 列的数据：\\n# 第1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第1 个神经元对应的权值\\n# 第2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第2 个神经元对应的权值\\n# 第3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整3 个神经元对应的权值\\n# X.shape 表示X的形状X.shape[0]得到X 的行数，表示有多少个数据\\n# X.shape[1]得到列数，表示每个数据有多少个特征值。\\n# 这里的公式跟书中公式3.2看起来有些不同，原因是这里的计算是矩阵运算，书中公\\n式3.2是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的\\ndelta_W = lr * (X.T.dot(E)) / X.shape[0]\\nW = W + delta_W\\n# 训练100 次\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 77, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 78\\nfor i in range(100):\\n#更新一次权值\\ntrain()\\n# 打印当前训练次数\\nprint('epoch:',i + 1)\\n# 打印当前权值\\nprint('weights:',W)\\n# 计算当前输出\\nY = np.sign(np.dot(X,W))\\n# .all()表示Y中的所有值跟T中所有值都对应相等，结果才为真\\nif(Y == T).all():\\nprint('Finished')\\n# 跳出循环\\nbreak\\n#————————以下为画图部分————————#\\n# 正样本的xy坐标\\nx1 = [3,4]\\ny1 = [3,3]\\n# 负样本的xy坐标\\nx2 = [1,2]\\ny2 = [1,1]\\n# 计算分类边界线的斜率以及截距\\n# 神经网络的信号总和为w0×x0+w1×x1+w2×x2\\n# 当信号总和大于0 再进过激活函数，模型的预测值会得到1\\n# 当信号总和小于0 再进过激活函数，模型的预测值会得到-1\\n# 所以当信号总和w0×x0+w1×x1+w2×x2=0时为分类边界线表达式\\n# 我们在画图的时候把x1，x2 分别看成是平面坐标系中的x和y\\n# 可以得到：w0 + w1×x + w2 × y = 0\\n# 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到：\\nk = - W[1] / W[2]\\nd = -W[0] / W[2]\\n# 设定两个点\\nxdata = (0,5)\\n# 通过两个点来确定一条直线，用红色的线来画出分界线\\nplt.plot(xdata,xdata * k + d,'r')\\n# 用蓝色的点画出正样本\\nplt.scatter(x1,y1,c='b')\\n# 用黄色的点来画出负样本\\nplt.scatter(x2,y2,c='y')\\n# 显示图案\\nplt.show()\\n运行结果如下：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 78, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 79\\nepoch: 1\\nweights: [[0.83669451]\\n[0.58052698]\\n[0.25564497]]\\nepoch: 2\\nweights: [[0.73669451]\\n[0.43052698]\\n[0.15564497]]\\nepoch: 3\\nweights: [[0.63669451]\\n[0.28052698]\\n[0.05564497]]\\n……\\nepoch: 16\\nweights: [[-0.01330549]\\n[ 0.13052698]\\n[ 0.20564497]]\\nepoch: 17\\nweights: [[-0.11330549]\\n[-0.01947302]\\n[ 0.10564497]]\\nFinished\\n因为权值的初始化使用的是随机的初始化方式，所以每一次训练的周期以及画出来的图\\n可能都是不一样的。这里我们可以看到单层感知器的一个问题，虽然单层感知器可以顺利地\\n完成分类任务，但是使用单层感知器来做分类的时候，最后得到的分类边界距离某一个类别\\n比较近，而距离另一个类别比较远，并不是一个特别理想的分类效果。图 3.7 中的分类效果\\n应该才是比较理想的分类效果，分界线在两个类别比较中间的位置。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 79, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 80\\n图3.7 单层感知器比较理想的分类边界\\n3.8 线性神经网络\\n3.8.1 线性神经网络介绍\\n线性神经网络跟单层感知器非常类似，只是把单层感知器的sign激活函数改成了purelin\\n函数：\\n𝑦 = 𝑥 (3.5)\\npurelin 函数也称为线性函数，函数图像如图3.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 80, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 81\\n图3.8 线性函数\\n3.8.2 线性神经网络分类案例\\n参考“单层感知器案例”，我们这次使用线性神经网络来完成相同的任务。线性神经网络的\\n程序跟单层感知器的程序非常相似，大家可以思考一下需要修改哪些地方。\\n大家可以仔细阅读代码3-4，找到修改了的部分。\\n代码3-4：线性神经网络案例\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# 定义输入，我们习惯上用一行代表一个数据\\nX = np.array([[1,3,3],\\n[1,4,3],\\n[1,1,1],\\n[1,2,1]])\\n# 定义标签，我们习惯上用一行表示一个数据的标签\\nT = np.array([[1],\\n[1],\\n[-1],\\n[-1]])\\n# 权值初始化，3 行1 列\\n# np.random.random可以生成0-1 的随机数\\nW = np.random.random([3,1])\\n# 学习率设置\\nlr = 0.1\\n# 神经网络输出\\nY = 0\\n# 更新一次权值\\ndef train():\\n# 使用全局变量W\\nglobal W\\n# 同时计算4 个数据的预测值\\n# Y的形状为(4,1)-4 行1 列\\nY = np.dot(X,W)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 81, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 82\\n# T - Y得到4 个的标签值与预测值的误差E。形状为(4,1)\\nE = T - Y\\n# X.T表示X的转置矩阵，形状为(3,4)\\n# 我们一共有4 个数据，每个数据3 个值。定义第i 个数据的第j 个特征值为xij\\n# 如第1 个数据，第 2 个值为x12\\n# X.T.dot(T - Y)为一个3 行1 列的数据：\\n# 第1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第1 个神经元对应的权值\\n# 第2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第2 个神经元对应的权值\\n# 第3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整3 个神经元对应的权值\\n# X.shape 表示X的形状X.shape[0]得到X 的行数，表示有多少个数据\\n# X.shape[1]得到列数，表示每个数据有多少个特征值。\\n# 这里的公式跟书中公式3.2看起来有些不同，原因是这里的计算是矩阵运算，书中公式\\n3.2是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的\\ndelta_W = lr * (X.T.dot(E)) / X.shape[0]\\nW = W + delta_W\\n# 训练100 次\\nfor i in range(100):\\n#更新一次权值\\ntrain()\\n#————————以下为画图部分————————#\\n# 正样本的xy坐标\\nx1 = [3,4]\\ny1 = [3,3]\\n# 负样本的xy坐标\\nx2 = [1,2]\\ny2 = [1,1]\\n# 计算分类边界线的斜率以及截距\\n# 神经网络的信号总和为w0×x0+w1×x1+w2×x2\\n# 当信号总和大于0 再进过激活函数，模型的预测值会得到1\\n# 当信号总和小于0 再进过激活函数，模型的预测值会得到-1\\n# 所以当信号总和w0×x0+w1×x1+w2×x2=0时为分类边界线表达式\\n# 我们在画图的时候把x1，x2 分别看成是平面坐标系中的x和y\\n# 可以得到：w0 + w1×x + w2 × y = 0\\n# 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到：\\nk = - W[1] / W[2]\\nd = -W[0] / W[2]\\n# 设定两个点\\nxdata = (0,5)\\n# 通过两个点来确定一条直线，用红色的线来画出分界线\\nplt.plot(xdata,xdata * k + d,'r')\\n# 用蓝色的点画出正样本\\nplt.scatter(x1,y1,c='b')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 82, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 83\\n# 用黄色的点来画出负样本\\nplt.scatter(x2,y2,c='y')\\n# 显示图案\\nplt.show()\\n运行结果如下：\\n线性神经网络的程序有两处是对单层感知器程序进行了修改。\\n第一处是在train()函数中，将Y = np.sign(np.dot(X,W))改成了Y = np.dot(X,W)。因为线性\\n神经网络的激活函数是y=x，所以这里就不需要 np.sign()了。\\n第二处是在for i in range(100)中，把原来的：\\n# 训练100 次\\nfor i in range(100):\\n#更新一次权值\\ntrain()\\n# 打印当前训练次数\\nprint('epoch:',i + 1)\\n# 打印当前权值\\nprint('weights:',W)\\n# 计算当前输出\\nY = np.sign(np.dot(X,W))\\n# .all()表示Y中的所有值跟T中所有值都对应相等，结果才为真\\nif(Y == T).all():\\nprint('Finished')\\n# 跳出循环\\nbreak\\n改成了：\\n# 训练100 次\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 83, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 84\\nfor i in range(100):\\n#更新一次权值\\ntrain()\\n在单层感知器中，当y 等于t时，∆𝑤就会为0，模型训练就结束了，所以可以提前跳出\\n循环。单层感知器使用的模型收敛条件是两次迭代模型的权值已经不再发生变化，则可以认\\n为模型收敛。\\n而在线性神经网络中，y 会一直逼近 t的值，不过一般不会得到等于t的值，所以可以对\\n模型不断进行优化。线性神经网络使用的模型收敛条件是设置一个最大迭代次数，当训练了\\n一定次数后就可以认为模型收敛了。\\n对比单层感知器和线性神经网络所得到的结果，我们可以看得出线性神经网络所得到的\\n结果会比单层感知器得到的结果更理想。但是线性神经网络也还不够优秀，当使用它处理非\\n线性问题的时候，它就不能很好完成工作了。\\n3.9 线性神经网络处理异或问题\\n首先我们先来回顾一下异或运算：\\n（1）0 与0 异或等于0；\\n（2）0 与1 异或等于1；\\n（3）1 与0 异或等于1；\\n（4）1 与1 异或等于0。\\n线性神经网络-处理异或问题的代码如代码3-5 所示。\\n代码3-5：线性神经网络-处理异或问题\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 84, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 85\\n# 输入数据\\n# 4 个数据分别对应0 与0 异或，0 与1 异或，1 与0 异或，1 与1 异或\\nX = np.array([[1,0,0],\\n[1,0,1],\\n[1,1,0],\\n[1,1,1]])\\n# 标签，分别对应4 种异或情况的结果\\n# 注意这里我们使用-1 作为负标签\\nT = np.array([[-1],\\n[1],\\n[1],\\n[-1]])\\n# 权值初始化，3 行1 列\\n# np.random.random可以生成0-1 的随机数\\nW = np.random.random([3,1])\\n# 学习率设置\\nlr = 0.1\\n# 神经网络输出\\nY = 0\\n# 更新一次权值\\ndef train():\\n# 使用全局变量W\\nglobal W\\n# 计算网络预测值\\nY = np.dot(X,W)\\n# 计算权值的改变\\ndelta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n# 更新权值\\nW = W + delta_W\\n# 训练100 次\\nfor i in range(100):\\n#更新一次权值\\ntrain()\\n#————————以下为画图部分————————#\\n# 正样本\\nx1 = [0,1]\\ny1 = [1,0]\\n# 负样本\\nx2 = [0,1]\\ny2 = [0,1]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 85, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 86\\n#计算分界线的斜率以及截距\\nk = - W[1] / W[2]\\nd = - W[0] / W[2]\\n# 设定两个点\\nxdata = (-2,3)\\n# 通过两个点来确定一条直线，用红色的线来画出分界线\\nplt.plot(xdata,xdata * k + d,'r')\\n# 用蓝色的点画出正样本\\nplt.scatter(x1,y1,c='b')\\n# 用黄色的点来画出负样本\\nplt.scatter(x2,y2,c='y')\\n# 显示图案\\nplt.show()\\n运行结果如下：\\n从结果我们能够看出用一条直线并不能把异或问题中的两个类别给划分开来，因为这是一\\n个非线性的问题，可以使用非线性的方式来进行求解。\\n其中一种方式是我们可以给神经网络加入非线性的输入。代码 3-5 中的输入信号只有3 个\\n信 号 x0,x1,x2 ， 我 们 可 以利用 这 3 个 信 号得到 带 有非 线性特征的输入：\\nx0,x1,x2,x1×x1,x1×x2,x2×x2，其中 x1×x1,x1×x2,x2×x2 为非线性特征。引入非线性输入\\n的线性神经网络如图3.9 所示。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 86, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 87\\n图3.9 引入非线性输入的线性神经网络\\n线性神经网络引入非线性特征解决异或问题的代码如代码 3-6 所示。\\n代码3-6：线性神经网络引入非线性特征解决异或问题\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# 输入数据\\n# 原来X的3 个特征分别为：x0,x1,x2\\n# X = np.array([[1,0,0],\\n# [1,0,1],\\n# [1,1,0],\\n# [1,1,1]])\\n# 给网络输入非线性特征\\n# 现在X的6 个特征分别为：x0,x1,x2,x1×x1,x1×x2,x2×x2\\nX = np.array([[1,0,0,0,0,0],\\n[1,0,1,0,0,1],\\n[1,1,0,1,0,0],\\n[1,1,1,1,1,1]])\\n# 标签，分别对应4 种异或情况的结果\\nT = np.array([[-1],\\n[1],\\n[1],\\n[-1]])\\n# 权值初始化，6 行1 列\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 87, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 88\\n# np.random.random可以生成0-1 的随机数\\nW = np.random.random([6,1])\\n# 学习率设置\\nlr = 0.1\\n# 神经网络输出\\nY = 0\\n# 更新一次权值\\ndef train():\\n# 使用全局变量W\\nglobal W\\n# 计算网络预测值\\nY = np.dot(X,W)\\n# 计算权值的改变\\ndelta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n# 更新权值\\nW = W + delta_W\\n# 训练1000 次\\nfor i in range(1000):\\n#更新一次权值\\ntrain()\\n# 计算模型预测结果并打印\\nY = np.dot(X,W)\\nprint(Y)\\n#————————以下为画图部分————————#\\n# 正样本\\nx1 = [0,1]\\ny1 = [1,0]\\n# 负样本\\nx2 = [0,1]\\ny2 = [0,1]\\n# 神经网络信号的总合为：w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2\\n# 当w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2=0时为分类边界线\\n# 其中x0 为1，我们可以把x1，x2 分别看成是平面坐标系中的x和y\\n# 可以得到：w0 + w1x + w2y + w3xx + w4xy + w5yy = 0\\n# 通分可得：w5y² + (w2+w4x)y + w0 + w1x + w3x² = 0\\n# 其中 a = w5, b = w2+w4x, c = w0 + w1x + w3x²\\n# 根据一元二次方程的求根公式：ay²+by+c=0，y=[-b±(b^2-4ac)^(1/2)]/2a\\ndef calculate(x,root):\\n# 定义参数\\na = W[5]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 88, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 89\\nb = W[2] + x * W[4]\\nc = W[0] + x * W[1] + x * x * W[3]\\n# 有两个根\\nif root == 1:\\nreturn (- b + np.sqrt(b * b - 4 * a * c)) / (2 * a)\\nif root == 2:\\nreturn (- b - np.sqrt(b * b - 4 * a * c)) / (2 * a)\\n# 从-1 到2 之间均匀生成100 个点\\nxdata = np.linspace(-1,2,100)\\n# 使用第一个求根公式计算出来的结果画出第一条红线\\nplt.plot(xdata,calculate(xdata,1),'r')\\n# 使用第二个求根公式计算出来的结果画出第二条红线\\nplt.plot(xdata,calculate(xdata,2),'r')\\n# 蓝色点表示正样本\\nplt.plot(x1,y1,'bo')\\n# 黄色点表示负样本\\nplt.plot(x2,y2,'yo')\\n# 绘图\\nplt.show()\\n运行结果如下：\\n[[-0.98650596]\\n[ 0.990989 ]\\n[ 0.990989 ]\\n[-0.99302749]]\\n从输出的预测值我们可以看出，预测值与真实标签的数值是非常接近的，几乎相等，说\\n明预测值很符合我们想要的结果。而从输出图片中也能观察到两条曲线的内部是负样本所属\\n的类别，两条曲线的外部是正样本所属的类别。这两条曲线很好地把两个类别区分开了。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 89, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 90\\n线性神经网络可以通过引入非线性的输入特征来解决非线性问题，但这并不是一种非常好\\n的解决方案。\\n下一章节我们将介绍一种新的神经网络，BP神经网络。通过学习 BP神经网络我们可以获\\n得更好的解决问题的思路。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 90, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 91\\n第 4 章-BP 神经网络\\n这一章节可能是本书在数学上最难的一章，详细介绍了 BP 算法的具体推导流程。BP 算\\n法是神经网络深度学习中最重要的算法之一，了解BP 算法可以让我们更理解神经网络深度学\\n习模型优化训练的本质，属于内功修行的基础内容。\\n不过作为初学者我们也要学会量力而行，BP 算法的推导对于初学者来说我觉得可以作为\\n选学的知识，也就是可学可不学。如果大家数学基础比较好的话，可以好好看一下本章的推导\\n过程，为后面的学习打好基础。如果数学基础没这么好也没关系，关于BP 算法的推导可以先\\n跳过，我们大概知道它是神经网络深度学习的核心优化算法即可，并不会影响到我们对后面知\\n识的学习，也不会影响到我们写程序做应用。我们在学习的过程中如果遇到困难，不要被它卡\\n住，可以先暂时放一放，等自身积累足够多之后再回过头来看之前遇到的问题，或许就可以迎\\n刃而解了。\\n4.1 BP 神经网络介绍及发展背景\\nBP(back propagation)神经网络是1986 年由Rumelhart和McClelland为首的科学家\\n提出的概念，他们在《Parallel Distributed Processing》[1]一书中对BP神经网络进行了详细\\n的分析。BP 神经网络是一种按照误差逆向传播算法训练的多层前馈神经网络，它是 20 世纪\\n末期神经网络算法的核心，也是如今深度学习算法的基础。\\n感知器对人工神经网络的发展发挥了极大的作用，但是它的结构只有输入层和输出层，不\\n能解决非线性问题的求解。Minsky 和 Papert 在颇具影响力的《Perceptron》一书中指出，\\n简单的感知器只能求解线性问题，能够求解非线性问题的网络应该具有隐藏层，但是对隐藏层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 91, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 92\\n神经元的学习规则还没有合理的理论依据。从前面介绍的感知器学习规则来看，其权值的调整\\n取决于期望输出与实际输出之差：\\n∆𝑤 = 𝜂(𝑡 − 𝑦)𝑥 (4.1)\\n( (\\n但是对于各个隐藏层的节点来说，不存在已知的期望输出，因而该学习规则不能用于隐藏\\n层的权值调整。\\nBP 算法的基本思想是，学习过程由信号的正向传播和误差的反向传播两个过程组成。\\n正向传播时，把样本的特征从输入层进行输入，信号经过各个隐藏层逐层处理后，最后从\\n输出层传出。对于网络的实际输出与期望输出之间的误差，把误差信号从最后一层逐层反传，\\n从而获得各个层的误差学习信号，再根据误差学习信号来修正各个层神经元的权值。\\n这种信号正向传播与误差反向传播，然后各个层调整权值的过程是周而复始地进行的。权\\n值不断调整的过程，也就是网络学习训练的过程。进行此过程直到网络输出误差减小到预先设\\n置的阈值以下，或者是超过预先设置的最大训练次数。\\n4.2 代价函数\\n代价函数也称为损失函数，英文称为 loss function或cost function，有些地方我们会看\\n到使用loss表示代价函数的值，有些地方我们会看到用 cost 表示代价函数的值。为了统一规\\n范，本书中我们统一使用代价函数这个名字，英文使用 loss。\\n代价函数并没有准确的定义，一般我们可以理解为是一个人为定义的函数，我们可以利用\\n这个函数来优化模型的参数。最简单常见的一个代价函数是 均方差（Mean-Square Error,\\nMSE）代价函数，也称为二次代价函数：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 92, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 93\\nP\\n1 1\\n𝐸 = (𝑇 − 𝑌)# = ?(𝑡 − 𝑦 )# (4.2)\\n( (\\n2𝑁 2𝑁\\n(A\"\\n矩阵可以用大写字母来表示，这里的 T 表示真实标签，Y 表示网络输出，i 表示第 i 个数\\n据。N表示训练样本的个数(注意这里的N 是一个大于0 的整数，不是矩阵)\\nT-Y可以到每个训练样本与真实标签的误差。误差的值有正有负，我们可以求平方，把所\\n有的误差值都变成正的，然后除以 2N。这里 2 没有特别的含义，主要是我们对均方差代价函\\n数求导的时候，公式中的 2 次方的 2 可以跟分母中的 2 约掉，使得公式推导看起来更加整齐\\n简洁。除以N表示求每个样本误差平均的平均值。\\n公式可以用矩阵形式来表达，也可以拆分为用Σ来累加各个训练样本的真实标签与网络输\\n出的误差的平方。\\n4.3 梯度下降法\\n4.3.1 梯度下降法（Gradient Descent）介绍\\n在求解机器学习算法的模型参数时，梯度下降法是最常用的方法之一。在学习梯度下降法\\n之前我们先来了解一下 导数（Derivative）、偏导数（Partial Derivative）、方向导数\\n（Directional Derivative）和梯度(Gradient)的概念。\\n导数 —— 导数的概念就如图4.1 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 93, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 94\\n图4.1 导数\\n导数的定义如下：\\nΔ𝑦 𝑓(𝑥 + Δ𝑥) − 𝑓(𝑥 )\\n𝑓R(𝑥 ) = lim = lim < < (4.3)\\n<\\nUV→<Δ𝑥 UV→< Δ𝑥\\n𝑓R(𝑥 )表示函数f在x0 处的导数\\n<\\n𝛥𝑥表示x的变化量\\n𝛥𝑦: 𝑓(𝑥 +𝛥𝑥)−𝑓(𝑥 )表示函数的增量\\n< <\\n𝑙𝑖𝑚表示𝛥𝑥趋近于0\\n^V→<\\ndx表示x的变化量𝛥𝑥趋近于0\\ndy 表示𝑓R(𝑥 )𝑑𝑥\\n<\\n总的来说𝑓R(𝑥 )反映的是函数𝑦 = 𝑓(𝑥)在x轴上某一点处沿x轴正方向的变化率/变化趋\\n<\\n势。也就是在x轴上的某一点，如果𝑓′(𝑥)＞0，说明𝑓(𝑥)的函数值在x点沿x轴正方向是趋\\n向于增加的；如果𝑓′(𝑥) < 0，说明𝑓(𝑥)的函数值在x点沿x轴正方向是趋向于减小的。\\n偏导数 —— 偏导数的定义如下：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 94, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 95\\n𝜕 Δ𝑦\\n𝑓(𝑥 ,𝑥 ,…,𝑥 ) = lim\\n< \" @\\n𝜕𝑥 UV→<Δ𝑥\\n(\\n𝑓(𝑥 ,…,𝑥 + Δ𝑥,…,𝑥 ) − 𝑓(𝑥 ,…,𝑥 ,…,𝑥 )\\n< ( @ < ( @\\n= lim (4.4)\\nUV→< Δ𝑥\\n可以看到，导数与偏导数本质是一致的，都是当自变量的变化量趋近于0 时，函数值的\\n变化量与自变量变化量比值的极限。直观地说，偏导数也就是函数在某一点上沿坐标轴正方\\n向的的变化率。\\n区别在于：\\n导数，指的是一元函数中，函数𝑦 = 𝑓(𝑥)在某一点处沿x轴正方向的变化率；\\n偏导数，指的是多元函数中，函数𝑦 = 𝑓(𝑥 ,𝑥 ,…,𝑥 )在某一点处沿某一坐标轴\\n< \" @\\n(𝑥 ,𝑥 ,…,𝑥 )正方向的变化率。\\n< \" @\\n方向导数 —— 方向导数的定义如下：\\n𝜕 Δ𝑦\\n𝑓(𝑥 ,𝑥 ,…,𝑥 ) = lim\\n< \" @\\n𝜕𝑙 Ue→<Δ𝑥\\n𝑓(𝑥 + Δ𝑥 ,…,𝑥 + Δ𝑥 ,…,𝑥 + Δ𝑥 ) − 𝑓(𝑥 ,…,𝑥 ,…,𝑥 )\\n< < ( ( @ @ < ( @\\n= lim (4.5)\\nUe→< 𝜌\\n其中𝜌 = g(Δ𝑥 )# + ⋯+ (Δ𝑥 )# + ⋯+ (Δ𝑥 )#\\n< ( @\\n𝑙表示某个方向\\n在前面导数和偏导数的定义中，均是沿坐标轴正方向讨论函数的变化率。那么当我们讨\\n论函数沿任意方向的变化率时，也就引出了方向导数的定义，即：某一点在某一趋近方向上\\n的导数值。\\n通俗的解释是：\\n我们不仅要知道函数在坐标轴正方向上的变化率（即偏导数），而且还要设法求得函数在\\n其他特定方向上的变化率。而方向导数就是函数在其他特定方向上的变化率。\\n梯度 —— 梯度的定义如下：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 95, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 96\\n𝜕𝑓 𝜕𝑓 𝜕𝑓\\n𝑔𝑟𝑎𝑑𝑓(𝑥 ,𝑥 ,…,𝑥 ) = l ,…, ,…, m (4.6)\\n< \" @\\n𝜕𝑥 𝜕𝑥 𝜕𝑥\\n< ( @\\n对于𝑓(𝑥 ,…,𝑥 ,…,𝑥 )上的某一点来说存在很多个方向导数，梯度的方向是函数\\n< ( @\\n𝑓(𝑥 ,…,𝑥 ,…,𝑥 )在某一点增长最快的方向，梯度的模则是该点上方向导数的最大值，梯度的\\n< ( @\\n模等于：\\n#\\n𝜕𝑓 𝜕𝑓 𝜕𝑓\\n|𝑔𝑟𝑎𝑑𝑓(𝑥 ,𝑥 ,…,𝑥 )| = o( )# + ⋯+ l m + ⋯+ ( )# (4.7)\\n< \" @\\n𝜕𝑥 𝜕𝑥 𝜕𝑥\\n< ( @\\n这里注意三点：\\n1. 梯度是一个向量，即有方向有大小\\n2. 梯度的方向是最大方向导数的方向\\n3. 梯度的值是最大方向导数的值\\n梯度下降法 —— 既然在变量空间的某一点处，函数沿梯度方向具有最大的变化率，那么\\n在优化代价函数的时候，就可以沿着负梯度方向去减小代价函数的值。计算过程可以描述如下：\\n𝑅𝑒𝑝𝑒𝑎𝑡{\\n𝜕𝑓\\n𝑥 = 𝑥 − 𝜂\\n< <\\n𝜕𝑥\\n<\\n………\\n𝜕𝑓\\n𝑥 = 𝑥 − 𝜂\\n( (\\n𝜕𝑥\\n(\\n………\\n𝜕𝑓\\n𝑥 = 𝑥 − 𝜂\\n@ @\\n𝜕𝑥\\n@\\n}\\n𝑅𝑒𝑝𝑒𝑎𝑡表示不断重复\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 96, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 97\\nuv\\n𝑥 = 𝑥 − 𝜂 表示参数调整，𝜂表示学习率\\nuV\\n4.3.2 梯度下降法（Gradient Descent）二维例子\\n4.2 中我们已经知道了代价函数的定义，代价函数的值越小，说明模型的预测值越接近真\\n实标签的值。代价函数中的预测值 y 是跟神经网络中的参数 w 和 b 相关的。我们可以先考虑\\n一个简单的情况，假如神经网络只有一个参数 w，参数 w 与代价函数 loss 的关系如图 4.2 所\\n示。\\n图4.2 参数w与代价函数loss的关系图\\n假设w的初始值是-3，我们需要使用梯度下降法来不断优化w的取值，使得loss值不\\n断减少，首先我们应该先计算w=-3 时的梯度，如图4.3 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 97, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 98\\n图 4.3 w为-3 时的梯度\\n从图 4.3 中我们可以看出，当 w 为-3 时，w 所处位置的梯度应该是一个负数，梯度下降\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个正数，\\nw的值应该变大。根据梯度下降法的优化公式：\\n𝜕𝑓\\n𝑤 = 𝑤 − 𝜂 (4.8)\\n𝜕𝑤\\n学习率𝜂一般是一个大于0 的数，uv 为负数，我们可以判断出 w的值会变大。变大的数值\\nux\\n跟学习率大小𝜂有关，也跟函数f在w处的梯度大小有关。\\n假设w变大移动到了w=2 的位置，我们需要再次计算 w=2 时的梯度，如图4.4 所示。\\n图 4.4 w为2 时的梯度\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 98, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 99\\n从图 4.4 中我们可以看出，当 w 为 2 时，w 所处位置的梯度应该是一个正数，梯度下降\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个负数，\\nw的值应该变小。\\nuv\\n学习率𝜂一般是一个大于0 的数， 为正数，我们可以判断出w的值会变小。变小的数值\\nux\\n跟学习率大小𝜂有关，也跟函数f在w处的梯度大小有关。\\n我们可以发现不管 w 处于那一个位置，当 w 向着负梯度的方向进行移动时，实际上就是\\n向着可以使 loss 值减小的方向进行移动。这就有点类似一个小球在山坡上面，它总是往坡底\\n的方向进行移动，只不过它每一次是移动一步，这个步子的大小会受到学习率和所处位置梯度\\n的大小所影响。\\n4.3.3 梯度下降法（Gradient Descent）三维例子\\n我们可以再考虑一个稍微复杂一点点的情况，假如神经网络有两个参数 w1 和 w2，参数\\nw1 和w2 与代价函数 loss的关系如图4.5 所示。\\n图4.5 w1 和w2 与loss的关系图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 99, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 100\\n我们在图中随机选取两个w1 和w2 的初始值p1 和p2，然后从p1,p2 这两个初始位置\\n开始使用梯度下降法优化网络参数，得到如图 4.6 所示的结果。\\n图4.6 从p1,p2初始点开始优化网络\\n图4.6 中可以看到网络参数的优化过程其实就是p1,p2两个“小球“从初始点开始，每次\\n移动一步，不断向坡底进行移动。在这个过程中整个网络的 loss值是在不断变小的。\\n同时我们还可以观察到一个现象， p1“小球“最后走到了图中的 全局最小值（Global\\nMinimum），而p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我\\n们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果，有些时候我们可以\\n得到loss的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是 loss的局\\n部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存\\n在的一个缺点。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 100, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 101\\n不过大家不用太担心这个问题，一般实际模型训练的时候局部极小值的情况不常出现。如\\n果我们担心模型得到的结果是局部极小值的话可以让模型多训练几次，然后取最好的那一次结\\n果作为模型的最终结果就可以了。\\n4.4 Delta 学习规则\\n1986 年，认知心理学家 McClelland 和 Rumelhart 在神经网络训练中引入了𝛿（Delta）\\n规则，该规则也可以称为连续感知器学习规则。\\n𝛿（Delta）学习规则是一种利用梯度下降法的一般性的学习规则，其实就是利用梯度下降\\n法来最小化代价函数。比如代价函数为前面公式4.2 介绍的均方差代价函数，为了简单我们只\\n计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。一个样\\n本 的均方差公式定义 如下 ：\\n𝐸 = \" (𝑇 − 𝑌)# = \" (𝑡 − 𝑦)# = \" (𝑡 − 𝑓(𝑊𝑋))# (4.9)\\n# # #\\n误差 E 是 W 的函数，我们可以使用梯度下降法来最小化 E 的值，权值矩阵的变化∆W等\\n于负的学习率−𝜂乘以E对W进行求导：\\n∆𝑊 = −𝜂𝐸R = 𝜂𝑋~(𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑋~𝛿 (4.10)\\n注意这里的 X 和 W 都是矩阵，所以这里求导的时候是对矩阵 W 进行求导，矩阵求导的\\n方式跟单个元素求导的方式有一些不同。下面公式是单个 w元素的权值变化计算：\\n∆𝑤 = −𝜂𝐸R = 𝜂𝑥 (𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑥 𝛿 (4.11)\\n( ( (\\n这里的𝛿（Delta）符号没有什么特别的含义，就是用来替代(𝑡−𝑦)𝑓R(𝑊𝑋)。∆𝑤 表示第 i\\n(\\n个权值的变化。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 101, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 102\\n在上一章节中关于单层感知器的权值变化公式是如何得到的还没有解释，这里我们可以看\\n到当我们使用线性激活函数y=x时，激活函数的导数𝑓R(𝑊𝑋) = 1，所以：\\n∆𝑤 = −𝜂𝐸R = 𝜂𝑥 (𝑡 − 𝑦) (4.12)\\n( (\\n公式 4.12 跟感知器的学习规则公式 3.2 是一样的，所以使用 Delta 学习规则我们可以推\\n导出感知器的学习规则。\\n4.5 常用激活函数讲解\\n神经网络的激活函数其实有很多种，在前面的章节中我们介绍过两种激活函数，sign 函\\n数和purelin 函数。sign 函数也称为符号函数，因为sign(x)中x＞0，函数结果为1；sign(x)\\n中x＜0，函数结果为-1。purelin 函数也称为线性函数，表达式为 y=x。这两种激活函数在处\\n理复杂非线性问题的时候都不能得到很好的结果，线性函数的分类边界也是线性的，所以不能\\n区别非线性的复杂边界，比如一条直线不能区分异或问题的两个类别。下面我们介绍几个在 BP\\n神经网络中常用的非线性激活函数，sigmoid 函数，tanh 函数，softsign 函数和 ReLU 函\\n数，使用这些非线性激活函数可以帮助我们解决复杂的非线性问题。\\n4.5.1 sigmoid 函数\\nsigmoid函数 —— sigmoid函数也称为逻辑函数(logical function)，函数的公式为\\n1\\n𝑓(𝑥) = (4.13)\\n1 + 𝑒(cid:127)V\\n函数图像如图4.7 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 102, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 103\\n图4.7 sigmoid函数图像\\n图中我们可以看出函数的取值范围是 0-1 之间，当 x 趋向于-∞的时候函数值趋向于 0；\\n当x趋向于+∞的时候函数值趋向于 1。\\n4.5.2tanh 函数\\ntanh函数 —— tanh函数也称为双曲正切函数，函数的公式为\\n𝑒V − 𝑒(cid:127)V\\n𝑓(𝑥) = (4.14)\\n𝑒V + 𝑒(cid:127)V\\n函数图像如图4.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 103, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 104\\n图4.8 tanh函数图像\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n当x趋向于+∞的时候函数值趋向于 1。\\n4.5.3 softsign 函数\\nsoftsign函数 —— softsign 函数的公式为：\\n𝑥\\n𝑓(𝑥) = (4.15)\\n1 + |𝑥|\\n函数图像如图4.9 所示。\\n图 4.9 softsign 函数图像\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n当x趋向于+∞的时候函数值趋向于 1。\\n我们可以通过图4.10 对比一下这三种函数的区别。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 104, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 105\\n图 4.10 三种函数对比\\n它们这三个激活函数都是 S 形函数，形状相似，只不过 sigmoid 函数取值范围是 0-1 之\\n间，tanh 函数和 softsign 函数取值范围是-1-1 之间。我们还可以观察到 softsign 函数相对\\n于tanh函数而言过渡更加平滑，在x等于0 附近函数的数值改变更缓慢。\\n4.5.4 ReLU 函数\\n该函数最早源自2011 年的一篇论文《Deep Sparse Rectifier Neural Networks》[2]。\\n它是模拟生物神经元的激活函数设计出来的一个人工神经网络激活函数。图 4.11 为生物神经\\n元放电曲线图。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 105, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 106\\n图4.11 生物神经元放电曲线图[2]\\n图 4.11 中可以看到当输入电压不足时，生物神经元放电为 0，电压达到一定的阈值以后\\n生物神经元才会开始放电，并且放电速率跟输入电压成正相关关系。\\nReLU 函数 —— ReLU(The Rectified Linear Unit)函数的公式为\\n𝑓(𝑥) = max (0,𝑥) (4.16)\\n函数图像如图4.12 所示。\\n图4.12 ReLU函数图像\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 106, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 107\\n当x小于0 时，y 等于0。当x大于 0 时，y 等于x。ReLU的中文名称是校正线性单\\n元，虽然在x小于0 时函数是线性的，x大于0 时函数也是线性的，但是组合起来之后，函\\n数就具有了非线性的特征。这种非线性的特征是怎么体现的呢，我们可以观察下面的一系列\\n图片，首先看到图4.13。\\n图4.13 使用tanh作为激活函数的分类边界\\n图4.13 使用的是tanh作为激活函数训练出来的分类模型，其实使用 sigmoid或者\\nsoftsign 函数也可以得到类似结果。我使用了带有4 个隐藏层的神经网训练了出了这个模\\n型，图中有两个类别的数据，并且我们可以观察到一个类似椭圆形的分类边界把两个类别给\\n区分开了。我们再观察图4.14：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 107, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 108\\n图4.14 使用 ReLu 作为激活函数的分类边界\\n我使用带有4 个隐藏层的神经网络训练出了这个模型。我们发现使用 ReLU激活函数得\\n到的分类边界跟使用tanh激活函数得到分类边界是差不多的，并不能看出 ReLU函数的特\\n点。同样的一个学习任务和数据，我改变了神经网络的层数，只使用 2 个隐藏层，依然使用\\nReLU激活函数得到了图 4.15 所示的结果。\\n图4.15 使用 ReLU作为激活函数的分类边界\\n我们观察图4.15 可以得到一些结论：\\n（1）我们可以发现 ReLU激活函数所描绘出来的边界其实是一条一条的直线构成的，不\\n存在曲线。图4.14 中的边界看起来像一个椭圆，实际上它也是由一段一段很小的直线构成\\n的。\\n（2）神经网络的层数会影响模型的拟合效果，层数越多，模型就可以拟合出更复杂的分\\n类边界。\\n模型的拟合效果其实还跟其他一些因素相关，比如说每一层隐藏层的神经元越多，那么模\\n型的拟合能力也就越强。模型训练的周期越多，模型的拟合能力就越强。关于模型拟合强弱的\\n问题，再后面的章节中我们还会进一步讨论。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 108, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 109\\n另外我们再来看一下ReLU应用于回归预测时的特点，我看一下图4.16 和图4.17。\\n图4.16 使用tanh激活函数训练的回归模型\\n图4.17 使用 ReLU激活函数训练的回归模型\\n我们发现了跟分类中类似的情况，tanh激活函数得到的回归线是一条曲线，而ReLU激\\n活函数得到的是由一段一段直线构成的回归线。\\n大家可以思考一个问题，上面介绍的这几个激活函数，哪一个效果比较好，为什么？这\\n个问题在4.8 小节中我们再继续讨论。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 109, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 110\\n4.6 BP 网络模型和公式推导\\n这一小节我们将学习BP 算法的推导流程，如果觉得这个小节内容有一定难度可以直接跳\\n到下一小节进行学习。BP 算法其实是在Delta学习规则的基础上做了进一步的推广，Delta是\\n对单层感知器定义了计算流程和代价函数，然后用梯度下降法来最小化代价函数。BP 算法是\\n对多层神经网络定义了计算流程和代价函数，然后再使用梯度下降法来最小化代价函数。由于\\nBP 算法的广泛使用，所以一般的全连接多层神经网络我们也称为BP 神经网络。\\nBP 网络中不仅有输入层和输出层，在输入层和输出层中间还可以添加隐藏层。输入层的\\n神经元个数一般跟输入数据相关，输出层的神经元个数一般跟标签相关，而网络中间的隐藏层\\n的层数和隐藏层神经元的个数都是超参数。也就是说隐藏层的层数以及隐藏层每一层的神经元\\n个数我们都可以随意设置，主要靠经验和实验来决定。通常来说隐藏层的层数越多，隐藏层每\\n一层神经元个数越多，这个神经网络结构就越复杂，越能拟合复杂的函数曲线，处理复杂的分\\n类回归问题。反之，隐藏层层数越少，隐藏层每一层神经元个数越少，网络结构就越简单，它\\n所能够拟合的函数曲线就越简单，比较适合处理简单的分类回归问题。\\n网络的结构不是越复杂越好，也不是越简单越好。网络的结构复杂度需要跟我们要解决的\\n问题相关，如果问题越复杂，那么网络结构就要越复杂；如果问题简单，那么就要用结构简单\\n的网络来建模。如果网络结构的复杂度跟要解决的问题不匹配的话就会出现欠拟合（Under-\\nFitting）或者过拟合（Over-Fitting）。什么是欠拟合（Under-Fitting）和过拟合（Over-Fitting），\\n在后面的章节中再详细介绍。总之一个好的网络结构是需要很多的经验加大量的实验才能获得。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 110, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 111\\n4.6.1 BP 网络模型[3]\\n假设我们有一个 2 层（统计神经网络层数的时候一般输入层忽略不计）的神经网络如图\\n4.18所示。\\n图4.18 BP神经网络\\n该网络的输入向量为𝑋 = (𝑥 ,𝑥 ,…,𝑥 ,…,𝑥 )，图中𝑥 = 1表示输入层偏置值。隐藏层输\\n\" # ( @ <\\n出向量为𝑌\" = (𝑦\",𝑦\",…,𝑦\",…,𝑦\")，图中𝑦\" = 1表示隐藏层偏置值。输出层输出向量为𝑌# =\\n\" # (cid:129) (cid:130) <\\n(𝑦#,𝑦#,…,𝑦#,…,𝑦#)。期望输出𝑇 = (𝑡 ,𝑡 ,…,𝑡 ,…,𝑡 )。输入层到隐藏层之间的权值用矩阵\\n\" # (cid:131) (cid:132) \" # (cid:131) (cid:132)\\n𝑊\"表示，𝑤\"表示𝑊\"矩阵中第i 行第 j 列的权值。隐藏层到输出层之间的权值用矩阵𝑊#表\\n((cid:129)\\n示，𝑤#表示𝑊#矩阵中第j 行第k 列的权值。另外我们定义𝑛𝑒𝑡\"为隐藏层中权值𝑊\"乘以输入\\n(cid:129)(cid:131)\\n层信号𝑋的总和，𝑛𝑒𝑡\"表示隐藏层中第 j 个神经元得到的输入信号总和。𝑛𝑒𝑡#为输出层中权值\\n(cid:129)\\n𝑊#乘以隐藏层信号𝑌\"的总和，𝑛𝑒𝑡#表示输出层中第k 个神经元得到的输入信号总和。\\n(cid:131)\\n对于隐藏层有：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 111, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 112\\n@\\n𝑛𝑒𝑡\" = ?𝑤\"𝑥 𝑗 = 1,2,…,𝑚 (4.17)\\n(cid:129) ((cid:129) (\\n(A<\\n𝑦\" = 𝑓(𝑛𝑒𝑡\") 𝑗 = 1,2,…,𝑚 (4.18)\\n(cid:129) (cid:129)\\n对于输出层有：\\n(cid:130)\\n𝑛𝑒𝑡# = ?𝑤# 𝑦\" 𝑘 = 1,2,…,𝑙 (4.19)\\n(cid:131) (cid:129)(cid:131) (cid:129)\\n(cid:129)A<\\n𝑦# = 𝑓(𝑛𝑒𝑡#) 𝑘 = 1,2,…,𝑙 (4.20)\\n(cid:131) (cid:131)\\n公式 4.18 和 4.20 中的激活函数假设我们都使用 sigmoid 函数，sigmoid 函数的公式在\\n上文中的公式4.13。sigmoid函数具有连续、可导的特点，它的导数为：\\n𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)] (4.21)\\n4.6.2 BP 算法推导\\n根据上文中提到的代价函数，当网络输出与期望输出不同时，会存在输出误差 E，为了简\\n单我们只计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。\\n一个样本的均方差公式定义如下：\\n(cid:132)\\n1 1\\n𝐸 = (𝑇 − 𝑌#)# = ?(𝑡 − 𝑦#)# (4.22)\\n(cid:131) (cid:131)\\n2 2\\n(cid:131)A\"\\n将以上误差定义式展开至隐藏层：\\n(cid:132)\\n1\\n𝐸 = ?[𝑡 − 𝑓(𝑛𝑒𝑡#) ]#\\n(cid:131) (cid:131)\\n2\\n(cid:131)A\"\\n#\\n(cid:132) (cid:130)\\n1\\n= ?(cid:138)𝑡 − 𝑓(cid:139)?𝑤# 𝑦\"(cid:140) (cid:141) (4.23)\\n(cid:131) (cid:129)(cid:131) (cid:129)\\n2\\n(cid:131)A\" (cid:129)A<\\n再进一步展开至输入层：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 112, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 113\\n#\\n(cid:132) (cid:130)\\n1\\n𝐸 = ?(cid:138)𝑡 − 𝑓(cid:139)?𝑤# 𝑓(cid:142)𝑛𝑒𝑡\"(cid:143) (cid:140) (cid:141)\\n(cid:131) (cid:129)(cid:131) (cid:129)\\n2\\n(cid:131)A\" (cid:129)A<\\n#\\n(cid:132) (cid:130) @\\n1\\n= ?(cid:138)𝑡 − 𝑓(cid:139)?𝑤# 𝑓>?𝑤\"𝑥 B (cid:140) (cid:141) (4.24)\\n(cid:131) (cid:129)(cid:131) ((cid:129) (\\n2\\n(cid:131)A\" (cid:129)A< (A<\\n从公式 4.23 和 4.24 中可以看出，网络的误差 E 是跟神经网络各层权值𝑤\"和𝑤#相关的，\\n((cid:129) (cid:129)(cid:131)\\n因此调整各层的权值，就可以改变误差E的值。我们的目标就是要得到比较小的误差值，所以\\n我们可以采用梯度下降法来最小化误差 E的值。根据梯度下降法，我们可以得到：\\n𝜕𝐸\\n∆𝑤\" = −𝜂 𝑖 = 0,1,2,…,𝑛;𝑗 = 1,2,…,𝑚 (4.25)\\n((cid:129) 𝜕𝑤\"\\n((cid:129)\\n𝜕𝐸\\n∆𝑤# = −𝜂 𝑗 = 0,1,2,…,𝑚;𝑘 = 1,2,…,𝑙 (4.26)\\n(cid:129)(cid:131) 𝜕𝑤#\\n(cid:129)(cid:131)\\n在下面的推导过程中均默认对于隐藏层有：𝑖 = 0,1,2,…,𝑛;𝑗 = 1,2,…,𝑚；对于输出层有：\\n𝑗 = 0,1,2,…,𝑚;𝑘 = 1,2,…,𝑙。\\n根据微积分的链式法则可以得到，对于隐藏层有：\\n𝜕𝑛𝑒𝑡\"\\n𝜕𝐸 𝜕𝐸\\n∆𝑤\" = −𝜂 = −𝜂 (cid:129) (4.27)\\n((cid:129) 𝜕𝑤\" 𝜕𝑛𝑒𝑡\" 𝜕𝑤\"\\n((cid:129) (cid:129) ((cid:129)\\n根据微积分的链式法则可以得到，对于输出层有：\\n𝜕𝐸 𝜕𝐸 𝜕𝑛𝑒𝑡#\\n∆𝑤# = −𝜂 = −𝜂 (cid:131) (4.28)\\n(cid:129)(cid:131) 𝜕𝑤# 𝜕𝑛𝑒𝑡# 𝜕𝑤#\\n(cid:129)(cid:131) (cid:131) (cid:129)(cid:131)\\n我们可以定义一个误差信号，命名为𝛿（Delta），令：\\n𝜕𝐸\\nδ\" = − (4.29)\\n(cid:129) 𝜕𝑛𝑒𝑡\"\\n(cid:129)\\n𝜕𝐸\\nδ# = − (4.30)\\n(cid:131) 𝜕𝑛𝑒𝑡#\\n(cid:131)\\n综合公式4.17,4.27,4.29，可以得到输入层到隐藏层的权值调整公式为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 113, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 114\\n∆𝑤\" = 𝜂δ\"𝑥 (4.31)\\n((cid:129) (cid:129) (\\n综合公式4.19,4.28,4.30，可以得到隐藏层到输出层的权值调整公式为：\\n∆𝑤# = 𝜂δ#𝑦\" (4.32)\\n(cid:129)(cid:131) (cid:131) (cid:129)\\n中，只要求出δ\" 和δ# 的值，就可以计算出∆𝑤\" 和∆𝑤#\\n可以看出在公式4.31 和4.32 的值\\n(cid:129) (cid:131) ((cid:129) (cid:129)(cid:131)\\n了。\\n\"\\n对于隐藏层，δ 可以展开为：\\n(cid:129)\\n𝜕𝑦\"\\n𝜕𝐸 𝜕𝐸 𝜕𝐸\\nδ\" = − = − (cid:129) = − 𝑓R(cid:142)𝑛𝑒𝑡\"(cid:143) (4.33)\\n(cid:129) 𝜕𝑛𝑒𝑡\" 𝜕𝑦\"𝜕𝑛𝑒𝑡\" 𝜕𝑦\" (cid:129)\\n(cid:129) (cid:129) (cid:129) (cid:129)\\n#\\n对于输出层，δ 可以展开为：\\n(cid:131)\\n𝜕𝐸 𝜕𝐸 𝜕𝑦# 𝜕𝐸\\nδ# = − = − (cid:131) = − 𝑓R(𝑛𝑒𝑡#) (4.34)\\n(cid:131) 𝜕𝑛𝑒𝑡# 𝜕𝑦#𝜕𝑛𝑒𝑡# 𝜕𝑦# (cid:131)\\n(cid:131) (cid:131) (cid:131) (cid:131)\\n在公式4.33 和4.34中，求网络误差对各层输出的偏导，对于输出层：\\n𝜕𝐸\\n= −(𝑡 − 𝑦#) (4.35)\\n𝜕𝑦# (cid:131) (cid:131)\\n(cid:131)\\n对于隐藏层：\\n1 #\\n𝜕𝐸 𝜕 2∑(cid:132) (cid:131)A\"(cid:146)𝑡 (cid:131) − 𝑓(cid:142)∑(cid:130) (cid:129)A<𝑤 (cid:129)# (cid:131)𝑦 (cid:129)\"(cid:143) (cid:147)\\n=\\n𝜕𝑦\" 𝜕𝑦\"\\n(cid:129) (cid:129)\\n(cid:132) (cid:130) (cid:130)\\n= −?(cid:148)𝑡 − 𝑓(cid:139)?𝑤# 𝑦\"(cid:140)(cid:149)𝑓R (cid:139)?𝑤# 𝑦\"(cid:140)𝑤#\\n(cid:131) (cid:129)(cid:131) (cid:129) (cid:129)(cid:131) (cid:129) (cid:129)(cid:131)\\n(cid:131)A\" (cid:129)A< (cid:129)A<\\n(cid:132)\\n= −?(𝑡 − 𝑦#)𝑓R(𝑛𝑒𝑡#)𝑤# (4.36)\\n(cid:131) (cid:131) (cid:131) (cid:129)(cid:131)\\n(cid:131)A\"\\n将式（4.35）带入式（4.34），再根据 sigmoid函数的求导式（4.21），可以得到：\\n𝜕𝐸\\nδ# = − 𝑓R(𝑛𝑒𝑡#) = (𝑡 − 𝑦#)𝑦#(1 − 𝑦#) (4.37)\\n(cid:131) 𝜕𝑦# (cid:131) (cid:131) (cid:131) (cid:131) (cid:131)\\n(cid:131)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 114, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 115\\n(cid:132)\\n𝜕𝐸\\nδ\" = − 𝑓R(cid:142)𝑛𝑒𝑡\"(cid:143) = >?(𝑡 − 𝑦#)𝑓R(𝑛𝑒𝑡#)𝑤# B𝑓R(cid:142)𝑛𝑒𝑡\"(cid:143)\\n(cid:129) 𝜕𝑦\" (cid:129) (cid:131) (cid:131) (cid:131) (cid:129)(cid:131) (cid:129)\\n(cid:129)\\n(cid:131)A\"\\n(cid:132)\\n= >?(𝑡 − 𝑦#)𝑦#(1 − 𝑦#)𝑤# B𝑓R(cid:142)𝑛𝑒𝑡\"(cid:143)\\n(cid:131) (cid:131) (cid:131) (cid:131) (cid:129)(cid:131) (cid:129)\\n(cid:131)A\"\\n(cid:132)\\n= >?δ# 𝑤# B𝑦\"(cid:142)1 − 𝑦\"(cid:143) (4.38)\\n(cid:131) (cid:129)(cid:131) (cid:129) (cid:129)\\n(cid:131)A\"\\n将公式4.37 带入4.32 中，得到隐藏层到输出层权值调整：\\n∆𝑤# = 𝜂δ#𝑦\" = 𝜂(𝑡 − 𝑦#)𝑦#(1 − 𝑦#)𝑦\" (4.39)\\n(cid:129)(cid:131) (cid:131) (cid:129) (cid:131) (cid:131) (cid:131) (cid:131) (cid:129)\\n将公式4.38带入4.31 中，得到输入层到隐藏层权值调整：\\n(cid:132)\\n∆𝑤\" = 𝜂δ\"𝑥 = 𝜂>?δ# 𝑤# B𝑦\"(cid:142)1 − 𝑦\"(cid:143)𝑥 (4.40)\\n((cid:129) (cid:129) ( (cid:131) (cid:129)(cid:131) (cid:129) (cid:129) (\\n(cid:131)A\"\\n对于一个多层的神经网络，假设一共有 h个隐藏层，按顺序将各隐藏层节点数分别记\\n为：𝑚 ,𝑚 ,…,𝑚 ，输入神经元个数为n，输出神经元个数为𝑙；各隐藏层输出分别记为：\\n\" # (cid:150)\\n𝑌\",𝑌#,…,𝑌(cid:150)，输入层的输入记为：𝑋，输出层的输出记为：𝑌(cid:150)(cid:151)\"；各层权值矩阵分别记为：\\n𝑊\",𝑊#,…,𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输\\n出层的权值矩阵；各层学习信号分别记为：𝜹\",𝜹#,…,𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信\\n号；则各层权值调整计算公式为：\\n对于输出层：\\n∆𝑤(cid:153)(cid:151)\" = 𝜂δ(cid:150)(cid:151)\"𝑦(cid:150) = 𝜂(cid:142)𝑡 − 𝑦(cid:150)(cid:151)\"(cid:143)𝑦(cid:150)(cid:151)\"(cid:142)1 − 𝑦(cid:150)(cid:151)\"(cid:143)𝑦(cid:150) (4.41)\\n(cid:129)(cid:131) (cid:131) (cid:129) (cid:131) (cid:131) (cid:131) (cid:131) (cid:129)\\n𝑗 = 0,1,2,…,𝑚 ;𝑘 = 1,2,…,𝑙\\n(cid:150)\\n对于第h隐藏层：\\n(cid:132)\\n∆𝑤(cid:153) = 𝜂δ(cid:150)𝑦(cid:150)(cid:127)\" = 𝜂>?δ(cid:150)(cid:151)\"𝑤(cid:150)(cid:151)\"B𝑦(cid:150)(cid:142)1 − 𝑦(cid:150)(cid:143)𝑦(cid:150)(cid:127)\" (4.42)\\n((cid:129) (cid:129) ( (cid:131) (cid:129)(cid:131) (cid:129) (cid:129) (\\n(cid:131)A\"\\n𝑖 = 0,1,2,…,𝑚 ;𝑗 = 1,2,…,𝑚\\n(cid:150)(cid:127)\" (cid:150)\\n按照以上规律逐层类推，则第一个隐藏层的权值调整公式为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 115, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 116\\n(cid:130)\\n(cid:157)\\n∆𝑤\" = 𝜂δ\"𝑥 = 𝜂(cid:139)?δ#𝑤# (cid:140)𝑦\"(cid:142)1 − 𝑦\"(cid:143)𝑥 (4.43)\\n(cid:154)(cid:155) (cid:155) (cid:154) (cid:156) (cid:155)(cid:156) (cid:155) (cid:155) (cid:154)\\n(cid:156)A\"\\n𝑝 = 0,1,2,…,n;𝑞 = 1,2,…,𝑚\\n\"\\n4.6.3 BP 算法推导的补充说明\\n我们已经从头到尾详细推导了一遍 BP 算法的整个流程，在这一小节中对 BP 算法再做两\\n点补充说明。\\n1.网络的偏置值\\n在上文中我们的推导过程一直是使用权值w来进行计算的，如果我们把偏置值独立出来，\\n那么偏置值的参数应该怎么调整呢？\\n我们可以看到公式4.31 以及4.32，在公式 4.31 中，把 i 的取值设置为0，并且我们知道\\n𝑥 = 1，所以我们可以得到：\\n<\\n∆𝑏\" = 𝜂δ\" (4.44)\\n(cid:129) (cid:129)\\n在公式4.31 中，把j 的取值设置为0，并且我们知道𝑦 = 1，所以我们可以得到：\\n<\\n∆𝑏# = 𝜂δ# (4.45)\\n(cid:131) (cid:131)\\n如果是把偏置值单独拿出来计算的话就是公式 4.44和4.45的表达式。\\n2.用矩阵形式来表达BP 学习算法\\n下面我们直接给出BP学习算法矩阵表达形式的结果，具体推导过程跟上文中的推导过程\\n类似，不过会涉及到矩阵求导的相关知识，大家有兴趣的话可以自己推导一下。如果是把 BP\\n学习算法写成矩阵的形式来表达，假设一共有 h个隐藏层。输入数据的矩阵为𝑋，𝑋中的每一\\n行表示一个数据，列表示数据的特征。比如我们一次性输入 3 个数据，每个数据有4 个特\\n征，那么𝑋就是一个3 行4 列的矩阵。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 116, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 117\\n各隐藏层输出分别记为：𝑌\",𝑌#,…,𝑌(cid:150)，输出层的输出记为：𝑌(cid:150)(cid:151)\"。𝑌中的每一个行表示\\n一个数据的标签。比如我们有3 个数据，每个数据有 1 个标签，那么𝑌就是一个3 行1 列的\\n矩阵。\\n各层权值矩阵分别记为：𝑊\",𝑊#,…,𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，\\n𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输出层的权值矩阵。权值矩阵的行等于前一层的神经元个数，权\\n值矩阵的列对应于后一层的神经元个数。比如在输入层和第一个隐藏层之间的权值矩阵是\\n𝑊\"，输入层有 3 个神经元，第一个隐藏层有10 个神经元，那么𝑊\"就是一个3 行10 列的矩\\n阵。\\n各层学习信号分别记为：𝜹\",𝜹#,…,𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信号。\\n对于输出层的学习信号𝜹(cid:150)(cid:151)\"：\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1)\\n= (𝑇 − 𝑌ℎ+1) ∘ 𝑌ℎ+1 ∘ (1 − 𝑌ℎ+1) (4.46)\\n公式4.46中的\"∘\"符号是element-wise multiplication，意思是矩阵中的元素对应相\\n乘。例如下面的例子：\\n𝑎 𝑎 𝑎 𝑏 𝑏 𝑏 𝑎 𝑏 𝑎 𝑏 𝑎 𝑏\\n\"\" \"# \"$ \"\" \"# \"$ \"\" \"\" \"# \"# \"$ \"$\\n>𝑎 𝑎 𝑎 B∘>𝑏 𝑏 𝑏 B = >𝑎 𝑏 𝑎 𝑏 𝑎 𝑏 B\\n#\" ## #$ #\" ## #$ #\" #\" ## ## #$ #$\\n𝑎 𝑎 𝑎 𝑏 𝑏 𝑏 𝑎 𝑏 𝑎 𝑏 𝑎 𝑏\\n$\" $# $$ $\" $# $$ $\" $\" $# $# $$ $$\\n对于第h隐藏层的学习信号𝜹(cid:150)：\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ)\\n= 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑌ℎ ∘ (1 − 𝑌ℎ) (4.47)\\n对于第1 隐藏层的学习信号𝜹\"：\\n𝛅\" = 𝛅#(𝑊#)~ ∘ 𝑓R(𝑋𝑊1)\\n= 𝛅#(𝑊#)~ ∘ 𝑌1 ∘ (1 − 𝑌1) (4.48)\\n对于输出层的权值矩阵𝑊(cid:150)(cid:151)\"：\\n∆𝑊ℎ+1 = 𝜂(𝑌ℎ)~ 𝛅(cid:150)(cid:151)\" (4.49)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 117, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 118\\n对于第h隐藏层权值矩阵𝑊(cid:150)：\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~ 𝛅(cid:150) (4.50)\\n对于第1 隐藏层权值矩阵𝑊\"：\\n∆𝑊1 = 𝜂(𝑋)~ 𝛅\" (4.51)\\n4.7 BP 算法推导结论总结\\n上一小节我们推导了BP 算法的公式，可能部分同学暂时先跳过了详细推导的部分。如果\\n推导过程看起来有点复杂，我们只看最后推导得到的结论即可。最后推导的结论也就是权值调\\n整的公式为：\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~ 𝛅(cid:150) (4.52)\\n这里的∆𝑊(cid:150)表示第 h 层权值矩阵 W 的变化，𝜂表示学习率，𝑌(cid:150)(cid:127)\"表示网络第 h-1 层的输\\n出，𝜹(cid:150)表示第h层的学习信号。\\n𝜂学习率是为人设置的超参数，𝑌(cid:150)(cid:127)\"网络第h-1 层的输出只要把数据传入网络中就可以计\\n算出来，所以这里要重点关注的是第h层的学习信号𝜹(cid:150)。学习信号有两个不同的公式，输出层\\n的学习信号公式为：\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1) (4.53)\\n这里的𝜹(cid:150)(cid:151)\"表示输出层的学习信号，T 表示数据的标签值，𝑌(cid:150)(cid:151)\"表示模型的预测值，𝑓R表\\n示激活函数的导数，𝑌(cid:150)𝑊(cid:150)(cid:151)\"表示输出层信号的汇总。\\nT 是已知的数据标签，Y(cid:153)(cid:151)\"可以传入数据计算得到，激活函数确定以后𝑓R也是已知的，𝑌(cid:150)\\n传入数据可以计算得到，𝑊(cid:150)(cid:151)\"在网络进行随机初始化以后也确定下来了。所以这个公式里面\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 118, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 119\\n的所有值都是已知的，或者可以计算得到，把𝜹(cid:150)(cid:151)\"计算出来以后再带入到 4.52 的公式中就可\\n以计算出输出层的权值矩阵要怎么要调整了。\\n除了输出层以外，剩下的网络层的学习信号的公式都是：\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ) (4.54)\\n从这个公式我们可以看到，第 h 层的学习信号𝜹(cid:150)，跟它的下一层 h+1 层的学习信号𝜹(cid:150)(cid:151)\"\\n有关系，还跟它的下一层h+1 层的权值矩阵的转置(𝑊(cid:150)(cid:151)\")~有关系，以及跟𝑓R(𝑌(cid:150)(cid:127)\"𝑊(cid:150))相关。\\n所以我们在使用 BP 算法的时候需要先根据网络预测的误差计算最后一层的学习信号，然\\n后再计算倒数第二层的学习信号，然后再计算倒数第三层的学习信号以此类推，从后向前计算，\\n因此 BP 算法叫做误差反向传播算法。计算得到每一层的学习信号以后再根据公式 4.52 来计\\n算每一层的权值矩阵如何调整，最后对所有层的权值矩阵进行更新。\\n4.8 梯度消失与梯度爆炸\\n前面给大家留了一个思考题，在我们介绍的几种激活函数中，哪种激活函数的效果是最好\\n的。其实这个问题的答案很简单，在介绍它们的时候，一般排在越后面的说明效果就越好，所\\n以ReLU是最好的。开个玩笑，下面我们来具体分析一下这几个激活函数的不同效果。\\n4.8.1 梯度消失\\n根据上文BP算法中的推导，我们从公式4.49,,4.50,4.51中可以知道，权值的调整∆𝑊是\\n跟学习信号𝛿相关的。同时我们从4.46,4.47,4.48中可以知道在学习信号𝛿表达式中存在\\n𝑓R(𝑥)。也就是说激活函数的导数会影响学习信号𝛿的值，而学习信号𝛿的值会影响权值调整\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 119, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 120\\n∆𝑊的值。那么激活函数的值越大，∆𝑊的值就越大；激活函数的值越小，∆𝑊的值也就越\\n小。\\n假设激活函数为sigmoid函数，前文中我们已经知道了sigmoid函数的表达式为：𝑓(𝑥) =\\n\"\\n，sigmoid 函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1−𝑓(𝑥)]，我们可以画出 sigmoid 函数的导数\\n\"(cid:151)⁄¥ƒ\\n图像如图4.19 所示。\\n图4.19 sigmoid函数导数\\n这里我们发现当x=0 时，sigmoid函数导数可以取得最大值0.25。x取值较大或较小时，\\nsigmoid 函数的导数很快就趋向于 0。不管怎么样，sigmoid 函数的导数都是一个小于 1 的\\n数，学习信号𝛿乘以一个小于1 的数，那么𝛿就会减小。学习信号从输出层一层一层向前反向传\\n播的时候，每传播一层学习信号就会变小一点，经过多层传播后，学习信号就会接近于 0，从\\n而使得权值∆𝑊调整接近于0。∆𝑊接近于 0 那就意味着该层的参数不会发生改变，不能进行优\\n化。参数不能优化，那整个网络就不能再进行学习了。学习信号随着网络传播逐渐减小的问题\\n也被称为梯度消失（Vanishing Gradient）的问题。\\n⁄ƒ(cid:127)⁄¥ƒ\\n我们再考虑一下 tanh 函数的导数，tanh 函数的表达式为：𝑓(𝑥) = ，tanh 函数的\\n⁄ƒ(cid:151)⁄¥ƒ\\n#\\n导数为：𝑓R(𝑥) = 1−(cid:142)𝑓(𝑥)(cid:143) ，tanh函数的导数如图4.20 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 120, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 121\\n图4.20 tanh函数导数\\ntanh函数导数图像看起来比sigmoid函数要好一些，x=0 时，tanh函数导数可以取得\\n最大值1。x取值较大或较小时，tanh函数的导数很快就趋向于0。不管怎么样，tanh函数\\n导数的取值总是小于等于1 的，所以 tanh作为激活函数也会存在梯度消失的问题。\\nV\\n对于 softsign 函数，softsign 函数的表达式为：𝑓(𝑥) = ，softsign 函数的导数为：\\n\"(cid:151)|V|\\n𝑓R(𝑥) = \" ，softsign 函数的导数如图 4.21 所示。\\n(\"(cid:151)|V|)(cid:157)\\n图4.21 softsign 函数导数\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 121, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 122\\nsoftsign 函数x=0 时，softsign 函数导数可以取得最大值1。x取值较大或较小时，\\nsoftsign 函数的导数很快就趋向于0。不管怎么样，softsign 函数导数的取值总是小于等于\\n1 的，所以softsign 作为激活函数也会存在梯度消失的问题。\\n4.8.2 梯度爆炸\\n当我们使用sigmoid,tanh和softsign 作为激活函数时，它们的导数取值范围都是小于等\\n于1 的，所以会产生梯度消失的问题。那么我们可能会想到，如果使用导数大于1 的函数作为\\n激活函数，情况会如何？\\n如果学习信号𝛿乘以一个大于 1 的数，那么δ就会变大。学习信号从输出层一层一层向前\\n反向传播的时候，每传播一层学习信号就会变大一点，经过多层传播后，学习信号就会接近于\\n无穷大，从而使得权值∆𝑊调整接近于无穷大。∆𝑊接近于无穷大那就意味着该层的参数，处于\\n一种极不稳定的状态，那么网络就不能正常工作了。学习信号随着网络传播逐渐增大的问题也\\n被称为梯度爆炸（Exploding Gradient）的问题。\\n既然激活函数的导数不能小于 1 也不能大于 1，我们可能会想到，能不能使用线性函数\\ny=x，这个函数的导数是 1。它既不会梯度消失，也不会梯度爆炸。确实如此，线性函数导数\\n为1 的特性是很好，但是，它是一个线性函数，也就是说，它不能处理非线性问题，比如异或\\n分类问题，它就无法解决。而在实际应用中，非常多的应用都是属于非线性问题，所以使用线\\n性函数来作为激活函数存在很大的局限性，所以也不适合。\\n4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题\\n我们知道 ReLU 的表达式为：𝑓(𝑥) = 𝑚𝑎𝑥 (0,𝑥)。当 x 小于 0 时，𝑓(𝑥)的取值为 0；当 x\\n大于0 时，𝑓(𝑥)的取值等于x。ReLU函数的导数如图4.22 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 122, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 123\\n图4.22 ReLU函数导数\\n前面我们讨论了当激活函数的导数小于 1 时，网络会产生梯度消失，激活函数的导数大\\n于1 时，网络会产生梯度爆炸。那么当我们使用 ReLU作为激活函数的时候，x小于0 时，\\nReLU的导数为 0；x大于0 时，ReLU的导数为1。导数为1 是一个很好的特性，不会使得\\n学习信号越来越小，也不会让学习信号越来越大，可以让学习信号比较稳定地从后向前传\\n播。解决了梯度消失和梯度爆炸的问题，同时计算方便，可以加速网络的训练。\\nReLU函数还有一个优点，它是一个非线性的激活函数，可以用来处理非线性问题，它\\n的非线性特性在4.5 小节中已经介绍过。\\n认真思考的同学这个时候可能会发现，ReLU函数看起来是挺好的，既是非线性函数，\\n导数又为1，但是它好像也存在一些问题，当 x小于0 时，ReLU函数输出为0，导数也为\\n0，有些信号不就丢失掉了吗？\\n如果你是这么想的，那你就想对了，确实是丢失了一些信号，但是没关系。在神经网络\\n中，信号是冗余的，也就是说其实网络最后在做预测的时候并不需要从前面传过来的所有的\\n信号，实际上只需要一部分的信号，网络就可以进行预测。并且使用部分信号来进行预测与\\n使用全部信号来进行预测得到的结果相差不大。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 123, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 124\\n比如我们把网络中输出为0 的神经元看成是不工作的神经元，那么使用 ReLU函数以后会\\n产生大量不工作的神经元。网络中存在不工作的神经元，我们可以称这个网络具有一定的稀疏\\n性（Sparsity）。不工作的神经元越多，网络就越稀疏。使得网络产生稀疏性的方式很多，除\\n了使用ReLU激活函数以外，还可以使用L1正则化（L1 Regularization）和Dropout，这\\n两个技术在后面的章节中会有详细介绍。所以使得神经网络变稀疏并不是什么稀奇的事，也不\\n一定是坏事。\\n稀疏性这一特性也存在于生物体内的神经网络中，大脑中神经网络的稀疏性高达 95%-\\n99%，也就是说在同一时刻其实大脑中大部分的神经元都是不工作。人工神经网络中比较常见\\n的网络稀疏性是50%-80%。\\n4.9 使用 BP 神经网络解决异或问题\\nBP 神经网络解决异或问题的代码如代码4-1 所示。\\n代码4-1：BP 神经网络解决异或问题\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# 输入数据\\nX = np.array([[0,0],\\n[0,1],\\n[1,0],\\n[1,1]])\\n# 标签\\nT = np.array([[0],\\n[1],\\n[1],\\n[0]])\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 124, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 125\\n# 定义一个2 层的神经网络：2-10-1\\n# 输入层2 个神经元，隐藏层10 个神经元，输出层 1 个神经元\\n# 输入层到隐藏层的权值初始化，2 行10 列\\nW1 = np.random.random([2,10])\\n# 隐藏层到输出层的权值初始化，10 行1 列\\nW2 = np.random.random([10,1])\\n# 初始化偏置值，偏置值的初始化一般可以取 0，或者一个比较小的常数，如0.1\\n# 隐藏层的10 个神经元偏置\\nb1 = np.zeros([10])\\n# 输出层的1 个神经元偏置\\nb2 = np.zeros([1])\\n# 学习率设置\\nlr = 0.1\\n# 定义训练周期数\\nepochs = 100001\\n# 定义测试周期数\\ntest = 5000\\n# 定义sigmoid函数\\ndef sigmoid(x):\\nreturn 1/(1+np.exp(-x))\\n# 定义sigmoid函数导数\\ndef dsigmoid(x):\\nreturn x*(1-x)\\n# 更新权值和偏置值\\ndef update():\\nglobal X,T,W1,W2,lr,b1,b2\\n# 隐藏层输出\\nL1 = sigmoid(np.dot(X,W1) + b1)\\n# 输出层输出\\nL2 = sigmoid(np.dot(L1,W2) + b2)\\n# 求输出层的学习信号\\ndelta_L2 = (T - L2) * dsigmoid(L2)\\n# 隐藏层的学习信号\\ndelta_L1 = delta_L2.dot(W2.T) * dsigmoid(L1)\\n# 求隐藏层到输出层的权值改变\\n# 由于一次计算了多个样本，所以需要求平均\\ndelta_W2 = lr * L1.T.dot(delta_L2) / X.shape[0]\\n# 输入层到隐藏层的权值改变\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 125, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 126\\n# 由于一次计算了多个样本，所以需要求平均\\ndelta_W1 = lr * X.T.dot(delta_L1) / X.shape[0]\\n# 更新权值\\nW2 = W2 + delta_W2\\nW1 = W1 + delta_W1\\n# 改变偏置值\\n# 由于一次计算了多个样本，所以需要求平均\\nb2 = b2 + lr * np.mean(delta_L2, axis=0)\\nb1 = b1 + lr * np.mean(delta_L1, axis=0)\\n# 定义空list用于保存loss\\nloss = []\\n# 训练模型\\nfor i in range(epochs):\\n# 更新权值\\nupdate()\\n# 每训练5000 次计算一次loss值\\nif i % test == 0:\\n# 隐藏层输出\\nL1 = sigmoid(np.dot(X,W1) + b1)\\n# 输出层输出\\nL2 = sigmoid(np.dot(L1,W2) + b2)\\n# 计算loss值\\nprint('epochs:',i,'loss:',np.mean(np.square(T - L2) / 2))\\n# 保存loss值\\nloss.append(np.mean(np.square(T - L2) / 2))\\n# 画图训练周期数与loss的关系图\\nplt.plot(range(0,epochs,test),loss)\\nplt.xlabel('epochs')\\nplt.ylabel('loss')\\nplt.show()\\n# 隐藏层输出\\nL1 = sigmoid(np.dot(X,W1) + b1)\\n# 输出层输出\\nL2 = sigmoid(np.dot(L1,W2) + b2)\\nprint('output:')\\nprint(L2)\\n# 因为最终的分类只有0 和1，所以我们可以把\\n# 大于等于0.5的值归为1 类，小于0.5的值归为0 类\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 126, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 127\\ndef predict(x):\\nif x>=0.5:\\nreturn 1\\nelse:\\nreturn 0\\n# map 会根据提供的函数对指定序列做映射\\n# 相当于依次把L2 中的值放到predict函数中计算\\n# 然后打印出结果\\nprint('predict:')\\nfor i in map(predict,L2):\\nprint(i)\\n运行结果如下：\\nepochs: 0 loss: 0.2382731940835196\\nepochs: 5000 loss: 0.1206923173399693\\nepochs: 10000 loss: 0.0790971946756123\\nepochs: 15000 loss: 0.02378338344093093\\nepochs: 20000 loss: 0.008377749771590743\\nepochs: 25000 loss: 0.004291050338268038\\nepochs: 30000 loss: 0.002694668764968099\\nepochs: 35000 loss: 0.0018982939821333231\\nepochs: 40000 loss: 0.0014365256397058071\\nepochs: 45000 loss: 0.001140826866565359\\nepochs: 50000 loss: 0.0009377943334308873\\nepochs: 55000 loss: 0.0007910315050028132\\nepochs: 60000 loss: 0.000680683460806228\\nepochs: 65000 loss: 0.0005950985467089836\\nepochs: 70000 loss: 0.0005270339320851203\\nepochs: 75000 loss: 0.00047177302525578296\\nepochs: 80000 loss: 0.0004261243077828677\\nepochs: 85000 loss: 0.00038785770517095713\\nepochs: 90000 loss: 0.0003553718177062329\\nepochs: 95000 loss: 0.0003274893656556488\\nepochs: 100000 loss: 0.00030332701795183955\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 127, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 128\\noutput:\\n[[0.02462022]\\n[0.97697496]\\n[0.97534433]\\n[0.02612291]]\\npredict:\\n0\\n1\\n1\\n0\\n4.10 分类模型评估方法\\n4.10.1 准确率/精确率/召回率/F1 值\\n机器学习中有很多分类模型评估指标，比如 准确率（Accuracy），精确率（查准率，\\nPrecision）和召回率（查全率，Recall）都是比较常见的。\\n我们先来说一下准确率，准确也是我们日常生活中用得较多的一个判断指标，准确率的计\\n算很简单，准确率=所有预测正确的结果除以所有结果。比如一个模型要识别5 张图片，最后\\n识别正确4 张图片，错了 1 张，那么准确率就是4/5=80%。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 128, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 129\\n倘若某人声称创建了一个能够识别登上飞机的恐怖分子的模型，并且准确率（accuracy）\\n高达 99%。这能算是个好模型吗？已知美国全年平均有 8 亿人次的乘客，并且在 2000-\\n2017 年间共发现了 19 名恐怖分子。如果有一个模型将从美国机场起飞的所有乘客都标注为\\n非恐怖分子，那么这个模型达到了接近完美的准确率——99.99999%。这听起来确实令人印\\n象深刻，但是美国国土安全局肯定不会购买这个模型。尽管这个模型拥有接近完美的准确率，\\n但是在这个问题中准确率显然不是一个合适的度量指标。\\n恐怖分子检测是一个不平衡的分类问题：我们需要鉴别的类别有两个，恐怖分子和非恐怖\\n分子，其中一个类别代表了极大多数的数据，而另一个类别数据却很少。比如我们把恐怖分子\\n定义为正例，非恐怖分子定义为负例，那么正例类别——恐怖分子，远远少于负例类别——非\\n恐怖分子的数量。这种数据不均衡的问题是数据科学中比较常见的，在数据不均衡的情况下使\\n用准确率并不是评估模型性能的很好的衡量标准。当然，如果是数据比较均衡的情况下，我们\\n还是可以使用准确率来作为分类模型的评估指标。\\n所以在数据不均衡的场景下，我们应该考虑的评估指标应该是精确率和召回率。我们先看\\n一下图4.23。\\n图4.23 真实标注与模型预测对比\\n图中的True Positive(TP)表示模型预测结果是恐怖分子，数据的真实标注也是恐怖分子；\\nFalse Positive(FP)表示模型预测结果是恐怖分子，数据的真实标注是非恐怖分子； False\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 129, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 130\\nNegative(FN)表示模型预测结果是非恐怖分子，数据的真实标注是恐怖分子； True\\nNegative(TN)表示模型预测结果是非恐怖分子，数据的真实标注也是非恐怖分子。\\n这里的 True/Fasle 和 Positive/Negative 我们可以这么来理解，True 或 Fasle 表示模型\\n预测结果是否正确，如果预测正确就是 True，预测错误就是 Fasle。所以相当于 TP 和 TN 都\\n表示模型预测是正确的，FP和FN 表示模型预测不正确。Positive或Negative 表示模型的预\\n测结果。TP 和 FP模型预测结果都是 Positive，TN 和FN 模型预测结果都是Negative。\\n看懂这个图以后我们来看一下召回率（recall）的公式：\\n𝑇𝑃\\n𝑟𝑒𝑐𝑎𝑙𝑙 = (4.55)\\n𝑇𝑃 + 𝐹𝑁\\n召回率描述的是模型对于正例——恐怖分子的召回能力，也就是找到恐怖分子的能力。比\\n如一共有 19 名恐怖分子，模型可以正确识别出 10 名恐怖分子，有 9 名恐怖分子没有识别出\\n来。那么 TP=10，FN=9，recall=10/(10+9)=52.63%。比如一共有19 名恐怖分子，模型可\\n以正确识别出 18 名恐怖分子，有 1 名恐怖分子没有识别出来，那么 TP=18，FN=1，\\nrecall=18/(18+1)=94.74%。召回率越高说明模型找到恐怖分子的能力越强。\\n我们再来看一下精确率（precision）的公式：\\n𝑇𝑃\\n𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 = (4.56)\\n𝑇𝑃 + 𝐹𝑃\\n精确率描述的是模型对于正例-恐怖分子的判断能力。比如模型可以正确识别出 10 名恐\\n怖分子，另外还有 40 人模型判断是恐怖分子，其实这 40 人是非恐怖分子。那么 TP=10，\\nFP=40，precision=10/(10+40)=20%。比如模型可以正确识别 9 名恐怖分子，另外还有 1\\n人模 型判断是恐 怖分子 ， 其实这 1 人 是非恐 怖分子 。那么 TP=9 ， FP=1 ，\\nprecision=9/(9+1)=90%。精确率越高说明模型对于恐怖分子的识别越精准。\\n准确率（accuracy）的公式为：\\n𝑇𝑃 + 𝑇𝑁\\n𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 = (4.57)\\n𝑇𝑃 + 𝐹𝑁 + 𝐹𝑃 + 𝑇𝑁\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 130, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 131\\n也就是所有识别正确的结果除以所有结果。\\n针对不同的问题，我们所关注的评估指标可能也会有所不同。比如 2020 年初新型冠状病\\n毒爆发时期，我们更关注召回率，因为我们要尽量找到所有带有新型冠状病毒的病人，然后把\\n病人进行隔离观察治疗，宁可抓错100，也不能放过1 个。\\n再举一个信息检索中比较极端的例子，假如一个搜索引擎有 10000 个网站，其中有 100\\n个深度学习相关的网站。当我们搜索“深度学习是什么？”的时候，如果搜索引擎想提高精确\\n率，那么它可以只返回一个跟深度学习相关度最高的网站，如果这个结果是我们想要的，那么\\n精确率就是 100%，不过这样做，召回率只有 1%。如果搜索引擎想提高召回率，那么它可以\\n返回10000 个网站，这样做召回率就可以有100%，不过精确率只有1%。\\n所以判断一个搜索引擎好坏，主要看的是前面几十条结果的精确率，因为我们通常只会查\\n看最前面的几十条结果，特别是最前面的几条结果。最前面的几条结果是我们想要的，我们就\\n会认为这个搜索引擎很好。我们并不是很在意搜索引擎的召回率，比如一共有 10000 条结果\\n是符合我们想要的结果，搜索引擎给我们返回了 1000 条还是 9000 条，其实我们并不在意，\\n因为我们只会看最前面的几十条结果。\\n在实际应用中，最理想的情况是精确率和召回率都比较高，不过一般来说，很难得到精确\\n率和召回率都很高的结果。很多时候是提高了精确率，召回率就会降低；提高召回率，精确率\\n就会降低。所以我们还需要一个综合评估指标，也就是 F 值，F 值是精确率(P)和召回率(R)的\\n加权调和平均，公式为：\\n((𝛼# + 1) × 𝑃 × 𝑅)\\n𝐹 = (4.58)\\n𝛼# × 𝑃 + 𝑅\\n当参数𝛼 = 1时，就是最常见的的 F1 值，即：\\n2 × 𝑃 × 𝑅\\n𝐹1 = (4.59)\\n𝑃 + 𝑅\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 131, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 132\\nF1 值综合了 P和R的结果，可用于综合评价分类结果的质量。\\n准确率，召回率，精确率，F1 值都是在0-1 之间，并且都是越大越好。\\n最后我再举一个例子，帮助大家理解这4 个评估指标的计算。比如一个预测恐怖分子的模\\n型结果如图4.24所示。\\n图4.24 模型结果\\n有10 个恐怖分子模型预测结果也是恐怖分子（TP）\\n有10 个非恐怖分子模型预测结果是恐怖分子（FP）\\n有5 个恐怖分子模型预测结果是非恐怖分子（FN）\\n有75 个非恐怖分子模型预测结果是非恐怖分子（TN）\\n准确率计算：(TP+TN)/(TP+FN+FP+TN)=(10+75)/(10+5+10+75)=85%\\n召回率计算：TP/(TP+FN)=10/(10+5)=66.67%\\n精确率计算：TP/(TP+FP)=10/(10+10)=50%\\nF1 值：(2×50%×66.67%)/(50%+66.67%)=57.14%\\n4.10.2 混淆矩阵(Confusion Matrix)\\n在机器学习领域，混淆矩阵又称为可能性表格或者是错误矩阵。它是一种特定的矩阵用来\\n呈现算法的效果。我们还是通过例子来讲解，假设有一个人，狗，猫的分类系统，我们的测试\\n样本一共有10 个人，15 只狗，5 只猫，得到如下混淆矩阵，如图4.25 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 132, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 133\\n模型预测\\n猫 狗 人\\n猫 3 1 1\\n真实标签 狗 3 11 1\\n人 1 2 7\\n图4.25 混淆矩阵\\n图中表达的意思是，一共有5 只猫，其中 3 中预测正确了，有1 只猫被预测成了狗，有\\n1 只猫被预测成了人；一共有 15 只狗，其中有3 只狗被预测成了猫，有11 只狗预测正确，\\n有1 只狗被预测成了人；一共有 10 个人，其中有1 个人被预测成了猫，有两个人被预测成\\n了狗，有7 个人预测正确。\\n4.11 独热编码（One-Hot Encoding）\\n在神经网络，深度学习的分类问题中，我们通常会把分类问题的标签转化为独热编码的格\\n式。比如在手写数字识别的任务中，数字有0-9 一共10 中状态，所以每个数字都可以转换为\\n长度为10 的编码：\\n0->1000000000\\n1->0100000000\\n2->0010000000\\n3->0001000000\\n4->0000100000\\n5->0000010000\\n6->0000001000\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 133, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 134\\n7->0000000100\\n8->0000000010\\n9>-0000000001\\n比如对于根据图片判断性别的模型：\\n男性可以编码为：10\\n女性可以编码为：01\\n比如给花的品种进行分类的模型，假设有红黄蓝三种花：\\n红花可以编码为：100\\n黄花可以编码为：010\\n蓝花可以编码为：001\\n根据以上的几个例子大家应该都可以了解独热编码是怎么回事了，在后面的分类应用中我\\n们经常会把分类的标签处理成为独热编码的格式，然后用来训练模型。\\n4.12 BP 神经网络完成手写数字识别\\n这一小节中我们要自己搭建一个BP网络来完成手写数字识别的功能，我们使用到的训练\\n集是sklearn中自带的手写数字数据集。首先我们先看一下数据集，如代码4-2 所示。\\n代码4-2：手写数字数据集介绍\\nfrom sklearn.datasets import load_digits\\nimport matplotlib.pyplot as plt\\n# 载入手写数字数据\\ndigits = load_digits()\\n# 打印数据集的shape，行表示数据集个数，列表示每个数据的特征数\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 134, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 135\\nprint('data shape:',digits.data.shape)\\n# 打印数据标签的shape，数据标签的值为0-9\\nprint('target shape:',digits.target.shape)\\n# 准备显示第0 张图片，图片为灰度图\\nplt.imshow(digits.images[0],cmap='gray')\\n# 显示图片\\nplt.show()\\n运行结果如下：\\ndata shape: (1797, 64)\\ntarget shape: (1797,)\\n观察4-2 程序的输出我们可以发现这个数据集中每个数据的图片是一张8×8 的图片，分\\n别对应数字0-9。所以我们可以考虑构建一个输入层为64 个神经元的神经网络，64 个神经\\n元对应于图片中的64 个像素点。假设我们设置一层隐藏层，隐藏层有100 个神经元。最后\\n设置一个输出层，我们会把标签转变为独热编码(one-hot)的格式，数字0-9 一共10 个状\\n态，所以输出层我们可以设置10 个神经元。数字识别网络结构图如图4.26 所示。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 135, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 136\\n图4.26 数字识别网络结构图\\nBP 网络完成手写数字识别的代码如代码4-3 所示。\\n代码4-3：BP 网络完成手写数字识别\\n# 导入numpy科学计算库\\nimport numpy as np\\n# 载入画图工具包\\nimport matplotlib.pyplot as plt\\n# 导入手写数字数据集\\nfrom sklearn.datasets import load_digits\\n# 用于标签二值化处理，把标签转成独热编码 one-hot的格式\\nfrom sklearn.preprocessing import LabelBinarizer\\n# 用于把数据集拆分为训练集和测试集\\nfrom sklearn.cross_validation import train_test_split\\n# 用于评估分类结果\\nfrom sklearn.metrics import classification_report,confusion_matrix\\n# 定义sigmoid函数\\ndef sigmoid(x):\\nreturn 1/(1+np.exp(-x))\\n# 定义sigmoid函数的导数\\ndef dsigmoid(x):\\nreturn x*(1-x)\\n# 定义神经网络类\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 136, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 137\\nclass NeuralNetwork:\\n# 初始化网络，定义网络结构\\n# 假设传入(64,100,10)，说明定义：\\n# 输入层64 个神经元，隐藏层100 个神经元，输出层 10 个神经元\\ndef __init__(self,layers):\\n# 权值的初始化，范围-1 到1\\nself.W1 = np.random.random([layers[0],layers[1]])*2-1\\nself.W2 = np.random.random([layers[1],layers[2]])*2-1\\n# 初始化偏置值\\nself.b1 = np.zeros([layers[1]])\\nself.b2 = np.zeros([layers[2]])\\n# 定义空list用于保存list\\nself.loss = []\\n# 定义空list用于保存\\nself.accuracy = []\\n# 训练模型\\n# X为数据输入\\n# T为数据对应的标签\\n# lr学习率\\n# steps训练次数\\n# batch 批次大小\\n# 使用批量随机梯度下降法，每次随机抽取一个批次的数据进行训练\\ndef train(self,X,T,lr=0.1,steps=20000,test=5000,batch=50):\\n# 进行steps+1 次训练\\nfor n in range(steps+1):\\n# 随机选取一个批次数据\\nindex = np.random.randint(0,X.shape[0],batch)\\nx = X[index]\\n# 计算隐藏层输出\\nL1 = sigmoid(np.dot(x,self.W1)+self.b1)\\n# 计算输出层输出\\nL2 = sigmoid(np.dot(L1,self.W2)+self.b2)\\n# 求输出层的学习信号\\ndelta_L2 = (T[index]-L2)*dsigmoid(L2)\\n# 求隐藏层的学习信号\\ndelta_L1= delta_L2.dot(self.W2.T)*dsigmoid(L1)\\n# 求隐藏层到输出层的权值改变\\n# 由于一次计算了多个样本，所以需要求平均\\nself.W2 += lr * L1.T.dot(delta_L2) / x.shape[0]\\n# 求输入层到隐藏层的权值改变\\n# 由于一次计算了多个样本，所以需要求平均\\nself.W1 += lr * x.T.dot(delta_L1) / x.shape[0]\\n# 改变偏置值\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 137, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 138\\nself.b2 = self.b2 + lr * np.mean(delta_L2, axis=0)\\nself.b1 = self.b1 + lr * np.mean(delta_L1, axis=0)\\n# 每训练5000 次预测一次准确率\\nif n%test==0:\\n# 预测测试集的预测结果\\nY2 = self.predict(X_test)\\n# 取得预测结果最大的所在的索引\\n# 例如最大值所在的索引是3，那么预测结果就是3\\npredictions = np.argmax(Y2,axis=1)\\n# 计算准确率\\n# np.equal(predictions,y_test)判断预测结果和真实标签是否相等，相等返回\\nTrue，不相等返回False\\n# np.equal(predictions,y_test)执行后得到一个包含多个True 和False 的列表\\n# 然后用np.mean 对列表求平均True 为1，False 为0。\\n# 例如一共有10 个结果，9 个True，一个False，平均后的结果为0.9，即预测的\\n准确率为90%\\nacc = np.mean(np.equal(predictions,y_test))\\n# 计算loss\\nl = np.mean(np.square(y_test - predictions) / 2)\\n# 保存准确率\\nself.accuracy.append(acc)\\n# 保存loss值\\nself.loss.append(l)\\n# 打印训练次数,准确率和loss\\nprint('steps:%d accuracy:%.3f loss:%.3f' % (n,acc,l))\\n# 模型预测结果\\ndef predict(self,x):\\nL1 = sigmoid(np.dot(x,self.W1)+self.b1)#隐层输出\\nL2 = sigmoid(np.dot(L1,self.W2)+self.b2)#输出层输出\\nreturn L2\\n# 程序从这里开始运行\\n# 定义训练次数\\nsteps = 30001\\n# 定义测试周期数\\ntest = 3000\\n# 载入数据\\ndigits = load_digits()\\n# 得到数据\\nX = digits.data\\n# 得到标签\\ny = digits.target\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 138, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 139\\n# 输入数据归一化，有助于加快训练速度\\n# X中原来的数值范围是0-255 之间，归一化后变成0-1 之间\\nX -= X.min()\\nX /= X.max() - X.min()\\n# 分割数据1/4为测试数据，3/4为训练数据\\n# 有1347 个训练数据，450 个测试数据\\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\\n# 创建网络,输入层64 个神经元，隐藏层 100 个神经元，输出层10 个神经元\\nnm = NeuralNetwork([64,100,10])\\n# 标签转化为独热编码one-hot的格式\\nlabels_train = LabelBinarizer().fit_transform(y_train)\\n# 开始训练\\nprint('Start training')\\nnm.train(X_train,labels_train,steps=steps,test=test)\\n# 预测测试数据\\npredictions = nm.predict(X_test)\\n# predictions.shape为(450,10)\\n# y_test.shape 为(450,)\\n# 所以需要取得预测结果最大的所在的索引，该索引就是网络预测的结果\\n# np.argmax(predictions,axis=1)执行后得到的形状也变成了(450,)\\npredictions = np.argmax(predictions,axis=1)\\n# 对比测试数据的真实标签与网络预测结果，得到准确率，召回率和 F1 值\\nprint(classification_report(y_test,predictions))\\n# 对于测试数据的真实标签与网络预测结果，得到混淆矩阵\\nprint(confusion_matrix(y_test,predictions))\\n# 训练次数与loss的关系图\\nplt.plot(range(0,steps+1,test),nm.loss)\\nplt.xlabel('steps')\\nplt.ylabel('loss')\\nplt.show()\\n# 训练次数与accuracy的关系图\\nplt.plot(range(0,steps+1,test),nm.accuracy)\\nplt.xlabel('steps')\\nplt.ylabel('accuracy')\\nplt.show()\\n运行结果如下：\\nStart training\\nsteps:0 accuracy:0.111 loss:10.206\\nsteps:3000 accuracy:0.922 loss:0.777\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 139, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 140\\nsteps:6000 accuracy:0.960 loss:0.469\\nsteps:9000 accuracy:0.964 loss:0.389\\nsteps:12000 accuracy:0.967 loss:0.361\\nsteps:15000 accuracy:0.964 loss:0.416\\nsteps:18000 accuracy:0.971 loss:0.342\\nsteps:21000 accuracy:0.969 loss:0.378\\nsteps:24000 accuracy:0.971 loss:0.342\\nsteps:27000 accuracy:0.971 loss:0.360\\nsteps:30000 accuracy:0.971 loss:0.360\\nprecision recall f1-score support\\n0 1.00 0.98 0.99 45\\n1 0.93 0.98 0.95 41\\n2 0.98 1.00 0.99 50\\n3 1.00 0.93 0.96 40\\n4 0.98 0.98 0.98 48\\n5 0.94 0.98 0.96 51\\n6 0.98 1.00 0.99 42\\n7 1.00 1.00 1.00 45\\n8 0.93 0.91 0.92 44\\n9 0.98 0.95 0.97 44\\navg / total 0.97 0.97 0.97 450\\n[[44 0 0 0 1 0 0 0 0 0]\\n[ 0 40 0 0 0 0 0 0 1 0]\\n[ 0 0 50 0 0 0 0 0 0 0]\\n[ 0 0 0 37 0 2 0 0 1 0]\\n[ 0 0 0 0 47 0 0 0 0 1]\\n[ 0 0 0 0 0 50 1 0 0 0]\\n[ 0 0 0 0 0 0 42 0 0 0]\\n[ 0 0 0 0 0 0 0 45 0 0]\\n[ 0 3 1 0 0 0 0 0 40 0]\\n[ 0 0 0 0 0 1 0 0 1 42]]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 140, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 141\\n4.13 Sklearn 手写数字识别\\n上一小节我们学习了如何从头开始搭建一个 BP 神经网络来完成手写数字识别，其实搭\\n建BP 神经网络还有更简单快捷的方法，就是使用scikit-learn模块。scikit-learn是一个常\\n用的python模型，里面封装了大量机器学习算法，其中就包括BP 神经网络。下面我们来\\n看一下如何使用scikit-learn中的神经网络算法来进行手写数字识别，如代码 4-4 所示。\\n代码4-4：BP 网络完成手写数字识别(使用scikit-learn中的神经网络算法)\\n# 载入BP神经网络算法\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 141, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 142\\nimport matplotlib.pyplot as plt\\n#载入数据\\ndigits = load_digits()\\n#数据\\nx_data = digits.data\\n#标签\\ny_data = digits.target\\n# X中原来的数值范围是0-255 之间，归一化后变成0-1 之间\\nx_data -= x_data.min()\\nx_data /= x_data.max() - x_data.min()\\n# 分割数据1/4为测试数据，3/4为训练数据\\n# 有1347 个训练数据，450 个测试数据\\nx_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.25)\\n# 定义神经网络模型，模型输入神经元个数和输出神经元个数不需要设置\\n# hidden_layer_sizes用于设置隐藏层结构：\\n# 比如(50)表示有1 个隐藏层，隐藏层神经元个数为50\\n# 比如(100,20)表示有2 个隐藏层，第 1 个隐藏层有100 个神经元，第2 个隐藏层有20 个神\\n经元\\n# 比如(100,20,10)表示3 个隐藏层，神经元个数分别为 100，20，10\\n# max_iter设置训练次数\\nmlp = MLPClassifier(hidden_layer_sizes=(100,20), max_iter=500)\\n# fit 传入训练集数据开始训练模型\\nmlp.fit(x_train,y_train)\\n# predict用于模型预测\\npredictions = mlp.predict(x_test)\\n# 标签数据和模型预测数据进行对比，计算分类评估指标\\nprint(classification_report(y_test, predictions))\\n运行结果如下：\\nprecision recall f1-score support\\n0 1.00 1.00 1.00 35\\n1 0.98 1.00 0.99 49\\n2 1.00 0.98 0.99 50\\n3 0.97 0.97 0.97 38\\n4 1.00 0.98 0.99 56\\n5 1.00 0.93 0.96 43\\n6 1.00 1.00 1.00 47\\n7 0.94 1.00 0.97 46\\n8 0.95 1.00 0.97 36\\n9 0.98 0.96 0.97 50\\naccuracy 0.98 450\\nmacro avg 0.98 0.98 0.98 450\\nweighted avg 0.98 0.98 0.98 450\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 142, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 143\\n要注意的是scikit-learn中封装的神经网络只是普通的 BP 神经网络，不具备深度学习算\\n法。如果要实现深度学习算法需要使用专门的深度学习框架，如 Tensorflow，在下一章节中\\n我们会详细介绍。\\n4.14 参考文献\\n[1] McClelland J L, Rumelhart D E, PDP Research Group. Parallel Distributed\\nProcessing [J]. Explorations in the Microstructure of Cognition, 1986, 2: 216-271.\\n[2] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural\\nnetworks[C]//Proceedings of the fourteenth international conference on artificial\\nintelligence and statistics. 2011: 315-323.\\n[3] 韩力群, 康芊. 人工神经网络理论, 设计及应用——神经细胞, 神经网络和神经系统[J].\\n北京工商大学学报: 自然科学版, 2005, 23(1): 52-52.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 143, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 144\\n第 5 章-深度学习框架 Tensorflow 基础使\\n用\\n在介绍正式内容以前，我想先给大家说明一个基本情况，也就是目前深度学习还处于一\\n个非常早期的，不成熟的阶段，所以我们会看到各种各样的人写着各种各样风格的代码。当\\n我们想完成一个应用的时候，我们会有很多种方式和选择，有时候选择太多也不一定是好\\n事，因为我们可能会面临选择的困难。虽然“条条大路通罗马”，但是有些路好走，有些路不\\n好走；有些路部分人觉得好走，部分人觉得不好走。很多时候我们很难判断哪条路好，哪条\\n路不好。\\n给大家举一个例子来说明这个问题，如图 5.1 所示。\\n图 5.1 条条大路通罗马\\n比如我们想做一个图像识别的应用，那么首先我们有很多种深度学习的框架可以选择。\\n如果是在2016-2017 年左右，那么这个选择还是挺难的，因为每个深度学习的框架都有自己\\n的优缺点，我们可能很难选择学习哪一个框架。当然，这个问题现在相对变得容易了，经过\\n时间的考验，现在业内公认的首选的深度学习框架就是 Tensorflow或者Pytorch。Pytorch\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 144, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 145\\n是最近一两年学术界最喜欢使用的深度学习框架，Tensorflow是落地应用最多的深度学习框\\n架。如果让我推荐的话，我会推荐两者都学，多学总不是坏事。我们这本书主要是以\\nTensorflow为重点，大家可以先跟着我把Tensorflow学好。\\n深度学习框架选好之后，接下来要继续选择，每个框架在实现某个具体应用的时候通常\\n都会有很多种实现方式。比如如何载入数据进行数据预处理有很多种方法，如何搭建网络有\\n很多种方法，如何训练模型又有很多种方法。比如图 5.1 中，假设我们选择了Tensorflow作\\n为我们的深度学习框架，那么我们在搭建网络结构的时候又可以选择使用 Tensorflow的高\\n级API：Slim，TFLearn，tf.layers，tf.keras或其他API，最后完成图像识别的应用。由于\\n各种方法比较多，我们全部都学并不是一个明智的选择，所以在本书中我会选择我认为比较\\n容易理解和学习方法来教大家。Tensorflow2.0 推出以后，谷歌官方建议大家使用tf.keras\\n来搭建和训练模型。Keras也是我非常喜欢的一款深度学习框架，它是所有深度学习框架中\\n最容易使用的，没有之一，所以也比较适合初学者使用。鉴于 Keras的简洁易用性以及容易\\n理解和学习的特点，本书中关于深度学习的应用大部分都会基于 tf.keras的API完成。\\n5.1 Tensorflow 介绍\\n5.1.1 Tensorflow 简介\\nTensorflow的官网是：https://tensorflow.google.cn/，不需要翻墙。\\n还有一个需要翻墙的官网是：https://www.tensorflow.org。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 145, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 146\\nTensorflow 是谷歌基于 DisBelief 进行研发的第二代人工智能学习系统，并于 2015 年\\n11 月9 日开源。Tensorflow可被用于图像识别，语音识别，文本处理等多项机器学习和深度\\n学习领域。并且可以运行在智能手机，个人电脑，数据中心服务器等各种设备上。\\n目前支持Windows，MacOS，Linux系统，支持CPU/GPU版本，支持单机和分布式版\\n本。\\nTensorflow支持多种编程语言，目前有Python，C++，GO，JAVA，R，SWIFT，JavaScript。\\n最主流的编程语言是Python，本书主要介绍的编程语言也是 Python。目前Tensorflow支持\\n64 位的Python3.5/3.6/3.7/3.8 版本。\\n2019 年3 月8 日，Google 发布最新Tensorflow2.0-Alpha版本，并在2019 年10 月\\n1 日发布了Tensorflow2.0 正式版本。新版本的Tensorflow有很多新特性，更快更容易使用\\n更人性化。因为新版本的Tensorflow有较大的更新，所以老版的Tensorflow程序在新版本\\n中几乎都无法继续使用。\\n如果是作为一个初学者，那么我们应该先学 Tensorflow1 呢，还是直接学习\\nTensorflow2。学习Tensorflow1 的理由是现在网上的Tensorflow开源程序以及比较成熟\\n的Tensorflow项目基本上都是基于Tensorflow1 的，Tensorflow2 刚出不久，资源相对来\\n说肯定会比较少一些。不过Tensorflow2 肯定是未来发展的趋势，虽然现在还比较新，但是\\n我还是建议大家学习Tensorflow2 为主。Tensorflow1 和Tensorflow2 作为两个大的版本，\\n它们之间肯定会有很多不同之处，下面我选取两个我觉得最大的变化来给大家进行说明。\\n5.1.2 静态图和动态图机制 Eager Execution\\nTensorflow1 版本跟很多其他的“老”深度学习框架一样，都是使用静态图机制，而\\nTensorflow2 版本跟 Pytorch 一样都是使用现在最新潮的动态图机制。什么是动态图机制我\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 146, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 147\\n觉得基本上不需要跟大家解释，动态图机制是一种跟我们平时写Python 代码类似的一种机制，\\n用起来很自然。比如代码5-1 为Tensorflow2 的程序。\\n代码5-1：动态图\\nimport tensorflow as tf\\n# 创建一个常量\\nm1 = tf.constant([[4,4]])\\n# 创建一个常量\\nm2 = tf.constant([[2],[3]])\\n# 创建一个矩阵乘法，把m1 和m2 传入\\nproduct = tf.matmul(m1,m2)\\n# 打印结果\\nprint(product)\\n结果输出为：\\ntf.Tensor([[20]], shape=(1, 1), dtype=int32)\\n动态图程序看起来就跟一段普通的 Python 程序一样，没什么好特别说明的。不过静态图\\n就没这么好理解了，因为静态图跟我们平时的编程习惯不符。在静态图机制中我们需要在一个\\n计算图（Graph）中定义计算的流程，然后再创建一个会话（Session），在会话中执行计算图\\n的计算。比如代码5-2 为Tensorflow1 的程序。\\n代码5-2：静态图（片段1）\\n# 这个程序我是在Tensorflow1的环境中运行的\\nimport tensorflow as tf\\n# 创建一个常量\\nm1 = tf.constant([[4,4]])\\n# 创建一个常量\\nm2 = tf.constant([[2],[3]])\\n# 创建一个矩阵乘法，把m1 和m2 传入\\nproduct = tf.matmul(m1,m2)\\n# Tensorflow1的程序跟一般的python 程序不太一样\\n# 这个时候打印product，只能看到product的属性，不能计算它的值\\n# 应该这里我只定义了计算图，图必须在会话中运行，我们还没有定义会话\\nprint(product)\\n结果输出为：\\nTensor(\"MatMul:0\", shape=(1, 1), dtype=int32)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 147, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 148\\n代码5-2：静态图（片段2）\\n# 定义一个会话\\nsess = tf.Session()\\n# 调用sess的run 方法来执行矩阵乘法\\n# 计算product，最终计算的结果存放在result中\\nresult = sess.run(product)\\nprint(result)\\n# 关闭会话\\nsess.close()\\n结果输出为：\\n[[20]]\\n对比动态图和静态图这两个简单的程序我们就能看出还是动态图使用起来比较简单，也更\\n加自然。这也是深度学习框架未来的发展趋势，以后静态图机制应该会被慢慢淘汰。\\n5.1.3 tf.keras\\n在说 tf.keras之前我们先来说一下 Keras，Keras 是所有深度学习框架中最容易使用，最\\n初是由Google AI 研究人员 Francois Chollet 创建并开发的。Francois 于 2015 年 3 月\\n27 日将 Keras 的第一个版本发布在他的 GitHub。Keras 是一个高度封装的深度学习框架，\\n它的后端可以是Theano，Tensorflow或者CNTK。很快，Keras的易用性得到了广大深度学\\n习研究开发者的认可，并引起了 Tensorflow 官方的注意。并从 Tensorflow1.10 版本开始加\\n入 tf.keras 接口，也就是我们在 Tensorflow 中也可以使用 Keras 的方式来搭建和训练模型。\\n不过Keras和tf.keras是分开的两个项目，它们使用起来基本上是一样的，只是在细节上\\n会有一些小的不同。随着Tensorflow2.0 的推出，谷歌宣布Keras现在是Tensorflow的官方\\n高级 API，用于快速简单的模型设计和训练，并推荐大家使用。随着 Keras2.3.0 的发布，\\nFrancois 也发表声明推荐深度学习从业人员都应该将代码转成 Tensorflow2.0 和tf.keras，而\\n不是继续使用Keras。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 148, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 149\\n在 Tensorflow1.0 中如何完成我们的深度学习模型训练程序我们有非常多选择，\\nTensorflow2.0 把选择进行了简化，只保留了更好的几种。基于 Tensorflow 官方推荐以及我\\n个人的使用经验，我认为在Tensorflow2.0 的使用中，我们可以尽量多使用tf.keras的接口来\\n完成我们的应用。\\n前面我介绍了很多关于 Keras/tf.keras 的优点，Keras/tf.keras 的缺点是程序运行效率会\\n比纯Tensorflow程序要稍微慢一点点。这和容易理解，程序封装越多，用起来越方便，运行\\n起来自然就会慢一些。不过Tensorflow针对这个问题也做了很多优化，所以实际应用中其实\\n纯 Tensorflow 和 tf.keras速度的差距一般也不会很大。真正影响深度学习运行速度的主要影\\n响因素是模型的复杂度和硬件条件，tf.keras对于速度基本上影响不会很大。\\n5.2 Tensorflow-cpu 安装\\nhttps://tensorflow.google.cn/install/pip 官方网址可以看到关于使用 pip 安装\\nTensorflow比较详细的说明。\\n5.2.1 Tensorflow-cpu 在线安装\\n使用Windows安装Tensorflow的同学要注意，从 TensorFlow 2.1.0 版本开始，需要\\n安装 vc_redist.x64.exe ， 进入链接 https://support.microsoft.com/en-\\nus/help/2977003/the-latest-supported-visual-c-downloads。下载Visual Studio 2015，\\n2017 and 2019 下 面 的 x64:vc_redist.x64.exe （或直 接 从\\nhttps://aka.ms/vs/16/release/vc_redist.x64.exe 链接下载，下载后双击进行安装。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 149, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 150\\nTensorflow 在 Winodws/MacOS/Linux 环境下安装方式基本上都是一样的，首先先来\\n介绍CPU版本的安装。安装 Tensorflow之前，先要安装 Python 环境，Python 的安装在本\\n书第二章节已经介绍过了，大家先要把 Anaconda 给安装好，如使用 Windows 系统，则需\\n要安装Python3.5/3.6/3.7 版本的64 位的Anaconda。如果大家跟着书中的步骤进行安装的\\n话，先把安装流程全部看完再动手，不然可能会操作错误。Python 安装模块的方式都可以用\\npip install 的命令进行安装。Tensorflow2.0 正式发布以后，现在Tesnorflow默认安装的版\\n本就是Tensorflow2 的版本，安装Tensorflow可以用管理员方式打开命令提示符，运行如下\\n命令：\\npip install tensorflow-cpu\\n不过上面命令通常下载速度比较慢，推荐从国内源进行下载速度比较快，使用下面命令下\\n载速度比较快：\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n-i https://pypi.douban.com/simple 是国内下载源，安装其他python模型也可以使用\\n该下载源。\\n执行完之后会自动从网上下载 tensorflow 安装包并安装，安装 tensorflow 的同时也会\\n安装和更新一些其他的python包。\\n顺利的话就运行完这段命令 tensorflow 就安装好了，安装好之后我们可以在命令行安装\\n的最后看到类似如下信息：\\nSuccessfully installed absl-py-0.8.1 cachetools-3.1.1 certifi-2019.11.28 gast-0.2.2\\ngoogle-auth-1.9.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 oauthlib-3.1.0\\npyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0\\ntensorboard-2.0.2 tensorflow-2.0.0 urllib3-1.25.7\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 150, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 151\\n不过一般来说都不会这么顺利，关于可能会出现的问题以及如何解决问题后面会总结。\\n假设安装没有问题，那么可以打开一个python的运行环境，比如Jupyter，然后运行命\\n令：\\nimport tensorflow\\n如果没有产生错误，那么就代表安装成功了。如果看到警告不要紧张，有警告是正常的，\\n一般警告都可以忽略掉，如图5.2 所示表示安装成功。\\n图5.2 Tensorflow安装成功\\n5.2.2 安装过程中可能遇到的问题汇总\\n由于 Tensorflow 会不断地更新，每个 Tensorflow 版本我们可能会遇到的问题不同，每\\n个人的电脑环境也有所不同，所以我这里总结的问题不一定跟大家碰到的问题相同，也可能会\\n有缺漏，如果问题不同或者有缺漏，大家可以给我反馈，我再进行补充。\\n问 题 1 ： 在安装 过程中出现“ ERROR: tensorboard 2.0.2 has requirement\\ngrpcio>=1.24.3, but you'll have grpcio 1.14.1 which is incompatible.\\nERROR: keras 2.2.2 has requirement keras-applications==1.0.4, but you'll have\\nkeras-applications 1.0.8 which is incompatible.”或者类似错误。\\n解决方法：这类错误可以忽略不处理。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 151, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 152\\n问题2：在安装过程中出现“ERROR: Cannot uninstall 'wrapt'. It is a distutils installed\\nproject and thus we cannot accurately determine which files belong to it which would\\nlead to only a partial uninstall.”。\\n解决方法：用管理员方式打开命令提示符，然后运行：\\npip install wrapt --upgrade --ignore-installed\\n然后再次运行：\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n如果出错的不是'wrapt'而是其他模块，类似的错误可以用类似的方法解决。\\n问题 3：在安装过程中出现“ distributed 1.21.8 requires msgpack,which is not\\ninstalled.”类似错误。\\n解决方法：安装“msgpack“，打开命令提示符，然后运行：\\npip install msgpack -i https://pypi.douban.com/simple\\n问题4：某条命令在安装过程中出现“PermissionError：[WinError 5] 拒绝访问”。\\n解决方法：这个错误主要是权限问题，关闭所有 python相关软件，重新用管理员方式打\\n开命令提示符，然后再次运行该命令。\\n问题5：在安装过程中模块下载中断并出现“ReadTimeoutError:HTTPSConnectionPoll”。\\n解决方法：由于下载的资源在国外，所以网速不好可能会导致下载连接超时，可以尝试重\\n新运行命令再次下载安装。也可以使用国内的下载源进行安装，一般速度会比较快，运行下面\\n的命令使用国内的源进行安装：\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n问题6：在安装过程中模块下载中断并出现“拒绝访问”。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 152, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 153\\n解决方法：系统权限问题，可以用管理员方式打开命令提示符，然后重新安装，或者是在\\n安装命令后面加上“--user”，例如：\\npip install tensorflow-cpu -i https://pypi.douban.com/simple --user\\n问题 7：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n“ ImportError:cannot import name ‘dense_features’from\\n‘tensorflow.python.feature_column’”。\\n解决方法：用管理员的方式打开命令提示符，先运行：\\npip uninstall tensorflow_estimator\\n再运行\\npip install tensorflow_estimator\\n问题8：Tensorflow安装成功后在python环境中运行import tensorflow 后出现\\n“ImportError: DLL load failed with error code -1073741795 和ImportError: No\\nmodule named '_pywrap_tensorflow_internal'”。\\n解决方法：由于电脑CPU太老导致的错误，解决方法一是安装老版本的 Tensorflow，比\\n如Tensorflow1.2.0 版本，但是不推荐。推荐的解决方法是换一台新一点的电脑。\\n问题 9：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现：\\nERROR:root:Internal Python error in the inspect module.Below is the traceback from\\nthis internal error.\\n解决方法：安装vc_redist.x64.exe，具体查看5.2.1中说明。然后再重新安装Tensorflow。\\n问题10：Tensorflow安装成功后在 python环境中运行import tensorflow 后出现“No\\nmodule named ‘tensorflow’”，说明Tensorflow还没有安装好。\\n解决方法：打开命令提示符，重新安装：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 153, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 154\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n问题 11：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n“ImportError：DLL load failed：找不到指定的模型”。\\n解决方法：安装vc_redist.x64.exe，具体查看5.2.1中说明。然后再重新安装Tensorflow。\\n5.2.3 Tensorflow-cpu 卸载\\n如果已经安装好了Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\npip uninstall tensorflow-cpu\\n5.2.4 Tensorflow-cpu 更新\\n如果已经安装过Tensorlfow，现在想把Tensorflow更新到最新版本，可以用管理员方式\\n打开命令行，执行命令：\\npip install tensorflow-cpu –upgrade\\n5.2.5 Tensorflow-cpu 指定版本的安装\\n如果我们想安装Tensorflow指定版本，比如老一点的版本，可以使用指定版本的安装方\\n式，比如我们想安装 Tensorflow1.13.2 版本的话，可以用管理员方式打开命令行，执行命令：\\npip install tensorflow==1.13.2\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 154, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 155\\n5.3 Tensorflow-gpu 安装\\n5.3.1 Tensorflow-gpu 了解最新版本情况\\n先在 Tensorflow 官网查看 Tensorflow-gpu 最 新的安装 情况\\n（https://tensorflow.google.cn/install/gpu），如图5.3 所示。\\n图5.3 tensorflow-gpu 版本最新情况\\n一般来说比较新的英伟达(NVIDIA)的GPU都可以支持。这里要注意的是CUDA的版本\\n和cuDNN的版本。比如我们在图5.3 中看到的Tensorflow-gpu 版本需要安装CUDA10.1\\n的版本，cuDNN的版本要求7.6 以上。如果 Tensorflow出了更新的版本，对应的CUDA\\n和cuDNN的版本可能也会发生变化。\\n5.3.2 Tensorflow-gpu 安装 CUDA\\nCUDA（Compute Unified Device Architecture）是英伟达 NVIDIA 推出的运算平台，\\n是一种通用的并行计算机构，可以使得 GPU能够解决复杂的计算问题。CUDA的下载的地址\\n为：https://developer.nvidia.com/cuda-toolkit-archive，如图5.4 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 155, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 156\\n图5.4 不同版本CUDA下载\\n比如我们想下载CUDA10.1，可以点击 CUDA Toolkit10.1。如果点击右侧的Online\\nDocumentation 可以查看关于CUDA安装的一些说明。图5.5 为CUDA10.1 对于\\nWindows环境的一些要求。\\n图5.5 CUDA10.1 对Windows环境要求\\n图中我们可以看到CUDA10.1 要求的 Windows系统在Table1 中，比较常用的系统都可\\n以满足。另外在Table2 中我们看到安装CUDA10.1 之前我们还需要安装Visual Studio，推\\n荐安装Visual Studio15或Visual Studio17版本。\\n图5.6 为CUDA10.1 对于Linux环境的一些要求。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 156, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 157\\n图5.6 CUDA10.1 对Linux环境要求\\n准备好 CUDA10.1 要求的环境以后看我们进入 CUDA 下载界面，并根据情况做好选择，\\n最后点击Downdload，如图5.7 所示。\\n图5.7 下载CUDA\\n安装很简单，跟普通软件一样，一直下一步就可以。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 157, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 158\\n5.3.3 Tensorflow-gpu 安装 cuDNN 库\\ncuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针\\n对深度神经网络（Deep Neural Networks）中的基础操作而设计基于GPU的加速库。cuDNN\\n为深度神经网络中的标准流程提供了高度优化的实现方式，例如 convolution、pooling、\\nnormalization 以及activation layers的前向以及后向过程。\\ncuDNN的下载地址为：https://developer.nvidia.com/cudnn。下载之前需要注册。\\nTensorflow 的 GPU版本对cuDNN的版本是有严格要求的，前面我们看到目前\\nTensorflow2 支持的是cuDNN7.6 以上版本。\\n进入下载地址后，选择对应CUDA10.1 版本和对应操作系统的cuDNN进行下载，如图\\n5.8 所示。\\n图5.8 下载cuDNN\\n下载好了之后可以得到一个压缩包，解压完之后可以看到三个文件夹，我们要做的就是\\n把这三个文件夹中的内容拷贝到CUDA安装目录下面所对应的三个文件夹中，如图5.9（这\\n是我之前配置CUDA9.0 和对应cuDNN时的图，其他版本的CUDA和cuDNN也一样）所\\n示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 158, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 159\\n图5.9 配置cuDNN\\n5.3.4 Tensorflow-gpu 在线安装\\n安装方式跟CPU版本差不多，用管理员方式打开命令提示符，执行命令：\\npip install tensorflow-gpu -i https://pypi.douban.com/simple\\n5.3.5 Tensorflow-gpu 卸载\\n如果已经安装好了Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\npip uninstall tensorflow-gpu\\n5.3.6 Tensorflow-gpu 更新\\n如果已经安装过Tensorlfow，现在想把Tensorflow更新到最新版本，可以用管理员方式\\n打开命令行，执行命令：\\npip install tensorflow-gpu –upgrade\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 159, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 160\\n5.4 Tensorflow 基本概念\\nTensorflow中的一些基本概念在Tensorflow2 版本中已经被隐藏起来，或者已经不再使\\n用了，不过我还是打算给大家简单介绍一些Tensorflow的基本概念，虽然之后可能不会用到。\\nTensorflow 是一个编程系统，使用图(graphs)来表示计算任务，图(graphs)中的节点称\\n之为op(operation)，一个op获得0 个或多个Tensor，执行计算，产生0 个或多个Tensor，\\nTensor看作是一个n 维的数据。Tensorflow1 中图必须在会话（Session）中运行，如图5.10\\n所示。\\n图5.10 会话Session\\n图中的Tensor表示数据，一般可以用在数据的输入，输出，以及计算的中间流程。Variable\\n表示变量，一般用于记录一些需要变化的数值，比如需要训练的模型参数。虽然可以使用\\nTensor的地方都可以使用Variable，不过它们还是有一些区别。\\n图中的 Graph 表示一个完整的计算任务，最上面的 Tensor0 和 Variable0 一起传入一个\\noperation0 里面，这个 operation0 可以是加法，减法，乘法，除法等运算。运算完了之后产\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 160, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 161\\n生了一个Tensor1，这个 Tensor1 跟Tensor2 一起被送入了operation1，在 operation1 中\\n进行计算。\\n再举一个更具体的例子，如图5.11 所示。\\n图5.11 神经网络计算图\\n图中的x是一个Tensor，表示数据的输入，图中的W和b是Variable，表示模型需要\\n训练的参数。W和x共同传入了MatMul 的operation 中，进行矩阵乘法的操作，计算完\\n后得到的Tensor0 会传入到Add(operation)中，跟变量b一起进行加法操作，得到\\nTensor1。Tensor1 传入ReLU(operation)激活函数进行计算，然后得到Tensor2 再继续传\\n递信号，最终得到Tensor3。\\n在前面的内容中我们已经介绍过，在 Tensorflow2 中使用的是动态图机制，也就是说我\\n们不再需要会话，我们可以在任意时候进行计算并得到结果，程序设计起来会更加方便，更\\n加自然。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 161, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 162\\n5.5 Tensorflow 基础使用\\n1．TF1 转 TF2 工具\\nTensorflow2安装好之后，会自带一个工具可以把Tensorflow1的程序转成Tensorflow2\\n的程序，使用方法是打开命令提示符，然后执行：\\ntf_upgrade_v2 --infile input.py --outfile output.py\\ntf_upgrade_v2 为转化工具，input.py 为 Tensorflow1 的程序路径，output.py 为新产\\n生的Tensorflow2 的程序保存路径。\\n这个工具的转换效果不能算很好，并不是所有的 Tensorflow1 的程序都可以使用这个工\\n具转变为 Tensorflow2 的程序。一些比较复杂的 Tensorflow1 的程序还是需要进行比较多的\\n改写才能转成Tensorflow2 的程序。所以大家需要把Tensorflow1 转成Tensorflow2 的时候\\n可以尝试使用，如果发现不行的话可以再自行修改。\\n2. Tensorflow 基本操作\\nTensorflow基本操作的代码如代码5-3 所示。\\n代码5-3：Tensorflow基本操作\\nimport tensorflow as tf\\n# 定义一个变量\\nx = tf.Variable([1,2])\\n# 定义一个常量\\na = tf.constant([3,3])\\n# 减法op\\nsub = tf.subtract(x, a)\\n# 加法op\\nadd = tf.add(x,sub)\\nprint(sub)\\nprint(add)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 162, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 163\\n结果输出为：\\ntf.Tensor([-2 -1], shape=(2,), dtype=int32)\\ntf.Tensor([-1 1], shape=(2,), dtype=int32)\\n3. 拟合线性函数\\n拟合线性函数的代码如代码5-4 所示。\\n代码5-4：拟合线性函数（片段1）\\nimport tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom tensorflow.keras.optimizers import SGD\\n# 使用numpy生成100 个从0-1 的随机点，作为x\\nx_data = np.random.rand(100)\\n# 生成一些随机扰动\\nnoise = np.random.normal(0,0.01,x_data.shape)\\n# 构建目标值，符合线性分布\\ny_data = x_data*0.1 + 0.2 + noise\\n# 画散点图\\nplt.scatter(x_data, y_data)\\nplt.show()\\n结果输出为：\\n代码5-4：拟合线性函数（片段2）\\n# 构建一个顺序模型\\n# 顺序模型为keras中的基本模型结构，就像汉堡一样一层一层叠加网络\\nmodel = tf.keras.Sequential()\\n# Dense 为全连接层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 163, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 164\\n# 在模型中添加一个全连接层\\n# units为输出神经元个数，input_dim为输入神经元个数\\nmodel.add(tf.keras.layers.Dense(units=1,input_dim=1))\\n# 设置模型的优化器和代价函数，学习率为 0.03\\n# sgd:Stochastic gradient descent，随机梯度下降法\\n# mse:Mean Squared Error，均方误差\\nmodel.compile(optimizer=SGD(0.03),loss='mse')\\n# 训练2001 个批次\\nfor step in range(2001):\\n# 训练一个批次数据，返回cost值\\ncost = model.train_on_batch(x_data,y_data)\\n# 每500 个batch 打印一次cost值\\nif step % 500 == 0:\\nprint('cost:',cost)\\n# 使用predict对数据进行预测，得到预测值y_pred\\ny_pred = model.predict(x_data)\\n# 显示随机点\\nplt.scatter(x_data,y_data)\\n# 显示预测结果\\nplt.plot(x_data,y_pred,'r-',lw=3)\\nplt.show()\\n结果输出为：\\ncost: 0.33022374\\ncost: 0.0003510235\\ncost: 9.941429e-05\\ncost: 9.440048e-05\\ncost: 9.430057e-05\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 164, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 165\\n4.拟合非线性函数\\n拟合非线性函数的代码如代码5-5 所示。\\n代码5-5：拟合非线性函数（片段1）\\nimport tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom tensorflow.keras.optimizers import SGD\\n# 使用numpy生成200 个均匀分布的点，并新增一个维度\\nx_data = np.linspace(-0.5,0.5,200)[:,np.newaxis]\\n# 生成一些跟x_data 相同shape 的随机值作为噪声数据\\nnoise = np.random.normal(0,0.02,x_data.shape)\\n# 构建目标值，符合非线性函数，另外再加上噪声值\\ny_data = np.square(x_data) + noise\\n# 画散点图\\nplt.scatter(x_data,y_data)\\nplt.show()\\n结果输出为：\\n代码5-5：拟合非线性函数（片段2）\\n# 构建一个顺序模型\\n# 顺序模型为keras中的基本模型结构，就像汉堡一样一层一层叠加网络\\nmodel = tf.keras.Sequential()\\n# 因为要做非线性回归，所以需要一个带有隐藏层的神经网络\\n# 并且需要使用非线性的激活函数，比如 tanh 函数\\n# keras中input_dim只需要在输入层设置，后面的网络可以自动推断出该层对应的输入\\n# keras中定义网络结构已经默认设置好权值初始化，所以我们不需要额外进行设置\\nmodel.add(tf.keras.layers.Dense(units=10,input_dim=1,activation='tanh'))\\nmodel.add(tf.keras.layers.Dense(units=1,activation='tanh'))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 165, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 166\\n# 设置模型的优化器和代价函数，学习率为 0.1\\n# sgd:Stochastic gradient descent，随机梯度下降法\\n# mse:Mean Squared Error，均方误差\\nmodel.compile(optimizer=SGD(0.3),loss=\\'mse\\')\\n# 训练3001 个批次\\nfor step in range(3001):\\n# 训练一个批次数据，返回cost值\\ncost = model.train_on_batch(x_data,y_data)\\n# 每1000 个 batch 打印一次cost值\\nif step % 1000 == 0:\\n# 定义一个2*2 的图，当前是第 i/1000+1个图\\nplt.subplot(2,2,step/1000+1)\\n# 把x_data 喂到模型中获得预测值\\nprediction_value = model.predict(x_data)\\n# 画散点图\\nplt.scatter(x_data,y_data)\\n# 画模型预测曲线图\\nplt.plot(x_data,prediction_value,\\'r-\\',lw=5)\\n# 不显示坐标\\nplt.axis(\\'off\\')\\n# 图片的标题设置\\nplt.title(\"picture:\" + str(int(step/1000+1)))\\nplt.show()\\n结果输出为：\\n从结果中我们能看得出，随着权值的调整，模型的预测结果也在不断地调整，最终得到比\\n较好的拟合效果。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 166, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 167\\n5.6 手写数字图片分类任务\\n5.6.1 MNIST 数据集介绍\\nMNIST 是一个手写数字的数据集。其中训练集有60000 张图片，测试集有10000 张图\\n片，每一张图片包含28*28 个像素。数据集的下载网址为：\\nhttp://yann.lecun.com/exdb/mnist/。MNIST 数据集的图片如图5.12\\n图5.12 MNIST 数据集\\nMNIST 数据集的标签是介于 0-9 的数字，有时候我们要把标签转化为独热编码(one-hot\\nvectors)，然后再传给模型进行训练。\\n5.6.2 Softmax 函数介绍\\n在多分类问题中，我们通常会使用 softmax函数作为网络输出层的激活函数，softmax\\n函数可以对输出值进行归一化操作，把所有输出值都转化为概率，所有概率值加起来等于\\n1，softmax的公式为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 167, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 168\\nexp (𝑥 )\\n(\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑥) = (5.1)\\n(\\n∑ exp (𝑥 )\\n(cid:129) (cid:129)\\n例如某个神经网络有3 个输出值，为[1,5,3]。\\n计算𝑒\" = 2.718，𝑒(cid:176) = 148.413，𝑒$ = 20.086，𝑒\" +𝑒(cid:176) +𝑒$ = 171.217。\\n⁄– ⁄† ⁄‡\\n𝑝1 = = 0.016，𝑝2 = = 0.867，𝑝3 = = 0.117。\\n⁄–(cid:151)⁄†(cid:151)⁄‡ ⁄–(cid:151)⁄†(cid:151)⁄‡ ⁄–(cid:151)⁄†(cid:151)⁄‡\\n所以加上softmax函数后数值变成了[0.016,0.867,0.117]。\\n例如手写数字识别的网络最后的输出结果本来是[-0.124,-4.083,-0.62,0.899,-1.193,-0.70\\n1,-2.834,6.925,-0.332,2.064]，加上softmax函数后会变成[0.001,0.0,0.001,0.002,0.0,0.0,\\n0.0,0.987,0.001,0.008]。\\n5.6.3 简单 MNIST 数据集分类模型-没有高级封装\\n我们可以考虑先构建一个简单的神经网络，这个网络只有输入层和输出层，输入层有 784\\n个神经元，对应每张图片的784 个像素点，输出层有10 个神经元，对应one-hot的标签值，\\n如图5.13：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 168, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 169\\n图5.13 简单MNIST 数据集分类模型\\n大家刚开始学习tensorflow，所以没有使用tf.keras高级封装的代码我也会准备一些给\\n大家学习，代码5-6 没有使用tf.keras来封装模型数据载入和模型训练的过程。\\n代码5-6：MNIST 数据集分类模型-没有高级封装\\nimport tensorflow as tf\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n# 训练集数据x_train 的数据形状为（60000，28，28）\\n# 训练集标签y_train 的数据形状为（60000）\\n# 测试集数据x_test的数据形状为（10000，28，28）\\n# 测试集标签y_test的数据形状为（10000）\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 创建dataset对象，使用dataset对象来管理数据\\nmnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n# 训练周期设置为1（把所有训练集数据训练一次称为训练一个周期）\\nmnist_train = mnist_train.repeat(1)\\n# 批次大小设置为32（每次训练模型传入32 个数据进行训练）\\nmnist_train = mnist_train.batch(32)\\n# 创建dataset对象，使用dataset对象来管理数据\\nmnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\n# 训练周期设置为1（把所有训练集数据训练一次称为训练一个周期）\\nmnist_test = mnist_test.repeat(1)\\n# 批次大小设置为32（每次训练模型传入32 个数据进行训练）\\nmnist_test = mnist_test.batch(32)\\n# 模型定义\\n# 先用Flatten 把数据从3 维变成2 维，(60000,28,28)->(60000,784)\\n# 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 169, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 170\\n# 优化器定义\\noptimizer = tf.keras.optimizers.SGD(0.1)\\n# 计算平均值\\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\\n# 训练准确率计算\\ntrain_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\\n# 计算平均值\\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\\n# 测试准确率计算\\ntest_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\\n# 我们可以用@tf.function 装饰器来将 python 代码转成tensorflow 的图表示代码，用于加速\\n代码运行速度\\n# 定义一个训练模型的函数\\n@tf.function\\ndef train_step(data, label):\\n# 固定写法，使用tf.GradientTape()来计算梯度\\nwith tf.GradientTape() as tape:\\n# 传入数据获得模型预测结果\\npredictions = model(data)\\n# 对比label和predictions计算loss\\nloss = tf.keras.losses.MSE(label, predictions)\\n# 传入loss和模型参数，计算权值调整\\ngradients = tape.gradient(loss, model.trainable_variables)\\n# 进行权值调整\\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\\n# 计算平均loss\\ntrain_loss(loss)\\n# 计算平均准确率\\ntrain_accuracy(label, predictions)\\n# 我们可以用@tf.function 装饰器来将 python 代码转成tensorflow 的图表示代码，用于加速\\n代码运行速度\\n# 定义一个模型测试的函数\\n@tf.function\\ndef test_step(data, label):\\n# 传入数据获得模型预测结果\\npredictions = model(data)\\n# 对比label和predictions计算loss\\nt_loss = tf.keras.losses.MSE(label, predictions)\\n# 计算平均loss\\ntest_loss(t_loss)\\n# 计算平均准确率\\ntest_accuracy(label, predictions)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 170, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 171\\n# 训练10 个周期（把所有训练集数据训练一次称为训练一个周期）\\nEPOCHS = 10\\nfor epoch in range(EPOCHS):\\n# 训练集循环60000/32=1875次\\nfor image, label in mnist_train:\\n# 每次循环传入一个批次的数据和标签训练模型\\ntrain_step(image, label)\\n# 测试集循环10000/32=312.5->313 次\\nfor test_image, test_label in mnist_test:\\n# 每次循环传入一个批次的数据和标签进行测试\\ntest_step(test_image, test_label)\\n# 打印结果\\ntemplate = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'\\nprint(template.format(epoch+1,\\ntrain_loss.result(),\\ntrain_accuracy.result(),\\ntest_loss.result(),\\ntest_accuracy.result()))\\n结果输出为：\\nEpoch 1, Loss: 0.017, Accuracy: 0.892, Test Loss: 0.0138, Test Accura\\ncy: 0.909\\nEpoch 2, Loss: 0.015, Accuracy: 0.905, Test Loss: 0.0134, Test Accura\\ncy: 0.911\\nEpoch 3, Loss: 0.014, Accuracy: 0.911, Test Loss: 0.0131, Test Accura\\ncy: 0.913\\nEpoch 4, Loss: 0.0134, Accuracy: 0.914, Test Loss: 0.0129, Test Accur\\nacy: 0.915\\nEpoch 5, Loss: 0.013, Accuracy: 0.917, Test Loss: 0.0127, Test Accura\\ncy: 0.916\\nEpoch 6, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0126, Test Accur\\nacy: 0.917\\nEpoch 7, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0125, Test Accur\\nacy: 0.918\\nEpoch 8, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0124, Test Accur\\nacy: 0.919\\nEpoch 9, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur\\nacy: 0.919\\nEpoch 10, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122,Test Accur\\nacy: 0.92\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 171, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 172\\n5.6.4 简单 MNIST 数据集分类模型-keras 高级封装\\n给大家介绍了没有使用高级封装的程序以后，下面要给大家介绍一下使用 tf.keras高级封\\n装的MNIST 数据集分类程序，如代码5-7 所示。\\n代码5-7：MNIST 数据集分类模型-keras高级封装\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n# 训练集数据x_train 的数据形状为（60000，28，28）\\n# 训练集标签y_train 的数据形状为（60000）\\n# 测试集数据x_test的数据形状为（10000，28，28）\\n# 测试集标签y_test的数据形状为（10000）\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\n# 先用Flatten 把数据从3 维变成2 维，(60000,28,28)->(60000,784)\\n# 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# sgd 定义随机梯度下降法优化器\\n# loss='mse'定义均方差代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\nsgd = SGD(0.1)\\nmodel.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n# 周期大小为10（把所有训练集数据训练一次称为训练一个周期）\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 172, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 173\\n# validation_data设置验证集数据\\nmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n程序的输出结果为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/10\\n60000/60000 [==============================] - 2s 34us/sample - los\\ns: 0.0374 - accuracy: 0.7822 - val_loss: 0.0214 - val_accuracy: 0.880\\n2\\nEpoch 2/10\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0203 - accuracy: 0.8816 - val_loss: 0.0175 - val_accuracy: 0.897\\n8\\nEpoch 3/10\\n60000/60000 [==============================] - 2s 32us/sample - los\\ns: 0.0177 - accuracy: 0.8932 - val_loss: 0.0160 - val_accuracy: 0.904\\n1\\nEpoch 4/10\\n60000/60000 [==============================] - 2s 31us/sample - los\\ns: 0.0165 - accuracy: 0.8994 - val_loss: 0.0151 - val_accuracy: 0.907\\n0\\nEpoch 5/10\\n60000/60000 [==============================] - 2s 31us/sample - los\\ns: 0.0157 - accuracy: 0.9031 - val_loss: 0.0145 - val_accuracy: 0.910\\n7\\nEpoch 6/10\\n60000/60000 [==============================] - 2s 32us/sample - los\\ns: 0.0151 - accuracy: 0.9063 - val_loss: 0.0140 - val_accuracy: 0.913\\n1\\nEpoch 7/10\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.0147 - accuracy: 0.9090 - val_loss: 0.0137 - val_accuracy: 0.914\\n5\\nEpoch 8/10\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.0143 - accuracy: 0.9112 - val_loss: 0.0134 - val_accuracy: 0.915\\n8\\nEpoch 9/10\\n60000/60000 [==============================] - 2s 34us/sample - los\\ns: 0.0140 - accuracy: 0.9122 - val_loss: 0.0132 - val_accuracy: 0.917\\n6\\nEpoch 10/10\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 173, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 174\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.0138 - accuracy: 0.9137 - val_loss: 0.0131 - val_accuracy: 0.918\\n4\\n对比看来，使用了 tf.keras 高级封装的程序更简洁，同时也更容易理解，并且程序运行时\\n的结果输出也更友好。我们在程序运行时可以实时看到模型训练一共要训练多少个周期，当前\\n训练到第几个周期，当前周期的进度条，训练当前周期的剩余时间，当前训练集的准确率和 loss。\\n训练完一个周期之后可以看到训练一个周期所花费的时间，如果设置了验证集，可以看到验证\\n集的准确率和loss。这些信息都是默认输出的，当然我们也可以把fit 方法中的参数verbose设\\n置为0，让模型训练过程中不输出任何信息。不过推荐大家还是保持默认值berbose=1，毕竟\\n看到这些输出信息更有利于我们了解模型的训练情况。\\n最后模型的测试集准确率大约是92%左右，并不是特别高。\\n如何可以进一步提升模型的效果，我们将在下一个章节介绍。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 174, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 175\\n第 6 章-网络优化方法\\n本章节内容我们将学习神经网络的一些优化方法，包括使用交叉熵代价函数，抵抗过拟\\n合的几种方法和使用不同的模型优化器。这些模型优化方法有些可以比较有效的提升模型收\\n敛速度或模型的效果，有些只是有可能提升模型的效果。所以我们在选择使用不同的网络优\\n化方法的时候，还是需要根据实际的测试情况来进行选择。\\n6.1 交叉熵代价函数\\n我们在读高中的时候，每天都会做大量的练习，很多课后作业。但是很多题目我们做错以\\n后，下次再见到这个题目的时候已经不记得了，所以会再次做错同样的题目。因为做错普通的\\n课后作业练习题并不能引起我们的重视，所以印象不深刻。\\n如果是老师让我们单独上讲台做题目的话，每次遇到这种情况我们都会比较紧张，因为全\\n班同学，包括我们的暗恋对象都在看着我们。如果在这个时候，我们把题目给做错了，那就丢\\n人丢大了。而被我们做错的那个题目，也会让我们格外印象深刻，下次遇到这个题目的时候就\\n不容易犯错了。\\n也就是说我们在犯了更大的错误以后，往往会学到更多东西，进步更快。理想的情况下，\\n我们也希望神经网络可以从错误中快速学习，最好是错误越大，学习越快，因此均方差代价函\\n数通常用在回归任务中，分类任务中我们会使用交叉熵（Cross Entropy）作为代价函数。\\n6.1.1 均方差代价函数的缺点\\n我们先来重新思考一下均方差代价函数。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 175, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 176\\n先看一个小例子，假如有一个简单的神经网络，它只有一个权值 w和偏置b，一个输入 x\\n和一个输出y，激活函数为sigmoid函数，如图 6.1 所示。\\n图6.1 单输入单输出的简单神经网络\\n我们要训练这个网络做一个简单的事情，给定 x，w和b的值，可以计算出网络输出值\\ny，已知网络的目标值t，然后用梯度下降法来优化网络的参数w和b，使得网络的loss值\\n不断减小。这里我们先把代价函数定义为之前我们学过的均方差代价函数：\\nP\\n1 1\\n𝐸 = (𝑇 − 𝑌)# = ?(𝑡 − 𝑦 )# (6.1)\\n( (\\n2𝑁 2𝑁\\n(A\"\\n第一次试验，x的值为1，w的初始值设置为0.6，b的初始值设置为0.9，目标值t的\\n值为0，使用梯度下降法学习率 0.15，训练 300 周期，网络的初始参数如图6.2 所示。\\n图 6.2 试验一初始状态\\n实验一训练了300 周期后的状态如图6.3 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 176, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 177\\n图6.3 试验一训练 300 次之后的状态\\n实验一loss的变化如图6.4 所示。\\n图 6.4 试验一loss变化\\n第二次试验，x的值为1，w的初始值设置为1.85，b的初始值设置为1.85，目标值t\\n的值为0，使用梯度下降法学习率 0.15，训练300 周期，网络的初始参数如图6.5 所示。\\n图 6.5 试验二初始状态\\n试验二训练了300 周期后的状态如图6.6 所示。\\n图6.6 试验二训练 300 次之后的状态\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 177, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 178\\n实验二loss的变化如图6.7 所示。\\n图 6.7 试验二loss变化\\n观察实验一和试验二我们会发现试验结果和我们理想的结果不同，我们理想的学习效果\\n应该是误差越大，学习得越快。\\n从两个试验的loss曲线我们能看到它们不同的学习速度。实验一的初始输出为0.82，距\\n离目标值0 的误差相对比较小，但是初始学习速度比较快。实验二的初始输出为 0.99，距离\\n目标值0 的误差相对比较大，但是初始学习速度比较慢。这个现象不仅仅是在这个小实验\\n中，也会在其他的神经网络应用中出现。我们想进一步理解这个现象，就要分析一下它的代\\n价函数。当N=1 时，二次代价函数为\\n1\\n𝐸 = (𝑦 − 𝑡)# (6.2)\\n2\\n其中E为代价函数，t为目标输出，y 为神经网络的输出。因为激活函数为sigmoid函数，\\n符号为𝜎，所以𝑦 = 𝜎(𝑧)，𝑧 = 𝑤𝑥 +𝑏。使用链式法则来求权重和偏置的偏导数可以得到：\\n𝜕𝐸\\n= (𝑦 − 𝑡)𝜎R(𝑧)𝑥 (6.3)\\n𝜕𝑤\\n𝜕𝐸\\n= (𝑦 − 𝑡)𝜎R(𝑧) (6.4)\\n𝜕𝑏\\n把x=1 以及t=0 带入公式6.3 和公式6.4，可以得到：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 178, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 179\\n𝜕𝐸\\n= 𝑦𝜎R(𝑧) (6.5)\\n𝜕𝑤\\n𝜕𝐸\\n= 𝑦𝜎R(𝑧) (6.6)\\n𝜕𝑏\\n从公式6.5 和公式6.6 我们可以看出，权值和偏置值的调整是跟激活函数的导数成正比\\n的，我们可以回忆一下sigmoid函数的图像，如图6.8 所示。\\n图6.8 sigmoid函数图像\\n从图中我们可以看出，当神经元的输出接近 1 和0 的时候，曲线变得非常平，也就意味\\n着在输出接近1 和0 的位置函数的导数接近于0。函数的导数接近于0，那么公式6.5 和6.6\\n的值就接近于0，其实就是代表网络的参数调节的速度非常慢，网络的优化速度非常慢。\\nsigmoid函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1−𝑓(𝑥)]，实验一的初始输出为0.82，初始导数\\n为0.1476。实验二的初始输出为0.99，初始导数为0.0099。所以实验一中网络权值的初始\\n调节速度要比实验二中网络权值的初始调节速度快。但是违反了我们误差越大，应该学习越\\n快的直觉。\\n6.1.2 引入交叉熵代价函数\\n我们换一个思路，不改变激活函数而是改变代价函数，改用交叉熵代价函数：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 179, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 180\\nP\\n1\\n𝐸 = − ?[𝑡 𝑙𝑛𝑦 + (1 − 𝑡 )ln (1 − 𝑦 )] (6.7)\\n( ( ( (\\n𝑁\\n(A\"\\n其中N是训练数据的总数，y 是网络的预测值，t是网络的目标值。\\n首先我们先观察一下这个函数的特性：\\n1. 当我们使用sigmoid激活函数的时候，y 的取值范围是0-1 之间，t的取值为\\n0 或1，所以代价函数的值是非负的。\\n2. 当目标值t=0 时，预测值y 越接近于0，代价函数的值E越小，E的最小值为\\n0；当目标值t=0 时，预测值 y 越接近于1，代价函数的值E越大，E的最大值为+∞。\\n3. 当目标值t=1 时，预测值y 越接近于1，代价函数的值E越小，E的最小值为\\n0；当目标值t=1 时，预测值 y 越接近于0，代价函数的值E越大，E的最大值为+∞。\\n综上所述，交叉熵的值是非负的，并且网络的预测值越接近于目标值，则交叉熵的值就越\\n小，这些都是我们想要的代价函数的特性。均方差代价函数其实也是具备这些特性的。\\n接下来我们对交叉熵求w的偏导数，当N=1 时有：\\n𝜕𝐸 𝑡 (1 − 𝑡 ) 𝜕𝜎\\n( (\\n= −¶ − •\\n𝜕𝑤 𝜎(𝑧) 1 − 𝜎(𝑧) 𝜕𝑤\\n(cid:129) ( ( (cid:129)\\n𝑡 (1 − 𝑡)\\n= −¶ − •𝜎R(𝑧)𝑥\\n𝜎(𝑧) 1 − 𝜎(𝑧) (cid:129)\\n𝜎R(𝑧)𝑥\\n(cid:129)\\n= ¶ •(𝜎(𝑧) − 𝑡) (6.8)\\n𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\nSigmoid函数的导数为：\\n𝜎R(𝑧) = 𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143) (6.9)\\n所以：\\n𝜕𝐸\\n= 𝑥 ( 𝜎(𝑧) − 𝑡)\\n(cid:129)\\n𝜕𝑤\\n(cid:129)\\n= 𝑥 ( 𝑦 − 𝑡) (6.10)\\n(cid:129)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 180, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 181\\n这是一个非常优美的公式，我们可以看出权重的学习速度是跟 y-t 成正比的。y-t 就是网\\n络的误差值，误差越大，网络的学习速度越快，这正是我们想要的。sigmoid函数与交叉熵配\\n合使用可以加快网络收敛的速度。\\n6.1.3 交叉熵代价函数推导过程\\n以权值b为例，推导交叉熵代价函数，对E求b的偏导数有：\\n𝜕𝐸 𝜕𝐸 𝜕𝑦 𝜕𝑧\\n= ∙ ∙\\n𝜕𝑏 𝜕𝑦 𝜕𝑧 𝜕𝑏\\n𝜕𝐸 𝜕(𝑤𝑥 + 𝑏)\\n= ∙ 𝜎R(𝑧) ∙\\n𝜕𝑦 𝜕𝑏\\n𝜕𝐸\\n= 𝜎R(𝑧)\\n𝜕𝑦\\n𝜕𝐸\\n= 𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n𝜕𝑦\\n𝜕𝐸\\n= 𝑦(1 − 𝑦) (6.11)\\n𝜕𝑦\\n我们希望b对E的导数是跟网络的误差y-t成正比的，因此我们可以让：\\n𝜕𝐸 𝜕𝐸\\n= 𝑦(1 − 𝑦) = 𝑦 − 𝑡 (6.12)\\n𝜕𝑏 𝜕𝑦\\n即：\\n𝜕𝐸 𝑦 − 𝑡 𝑡 1 − 𝑡\\n= = −l − m (6.13)\\n𝜕𝑦 𝑦(1 − 𝑦) 𝑦 1 − 𝑦\\n对等式两侧求积分，可以得到：\\n𝐸 = −[𝑡𝑙𝑛𝑦 + (1 − 𝑡)ln(1 − 𝑦)] (6.14)\\n公式6.14就是前面介绍的交叉熵函数。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 181, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 182\\n6.1.4 Softmax 与对数似然代价函数\\n通过前面的内容我们可以知道 sigmoid 函数配合交叉熵代价函数的使用可以加快网络训\\n练速度，而在处理多分类的任务时，我们经常会使用 softmax 函数作为输出层的激活函数。\\n当我们使用softmax作为输出层的激活函数时，与之匹配的代价为对数似然（Log Likelihood）\\n代价函数。\\nsoftmax函数与对数似然代价函数的组合跟sigmoid函数与交叉熵代价函数的组合类似。\\nsoftmax 函数与对数似然代价函数在处理二分类问题的时候可以简化为 sigmoid 函数与交叉\\n熵代价函数的形式。\\n对数似然代价函数的公式为：\\nP\\n𝐸 = −?𝑡 𝑙𝑜𝑔(𝑦 ) (6.15)\\n( (\\n(A\"\\n其中，N表示一共有N个输出神经元，也可以认为是 N个分类，𝑡 表示第i 个输出神经元\\n(\\n的目标值，𝑦 表示第i 个输出神经元预测值，取值范围是0-1 之间。\\n(\\n假设把一个样本输入到网络中，只有一个神经元对应了该样本的正确类别（样本的标签为\\none-hot格式），那么这个神经元输出的概率值越高，则公式6.15 的代价函数的值就越小，反\\n之，代价函数的值就越大。\\nsoftmax的公式为：\\ne„\\n”\\n𝑦 = (6.16)\\n( ∑ 𝑒„ »\\n(cid:129)\\n𝑦 表示输出层第 i 个神经元的输出，𝑧 表示输出层第 i 个神经元的输入，e 表示自然常数，\\n( (\\n∑ 𝑒„ »表示输出层所有神经元的输入之和。\\n(cid:129)\\nsoftmax的求导结果比较特别，需要分为两种情况：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 182, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 183\\nif j=i:\\ne„\\n”\\n𝜕l m\\n𝜕𝑦 ∑ 𝑒„ »\\n( (cid:129)\\n=\\n𝜕𝑧 𝜕𝑧\\n(cid:129) (cid:129)\\ne„ ” ∙ ∑ 𝑒„ » − e„ ” ∙ e„ ”\\n(cid:129)\\n=\\n#\\n(cid:142)∑ 𝑒„ »(cid:143)\\n(cid:129)\\ne„ e„ e„\\n” ” ”\\n= − ∙\\n∑ 𝑒„ » ∑ 𝑒„ » ∑ 𝑒„ »\\n(cid:129) (cid:129) (cid:129)\\n= 𝑦 (1 − 𝑦 ) (6.17)\\n( (\\nif j≠i:\\ne„\\n”\\n𝜕l m\\n𝜕𝑦 ∑ 𝑒„ »\\n( (cid:129)\\n=\\n𝜕𝑧 𝜕𝑧\\n(cid:129) (cid:129)\\n0 ∙ ∑ 𝑒„ » − e„ » ∙ e„ ”\\n(cid:129)\\n=\\n#\\n(cid:142)∑ 𝑒„ »(cid:143)\\n(cid:129)\\ne„ e„\\n» ”\\n= − ∙\\n∑ 𝑒„ » ∑ 𝑒„ »\\n(cid:129) (cid:129)\\n= −𝑦 𝑦 (6.18)\\n(cid:129) (\\n接下来我们对对数似然代价函数求 w的偏导数：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 183, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 184\\n𝜕𝐸 𝜕𝐸 𝜕𝑧\\n(cid:129)\\n= ∙\\n𝜕𝑤 𝜕𝑧 𝜕𝑤\\n(cid:129) (cid:129) (cid:129)\\n𝜕(cid:142)∑P 𝑡 log (𝑦 )(cid:143) 𝜕(𝑤 𝑥 + 𝑏 )\\n(A\" ( ( (cid:129) (cid:129) (cid:129)\\n= ∙\\n𝜕𝑧 𝜕𝑤\\n(cid:129) (cid:129)\\nP\\n1 𝜕𝑦\\n(\\n= −𝑥 ?𝑡\\n(cid:129) (\\n𝑦 𝜕𝑧\\n( (cid:129)\\n(A\"\\nP\\n1 𝜕𝑦 1 𝜕𝑦\\n(cid:129) (\\n= −𝑥 (cid:139)𝑡 + ?𝑡 (cid:140)\\n(cid:129) (cid:129) (\\n𝑦 𝜕𝑧 𝑦 𝜕𝑧\\n(cid:129) (cid:129) ( (cid:129)\\n(¿(cid:129)\\n(cid:142)应用𝑠𝑜𝑓𝑡𝑚𝑎𝑥的导数(cid:143)\\nP\\n1 1\\n= −𝑥 (cid:148)𝑡 𝑦 (cid:142)1 − 𝑦 (cid:143) + ?𝑡 (cid:142)−𝑦 𝑦 (cid:143)(cid:149)\\n(cid:129) (cid:129) (cid:129) (cid:129) ( (cid:129) (\\n𝑦 𝑦\\n(cid:129) (\\n(¿(cid:129)\\nP\\n= −𝑥 (cid:139)𝑡 − 𝑡 𝑦 − ?𝑡 𝑦 (cid:140)\\n(cid:129) (cid:129) (cid:129) (cid:129) ( (cid:129)\\n(¿(cid:129)\\nP\\n= −𝑥 >𝑡 − 𝑦 ?𝑡 B = 𝑥 (cid:142)𝑦 − 𝑡 (cid:143) (6.19)\\n(cid:129) (cid:129) (cid:129) ( (cid:129) (cid:129) (cid:129)\\n(A\"\\n公式 6.19 最后的∑P 𝑡 表示所以输出的目标值累加，一般我们会把目标值转成 one-hot\\n(A\" (\\n的数据格式，所以∑P 𝑡 的值为 1。从对数似然代价函数的梯度公式我们也能看出，网络权值\\n(A\" (\\n的调整是跟网络的误差相关的，误差越大则网络训练速度越快，跟交叉熵代价函数有类似的结\\n果。\\n6.1.5 交叉熵程序\\n简单MNIST 数据集分类模型-交叉熵的代码如代码6-1 所示。\\n代码6-1：简单MNIST 数据集分类模型-交叉熵（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 184, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 185\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n# 训练集数据x_train 的数据形状为（60000，28，28）\\n# 训练集标签y_train 的数据形状为（60000）\\n# 测试集数据x_test的数据形状为（10000，28，28）\\n# 测试集标签y_test的数据形状为（10000）\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\n# 先用Flatten 把数据从3 维变成2 维，(60000,28,28)->(60000,784)\\n# 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可\\nmodel1 = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 在定义一个一模一样的模型用于对比测试\\nmodel2 = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# sgd 定义随机梯度下降法优化器，学习率0.1\\n# loss='mse'定义均方差代价函数\\n# loss='categorical_crossentropy'定义交叉熵代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\n# model1用均方差代价函数，model2用交叉熵代价函数\\nsgd = SGD(0.1)\\nmodel1.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\nmodel2.compile(optimizer=sgd,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n# 周期大小为8（把所有训练集数据训练一次称为训练一个周期）\\nepochs = 8\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 185, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 186\\nbatch_size=32\\n# validation_data设置验证集数据\\n# 先训练model1\\nhistory1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n# 再训练model2\\nhistory2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/8\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.0515 - accuracy: 0.6711 - val_loss: 0.0295 - val_accuracy: 0.853\\n0\\nEpoch 2/8\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0260 - accuracy: 0.8587 - val_loss: 0.0218 - val_accuracy: 0.881\\n9\\n……\\nEpoch 8/8\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0162 - accuracy: 0.9020 - val_loss: 0.0150 - val_accuracy: 0.909\\n1\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/8\\n60000/60000 [==============================] - 2s 35us/sample - los\\ns: 0.4165 - accuracy: 0.8858 - val_loss: 0.3117 - val_accuracy: 0.912\\n4\\nEpoch 2/8\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.3144 - accuracy: 0.9114 - val_loss: 0.2916 - val_accuracy: 0.918\\n7\\n…...\\nEpoch 8/8\\n60000/60000 [==============================] - 2s 32us/sample - los\\ns: 0.2713 - accuracy: 0.9244 - val_loss: 0.2736 - val_accuracy: 0.923\\n3\\n代码6-1：简单MNIST 数据集分类模型-交叉熵（片段2）\\n# 画出model1验证集准确率曲线图\\nplt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='mean_squared_error'\\n)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 186, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 187\\n# 画出model2验证集准确率曲线图\\nplt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='softmax_cross_entro\\npy')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n结果输出为：\\nhistory1.history和history2.history保存着mode1 和model2 训练过程中每个训练周\\n期的训练集准确率和训练集loss以及验证集准确率和验证集loss。例如通过：\\nhistory1.history['accuracy']可以获得model1 的训练集准确率\\nhistory1.history['loss']可以获得 model1 的训练集loss\\nhistory1.history['val_accuracy']可以获得model1 的验证集准确率\\nhistory1.history['val_loss']可以获得 model1 的验证集loss\\n从输出结果的图中我们可以看出使用交叉熵代价函数来训练模型可以使得模型的收敛速\\n度更快，更少的训练次数和更少的训练时间就可以使得模型得到更好的效果。所以在分类模\\n型中我们通常都是使用交叉熵代价函数。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 187, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 188\\n6.2 过拟合（Over-Fitting）\\n6.2.1 什么是过拟合\\n拟合可以分为三种情况，欠拟合（Under-Fitting），正确拟合（Right-Fitting）以及过拟\\n合（Over-Fitting）。过拟合在机器学习和深度学习中经常会出现，简单说来其实就是我们所构\\n建的模型在训练集中表现非常好，但是在测试集中表现得不够好。\\n图6.9 表示的是回归问题中的欠拟合，正确拟合以及过拟合的情况。我们使用相同的训练\\n集和不同的模型来做训练，第一幅图使用比较简单的模型，第二幅图使用合适的模型，第三幅\\n图使用比较复杂的模型。\\n图6.9 回归中的三种拟合情况\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 188, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 189\\n在图6.9 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n第二幅图的拟合效果比较好，并且回归线比较平滑，模型属于正确拟合；第三幅图拟合的效\\n果非常好，预测的回归线与真实的训练样本数据分布的误差几乎为 0。假如我们把同样的模\\n型应用到测试集中来做测试，如图6.10 所示。\\n图6.10 把回归模型应用于测试集\\n图6.10 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n的表现就不是特别好。\\n在分类的任务中也有类似的情况。图 6.11 表示的是分类问题中的欠拟合，正确拟合以及\\n过拟合的情况。我们使用相同的训练集和不同的模型来做训练，第一幅图使用比较简单的模型，\\n第二幅图使用合适的模型，第三幅图使用比较复杂的模型：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 189, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 190\\n图6.11 分类中的三种拟合情况\\n在图6.11 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n第二幅图的拟合效果比较好，并且分类边界比较平滑，模型属于正确拟合；第三幅图拟合的\\n效果非常好，分类的误差几乎为0。假如我们把同样的模型应用到测试集中来做测试，如图\\n6.12 所示。\\n图6.12 把分类模型应用于测试集\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 190, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 191\\n图6.12 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n的表现就不是特别好。\\n模型的复杂度与模型误差的关系如图 6.13 所示。\\n图6.13 模型复杂度与模型误差的关系\\n模型复杂度在深度学习中主要指的是网络的层数以及每层网络神经元的各种，网络的层\\n数越多越复杂，神经元的个数越多越复杂。从图 6.13 中我们可以看到，训练集的误差是随着\\n模型复杂度的提升而不断降低的，测试集的误差是随着模型复杂度的提升而先下降后上升。\\n训练集误差和测试集误差的曲线左端欠拟合的状态，训练误差和测试误差都比较高；中间部\\n分是正确拟合的状态，训练误差和测试误差都比较低；右边部分是过拟合的状态，巡逻误差\\n比较低，测试误差比较高。\\n6.2.2 抵抗过拟合的方法\\n常见的抵抗过拟合的方法有：增大数据集，提前停止(Early-Stopping)，Dropout，正则\\n化等，标签平滑(label Smoothing)等。\\n这几种方法我们单独拿出来放在后面的小节中讲解。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 191, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 192\\n6.3 数据增强（Data Augmentation）\\n数据增强就是增加数据量，数据对于机器学习或者深度学习来说非常重要，有时候拥有更\\n多的数据胜过拥有一个好的模型。一般来说更多的数据参与训练，训练得到的模型就更好。如\\n果数据太少，而我们构建的神经网络又太复杂的话就比较容易产生过拟合的现象。\\n例如在图像领域，数据增加的手段经常被使用，我们可以通过对图片进行一些调整来生成\\n更多图片，常用的手段如下：\\n1. 旋转 | 反射变换(Rotation/reflection): 随机旋转图像一定角度; 改变图像内\\n容的朝向。\\n2. 翻转变换(flip): 沿着水平或者垂直方向翻转图像。\\n3. 缩放变换(zoom): 按照一定的比例放大或者缩小图像。\\n4. 平移变换(shift): 在图像平面上对图像以一定方式进行平移。\\n5. 尺度变换(scale): 对图像按照指定的尺度因子, 进行放大或缩小。\\n6. 对比度变换(contrast): 在图像的 HSV 颜色空间，改变饱和度 S 和 V 亮度分\\n量，保持色调 H 不变. 对每个像素的 S 和 V 分量进行指数运算(指数因子在 0.25 到 4\\n之间), 增加光照变化。\\n7. 噪声扰动(noise): 对图像的每个像素 RGB 进行随机扰动, 常用的噪声模式是\\n椒盐噪声和高斯噪声。\\n8. 颜色变换(color): 对训练集图像的颜色进行一些有规律的调整。\\n比如水平翻转，如图6.14所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 192, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 193\\n图6.14 水平翻转\\n比如旋转一定角度，然后再随机裁剪，如图 6.15 所示。\\n图6.15 旋转裁剪\\n比如调整图像的颜色，如图6.16 所示。\\n图6.16 颜色变换\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 193, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 194\\nTensorflow中有封装好的程序可以非常方便的帮助我们实现图像数据增强的功能，如代\\n码6-2 所示。\\n代码6-2：图像数据增强\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load\\n_img\\nimport numpy as np\\ndatagen = ImageDataGenerator(\\nrotation_range = 40, # 随机旋转度数\\nwidth_shift_range = 0.2, # 随机水平平移\\nheight_shift_range = 0.2,# 随机竖直平移\\nrescale = 1/255, # 数据归一化\\nshear_range = 30, # 随机错切变换\\nzoom_range = 0.2, # 随机放大\\nhorizontal_flip = True, # 水平翻转\\nbrightness_range = (0.7,1.3), # 亮度变化\\nfill_mode = 'nearest', # 填充方式\\n)\\n# 载入图片\\nimg = load_img('image.jpg')\\n# 把图片变成array，此时数据是3 维\\n# 3 维(height,width,channel)\\nx = img_to_array(img)\\n# 在第0 个位置增加一个维度\\n# 我们需要把数据变成4 维，然后再做数据增强\\n# 4 维(1,height,width,channel)\\nx = np.expand_dims(x,0)\\n# 生成20 张图片\\ni = 0\\n# 生成的图片都保存在temp 文件夹中，文件名前缀为new_cat,图片格式为jpeg\\nfor batch in datagen.flow(x, batch_size=1, save_to_dir='temp', save_prefix='new_cat', save\\n_format='jpeg'):\\ni += 1\\nif i==20:\\nbreak\\n使用1 张原始图片，程序运行后在 temp文件夹中产生了20 张差异较大的图片，如图\\n6.17 所示。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 194, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 195\\n图6.17 图像数据增强\\n6.4 提前停止训练（Early-Stopping）\\nEarly-Stopping 是一种提前结束训练的策略用来防止过拟合。\\n在训练模型的时候，我们往往会设置一个比较大的迭代次数n。一般的做法是记录到目前\\n为止最好的测试集准确率 p，之后连续 m 个周期没有超过最佳测试集准确率 p 时，则可以认\\n为p不再提高了，此时便可以提前停止迭代(Early-Stopping)。代码6-3 是在代码5-7 的基础\\n上进行修改得到，加上了Early-Stopping 的功能。\\n代码6-3：简单MNIST 数据集分类模型- Early_Stoppping\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n# 训练集数据x_train 的数据形状为（60000，28，28）\\n# 训练集标签y_train 的数据形状为（60000）\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 195, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 196\\n# 测试集数据x_test的数据形状为（10000，28，28）\\n# 测试集标签y_test的数据形状为（10000）\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\n# 先用Flatten 把数据从3 维变成2 维，(60000,28,28)->(60000,784)\\n# 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# sgd 定义随机梯度下降法优化器\\n# loss='mse'定义均方差代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\nsgd = SGD(0.5)\\nmodel.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# EarlyStopping是Callbacks的一种，callbacks用于指定在每个epoch 或batch 开始和结\\n束的时候进行哪种特定操作\\n# monitor='val_accuracy',监控验证集准确率\\n# patience=5,连续 5 个周期没有超过最高的 val_accuracy值，则提前停止训练\\n# verbose=1，停止训练时提示early stopping\\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\\n# 传入训练集数据和标签训练模型\\n# 周期大小为100（把所有训练集数据训练一次称为训练一个周期）\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\n# validation_data设置验证集数据\\n# callbacks=[early_stopping]设置early_stopping\\nmodel.fit(x_train, y_train,\\nepochs=100,\\nbatch_size=32,\\nvalidation_data=(x_test,y_test),\\ncallbacks=[early_stopping])\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 196, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 197\\nEpoch 1/100\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.0267 - accuracy: 0.8420 - val_loss: 0.0167 - val_accuracy: 0.899\\n9\\nEpoch 2/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0164 - accuracy: 0.8993 - val_loss: 0.0145 - val_accuracy: 0.909\\n5\\nEpoch 3/100\\n……\\nEpoch 30/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0108 - accuracy: 0.9329 - val_loss: 0.0111 - val_accuracy: 0.929\\n3\\nEpoch 31/100\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0108 - accuracy: 0.9330 - val_loss: 0.0111 - val_accuracy: 0.929\\n9\\nEpoch 32/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0107 - accuracy: 0.9332 - val_loss: 0.0110 - val_accuracy: 0.929\\n5\\nEpoch 33/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.929\\n9\\nEpoch 34/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0107 - accuracy: 0.9344 - val_loss: 0.0110 - val_accuracy: 0.929\\n6\\nEpoch 35/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0106 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.928\\n6\\nEpoch 36/100\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0106 - accuracy: 0.9347 - val_loss: 0.0110 - val_accuracy: 0.929\\n9\\nEpoch 00036: early stopping\\n虽然我们设置了让模型训练100 个周期，不过在训练到第31 周期时模型得到了一个 val\\n_accuracy 为0.9299。之后连续5 个周期模型的 val_accuracy都没有超过第31 周期的val_\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 197, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 198\\naccuracy值。我们可以认为继续训练模型可能也不会得到更好的结果了，反而可能会出现过\\n拟合的情况，所以就让模型提前停止训练了。\\n6.5 Dropout\\n6.5.1 Dropout 介绍\\nDropout 也是一种用于抵抗过拟合的技术，它试图改变网络本身来对网络进行优化。我\\n们先来了解一下它的工作机制，当我们训练一个普通的神经网络时，网络的结构可能如图6.18\\n所示。\\n图 6.18 普通的神经网络[1]\\nDropout通常是在神经网络隐藏层的部分使用，使用的时候会临时关闭掉一部分的神经\\n元，我们可以通过一个参数来控制神经元被关闭的概率，网络结构如图 6.19 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 198, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 199\\n图6.19 使用Dropout的神经网络[1]\\n更详细的流程如下：\\n1. 在模型训练阶段我们可以先给 Dropout 参数设置一个值，例如 0.4。意思是\\n大约60%的神经元是工作的，大约 40%神经元是不工作的。\\n2. 给需要进行Dropout的神经网络层的每一个神经元生成一个0-1的随机数(一\\n般是对隐藏层进行Dropout)。如果神经元的随机数小于 0.6，那么该神经元就设置为\\n工作状态的；如果神经元的随机数大于等于0.6，那么该神经元就设置为不工作的，不\\n工作状态的意思就是不参与计算和训练，可以当这个神经元不存在。\\n3. 设置好一部分神经元工作一部分神经元不工作之后，我们会发现神经网络的输\\n出值会发现变化，如图6.18中，如果隐藏层有一半不工作，那么网络输出值就会比原\\n来的值要小，因为计算 WX+b 时，如果 W 矩阵中，有一部分的值变成 0，那么最后\\n的计算结果肯定会变小。所以为了使用 Dropout的网络层神经元信号的总和不会发生\\n太大的变化，对于工作的神经元的输出信号还需要除以 0.4。\\n4. 训练阶段重复1-3 步骤，每一次都随机选择部分的神经元参与训练。\\n5. 在测试阶段所有的神经元都参与计算。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 199, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 200\\nDropout 为什么会起作用呢？这个问题很难通过数学推导来证明。我们在介绍 ReLU 激\\n活函数的时候有提到过神经网络的信号是冗余的，神经网络在做预测时并不需要隐藏层所有神\\n经元都工作，只需要一部分隐藏层神经元工作即可。我们可以抽象地来理解 Dropout，当我们\\n使用 Dropout 的时候，就有点像我们在训练很多不同的结构更简单的神经网络，最后测试阶\\n段再综合所有的网络结构得到结果。或者另外一种理解方式是我们使用 Dropout 的时候减少\\n了神经元之间的相互关联，同时强制网络使用更少的特征来做预测，可以增加模型的健壮性。\\n除了这两种理解方式之外还可以有其他的很多理解方式，深度学习中很多技巧都是不能用\\n数学推导得到同时又比较难理解的。但重要的是这些技巧在实际应用中可以帮助我们得到更好\\n的结果。\\nDropout 比较适合应用于只有少量数据但是需要训练复杂模型的场景，这类场景在图像\\n领域比较常见，所以Dropout经常用于图像领域。\\n6.5.2 Dropout 程序\\n这部分我们将看到一个Dropout在MNIST 数据集识别中的应用，如代码6-4 所示。\\n代码6-4：MNIST 数据集分类模型-Dropout（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\\nfrom tensorflow.keras.optimizers import SGD\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 200, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 201\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义，model1使用Dropout\\n# Dropout(0.4)表示隐藏层40%神经元不工作\\nmodel1 = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDropout(0.4),\\nDense(units=100,activation='tanh'),\\nDropout(0.4),\\nDense(units=10,activation='softmax')\\n])\\n# 在定义一个一模一样的模型用于对比测试，model2不使用Dropout\\n# Dropout(0)表示隐藏层所有神经元都工作，相当于没有Dropout\\nmodel2 = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDropout(0),\\nDense(units=100,activation='tanh'),\\nDropout(0),\\nDense(units=10,activation='softmax')\\n])\\n# sgd 定义随机梯度下降法优化器\\n# loss='categorical_crossentropy'定义交叉熵代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\nsgd = SGD(0.2)\\nmodel1.compile(optimizer=sgd,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nmodel2.compile(optimizer=sgd,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n# 周期大小为30（把所有训练集数据训练一次称为训练一个周期）\\nepochs = 30\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\nbatch_size=32\\n# validation_data设置验证集数据\\n# 先训练model1\\nhistory1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 201, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 202\\n# 再训练model2\\nhistory2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n60000/60000 [==============================] - 4s 62us/sample - los\\ns: 0.4170 - accuracy: 0.8737 - val_loss: 0.2087 - val_accuracy: 0.937\\n0\\nEpoch 2/30\\n60000/60000 [==============================] - 3s 54us/sample - los\\ns: 0.2808 - accuracy: 0.9165 - val_loss: 0.1627 - val_accuracy: 0.949\\n8\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 3s 52us/sample - los\\ns: 0.1006 - accuracy: 0.9689 - val_loss: 0.0824 - val_accuracy: 0.977\\n3\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n60000/60000 [==============================] - 3s 54us/sample - los\\ns: 0.2552 - accuracy: 0.9234 - val_loss: 0.1505 - val_accuracy: 0.954\\n2\\nEpoch 2/30\\n60000/60000 [==============================] - 3s 51us/sample - los\\ns: 0.1163 - accuracy: 0.9642 - val_loss: 0.1073 - val_accuracy: 0.966\\n4\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 3s 57us/sample - los\\ns: 4.9737e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy:\\n0.9818\\n代码6-4：MNIST 数据集分类模型-Dropout（片段2）\\n# 画出model1验证集准确率曲线图\\nplt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Dropout')\\n# 画出model2验证集准确率曲线图\\nplt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 202, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 203\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n结果输出为：\\n模型训练结果前 1-30 周期是使用了 Dropout 的结果，后面的 1-30 周期是没有使用\\nDropout的结果。观察结果我们发现使用了 Dropout之后训练集准确率和验证集的准确率相\\n差并不是很大，所以能看出 Dropout 确实是可以起到抵抗过拟合的作用。我们还可以发现一\\n个有趣的现象就是前1-30 周期model1 的验证集准确率还高于训练集的准确率，这是因为模\\n型在计算训练集准确率的时候模型还在使用 Dropout，在计算验证集准确率的时候已经不使\\n用 Dropout 了。使用 Dropout 的时候模型的准确率会稍微降低一些。同时我们也可以发现，\\n不用Dropout的model2 中测试集的准确率看起来比使用Dropout的model1 要更高。\\n事实上使用 Dropout 之后模型的收敛速度会变慢一些，所以需要更多的训练次数才能得\\n到最好的结果。代码 6-3 中不用 Dropout 的 model2 验证集训练 30 个周期最高准确率大概\\n是98.2%左右；使用 Dropout的model1 如果训练足够多的周期，验证集最高准确率可以达\\n到98.8%左右。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 203, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 204\\n6.6 正则化（Regularization）\\n6.6.1 正则化介绍\\n正则化也叫作规范化，通常用得比较多的方式是 L1 正则化和 L2 正则化。L1 和 L2 正则\\n化的使用实际上就是在普通的代价函数（例如均方差代价函数或交叉熵代价函数）后面加上一\\n个正则项，例如加上了L1 正则项的交叉熵为：\\nP\\n1 𝜆\\n𝐸 = − ?[𝑡 𝑙𝑛𝑦 + (1 − 𝑡 )ln (1 − 𝑦 )] + ?|𝑤| (6.20)\\n( ( ( (\\n𝑁 2𝑁\\n(A\" x\\n加上L2 正则项的交叉熵为：\\nP\\n1 𝜆\\n𝐸 = − ?[𝑡 𝑙𝑛𝑦 + (1 − 𝑡 )ln (1 − 𝑦 )] + ?𝑤# (6.21)\\n( ( ( (\\n𝑁 2𝑁\\n(A\" x\\n公式6.21 可以写成：\\n𝜆\\n𝐸 = 𝐸 + ?𝑤# (6.22)\\n<\\n2𝑁\\nx\\n其中E 是原始的代价函数，𝜆是正则项的系数，𝜆是一个大于 0 的数，𝜆的值越大那么正则\\n<\\n项的影响就越大，𝜆的值越小正则项的影响也就越小，当𝜆为0 时，相当于正则项不存在。N表\\n示样本个数。w代表所有的权值参数和偏置值。\\n我们训练模型的过程中实际上就是使用梯度下降法来最小化代价函数的过程，交叉熵代价\\n函数中的t和y 的值越接近，那么代价函数的值就越接近于 0。观察带有正则项的代价函数表\\n达式我们可以知道，最小化代价函数的过程中不仅要使得 t的值接近于y，还要使得神经网络\\n的权值参数w的值趋近于0。因为不管是对于L1正则项 ´ ∑ |𝑤|还是对于L2正则项 ´ ∑ 𝑤#，\\nx x\\n#P #P\\n正则项的值都是大于0 的，所以最小化正则项的值，实际上就是让 w的值接近于0。\\nL1 正则项和L2 正则项的区别在于：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 204, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 205\\nL1 正则项会使得神经网络中的很多权值参数变为0，如果神经网络中很多的权值都是0 的\\n话那么可以认为网络的复杂度降低了，拟合能力也降低了，因此不容易出现过拟合的情况。\\nL2 正则项会使得神经网络的权值衰减，权值参数变为接近于 0 的值，注意这里的接近于 0\\n不是等于零，L2 正则化很少会使权值参数等于 0。L2 正则项之所以有效是因为权值参数w变\\n得很小之后WX+b的计算也是会变成一个接近于0 的值。我们知道在使用sigmoid(x)函数或\\n者tanh(x)函数时，当x的取值在0 附近时，函数的曲线是非常接近于一条直线的，如图6.20\\n所示。\\n图6.20 tanh函数图像\\n所以神经网络中增加了很多线性特征减少了很多非线性的特征，网络的复杂度降低了，因\\n此不容易出现过拟合。\\n6.6.2 正则化程序\\n这部分我们将看到一个正则化在MNIST 数据集识别中的应用，如代码6-5 所示。\\n代码6-5：MNIST 手写数字识别-正则化（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\\nfrom tensorflow.keras.optimizers import SGD\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 205, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 206\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 使用l1 或l2 正则化\\nfrom tensorflow.keras.regularizers import l1,l2\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义，model1使用l2 正则化\\n# l2(0.0003)表示使用l2 正则化，正则化系数为0.0003\\nmodel1 = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh',kernel_regularizer=l2(0.0003)),\\nDense(units=100,activation='tanh',kernel_regularizer=l2(0.0003)),\\nDense(units=10,activation='softmax',kernel_regularizer=l2(0.0003))\\n])\\n# 在定义一个一模一样的模型用于对比测试，model2不使用正则化\\nmodel2 = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDense(units=100,activation='tanh'),\\nDense(units=10,activation='softmax')\\n])\\n# sgd 定义随机梯度下降法优化器\\n# loss='categorical_crossentropy'定义交叉熵代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\nsgd = SGD(0.2)\\nmodel1.compile(optimizer=sgd,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nmodel2.compile(optimizer=sgd,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 206, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 207\\n# 周期大小为30（把所有训练集数据训练一次称为训练一个周期）\\nepochs = 30\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\nbatch_size=32\\n# 先训练model1\\nhistory1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n# 再训练model2\\nhistory2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n60000/60000 [==============================] - 4s 69us/sample - los\\ns: 0.4083 - accuracy: 0.9208 - val_loss: 0.2928 - val_accuracy: 0.952\\n5\\nEpoch 2/30\\n60000/60000 [==============================] - 4s 59us/sample - los\\ns: 0.2626 - accuracy: 0.9601 - val_loss: 0.2285 - val_accuracy: 0.966\\n2\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 4s 60us/sample - los\\ns: 0.1380 - accuracy: 0.9835 - val_loss: 0.1492 - val_accuracy: 0.979\\n6\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n60000/60000 [==============================] - 3s 56us/sample - los\\ns: 0.2563 - accuracy: 0.9222 - val_loss: 0.1415 - val_accuracy: 0.956\\n8\\nEpoch 2/30\\n60000/60000 [==============================] - 3s 53us/sample - los\\ns: 0.1178 - accuracy: 0.9634 - val_loss: 0.1115 - val_accuracy: 0.965\\n7\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 3s 49us/sample - los\\ns: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy:\\n0.9817\\n代码6-5：MNIST 手写数字识别-正则化（片段2）\\n# 画出model1验证集准确率曲线图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 207, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 208\\nplt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='L2 Regularization')\\n# 画出model2验证集准确率曲线图\\nplt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n结果输出为：\\n前1-30 周期是使用l2 正则化的model1 的结果，后1-30 周期是不使用正则化的mod\\nel2 的结果。从结果上看，使用正则化后 model1 的训练集准确率和验证集准确率相差不\\n大，说明正则化确实是可以起到抵抗过拟合的作用。但是使用正则化之后验证集准确率的结\\n果并不是非常理想，说明正则化并不是适用于所有场景。在神经网络结构比较复杂，训练数\\n据量比较少的时候，使用正则化效果会比较好。如果网络不算太复杂的话，任务比较简单的\\n时候，使用正则化可能准确率反而会下降。对于 Dropout来说也有类似的情况。所以 Drop\\nout和正则化需要根据实际使用情况的好坏来决定是否使用。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 208, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 209\\n6.7 标签平滑（Label Smoothing）\\n6.7.1 标签平滑(Label Smoothing)介绍\\n标签平滑（label smoothing）也称为标签平滑正则化（label-smoothing regularization），\\n简称LSR。从名字就可以看出标签平滑也是一种正则化策略。\\n我们在做分类模型的时候通常会把标签变成独热编码（one-hot），但是 变 成 独 热编 码的\\n标签在模型训练时会使得模型变得“极度自信”，容易产生过拟合。独热编码（one-hot）可能\\n存在的问题我给大家举个例子大家就容易理解了，如图 6.21 所示是我写的一个数字。\\n图6.21 一个数字\\n这个数字你能说它100%就是6 吗，不一定吧，它也有点像2，说不定还是1 或者7 只不\\n过手滑了。所以让模型非常自信的认为图中的数字就是 6，独热编码(0,0,0,0,0,0,1,0,0,0)，不\\n一定是合适的。可能把它的标签改成(0,0.02,0.2,0.01,0.01,0.01,0.7,0.03,0.01,0.01)会比较好\\n一点。\\n在MNIST 数据集里面实际上确实有一些数字会写得比较奇怪，让人也很难分辨，其它数\\n据集也会有类似的问题，所以让模型“过度自信”就不一定是好事了。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 209, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 210\\n标签平滑的处理方式很简单，给大家举一个具体的例子大家就知道了。我们需要设置一个\\n平滑系数，比如0.1，假设一共有10 个种类。某个数据的真实标签为：\\n(0,0,0,0,0,1,0,0,0,0)\\n经过标签平滑处理以后的标签为：\\n(0.01,0.01,0.01,0.01,0.01,0.91,0.01,0.01,0.01,0.01)\\n也就类似于下面程序，label_smoothing为平滑系数：\\nnew_onehot_labels = onehot_labels * (1 - label_smoothing)\\n+ label_smoothing / num_classes\\n6.7.2 标签平滑（Label Smoothing）程序\\n实现MNIST 手写数字识别-标签平滑的代码如代码6-6 所示。\\n代码6-6：MNIST 手写数字识别-标签平滑（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.losses import CategoricalCrossentropy\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义，model1不用label smoothing\\nmodel1 = Sequential([\\nFlatten(input_shape=(28, 28)),\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 210, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 211\\nDense(units=200,activation='tanh'),\\nDense(units=100,activation='tanh'),\\nDense(units=10,activation='softmax')\\n])\\n# 在定义一个一模一样的模型用于对比测试，model2使用label smoothing\\nmodel2 = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDense(units=100,activation='tanh'),\\nDense(units=10,activation='softmax')\\n])\\n# model1不用label smoothing\\nloss1 = CategoricalCrossentropy(label_smoothing=0)\\n# model2使用label smoothing\\nloss2 = CategoricalCrossentropy(label_smoothing=0.1)\\n# sgd 定义随机梯度下降法优化器\\n# loss定义交叉熵代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\nsgd = SGD(0.2)\\nmodel1.compile(optimizer=sgd,\\nloss=loss1,\\nmetrics=['accuracy'])\\nmodel2.compile(optimizer=sgd,\\nloss=loss2,\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n# 周期大小为30（把所有训练集数据训练一次称为训练一个周期）\\nepochs = 30\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\nbatch_size=32\\n# 先训练model1\\nhistory1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n# 再训练model2\\nhistory2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 211, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 212\\n60000/60000 [==============================] - 4s 62us/sample - los\\ns: 0.2526 - accuracy: 0.9235 - val_loss: 0.1460 - val_accuracy: 0.957\\n1\\nEpoch 2/30\\n60000/60000 [==============================] - 3s 51us/sample - los\\ns: 0.1139 - accuracy: 0.9659 - val_loss: 0.0915 - val_accuracy: 0.970\\n0\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 3s 50us/sample - los\\ns: 4.9963e-04 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy:\\n0.9816\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/30\\n60000/60000 [==============================] - 3s 54us/sample - los\\ns: 0.7274 - accuracy: 0.9243 - val_loss: 0.6323 - val_accuracy: 0.957\\n2\\nEpoch 2/30\\n60000/60000 [==============================] - 3s 51us/sample - los\\ns: 0.6139 - accuracy: 0.9663 - val_loss: 0.6093 - val_accuracy: 0.965\\n4\\n……\\nEpoch 30/30\\n60000/60000 [==============================] - 3s 51us/sample - los\\ns: 0.5127 - accuracy: 0.9996 - val_loss: 0.5527 - val_accuracy: 0.981\\n7\\n代码6-6：MNIST 手写数字识别-标签平滑（片段2）\\n# 画出model1验证集准确率曲线图\\nplt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='without LSR')\\n# 画出model2验证集准确率曲线图\\nplt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='LSR')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 212, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 213\\n从结果看来使用标签平滑label_smoothing(LSR)后结果稍微好一点点的，不过不太明显。\\n其实标签平滑 label_smoothing 作为一个优化策略也并不是每次都能使结果更好，不过它有\\n机会可以让结果更好，所以有时候也值得我们尝试用一下。\\n6.8 优化器（Optimizer）\\n目前在tf.keras.optimizers中有下面这些优化器可以使用：\\nAdadelta\\nAdagrad\\nAdam\\nAdamax\\nFtrl\\nNadam\\nRMSprop\\nSGD\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 213, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 214\\n优化器的种类很多，在 Keras中只包含了部分常用的优化器，不是全部。之前我们经常使\\n用的优化器是随机梯度下降法（SGD），使用SGD算法来最小化代价函数。其实其他的一些优\\n化器的基础也是梯度下降法，只不过分别做了一些不同的调整或优化。\\n下面我们选几种常用的优化器来重点介绍。\\n6.8.1 梯度下降法 SGD\\n梯度下降法有三种常见的变形，BGD,SGD,MBGD。我们通常把梯度下降法称为随机梯度\\n下降法SGD，但是梯度下降法通常的用的是MBGD 算法。\\nBGD是Batch gradient descent，表示每次训练都采用整个训练集数据来优化模型。BGD\\n的优点是每次训练都考虑所有的样本，所以模型优化的方向会比较正确；缺点是每次训练都需\\n要计算大量的数据，所以模型训练的速度比较慢。\\nSGD是Stochastic gradient descent，表示每次训练都选择训练集中的一个样本来优化\\n模型。SGD 的优点是每次只计算一个样本，权值调整速度比较快；缺点是每次只考虑了一个\\n样本，所以模型优化的方向很可能是错误的。\\nMBGD 是 Mini-batch gradient descent，表示每次训练都选择训练集中一个批次的数\\n据来优化模型，这里的一个批次常用的取值是 32，64 等，当然如果取其他的数值也可以。\\nMBGD 相当于是结合了 BGD 和 SGD 两者的优点，采用一个小批次的数据量来训练模型，这\\n样训练的速度比较快，同时模型优化的方向也比较正确。所以目前带有小批次的训练方法是最\\n主流的训练方法。一般我们提到梯度下降法，或者随机梯度下降法 SGD 的时候，默认就是使\\n用MBGD 的方法。\\n梯度下降法的公式为：\\n𝑊 = 𝑊 − 𝜂𝛻 𝑓(𝑊 ) (6.23)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 214, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 215\\n其中 t 表示第 t 时刻，𝜂表示学习率，𝛻 𝑓(𝑊 )表示 t-1 时刻对代价函数 f 求 W 的导数。\\nx ˆ(cid:127)\"\\n6.8.2 Momentum\\nMomentum是模拟物理中动量的概念，积累之前的动量来替代真正的梯度。\\nMomentum的公式为：\\n𝑉 = 𝛾𝑉 + 𝜂𝛻 𝑓(𝑊 ) (6.24)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\n𝑊 = 𝑊 − 𝑉 (6.25)\\nˆ ˆ(cid:127)\" ˆ\\n𝛾为动力项，通常设置为 0.9。当前权值的改变会受到上一次权值改变的影响，类似于小球\\n向下滚动的时候带上了惯性。这样可以加快小球的向下的速度，同时可以抑制小球振荡。\\n6.8.3 NAG(Nesterov Accelerated Gradient)\\nNAG的公式为：\\n𝑉 = 𝛾𝑉 + 𝜂𝛻 𝑓(𝑊 − 𝛾𝑉 ) (6.26)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\" ˆ(cid:127)\"\\n𝑊 = 𝑊 − 𝑉 (6.27)\\nˆ ˆ(cid:127)\" ˆ\\n𝛾为动力项，通常设置为 0.9。𝑊 −𝛾𝑉 用来近似代价函数下一步的值，则计算的梯度\\nˆ(cid:127)\" ˆ(cid:127)\"\\n不是当前位置的梯度，而是下一个位置的梯度。NAG 相当于是一个预先知道正确方向的更聪\\n明的小球。\\nMomentum和NAG都是为了使得梯度更新更加灵活，不过学习率的设置仍然是一个问\\n题，下面介绍的几种优化器针对学习率的问题做出优化，具有自适应学习率的能力。\\n6.8.4 Adagrad\\nAdagrad的公式为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 215, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 216\\n𝐺 = 𝐺 + 𝛻 𝑓(𝑊 )# (6.28)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\n𝜂\\n𝑊 = 𝑊 − ∙ 𝛻 𝑓(𝑊 ) (6.29)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\ng𝐺 + 𝜀\\nˆ(cid:127)\"\\nε的作用是避免分母为 0，取值一般是10(cid:127)(cid:201)。Adagrad 其实是对学习率进行了一个约束。\\nAdagrad 主要的优势是人为设定一个学习率后，这个学习率可以自动调节。它的缺点在于，\\n随着迭代次数的增多，学习率也会越来越低，最终会趋向于 0。\\n6.8.5 Adadelta\\nAdadelta的公式为：\\n𝐺 = 𝛾𝐺 + (1 − 𝛾)𝛻 𝑓(𝑊 )# (6.29)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\n𝐸 = 𝛾𝐸 + (1 − 𝛾)(∆𝑊 )# (6.30)\\nˆ ˆ(cid:127)\" ˆ\\ng𝐸 + 𝜀\\nˆ(cid:127)\"\\n∆𝑊 = − 𝛻 𝑓(𝑊 ) (6.31)\\nˆ x ˆ\\ng𝐺 + 𝜀\\nˆ\\n𝑊 = 𝑊 + ∆𝑊 (6.32)\\nˆ ˆ(cid:127)\" ˆ(cid:127)\"\\n𝛾通常取 0.9，Adadelta 算是对 Adagrad 的改进，此时 Adadelta 已经不用依赖于全局\\n学习率了。\\n6.8.6 RMRprop\\nRMSprop可以算作Adadelta的一个特例，RMSprop的公式为：\\n𝐺 = 𝛾𝐺 + (1 − 𝛾)𝛻 𝑓(𝑊 )# (6.33)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\n𝜂\\n𝑊 = 𝑊 − ∙ 𝛻 𝑓(𝑊 ) (6.34)\\nˆ ˆ(cid:127)\" x ˆ(cid:127)\"\\ng𝐺 + 𝜀\\nˆ(cid:127)\"\\n𝛾通常取 0.9，RMSprop 依然依赖于全局学习率，RMSprop 也算是 Adagrad 的一种发\\n展。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 216, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 217\\n6.8.7 Adam\\nAdam(Adaptive Moment Estimation)本质上是带有动量项的 RMSprop，Adam 的公\\n式为：\\n𝑚 = 𝛽 𝑚 + (1 − 𝛽 )𝛻 𝑓(𝑊 ) (6.35)\\nˆ \" ˆ(cid:127)\" \" x ˆ\\n𝑣 = 𝛽 𝑣 + (1 − 𝛽 )𝛻 𝑓(𝑊 )# (6.36)\\nˆ # ˆ(cid:127)\" # x ˆ\\n𝑚\\nˆ\\n𝑚(cid:204) = (6.37)\\nˆ 1 − 𝛽ˆ\\n\"\\n𝑣\\nˆ\\n𝑣˝ = (6.38)\\nˆ 1 − 𝛽ˆ\\n#\\n𝑚(cid:204)\\nˆ\\n𝑊 = 𝑊 − 𝜂 (6.39)\\nˆ ˆ(cid:127)\"\\ng 𝑣˝ + 𝜀\\nˆ\\n𝛽 通常取 0.9, 𝛽 通常取 0.999。其中𝑚 ，𝑣 分别是对梯度的一阶矩估计和二阶矩估计，\\n\" # ˆ ˆ\\n可以看作对期望𝐸|𝛻 𝑓(𝑊 )|，𝐸˛𝛻 𝑓(𝑊 )2˛的估计； 𝑚(cid:204) ， 𝑣˝ 是对𝑚 ，𝑣 的校正，这样可以近\\n𝑤 𝑡 𝑤 𝑡 ˆ ˆ ˆ ˆ\\n似为对期望的无偏估计。Adam大多数情况下效果都比较好，所以目前用得最多的优化器就是\\nAdam。Adam与其他一些优化器在训练MNIST 数据集时的对比，如图6.22 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 217, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 218\\n图6.22 Adam与其他优化器对比[2]\\n从图 6.22 中我们能看出来，在使用多层神经网络训练 MNIST 数据集时，Adam 的优化\\n速度是最快的。\\n6.8.8 优化器程序\\n如代码 6-7 所示，这里给出一个使用 Adam 优化器的例子，如果想使用其他优化器也类\\n似，调用tensorflow.keras.optimizers 里面的优化器即可。\\n代码6-7：MNIST 数据集分类模型-优化器（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD,Adam\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\nmodel1 = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 在定义一个一模一样的模型用于对比测试\\nmodel2 = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 定义sgd 优化器，学习率0.1\\nsgd = SGD(0.1)\\n# 定义Adam优化器，学习率0.001,Adam优化器学习率通常较低\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 218, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 219\\nadam = Adam(0.001)\\n# loss='mse'定义均方差代价函数\\n# metrics=['accuracy']模型在训练的过程中同时计算准确率\\n# model1用Adam优化器，model2用sgd 优化器\\nmodel1.compile(optimizer=adam,\\nloss='mse',\\nmetrics=['accuracy'])\\nmodel2.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n# 周期大小为6（把所有训练集数据训练一次称为训练一个周期）\\nepochs = 6\\n# 批次大小为32（每次训练模型传入32 个数据进行训练）\\nbatch_size=32\\n# validation_data设置验证集数据\\n# 先训练model1\\nhistory1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n# 再训练model2\\nhistory2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da\\nta=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/6\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.0196 - accuracy: 0.8819 - val_loss: 0.0131 - val_accuracy: 0.917\\n5\\nEpoch 2/6\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0129 - accuracy: 0.9182 - val_loss: 0.0118 - val_accuracy: 0.924\\n1\\n……\\nEpoch 6/6\\n60000/60000 [==============================] - 2s 31us/sample - los\\ns: 0.0107 - accuracy: 0.9327 - val_loss: 0.0109 - val_accuracy: 0.931\\n6\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/6\\n60000/60000 [==============================] - 3s 47us/sample - los\\ns: 0.0499 - accuracy: 0.6986 - val_loss: 0.0285 - val_accuracy: 0.852\\n1\\nEpoch 2/6\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 219, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 220\\n60000/60000 [==============================] - 2s 29us/sample - los\\ns: 0.0257 - accuracy: 0.8583 - val_loss: 0.0216 - val_accuracy: 0.878\\n9\\n……\\nEpoch 6/6\\n60000/60000 [==============================] - 2s 34us/sample - los\\ns: 0.0173 - accuracy: 0.8953 - val_loss: 0.0160 - val_accuracy: 0.903\\n3\\n代码6-7：MNIST 数据集分类模型-优化器（片段2）\\n# 画出model1验证集准确率曲线图\\nplt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Adam')\\n# 画出model2验证集准确率曲线图\\nplt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='SGD')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n结果输出为：\\n从结果对比我们可以看到使用 Adam 优化器之后模型的收敛速度加快了很多，最后得到\\n了更好的训练效果。\\n这一章节我们学习了很多模型优化方法，使用这些模型优化方法把模型训练好以后我们还\\n需要把模型保存下来。如何保存模型将是我们下一章节要介绍的内容。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 220, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 221\\n6.9 参考文献\\n[1] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural\\nnetworks from overfitting[J]. The journal of machine learning research, 2014, 15(1):\\n1929-1958.\\n[2] Kingma D P, Ba J. Adam: A method for stochastic optimization[J]. arXiv preprint\\narXiv:1412.6980, 2014.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 221, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 222\\n第 7 章-Tensorflow 模型的保存和载入\\n在Tensorflow1.0 中模型的保存和载入通常有两种方式，一种是 Checkpoint的方式，\\n还有一种是Protocol buffer的方式，这两种方式都有各自的一些特点。\\n——Checkpoint保存的模型通常以“.ckpt”结尾，保存后会得到4 个文件，如图7.1\\n中的4 个文件.\\n图7.1 Tensorflow 模型文件\\nCheckpoint是一个文本文件，记录了训练过程中保存的模型的名称，首行记录的是最\\n后（最近）一次保存的模型名称。\\n.data文件保存的是模型的变量值。\\n.index文件保存的是.data文件中的数据跟.meta文件中的结构之间的对应关系\\n.meta文件以“protocol buffer”格式保存了整个模型的结构图，模型上定义的操作等\\n信息。\\n——Protocol buffer 的方式是把模型的参数转换为常量后进行保存，同时还会保存模型\\n的结构，保存的模型通常以“.pb”结尾，只会得到一个文件。\\n由于在Tensorflow2 中很多时候我们都是使用Tensorflow.keras来搭建和训练模型，所\\n以模型的保存一般也是使用Tensorflow.keras的方式。Tensorflow1.0 中所使用的\\nCheckpoint模型保存方式在Tensorflow2 中有时也会用到。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 222, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 223\\n7.1 Keras 模型保存和载入\\n7.1.1 Keras 保存模型\\n使用Keras保存模型操作很简单，如模型为model，可以使用：\\nmodel.save('path_to_my_model.h5')\\n来保存模型，'path_to_my_model'为模型保存路径，'h5'为HDF5 文件格式。使用\\nmodel.save来保存模型，可以把模型的结构，权值参数和优化器设置，代价函数设置，\\nmetrics设置全部保存下来。Keras模型保存参考代码如代码 7-1 所示。\\n代码7-1：Keras模型保存\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 定义优化器，代价函数\\nsgd = SGD(0.2)\\nmodel.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\nmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 223, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 224\\n# 保存模型\\nmodel.save('my_model/mnist.h5')\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/5\\n60000/60000 [==============================] - 2s 35us/sample - los\\ns: 0.0379 - accuracy: 0.7752 - val_loss: 0.0214 - val_accuracy: 0.880\\n8\\n……\\nEpoch 5/5\\n60000/60000 [==============================] - 2s 31us/sample - los\\ns: 0.0156 - accuracy: 0.9043 - val_loss: 0.0145 - val_accuracy: 0.909\\n8\\n模型训练好之后会生成一个h5 模型文件保存在'my_model/mnist.h5'。\\n7.1.2 Keras 载入模型\\n使用Keras载入模型操作也很简单，可以使用：\\ntensorflow.keras.models.load_model('path_to_my_model.h5')\\n来载入模型，'path_to_my_model'为模型所在路径。Keras模型载入参考代码如代码\\n7-2 所示。\\n代码7-2：Keras模型载入\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import load_model\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 载入模型\\nmodel = load_model('my_model/mnist.h5')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 224, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 225\\n# 再训练5 个周期模型\\nmodel.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/5\\n60000/60000 [==============================] - 2s 34us/sample - los\\ns: 0.0150 - accuracy: 0.9073 - val_loss: 0.0141 - val_accuracy: 0.913\\n7\\n……\\nEpoch 5/5\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0137 - accuracy: 0.9139 - val_loss: 0.0130 - val_accuracy: 0.918\\n0\\n从输出结果可以看到模型是在已经训练了 5 个周期的基础上继续训练的。并且使用\\nmodel.save保存模型的时候，不仅保存的模型的结构和权值参数，还保存了模型的优化\\n器，代价函数，metrics这些设置。所以在载入模型之后，我们不需要设置优化器，代价函\\n数和metrics，就可以直接使用fit对模型进行训练。\\n7.2 SavedModel 模型保存和载入\\n7.2.1 SavedModel 保存模型\\nSavedModel是Tensorflow中一种模型格式，SavedModel的优点是与语言无关，比\\n如可以用时python训练模型，然后在Jave中非常方便的加载模型。SavedModel中包含了\\n计算图和网络的权值，一个SavedModel模型包含以下内容：\\nassets/\\nsaved_model.pb\\nvariables/\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 225, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 226\\nvariables.data-00000-of-00001\\nvariables.index\\n其中saved_model.pb包含计算图结构，variables文件夹保存模型训练得到的权值。\\nassets文件夹一般是空的，可以添加一些可能需要的外部文件。\\n假设程序中训练好的模型为model，那么可以使用：\\nmodel.save('path_to_saved_model')\\n来保存模型，注意这里的'path_to_saved_model'为模型保存的路径，保存后会得到一个\\n文件夹，所以'path_to_saved_model'不需要加后缀。\\nmodel.save 可以保存两种格式的模型。当我们使用 model.save的时候，如果\\n'path_to_saved_model'没有后缀就是保存为SavedModel 格式；如果\\n'path_to_saved_model.h5'有'h5'这个后缀就是保存为Keras的HDF5 格式的模型。\\nSavedModel 保存模型参考代码如代码 7-3 所示。\\n代码7-3：SavedModel 模型保存\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 226, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 227\\n# 定义优化器，代价函数\\nsgd = SGD(0.2)\\nmodel.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\nmodel.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))\\n# 保存模型为SavedModel格式\\nmodel.save('path_to_saved_model')\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/5\\n60000/60000 [==============================] - 2s 37us/sample - los\\ns: 0.0373 - accuracy: 0.7806 - val_loss: 0.0217 - val_accuracy: 0.877\\n6\\n……\\nEpoch 5/5\\n60000/60000 [==============================] - 2s 32us/sample - los\\ns: 0.0156 - accuracy: 0.9038 - val_loss: 0.0145 - val_accuracy: 0.909\\n3\\n7.2.2 SavedModel 载入模型\\nSavedModel 模型的载入也很简单，也是使用：\\ntensorflow.keras.models.load_model('path_to_my_model')\\n来载入就可以了。载入模型以后再次训练的程序基本上跟代码 7-2 一样，如代码7-4 所\\n示。\\n代码7-4：SavedModel 模型载入\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import load_model\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 227, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 228\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 载入SavedModel模型\\nmodel = load_model('path_to_saved_model')\\n# 再训练5 个周期模型\\nmodel.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/5\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.0151 - accuracy: 0.9065 - val_loss: 0.0140 - val_accuracy: 0.913\\n3\\n……\\nEpoch 5/5\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0138 - accuracy: 0.9141 - val_loss: 0.0130 - val_accuracy: 0.917\\n2\\n7.3 单独保存模型结构\\n7.3.1 保存模型结构\\n有些时候，可能我们只对模型的结构感兴趣，只想保存模型的结构，而不保存模型的权\\n值，优化器和代价函数等内容。那么我们可以使用：\\nconfig = model.get_config()\\n来保存模型结构，模型的结构数据是一个 python的字典，使用这个模型结构我们可以\\n重建一个一摸一样的模型，然后重新训练这个模型。\\n另外还有一个保存模型结构的方式是使用：\\njson_config = model.to_json()\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 228, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 229\\n来保存模型结构。这个方法是使用 JSON 格式来保存模型结构。单独保存模型结构参考\\n代码如代码7-5 所示。\\n代码7-5：保存模型结构（片段1）\\nfrom tensorflow.keras import Sequential\\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout\\n# 模型定义\\nmodel = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDropout(0.4),\\nDense(units=100,activation='tanh'),\\nDropout(0.4),\\nDense(units=10,activation='softmax')\\n])\\n# 保存模型结构\\nconfig = model.get_config()\\nprint(config)\\n结果输出为：\\n{'name': 'sequential', 'layers': [{'class_name': 'Flatten', 'config\\n': {'name': 'flatten', 'trainable': True, 'batch_input_shape': (Non\\ne, 28, 28), 'dtype': 'float32', 'data_format': 'channels_last'}}, {'\\nclass_name': 'Dense', 'config': {'name': 'dense', 'trainable': True,\\n'dtype': 'float32', 'units': 200, 'activation': 'tanh', 'use_bias':\\nTrue, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config\\n': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'con\\nfig': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'ac\\ntivity_regularizer': None, 'kernel_constraint': None, 'bias_constrai\\nnt': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout',\\n'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': N\\none, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'den\\nse_1', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activat\\nion': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name':\\n'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'c\\nlass_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bia\\ns_regularizer': None, 'activity_regularizer': None, 'kernel_constrai\\nnt': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'con\\nfig': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', '\\nrate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Den\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 229, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 230\\nse\\', \\'config\\': {\\'name\\': \\'dense_2\\', \\'trainable\\': True, \\'dtype\\': \\'floa\\nt32\\', \\'units\\': 10, \\'activation\\': \\'softmax\\', \\'use_bias\\': True, \\'kerne\\nl_initializer\\': {\\'class_name\\': \\'GlorotUniform\\', \\'config\\': {\\'seed\\': N\\none}}, \\'bias_initializer\\': {\\'class_name\\': \\'Zeros\\', \\'config\\': {}}, \\'k\\nernel_regularizer\\': None, \\'bias_regularizer\\': None, \\'activity_regula\\nrizer\\': None, \\'kernel_constraint\\': None, \\'bias_constraint\\': None}}]}\\n代码7-5：保存模型结构（片段2）\\nimport json\\n# 保存json 模型结构文件\\nwith open(\\'model.json\\',\\'w\\') as m:\\njson.dump(json_config,m)\\nconfig的内容跟json_config 的内容是差不多的，所以这里附上一个输出结果。保存\\njson模型结构文件以后，在本地会得到一个model.json 文件。\\n7.3.2 载入模型结构\\n模型结构保存后，可以使用model_from_json 方法再重新把模型的结构载入，模型结构\\n载入的参考代码如代码7-6 所示。\\n代码7-6：载入模型结构\\nimport tensorflow as tf\\nimport json\\n# 读入json 文件\\nwith open(\\'model.json\\') as m:\\njson_config = json.load(m)\\n# 载入json 模型结构得到模型model\\nmodel = tf.keras.models.model_from_json(json_config)\\n# summary用于查看模型结构\\nmodel.summary()\\n结果输出为：\\nModel: \"sequential\"\\n_________________________________________________________\\nLayer (type) Output Shape Param #\\n=========================================================\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 230, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 231\\nflatten (Flatten) (None, 784) 0\\n_________________________________________________________\\ndense (Dense) (None, 200) 157000\\n_________________________________________________________\\ndropout (Dropout) (None, 200) 0\\n_________________________________________________________\\ndense_1 (Dense) (None, 100) 20100\\n_________________________________________________________\\ndropout_1 (Dropout) (None, 100) 0\\n_________________________________________________________\\ndense_2 (Dense) (None, 10) 1010\\n=========================================================\\nTotal params: 178,110\\nTrainable params: 178,110\\nNon-trainable params: 0\\n_________________________________________________________\\n我们可以看到模型打印出来的结构跟代码 7-5 中定义的结构是一样的。\\nmodel.summary()可以很方便的打印出模型的结构，并可以看到网络每一层的输出shape\\n和需要训练的参数Param，最后还会统计所有需要训练的参数个数。想了解模型结构的时候\\nmodel.summary()可以多使用。\\n7.4 单独保存模型参数\\n7.4.1 保存模型参数\\n有时候我们只对模型的权值参数感兴趣，对模型框架不感兴趣。这个时候我们可以只获取\\n模型的权值参数，我们可以使用：\\nweights = model.get_weights()\\n来获取模型的权值参数，权值保存后会得到一个 list，list 中保存了每一层权值参数的具\\n体数值。获取模型参数以后可以使用：\\nmodel.set_weights(weights)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 231, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 232\\n来对模型进行权值进行重新设置。\\n如果我们想保存模型的参数可以使用：\\nmodel.save_weights('path_to_my_model.h5')\\n来保存模型参数。参考代码如代码 7-7 所示。\\n代码7-7：保存模型参数\\nfrom tensorflow.keras import Sequential\\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout\\nimport numpy as np\\n# 模型定义\\nmodel = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDropout(0.4),\\nDense(units=100,activation='tanh'),\\nDropout(0.4),\\nDense(units=10,activation='softmax')\\n])\\n# 保存模型参数\\nmodel.save_weights('my_model/model_weights')\\n# 获取模型参数\\nweights = model.get_weights()\\n# 把list转变成array\\nweights = np.array(weights)\\n# 循环每一层权值\\n# enumerate相当于循环计数器，记录当前循环次数\\n# weights保存的数据可以对照print输出查看\\nfor i,w in enumerate(weights):\\nif i%2==0:\\nprint('{}:w_shape:{}'.format(int(i/2+1),w.shape))\\nelse:\\nprint('{}:b_shape:{}'.format(int(i/2+0.5),w.shape))\\n结果输出为：\\n1:w_shape:(784, 200)\\n1:b_shape:(200,)\\n2:w_shape:(200, 100)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 232, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 233\\n2:b_shape:(100,)\\n3:w_shape:(100, 10)\\n3:b_shape:(10,)\\n7.4.2 载入模型参数\\n模型的参数载入很简单，使用：\\nmodel.load_weights('path_to_my_model.h5')\\n就可以载入参数。不过要注意，载入模型参数之前需要把模型先定义好，或者使用\\nmodel_from_json 方法先载入模型。并且如果我们想进一步训练模型的参数的话，不仅要定\\n义好模型结构，载入模型参数。还需要定义 compile 中的内容，包括优化器和代价函数等。\\n因为model.save()会保存compile 中的内容，而model.save_weights只会保存模型的参\\n数。所以load_weights以后还需要重新定义compile 的内容，才能进一步训练模型。\\n载入模型参数的参考代码如代码7-8 所示。\\n代码7-8：载入模型参数\\nfrom tensorflow.keras import Sequential\\nfrom tensorflow.keras.layers import Flatten,Dense,Dropou\\n# 载入模型参数前需要先把模型定义好\\n# 模型结构需要与参数匹配\\n# 或者可以使用tf.keras.models.model_from_json 载入模型结构\\nmodel = Sequential([\\nFlatten(input_shape=(28, 28)),\\nDense(units=200,activation='tanh'),\\nDropout(0.4),\\nDense(units=100,activation='tanh'),\\nDropout(0.4),\\nDense(units=10,activation='softmax')\\n])\\n# 载入模型参数\\nmodel.load_weights('my_model/model_weights.h5')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 233, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 234\\n7.5 ModelCheckpoint 自动保存模型\\n在第6 章的抵抗过拟合方法中我们学习了 Early-Stopping，我们在学习Early-Stopping\\n的时候使用了：\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n复习一下，EarlyStopping是Callbacks的一种，callbacks 用于指定在每个epoch 或\\nbatch开始和结束的时候进行哪种特定操作。这个部分我们要学习的ModelCheckpoint 也\\n是Callbacks中的一种，用于自动保存模型。\\n其中参数monitor可以设置{'val_accuracy','val_loss','accuracy','loss'，} 如果设置监测\\n{'val_accuracy','accuracy'}，那么模型准确率大于最大{'val_accuracy','accuracy'}的时候就\\n会保存模型；如果设置监测{'val_loss','loss'}，那么模型loss小于最小{'val_loss','loss'}的时\\n候就会保存模型。ModelCheckpoint 的使用方法和说明参数代码如代码7-9 所示。\\n代码7-9：ModelCheckpoint 自动保存模型\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 234, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 235\\n# 定义优化器，代价函数\\nadam = Adam(0.001)\\nmodel.compile(optimizer=adam,\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\n# 模型保存位置\\noutput_model = 'ModelCheckpoint/'\\n# log 保存位置\\noutput_log = 'log/'\\n# ModelCheckpoint用于自动保存模型\\n# filepath 可以设置模型保存位置以及模型信息，epoch 表示训练周期数，val_accuracy表示\\n验证集准确值\\n# monitor可选{'val_accuracy','val_loss','accuracy','loss'},一般'val_accuracy'用得比较多\\n# verbose=1表示保存模型的时候打印信息\\n# save_best_only=True表示只保存>best_val_accuracy的模型\\n# CSVLogger也是callbacks，用于生成模型训练的log\\ncallbacks = [\\nModelCheckpoint(filepath=output_model+'{epoch:02d}-{val_accuracy:.4f}.h5',\\nmonitor='val_accuracy',\\nverbose=1,\\nsave_best_only=True),\\nCSVLogger(output_log + 'log.csv')\\n]\\n# 传入训练集数据和标签训练模型\\nmodel.fit(x_train, y_train,\\nepochs=6, batch_size=32,\\nvalidation_data=(x_test,y_test),\\ncallbacks=callbacks)\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/6\\n59744/60000 [============================>.] - ETA: 0s - loss: 0.371\\n1 - accuracy: 0.8957 ETA: 0s - loss: 0.3733 - accuracy: 0.89\\nEpoch 00001: val_accuracy improved from -inf to 0.91850, saving model\\nto ModelCheckpoint/01-0.9185.h5\\n60000/60000 [==============================] - 2s 39us/sample - los\\ns: 0.3709 - accuracy: 0.8958 - val_loss: 0.2899 - val_accuracy: 0.918\\n5\\nEpoch 2/6\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 235, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 236\\n59072/60000 [============================>.] - ETA: 0s - loss: 0.287\\n5 - accuracy: 0.9185\\nEpoch 00002: val_accuracy improved from 0.91850 to 0.92120, saving mo\\ndel to ModelCheckpoint/02-0.9212.h5\\n60000/60000 [==============================] - 2s 39us/sample - los\\ns: 0.2874 - accuracy: 0.9185 - val_loss: 0.2792 - val_accuracy: 0.921\\n2\\nEpoch 3/6\\n59872/60000 [============================>.] - ETA: 0s - loss: 0.276\\n5 - accuracy: 0.9224\\nEpoch 00003: val_accuracy improved from 0.92120 to 0.92200, saving mo\\ndel to ModelCheckpoint/03-0.9220.h5\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.2763 - accuracy: 0.9225 - val_loss: 0.2813 - val_accuracy: 0.922\\n0\\nEpoch 4/6\\n58496/60000 [============================>.] - ETA: 0s - loss: 0.270\\n2 - accuracy: 0.9243\\nEpoch 00004: val_accuracy improved from 0.92200 to 0.92630, saving mo\\ndel to ModelCheckpoint/04-0.9263.h5\\n60000/60000 [==============================] - 2s 38us/sample - los\\ns: 0.2701 - accuracy: 0.9243 - val_loss: 0.2696 - val_accuracy: 0.926\\n3\\nEpoch 5/6\\n59936/60000 [============================>.] - ETA: 0s - loss: 0.265\\n8 - accuracy: 0.9261\\nEpoch 00005: val_accuracy did not improve from 0.92630\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.2658 - accuracy: 0.9261 - val_loss: 0.2766 - val_accuracy: 0.925\\n4\\nEpoch 6/6\\n58816/60000 [============================>.] - ETA: 0s - loss: 0.261\\n7 - accuracy: 0.9269\\nEpoch 00006: val_accuracy did not improve from 0.92630\\n60000/60000 [==============================] - 2s 36us/sample - los\\ns: 0.2624 - accuracy: 0.9267 - val_loss: 0.2866 - val_accuracy: 0.921\\n7\\n从输出结果我们就可以看出并不是每一个周期模型都会保存，只有 val_accuracy 大于之\\n前最大的 val_accuracy，模型才会保存。程序训练 6 个周期以后用来保存模型的文件夹得到\\n了4 个模型，如图 7.2 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 236, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 237\\n图7.2 ModelCheckPoint自动保存模型\\n从模型的文件名我们就可以看出模型是训练了多少个周期得到的，并且还可以看出模型\\n的val_accuracy准确率，只有得到越来越大的val_accuracy模型才会保存。训练第5 第6\\n周期的时候，模型的val_accuracy没有超过第4 个周期的0.9263，所以第5 第6 周期的模\\n型没有保存。\\n训练结束之后我们还会得到一个CSV 格式的log文件，log文件中的内容如图7.3 所\\n示。\\n图7.3 模型训练log文件\\n在log文件中包含了模型训练每个周期的训练集准确率，训练集 loss，验证集准确率，\\n验证集loss。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 237, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 238\\n7.6 Checkpoint 模型保存和载入\\n7.6.1 Checkpoint 模型保存\\n在Tensorflow2 中我们也可以使用Checkpoint来保存和载入模型，用法跟\\nTensorflow1 有些区别，具体使用方法可以参考下面的例子，如代码7-10 所示。\\n代码7-10：Checkpoint模型保存\\nimport tensorflow as tf\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 归一化\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 标签转独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 创建dataset对象\\nmnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n# 训练周期\\nmnist_train = mnist_train.repeat(1)\\n# 批次大小\\nmnist_train = mnist_train.batch(32)\\n# 创建dataset对象\\nmnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\n# 训练周期\\nmnist_test = mnist_test.repeat(1)\\n# 批次大小\\nmnist_test = mnist_test.batch(32)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 优化器定义\\noptimizer = tf.keras.optimizers.SGD(0.1)\\n# 训练loss\\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\\n# 训练准确率计算\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 238, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 239\\ntrain_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\\n# 测试loss\\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\\n# 测试准确率计算\\ntest_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\\n# 模型训练\\n@tf.function\\ndef train_step(data, label):\\nwith tf.GradientTape() as tape:\\n# 传入数据预测结果\\npredictions = model(data)\\n# 计算loss\\nloss = tf.keras.losses.MSE(label, predictions)\\n# 计算权值调整\\ngradients = tape.gradient(loss, model.trainable_variables)\\n# 进行权值调整\\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\\n# 计算平均loss\\ntrain_loss(loss)\\n# 计算平均准确率\\ntrain_accuracy(label, predictions)\\n# 模型测试\\n@tf.function\\ndef test_step(data, label):\\n# 传入数据预测结果\\npredictions = model(data)\\n# 计算loss\\nt_loss = tf.keras.losses.MSE(label, predictions)\\n# 计算平均loss\\ntest_loss(t_loss)\\n# 计算平均准确率\\ntest_accuracy(label, predictions)\\n# 定义模型保存，保存优化器和模型参数\\nckpt = tf.train.Checkpoint(optimizer=optimizer, model=model)\\n# 用于管理模型\\n# ckpt为需要保存的内容\\n# 'tf2_ckpts'为模型保存位置\\n# max_to_keep设置最多保留几个模型\\nmanager = tf.train.CheckpointManager(ckpt, 'tf2_ckpts', max_to_keep=3)\\nEPOCHS = 5\\n# 训练5 个周期\\nfor epoch in range(EPOCHS):\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 239, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 240\\n# 循环60000/32=1875次\\nfor image, label in mnist_train:\\n# 训练模型\\ntrain_step(image, label)\\n# 循环10000/32=312.5->313 次\\nfor test_image, test_label in mnist_test:\\n# 测试模型\\ntest_step(test_image, test_label)\\n# 打印结果\\ntemplate = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'\\nprint (template.format(epoch+1,\\ntrain_loss.result(),\\ntrain_accuracy.result(),\\ntest_loss.result(),\\ntest_accuracy.result()))\\n# 保存模型\\n# checkpoint_number设置模型编号\\nmanager.save(checkpoint_number=epoch)\\n结果输出为：\\nEpoch 1, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0125, Test Accur\\nacy: 0.917\\nEpoch 2, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0124, Test Accur\\nacy: 0.918\\nEpoch 3, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0123, Test Accur\\nacy: 0.918\\nEpoch 4, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur\\nacy: 0.919\\nEpoch 5, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122, Test Accur\\nacy: 0.92\\n7.6.2 Checkpoint 模型载入\\n实现Checkpoint模型载入的代码如代码 7-11 所示。\\n代码7-11：Checkpoint模型载入\\nimport tensorflow as tf\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 240, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 241\\n# 归一化\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 标签转独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 创建dataset对象\\nmnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n# 训练周期\\nmnist_train = mnist_train.repeat(1)\\n# 批次大小\\nmnist_train = mnist_train.batch(32)\\n# 创建dataset对象\\nmnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\n# 训练周期\\nmnist_test = mnist_test.repeat(1)\\n# 批次大小\\nmnist_test = mnist_test.batch(32)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28)),\\ntf.keras.layers.Dense(10, activation='softmax')\\n])\\n# 优化器定义\\noptimizer = tf.keras.optimizers.SGD(0.1)\\n# 训练loss\\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\\n# 训练准确率计算\\ntrain_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\\n# 测试loss\\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\\n# 测试准确率计算\\ntest_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\\n# 模型训练\\n@tf.function\\ndef train_step(data, label):\\nwith tf.GradientTape() as tape:\\n# 传入数据预测结果\\npredictions = model(data)\\n# 计算loss\\nloss = tf.keras.losses.MSE(label, predictions)\\n# 计算权值调整\\ngradients = tape.gradient(loss, model.trainable_variables)\\n# 进行权值调整\\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 241, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 242\\n# 计算平均loss\\ntrain_loss(loss)\\n# 计算平均准确率\\ntrain_accuracy(label, predictions)\\n# 模型测试\\n@tf.function\\ndef test_step(data, label):\\n# 传入数据预测结果\\npredictions = model(data)\\n# 计算loss\\nt_loss = tf.keras.losses.MSE(label, predictions)\\n# 计算平均loss\\ntest_loss(t_loss)\\n# 计算平均准确率\\ntest_accuracy(label, predictions)\\n# 定义Checkpoint，用于保存优化器和模型参数\\nckpt = tf.train.Checkpoint(optimizer=optimizer, model=model)\\n# restore 载入Checkpoint\\n# latest_checkpoint表示载入编号最大的Checkpoint\\nckpt.restore(tf.train.latest_checkpoint('tf2_ckpts/'))\\n# 载入模型后继续训练\\nEPOCHS = 5\\n# 训练5 个周期\\nfor epoch in range(EPOCHS):\\n# 循环60000/32=1875次\\nfor image, label in mnist_train:\\n# 训练模型\\ntrain_step(image, label)\\n# 循环10000/32=312.5->313 次\\nfor test_image, test_label in mnist_test:\\n# 测试模型\\ntest_step(test_image, test_label)\\n# 打印结果\\ntemplate = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'\\nprint (template.format(epoch+1,\\ntrain_loss.result(),\\ntrain_accuracy.result(),\\ntest_loss.result(),\\ntest_accuracy.result()))\\n结果输出为：\\nEpoch 1, Loss: 0.0105, Accuracy: 0.934, Test Loss: 0.0116, Test Accur\\nacy: 0.925\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 242, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 243\\nEpoch 2, Loss: 0.0105, Accuracy: 0.935, Test Loss: 0.0116, Test Accur\\nacy: 0.925\\nEpoch 3, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur\\nacy: 0.925\\nEpoch 4, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur\\nacy: 0.925\\nEpoch 5, Loss: 0.0103, Accuracy: 0.936, Test Loss: 0.0116, Test Accur\\nacy: 0.925\\n这一章节我们学习了Tensorflow2 中3 种模型保存的方式，使用tf.keras接口把模型保\\n存为h5 的文件，保存SavedModel 格式的模型以及保存Checkpoint模型。\\n学习完神经网络和Tensorflow 的基础知识，下一章节我们将开始介绍深度学习算法。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 243, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 244\\n第 8 章-卷积神经网络 CNN\\n计算机视觉是人工智能领域最热门的研究领域之一，并且是近几年发展最快的人工智能领\\n域之一。 10 年前的人们一定想象不到如今的计算机视觉可以做到如此优秀的水平，\\nCV(Computer Vision)领域的快速发展主要得益于卷积神经网络的使用。\\n8.1 计算机视觉介绍\\n8.1.1 计算机视觉应用介绍\\n如今计算机视觉的应用已经深入到我们生活中的方方面面，有着许多的实际应用。\\n人脸识别：使用在高铁进站，酒店住宿，公司门禁等场景下，如图 8.1 所示。\\n图8.1 人脸识别\\n图像检索：使用在搜索引擎的图片搜索中，以及电商网站的商品检索等，如图 8.2 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 244, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 245\\n8.2 图像检索\\n监控：使用在公共场所中用于检测行人车辆的流量以及可疑行为等，如图 8.3 所示。\\n图8.3 监控\\n光学字符识别OCR：证件识别，车牌识别，文档识别，银行卡识别，名片识别，身份证识\\n别等，如图8.4 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 245, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 246\\n图8.4 OCR\\n自动驾驶：检测交通标志，路上行人和车辆等，如图 8.5 所示。\\n图8.5 自动驾驶\\n8.1.2 计算机视觉技术介绍\\n计算机视觉包含很多中技术，下面我们简单介绍 5 种计算机视觉的常用技术。\\n1.图像分类：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 246, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 247\\n图像分类就是图像识别，识别一张图片中的物体，然后给出类别判断。一般对一张图片我\\n们可能会得到多个类别判断，我们可以根据类别的置信度（模型认为图片属于该类别的概率）\\n从高到低进行排序，然后得到可能性最大的几个类别，如图 8.6 所示。\\n图8.6 图像分类\\n2.目标检测\\n有时候我们不仅要识别图片是属于什么类别，还需要把它们给框选出来，\\n确定它们在图片中的位置和大小。如图 8.7 所示。\\n图8.7 目标检测[1]\\n3.目标跟踪\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 247, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 248\\n目标跟踪是指在特定场景跟踪某一个或多个特定感兴趣对象的过程，如图 8.6 所示。\\n图8.6 目标跟踪[2]\\n4.语义分割\\n语义分割可以将图像分为不同的语义可解释类别，例如我们可能会把图片中汽车的颜色\\n都用蓝色的表示，所有行人用红色表示。与图像分类或目标检测相比，语义分割可以让我们\\n对图像有更加细致的了解，如图8.7 所示。\\n图8.7 语义分割[3]\\n5.实例分割\\n实例分割可以将不同类型的实例进行分类，比如用 4 种颜色来表示4 辆不同的汽车，用\\n8 种颜色表示8 个不同的人，如图8.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 248, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 249\\n图8.8 实例分割[4]\\n8.2 卷积神经网简介\\n卷积神经网络就是一种包含卷积计算的神经网络。卷积计算是一种计算方式，有一个卷积\\n窗口（Convolution Window）在一个平面上滑动，每次滑动会进行一次卷积计算得到一个\\n数值，卷积窗口滑动计算完成后会得到一个用于表示图像特征的特征图（Feature Map）。下\\n面是一个忽略具体数值计算的卷积计算流程，具体的卷积数值计算在后面的内容再进行详细介\\n绍：用一个3×3 的卷积窗口对4×4 的图片求卷积，卷积的移动步长为1，最后得到2×2 的特\\n征图，如图8.9 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 249, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 250\\n图8.9 卷积计算\\n8.2.1 BP 神经网络存在的问题\\n在前面的章节中我们使用了 BP 神经网络来处理 MNIST 手写数字识别的任务，并且得到\\n了还不错的识别效果。有一个细节问题当时我们可能没有注意到，当时我们使用的手写数字图\\n片是28×28 的黑白图片，输入数据一共有28×28×1 个数据，所以输入层只需要784 个神经\\n元。假如我们有一张 1000×1000 的彩色图片，那么输入层神经元就需要1000×1000×3 个，\\n我们使用带有一个隐藏层的神经网络，隐藏层神经元个数为 1000，那么输入层和隐藏层之间\\n权值的个数就会有30 亿个，这是一个非常巨大的数字。\\n如此大量的权值会带来两个问题，一个问题是计算量巨大，要计算这么多权值就需要花费\\n大量时间。第二个问题是要训练这么多权值就需要大量的训练样本来进行训练，防止模型过拟\\n合。\\n因此我们需要使用卷积神经网络解决计算机视觉任务中权值数量巨大的问题。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 250, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 251\\n8.2.2 局部感受野和权值共享\\n卷积网络跟神经网络一样，也是受到了生物学的启发。 20 世纪 60 年代神经生理学家\\nHubel 和Wiesel通过研究猫的视觉感受野（Receptive field of vision）提出的视觉神经系\\n统的层级结构模型，从简单细胞到复杂细胞、超复杂细胞的层级信息处理结构。他们的研究成\\n果在1981 年获得诺贝尔生理学或医学奖。\\n卷积神经网络的设计借鉴了 Hubel 和 Wiesel 的研究，在卷积网络中使用了局部感受野\\n（Local Receptive Field）。卷积层中的神经元连接不是全连接的，而是后一层的每个神经元\\n连接前一层的一部分神经元。如图 8.10 所示，左边为 BP 网络的全连接结构，右边为卷积网\\n络的局部连接结构。\\n图8.10 全连接和局部连接\\n图中一条连线就是一个权值，如果神经元不是全连接，那么权值就减少了很多。此外卷积\\n神经网络还用到了权值共享（Weight Sharing）。这里的权值共享指的是同一卷积层中的同\\n一个卷积窗口的权值是共享的。使用 3×3 的卷积窗口（也就是后一层的一个神经元连接前一\\n层3×3 的区域）对 1000×1000 的图片求卷积， 那么大家思考一下输入层和卷积层之间一共\\n有多少个权值需要训练？\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 251, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 252\\n现在公布答案，使用3×3 的卷积窗口对1000×1000 的图片求卷积，一共有9 个权值加\\n1 个偏置值需要训练。3×3 的卷积窗口就有9 个权值，1 个卷积窗口还会有1 个偏置值。卷\\n积窗口在进行滑动计算的时候窗口内的 9 个权值是权值共享的，所以一共只有9 个权值。同\\n理，假设使用5×5 的卷积窗口对500×500 的图片求卷积，一共有25 个权值加1 个偏置值\\n训练训练。卷积层的权值数量跟被卷积的图片大小无关，跟卷积步长也无关，跟卷积窗口的\\n大小相关。\\n8.3 卷积的具体计算\\n下面我们来讲解一下卷积的具体计算流程。卷积窗口又称为 卷积核（ Convolution\\nKernel），卷积之后生成的图称为特征图。卷积窗口/卷积核一般都是使用正方形的，比如1×\\n1，3×3，5×5 等，极少数特殊情况才会使用长方形。对一张图片求卷积实际上就是卷积核在\\n图片上面滑动，并进行卷积计算。卷积计算很简单，就是卷积核与图片中对应位置的数值相乘\\n然后再求和。我们可以通过下面的具体例子来理解，假设我们有一个3×3 的卷积核，如图 8.11\\n所示。\\n1 0 1\\n0 1 0\\n1 0 1\\n图8.11 3×3 的卷积核\\n然后我们使用该卷积核，对4×4 的图片求卷积，图片如下，图8.12 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 252, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 253\\n1 1 1 0\\n0 1 1 1\\n0 0 1 1\\n0 0 0 1\\n图8.12 4×4 的图片\\n3×3 的卷积核对 4×4 的图片求卷积，步长为 1，可以分为 4 个步骤，第一步，对左上方\\n9 个数求卷积，如图 8.13 所示。\\n图8.13 卷积第一步\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n卷积第二步如图8.14 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 253, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 254\\n图8.14 卷积第二步\\n具体卷积计算为：1×1+0×1+1×0+0×1+1×1+0×1+1×0+0×1+1×1=3。\\n卷积第三步如图8.15 所示。\\n图8.15 卷积第三步\\n具体卷积计算为：1×0+0×1+1×1+0×0+1×0+0×1+1×0+0×0+1×0=2。\\n卷积第四步如图8.16 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 254, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 255\\n图8.16 卷积第四步\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n卷积的符号一般用“*”表示，上述的卷积计算如图8.17 所示。\\n图8.17 卷积计算\\n8.4 卷积的步长\\n卷积的步长指的是卷积每一次移动的步数，前面我们列举的例子中，卷积的步长为 1，卷\\n积的步长理论上可以取任意正整数。图 8.18 中的例子是步长为2 的卷积.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 255, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 256\\n图8.18 步长为2 的卷积\\n下图8.19 为步长为3 的卷积计算.\\n图8.19 步长为3 的卷积\\n8.5 不同的卷积核\\n使用不同的卷积核来对同一张图片求卷积会得到不同的结果，如图 8.20 和图 8.21 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 256, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 257\\n图8.20 使用不同卷积核求卷积（1）\\n图8.21 使用不同卷积核求卷积（2）\\n所以在卷积神经网络中，我们通常会使用多个不同的卷积核来对同一图像求卷积，目的\\n就是为了可以提取出图像中多种不同的特征。\\n那么卷积核的取值要怎么取？如果是使用传统的机器学习思维，我们能想到的方法可能\\n是人为设计大量不同的卷积核，然后使用大量图片来做测试，最后分析哪种卷积核提取出来\\n的特征比较有效。\\n那在深度学习里面，卷积核中的数值实际上就是卷积核的权值。所以说卷积核的取值在\\n卷积神经网络训练最开始的阶段是随机初始化的，之后结合误差反向传播算法，逐渐训练得\\n到最终的结果。训练好的卷积核就可以作为特征提取器，用于提取图像特征，然后传到网络\\n后面的全连接层，用于分类回归等任务。\\n在同一个卷积核中的权值是共享的，在不同的卷积核中的权值是不共享的。假设使用6\\n个5×5 的卷积核对一幅图像求卷积，会产6×5×5=150 个权值加6 个偏置值，卷积后会得\\n到6 个不同的特征图，如图 8.22 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 257, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 258\\n图8.22 使用多个卷积核计算\\n8.6 池化（Pooling）\\n一个经典的卷积层包含3 部分，卷积计算->非线性激活函数->池化（Pooling），如图8.23\\n所示。\\n图8.23 经典卷积层的3 部分\\n池化也有一个滑动窗口在图像中进行滑动计算，这一点跟卷积有点类似，不过池化层中\\n没有需要训练的权值。\\n我们通常会使用多个不同的卷积核来对图像求卷积，之后生成很多个不同的特征图，卷\\n积网络中的权值参数仍然是很多的。池化的一个作用是可以做进一步的特征提取，减少权值\\n参数的个数。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 258, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 259\\n池化的另一个作用是使得网络的输入具有平移不变形。平移不变形指的是当我们对输入\\n进行少量平移时，经过池化后的数值并不会发生太大变化。这是一个非常有用的性质，因为\\n我们通常关心的是某个特征是否在图像中出现，而不是关心这个特征具体出现的位置。例如\\n我们要判断一张图片中是否有猫，我们并不关心猫是出现在图片上方，还是下方，还是左\\n边，还是右边，我们只关心猫是否出现在图片中，如图 8.24 所示。\\n图8.24 平移不变形\\n不过稍微要注意的是我们对输入进行少量平移时，经过池化后的数值并不会发生太大变化。\\n如果对输入平移太多时，池化后的数值还是会发生较大变化的。\\n池化也有池化窗口，对图像进行扫描计算，这一点跟卷积类似。池化通常可以分为三种方\\n式，最大池化（Max-Pooling），平均池化（Mean-Pooling）和随机池化（ Stochastic\\nPooling）。最大池化指的是提取池化窗口区域内的最大值，平均池化指的是提取池化窗口区\\n域内的平均值，随机池化指的是提取池化窗口区域内的随机值，其中最常用的是最大池化。常\\n用的池化窗口大小为2×2，步长为2。\\n池化窗口大小为2×2，步长为2 的最大池化计算如图8.25 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 259, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 260\\n图8.25 最大池化\\n池化窗口大小为2×2，步长为2 的平均池化计算如图8.26 所示。\\n图8.26 平均池化\\n随机池化就是从池化窗口中随机取一个值，一般用得比较少。\\n8.7 Padding\\n在卷积神经网络中我们通常会堆叠多个卷积层的结构，形成一个深度的卷积神经网络。\\n堆叠多个卷积层结构会碰到一个问题，那就是每一次做卷积，得到的特征图就会比原来的图\\n像要变小一些，这样特征的数量会不断减少。例如使用 3×3 的卷积核对4×4 的图像求卷\\n积，步长为1，卷积后得到一个 2×2 的特征图，如图8.27 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 260, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 261\\n图8.27 卷积后得到的特征图比原图像小\\n另外在计算卷积的时候图像中间的数据会重复使用多次，而图像边缘的数据可能只会被用\\n到一次。图8.28 表示，使用3×3 的卷积核对4×4 的图像求卷积，步长为1。\\n图8.28 边缘数据计算次数较少\\n图 8.28 中四个角的四个数据只计算了一次，而图像中心的四个数据则计算了四次，这就\\n表示卷积容易丢失掉图像的边缘特征（不过其实边缘位置的信息一般来说也没这么重要）。\\n针对上述两个问题，我们可以使用 Padding的方式来解决。卷积和池化操作都可以使用\\nPadding，Padding一般有两种方式，一种是Valid Padding，还有一种是 Same Padding。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 261, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 262\\nValid Padding其实就是不填充。不填充数据那么卷积后得到的特征图就会比原始图像要\\n小一点，如图8.29 所示。\\n图8.29 Valid Padding\\nSame Padding 指的是通过填充数据（一般都是填充 0），使得卷积后的特征图的大小跟\\n原始的图像大小相同，如图8.30 所示。\\n图8.30 Same Padding\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 262, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 263\\n上图中使用3×3 的卷积核对5×5 的图像进行求卷积的操作，步长为1。给原图像外圈填\\n充1 圈0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同，也是5×5 的大小。\\n同理如果使用 5×5 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 2\\n圈0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n如果使用 7×7 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 3 圈 0\\n之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n这也是为什么卷积核经常使用单数×单数，因为我们可以通过填充 0 的方式得到与原始图\\n像大小相同的特征图。\\nSame Padding 还有另外一种理解方式，就是当步长不为 1 的时候，Same Padding 指\\n的是可能会给平面外部补0。下面举两个例子：\\n例1：假如有一个28×28 的图像，用2×2 步长为2 的池化窗口对其进行池化的操作，使\\n用Same Padding的方式，池化后得到 14×14 的特征图；使用 Valid Padding的方式，池化\\n后得到14×14 的特征图。两种 Padding方式得到的结果是相同的。\\n例2：假如有一个2×3 的图像，用2×2 步长为2 的池化窗口对其进行池化的操作，使用\\nSame Padding的方式，池化后得到1×2 的特征图；使用Valid Padding的方式，池化后得\\n到 1×1 的特征图。Same Padding 给原图像补了 0，所以可以进行 2 次池化计算，而 Valid\\nPadding不会给图像补0，所以只能进行1 次池化计算。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 263, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 264\\n8.8 常见的卷积计算总结\\n8.8.1 对 1 张图像进行卷积生成 1 张特征图\\n对 1 张图像进行卷积生成 1 张特征图是最简单的一种卷积方式，前面我们已经进行了详\\n解的举例计算，如图8.31 所示。\\n图8.31 对 1 张图像进行卷积生成1 张特征图\\n假如我们只统计乘法的计算量，图中一种进行了 3×3×4 次乘法计算。总共有 9 个权值和\\n1 个偏置值需要训练。\\n8.8.2 对 1 张图像进行卷积生成多张特征图\\n生成多张特征图需要使用多个不同的卷积核，使用多个不同的卷积核来求卷积。这里我们\\n使用 3 个不同的 5×5 大小的卷积核对 28×28 的图像求卷积，使用 Same Padding 的方式，\\n步长为1，卷积计算后生成 3 个不同的特征图，如图8.32 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 264, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 265\\n图8.32 对1 张图像进行卷积生成多张特征图\\n因为每个卷积核中的权值不同，所以使用 3 个不同的卷积核求卷积会得到 3 个不同的特\\n征图。一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28\\n×28×3=58800。总共有5×5×3=75个权值和3 个偏置值需要训练。偏置值数量主要跟特征\\n图数量相关，每个特征图有1 个偏置值。\\n8.8.3 对多张图像进行卷积生成 1 张特征图\\n比如我们多 1 张彩色图片求卷积，彩色图片可以看成是 RGB三原色的组合，所以可以看\\n成是 3 张图像。这里我们对 3 张 28×28 的图像求卷积，卷积窗口大小为 5×5，使用 Same\\nPadding的方式，步长为1，卷积计算后生成1 张特征图，如图8.33 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 265, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 266\\n图8.33 对多张图像进行卷积生成1 张特征图\\n对3 张图像进行卷积的时候先分别对每张图像进行卷积，得到 3 个大小相同，数值不同\\n的特征图。然后再对每个特征图对应位置的数值进行相加，最后得到 1 个特征图。\\n一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28×\\n28×3=58800。这里要注意，我们对不同图像进行卷积的时候，所使用的卷积核也是不同的，\\n所以总共有5×5×3=75个权值和1 个偏置值需要训练。\\n这里我们把对多张图像进行卷积的多个不同的卷积核称为一个滤波器（Filter），一个滤波\\n器可以产生一个特征图。在我们写程序搭建网络结构的时候，我们需要定义卷积层Filter的数\\n量，实际上就是在定义卷积后生成的特征图的数量。\\n8.8.4 对多张图像进行卷积生成多张特征图\\n对多张图像进行卷积生成多张特征图相对来说最难理解同时也是最常见的情况。在卷积网\\n络中，很多时候都需要对多张图像进行卷积然后生成多张特征图。这里我们使用 128 个滤波\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 266, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 267\\n器对 64 张 28×28 的图像求卷积，使用 Same Padding 的方式，步长为 1，卷积计算后生成\\n128 个不同的特征图。每个滤波器由64 个不同的5×5 卷积核组成，如图8.34 所示。\\n图8.34 对多张图像进行卷积生成多张特征图\\n下面我们来分析一下上面这个例子的计算量和权值数量。1 个滤波器对64 张图像进行卷\\n积，得到1 张特征图。1 个滤波器中有64 个不同的5×5 卷积核。每个5×5 卷积核对1 张图\\n像求卷积。\\n1 个卷积核对 1 张图片求卷积的计算量是5×5×28×28，所以1 个滤波器64 个卷积核的\\n计算量是5×5×28×28×64。一共有128 个不同的滤波器，所以总的计算量是5×5×28×28\\n×64×128=160563200。\\n每个卷积核有5×5 个权值，1 个滤波器有64 个卷积核有5×5×64 个权值，128 个滤波\\n器有5×5×64×128=204800 个权值，加上128 个偏置值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 267, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 268\\n8.9 经典的卷积神经网络\\n前面的内容中我们介绍了很多卷积神经网络相关的知识点，不过大家可能对一个完整的卷\\n积神经网络的结构可能还不太了解。常见的卷积神经网络结构实际上是多个卷积层叠加起来之\\n后再加上全连接层构成的。有些卷积网络有几十层或者几百层，实际上就是因为网络内部的卷\\n积层的数量比较多，如图8.35 所示是一个比较典型卷积网络结构。\\n图8.35 识别猫的卷积神经网络\\n卷积神经网前面的部分进行卷积池化相当于是进行特征提取，后面部分进行全连接相当于\\n是利用提取出来的图像特征进行分类。\\n我们还可以把卷积神经网络应用于 MNIST 手写数字识别，如图8.36 所示。\\n图8.36 卷积神经网络应用于手写数字识别\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 268, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 269\\n为了能让大家看到一目了然的图，我也特地花了一些时间来研究如何画网络结构以及如何\\n表示图中的计算流程，后面的内容中大家还会看到更多类似上图的网络结构图。图中的 s表示\\nstride，s1 代表卷积或池化的步长为 1，s2 代表卷积或池化的步长为 2，以此类推；conv 是\\n卷积（convolution）的缩写；pool 表示最大池化（max pooling），fc 表示全连接（fully\\nconnected）。\\n图中原始的手写数字的图片是一张 28×28 的图片，并且是黑白的，所以图片的通道数是\\n1，输入数据是 28×28×1 的数据，如果是彩色图片，图片的通道数就为3。\\n该网络结构是一个 4 层的卷积神经网络（计算神经网络层数的时候，有权值的才算是一\\n层，比如池化层就不能单独算一层）。第 1 层为卷积层，使用32 个5×5 的卷积核对原始图片\\n求卷积，步长为1，Same Padding。因为是Same Padding并且步长为1，所以卷积后的特\\n征图大小跟原图片一样，可以得到 32 张28×28 的特征图。池化的计算是在卷积层中进行的，\\n使用 2×2，步长为 2 的池化窗口做池化计算，池化后得到 32 张 14×14 的特征图。特征图的\\n长宽都变成了之前的1/2。权值的数量为 5×5×32=800，偏置值数量为 32（1 个特征图会有\\n1 个偏置值）。\\n第 2 层也是卷积层，使用 64 个 5×5 的卷积核对 32 张 14×14 的特征图求卷积，步长为\\n1，Same Padding。因为是Same Padding并且步长为1，所以卷积后的特征图大小跟原图\\n片一样，可以得到 64 张 14×14 的特征图。这里对 32 个特征图求卷积产生出 64 个特征图涉\\n及到前面我们介绍的对多张图像进行卷积生成多张特征图。\\n对多张特征图求卷积，相当于是同时对多张特征图进行特征提取。同一个特征图中权值是\\n共享的，不同的特征图之间权值是不同的。对32 张图像求卷积产生1 个特征图，需要使用32\\n个不同的5×5 的卷积核，那么就会有5×5×32=800 个连接，800 个权值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 269, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 270\\n所以在我们现在看到的这个例子中，第2 个卷积层卷积窗口大小5×5，对32 张图像求卷\\n积产生 64 个特征图，参数个数是 5×5×32×64=51200 个权值加上 64 个偏置（1 个特征图\\n会有1 个偏置值）。\\n池化的计算是在卷积层中进行的，使用 2×2，步长为 2 的池化窗口做池化计算，池化后\\n得到64 张7×7 的特征图。特征图的长宽都变成了之前的 1/2。\\n第3层是全连接层，第2个池化层之后的64×7×7个神经元跟1024个神经元做全连接。\\n第4 层是输出层，输出 10 个预测值，对应0-9 的10 个数字。\\n这个例子中卷积后产生的特征图的个数 32，64 是属于卷积神经网络中的超参数，需要我\\n们自己调节和设置，也可以修改为其他值，一般设置为2 的倍数。特征图数量越多说明卷积网\\n络提取的特征数量越多，如果特征图数量设置得太少容易出现欠拟合，如果特征图数量设置得\\n太多容易出现过拟合，所以需要设置为合适的数值。\\n8.10 卷积神经网络应用于 MNIST 数据集分类\\n实现卷积神经网络应用于MNIST 数据集分类的代码如代码8-1 所示。\\n代码8-1：卷积神经网络应用于MNIST 数据集分类\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\\nfrom tensorflow.keras.optimizers import Adam\\n# 载入数据\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 这里要注意，在tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式\\n# 这4 个维度是(数据数量，图片高度，图片宽度，图片通道数)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 270, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 271\\n# 所以这里把数据reshape变成4 维数据，黑白图片的通道数是 1，彩色图片通道数是3\\nx_train = x_train.reshape(-1,28,28,1)/255.0\\nx_test = x_test.reshape(-1,28,28,1)/255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 定义顺序模型\\nmodel = Sequential()\\n# 第一个卷积层\\n# input_shape 输入数据\\n# filters 滤波器个数32，生成32 张特征图\\n# kernel_size 卷积窗口大小5*5\\n# strides 步长1\\n# padding padding方式 same/valid\\n# activation 激活函数\\nmodel.add(Convolution2D(\\ninput_shape = (28,28,1),\\nfilters = 32,\\nkernel_size = 5,\\nstrides = 1,\\npadding = 'same',\\nactivation = 'relu'\\n))\\n# 第一个池化层\\n# pool_size 池化窗口大小2*2\\n# strides 步长2\\n# padding padding方式 same/valid\\nmodel.add(MaxPooling2D(\\npool_size = 2,\\nstrides = 2,\\npadding = 'same',\\n))\\n# 第二个卷积层\\n# filters 滤波器个数64，生成64 张特征图\\n# kernel_size 卷积窗口大小5*5\\n# strides 步长1\\n# padding padding方式 same/valid\\n# activation 激活函数\\nmodel.add(Convolution2D(64,5,strides=1,padding='same',activation='relu'))\\n# 第二个池化层\\n# pool_size 池化窗口大小2*2\\n# strides 步长2\\n# padding padding方式 same/valid\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 271, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 272\\nmodel.add(MaxPooling2D(2,2,'same'))\\n# 把第二个池化层的输出进行数据扁平化\\n# 相当于把(64,7,7,64)数据->(64,7*7*64)\\nmodel.add(Flatten())\\n# 第一个全连接层\\nmodel.add(Dense(1024,activation = 'relu'))\\n# Dropout\\nmodel.add(Dropout(0.5))\\n# 第二个全连接层\\nmodel.add(Dense(10,activation='softmax'))\\n# 定义优化器\\nadam = Adam(lr=1e-4)\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 训练模型\\nmodel.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test, y_test))\\n# 保存模型\\nmodel.save('mnist.h5')\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/10\\n60000/60000 [==============================] - 73s 1ms/sample - los\\ns: 0.3466 - accuracy: 0.8985 - val_loss: 0.0953 - val_accuracy: 0.970\\n6\\nEpoch 2/10\\n60000/60000 [==============================] - 72s 1ms/sample - los\\ns: 0.0986 - accuracy: 0.9706 - val_loss: 0.0601 - val_accuracy: 0.980\\n4\\n……\\nEpoch 9/10\\n60000/60000 [==============================] - 71s 1ms/sample - los\\ns: 0.0251 - accuracy: 0.9920 - val_loss: 0.0263 - val_accuracy: 0.990\\n9\\nEpoch 10/10\\n60000/60000 [==============================] - 72s 1ms/sample - los\\ns: 0.0222 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.992\\n8\\n使用卷积神经网络之后，MNIST手写数字识别的测试集准确率可以提升到99%以上的高水\\n准。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 272, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 273\\n8.11 识别自己写的数字图片\\n在识别 MNIST 数据集的程序中，我们直接调用了 tensorflow 打包过的数据，而不是一\\n张一张的图片，所以整个流程可能不够直观。我们可以使用MNIST 数据集训练好的模型来识\\n别自己写的数字图片，来检测一下模型的识别效果。\\n我们可以自己找一张白纸，写一个数字，注意数字要写得粗一些，并且写在图片中间的位\\n置，跟MNIST 数据集中的数字类似，如图8.37 所示。\\n图8.37 手写数字6\\n然后通过代码8-2 来完成数字图片的识别.\\n代码8-2：识别自己写的数字图片（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import load_model\\nimport matplotlib.pyplot as plt\\nfrom PIL import Image\\nimport numpy as np\\n# 载入数据\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 获取一张照片，并把它的shape 变成二维（784->28×28）,用灰度图显示\\nplt.imshow(x_train[18],cmap='gray')\\n# 不显示坐标\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 273, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 274\\nplt.axis('off')\\nplt.show()\\n结果输出为：\\n代码8-2：识别自己写的数字图片（片段2）\\n# 载入我自己写的数字图片\\nimg=Image.open('6.jpg')\\n# 显示图片\\nplt.imshow(img)\\n# 不显示坐标\\nplt.axis('off')\\nplt.show()\\n结果输出为：\\n代码8-2：识别自己写的数字图片（片段3）\\n# 把图片大小变成28×28，并且把它从3D 的彩色图变为1D 的灰度图\\nimage = np.array(img.resize((28,28)).convert('L'))\\n# 显示图片,用灰度图显示\\nplt.imshow(image,cmap='gray')\\n# 不显示坐标\\nplt.axis('off')\\nplt.show()\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 274, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 275\\n结果输出为：\\n代码8-2：识别自己写的数字图片（片段4）\\n# 观察发现我自己写的数字是白底黑字，MNIST数据集的图片是黑底白字\\n# 所以我们需要先把图片从白底黑字变成黑底白字，就是 255-image\\n# MNIST数据集的数值都是0-1 之间的，所以我们还需要/255.0 对数值进行归一化\\nimage = (255-image)/255.0\\n# 显示图片，用灰度图显示\\nplt.imshow(image,cmap='gray')\\n# 不显示坐标\\nplt.axis('off')\\nplt.show()\\n结果输出为：\\n代码8-2：识别自己写的数字图片（片段5）\\n# 把数据处理变成4 维数据\\nimage = image.reshape((1,28,28,1))\\n# 载入训练好的模型\\nmodel = load_model('mnist.h5')\\n# predict_classes对数据进行预测并得到它的类别\\nprediction = model.predict_classes(image)\\nprint(prediction)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 275, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 276\\n[6]\\n8.12 CIFAR-10 数据集分类\\nCIFAR-10 数据集是深度学习领域比较常用的一个图片数据集，很多模型都会使用 CIFAR-\\n10 数据集来检验模型的效果。CIFAR-10 数据集一共有10 个分类，每个分类的图片都是32×\\n32 的彩色图片，每个分类都有 6000 张图片，一共个 60000 张图片。其中50000 张图片是训\\n练集，10000 张图片是测试集。如图8.38 所示。\\n图8.38 CIFAR-10\\n另外还有一个数据集叫CIFAR-100，顾名思义就是有100 个种类，每个种类有600 张图\\n片，一共60000 张。其中50000 张为训练集，10000 张为测试集。CIFAR-10 数据集比较\\n用得更多一些，CIFAR-10 数据集分类代码如8-3 所示。\\n代码8-3：CIFAR-10 数据集分类（片段1）\\nimport numpy as np\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 276, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 277\\nfrom tensorflow.keras.datasets import cifar10\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\\nfrom tensorflow.keras.optimizers import Adam\\nimport matplotlib.pyplot as plt\\n# 下载并载入数据\\n# 训练集数据(50000, 32, 32, 3)\\n# 测试集数据(50000, 1)\\n(x_train,y_train),(x_test,y_test) = cifar10.load_data()\\n# 显示1 张图片\\n# 第3 张图片\\nn = 3\\n# 一共10 个种类\\ntarget_name = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\\n# 显示图片\\nplt.imshow(x_train[n])\\nplt.axis('off')\\n# 根据标签获得种类名称\\nplt.title(target_name[y_train[n][0]])\\nplt.show()\\n结果输出为：\\n代码8-3：CIFAR-10 数据集分类（片段2）\\n# 数据归一化\\nx_train = x_train/255.0\\nx_test = x_test/255.0\\n# 转one hot格式\\ny_train = to_categorical(y_train,num_classes=10)\\ny_test = to_categorical(y_test,num_classes=10)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 277, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 278\\n# 定义卷积网络\\nmodel = Sequential()\\nmodel.add(Convolution2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, pad\\nding='same', activation = 'relu'))\\nmodel.add(Convolution2D(filters=32, kernel_size=3, strides=1, padding='same', activation =\\n'relu'))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.2))\\nmodel.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation =\\n'relu'))\\nmodel.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation =\\n'relu'))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.3))\\nmodel.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation\\n= 'relu'))\\nmodel.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation\\n= 'relu'))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.4))\\nmodel.add(Flatten())\\nmodel.add(Dense(10,activation = 'softmax'))\\n# 定义优化器\\nadam = Adam(lr=1e-4)\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 训练模型\\nmodel.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuf\\nfle=True)\\n结果输出为：\\nTrain on 50000 samples, validate on 10000 samples\\nEpoch 1/100\\n50000/50000 [==============================] - 9s 181us/sample - los\\ns: 1.9268 - acc: 0.2873 - val_loss: 1.6186 - val_acc: 0.4077\\nEpoch 2/100\\n50000/50000 [==============================] - 6s 127us/sample - los\\ns: 1.5641 - acc: 0.4284 - val_loss: 1.4547 - val_acc: 0.4748\\nEpoch 3/100\\n50000/50000 [==============================] - 6s 126us/sample - los\\ns: 1.4103 - acc: 0.4897 - val_loss: 1.2902 - val_acc: 0.5436\\n……\\nEpoch 98/100\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 278, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 279\\n50000/50000 [==============================] - 6s 126us/sample - los\\ns: 0.2807 - acc: 0.8987 - val_loss: 0.5496 - val_acc: 0.8293\\nEpoch 99/100\\n50000/50000 [==============================] - 6s 126us/sample - los\\ns: 0.2797 - acc: 0.8995 - val_loss: 0.5561 - val_acc: 0.8303\\nEpoch 100/100\\n50000/50000 [==============================] - 6s 126us/sample - los\\ns: 0.2822 - acc: 0.8979 - val_loss: 0.5498 - val_acc: 0.8278\\n训练100 个周期，最后得到了83%左右的测试集准确率。\\n卷积神经网络是如今深度学习中最常用的算法之一，而另一种非常常用的算法——序列模\\n型将是我们下一章要介绍的内容。\\n8.13 参考文献\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\narXiv:1804.02767, 2018.\\n[2] Nam H, Han B. Learning multi-domain convolutional neural networks for visual\\ntracking[C]//Proceedings of the IEEE conference on computer vision and pattern\\nrecognition. 2016: 4293-4302.\\n[3] Badrinarayanan V, Kendall A, Cipolla R. Segnet: A deep convolutional encoder-\\ndecoder architecture for image segmentation[J]. IEEE transactions on pattern analysis\\nand machine intelligence, 2017, 39(12): 2481-2495.\\n[4] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\ninternational conference on computer vision. 2017: 2961-2969.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 279, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 280\\n第 9 章-序列模型\\n1986 年 Rumelhart 等人提出循环神经网络（Recurrent Neural Network），简称\\nRNN。RNN跟我们之前学习过的神经网络都不太一样，它是一种序列模型。比如卷积网络\\n是专门用来处理网格化数据（例如图像数据）的神经网络，RNN是专门用来处理序列数据的\\n神经网络。所谓的序列数据指的是跟序列相关的数据，比如一段语音，一首歌曲，一段文\\n字，一段录像等。\\n9.1 序列模型应用\\n我们生活中的很多数据都是序列数据，因此序列模型可以应用于我们生活中的很多方\\n面，例如：\\n语音识别：把语音转换成为文字，如图 9.1 所示。\\n图9.1 语音识别\\n文本分类：把文章，邮件或用户评论等文本数据做分类，如图 9.2 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 280, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 281\\n图9.2 文本分类\\n机器翻译：如把中文翻译成英文，如图 9.3 所示。\\n图9.3 机器翻译\\n视频识别：通过一段视频分析视频中发生的事件，如图 9.4 所示。\\n图9.4 视频识别\\n分词标注：给一段文字做分词标注，标注每个字对应的标号。假如使用4-tag(BMES)标注\\n标签，B 表示词的起始位置，M 表示词的中间位置，E表示词的结束位置，S 表示单字词。可\\n以得到类似如下结果：\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 281, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 282\\n9.2 循环神经网络 RNN\\n9.2.1 循环神经网络介绍\\n循环神经网络 RNN 的基本结构是 BP 网络的结构，也是有输入层，隐藏层和输出层。只\\n不过在RNN 中隐藏层的输出不仅可以传到输出层，并且还可以传给下一个时刻的隐藏层，如\\n图9.5 所示。\\n图9.5 RNN结构\\n图 9.5 中 RNN 的结构可以展开为右边的结构，其中 x 为输入信号，𝑥 为 t-1 时刻的输\\nˆ(cid:127)\"\\n入信号，𝑥 为t时刻的输入信号，𝑥 为 t+1时刻的输入信号。ℎ 为t-1 时刻的隐藏层信号，\\nˆ ˆ(cid:151)\" ˆ(cid:127)\"\\nℎ 为 t 时刻的隐藏层信号，ℎ 为 t+1 时刻的隐藏层信号。𝑦 为 t-1 时刻的输出层信号，𝑦\\nˆ ˆ(cid:151)\" ˆ(cid:127)\" ˆ\\n为 t 时刻的输出层信号，𝑦 为 t+1 时刻的输出层信号。W，U，V 为网络的权值矩阵。h 是\\nˆ(cid:151)\"\\n隐藏(hidden)的首字母。\\n假如图9.5 是一个训练好的词性分析模型，有一个句子是“我爱你”，那么先把句子做分\\n词得到“我”，“爱”，“你”三个词，然后依次把这三个词输入到网络中。那么𝑥 为“我”\\nˆ(cid:127)\"\\n所表示的信号，𝑥 为“爱”所表示的信号，𝑥 为“你”所表示的信号。而𝑦 输出结果是主\\nˆ ˆ(cid:151)\" ˆ(cid:127)\"\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 282, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 283\\n语，𝑦 输出结果是谓语，𝑦 输出结果是宾语，分别得到“我”，“爱”，“你”这三个词的\\nˆ ˆ(cid:151)\"\\n词性。\\n从结构上可以观察到RNN最大的特点是之前序列输入的信息会对模型之后的输出结果造\\n成影响。\\n9.2.2 Elman network 和 Jordan network\\n循环神经网络RNN 有两种常见的模型，一种是Elman network 另一种是Jordan\\nnetwork。Elman network 和Jordan network 也被称为\\nSimple Recurrent Networks (SRN)或SimpleRNN，即简单的循环神经网络。\\n这两种模型的网络结构是一样的，都如图 9.5，只不过它们的计算公式有一点不同。\\nElman network 的公式为：\\nℎ = 𝜎 (𝑊𝑥 + 𝑈ℎ + 𝑏 ) (9.1)\\nˆ (cid:150) ˆ ˆ(cid:127)\" (cid:150)\\n𝑦 = 𝜎 (cid:142)𝑉ℎ + 𝑏 (cid:143) (9.2)\\nˆ — ˆ —\\nJordan network 的公式为：\\nℎ = 𝜎 (𝑊𝑥 + 𝑈𝑦 + 𝑏 ) (9.3)\\nˆ (cid:150) ˆ ˆ(cid:127)\" (cid:150)\\n𝑦 = 𝜎 (cid:142)𝑉ℎ + 𝑏 (cid:143) (9.4)\\nˆ — ˆ —\\n其中𝑥 为 t 时刻的输入信号，ℎ 为 t 时刻隐藏层的输出信号，𝑦 为 t 时刻输出层的输出信\\nˆ ˆ ˆ\\n号。W，U，V 对应图 9.5 中的权值矩阵，b 为偏置值。𝜎 和𝜎 为激活函数，激活函数可以自\\n(cid:150) —\\n行选择。\\n从上面Elman network 和Jordan network 的公式对比中可以看出，Elman network\\n的隐层ℎ 接收的是上时刻的隐层ℎ 的信号；而 Jordan network 的隐层ℎ 接收的是上时刻的\\nˆ ˆ(cid:127)\" ˆ\\n输出层𝑦 的信号。一般 Elman network 的形式会更常用一些。\\nˆ(cid:127)\"\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 283, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 284\\n9.3 RNN 的不同架构\\n为了处理不同输入输出组合的各类任务，RNN可以分为以下几种不同的架构。\\n9.3.1 一对一架构\\n一对一架构如图9.6 所示。\\n图9.6 RNN 一对一架构\\n其实就是普通的神经网络，输入序列长度为 1，输出序列长度也是 1。注意这里的𝑥 不是\\n\"\\n一个数值的意思，而是第一个序列输入的意思，𝑥 可以是多个数值。比如𝑥 输入MNIST 数据\\n\" \"\\n集图片的数据，一张图片有 784 个像素，那么这里的𝑥 就有 784 个值。把𝑥 的数据输入，然\\n\" \"\\n后𝑦 得到图片数据的预测结果。\\n\"\\n9.3.2 多对一架构\\n多对一架构如图9.7 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 284, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 285\\n图9.7 RNN 多对一架构\\n模型有多次输入，我们只关心序列输出的最后一个值。比如可以用于情感分类，给模型\\n输入一个句子或一篇文章，一个句子或一篇文章包含很多个词，每个词看成是一个输入信\\n号，那么一个序列被分为多次输入。最后模型的预测结果可以是一个句子或一篇文章的情感\\n分类，比如说是正面的情感还是负面的情感，两个类别，那么模型的最后一个序列的输出可\\n以看成是预测结果。同样的道理，如果做文本分类也是可以用多对一架构。\\n这里要注意的是，多对一架构并不是说模型只有最后一个序列才有输出值。其实每次给\\n模型输入一个词的信号，模型都会输出一个结果。只不过如果我们需要分析一个句子或者一\\n篇文章的情感，那么我们需要把整个句子或整篇文章的词的数据都输入到模型进行计算之\\n后，再获得模型最终的一个输出结果，模型最终的这个输出结果会更准确。而前面得到的模\\n型输出结果可能就没这么准确。\\n9.3.3 多对多架构\\n多对多架构如图9.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 285, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 286\\n图9.8 RNN多对多架构\\n序列有多次输入和多次输出。可以应用在 Tagging（标注），比如说词性标注，标注句\\n子中的每个词分别是什么词性。输入一个信号，然后就输出这个信号的预测结果。\\n9.3.4 一对多架构\\n一对多架构如图9.9 所示。\\n图9.9 RNN 一对多架构\\n一对多模型是只有一个输入信号，就可以得到很多个输出结果。第一个序列的输出结果\\n会作为输入传给第二个序列，第二个序列的输出会作为输入传给第三个序列，以此类推。比\\n如可以应用于音乐生成和文章生存。给出第一个音符或字，就可以生成一段旋律或者一句\\n话。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 286, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 287\\n9.3.5 Seq2Seq 架构\\nSeq2Seq的全称是Sequence to Sequence，也就是序列到序列模型。seq2seq也算\\n是多对多架构，如图9.10 所示。\\n图9.10 RNN 的seq2seq架构\\nseq2seq由两部分组成，左边部分为编码器（encoder），右边部分为解码器\\n（decoder）。Encoder 的作用是负责将输入序列压缩成指定长度的向量，相当于是做特征\\n提取。然后把这个向量传给decoder进行计算得到多个序列输出。\\n经典的多对多RNN 架构的输入和输出是等长的，也就是有10 个输入就必须有10 个输\\n出结果，它的应用场景也比较有限。而 seq2seq模型的输入和输出可以是不等长的，它实现\\n了一个序列到另一个序列的转换。比如可以用来做机器翻译，encoder 输入一段中文，\\ndecoder可以输出一段英文，中文句子的词汇数跟英文句子的词汇数不一定要相同。比如还\\n可以用来做聊天机器人，encoder 输入一句话，decoder回复另一句话，这两句话的长度也\\n不一定相同。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 287, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 288\\n9.4 传统 RNN 的缺点\\n我们知道RNN 可以根据历史信息来进行预测，假如我们训练了一个可以进行文本填空\\n的RNN 模型，下面要进行文本填空：\\n题目1:有一朵云飘在（）。\\n对于题目1 来说正确的答案应该是“天上”，或者“空中“，或者”天空中“等。经过\\n大量训练之后的RNN 可以根据前面文本的信息填出正确的答案。\\n题目2:我从小生长在美国，父亲是英国人，母亲是美国人。我最喜欢喝牛奶，吃牛肉，\\n长大想当科学家。我的兴趣爱好是看电影，看书，踢足球还有周末跟爷爷去钓鱼。我可以说\\n一口流利的（）。\\n对于题目2 来说因为是从小生长在美国，所以应该是可以说一口流利的“英语“。但是\\n传统的RNN 不一定能预测出正确的结果，原因是句子的长度太长了。\\n为什么句子的长度太长会对RNN 的预测产生影响呢？这要考虑到RNN的基本模型结\\n构，传统的RNN 基本模型结构是BP 网络。我们在学习BP 网络的时候有特别讨论过关于梯\\n度消失的问题。就是模型计算得到的误差信号从输出层不断向前传播，以此来调整前面层的\\n权值，使得模型的性能越来越好。但是由于误差信号在每次传递的时候都需要乘以激活函数\\n的导数，当激活函数的导数取值范围是 0-1 之间时，会使得误差信号越传越小，最终趋近于\\n0。\\n这个梯度消失的问题在RNN 中同样存在，RNN 的序列结构展开之后也可以看成是有很\\n多的“层”，在计算误差信号的时候同样会出现梯度消失的问题，使得网络输出的学习信号\\n只能影响到它前面的几层，对它前面的几层的权值进行调节。所以反过来考虑，一个信号的\\n输入，只能影响到它后面的几个序列的输出，并且影响力会越来越弱，如图 9.11 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 288, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 289\\n图9.11 RNN 的梯度消失问题[1]\\n9.5 长短时记忆网络 LSTM\\nLSTM(Long Short Term Memory)是Hochreater 和Schmidhuber在1997 年提出的\\n一种网络结构，尽管该模型在序列建模上的特性非常突出，但由于当时正是神经网络的下坡\\n期，没有能够引起学术界足够的重视。随着深度学习逐渐发展，后来 LSTM 的应用也逐渐增\\n多。\\nLSTM 区别于 SimpleRNN 的地方，主要就在于它在算法中加入了一个判断信息有用与\\n否的“处理器”，这个处理器作用的结构被称为记忆块（Memory Block），如图9.12 所\\n示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 289, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 290\\n图9.12 记忆块（memory block）[1]\\n图9.12 中最下面4 个神经元是输入神经元，最上面 5 个神经元是输出神经元，\\nmemory block 在隐藏层的位置。传统的 BP 网络隐藏层是普通的神经元，不过在LSTM 里\\n面是结构比较复杂的memory block。memory block内部具体结构如图9.13 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 290, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 291\\n图9.13 memory block 结构[1]\\n𝑓 = 𝜎 (cid:142)𝑊 𝑥 + 𝑈 ℎ + 𝑏 (cid:143) (9.5)\\nˆ (cid:209) v ˆ v ˆ(cid:127)\" v\\n𝑖 = 𝜎 (𝑊𝑥 + 𝑈 ℎ + 𝑏 ) (9.6)\\nˆ (cid:209) ( ˆ ( ˆ(cid:127)\" (\\n𝑜 = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑏 ) (9.7)\\nˆ (cid:209) (cid:210) ˆ (cid:210) ˆ(cid:127)\" (cid:210)\\n𝑐 = 𝑓 ∘ 𝑐 + 𝑖 ∘ 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑏 ) (9.8)\\nˆ ˆ ˆ(cid:127)\" ˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211)\\nℎ = 𝑜 ∘ 𝜎 (𝑐 ) (9.9)\\nˆ ˆ (cid:150) ˆ\\n𝑐̃ = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑏 ) (9.10)\\nˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211)\\nmemory block 结构主要包含了三个门：遗忘门（Forget Gate）、输入门（Input\\nGate）、输出门（Output Gate）与一个记忆单元（Cell）。信号从下面传入，上面传出。\\n首先我们先了解一下公式中符号的含义。\\n𝑓：遗忘门信号\\nˆ\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 291, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 292\\n𝑖 ：输入门信号\\nˆ\\n𝑜 ：输出门信号\\nˆ\\n𝑥 ：第t个序列的输入\\nˆ\\nℎ ：第t-1 个序列的memory block 输出\\nˆ(cid:127)\"\\nℎ ：第t个序列的memory block 输出，也称为Hidden State。\\nˆ\\n𝑐̃ ：cell输入信号\\nˆ\\n𝑐 ：cell输出信号，也称为Cell State。\\nˆ\\n𝑐 ：第t-1 个序列的cell信号\\nˆ(cid:127)\"\\n𝜎 ：sigmoid函数\\n(cid:209)\\n𝜎 ：tanh函数\\n(cid:211)\\n𝜎 ：tanh函数或线性函数\\n(cid:150)\\n𝑊,𝑈,𝑏：𝑊和𝑈是权值矩阵，𝑏是偏置\\n观察图9.13，信号从blcok 底部传入，传入的信号为第 t个序列的输入𝑥 ，以及第 t-1\\nˆ\\n个序列的输出ℎ ，也就是上一个时间block 的输出信号会传给当前的block 做计算。𝑥 和\\nˆ(cid:127)\" ˆ\\nℎ 乘以对应的权值矩阵加上偏置值经过激活函数得到𝑐̃ 的信号，计算公式为9.10，如图\\nˆ(cid:127)\" ˆ\\n9.14所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 292, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 293\\n图 9.14 𝑐̃ 的信号计算[1]\\nˆ\\n𝑐̃ 信号继续传会碰到Input Gate输入门，输入门的计算公式为9.6。输入门的传入信号\\nˆ\\n也是𝑥 和ℎ ，激活函数为sigmoid函数。我们要注意 2 个地方：\\nˆ ˆ(cid:127)\"\\n1.block 中一共有3 个门，并且这 3 个门的输入信号都是𝑥 和ℎ ，它们的计算公式都是\\nˆ ˆ(cid:127)\"\\n差不多的，不过他们的权值矩阵是不同的值，不同的门有不同的权值。\\n2.3 个门的激活函数都是sigmoid函数，所以3 个门的输出值都是0-1 之间，体现了门\\n的作用。门的作用就是控制信号的开关。\\n𝑐̃ 信号和输入门信号𝑖 会进行对位相乘，然后再进行传递。𝑖 的作用在这里就体现出来\\nˆ ˆ ˆ\\n了，𝑖 的值等于 1 表示𝑐̃ 信号会100%传递；𝑖 的值等于0 表示𝑐̃ 信号会完全消失；𝑖 的值等\\nˆ ˆ ˆ ˆ ˆ\\n于0.6 表示𝑐̃ 信号会保留60%的大小进行传递。如图 9.15 所示。\\nˆ\\n图9.15 𝑖 的信号计算[1]\\nˆ\\n𝑐̃ 和𝑖 对位相乘后继续传递到达Cell的位置。Cell的位置有一个Forget Gate 遗忘门，\\nˆ ˆ\\n遗忘门的计算公式为9.5，跟输入门的计算类似，最后得到0-1 之间的结果。当前的𝑐 信号计\\nˆ\\n算公式为9.8，表示𝑐̃ 和𝑖 对位相乘后的信号再加上前一个序列的Cell信号𝑐 和𝑓对位相乘\\nˆ ˆ ˆ(cid:127)\" ˆ\\n的信号。\\n其实就相当于是在block 内部可以保存一个 Cell信号为𝑐 ，这个信号会不断“遗忘”，\\nˆ\\n所以需要乘以遗忘门信号𝑓。具体需要全部遗忘，还是不遗忘，还是遗忘一部分，是由遗忘\\nˆ\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 293, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 294\\n门信号𝑓来控制的。当前的Cell信号就等于之前的 Cell信号进行一些遗忘𝑐 ∘𝑓再加上当\\nˆ ˆ(cid:127)\" ˆ\\n前传入的信号𝑐̃ ∘𝑖 。如图9.16 所示。\\nˆ ˆ\\n图 9.16 𝑐 的信号计算[1]\\nˆ\\n𝑐 信号继续传递会碰到Output Gate输出门，输出门的计算公式为9.7，跟输入门和遗\\nˆ\\n忘门类似。整个block 最后的输出为ℎ ，公式为9.9。就是𝑐 信号加上tanh激活函数再跟输\\nˆ ˆ\\n出门信号𝑜 对位相乘得到 block 的输出ℎ ，如图9.17 所示。\\nˆ ˆ\\n图9.16 ℎ 的信号计算[1]\\nˆ\\nmemory blocks输出的ℎ 信号会再乘上输出层的权值矩阵加上偏置值再经过激活函数最\\nˆ\\n后得到LSTM 网络的输出结果。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 294, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 295\\n9.6 Peephole LSTM 和 FC-LSTM\\n9.6.1 Peephole LSTM 介绍\\nPeephole LSTM跟LSTM 差不多，结构如图 9.17 所示。\\n图9.17 Peephole LSTM 结构图[1]\\n𝑓 = 𝜎 (cid:142)𝑊 𝑥 + 𝑈 𝑐 + 𝑏 (cid:143) (9.11)\\nˆ (cid:209) v ˆ v ˆ(cid:127)\" v\\n𝑖 = 𝜎 (𝑊𝑥 + 𝑈 𝑐 + 𝑏 ) (9.12)\\nˆ (cid:209) ( ˆ ( ˆ(cid:127)\" (\\n𝑜 = 𝜎 (𝑊 𝑥 + 𝑈 𝑐 + 𝑏 ) (9.13)\\nˆ (cid:209) (cid:210) ˆ (cid:210) ˆ(cid:127)\" (cid:210)\\n𝑐 = 𝑓 ∘ 𝑐 + 𝑖 ∘ 𝜎 (𝑊 𝑥 + 𝑈 𝑐 + 𝑏 ) (9.14)\\nˆ ˆ ˆ(cid:127)\" ˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211)\\nℎ = 𝑜 ∘ 𝜎 (𝑐 ) (9.15)\\nˆ ˆ (cid:150) ˆ\\n𝑐̃ = 𝜎 (𝑊 𝑥 + 𝑈 𝑐 + 𝑏 ) (9.16)\\nˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 295, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 296\\n大家可以自己先观察一下Peephole LSTM跟LSTM 的结构和公式哪里不同。\\n不仔细观察可能不容易看出，它们不同之处在与把所有的ℎ 都改成了𝑐 ，也就是说当\\nˆ(cid:127)\" ˆ(cid:127)\"\\n前序列的𝑐 信号传传给下一个序列的计算，而不是ℎ 信号。\\nˆ ˆ\\n9.6.2 FC-LSTM 介绍\\nLSTM 还有一个结构为 FC-LSTM(Fully-Connected LSTM)，结构如图9.18所示。\\n图9.18 FC-LSTM 结构[1]\\n𝑓 = 𝜎 (cid:142)𝑊 𝑥 + 𝑈 ℎ + 𝑉 𝑐 + 𝑏 (cid:143) (9.17)\\nˆ (cid:209) v ˆ v ˆ(cid:127)\" v ˆ(cid:127)\" v\\n𝑖 = 𝜎 (𝑊𝑥 + 𝑈 ℎ + 𝑉𝑐 + 𝑏 ) (9.18)\\nˆ (cid:209) ( ˆ ( ˆ(cid:127)\" ( ˆ(cid:127)\" (\\n𝑜 = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑉 𝑐 + 𝑏 ) (9.19)\\nˆ (cid:209) (cid:210) ˆ (cid:210) ˆ(cid:127)\" (cid:210) ˆ(cid:127)\" (cid:210)\\n𝑐 = 𝑓 ∘ 𝑐 + 𝑖 ∘ 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑉𝑐 + 𝑏 ) (9.20)\\nˆ ˆ ˆ(cid:127)\" ˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211) ˆ(cid:127)\" (cid:211)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 296, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 297\\nℎ = 𝑜 ∘ 𝜎 (𝑐 ) (9.21)\\nˆ ˆ (cid:150) ˆ\\n𝑐̃ = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑉𝑐 + 𝑏 ) (9.22)\\nˆ (cid:211) (cid:211) ˆ (cid:211) ˆ(cid:127)\" (cid:211) ˆ(cid:127)\" (cid:211)\\n观察FC-LSTM 的结构和公式，我们可以很容易的知道，FC-LSTM 的𝑐 信号和ℎ 信号都\\nˆ ˆ\\n可以传给下一个序列进行计算。\\n总结一下，在LSTM 中存在3 个门，输入门控制信号的输入，遗忘门控制Cell信号的遗\\n忘，输出门控制信号的输出。LSTM 的隐藏层中有大量的 block，数量我们可以自己设置。\\n经过随时间反向传播(BPTT)算法(跟BP 算法类似)训练后LSTM 中的block 就可以自动判断\\n哪些信号应该让它输入，哪些信号应该保存或遗忘，哪些信号应该让它输出。它的输入门会\\n控制有用的信号进行输入，过滤掉一些无用的信号；它的遗忘门会保留一些重要的信号，忘\\n记一些不太有用的信号；它的输出门会控制输出一些有用的信号，如图 9.19 所示。\\n图9.19 LSTM 对信号的控制[1]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 297, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 298\\n9.7 其他 RNN 模型\\n9.7.1 门控循环单元 GRU\\nGRU(Gated Recurrent Unit)这个结构是2014 年才出现的，效果跟LSTM 差不多，但\\n是用到的参数更少，所以计算速度会更快一些。GRU将遗忘门和输入门合成了一个单一的更\\n新门。GRU的block 结构简图9.20 所示。\\n图9.20 GRU结构\\n𝑧 = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑏 ) (9.23)\\nˆ (cid:209) „ ˆ „ ˆ(cid:127)\" „\\n𝑟 = 𝜎 (𝑊 𝑥 + 𝑈 ℎ + 𝑏 ) (9.24)\\nˆ (cid:209) (cid:156) ˆ (cid:156) ˆ(cid:127)\" (cid:156)\\nℎ(cid:213) = 𝑡𝑎𝑛ℎ(𝑊 𝑥 + 𝑈 (𝑟 ∘ ℎ )) (9.25)\\nˆ (cid:150) ˆ (cid:150) ˆ ˆ(cid:127)\"\\nℎ = (1 − 𝑧 ) ∘ ℎ + 𝑧 ∘ ℎ(cid:213) (9.26)\\nˆ ˆ ˆ(cid:127)\" ˆ ˆ\\n𝑧 是更新门(update gate)，决定ℎ 的更新情况\\nˆ ˆ\\n𝑟 是重置门(reset gate)，决定是否要放弃ℎ\\nˆ ˆ(cid:127)\"\\nℎ(cid:213) 是候选输出，接收[𝑥 ,ℎ ]\\nˆ ˆ ˆ(cid:127)\"\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 298, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 299\\nℎ 是当前输出，接收[ℎ ,ℎ(cid:213) ]\\nˆ ˆ(cid:127)\" ˆ\\n9.7.2 双向 RNN（Bidirectional RNN）\\n双向RNN(Bidirectional RNN)结构如图 9.21 所示。\\n图 9.21 双向RNN\\n(cid:214)ℎ(cid:214)(cid:214)⃗ = 𝑓(cid:142)𝑊(cid:214)(cid:214)(cid:214)⃗𝑥 + 𝑉(cid:214)⃗(cid:214)ℎ(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ + 𝑏(cid:214)⃗ (cid:143) (9.27)\\nˆ ˆ ˆ(cid:127)\"\\n⃖ℎ(cid:214)(cid:214)(cid:214) = 𝑓(cid:142)𝑊⃖(cid:214)(cid:214)(cid:214)𝑥 + 𝑉⃖(cid:214)⃖ℎ(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏⃖(cid:214) (cid:143) (9.28)\\nˆ ˆ ˆ(cid:151)\"\\n𝑦 = 𝑔(cid:142)𝑈(cid:146)(cid:214)ℎ(cid:214)(cid:214)⃗;ℎ⃖(cid:214)(cid:214)(cid:214) (cid:147) + 𝑐(cid:143) (9.29)\\nˆ ˆ ˆ\\n这里的RNN 可以使用任意一种RNN结构SimpleRNN，LSTM 或GRU。这里箭头表示\\n从左到右或从右到左传播，对于每个时刻的预测，都需要来自双向的特征向量，拼接\\n（concatenate）后进行结果预测。箭头虽然不同，但参数还是同一套参数。有些模型中也\\n可以使用两套不同的参数。𝑓,𝑔表示激活函数，(cid:146)ℎ(cid:214)(cid:214)(cid:214)⃗;ℎ⃖(cid:214)(cid:214)(cid:214)(cid:147)表示数据拼接（concatenate）。\\nˆ ˆ\\n双向的 RNN 是同时考虑“过去”和“未来”的信息。图9.21 是一个序列长度为4 的双\\n向RNN 结构。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 299, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 300\\n比如输入𝑥 沿着实线箭头传输到隐层得到ℎ ，然后还需要再利用𝑥 计算得到ℎR，利用𝑥 和\\n\" \" ˆ ˆ $\\nℎR计算得到ℎR，利用𝑥 和ℎR计算得到ℎR，利用𝑥 和ℎR计算得到ℎR，再把ℎ 和ℎR进行数据拼接\\nˆ $ # $ # \" # \" \" \"\\n（concatenate），再计算得到输出结果𝑦 。以此类推同时利用前向传递和反向传递的数据\\n\"\\n进行结果的预测。\\n双向RNN 就像是我们做阅读理解的时候从头向后读一遍文章，然后又从后往前读一遍文\\n章，然后再做题。有可能从后往前再读一遍文章的时候会有新的不一样的理解，最后模型可\\n能会得到更好的结果。\\n9.7.3 Stacked Bidirectional RNN\\n堆叠的双向RNN 结构如图9.22 所示。\\n图9.22 Stacked Bidirectional RNNs\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 300, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 301\\nℎ(cid:214)(cid:214)(cid:214)(cid:214) ((cid:214) (cid:132)(cid:214)⃗ ) 𝑓(cid:217)(cid:214) 𝑊(cid:214)(cid:214)(cid:214)(cid:214)⃗(cid:132)ℎ(cid:132)(cid:127)\" 𝑉(cid:214)(cid:214)(cid:214)(cid:214)⃗(cid:132)ℎ(cid:214)(cid:214)(cid:214)(cid:214)(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)⃗ 𝑏(cid:214)(cid:214)(cid:214)⃗(cid:132)(cid:218)\\n= + + (9.30)\\nˆ ˆ ˆ(cid:127)\"\\nℎ⃖(cid:214)(cid:214) ((cid:214)(cid:214) (cid:132)(cid:214) )(cid:214) = 𝑓(cid:217)⃖ 𝑊(cid:214)(cid:214)(cid:214)(cid:214)(cid:132)(cid:214) ℎ(cid:132)(cid:127)\" + 𝑉⃖(cid:214)(cid:214)(cid:214)(cid:132)(cid:214) ℎ⃖(cid:214)(cid:214)(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏⃖(cid:214)(cid:214)(cid:132)(cid:214) (cid:218) (9.31)\\nˆ ˆ ˆ(cid:151)\"\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ ⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)\\n((cid:132)) ((cid:132))\\n𝑦 = 𝑔l𝑈(cid:219)ℎ ;ℎ (cid:220) + 𝑐m (9.32)\\nˆ ˆ ˆ\\n注意这里的堆叠RNN 结构并不是只有双向RNN 才可以堆叠，其实任意的RNN 都可以\\n堆叠，比如SimpleRNN，LSTM，GRU这些循环神经网络也可以进行堆叠。堆叠指的是在\\nRNN 的结构中叠加多层，类似于 BP 神经网络中可以叠加多层，增加网络的非线性。图 9.22\\n中是一个堆叠了3 个隐藏层的RNN 网络。\\n9.8 LSTM 网络应用于 MNIST 数据集分类\\nLSTM 网络是序列模型，一般是比较适合处理序列问题。这里我们把它用于手写数字图\\n片的分类，其实是相当于把图片看成序列。一张 MNIST 数据集的图片是28*28 的大小，我\\n们可以把每一行看成是一个序列输入，那么一张图片就是 28 行，序列长度为28；每一行有\\n28 个数据，每个序列输入28 个值，具体实现如代码 9-1 所示。\\n代码9-1：LSTM 网络应用于MNIST 数据集分类\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import LSTM\\nfrom tensorflow.keras.optimizers import Adam\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n# 训练集数据x_train 的数据形状为（60000，28，28）\\n# 训练集标签y_train 的数据形状为（60000）\\n# 测试集数据x_test的数据形状为（10000，28，28）\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 301, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 302\\n# 测试集标签y_test的数据形状为（10000）\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 数据大小-一行有 28 个像素\\ninput_size = 28\\n# 序列长度-一共有 28 行\\ntime_steps = 28\\n# 隐藏层memory block个数\\ncell_size = 50\\n# 创建模型\\nmodel = Sequential()\\n# 循环神经网络的数据输入必须是3 维数据\\n# 数据格式为(数据数量，序列长度，数据大小)\\n# 载入的mnist数据的格式刚好符合要求\\n# 注意这里的input_shape设置模型数据输入时不需要设置数据的数量\\nmodel.add(LSTM(\\nunits = cell_size,\\ninput_shape = (time_steps,input_size),\\n))\\n# 50 个memory block输出的50 个值跟输出层 10 个神经元全连接\\nmodel.add(Dense(10,activation='softmax'))\\n# 定义优化器\\nadam = Adam(lr=1e-3)\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 训练模型\\nmodel.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test,y_test))\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/10\\n60000/60000 [==============================] - 14s 236us/sample - lo\\nss: 0.5748 - accuracy: 0.8189 - val_loss: 0.2315 - val_accuracy: 0.93\\n03\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 302, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 303\\nEpoch 2/10\\n60000/60000 [==============================] - 15s 247us/sample - lo\\nss: 0.1953 - accuracy: 0.9416 - val_loss: 0.1521 - val_accuracy: 0.95\\n55\\n……\\nEpoch 10/10\\n60000/60000 [==============================] - 14s 228us/sample - lo\\nss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0644 - val_accuracy: 0.98\\n03\\nLSTM 应用于 MNIST 数据识别也可以得到不错的结果，不过当然没有卷积网络得到的结\\n果好。更多序列模型的应用案例我们将在后面的章节中进一步介绍。\\n9.9 参考文献\\n[1] Graves A. Supervised sequence labelling[M]//Supervised sequence labelling with\\nrecurrent neural networks. Springer, Berlin, Heidelberg, 2012: 5-13.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 303, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 304\\n第 10 章-经典图像识别模型介绍（上）\\n经典的图像识别模型比较多，并且我希望可以把各种模型的技术细节，设计思路尽可能\\n地给大家介绍清楚。所以经典图像识别模型介绍的部分分为上下两个章节，第 10 章和第11\\n章。这两个章节的内容都属于内功修行，为了保持内容的连贯性，这两个章节的内容都是算\\n法理论的介绍，相关代码实践的内容我放到了第 12 章节。大家可以看完第10，11 章再看\\n12 章，或者是结合第12 章的代码来看第 10，11 章，两种方式都可以。\\n10.1 图像数据集 ImageNet\\n10.1.1 ImageNet 介绍\\n在正式介绍深度学习的经典图像识别模型之前，我们先来了解一下全世界最大的带有标\\n签的开源图像数据集ImageNet。\\nImageNet项目是从2007 年由斯坦福教授李飞飞领导发起，ImageNet项目团队从互\\n联网上下载了近10 亿张照片，然后使用众包技术（例如亚马逊机械土耳其人平台）来帮助\\n他们为这些图像打标签。在巅峰时期，ImageNet项目有来自167 个国家的近50000 名工\\n作者为其进行数据的清理，分类，标注。\\n直到2009 年ImageNet项目正式交付使用，在ImageNet数据库中有1500 万张左右\\n的照片，包含大约22000 种类别，免费提供给全世界的研究者使用。ImageNet的官网地址\\n是：http://www.image-net.org/index。如图10.1 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 304, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 305\\n图10.1 ImageNet官网\\n官网的右上角可以看到当前ImageNet数据库图片的数量为14197122 张图片，一共有\\n21841 个种类。\\n10.1.2 李飞飞简介\\n李飞飞是美籍华人，人工智能学术圈最知名的女性科学家之一。\\n1976 年出生于北京，长在四川，16 岁随父母移居美国新泽西州。\\n1999 年毕业于普林斯顿大学。\\n2005 年获得加州理工学院电子工程博士。\\n2009 年加入斯坦福大学担任助理教授。\\n2012 年担任副教授（终生教授），和斯坦福人工智能实验室与视觉实验室主任。\\n2017 年1 月入职Google，担任谷歌云首席科学家。\\n2018 年9 月，离开谷歌返回斯坦福大学担任教授，同时保留谷歌云的AI/ML 顾问。\\n2020 年2 月，当选为美国国家工程院院士。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 305, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 306\\n10.1.3 ImageNet 的深远影响\\n2020 年2 月李飞飞当选美国国家工程院院士，美国国家工程院(NAE)对于李飞飞的当选\\n给出的理由是“李飞飞为建立大型机器学习和视觉理解知识库作做出了贡献”。这里的“大\\n型机器学习和视觉理解知识库”其实说白了就是 ImageNet数据集。为什么创建一个数据\\n集，就可以有资格评选美国院士？下面是我个人对于 ImageNet数据集重要性的理解：\\n一．前瞻性和创新性。ImageNet项目在2007 年发起，到2009 年交付使用。这个巨\\n大的项目需要耗费大量的人力物力财力，但是这个项目交付以后能发挥多大的作用，在当时\\n并不是十分明确。我们从今天的视角来看，大规模深度学习模型的训练（这里的训练指的是\\n重新训练一个新模型，不是指迁移学习（Transfer Learning））必然需要大规模的数据集\\n才能得到很好的结果，这也是目前深度学习技术的一个局限性。但是在当时，深度学习技术\\n才刚刚萌芽，大家并不明确大规模数据集对于机器学习/深度学习技术会有多大的影响。\\n二．ImageNet 对于计算机视觉领域的巨大影响。如果大家之前稍微有关注过计算机视\\n觉的发展就会发现，在ImageNet交付使用后，特别是2012 年以后，计算机视觉领域的技\\n术发展可谓是突飞猛进。图像识别，目标检测，人脸识别等技术的应用效果得到了巨大提\\n升。10 年前人脸识别技术我们可能只听说过，没见过，现在走到哪里都有人脸识别。这一切\\n都主要得益于深度学习技术的发展和ImageNet数据集。\\nImageNet在 2009 年免费发布以后，从2010 年开始每年都会组织一次计算机视觉的比\\n赛ILSVRC（ImageNet Large Scale Visual Recognition Challenge），简称ImageNet\\nChallenge。这个比赛也是近年来计算机视觉领域最受追捧也最具权威的学术竞赛之一，代\\n表了计算机视觉领域的最高水平。比赛的项目有图像分类，目标定位，目标检测，视频目标\\n检测，场景分类。其中最重要也最受关注的就是图像分类的比赛。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 306, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 307\\nImageNet Challenge 的图像分类比赛是从 ImageNet数据集中选出了1000 个生活中\\n常见的分类，120 万张图片作为训练集，10 万张图片作为测试集，5 万张图片作为验证集。\\n参加比赛的人主要都是来自全世界的大公司，学校，研究院等。也有一些创业公司会参赛，\\n因为如果能在这个全世界最知名的图像比赛上拿奖的话，那就证明了获奖公司拥有全世界最\\n顶尖的图像技术水平，之后拿投资，做推广都会很容易。\\n从ImageNet Challenge 比赛中诞生出了很多优秀的深度学习模型，这些模型可以应用\\n于计算机视觉的各种领域，图像识别，目标检测，目标分割，人脸识别等等，极大推动了计\\n算机视觉的发展。\\n如果大家对ImageNet Challenge 比赛感兴趣，也想参赛的话，那么很遗憾，参加不了\\n了。因为这个比赛是从2010 年开始举办，到 2017 年结束，现在这个比赛已经没有了。因\\n为这个比赛的初衷就是希望可以通过比赛来推动计算机视觉技术的发展，很显然，这个目的\\n已经完全达到，比赛中各个项目的模型效果均已接近甚至超过人类水平。\\n三．ImageNet 对于其他技术领域的影响。ImageNet最直接的影响肯定是计算机视觉\\n领域，不过除了计算机视觉，ImageNet也间接推动了其他技术领域的发展。\\n深度学习的主要应用领域是图像，文本和语音等，每个技术领域都有不同的特点，不过\\n也都有一些相通的地方。比如不管在哪个领域使用深度学习都需要涉及到激活函数，代价函\\n数，网络结构设计等这些方面的内容。ImageNet的发布以及ImageNet Challenge 比赛促\\n进了深度学习技术的全面发展，让神经网络技术再一次流行起来，使得我们对神经网络/深度\\n学习的技术有了更深刻的理解。所以当我们在其他领域使用深度学习的时候，ImageNet也\\n起到了潜移默化的作用。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 307, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 308\\n10.1.4 ImageNet Challenge 历年优秀作品\\nImageNet Challenge 从2010 年开始举办到2017 年结束，总共举办了8 次。在这8\\n年的时间里诞生出了很多非常经典而且优秀的模型，让神经网络变得越来越流行，并出现了\\n多种优秀变体，可谓百花齐放。下面我们简单来回顾一下 ImageNet Challenge 比赛的历\\n史，图10.2 为历年比赛结果（数据来源于 http://image-net.org/challenges/LSVRC/）。\\n图10.2 ImageNet Challenge 历年比赛结果\\n图10.2 中的百分比为ImageNet Challenge 图像分类比赛中的错误率，注意这里的错误\\n率为Top5 错误率。一般在对ImageNet数据进行建模分类的时候，模型都会给出两个错误\\n率结果，一个是Top1 错误率，一个是 Top5 错误率。Top1 错误率表示模型在预测图像分类\\n的时候只能给出一个最可能的预测结果，预测结果跟真实标签相同则表示预测正确；Top5\\n错误率表示模型在预测图像分类的时候可以给出 5 个最可能的预测结果，这5 个最可能的预\\n测结果只要有其中一个跟真实标签相同则表示预测正确。由于 ImageNet Challenge 图像分\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 308, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 309\\n类比赛有1000 个分类，在做预测的时候有一定的错误容忍性，所以经常使用 Top5 错误率\\n作为主要指标判断模型好坏。\\n这里先对历年比赛结果做一个简单的介绍，后面我们还会再具体分析其中一些比较经典\\n和优秀的模型。如果大家仔细看的话会发现，有些年份我列出了冠亚军，有些年份我只列出\\n了冠军。这是因为有些模型虽然在某些年份的比赛中是亚军，但是它的名气，创新程度不亚\\n于冠军，所以我也列出来了。\\n2010 年和 2011 年的冠军使用的都是 SVM 算法，我们知道SVM 算法是机器学习领域\\n中的经典算法，在深度学习崛起之前，SVM 算法在计算机视觉中有着很多的应用。所以\\nImageNet Challenge 比赛的前两届大家用的还是老的思路，使用 SVM 来进行建模。从结\\n果中我们也可以看出来，使用SVM 来进行大规模的图片分类，得到的效果明显不如深度学\\n习。\\n2012 年对深度学习来说也是一个重要的年份，因为这是深度学习在 ImageNet\\nChallenge 图像分类的比赛上首次获得冠军。创造出这个深度学习模型的冠军团队来自多伦\\n多大学，主要作者是Alex Krizhevsky，所以这个模型被命名为AlexNet。团队成员中还有\\nGeoffrey Hinton，我们在本书最开始介绍深度学习领域的名人时有介绍过他，被称为“深\\n度学习教父”的人。Alex Krizhevsky是Geoffrey Hinton的学生，所以这个工作应该是在\\nHinton 大牛的带领下主要由学生完成的。AlexNet在当时大获成功，相比SVM，图像识别\\n的错误率有了大幅度的下降。2012 年比赛的亚军使用的算法还是传统机器学习算法，错误率\\n为26.17%，而AlexNet的错误率已经下降到了16.42%，拉开了巨大差距。从2012 年以\\n后，深度学习逐渐崛起，在后来的比赛中，所有人都开始使用深度学习来进行建模。\\n2013 年的冠军来自 Clarifai公司，他们用的也是深度学习模型，不过他们获得冠军的网\\n络模型不太有名，网上的资料也不多，后面就不多做介绍了。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 309, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 310\\n2014 年的冠军是来自谷歌的团队完成的，所以给模型命名为 GoogleNet。2014 年的亚\\n军模型也很有名，是来自牛津大学的研究组 VGG (Visual Geometry Group) ，所以给模型\\n起名为VGGNet。这两个模型都是非常有名和经典的模型，所以我在图中都列出来了。\\n2015 年的冠军是来自微软亚洲研究院(MSRA)，他们给模型命名为残差网络（Residual\\nNetwork），所以模型简称为ResNet。这个网络的层数多达152 层，网络结构设计非常具\\n有创新性。\\n2016 年的冠军由中国团队获得，是公安部第三研究所的 Trimps-Soushen团队，他们用\\n的也是深度学习模型，不过他们获得冠军的网络模型不太有名，网上的资料也不多，后面就\\n不多做介绍了。2016 年的亚军是来自加州大学圣地亚哥分校(UCSD)和Facebook AI\\nResearch(FAIR)的团队，他们的模型是在ResNet的基础上进行改进后得到的，所以模型命\\n名为ResNeXt。\\n2017 年的冠军是来自 Momenta公司的团队，他们提出了Squeeze-and-Excitation\\nNetworks（简称SENet）。\\n8 年来ImageNet Challenge 比赛不断推动着计算机视觉技术和深度学习的发展。人类\\n在ImageNet Challenge 图像识别比赛上的表现大约是 5.1%的错误率[1]，近年的比赛结果\\n已经比人类的错误率要低了许多。2017 年是ImageNet Challenge 的最后一年，也是一个\\n时代的终结。2017 年以后，ImageNet将与全世界最大的数据科学社区Kaggle 结合，在\\nKaggle 社区里继续举办比赛。ImageNet Challenge 虽然没有了，不过ImageNet的影响\\n将继续延续。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 310, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 311\\n10.2 AlexNet\\nAlexNet是在 ImageNet Challenge 图像识别比赛上第一个获得冠军的深度学习模型，\\n由自多伦多大学团队完成，主要作者是 Alex Krizhevsky，“深度学习教父” Geoffrey\\nHinton 也在团队中。AlexNet对后来的深度学习模型设计和模型训练都有着重要的启发和指\\n导作用。最早提出AlexNet的论文是《ImageNet Classification with Deep\\nConvolutional Neural Networks》[2]。\\n这里我想稍微多说几句，由于ImageNet Challenge 是一个比赛，比赛中有很多Trick\\n可以帮助模型得到更好的结果，比如在 AlexNet中在当时比较创新的使用了ReLU激活函\\n数，和使用Dropout来防止过拟合，然后把每张图片切分为多张进行训练和预测，改变图片\\n的颜色以生成更多的数据集等。比赛中的很多 Trick 内容比较分散，并且效果不稳定，有时\\n候可以让结果更好，有时候会让结果更差。所以关于模型的介绍我们主要是介绍模型的结构\\n设计，关于模型在比赛中所使用的Trick 大家有兴趣可以再另外自行研究。\\n图10.3 为《ImageNet Classification with Deep Convolutional Neural Networks》\\n论文中的网络结构图。\\n图10.3 AlexNet网络结构[2]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 311, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 312\\n图中的Stride 表示步长；Max pooling 表示最大池化；Dense表示全连接层。输入图片\\n大小为224×224，实际上作者在构建模型的时候使用的图片大小为227×227，主要是为了\\n后续计算方便。\\n大家初看这个图可能会觉得这个结构看起来有点复杂，可能暗藏玄机，这个模型的输入\\n是227×227 的图片（作者把ImageNet Challenge 比赛的图片都处理成227×227 的固定\\n大小再传入模型进行训练），后来怎么就变成了上下两个部分，这样设计有什么精妙之处\\n吗？\\n在当时看来，其实没有什么精妙，只是因为当时算力有限，也没有什么好用的深度学习\\n开源框架。他们手上只有两个GTX580 的3GB 内存的GPU，为了加快模型的训练速度，所\\n以他们把模型分为两个部分。一个GPU训练上面的部分，一个GPU训练下面的部分，所以\\n网络结构就变成了上下两个部分。我猜测如果尽量不改变模型的设计思路，放在今天的软硬\\n件条件下，AlexNet应该会被设计成图10.4 所示的结构。\\n图 10.4 AlexNet网络结构\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 312, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 313\\n图中的s表示stride，代表步长，s1 代表卷积或池化的步长为1，s2 代表卷积或池化的\\n步长为2，以此类推；fc 表示fully connected，代表全连接；pool 表示max pooling，代\\n表最大池化；conv 表示convolution，代表卷积；output表示输出。\\n其实我猜测的图10.4 结构和论文中图 10.3 结构还是有一点点小区别的，论文中的结构\\n分为上下两个部分以后，注意看图10.3 中的卷积的计算，在某些层会分为上下两个部分独立\\n计算，在某些层上下两个部分会一起计算。不过总的来说模型的效果差别不是很大（其实我\\n画的图10.4 的AlexNet结构会比原始的AlexNet结构效果差一点点，不过这里我们忽略不\\n计）。我们就以图10.4 来看一下AlexNet的网络设计。\\n把图画好其实就可以节省很多文字讲解了，图中已经把所有的卷积池化计算的窗口大\\n小，步长，以及卷积池化计算以后得到的特征图大小和数量都表示出来了，下面我再简单说\\n明一下即可。\\n图中卷积和池化的padding方式我没有标出来，有些层使用的是valid padding，有些\\n层使用的是same padding，不同的padding方式对模型结果一般不会有很大影响，所以图\\n中我就省略了。另外其实通过图中的已知的信息我们可以自己判断出 padding的方式。\\nAlexNet是一个 8 层的网络（卷积层和全连接层中有需要训练的权值，所以这里计算网\\n络层数的时候只计算卷积层和全连接层），除了最后输出层用的是 softmax函数以外，其他\\n层用的都是ReLU激活函数。\\nAlexNet是专门为 ImageNet级别的数据集设计的，一共有 6000 多万个需要训练的参\\n数，参数的数量巨大。\\n第1 层计算。网络的输入是 227×227 的“臭臭”照片。经过11×11 步长为4 的卷积\\n计算后，得到96 个55×55 的特征图。然后再进行3×3 步长为2 的最大池化计算，得到\\n96 个27×27 的特征图。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 313, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 314\\n第2 层计算。使用 5×5，步长为1 的卷积对96 个27×27 的特征图进行特征提取，得\\n到了256 个27×27 的特征图。然后再用 3×3 步长为2 的最大池化计算，得到256 个13×\\n13 的特征图。\\n第3 层计算。使用 3×3，步长为1 的卷积对256 个13×13 的特征图进行特征提取，得\\n到了384 个13×13 的特征图。\\n第4 层计算。使用 3×3，步长为1 的卷积对384 个13×13 的特征图进行特征提取，得\\n到了384 个13×13 的特征图。\\n第5 层计算。使用 3×3，步长为1 的卷积对384 个13×13 的特征图进行特征提取，得\\n到了256 个13×13 的特征图。然后再用 3×3 步长为2 的最大池化计算，得到256 个6×6\\n的特征图。\\n第6 层计算。把 pool3 的256 个6×6 的特征图数据跟fc1 中的4096 个神经元进行全\\n连接计算。\\n第7 层计算。把 fc2 的4096 个神经元跟fc1 中的4096 个神经元进行全连接计算。\\n第8 层计算。把 output的1000（ImageNet Challenge 比赛有1000 个分类）个神经\\n元跟fc2 中的4096 个神经元进行全连接计算。最后再经过softmax计算得到类别的概率值\\n进行输出。\\n可能大家会有一些疑问，什么AlexNet要设计成8 层的网络？为什么有些卷积后面加上\\n了池化，有些卷积后面没有池化？为什么有些卷积生成的特征图数量是 256，有些是 384？\\n为什么是384 而不是其他的数字？为什么有3 个全连接层，为什么是4096 个神经元？\\n其实这些为什么都很难给出合理的解释，因为直至今天深度学习的可解释性依旧是一个\\n重要科研难题。我觉得AlexNet的网络结构是在Alex团队有限的时间，有限的实验次数下\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 314, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 315\\n得到的最好的模型结构了。如果给他们更好的设备，更多的时间，做更多的实验，他们肯定\\n会得到更优秀的模型，得到更好的结果。\\n我们在2012 年的时候知道AlexNet是一个正确的方向，它开拓了一个新的并且更好的\\n思路，我们只要沿着这个方向继续往前走，肯定有更多的收获等着我们。\\n10.3 VGGNet\\nVGGNet是2014 年ImageNet Challenge 图像识别比赛的亚军。参赛团队是来自牛津\\n大学的研究组VGG (Visual Geometry Group) 。VGGNet的很多设计思想都受到AlexNet\\n的影响，所以跟AlexNet也有一点点相似的地方。VGGNet不仅在图像识别方向有着广泛应\\n用，很多目标检测，目标分割，人脸识别等方面的应用也会使用 VGGNet作为基础模型。\\nVGGNet在2014，2015 年左右的流行程度甚至超过了2014 年ImageNet Challenge\\n图像识别比赛的冠军GoogleNet，是当时用得最多的深度学习模型。VGGNet被广泛使用\\n也是有一定原因的，VGGNet的网络结构比较简单，也容易搭建，并且 VGGNet的单模型结\\n果与GoogleNet相当。ImageNet Challenge 是一个比赛，在比赛中我们经常会使用模型\\n融合（Ensemble Model）策略，把多个模型组合在一起，这样有可能会得到更好的结果。\\n2014 年，在ImageNet Challenge 比赛中，多个GoogleNet融合后的结果比多个\\nVGGNet融合后的结果要更好，所以 GoogleNet得到了冠军。最早提出VGGNet的论文是\\n《Very Deep Convolutional Networks for Large-Scale Image Recognition》[3]。\\n其实，VGGNet有多个版本，如图 10.5 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 315, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 316\\n图10.5 VGGNet的多个版本[3]\\n从图中ConvNet Configuration表示网络结构；weight layers表示网络层数；input\\n表示输入；conv 表示卷积；maxpool 表示最大池化；FC 表示全连接层。\\n我们可以看出VGGNet有6 个不同的版本，他们的主要区别是网络层数和网络结构的区\\n别。图中的conv3 表示3×3 的卷积，conv1 表示1×1 的卷积；conv3-128 表示3×3 的\\n卷积计算后生成128 个特征图；LRN(Local Response Normalization)是局部响应归一\\n化，一种在AlexNet中使用的数据归一化计算，不过VGGNet的作者认为LRN并没有什么\\n用，所以在VGGNet中并没有使用。\\n其中使用得比较多的有B，因为它有 13 层，我们称之为VGG13。使用得比较多的还有\\nD，因为它有16 层，我们称之为VGG16。使用得比较多的还有E，因为它有19 层，我们称\\n之为VGG19。在 ImageNet Challenge 图像识别比赛中效果最好的是VGG19，其次到\\nVGG16，最后是 VGG13。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 316, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 317\\n每个版本的模型网络结构不同，所以参数的数量也有所不同。参数数量最少的是 A，有1\\n亿3 千多万个参数。最多的是 E，有1 亿4 千多万个参数。别看网络中有很多的卷积层，其\\n实网络中大部分的参数都是在全连接层中。比如在 VGG16 中，卷积层的参数数量占所有参\\n数的13%，而全连接层的参数数量占到了 87%。\\n在很多应用中VGG16 似乎用得更多一些，下面我们来看一下 VGG16 的网络结构图\\n10.6 所示。\\n图10.6 VGG16 网络结构\\n图中fc 表示fully connected，代表全连接；pool 表示max pooling，代表最大池化；\\nconv 表示convolution，代表卷积；output表示输出。\\nVGG16 的所有卷积都是 3×3，步长为1，same padding；所有池化都是2×2，步长\\n为2，same padding；输出层函数为softmax，除了输出层以外，其他层激活函数都是\\nReLU函数。\\nVGG16 受 AlexNet的影响和启发，图片的输入为 224×224 的大小，卷积层后面也使\\n用了3 个全连接层，并且全连接层也是使用 4096 个神经元。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 317, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 318\\nVGG16 是一个 16 层的网络，它的结构比较简单易懂，叠加了很多个卷积池化层。2×\\n2，步长为 2 的池化特会使得特征图的长宽减少为原来1/2，池化后的下一个卷积会使得特征\\n图的数量会变成原来的2 倍。\\nVGG16 的输入是 224×224 大小的图片。\\nblock1 为第1，2 层，其中包含了 2 个卷积和1 池化，卷积后图像大小没有发生变化\\n224×224，池化后特征图大小变成了112×112，特征图的数量为64。\\nblock2为第3，4 层，其中包含了 2 个卷积和1 池化，卷积后图像大小没有发生变化\\n112×112，池化后特征图大小变成了56×56，特征图的数量为128。\\nblock3 为第5，6，7 层，其中包含了3 个卷积和1 池化，卷积后图像大小没有发生变化\\n56×56，池化后特征图大小变成了 28×28，特征图的数量为256。\\nblock4 为第8，9，10 层，其中包含了3 个卷积和1 池化，卷积后图像大小没有发生变\\n化28×28，池化后特征图大小变成了 14×14，特征图的数量为512。\\nblock5 为第11，12，13 层，其中包含了 3 个卷积和1 池化，卷积后图像大小没有发生\\n变化14×14，池化后特征图大小变成了 7×7，特征图的数量为512。大家可能会稍微有点\\n疑惑，block5 中的特征图的数量按照规律不应该会变成1024 吗，但是这里还是512。这里\\n的原因我猜测是作者他们肯定也尝试过 1024，但是最后的效果估计跟512 的效果差不多。\\n并且改成1024 后会增加很多计算量和需要训练的权值，所以最后的版本中就没有使用\\n1024。\\n第14 层计算。把pool5 的512 个 7×7 的特征图数据跟fc1 中的4096 个神经元进行全\\n连接计算。\\n第15 层计算。把fc2 的4096 个神经元跟 fc1 中的4096 个神经元进行全连接计算。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 318, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 319\\n第16 层计算。把output的1000（ImageNet Challenge 比赛有1000 个分类）个神\\n经元跟fc2 中的 4096 个神经元进行全连接计算。最后再经过softmax计算得到类别的概率\\n值进行输出。\\nVGGNet网络结构本身并没有太多创新的内容，它可以看成是对 AlexNet网络的改进优\\n化版本。\\n10.4 GoogleNet\\nGoogleNet是2014 年ImageNet Challenge 图像识别比赛的冠军。从它的名字我们就\\n可以看出是来自谷歌的团队完成的。前面我们有介绍，GoogleNet之所以获得冠军，是因为\\n它进行模型融合以后得到的效果要比VGGNet模型融合之后的效果要好。不过单模型比拼，\\n它与VGGNet的效果相当。\\n虽然GoogleNet的模型的效果跟VGGNet相差不大，不过它比VGGNet更具有创新\\n性。GoogleNet有一些更具创新性的设计，为后来的模型设计提供了很多新的思路。最早提\\n出GoogleNet的论文是《Going Deeper with Convolutions》[4]。\\n10.4.1 1×1 卷积介绍\\n在介绍GoogleNet结构之前，我们必须先来介绍一下什么是1×1 卷积。1×1 卷积在\\nGoogleNet中有着大量应用，是一个非常重要的设计。它的主要作用主要有两个，一是增加\\n网络非线性，二是减少计算量和需要训练的权值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 319, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 320\\n所谓1×1 卷积其实很简单，就是卷积核的大小是1×1，其他方面跟之前我们学习的卷\\n积没有区别。图10.7 为1×1 卷积示意图。\\n图10.7 1×1 卷积\\n使用1×1 卷积对6×6 图像进行特征提取，然后得到 6×6 的特征图。我们可以这么理\\n解，只考虑对1 张图像进行卷积计算时，3×3，5×5 这样的大卷积核可以对大范围区域的\\n特征进行提取然后得到1 个特征值。1×1 的卷积只对图上的1 个值进行特征提取然后得到1\\n个特征值。那么下面我们具体来看一下 1×1 卷积如何应用于实际的网络搭建。我们先考虑\\n一个没有1×1 卷积的卷积层计算，如图10.8 所示。\\n图10.8 没有加入 1×1 卷积的卷积计算\\n图中conv 表示卷积。\\n从图中可知192 个28×28 的特征图经过 5×5，步长为1 的卷积进行特征提取，得到 32\\n个28×28 的特征图。这里我们主要考虑一下图中的权值数量和计算量。关于卷积的权值数\\n量和计算量的计算我们在第8 章中已有详细介绍，下面我们就不再详细说明了：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 320, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 321\\n权值数量的计算为：5×5×192×32+32 个偏置值=153632。\\n计算量为（这里我们只计算乘法的计算量）：5×5×28×28×192×32≈120M，M 为\\nmillion 百万。\\n我们对正常卷积计算的权值数量和计算量有了大致的了解，下面我们再来看一下加入 1×\\n1 卷积后的计算，如图 10.9 所示。\\n图10.9 加入了1×1 卷积的卷积计算\\n图中conv 表示卷积。\\n从图中可知192 个28×28 的特征图经过两次卷积，最后得到 32 个28×28 的特征图，\\n最左边和最右边的特征图跟图10.8 中的左右两边的特征图是完全一样的，只是图 10.9 中间\\n多了一次1×1 的卷积。\\n从表面上看，我们就可以看出1×1 卷积的第一个作用了，增加网络的非线性。因为网络\\n的层数多了一层，层数越多，网络的非线性就越强。\\n下面我们再来计算一下加入1×1 卷积后网络的权值数量和计算量。\\n权值数量的计算为：第一个卷积层：1×1×192×16+16 个偏置值=3088。第二个卷积\\n层：5×5×16×32+32 个偏置值=12832。两个卷积层权值数量相加\\n3088+12832=15920，约为图10.9 中没有1×1 卷积的1/10。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 321, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 322\\n计算量为（这里我们只计算乘法的计算量）：第一个卷积层：1×1×28×28×192×\\n16≈2.4M，M 为million 百万。第二个卷积层：5×5×28×28×16×32≈10M。两个卷积层\\n计算量相加2.4M+10M=12.4M，约为图10.9 中没有1×1 卷积的1/10。\\n这就是1×1 卷积的第二个作用，减少计算量和需要训练的权值。初看这个结果大家可能\\n会有点难接受。前后两端都没有发生变化，看起来明明是多了一个卷积层，感觉上应该会有\\n更多的权值和更多的计算量才对。\\n其实大家只要仔细再看一下就能发现其中的原因。其中一个原因是 1×1 卷积本身的计算\\n量和权值数量就很少，另一个重要原因是“16”。1×1 卷积计算后生成了16 个28×28 的特\\n征图，比最后输出的32 个28×28 特征图的特征数量更少，相当于1×1 卷积对原来的特征\\n图进行了特征压缩。特征数量越少，计算量和权值数量自然就越少了。\\n如果上面计算中我们把16 改成160，1×1 卷积后产生160 个28×28 的特征图，那么使\\n用了1×1 卷积的计算，它的权值数量和计算量都跟不使用1×1 卷积差不多。\\n所以并不是说用了1×1 卷积，就一定可以减少权值数量和计算量，也要看1×1 卷积后生\\n成了多少张特征图。不过通常来说，我们不会让 1×1 卷积生成太多的特征图，所以一般来说\\n加入1×1 卷积后是可以减少网络权值数量和计算量的。\\n10.4.2 Inception 结构\\n在GoogleNet最特别的设计就是Inception结构，所以GoogleNet在后来的版本中改\\n了名字，模型的名字改成了Inception，而GoogleNet就是Inception-v1。Inception结构\\n如图10.10 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 322, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 323\\n图 10.10 Inception结构[4]\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\npooling 表示最大池化，previous layer 表示前一层。\\n图10.10 中左边的结构是 Inception原始的版本，右边的结构是Inception后来优化的\\n版本了。前面我们已经介绍过1×1 卷积的作用，所以在（b）中我们看到1×1 卷积应该知道\\n它的用意了，增加网络的层数以增加非线性，同时减少网络的权值数量和计算量。\\n不过Inception最特别的设计不是在于 1×1 卷积，而是在于同时使用多种不同尺度的卷\\n积核。我们可以看到Inception结构中使用了 1×1 卷积，3×3 卷积，5×5 卷积和一个最大\\n池化。卷积的作用我们应该很清楚了，用来做特征提取。不同的卷积核的数值可以提取不同\\n的特征，那么不同大小的卷积核当然也是可以从不同的尺度来提取特征的。从一个小区域提\\n取出来的特征跟从一个大区域提取出来的特征当然是不一样的。所以 Inception具有创新的\\n设计在于使用了多种不同尺度的卷积核来提取不同尺度的特征。\\n下面我们举一个具体的例子来说明 Inception结构的计算，如图10.11 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 323, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 324\\n图10.11 Inception module\\n图中conv 表示卷积，pool 表示池化。\\nInception module 是从GoogleNet结构中拿出来的一个具体计算的例子。输入是192\\n个28×28 的特征图，Inception module 会对这些特征图进行不同的特征提取计算。假如我\\n们把Inception看成是有4 个通道的特征提取计算：\\n第1 个通道就是对输入特征做 1×1，步长为1，same padding卷积，生成64 个28×\\n28 的特征图。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 324, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 325\\n第2 个通道就是对输入特征做 1×1，步长为1，same padding卷积，生成96 个28×\\n28 的特征图。然后再做3×3，步长为 1，same padding卷积，生成128 个28×28 的特征\\n图。\\n第3 个通道就是对输入特征做 1×1，步长为1，same padding卷积，生成16 个28×\\n28 的特征图。然后再做5×5，步长为 1，same padding卷积，生成32 个28×28 的特征\\n图。\\n第4 个通道就是对输入特征做 3×3，步长为1，same padding的最大池化，生成192\\n个28×28 的特征图。然后再做1×1，步长为1，same padding卷积，生成32 个28×28\\n的特征图。\\n最后再把这4 个通道分别得到的特征图组合起来，得到 64+128+32+32=256 个28×\\n28 的特征图。\\n在GoogleNet中叠加了很多个Inception结构，使得网络的层数变得非常多，并且网络\\n特征提取的能力特别强。\\n10.4.3 GoogleNet 网络结构\\n这一小节我们来具体看一下GoogleNet的网络结构，如图10.12 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 325, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 326\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 326, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 327\\n图10.12 GoogleNet网络结构[4]\\n图中的conv 表示卷积；MaxPool表示最大池化；LocalRespNorm 表示局部响应归一\\n化；DepthConcat表示数据拼接；FC 表示全连接层；AveragePool表示平均池化。\\n我们就先从整体上来了解一下GoogleNet，它是一个22 层的网络，网络的输入跟\\nVGGNet一样也是224×224。除了最后一层用的是softmax函数外，其它层的激活函数都\\n是ReLU函数。我们可以看到GoogleNet的主要结构组成是Inception module，一共叠加\\n了9 个Inception。GoogleNet网络的一些具体细节如图10.13 所示。\\n图10.13 GoogleNet结构细节[4]\\n图中的type表示层的类型；patch size/stride表示窗口大小/步长；output size 表示输\\n出大小；depth表示深度；params表示参数数量；ops表示计算量；convolution 表示卷\\n积；max pool 表示最大池化；avg pool 表示平均池化；linear表示全连接层。\\n别看GoogleNet有22 层之多，它的权值参数数量只有 600 多万，仅约为AlexNet的\\n1/10，VGGNet的1/20。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 327, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 328\\nGoogleNet的输入是224×224×3 的彩色图片，从图中我们可以看到第一个卷积是7×7\\n步长为2，卷积后得到 64 个112×112 的特征图。卷积后进行了一次3×3 步长为2 的最大\\n池化，得到64 个56×56 的特征图。\\n接下来再进行一次1×1 步长为1 的卷积得到64 个56×56 的特征图，卷积后再进行 3×\\n3 步长为1 的卷积，得到192 个56×56 的特征图。这里我们要注意，图中第3 行的卷积，\\ndepth为2，说明这里是有2 层卷积。图中的reduce其实是表示1×1 卷积的意思，#3×3\\nreduce表示3×3 卷积之前的1×1 卷积。#5×5 reduce表示5×5 卷积之前的1×1 卷积。\\n卷积后再进行一次3×3 步长为2 的最大池化，得到192 个28×28 的特征图。\\n下面我们看到了第一个Inception模块inception(3a)，每个inception 模块都有两层卷\\n积，所有depth为2。\\n图中的信息还是很完整的，所以我们只要仔细看一下图中信息我们就可以知道\\nGoogleNet的网络结构了。中间部分的计算这里就省略不讲了，大家可以自己看。\\n我们可以想一下，在之前的网络中卷积池化计算后得到很多特征图，最后我们还需要做\\n全连接得到最后的分类结果。那么卷积池化计算后得到的特征图是一个 4 维的数据，所以我\\n们还需要做一个“Flatten”，把4 维数据变成2 维，因为全连接必须是2 维数据，AlexNet\\n和VGGNet中都是这么做的。\\nGoogleNet 的平均池化avg pool设计。我们看一下图中倒数第4 行“avg pool”，\\n这是平均池化，这个“avg pool”放在inception(5b)后面，我们之前在介绍池化操作的时\\n候有介绍过平均池化，不过在实际网络搭建中还没有介绍过。这里使用的“avg pool”，它\\n的作用跟“Flatten”的作用其实类似，主要目的是把4 维的特征图数据变成2 维的数据，再\\n跟后面的1000 个分类神经元进行全连接。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 328, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 329\\ninception(5b)的输出是1024 个7×7 的特征图，“avg pool”窗口大小为7×7，所以\\n也就是每个特征图求平均得到1 个特征值，那么 1024 个特征图就可以提取出1024 个特征\\n值，最后再跟1000 个神经元进行全连接。GoogleNet的论文中有提到，把“Flatten”后连\\n接1024 个神经元改成“avg pool”得到1024 个特征值，ImageNet Challenge 图像识别\\n比赛Top1 准确率提高了0.6%[4]。另外使用“avg pool”还可以减少模型的权值数量，因为\\n全连接层会产生大量权值，而池化计算是没有权值的。\\nGoogleNet 的辅助分类器auxiliary classifiers设计。最后我还想再给大家介绍一下在\\n图10.13 中，GoogleNet的网络有3 个输出，中间部分的两个输出是GoogleNet设计的两\\n个辅助分类器。作者引入的两个辅助分类器也会经过 softmax函数后输出预测结果，预测结\\n果跟真实标签做对比得到辅助损失aux_loss，该模型总损失等于真实损失和辅助损失的加权\\n和，论文中每个辅助损失使用的权重值是 0.3，总的loss公式如下：\\n𝑡𝑜𝑡𝑎𝑙 = 𝑟𝑒𝑎𝑙 + 0.3 × 𝑎𝑢𝑥 + 0.3 × 𝑎𝑢𝑥 (10.1)\\n(cid:132)(cid:210)(cid:222)(cid:222) (cid:132)(cid:210)(cid:222)(cid:222) (cid:132)(cid:210)(cid:222)(cid:222) (cid:132)(cid:210)(cid:222)(cid:222)\\n– (cid:157)\\n这两个辅助分类器的作用是增加反向传播的梯度信号[4]，也就是说即使整个网络都是用了\\nReLU激活函数，但是网络的层的比较多（22 层），梯度信号在反向传递的过程中，还是会\\n损失掉一些有用的信号。 所以作者在中间层加入两个辅助分类器，帮助中间层那部分的权值\\n和靠近输入层那部分的权值更好的训练。\\n辅助分类器只在模型训练阶段起作用，模型预测结果辅助分类器是不使用的。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 329, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 330\\n10.5 Batch Normalization\\n在介绍后面新的一些网络模型之前，这小节我们先介绍一下 Batch Normalization，因为\\n近几年很多网络中都使用了Batch Normalization 技术。\\nBatch Normalization中文一般称为批量标准化/批量规范化/批量归一化等，本书中我\\n们就称为批量标准化好了。Batch Normalization 英文的简称一般为BatchNorm 或BN，本\\n书中我们就称为BN 好了。BN 是Google 研究员Sergey Ioffe 和Christian Szegedy在\\n2015 年提出的一种标准化策略。BN 提出以后，很多网络都使用了BN 的技术。这里特别说\\n明一下很多网络模型用了BN 以后效果有所提升，但并不是所有模型用了BN 就会更好，所\\n以我们可以把它看成是一个很可能有效的网络优化策略。下面对 BN 的介绍主要是参考 BN\\n的原始论文《Batch Normalization: Accelerating Deep Network Training by Reducing\\nInternal Covariate Shift》[5]。我觉得 BN 虽然有效，但并不是一个很好理解的技术，如果\\n大家看了以后不是特别理解的话也不用钻牛角钻尖，先接受它的作用，至于它的原理有时间\\n再慢慢品。\\n10.5.1 Batch Normalization 提出背景\\nBN的提出主要由于网络的内部协变量偏移（Internal Covariate Shift），简称ICS。\\nBN 作者在论文中给出了ICS 一个比较规范的定义：在深度学习网络的训练过程中网络内部\\n结点的分布变化称为内部协变量偏移[5]。其实说白了就是深度学习的深层网络之间的关系很\\n复杂，每一层数据的微小变化都会随着网络一层一层的传递而被逐渐放大（类似于蝴蝶效\\n应）。底层网络（假设靠近输入层的网络我们称为底层网络）输入的微小变化，就会引起高\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 330, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 331\\n层网络（假设靠近输出层的网络我们称为高层网络）输入分布的剧烈变化，高层网络需要不\\n断去重新适应底层网络的参数更新。这就使得网络训练起来比较困难，也比较慢。\\n10.5.2 数据标准化（Normalization）\\n在机器学习领域中，数据标准化是一种很常用的数据处理策略。通常就是对输入数据的\\n每个维度的特征进行标准化。具体做法就是所有数据每个维度的特征减去该维度的平均值再\\n除以该维度的标准差。\\n𝑥 − 𝜇\\n@\\n𝑥˝ = (10.2)\\n@\\n√𝜎# + 𝜖\\n𝑥 为某个特征维度的第 n 个值，𝜇为该维度的平均值，𝜎为该维度的标准差，𝜖为一个接近\\n@\\n于0 的常数防止分母为 0。如图10.14 所示。\\n图10.14 数据标准化\\n图中a有5 个数据，每个数据有4 个特征，每个特征的大小不一，经过标准化处理以后\\n得到b，b中的数据都是在0 附近的一些值，数值大小差不多。经过标准化以后的数据 b每\\n个特征的均值都是0，方差为1。标准化以后的数据可以消除特征尺度（有些特征数值比较\\n大，有些特征数值比较小）对于模型训练的影响。并且 a中特征之间的相关系数和b中特征\\n之间的相关系数是一样的。特征之间的相关系数不会因为标准化而改变。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 331, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 332\\n10.5.3 Batch Normalization 模型训练阶段\\n我们了解深度学习模型存在的ICS 问题后，BN 作者提出了对神经网络每一层数据进行标\\n准化处理的策略。普通的数据标准化只是对输入的样本数据进行标准化处理，然后再放入模\\n型进行训练。而BN 是对网络每一层的输入特征进行标准化处理，使得每一层的每个输入特\\n征都是均值为0，方差为1 的分布。每一层标准化的公式都如同公式10.2。\\n在计算网络每一层的每个信号的均值和标准差的时候，我们并不是一次性把所有数据都\\n传入模型进行计算。因为计算机内存大小有限，所以我们训练模型的时候通常都是对数据进\\n行分批次mini-batch的训练。所以这里每层信号计算的均值和标准差都是针对一个批次\\nmini-batch来说的，所以这个算法的名字是Batch Normalization。\\n不过我们对每一层的输入信号做标准化处理可能会改变该层数据的表达。因为标准化处\\n理会把一组数据变成另一组数据，每一组数据所包含的信息都是不同的，所以不能做完标准\\n化处理就完事了。因此作者还对标准化后的数据进行了线性变换的处理：\\n𝑦((cid:131)) = 𝛾((cid:131))𝑥˝((cid:131)) + 𝛽((cid:131)) (10.3)\\n𝑥˝((cid:131))表示网络某一层第k 维度进行标准化后的数值，𝑦((cid:131))表示𝑥˝((cid:131))线性变换后的结果，𝛾((cid:131))\\n和𝛽((cid:131))表示网络某一层第k 维度的两个参数。使用𝛾((cid:131))和𝛽((cid:131))这两个参数可以对数据进行线性\\n变换。每一层网络的每一个维度都会有不同的𝛾和𝛽，𝛾和𝛽的具体数值是由网络训练得到的，\\n不是人为设置的。\\n比如网络某一层某个特征x，该特征的mini-batch计算得到的平均值是𝜇，标准差是𝜎。\\nx进行标准化后得到𝑥˝，𝑥˝经过线性变换后得到y。那么有一个比较特别的结果，当𝛾 = 𝜎，并\\n且𝛽 = 𝜇时线性变换后的结果y 刚好等于标准化之前的特征x。也就是作者设计的线性变换的\\n计算实际上是可以恢复原始数据的表达的，不过一般不会这么巧，毕竟𝛾和𝛽是通过模型训练\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 332, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 333\\n得到的。不管怎么说，𝛾和𝛽还是可以一定程度上起到恢复数据表达能力的作用。每层数据标\\n准化和线性变换的计算流程如图10.15 所示。\\n图 10.15 BN 计算流程[5]\\n图中内容就是我们前面讲的流程，先对数据进行标准化，然后再做线性变换。\\n10.5.4 Batch Normalization 模型预测阶段\\n模型训练阶段我们已经介绍完了，主要就是对每一层数据进行标准化处理和线性变换后\\n再传入下一层，模型训练好之后我们就把每一层每个维度的𝛾和𝛽训练好了。那么在模型预测\\n阶段我们也要对每一层的特征进行标准化处理，不过在测试阶段我们可能只传入一个数据进\\n行预测，只有一个数据的话计算均值和标准差就没有意义了。所以在模型测试阶段使用的均\\n值和标准差的数据其实是使用训练集数据计算得到的。\\n在模型训练阶段，我们会分批次训练模型，每一个批次在网络的每一层的每个特征都可\\n以计算出该批次的特征均值𝜇和特征方差𝜎#。我们在训练阶段把所有批次的特征均值和特征\\n方差都保存下来，然后计算出所有特征均值的均值𝐸[𝜇]和所有特征方差的均值𝐸[𝜎#]，再把\\n𝐸[𝜇]和𝐸[𝜎#]应用到预测阶段的标准化计算中。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 333, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 334\\n每一层的特性𝑥先减去用训练集数据计算得到的均值𝐸[𝜇]，再除以用训练集数据计算得到\\n的标准差g𝐸[𝜎#]+𝜖，再做线性变换乘以𝛾加上𝛽，公式如下：\\n𝑥 − E[𝜇]\\n𝑦 = 𝛾 + 𝛽 (10.4)\\ng𝐸[𝜎2] + 𝜖\\n10.5.5 Batch Normalization 作用分析\\n在BN 的原始论文中作者总结了BN 的很多作用，不过我觉得BN 的主要作用可以简化的\\n总结为：\\n1.加快模型训练速度。这个作用不需要多说，加快模型训练速度可以节约很多模型训练\\n的时间。\\n2.具有一定正则化作用。使用了BN 可以减少Dropout的使用，甚至不用Dropout，并\\n且可以减少L2 正则化的使用。\\n3.有机会使得模型效果更好。这个效果不是绝对的，不过很多模型使用了 BN 之后效果确\\n实变得更好了，所以BN 值得一试。\\n在《Batch Normalization: Accelerating Deep Network Training by Reducing\\nInternal Covariate Shift》论文中，还使用了 ImageNet数据集对BN 的效果做了一些实验\\n分析，如图10.16 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 334, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 335\\n图 10.16 BN 实验分析[5]\\n图中的准确率是使用ImageNet验证集计算得到的，由于这里计算的是Top1 准确率，\\n所以这些模型都没有到80%。\\nInception就是GoogleNet，学习率为0.0015。这个模型差不多是当时最好的图像识别\\n模型了。\\nBN-Baseline 为加上了BN 的Inception，其它训练参数一致。我们可以看到，加上BN\\n后模型训练速度快了很多。\\nBN-x5 跟BN-Baseline 结构一样，只不过学习率是 Inception的5 倍，为0.0075。我\\n们可以看到，学习率变大以后，模型训练得更快了。（如果没有使用 BN 的话，学习率不能\\n设置得太大，会使得模型调整太剧烈，导致模型无法训练或者训练的效果不好）\\nBN-x30，跟BN-Baseline 结构一样，只不过学习率是Inception的30 倍。我们可以看\\n到更大的学习率不能使得模型更快，虽然加上 BN 以后学习率可以设置得大一些，但是也不\\n能太大。\\nBN-x5-Sigmoid跟BN-x5 类似，只不过激活函数用的是 Sigmoid函数（其它模型都是\\n用ReLU函数）。不用BN 的话Sigmoid在GoogleNet中是无法使用的，由于梯度消失会\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 335, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 336\\n使得模型无法训练。用了BN 以后连Sigmoid函数也work 起来了，虽然最后的模型效果还\\n是不太理想。\\nSteps to match Inception 表示这几个模型达到同一准确率的位置。\\n几个模型的训练结果如图10.17 所示。\\n图10.17 几个模型训练结果[5]\\n图中的Model 表示模型；Mac accuracy表示最大准确率。\\n从模型训练结果可以看出加上了BN 的模型训练速度都比较快。训练结果最好的是 BN-\\nx30，最差的是BN-x5-Sigmoid，说明给模型加上BN 以后有可能会得到更好的结果。\\nBN 的作者融合了6 个BN-x30 模型，在ImageNet的验证集得到了4.9%的Top5 错误\\n率，在测试集得到了4.82%的Top5 错误率，在当时应该是ImageNet数据集最好的结果\\n了。\\n10.6 ResNet\\nResNet是2015 年ImageNet Challenge 图像识别比赛的冠军，由微软亚洲研究院\\n(MSRA)的研究团队完成，团队的负责人为何恺明。ResNet的论文获得了2016 年\\nCVPR(IEEE Conference on Computer Vision and Pattern Recognition)的最佳论文，并\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 336, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 337\\n且是2019 年机器学习领域被引用次数最多的论文，达到了 18000 多次。下面对ResNet的\\n思路进行介绍，主要是参考论文《Deep Residual Learning for Image Recognition》[6]。\\n10.6.1 ResNet背景介绍\\n在介绍ResNet网络之前我们先介绍一下何恺明，因为他是目前计算机视觉领域最知名\\n最活跃的专家之一，其代表作ResNet更是一鸣惊人。\\n何恺明在广州长大，从小就是好学生，2003 年保送清华大学。即便如此他还是参加了广\\n东省高考，得到了900 分满分的成绩。\\n2007 年何恺明进入微软亚洲研究院(MSRA)的视觉计算组实习，实习导师是孙剑（现旷\\n视科技首席科学家），当时视觉计算组的负责人是汤晓鸥（商汤科技创始人）。\\n2011 年香港中文大学博士毕业后正式加入 MSRA 。\\n2016 年8 月，何恺明离开微软亚洲研究院，加入Facebook AI 研究院（FAIR）。\\n2020 年1 月11 日，荣登AI全球最具影响力学者榜单。\\n观察ImageNet Challenge 前几届的优秀模型，我们不难发现一个现象，似乎模型的层\\n数越多，效果就越好。AlexNet有8 层，VGG19 有19 层，GoogleNet有22 层。于是\\nResNet团队就做了一个实验，他们模仿VGGNet的模型，分别设计了20，32，44，56 层\\n的网络，并使用CIFAR-10 数据集进行测试，测试结果如图10.18 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 337, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 338\\n图10.18 不同深度的网络结果对比\\n图中的iter 表示迭代次数，error 表示误差。\\n《Deep Residual Learning for Image Recognition》论文中把模仿VGGNet做出来的\\n一些模型称为“plain network”。实验结果表明，20 层的网络误差最低，56 层的网络误差\\n最高，并且层数越多误差越大，实验结果刚好是跟我们前面的猜想是相反的。\\n网络层数不是太多的时候，模型的正确率确实会随着网络的层数增加而提升，不过随着\\n网络层数的增加，正确率也会达到饱和，这个时候如果再继续增加网络层数，那么正确率就\\n会下降。ResNet论文中把这种现象称为退化问题（Degradation Problem），并且\\nResNet作者认为退化问题不是由过拟合引起的。\\n10.6.2 残差块（Residual Block）介绍\\nResNet之所以叫残差网络（Residual Network），是因为ResNet是由很多残差块\\n（Residual Block）组成。而残差块的使用，可以解决前面说到的退化问题。残差块如图\\n10.19 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 338, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 339\\n图10.19 残差块（Residual Block）[6]\\n图中的weight layer 是3×3 的卷积层，F(x)表示经过两个卷积层计算后得到的结果，\\nidentity 表示“恒等映射”也称为“shortcut connections”，说白了就是把x的值不做任\\n何处理直接传过去。最后计算F(x)+x，这里的F(x)跟x是shape相同的信号，所以可以进行\\nelement-wise addition，也就是对应位置进行相加。\\n图10.20 也是相同的残差块，加上了 BN 层。\\n图10.20 加上BN 层的残差块\\n图中的Conv表示卷积；Batch Norm 表示批量标准化。\\n残差块可以有多种设计方式，比如改变残差块中卷积层的数量，或者残差块中卷积窗口\\n的大小，或者卷积计算后先ReLU后BN，就像是搭积木一样，我们可以随意设置。ResNet\\n研究团队经过很多的测试最终定下了两种他们觉得最好的残差块的结构，如图 10.21 所示。\\n图 10.21 两种残差块结构[6]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 339, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 340\\n图中的1×1，3×3 表示卷积窗口大小，64 和256 表示特征图数量，注意这里的图片是\\n作者给出的示意图，真正搭建模型的时候特征图数量不一定是图中的 64 和256。图中左边\\n的残差结构有2 个卷积层前面我们已经见过，右边的残差结构有 3 个卷积层，加上BN 层后\\n如图10.22 所示。\\n图10.22 3 层残差结构\\n图中的Conv表示卷积；Batch Norm 表示批量标准化。\\nResNet也有很多个版本，比如ResNet18，ResNet34，ResNet50，ResNet101，\\nResNet152 等，不同的数字表示不同的网络层数，18 就是18 层，152 就是152 层。作者\\n在搭建不同版本的ResNet的时候使用了不同的残差结构，ResNet18 和ResNet34 用的是\\n2 层卷积的残差结构，ResNet50，ResNet101，ResNet152 用的是3 层卷积的残差结构。\\n残差结构的主要作用是传递信号，把深度学习浅层的网络信号直接传给深层的网络。深\\n度学习中不同的层所包含的信息是不同的，一般我们认为深层的网络所包含的特征可能对最\\n后模型预测更有帮助，但是并不是说浅层的网络所包含的信息就没用，深层网络的特征就是\\n从浅层网络不断提取而得到的。现在我们给网络提供一个“捷径”也就是“shortcut\\nconnections”，它可以直接将浅层信号传递给深层网络，跟深层网络的信号结合，来帮助\\n网络得到更好的效果。\\n10.6.3 ResNet网络结构\\n图10.23 中有 3 个网络结构，左边为VGG19，中间为模仿VGGNet设计的34 层plain\\nnetwork，右边为 ResNet34。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 340, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 341\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 341, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 342\\n图10.23 ResNet网络结构[6]\\n图中的conv 表示卷积；pool 表示池化；fc 表示全连接层；avg pool 表示平均池化；\\noutput size 表示输出大小；image 表示图片。\\nVGG19 和 plain network 大家自己看看就行，仔细看看就能看懂。plain network 中有\\n个地方要注意，plain network 没有使用pooling 层（池化层不一定要使用）。在网络中有\\n几个位置我们可以看到“7×7conv，64，/2”，“3×3conv，128，/2”，“3×3conv，\\n256，/2”，“3×3conv，512，/2”。这里的 7×7 和3×3 表示卷积窗口大小；\\n65/128/256/512 表示卷积后生成多少特征图；/2 表示卷积的步长为2，卷积后特征图的长\\n宽都会变为原来的1/2。最后的avg pool 为平均池化，是模仿GoogleNet的设计。\\n我们重点来看看ResNet34，ResNet34 是从34 层的plain network 改进得来的，结构\\n上跟34 层的plain network 非常相似。主要区别是ResNet34 增加了“shortcut\\nconnections”，由 16 个2 层的残差结构堆叠而成。不过我们发现“shortcut\\nconnections”分为实线和虚线，实线表示残差结构的输入x与残差结构中卷积计算结果\\nF(x)的shape是一样的，可以直接进行对位相加，具体例子如图10.24 所示。\\n图10.24 实线“shortcut connections”例子\\n图中的Conv表示卷积；Batch Norm 表示批量标准化，batch表示批次。\\n虚线“shortcut connections”表示无法直接进行对位相加的接连。我们可以发现虚线\\n部分的残差块输入x和残差结构中卷积计算结果F(x)的shape是不一致的，输入x的特征图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 342, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 343\\n数量是F(x)特征图数量的1/2，并且输入x的特征图长宽是F(x)特征图长宽的2 倍。虚线\\n“shortcut connections”在ResNet论文中给出了A，B 两种连接方式。\\nA．zero-padding。先做步长为 2 的恒等映射，新增的特征图用0 填充。ResNet一般\\n不用这种方式，论文中没有写明白具体的操作，网上的资料也比较少，所以下面 zero-\\npadding的操作主要来自我的推测，如图10.25 表示1 张特征图进行步长为2 的Identity\\nmapping：\\n图10.25 步长为2 的恒等映射\\n图中的Identity表示恒等映射，Stride 表示步长。\\n图10.26 表示多张特征图步长为 2 的恒等映射，特征图变成原来的2 倍，新增的特征图\\n用0 填充：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 343, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 344\\n图10.26 Identity mapping+zero-padding\\n图中的Identity表示恒等映射。\\n图10.27 表示 zero-padding的“shortcut connections”在ResNet中使用的具体例\\n子：\\n图10.27 zero-padding\\n图中的Conv表示卷积；Batch Norm 表示批量标准化；batch表示批次；Identity\\nmapping表示恒等映射。\\nZero-padding的好处是计算简单并且不需要给网络增加额外的权值，同时也可以得到较\\n好的效果。\\nB．projection shortcut。ResNet作者把第二种方式称为“projection shortcut”，\\n具体做法是用步长为2，大小为1×1 的卷积来对残差块的输入信号x进行特征提取，使x信\\n号和F(x)信号的shape一致。ResNet通常都是使用projection shortcut的方法，如图\\n10.28：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 344, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 345\\n图10.28 步长为2，1×1 卷积\\n图中的conv 表示卷积。\\n图10.29 表示 projection shortcut的“shortcut connections”在ResNet中使用的具\\n体例子：\\n图10.29 projection shortcut\\n图中的Conv表示卷积；Batch Norm 表示批量标准化；batch表示批次。\\n相比于zero-padding，使用projection shortcut可以让模型获得更好的效果。另外作\\n者还提出了另外一种shortcut连接方案“all shortcuts are projections”。\\nC．all shortcuts are projections。顾名思义，也就是ResNet中所有的shortcuts，\\n不管是没有特征图数量增加的实线shortcut，还是有特征图数量增加的虚线shortcut，都使\\n用带1×1 卷积的projection shortcut来进行连接。\\nResNet作者使用imagenet数据集对A，B，C三种shortcut方式进行了评估，结果如\\n图10.30 所示。\\n图10.30 三种shortcut方式评估[6]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 345, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 346\\n图中的model 表示模型；top-1 err.表示top1 错误率；top-5 err.表示top5 错误率。\\n图中的ABC分别表示前面我们提到的三种 shortcut方式，ResNet-50，ResNet-101，\\nResNet-152 用的是B(projection shortcut)的方式。我们从实验结果可以看出，C方案比B\\n方案稍微好一点点，B 方案比A方案稍微好一点点。C方案需要给网络增加较多的计算量和\\n权值参数，B 方案需要给网络增加一点计算量和权值参数，C方法不需要额外的权值参数。\\nResNet作者基于综合情况考虑，最终选择在模型中使用了B 方案。所以我们现在看到的\\nResNet模型一般都是使用B(projection shortcut)的方式，一般的残差块都是identity\\nmapping恒等映射，只有特征图数量改变的时候使用 projection shortcut。\\nResNet团队最终在2015 年ImageNet Challenge 图像识别比赛中，融合了6 个不同\\n深度的ResNet模型，得到了3.57%的 top5 测试集错误率，获得了当年比赛的冠军。图\\n10.31 为不同模型的测试结果。\\n图10.31 不同模型的测试结果[6]\\n图中的method表示模型，top-5 err. (test)表示测试集top5 错误率。\\n10.6.4 ResNet-V2\\n2016 年，何恺明所在的 ResNet团队又发表了一篇关于ResNet的论文《Identity\\nMappings in Deep Residual Networks》。在这篇论文中，他们提出了一种关于ResNet\\n的结构优化，并表示新的ResNet结构可以让ResNet获得更好的效果。我们一般把\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 346, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 347\\n《Identity Mappings in Deep Residual Networks》[7]这篇论文中提到的ResNet结构称\\n为ResNet-V2，如图 10.32 所示。\\n图 10.32 残差结构优化[7]\\n图中的Iterations表示迭代次数；Test Error表示测试集错误率。\\n(a)original 表示原始的 ResNet的残差结构，(b)proposed表示新的ResNet的残差结\\n构。主要差别就是(a)结构先卷积后进行 BN 和激活函数计算，最后执行addition 后再进行\\nReLU计算；(b)结构先进行BN 和激活函数计算后卷积，把addition后的ReLU计算放到了\\n残差结构内部。作者使用这两种不同的结构在 CIFAR-10 数据集上做测试，模型用的是 1001\\n层的ResNet模型。从图中结果我们可以看出，(b)proposed的测试集错误率明显更低一\\n些，达到了4.92%的错误率，(a)original 的测试集错误率是7.61%。\\n其实ResNet团队对ResNet的残差结构做了很多不同的尝试，如图10.33 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 347, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 348\\n图10.33 shortcut结构的不同尝试[7]\\n图中(a),(b),(c),(d),(e),(f)都是作者对残差结构的shortcut部分进行的不同尝试，这里我\\n们就不具体介绍了，因为作者对不同shortcut结构的尝试结果如图10.34 所示。\\n图10.34 不同 shortcut结构的测试结果[7]\\n作者用不同shortcut结构的ResNet-110 在CIFAR-10 数据集上做测试，发现最原始的\\n(a)original 结构是最好的，也就是 identity mapping恒等映射是最好的。\\n然后作者又对残差结构的残差单元进行了不同的尝试，如图 10.35 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 348, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 349\\n图10.35 不同残差单元测试结果[7]\\n最好的结果是(e)full pre-activation，其次到(a)original。(a)original 的残差结构是应用\\n在最原始的ResNet中的残差结构；(e)full pre-activation 的残差结构就是我们前面介绍的\\nResNet-V2 中的残差结构。\\n从ResNet的设计和发展过程中我们可以知道，深度学习是一门非常注重实验的学科，\\n我们需要有创新的好想法，同时也需要大量的实验来支撑和证明我们的想法。有些时候我们\\n无法从理论上推断哪种模型设计或优化方法是最好的，这个时候我们可能就需要做大量的实\\n验来不断尝试，找到最好的结果。如今 ResNet已经得到广泛的应用和肯定，对深度学习和\\n计算机视觉做出了重要贡献。\\n经典图像识别模型介绍下一章继续。\\n10.7 参考文献\\n[1] Russakovsky O , Deng J , Su H , et al. ImageNet Large Scale Visual Recognition\\nChallenge[J]. International Journal of Computer Vision, 2015, 115(3):211-252.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 349, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 350\\n[2] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n[3]Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for\\nLarge-Scale Image Recognition[J].\\n[4]Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n[5] Ioffe S , Szegedy C . Batch Normalization: Accelerating Deep Network Training by\\nReducing Internal Covariate Shift[J]. 2015.\\n[6] He K , Zhang X , Ren S , et al. Deep Residual Learning for Image Recognition[C]//\\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE\\nComputer Society, 2016.\\n[7] He K , Zhang X , Ren S , et al. Identity Mappings in Deep Residual Networks[J].\\n2016.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 350, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 351\\n第 11 章-经典图像识别模型介绍（下）\\n这一章节我们继续介绍经典图像识别模型。\\n11.1 Inception 模型系列\\nInception的前身就是前面我们介绍过的 GoogleNet，GoogleNet中提出了一个多种尺\\n度同时进行特征提取的结构称为Inception，所以GoogleNet后来改名变成了Inception-\\nv1。Google 的团队后来在Inception-v1 的基础上做了更多的研究和优化，提出了\\nInception-v2，Inception-v3，Inception-v4，Inception-ResNet-v1，Inception-\\nResNet-v2 多个优化版本。\\n11.1.1 Inception-v2/v3 优化策略\\nInception-v2 和Inception-v3 都出自同一篇论文《Rethinking the inception\\narchitecture for computer vision》[1]。该论文提出了多种基于Inception-v1 的模型优化\\n方法，Inception-v2 用了其中的一部分模型优化方法，Inception-v3 用了论文中提到的所有\\n优化方法。相当于Inception-v2 只是一个过渡版本，Inception-v3 一般用得更多。下面我\\n们主要针对论文中所涉及的一些比较重要的优化方法进行讲解，具体是用在 Inception-v2 还\\n是Inception-v3 就不做详细区分了，可以都看成是 Inception-v3 的内容。顺便说一下之前\\n我们学过的标签平滑（Label Smoothing）就是出自Inception-v3 的论文。\\nInception-v3 最大的优化是模型结构上的优化，在 Inception-v3 中作者对Inception结\\n构中的卷积进行了分解。分解后的好处是增加了网络的层数，也就是增加了网络的特征提取\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 351, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 352\\n能力。同时作者还对Inception结构进行了一些调整，设计了不同的 Inception，用在模型\\n的不同位置。\\n我们先回忆一下最原始的Inception结构，如图11.1 所示。\\n图11.1 原始Inception结构[1]\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\npooling 表示最大池化，previous layer 表示前一层。\\nInception-v3 中提出了一个新思路，可以使用两个 3×3 卷积来替代原始Inception结构\\n中的5×5 卷积，如图11.2 所示。\\n图11.2 分解5×5 卷积\\n将5×5 卷积分解为两层的3×3 卷积，对于最后得到的特征来说，感受野的大小是相同\\n的，都是5×5 的区域。相当于5×5 卷积对 5×5 区域进行特征提取，得到一个特征值；两层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 352, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 353\\n的3×3 卷积对5×5 区域进行特征提取，也是得到一个特征值。这两种特征提取的方式类\\n似，不过最后得到的特征值可能是不同的，右边的两层 3×3 卷积做了两次卷积得到的特征值\\n或许会更好一些。\\n沿着这个卷积分解的思路继续思考，作者又提出了一种新的卷积分解，把 3×3 卷积分解\\n为1×3 卷积和3×1 卷积，如图11.3 所示。\\n图11.3 分解3×3 卷积\\n把3×3 卷积分解为1×3 卷积和3×1 卷积，道理跟将5×5 卷积分解为两层的3×3 卷积\\n差不多，对于最后的特征来说，感受野的大小是一样的，并且分解后可以让网络层数变得更\\n多，增加网络的非线性。理论上n×n 的卷积都可以分解为1×n 卷积和n×1 卷积。\\n作者还分析了减小特征图大小时的操作，如图 11.4 所示。\\n图11.4 减小特征图大小的操作[2]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 353, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 354\\n图片Pooling 表示池化。\\n作者认为直接使用窗口大小2×2，步长为2 的池化来压缩特征图的大小效果不太好。因\\n为特征图的数量不变，但是特征图的长宽变成为原来的 1/2，相当于特征值的数量被压缩为\\n原来的1/4 了，特征值的数量一下减少太多不利于模型的训练，所以左边的结构不太理想。\\n右边的结构先用Inception来增加特征图数量然后再进行池化减小特征图大小，对于特征的\\n提取来说没什么问题，就是计算量太大。\\n所以设计了新的Inception结构，在减小特征图大小的同时可以增加特征图的数量，如\\n图11.5 所示。\\n图11.5 用于减小特征图大小并增加特征图数量[2]\\n图中Filter Concat表示滤波器拼接；stride表示步长；concat表示拼接；conv 表示卷\\n积；pool 表示池化。\\n除此之外作者还根据实验分析和建模经验，设计了一些新的 Inception结构，如图11.6\\n所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 354, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 355\\n图11.6 一些新的Inception结构[2]\\n图中Filter Concat表示滤波器拼接；Pool表示池化。\\n这些不同的Inception结构就像搭积木一样堆叠起来，组成了 Inception-v3 的模型。\\n11.1.2 Inception-v2/v3 模型结构\\nInception-v2/v3 模型的结构非常庞大，Inception-v2/v3 论文中给出的模型结构描述也\\n不是特别清晰，结构如图11.7 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 355, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 356\\n图11.7 Inception-v2/v3 模型结构[2]\\n图中architecture表示结构；Filter Concat表示滤波器拼接；Pool表示池化；type表\\n示层的类型；patch size/stride or remarks 表示窗口大小/步长；input size 表示输入大\\n小；conv 表示卷积；pool 表示池化；linear表示全连接层。\\n图中Inception-v2/v3 的结构大家应该能大致看懂，但是好像又看不太懂。那么要如何\\n把Inception-v2/v3 结构在书里表示清楚，让大家能看懂，我想了很久。其实要把\\nInception-v2/v3 结构图画出来不难，难的是怎么在书里画出来，书这个信息载体对长图片\\n的支持不太友好。最后我想到了一个比较清晰简洁，在书里看起来也相对比较友好的画结构\\n图的方法——“方块构图法”（我瞎起的名字）。我画的这个结构跟论文中描述的结构细节\\n上有些许不同，我是参考tensorflow.keras.applications.inception_v3中的结构画的，\\nInception-v2/v3 结构图如图11.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 356, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 357\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 357, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 358\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 358, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 359\\n图11.8 Inception-v2/v3 结构图\\n图中的Conv表示卷积；MaxPool表示最大池化；AvgPool表示平均池化；Concat表\\n示拼接；FC 表示全连接层；V 表示Valid Padding。\\n相信这个结构图大家应该是很容易看懂的，我只需要稍微提几个注意事项：\\n1. 图中卷积和池化默认的步长是 1 所以没有写出来。如果有“/2”表示步长为2。\\n2. 图中卷积和池化默认都是 same padding 所以没有写出来。如果有“V”表示 valid\\npadding。\\n3. 每个卷积层后面有BN 和ReLU，图中省略了。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 359, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 360\\n4. Inception-ABCD 表示论文中提到的几种不同类似的 Inception 模型，不过并不是跟\\n论文中完全一致。\\n最后我们来看一下Inception-v3 在ImageNet数据集中的测试结果，图11.9 为\\nInception-v3 单模型测试结果。\\n图11.9 Inception-v3 单模型测试结果[2]\\n图中Network 表示网络；Crops Evaluated表示模型评估时裁剪出多少张图片进行预\\n测；Top-5 Error表示Top5 错误率；Top-1 Error表示Top1 错误率。\\n图11.10 为 Inception-v3 模型融合后的测试结果。\\n图11.10 Inception-v3 模型融合后测试结果[2]\\n图中Network 表示网络；Models Evaluated表示评估时集成了几个模型；Crops\\nEvaluated表示模型评估时裁剪出多少张图片进行预测；Top-5 Error表示Top5 错误率；\\nTop-1 Error表示Top1 错误率。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 360, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 361\\nInception-v3 模型融合后的Top5 错误率为3.58%，这个结果跟2015 年ImageNet\\nChallenge 图像识别比赛的冠军ResNet已经非常接近，ResNet的Top5 错误率为\\n3.57%。\\n11.1.3 Inception-v4 和 Inception-ResNet介绍\\nInception-v3 结构的复杂程度以后够复杂了，但是它还有几个升级版本，就是\\nInception-v4，Inception-ResNet-v1 和Inception-ResNet-v2。这几个升级版本都出自同\\n一篇论文《Inception-v4, Inception-ResNet and\\nthe Impact of Residual Connections on Learning》[3]。\\n这几个升级版的Inception模型基本设计思路都是遵循 Inception-v3 的设计思路，只不\\n过比Inception-v3 再稍微更复杂一些。Inception-v4 的作者不认同非常深层的网络一定要\\n使用残差单元才行，所以他们设计了没有使用残差单元的深度网络 Inception-v4，我大概数\\n了一下论文中的Inception-v4 结构，应该是有 76 层。不过Inception-v4 的作者认同加上\\n残差单元以后，模型可以训练得更加快一些。\\nInception-ResNet-v1 和Inception-ResNet-v2 顾名思义就是Inception的设计加上\\nResNet的残差结构设计得到的模型。\\n由于Inception-v4，Inception-ResNet-v1 和Inception-ResNet-v2 的结构设计跟\\nInception-v3 差别不大，并且使用一次“方块构图法”消耗的体力太多，所以这几个模型的\\n具体网络结构就不给大家展示了。下面使用论文中的一些图给大家展示一下 Inception-v4 和\\nInception-ResNet-v2 的结构，大家大致看一下即可，图11.11 为Inception-v4 的结构图.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 361, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 362\\n图11.11 Inception-v4 结构图[3]\\n图中的Conv表示卷积；MaxPool表示最大池化；Output表示输出；Input 表示输入；\\nFilter concat表示滤波器拼接；Avg Pooling 和Average Pooling 表示平均池化；stride表\\n示步长。\\nInception-v4 延续了Inception-v3 的设计并进行了一些优化，主要也是使用多个不同的\\nInception结构堆叠得到深层的网络模型。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 362, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 363\\n图11.12 为 Inception-ResNet-v2 结构图。\\n图11.12 Inception-ResNet-v2 结构[3]\\n图中的Conv表示卷积；MaxPool表示最大池化；Output表示输出；Input 表示输入；\\nFilter concat表示滤波器拼接； Average Pooling 表示平均池化；stride表示步长。\\nInception-ResNet-v2 的结构特殊之处就是把Inception和残差单元的设计结合到了一\\n起变成了Inception-resnet模块。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 363, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 364\\n图11.13 为 4 个Inception模型在ImageNet数据集中，单模型Top5 错误率的测试结\\n果。\\n图11.13 4 种Inception模型在ImageNet数据集测试结果[3]\\n图中的Epoch表示训练周期；Error表示误差。\\n从图中我们可以看到Inception-v3 和Inception-ResNet-v1 效果是差不多的，可能\\nInception-ResNet-v1 稍微好一点点。Inception-v4 和Inception-ResNet-v2 效果是差不\\n多的，可能Inception-ResNet-v2 稍微好一点点。\\n图11.14 为几个模型在 ImageNet数据集中单模型测试结果。\\n图11.14 几个不同模型的单模型测试结果[3]\\n图中的Network 表示网络；Crops表示从一张图片中裁剪出多少张图片；Top-1 Error\\n表示Top1 错误率；Top-5 Error表示Top5 错误率。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 364, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 365\\nCrops中的dense表示直接对一张测试图片进行预测，得到一个预测结果。Crops中的\\n144 表示从一张测试图片中按照一定的规则裁剪出144 个子区域，然后对这144 个区域分别\\n进行预测得到144 个预测结果，最后再对这144 个预测结果求平均得到最终的一个预测结果\\n[4]。\\n图11.15 为模型融合的测试结果。\\n图11.15 模型融合的测试结果[3]\\n图中的Network 表示网络；Models 表示集成的模型数量；Top-1 Error表示Top1 错\\n误率；Top-5 Error表示Top5 错误率。\\n使用1 个Inception-v4 和3 个Inception-ResNet-v2 模型进行融合，在ImageNet的\\n验证集中得到了3.1%的Top5 错误率，在 ImageNet的测试集中得到了3.08%的Top5 错\\n误率，这个结果已经比ResNet的模型融合后的结果更好了。\\n11.2 ResNeXt\\nResNeXt获得了2016 年ImageNet Challenge 图像识别比赛的亚军。是由来自加州大\\n学圣地亚哥分校(UCSD)和Facebook AI Research(FAIR)的团队完成。名字中的“Res”表\\n示“ResNet”，名字中的“NeXt”表示“next dimension”，在ResNeXt的论文中\\n“next dimension”被称为“cardinality dimension”。作者提出把cardinality 作为深度\\n学习网络中的一个新参数，就像是网络的深度（网络的层数），宽度（特征图数量）一样。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 365, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 366\\n最早提出ResNeXt的论文是《Aggregated Residual Transformations for Deep Neural\\nNetworks》[5]。在介绍ResNeXt之前，我们先来了解一下 ResNeXt网络中的核心内容，分\\n组卷积(Group Convolution)。\\n11.2.1 分组卷积（Group Convolution）介绍\\n分组卷积是一种特殊的卷积，最早应该是用在 AlexNet网络中，AlexNet的原始结构分\\n为上下两部分，我们可以看成是上下两个通道或者是上下两个分组，如图 11.16 所示。\\n图 11.16 AlexNet结构[6]\\n图中的Stride 表示步长；Max Pooling 表示最大池化；dense表示全连接层。\\nAlexNet使用分组卷积主要是当时软硬件条件比较受限，AlexNet团队想用两个GPU来\\n加速模型模型，一个GPU运行上面分组的卷积计算，一个GPU运行下面分组的卷积计算。\\n所以在AlexNet中使用这样的分组卷积设计并不是他们的本意，更多的是巧合。不过有实验\\n证明当初AlexNet里面使用分组卷积是正确的设计，使用了分组卷积以后不仅计算量和权值\\n数量减少了，并且模型准确率也提升了一些[5]，实验结果如图11.17 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 366, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 367\\n图11.17 不同分组AlexNet的结果[7]\\n图中的Model Parameters表示模型参数数量；Top-5 Val. Error表示Top5 验证集错\\n误率；groups表示分组数。\\n图中横坐标表示模型的参数数量，纵坐标表示模型错误率，原始的 AlexNet为图中的“2\\ngroups”表示将卷积分为2 组，“no groups”表示不分组，”4 groups”表示将卷积分\\n为4 组。从图中我们可以看到分组越多模型的参数越少，模型的准确率上下会有浮动，不过\\n变化不是很大。这3 个实验结果里将卷积分为 2 组是最好的选择。\\n下面我们正式介绍分组卷积，简单来说分组卷积就是将特征图分为不同的组，再对每组\\n特征图分别进行卷积。这里的分组一般都是分为 n 个等份，理论上其实不是等份也可以，不\\n过一般为了实现方便都是分为等份。分组卷积的好处主要是可以减少模型的计算量和训练参\\n数，同时对模型准确率影响不大，甚至有可能会提高模型准确率。下面我们通过几个图来详\\n细了解一下，图11.18 为普通卷积：.\\n图11.18 普通卷积\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 367, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 368\\n图中的Conv表示卷积。\\n这里特征图的大小和卷积和的大小都不是重点内容，所以图中没有标出，我们只要能看\\n出6 个特征图卷积后得到 12 个特征图就可以了。不过为了让大家理解分组卷积的计算量和\\n权值数量这里我们举例计算一下，假设特征图大小是 28×28，卷积核大小为5×5，Same\\nPadding。卷积层权值数量为 5×5×6×12+12=1812，乘法计算量为5×5×28×28×6×\\n12=1411200。\\n下面我们看一下分组卷积，分组卷积一般都是把特征图分为 n 个等份，然后再对n 个等\\n份的特征图分别卷积，这里的n 可以人为设置，如图11.19 所示。\\n图11.19 分组卷积\\n图中的Conv表示卷积。\\n为了跟普通卷积对比，所以这里分组卷积的例子输入也是 6 个特征图，输出也是12 个特\\n征图。这里我们可以看到把6 个特征图分为了 3 组，每组2 个特征图，每组分别进行卷积，\\n卷积后得到4 个特征图。最后再把 3 个组共12 个特征图组合起来。假设特征图大小是28×\\n28，卷积核大小为5×5，Same Padding。这里卷积层权值数量为5×5×2×4×\\n3+12=612，乘法计算量为 5×5×28×28×2×4×3=470400。权值数量和计算量都约为普通\\n卷积的1/3。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 368, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 369\\n11.2.2 ResNeXt中的分组卷积\\n这一小节我们主要学习ResNeXt的核心内容，分组卷积在ResNeXt中的使用。\\nResNeXt中提出的一个模型调节的新维度“cardinality”其实就是分组卷积中的分组数量，\\n比如cardinality 为2 表示把卷积分为2 组，cardinality 为32 表示把卷积分为32 组。\\n作者将分组卷积应用到ResNet的残差结构中，如图11.20 所示。\\n图11.20 残差结构中使用分组卷积[5]\\n图中的in 表示输入；out表示输出；d表示dimension，代表维度；total 32 paths表\\n示总共32 个通道。\\n图中左边为ResNet的残差结构，右边是cardinality 为32 的新残差结构。每个格子中\\n的3 个数字分别表示（输入通道数，卷积核大小，输出通道数）。原始的 ResNet的残差结\\n构就不用多说了，ResNeXt中的残差结构也很容易理解，第1 层卷积输入是256 个特征\\n图，输出是4×32=128 个特征图。然后对这128 个特征图进行分组，分为32 组，每组 4 个\\n特征图，在第2 层卷积进行分组卷积计算。第 2 层卷积计算后，每组卷积都是产生4 个特征\\n图。第3 层卷积是对 4 个特征图进行卷积产生256 个特征图。然后再对32 个分组产生的32\\n组每组256 个特征图进行element-wise addition按位相加，最后再加上shortcut恒等映\\n射传过来的信号，得到残差结构的输出。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 369, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 370\\n这里大家可能会有个小疑问，为什么左边原始的残差结构第 1 层卷积输入256 个特征\\n图，产生64 个特征图。而右边的分组卷积残差结构第1 层卷积输入256 个特征图，产生 4×\\n32=128 个特征图。看起来两个残差结构中间部分产生的特征图数量不一致。其实作者之所\\n以这么设计分组卷积特征图的数量主要是为了使得两个残差结构的训练参数的数量大致相\\n同。\\n我们来计算一下图11.20 中左边的残差结构训练参数的数量为（为了计算方便忽略偏置\\n值）：256×64+3×3×64×64+64×256≈70000。右边的分组卷积残差结构参数数量为（为\\n了计算方便忽略偏置值）：C×(256×d+3×3×d×d+d×256) ≈70000，其中C=32表示\\ncardinality 为32，d=4 表示每个分组有4 个特征图。右边的残差结构我们也可以表示为32\\n×4d，意思是32 个分组每组4 个特征图；如果是8×16d表示8 个分组，每组16 个特张\\n图；如果是1×64d表示1 个分组（也就是不分组），每组64 个特张图。在作者的设计下，\\n新的分组卷积残差结构权值数量和计算量跟原始的残差结构差不多，不过最后模型效果可以\\n变得更好。\\n其实在ResNeXt的论文中，作者给出了3 种形式的分组卷积残差结构，这3 种形式的分\\n组卷积残差结构输入信号和输出信号都是一样的，只是中间部分略有不同，如图 11.21 所\\n示。\\n图11.21 3 种形式的分组卷积残差结构[5]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 370, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 371\\n图中的in 表示输入；out表示输出；d表示dimension，代表维度；total 32 paths表\\n示总共32 个通道；group表示分组数；equivalent 表示相等的；concatenate 表示拼接。\\n前面我们已经仔细分析了(a)结构，实际上(b)结构和(c)结构跟(a)结构也是非常类似的。\\n(b)结构是在第2 层卷积输出的位置对 32 组每组4 个特征图进行concatenate，得到了128\\n个特征图。然后再传给第3 层卷积进行计算，最后输出 256 个特征图。(c)结构作者在这里用\\n简化的方式表示分组卷积的计算，注意看(c)结构中有些数字是加粗的，加粗的数字表示跟分\\n组卷积相关。也就是(c)结构的第2 层卷积跟(a)，(b)结构都不一样，(c)的第2 层卷积分为32\\n组，每组输入4 个特征图，输出128 个特征图。然后再对这32 组每组128 个特征图进行\\nelement-wise addition按位相加，之后传给第 3 层卷积。第3 层卷积就是输入128 个特征\\n图，输出256 个特征图。\\n这3 种形式的残差结构作者都进行了实验，发现最后得到的结果基本上都差不多，最终\\n选择了(c)结构。作者认为(c)结构更简单速度也更快。\\n11.2.3 ResNeXt的网络结构\\n了解了ResNeXt中使用的残差结构以后，下面我们来看一下ResNeXt的网络结构，如\\n图11.22 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 371, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 372\\n图11.22 ResNeXt网络结构[5]\\n图中的stage表示阶段；conv 表示卷积；output表示输出；stride表示步长；d表示\\ndimension，代表维度；max pool 表示最大池化；C表示cardinality，代表分组数；\\nglobal average pool 表示全局平均池化；fc 表示全连接；params表示参数数量；FLOPs\\n表示计算量。\\n图中有两个网络的结构，一个是ResNet-50，一个是ResNeXt-50(32×4d)。ResNeXt-\\n50(32×4d)是在ResNet-50 网络结构的基础上对残差结构进行了一些修改得到的，所以这两\\n个模型的结构框架基本是一致的。这个结构图还是很容易看懂的，基本上要讲解的地方不\\n多。ResNeXt-50(32×4d)的残差结构是加上了分组卷积的，(32×4d)表示图中的conv2 中\\n使用的分组卷积是32 个分组每组4 个特征图。ResNeXt的结构一般只需要标明第一个分组\\n卷积残差模块的信息，因为后面conv3，conv4，conv5 中的分组卷积信息都可以由第一个\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 372, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 373\\n分组卷积得到。按照ResNeXt的设计思路，所有的分组卷积cardinality 都是一样的，比如\\n图中的32。conv2 特征图大小是56×56，每组4 个特征图；conv3 特征图大小是28×28，\\n每组8 个特征图；conv4 特征图大小是14×14，每组16 个特征图；conv5 特征图大小是7\\n×7，每组 32 个特征图。\\n图中我们还可以看出ResNet-50 和ResNeXt-50(32×4d)的权值参数数量和浮点计算量\\n都是差不多的。而ResNet-101 和ResNeXt-101(32×4d) 的权值参数数量和浮点计算量也\\n都是差不多的。这4 个模型在ImageNet数据集中的测试结果如图11.23 所示。\\n图11.23 4 个模型准确率对比[5]\\n图中的epochs 表示周期；top-1 error 表示top1 错误率；train 表示训练集；val表示\\n验证集。\\n图中可以看出ResNeXt-50(32×4d)比ResNet-50 要更好，ResNeXt-101(32×4d)比\\nResNet-101 要更好。\\n作者也尝试了一些不同分组的残差模块，测试结果如图 11.24 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 373, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 374\\n图11.24 不同分组的残差网络测试结果[5]\\n图中setting表示结构设置；top-1 error 表示top1 错误率。\\n图中的setting表示模型第一个分组卷积残差模块的分组数和特征图数量，结果看来 32\\n×4d是一个比较好的选择。\\n图11.25 为 ResNeXt使用不同大小的图片跟不同模型在 ImageNet验证集的单模型对\\n比结果：\\n图11.25 不同模型测试结果\\n图中top-1 err 表示top1 错误率；top-5 err 表示top5 错误率。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 374, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 375\\nResNet和ResNeXt使用的是224×224 和320×320 的分辨率图片，Inception相关的\\n模型用的是299×299 的分辨率图片。结果可以看出使用分辨率比较高的图片准确率也会高\\n一些，ResNeXt-101 是上面几个模型中最好的。\\nResNeXt模型融合后在ImageNet测试集得到了3.03%的Top5 错误率，比Inception-\\nv4/Inception-ResNet-v2 的3.08%结果要更好。\\n11.3 SENet\\nSENet是ImageNet Challenge 图像识别比赛 2017 年的冠军，是来自Momenta公司\\n的团队完成。他们提出了Squeeze-and-Excitation Networks（简称SENet）。SENet不\\n是独立的模型设计，只对模型的一种优化。一般 SENet都会结合其它模型一起使用，比如\\nSENet用于ResNet-50 中我们就把这个模型称为 SE-ResNet-50，比如SENet用于\\nInception-ResNet-v2 中我们就把这个模型称为SE- Inception-ResNet-v2。最早提出\\nSENet的论文是《Squeeze-and-Excitation Networks》[8]。\\n11.3.1 SENet 介绍\\n我们之前介绍了很多模型，Inception系列的模型使用不同尺度的卷积大小来提取不同的\\n特征，ResNet给模型增加了捷径更有利于信号传递，ResNeXt使用了分组卷积把特征提取\\n进行分组处理。SENet的模型优化思路很有意思，主要是针对特征的 channel进行优化。\\n我们可以想象在进行图像识别的时候，卷积计算后生成了很多特征图，不同的滤波器会\\n得到不同的特征图，不同的特征图代表从图像中提取的不同的特征。我们得到了这么多的特\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 375, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 376\\n征图，按理来说某些特征图的应该更重要，某些特征图应该没这么重要，并不是所有特征图\\n都一样的重要。所以SENet的核心思想就是给特征图增加注意力和门控机制，增强重要的特\\n征图的信息，减弱不重要的特征图的信息。\\n那么如何做到增强重要的信息，减弱不重要的信息，我们看一下 SENet的名字\\nSqueeze-and-Excitation Networks。其中的“Squeeze”中文意思是“挤压”，在模型中\\n的实际操作其实是压缩特征图的特征，作者使用的压缩特征图的特征的方式是 avg pooling\\n平均池化。这个大家应该很熟悉了，求一个特征图所有值的平均值，把 avg pooling 计算后\\n的结果作为这个特征图压缩后的特征。比如一共有 64 个特征图，“Squeeze”计算后我们\\n就会得到64 个值，代表64 个特征图压缩后的特征。\\n“Excitation”中文意思是“激发”，在模型中的实际操作是调节特征图信号强弱，作者\\n使用的方式是给“Squeeze”计算后的结果加上两个全连接层，最终输出每个特征图对应的\\n激活值，激活值可以改变特征图信号的强弱。每个特征图乘以它所对应的激活值，得到特征\\n图的输出，然后再传给下一层。\\n文字描述很难具体描述清楚，我们还是看图吧，我们先复习一下普通的 ResNet中的残\\n差结构如图11.26 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 376, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 377\\n图11.26 普通残差结构\\n图中的Conv表示卷积；Batch Norm 表示批量标准化；Identity mapping表示恒等映\\n射；batch表示批次。\\n普通的残差结构我们就不需要多说了，下面我们看一下加上了 Squeeze-and-Excitation\\n模块后的残差结构如图11.27 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 377, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 378\\n图 11.27 SE-残差结构\\n图中的Conv表示卷积；Batch Norm 表示批量标准化；Identity mapping表示恒等映\\n射；batch表示批次；AvgPool表示平均池化。\\n加上Squeeze-and-Excitation模块后的残差结构主要变化是在原来的残差结构最后一个\\n卷积层后面进行Squeeze-and-Excitation的操作。Squeeze就是先做平均池化，得到每一\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 378, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 379\\n个特征图的压缩特征。图中特征图大小为 56×56，所以池化的窗口大小也是56×56。池化\\n过后就是Excitation操作，前面我们有提到Excitation操作有两个全连接层，这是SENet\\n原始论文中的做法，实际我们在写程序的时候也可以用两个窗口大小1×1 的卷积层的替代，\\n效果跟全连接是一样的。Excitation操作部分最后的激活函数是Sigmoid函数，作者在这里\\n使用Sigmoid函数主要是利用 Sigmoid函数输出范围是0-1 这个特性，让Excitation的输\\n出激活值可以起到一个门控的作用。Excitation的输出的激活值会乘以原始残差结构最后一\\n个卷积层的输出结果，对特征图的数值大小进行控制。如果是重要的特征图，会保持比较大\\n的数值；如果是不重要的特征图，特征图的数值就会变小。\\nSENet的论文《Squeeze-and-Excitation Networks》中也有一些图一并给大家看看好\\n了，如图11.28 所示。\\n图11.28 Squeeze-and-Excitation block[8]\\n各种符号什么意思我就不解释了，跟我前面介绍的内容差不多，大家随意看看就可以。\\n图11.29 和图11.30 为SE-Inception模块和SE-ResNet模块。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 379, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 380\\n图11.29 SE-Inception模块[8]\\n图中的Global pooling 表示全局池化；W表示图片宽度；H 表示图片高度；C表示图片\\n通道数；FC 表示全连接层；r表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n就是一个超参数，不用细究，一般取值为 16。\\n图11.30 SE-ResNet模块[8]\\n图中的Global pooling 表示全局池化；W表示图片宽度；H 表示图片高度；C表示图片\\n通道数；FC 表示全连接层；r表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n就是一个超参数，不用细究，一般取值为 16。\\nResNet-50，SE-ResNet-50，SE-ResNeXt-50(32×4d)模型结构如图11.31 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 380, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 381\\n图11.31 3 种ResNet模型对比[8]\\n图中的Output size 表示输出大小；conv 表示卷积；max pool 表示最大池化；stride\\n表示步长；fc 表示全连接层；global average pool 表示全局平均池化；C表示分组数。\\n图中𝑓𝑐表示fully connected全连接层，𝑓𝑐后面的两个数字表示SE模块中两个全连接层\\n的输出维度。\\n11.3.2 SENet 结果分析\\n基础模型增加SE模块后会使得整体模型的参数增加10%左右，计算量增加不多，一般\\n来说模型的效果也会有所提升。作者使用多个模型在 ImageNet数据集上进行了测试，图\\n11.32 为多个模型在 ImageNet验证集测试结果。\\n图11.32 多个模型测试结果[8]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 381, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 382\\n图中original 表示模型原始论文中的结果；re-implementation 表示SENet作者重新训\\n练模型的结果；SENet表示给这些模型加上 SE模块后的结果；top-1 err.表示top1 错误\\n率；top-5 err.表示top5 错误率；GFLOPs表示计算量。\\n图中结果可以看出，图中测试的所有模型只要加上 SE模块，错误率都能降低，并且模型\\n浮点计算量没有太大变化。图11.33 和图 11.34 也能看出加上SE模块后模型效果可以变得\\n更好：\\n图11.33 加上 SE模块后的模型结果对比1[8]\\n图中的epochs 表示周期；Top-1 error 表示Top1 错误率；train 表示训练集；val表示\\n验证集。\\n图11.34 加上 SE模块后的模型结果对比2[8]\\n图中的epochs 表示周期；Top-1 error 表示Top1 错误率；train 表示训练集；val表示\\n验证集。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 382, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 383\\nSENet论文的最后，作者还给了一组很有意思的图。作者用 ImageNet数据集训练了一\\n个SE-ResNet-50，然后选出4 个种类(goldfish,pug,plane,cliff)的图片，统计这4 个种类在\\nSE-ResNet-50 模型的每个SE模块的特征图的激活情况，如图 11.35 所示。\\n图11.35 不同SE模块的激活情况[8]\\n图中的all 表示所有1000 个种类的平均值；goldfish表示金鱼；pug表示哈巴狗；\\nplane 表示飞机；cliff表示悬崖；channel index 表示通道；activation 表示激活值。\\n作者观察实验结果得到3 个结论：\\n第一，不同种类的物体在浅层激活分布情况是类似的，如图中的 SE_2_3 和SE_3_4。也\\n就是不管是识别哪种物体，浅层的卷积层中，重要的特征图总是比较固定的那些。\\n第二，在更深层一些的位置，不同种类在不同的特征图激活分布不同，因为不同类别对\\n特征有不同的偏好，如图中的SE_4_6 和SE_5_1。低层特征通常更普遍，识别不同种类物体\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 383, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 384\\n可以使用类似的滤波器，而高层特征通常包含更多细节，识别不同种类物体需要使用不同的\\n滤波器。\\n第三，在模型的最后阶段，SE_5_2 呈现出饱和状态，其中大部分激活值都接近于1，也\\n有一些接近于0。对于激活值为1 的特征图，相当于SE模块不存在。在网络的最后一个SE\\n模块SE_5_3，不同种类有着类似的分布，只是尺度不同。也就是说SE_5_2 和SE_5_3 相对\\n来说没有前面的一些SE模块重要，作者通过实验发现删除最后一个阶段的SE模块，总体参\\n数可以显著减少，性能只有一点损失(<0.1%的Top1 错误率)。\\n下一章节我们将介绍经典图像识别模型的代码实现，以及如何使用这些模型进行图像识\\n别。\\n11.4 参考文献\\n[1] Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n[2] C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna. Rethinking the inception\\narchitecture for computer vision. arXiv preprint arXiv:1512.00567, 2015.\\n[3] Szegedy C , Ioffe S , Vanhoucke V . Inception-v4, Inception-ResNet and the\\nImpact of Residual Connections on Learning[J]. 2016.\\n[4] Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for\\nLarge-Scale Image Recognition[J].\\n[5] Xie S , Girshick R , Dollár, Piotr, et al. Aggregated Residual Transformations for\\nDeep Neural Networks[J]. 2016.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 384, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 385\\n[6] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n[7] Ioannou Y , Robertson D , Cipolla R , et al. Deep Roots: Improving CNN Efficiency\\nwith Hierarchical Filter Groups[J]. 2016.\\n[8] Hu J , Shen L , Albanie S , et al. Squeeze-and-Excitation Networks[J]. IEEE\\nTransactions on Pattern Analysis and Machine Intelligence, 2017.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 385, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 386\\n第 12 章-图像识别项目实战\\n本章节内容主要是针对第10，11 章节经典图像识别模型的程序实现，理论部分就不再重\\n复了，直接上代码。注意代码实现不一定跟原始中的描述完全一致，基本框架以及核心实现\\n跟论文是一致的。我们将结合图像识别项目实战内容给大家讲解模型搭建，由于图像识别技\\n术在各个行业的应用基本上差别不大，不管你是做医疗图像分类，农产品图像分类，工业部\\n件图像分类，天气云图图像分类，生活用品图像分类等，只要是图像分类，所用到的技术和\\n流程都是差不多的。所以为了方便，本章节我们主要使用一个数据集给大家讲解，如果大家\\n有其他图像数据集或自己收集了一些图像数据集也可以用本章内容进行图像分类。\\n特别要说明一下，本章的重点在于 Tensorflow 中不同模型的搭建方法，以及图像识别模\\n型的训练流程，因为数据量比较小，我也没有进行调参，所以最后模型的准确率不需要太在\\n意。因为正常图像识别模型训练都不会从头训练（英文是 train from scratch），一般我们\\n都在预训练模型的基础上做进一步的训练。由于我们使用的数据集太小，并不是 ImageNet\\n级别的大数据集，所以从头训练（train from scratch）很难发挥模型的真正水平。本章\\n12.11 小节将会介绍使用预训练模型来进行迁移学习的方法。\\n12.1 图像数据准备\\n12.1.1 数据集介绍\\n在建模之前我们肯定需要先把数据给准备好，图像数据集有很多，大家可以自行收集，\\n我们这里使用的数据集是来自Visual Geometry Group的17 Category Flower Dataset 数\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 386, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 387\\n据集，也就是17 种花的数据集。具体是哪17 种这个我们可以不用管，反正就是17 个类\\n别。每个类别的花有80 张图片，一共是1360 张图片。单击网址\\nhttp://www.robots.ox.ac.uk/~vgg/data/flowers/17/。出现如图12.1 所示的界面。\\n图12.1 17 Category Flower Dataset\\n我们单击“1.Dataset images”就可以下载数据集了，下载后得到一个名为\\n“17flowers.tgz”的压缩包，解压后得到一个名为“17flowers”的文件夹，打开文件夹里\\n面是一个名为“jpg”的文件夹，再打开“jpg”文件夹，我们会看到1362 个文件，其中有\\n1360 张图片。我们需要把不是图片的那两个文件给删除，只留下图片文件，如图 12.2 所\\n示。\\n12.2 17 种花的图片\\n观察图片名称我们可以发现是都是由编号构成，前 1-80 号为第一种花，81 到160 号为\\n第二种花以此类推，1360 张图片一共 17 种花。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 387, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 388\\n12.1.2 数据集准备\\n我们在做图像分类任务的时候，通常需要把数据先整理好，数据整理的格式通常都是每\\n一个类别一个文件夹，文件夹的名称就是类别名称，如图 12.3 所示。\\n图12.3 数据集准备\\n如图我想做一个5 分类的图像识别模型，这 5 个分类分别\\n是”animal”,”flower”,”guitar”,”house”,”plane”,那么我需要在一个新的路径下\\n新建5 个文件夹，这 5 个文件夹的名称修改\\n为”animal”,”flower”,”guitar”,”house”,”plane”。然后把对应类别的图片存放到\\n对应的文件夹下面。如图12.4 所示。\\n图12.4 存放数据\\n这是图像分类任务的基本操作，正常情况下大家都会这么整理数据。不过 Visual\\nGeometry Group的17 Category Flower Dataset 数据集所有的图片都是在一个文件夹下\\n面的，所以这里我们还需要写一个程序来帮助我们整理一下图片，我写的这个程序是放在与\\n“17flowers”文件夹相同目录下运行的，如果在其他路径运行，要注意程序中路径的设置，\\n如代码12-1 所示。\\n代码12-1：17Flower 数据整理\\nimport os\\nimport shutil\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 388, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 389\\n# 新建文件夹用于存放整理后的图片\\nos.mkdir(\\'new_17_flowers\\')\\nfor i in range(17):\\n# 17 个种类新建17 个文件夹0-16\\nos.mkdir(\\'new_17_flowers\\'+\\'/\\'+str(i))\\n# 循环所有花的图片\\nfor i,path in enumerate(os.listdir(\\'17flowers/jpg/\\')):\\n# 定义花的图片完整路径\\nimage_path = \\'17flowers/jpg/\\' + path\\n# 复制到对应类别，每个类别80 张图片\\nshutil.copyfile(image_path, \\'new_17_flowers\\'+\\'/\\'+str(i//80)+\\'/\\'+path)\\n运行完程序后就会产生一个新的文件夹“new_17_flowers”，这个文件夹里面有17 个\\n子文件夹，名字为flower0- flower16，表示17 种花的编号。flower0- flower16 文件夹里\\n面都各自存放了80 张图片。\\n12.1.3 切分数据集程序\\n数据集按照格式准备好以后，我们还需要切分训练集和测试集。因为我经常需要做数据\\n切分的工作，所以就自己写了一个程序专门用于打乱数据并切分训练集和测试集。大家如果\\n之后需要做类似的操作，可以参考或直接使用代码 12-2。该程序是放在与\\n“new_17_flowers”文件夹相同的路径下的，如果大家在其他路径运行，需要注意程序中路\\n径的设置。\\n代码 12-2：切分数据集\\nimport os\\nimport random\\nimport shutil\\nimport numpy as np\\n# 数据集路径\\nDATASET_DIR = \"new_17_flowers\"\\n# 数据切分后存放路径\\nNEW_DIR = \"data\"\\n# 测试集占比\\nnum_test = 0.2\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 389, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 390\\n# 打乱所有种类数据，并分割训练集和测试集\\ndef shuffle_all_files(dataset_dir, new_dir, num_test):\\n# 先删除已有new_dir文件夹\\nif not os.path.exists(new_dir):\\npass\\nelse:\\n# 递归删除文件夹\\nshutil.rmtree(new_dir)\\n# 重新创建new_dir文件夹\\nos.makedirs(new_dir)\\n# 在new_dir文件夹目录下创建train 文件夹\\ntrain_dir = os.path.join(new_dir, 'train')\\nos.makedirs(train_dir)\\n# 在new_dir文件夹目录下创建test文件夹\\ntest_dir = os.path.join(new_dir, 'test')\\nos.makedirs(test_dir)\\n# 原始数据类别列表\\ndirectories = []\\n# 新训练集类别列表\\ntrain_directories = []\\n# 新测试集类别列表\\ntest_directories = []\\n# 类别名称列表\\nclass_names = []\\n# 循环所有类别\\nfor filename in os.listdir(dataset_dir):\\n# 原始数据类别路径\\npath = os.path.join(dataset_dir, filename)\\n# 新训练集类别路径\\ntrain_path = os.path.join(train_dir, filename)\\n# 新测试集类别路径\\ntest_path = os.path.join(test_dir, filename)\\n# 判断该路径是否为文件夹\\nif os.path.isdir(path):\\n# 加入原始数据类别列表\\ndirectories.append(path)\\n# 加入新训练集类别列表\\ntrain_directories.append(train_path)\\n# 新建类别文件夹\\nos.makedirs(train_path)\\n# 加入新测试集类别列表\\ntest_directories.append(test_path)\\n# 新建类别文件夹\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 390, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 391\\nos.makedirs(test_path)\\n# 加入类别名称列表\\nclass_names.append(filename)\\nprint('类别列表：',class_names)\\n# 循环每个分类的文件夹\\nfor i in range(len(directories)):\\n# 保存原始图片路径\\nphoto_filenames = []\\n# 保存新训练集图片路径\\ntrain_photo_filenames = []\\n# 保存新测试集图片路径\\ntest_photo_filenames = []\\n# 得到所有图片的路径\\nfor filename in os.listdir(directories[i]):\\n# 原始图片路径\\npath = os.path.join(directories[i], filename)\\n# 训练图片路径\\ntrain_path = os.path.join(train_directories[i], filename)\\n# 测试集图片路径\\ntest_path = os.path.join(test_directories[i], filename)\\n# 保存图片路径\\nphoto_filenames.append(path)\\ntrain_photo_filenames.append(train_path)\\ntest_photo_filenames.append(test_path)\\n# list转array\\nphoto_filenames = np.array(photo_filenames)\\ntrain_photo_filenames = np.array(train_photo_filenames)\\ntest_photo_filenames = np.array(test_photo_filenames)\\n# 打乱索引\\nindex = [i for i in range(len(photo_filenames))]\\nrandom.shuffle(index)\\n# 对3 个list进行相同的打乱，保证在 3 个list中索引一致\\nphoto_filenames = photo_filenames[index]\\ntrain_photo_filenames = train_photo_filenames[index]\\ntest_photo_filenames = test_photo_filenames[index]\\n# 计算测试集数据个数\\ntest_sample_index = int((1-num_test) * float(len(photo_filenames)))\\n# 复制测试集图片\\nfor j in range(test_sample_index, len(photo_filenames)):\\n# 复制图片\\nshutil.copyfile(photo_filenames[j], test_photo_filenames[j])\\n# 复制训练集图片\\nfor j in range(0, test_sample_index):\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 391, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 392\\n# 复制图片\\nshutil.copyfile(photo_filenames[j], train_photo_filenames[j])\\n# 打乱并切分数据集\\nshuffle_all_files(DATASET_DIR, NEW_DIR, num_test)\\n运行结果如下：\\n类别列表： ['flower0', 'flower1', 'flower10', 'flower11', 'flower12', 'flower13\\n', 'flower14', 'flower15', 'flower16', 'flower2', 'flower3', 'flower4', 'flowe\\nr5', 'flower6', 'flower7', 'flower8', 'flower9']\\n这个程序运行后会生成一个新的文件夹“data“，”data“文件夹中有两个子文件夹”\\ntrain“和”test“。”train“表示训练集数据，占数据集的80%，”test“表示测试集数\\n据，占数据集的20%。”train“和”test“文件夹下的子文件夹都是flower0- flower16，\\n就是17 种花的类别。“train”的子文件夹下，每个类别有 64 张图片，“test”的子文件夹\\n下，每个类别有16 张图片。\\n12.2 AlexNet 图像识别\\n这一小节我们要学习如何搭建AlexNet模型并从头进行模型训练，如代码12-3 所示。\\n代码12-3：AlexNet图像识别（片段1）\\nimport numpy as np\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\\nfrom tensorflow.keras.optimizers import Adam\\nimport matplotlib.pyplot as plt\\nfrom tensorflow.keras.callbacks import LearningRateScheduler\\n# 类别数\\nnum_classes = 17\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 392, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 393\\n# 批次大小\\nbatch_size = 32\\n# 周期数\\nepochs = 100\\n# 图片大小\\nimage_size = 224\\n# 训练集数据进行数据增强\\ntrain_datagen = ImageDataGenerator(\\nrotation_range = 20, # 随机旋转度数\\nwidth_shift_range = 0.1, # 随机水平平移\\nheight_shift_range = 0.1,# 随机竖直平移\\nrescale = 1/255, # 数据归一化\\nshear_range = 10, # 随机错切变换\\nzoom_range = 0.1, # 随机放大\\nhorizontal_flip = True, # 水平翻转\\nbrightness_range=(0.7, 1.3), # 亮度变化\\nfill_mode = 'nearest', # 填充方式\\n)\\n# 测试集数据只需要归一化就可以\\ntest_datagen = ImageDataGenerator(\\nrescale = 1/255, # 数据归一化\\n)\\n# 训练集数据生成器，可以在训练时自动产生数据进行训练\\n# 从'data/train'获得训练集数据\\n# 获得数据后会把图片resize 为image_size×image_size的大小\\n# generator每次会产生batch_size个数据\\ntrain_generator = train_datagen.flow_from_directory(\\n'data/train',\\ntarget_size=(image_size,image_size),\\nbatch_size=batch_size,\\n)\\n# 测试集数据生成器\\ntest_generator = test_datagen.flow_from_directory(\\n'data/test',\\ntarget_size=(image_size,image_size),\\nbatch_size=batch_size,\\n)\\n# 字典的键为17 个文件夹的名字，值为对应的分类编号\\nprint(train_generator.class_indices)\\n运行结果如下：\\n{'flower0': 0,\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 393, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 394\\n'flower1': 1,\\n'flower10': 2,\\n'flower11': 3,\\n'flower12': 4,\\n'flower13': 5,\\n'flower14': 6,\\n'flower15': 7,\\n'flower16': 8,\\n'flower2': 9,\\n'flower3': 10,\\n'flower4': 11,\\n'flower5': 12,\\n'flower6': 13,\\n'flower7': 14,\\n'flower8': 15,\\n'flower9': 16}\\n代码12-3：AlexNet图像识别（片段2）\\n# AlexNet\\nmodel = Sequential()\\n# 卷积层\\nmodel.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding='valid',input_shape\\n=(image_size,image_size,3),activation='relu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid'))\\nmodel.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid'))\\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2),padding='valid'))\\n# 全连接层\\nmodel.add(Flatten())\\nmodel.add(Dense(4096, activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(4096, activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(num_classes, activation='softmax'))\\n# 模型概要\\nmodel.summary()\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 394, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 395\\n# 模型概要输出省略。。。\\n# 学习率调节函数，逐渐减小学习率\\ndef adjust_learning_rate(epoch):\\n# 前30 周期\\nif epoch<=30:\\nlr = 1e-4\\n# 前30 到70 周期\\nelif epoch>30 and epoch<=70:\\nlr = 1e-5\\n# 70 到100 周期\\nelse:\\nlr = 1e-6\\nreturn lr\\n# 定义优化器\\nadam = Adam(lr=1e-4)\\n# 定义学习率衰减策略\\ncallbacks = []\\ncallbacks.append(LearningRateScheduler(adjust_learning_rate))\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# Tensorflow2.1版本之前可以使用fit_generator训练模型\\n# history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc\\nhs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\\n# Tensorflow2.1版本(包括2.1)之后可以直接使用fit 训练模型\\nhistory = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callba\\ncks=callbacks)\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 14s 418ms/step - loss: 2.77\\n50 - accuracy: 0.0800 - val_loss: 2.4774 - val_accuracy: 0.1250\\nEpoch 2/100\\n34/34 [==============================] - 13s 395ms/step - loss: 2.46\\n28 - accuracy: 0.1296 - val_loss: 2.2861 - val_accuracy: 0.1949\\n……\\nEpoch 99/100\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 395, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 396\\n34/34 [==============================] - 13s 390ms/step - loss: 0.08\\n79 - accuracy: 0.9743 - val_loss: 0.7067 - val_accuracy: 0.8346\\nEpoch 100/100\\n34/34 [==============================] - 13s 390ms/step - loss: 0.10\\n61 - accuracy: 0.9660 - val_loss: 0.7062 - val_accuracy: 0.8346\\n代码12-3：AlexNet图像识别（片段3）\\n# 画出训练集准确率曲线图\\nplt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy')\\n# 画出验证集准确率曲线图\\nplt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n运行结果如下：\\n12.3 VGGNet 图像识别\\n这一小节我们要学习如何搭建VGGNet模型并从头进行模型训练，由于我们使用的都是\\n同一个数据集案例，所以关于模块导入，参数设定，数据集预处理，模型训练，训练后画图\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 396, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 397\\n的程序基本都是一样的。主要就是模型搭建部分不同，所以为了节约用纸，我们仅在书中展\\n示模型搭建部分的代码，完整的代码可见于本书相关代码。模型代码如代码 12-4 所示。\\n代码12-4：VGGNet图像识别\\n……\\n……\\n……\\n# VGG16\\nmodel = Sequential()\\n# 卷积层\\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='rel\\nu',input_shape=(image_size,image_size,3)))\\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='rel\\nu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\\nmodel.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\\nelu'))\\nmodel.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 397, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 398\\n# 全连接层\\nmodel.add(Flatten())\\nmodel.add(Dense(4096,activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(4096,activation='relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(num_classes,activation='softmax'))\\n……\\n……\\n……\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 15s 447ms/step - loss: 2.83\\n44 - accuracy: 0.0506 - val_loss: 2.8332 - val_accuracy: 0.0588\\nEpoch 2/100\\n34/34 [==============================] - 14s 400ms/step - loss: 2.82\\n52 - accuracy: 0.0542 - val_loss: 2.8332 - val_accuracy: 0.0588\\n……\\nEpoch 99/100\\n34/34 [==============================] - 14s 401ms/step - loss: 0.20\\n13 - accuracy: 0.9311 - val_loss: 0.7145 - val_accuracy: 0.7831\\nEpoch 100/100\\n34/34 [==============================] - 14s 400ms/step - loss: 0.18\\n59 - accuracy: 0.9338 - val_loss: 0.7183 - val_accuracy: 0.7868\\n观察AlexNet和VGG16 模型的训练结果我们其实会发现 AlexNet的结果反而比\\nVGG16 的结果要好一些。AlexNet测试集的准确率在 83%左右，VGG16 测试集的准确率在\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 398, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 399\\n78%左右。由于我们是从新训练模型，并且数据量比较少，VGG16 模型比AlexNet结构更\\n复杂，所以更难训练，那么结果差一些也是可以理解的。如果是大量数据的情况下，VGG16\\n得到的结果应该会比AlexNet更好。\\n12.4 函数式（functional）模型\\n12.4.1 函数式（functional）模型介绍\\n在Tenorflow.keras种有两种模型搭建的方法，一种就是我们之前学习使用的\\nSequential 顺序模型，模型就像汉堡一样，是一层一层叠加起来的。除此之外模型搭建还有\\n另外一种方式称为函数式模型。\\n函数式模型的特点是需要定义模型的输入和输出，并且在模型搭建的过程中也更灵活。\\n下面举个例子，比如我们在构建GoogleNet的Inception结构时，使用函数式模型的方式\\n就会比较方便，下面程序我们将构建GoogleNet中第一个Inception的结构，如代码12-5\\n所示。\\n代码12-5：函数式编程实现Inception结构\\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate\\nfrom tensorflow.keras.models import Model\\n# 定义模型输入\\ninputs = Input(shape=(28,28,192))\\n# 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D 中计算\\ntower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\n# 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D 中计算\\ntower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 399, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 400\\n# 注意函数式模型的特点，Conv2D后面的(tower_2)表示把tower_2 信号输入到Conv2D中\\n计算\\ntower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='re\\nlu')(tower_2)\\n# 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D 中计算\\ntower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\n# 注意函数式模型的特点，Conv2D后面的(tower_3)表示把tower_3 信号输入到Conv2D中\\n计算\\ntower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='rel\\nu')(tower_3)\\n# 注意函数式模型的特点，MaxPool2D后面的(inputs)表示把inputs信号输入到MaxPool2D\\n中计算\\npooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs)\\n# 注意函数式模型的特点，Conv2D后面的(pooling)表示把pooling信号输入到Conv2D 中计\\n算\\npooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu'\\n)(pooling)\\n# concatenate合并 4 个信号，axis=3 表示根据channel进行合并，得到模型的输出\\noutputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3)\\n# 定义模型，设置输入和输出信号\\nmodel = Model(inputs=inputs, outputs=outputs)\\n# 查看模型概要\\nmodel.summary()\\n运行结果如下：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 400, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 401\\n由于我们第一次讲解函数式编程，所以注释里我强调了很多次要注意函数式模型的特\\n点，输入信号要放在函数的后面。\\n12.4.2 使用函数式模型进行 MNIST 图像识别\\n我们再来看一个函数式模型的完整例子，如代码 12-6 所示。\\n代码12-6：使用函数式模型进行MNIST 图像识别\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.models import Model\\n# 载入数据\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 这里要注意，在tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式\\n# 这4 个维度是(数据数量，图片高度，图片宽度，图片通道数)\\n# 所以这里把数据reshape变成4 维数据，黑白图片的通道数是 1，彩色图片通道数是3\\nx_train = x_train.reshape(-1,28,28,1)/255.0\\nx_test = x_test.reshape(-1,28,28,1)/255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 定义模型输入\\ninputs = Input(shape=(28,28,1))\\nx = Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu')(inputs)\\nx = MaxPool2D(pool_size=2,strides=2,padding='same')(x)\\nx = Conv2D(64,5,strides=1,padding='same',activation='relu')(x)\\nx = MaxPool2D(pool_size=2,strides=2,padding='same')(x)\\nx = Flatten()(x)\\nx = Dense(1024,activation='relu')(x)\\nx = Dropout(0.5)(x)\\nx = Dense(10,activation='softmax')(x)\\n# 定义模型\\nmodel = Model(inputs,x)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 401, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 402\\n# 定义优化器\\nadam = Adam(lr=1e-4)\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 训练模型\\nmodel.fit(x_train,y_train,batch_size=64,epochs=2,validation_data=(x_test, y_test))\\n运行结果如下：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/2\\n60000/60000 [==============================] - 83s 1ms/sample - los\\ns: 0.3269 - accuracy: 0.9077 - val_loss: 0.0849 - val_accuracy: 0.975\\n2\\nEpoch 2/2\\n60000/60000 [==============================] - 87s 1ms/sample - los\\ns: 0.0893 - accuracy: 0.9730 - val_loss: 0.0528 - val_accuracy: 0.982\\n5\\n12.5 模型可视化 plot_model\\n12.5.1 使用 plot_model 进行模型可视化\\nTensorflow 里面有一个小工具可以方便的画出模型结构，很好用。就是\\ntensorflow.keras.utils.plot_model。\\n使用plot_model 前需要做一些准备工作，首先我们先要打开命令提示符安装 3 个\\npython模块：\\npip install pydot\\npip install pydot_ng\\npip install graphviz\\n安装好3 个 python模型后，我们还需要安装一个软件，软件下载网址是：\\nhttps://graphviz.gitlab.io/download/。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 402, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 403\\n里面有Linux，Windows，Mac 系统相对应的安装方法，因为每个系统安装方式不太一\\n样，大家可以根据提示操作，搞不定的话可以网上搜索一下安装方法，我就不一一展开了。\\n安装方式如图12.6 所示。\\n图12.6 安装Graphviz软件\\nWindows用户应该比较多，我就以Windows为例简单说明一下，Windows版本有一\\n个软件下载地址为：\\nhttps://www2.graphviz.org/Packages/stable/windows/10/msbuild/Release/Win32/gr\\naphviz-2.38-win32.msi。下载完成后双击安装就可以，安装的路径我们要记住，默认路径\\n一般是“C:\\\\Program Files(x86)\\\\Graphviz2.38”，可以使用默认路径或者修改为其他路径\\n都可以。安装好之后，我们还需要把Graphviz软件主目录下bin 文件的路径添加到环境变\\n量中，如果是默认路径安装的话就是把“C:\\\\Program Files(x86)\\\\Graphviz2.38\\\\bin”添加\\n到环境变量中。（可能有些同学还不知道怎么添加环境变量，这个内容太基础了，自行通过\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 403, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 404\\n搜索引擎解决吧）。安装配置好以后最好重启电脑，到此为止准备工作应该就做好了。如果\\n运行时还出现有其他问题的话可以自行通过搜索引擎解决。\\n前面我们用函数式模型搭建了一个 Inception结构，这个Inception结构如果我们看它\\n的summary 输出结果，大概可以看出来它的信号传递关系，但是看起来不太直观。\\nsummary 比较适合用来看顺序模型的结构，看函数式模型就不太方便了。下面我们来学习\\nplot_model 的用法，它可以比较直观的绘制出模型的结构，实现代码如代码 12-7 所示。\\n代码12-7：画出模型结构plot_model\\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.utils import plot_model\\n# 定义模型输入\\ninputs = Input(shape=(28,28,192))\\ntower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\ntower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\ntower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='re\\nlu')(tower_2)\\ntower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel\\nu')(inputs)\\ntower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='rel\\nu')(tower_3)\\npooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs)\\npooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu'\\n)(pooling)\\n# concatenate合并 4 个信号，axis=3 表示根据channel进行合并，得到模型的输出\\noutputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3)\\n# 定义模型，设置输入和输出信号\\nmodel = Model(inputs=inputs, outputs=outputs)\\n# model 表示要画图的模型\\n# 'model.png'表示图片存放路径\\n# show_shapes=True画出信号的shape\\n# dpi 设置分辨率，默认是96\\nplot_model(model=model, to_file='model.png', show_shapes=True, dpi=200)\\n运行结果如下：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 404, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 405\\n运行程序后，在程序所在目录下会产生一张名为'model.png'的图片，保存着模型的结构\\n图。这个图我就不需要多解释了，可以清楚地看到信号的传递关系和信号的 shape变化。\\n代码12-6 中的模型使用plot_model 画出来的结构如图12.7 所示。\\n图12.7 plot_model 绘制模型结构\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 405, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 406\\nplot_model 画出来的图可以很清晰的看到网络各层结构，信号的流动关系，以及信号输\\n入输出的shape。如果以后大家对模型的结构理解得不够好的话，可以用 plot_model 把模\\n型结构画出来，看着模型结构图来理解模型的结构会容易一些。\\n12.5.2 plot_model 升级版\\n上一小节我们学习了使用Tensorflow 官方的plot_model 来绘制网络结构，\\nplot_model 确实对我们理解模型结构有着很好的帮助。但是如果你仔细观察的话你会发现\\n好像plot_model 画出来的图好像少了些什么重要的内容。对了，这就卷积/池化窗口的大\\n小，卷积/池化的步长，卷积/池化的padding方式，Dense层的激活函数，Dropout的系\\n数等这些具体参数对于我们理解网络具体结构也是非常重要的，但是 plot_model 没有把这\\n些信息标注出来。\\n为了可以画出更好的模型结构图，我在 Tensorflow 官方的plot_model 基础上进行的优\\n化，优化后的效果如图12.8 和图12.9 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 406, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 407\\n图12.8 plot_model 升级版1\\n图12.9 plot_model 升级版2\\n我对原始plot_model 的修改主要就是增加了更多的模型细节以及不同模块有不同颜\\n色，简单的模型可能效果不够明显，如果大家在学习复杂模型的时候，显示更多的细节和颜\\n色区分帮助还是很大的。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 407, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 408\\n我优化过的plot_model 已经发布在 PyPi：https://pypi.org/project/plot-model/。源\\n代码在我的Github可以看到：https://github.com/Qinbf/plot_model。推荐安装方式是\\n使用pip 安装，打开命令提示符输入命令：\\npip install plot_model\\n安装好以后通过如下代码导入：\\nfrom plot_model import plot_model\\nplot_model 的使用方式跟Tensorflow 中的plot_model 一样，不过增加了两个参数。\\n一个是style，可以取值0 和1，默认值为0。style=0 表示使用新风格，style=1 表示使用\\n老风格，大家可以自行尝试。还有一个参数是 color，取值为True 或False，默认值是\\nTrue。color=True 表示画彩色结构图，color=False 表示画黑白结构图。以后大家需要画模\\n型结构图的时候，推荐大家使用我的plot_model。\\n12.6 GoogleNet 图像识别\\nGoogleNet中包含了很多Inception模块，所以我们可以定义一个Inception函数专门\\n用于实现Inception模块。在调用Inception函数时根据论文中GoogleNet网络结构描述\\n传入不同的参数即可。我们将使用函数式模型来定义 GoogleNet，同样我们只展示建模相关\\n代码，如代码12-8 所示。\\n代码12-8：GoogleNet图像识别\\n……\\n……\\n……\\n# 定义Inception结构\\ndef Inception(x,filters):\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 408, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 409\\ntower_1 = Conv2D(filters=filters[0],kernel_size=1,strides=1,padding='same',activation='re\\nlu')(x)\\ntower_2 = Conv2D(filters=filters[1],kernel_size=1,strides=1,padding='same',activation='re\\nlu')(x)\\ntower_2 = Conv2D(filters=filters[2],kernel_size=3,strides=1,padding='same',activation='re\\nlu')(tower_2)\\ntower_3 = Conv2D(filters=filters[3],kernel_size=1,strides=1,padding='same',activation='re\\nlu')(x)\\ntower_3 = Conv2D(filters=filters[4],kernel_size=5,strides=1,padding='same',activation='re\\nlu')(tower_3)\\npooling = MaxPool2D(pool_size=3,strides=1,padding='same')(x)\\npooling = Conv2D(filters=filters[5],kernel_size=1,strides=1,padding='same',activation='rel\\nu')(pooling)\\nx = concatenate([tower_1,tower_2,tower_3,pooling],axis=3)\\nreturn x\\n# 定义GoogleNet 模型\\nmodel_input = Input(shape=(image_size,image_size,3))\\nx = Conv2D(filters=64,kernel_size=7,strides=2,padding='same',activation='relu')(model_inp\\nut)\\nx = MaxPool2D(pool_size=3,strides=2,padding='same')(x)\\nx = Conv2D(filters=64,kernel_size=1,strides=1,padding='same',activation='relu')(x)\\nx = Conv2D(filters=192,kernel_size=3,strides=1,padding='same',activation='relu')(x)\\nx = MaxPool2D(pool_size=3,strides=2,padding='same')(x)\\nx = Inception(x,[64,96,128,16,32,32])\\nx = Inception(x,[128,128,192,32,96,64])\\nx = MaxPool2D(pool_size=3,strides=2,padding='same')(x)\\nx = Inception(x,[192,96,208,16,48,64])\\nx = Inception(x,[160,112,224,24,64,64])\\nx = Inception(x,[128,128,256,24,64,64])\\nx = Inception(x,[112,144,288,32,64,64])\\nx = Inception(x,[256,160,320,32,128,128])\\nx = MaxPool2D(pool_size=3,strides=2,padding='same')(x)\\nx = Inception(x,[256,160,320,32,128,128])\\nx = Inception(x,[384,192,384,48,128,128])\\nx = AvgPool2D(pool_size=7,strides=7,padding='same')(x)\\nx = Flatten()(x)\\nx = Dropout(0.4)(x)\\nx = Dense(num_classes,activation='softmax')(x)\\nmodel = Model(inputs=model_input,outputs=x)\\n……\\n……\\n……\\n运行结果如下：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 409, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 410\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 16s 477ms/step - loss: 2.77\\n64 - accuracy: 0.0699 - val_loss: 2.5863 - val_accuracy: 0.1140\\nEpoch 2/100\\n34/34 [==============================] - 13s 392ms/step - loss: 2.46\\n51 - accuracy: 0.1360 - val_loss: 2.3358 - val_accuracy: 0.1471\\n……\\nEpoch 99/100\\n34/34 [==============================] - 13s 395ms/step - loss: 0.17\\n23 - accuracy: 0.9366 - val_loss: 0.8696 - val_accuracy: 0.7831\\nEpoch 100/100\\n34/34 [==============================] - 13s 393ms/step - loss: 0.16\\n41 - accuracy: 0.9430 - val_loss: 0.8596 - val_accuracy: 0.7904\\nGoogleNet的结构是一个个Inception结构叠加得到的，看程序就很容易理解，不过还\\n是建议大家用plot_model()把模型结构图画出来，对照着模型结构图来看理解起来更容易，\\n绝对能够让你清晰理解GoogleNet的具体结构（注意图片太大，dpi 不要调太高）。由于\\nplot_model()画出来的图太长我就不放到书里了，大家可以自行操作。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 410, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 411\\n12.7 Batch Normalization 使用\\nBN 我们在之前的内容中学习过，是一种很神奇的网络优化技巧，下面我们通过一个\\nCIFAR10 的图像分类来对比一下，使用BN 和不使用BN 的模型效果，如代码12-9 所示。\\n代码12-9：BN-CIFAR10 图像分类\\nimport numpy as np\\nfrom tensorflow.keras.datasets import cifar10\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchN\\normalization,Activation\\nfrom tensorflow.keras.optimizers import Adam,RMSprop\\nimport matplotlib.pyplot as plt\\n# 下载并载入数据\\n# 训练集数据(50000, 32, 32, 3)\\n# 测试集数据(50000, 1)\\n(x_train,y_train),(x_test,y_test) = cifar10.load_data()\\n# 数据归一化\\nx_train = x_train/255.0\\nx_test = x_test/255.0\\n# 换one hot格式\\ny_train = to_categorical(y_train,num_classes=10)\\ny_test = to_categorical(y_test,num_classes=10)\\n# 定义卷积网络\\nmodel = Sequential()\\nmodel.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding='s\\name', activation = 'relu'))\\nmodel.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu'))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.2))\\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu'))\\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu'))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.3))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 411, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 412\\nmodel.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu'\\n))\\nmodel.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu'\\n))\\nmodel.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel.add(Dropout(0.4))\\nmodel.add(Flatten())\\nmodel.add(Dense(10,activation = 'softmax'))\\n# 定义使用了BN 的卷积网络\\n# 两个模型结构完全一致，区别只在于是否使用 BN\\nmodel_bn = Sequential()\\nmodel_bn.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, paddin\\ng='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel_bn.add(Dropout(0.2))\\nmodel_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel_bn.add(Dropout(0.3))\\nmodel_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))\\nmodel_bn.add(BatchNormalization())\\nmodel_bn.add(Activation('relu'))\\nmodel_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\\nmodel_bn.add(Dropout(0.4))\\nmodel_bn.add(Flatten())\\nmodel_bn.add(Dense(10,activation = 'softmax'))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 412, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 413\\n# 定义优化器\\nadam = Adam(lr=1e-4)\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 定义优化器，loss function，训练过程中计算准确率\\nmodel_bn.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\\n# 训练模型\\nhistory = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_t\\nest), shuffle=True)\\nhistory_bn = model_bn.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_\\ntest, y_test), shuffle=True)\\nplt.plot(np.arange(100),history.history['val_accuracy'],c='b',label='without_bn')\\n# 画出使用BN 的模型验证集准确率\\nplt.plot(np.arange(100),history_bn.history['val_accuracy'],c='y',label='bn')\\nplt.legend()\\nplt.xlabel('epochs')\\nplt.ylabel('accuracy')\\nplt.show()\\n运行结果如下：\\n12.8 ResNet 图像识别\\n同样这里我们只展示ResNet建模相关代码，如代码12-10 所示。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 413, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 414\\n代码12-10：ResNet50 图像识别\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob\\nalAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D\\n……\\n……\\n……\\n# 定义残差单元\\ndef block(x, filters, strides=1, conv_shortcut=True):\\n# projection shortcut\\nif conv_shortcut == True:\\nshortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x)\\n# epsilon为BN 公式中防止分母为零的值\\nshortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\\nelse:\\n# identity_shortcut\\nshortcut = x\\n# 3 个卷积层\\nx = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\nx = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Add()([x, shortcut])\\nx = Activation('relu')(x)\\nreturn x\\n# 堆叠残差单元\\ndef stack(x, filters, blocks, strides):\\nx = block(x, filters, strides=strides)\\nfor i in range(blocks-1):\\nx = block(x, filters, conv_shortcut=False)\\nreturn x\\n# 定义ResNet50\\ninputs = Input(shape=(image_size,image_size,3))\\n# 填充3 圈0，填充后图像从224×224变成230×230\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 414, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 415\\nx = ZeroPadding2D((3, 3))(inputs)\\nx= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\n# 填充1 圈0\\nx = ZeroPadding2D((1, 1))(x)\\nx = MaxPool2D(pool_size=3,strides=2,padding='valid')(x)\\n# 堆叠残差结构\\n# blocks表示堆叠数量\\nx = stack(x, filters=64, blocks=3, strides=1)\\nx = stack(x, filters=128, blocks=4, strides=2)\\nx = stack(x, filters=256, blocks=6, strides=2)\\nx = stack(x, filters=512, blocks=3, strides=2)\\n# 根据特征图大小进行平均池化，池化后得到 2 维数据\\nx = GlobalAvgPool2D()(x)\\nx = Dense(num_classes, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(inputs=inputs,outputs=x)\\n……\\n……\\n……\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 19s 546ms/step - loss: 3.05\\n63 - accuracy: 0.1195 - val_loss: 2.8569 - val_accuracy: 0.0588\\nEpoch 2/100\\n34/34 [==============================] - 14s 399ms/step - loss: 2.45\\n23 - accuracy: 0.2022 - val_loss: 2.9909 - val_accuracy: 0.0588\\n……\\nEpoch 99/100\\n34/34 [==============================] - 14s 406ms/step - loss: 0.02\\n24 - accuracy: 0.9954 - val_loss: 1.0080 - val_accuracy: 0.7794\\nEpoch 100/100\\n34/34 [==============================] - 14s 404ms/step - loss: 0.02\\n29 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 415, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 416\\n这里我使用了一种比较简洁的方式来搭建 ResNet模型，程序比较简洁，不过理解起来\\n可能需要多花点时间，建议一行一行代码仔细理解。同时可以借助 plot_model()来帮助模型\\n结构的理解。由于plot_model()画出来的图太长我就不放到书里了，我截取两个局部给大家\\n看看好了，图12.10 为identity shortcut残差单元（左）和projection shortcut残差单元\\n（右）。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 416, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 417\\n图12.10 identity（左），projection（右）\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 417, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 418\\n12.9 ResNeXt图像识别\\n同样这里我们只展示ResNeXt建模相关代码，如代码12-11 所示。\\n代码12-11：ResNeXt50(32×4d)图像识别\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob\\nalAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D,Lambda\\n……\\n……\\n……\\n# 定义分组卷积\\n# g_channels 每组的通道数\\n# groups 多少组\\ndef grouped_convolution_block(init_x, strides, groups, g_channels):\\ngroup_list = []\\n# 分组进行卷积\\nfor c in range(groups):\\n# 分组取出数据\\nx = Lambda(lambda x: x[:, :, :, c*g_channels:(c+1)*g_channels])(init_x)\\n# 分组进行卷积\\nx = Conv2D(filters=g_channels,kernel_size=3,strides=strides,padding='same',use_bia\\ns=False)(x)\\n# 存入list\\ngroup_list.append(x)\\n# 合并list中的数据\\ngroup_merge = concatenate(group_list, axis=3)\\nx = BatchNormalization(epsilon=1.001e-5)(group_merge)\\nx = Activation('relu')(x)\\nreturn x\\n# 定义残差单元\\ndef block(x, filters, strides=1, groups=32, conv_shortcut=True):\\n# projection shortcut\\nif conv_shortcut == True:\\nshortcut = Conv2D(filters*2,kernel_size=1,strides=strides,padding='same')(x)\\n# epsilon为BN 公式中防止分母为零的值\\nshortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 418, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 419\\nelse:\\n# identity_shortcut\\nshortcut = x\\n# 3 个卷积层\\nx = Conv2D(filters=filters,kernel_size=1,strides=1,padding='same')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\n# 计算每组的通道数\\ng_channels = int(filters / groups)\\n# 进行分组卷积\\nx = grouped_convolution_block(x, strides, groups, g_channels)\\nx = Conv2D(filters=filters*2,kernel_size=1,strides=1,padding='same')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Add()([x, shortcut])\\nx = Activation('relu')(x)\\nreturn x\\n# 堆叠残差单元\\ndef stack(x, filters, blocks, strides, groups=32):\\nx = block(x, filters, strides=strides, groups=groups)\\nfor i in range(blocks):\\nx = block(x, filters, groups=groups, conv_shortcut=False)\\nreturn x\\n# 定义ResNeXt50\\ninputs = Input(shape=(image_size,image_size,3))\\n# 填充3 圈0，填充后图像从224×224变成230×230\\nx = ZeroPadding2D((3, 3))(inputs)\\nx= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\n# 填充1 圈0\\nx = ZeroPadding2D((1, 1))(x)\\nx = MaxPool2D(pool_size=3,strides=2,padding='valid')(x)\\n# 堆叠残差结构\\n# blocks表示堆叠数量\\nx = stack(x, filters=128, blocks=2, strides=1)\\nx = stack(x, filters=256, blocks=3, strides=2)\\nx = stack(x, filters=512, blocks=5, strides=2)\\nx = stack(x, filters=1024, blocks=2, strides=2)\\n# 根据特征图大小进行平均池化，池化后得到 2 维数据\\nx = GlobalAvgPool2D()(x)\\nx = Dense(num_classes, activation='softmax')(x)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 419, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 420\\n# 定义模型\\nmodel = Model(inputs=inputs,outputs=x)\\n# 电脑配置不好的话不要运行summary或者plot_model\\n# model.summary()\\n……\\n……\\n……\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 37s 1s/step - loss: 2.8832 -\\naccuracy: 0.0901 - val_loss: 2.9076 - val_accuracy: 0.0588\\nEpoch 2/100\\n34/34 [==============================] - 17s 490ms/step - loss: 2.48\\n76 - accuracy: 0.1838 - val_loss: 3.1728 - val_accuracy: 0.0588\\n……\\nEpoch 99/100\\n34/34 [==============================] - 17s 495ms/step - loss: 0.03\\n28 - accuracy: 0.9982 - val_loss: 0.9105 - val_accuracy: 0.8088\\nEpoch 100/100\\n34/34 [==============================] - 17s 495ms/step - loss: 0.02\\n48 - accuracy: 0.9991 - val_loss: 0.9058 - val_accuracy: 0.8088\\nResNeXt50 的模型程序跟ResNet50 差不多，使用一个函数\\ngrouped_convolution_block完成分组卷积的操作。建议大家使用 plot_model 看一下模型\\n结构（建议dpi使用96 或更低的值），groups=32画出来的图太大了，下面给大家看一下\\ngroups=4 画出来的图的残差结构，如图 12.11 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 420, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 421\\n图12.11 groups=4 的ResNeXt残差单元\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 421, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 422\\n12.10 SENet 图像识别\\n同样这里我们只展示SE-ResNet50 建模相关代码，如代码12-12 所示。\\n代码12-12：SE-ResNet50 图像识别\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob\\nalAvgPool2D,BatchNormalization,Activation,Add,ZeroPadding2D,Multiply\\n……\\n……\\n……\\n# SE模块\\ndef ChannelSE(input_tensor, reduction=16):\\n# 获得信号通道数\\nchannels = input_tensor.shape[-1]\\n# SE模块\\nx = GlobalAvgPool2D()(input_tensor)\\n# 把2 维数据再变成 4 维(?,1,1,?)\\nx = x[:, None, None, :]\\n# 卷积替代全连接层\\nx = Conv2D(filters=channels//reduction,kernel_size=1,strides=1)(x)\\nx = Activation('relu')(x)\\nx = Conv2D(filters=channels,kernel_size=1,strides=1)(x)\\nx = Activation('sigmoid')(x)\\nx = Multiply()([input_tensor, x])\\nreturn x\\n# 定义残差单元\\ndef block(x, filters, strides=1, conv_shortcut=True, reduction=16):\\n# projection shortcut\\nif conv_shortcut == True:\\nshortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x)\\n# epsilon为BN 公式中防止分母为零的值\\nshortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\\nelse:\\n# identity_shortcut\\nshortcut = x\\n# 3 个卷积层\\nx = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 422, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 423\\nx = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\n# SE模块\\nx = ChannelSE(x, reduction=reduction)\\nx = Add()([x, shortcut])\\nx = Activation('relu')(x)\\nreturn x\\n# 堆叠残差单元\\ndef stack(x, filters, blocks, strides):\\nx = block(x, filters, strides=strides)\\nfor i in range(blocks-1):\\nx = block(x, filters, conv_shortcut=False)\\nreturn x\\n# 定义SE-ResNet50\\ninputs = Input(shape=(image_size,image_size,3))\\n# 填充3 圈0，填充后图像从224×224变成230×230\\nx = ZeroPadding2D((3, 3))(inputs)\\nx= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x)\\nx = BatchNormalization(epsilon=1.001e-5)(x)\\nx = Activation('relu')(x)\\n# 填充1 圈0\\nx = ZeroPadding2D((1, 1))(x)\\nx = MaxPool2D(pool_size=3,strides=2,padding='valid')(x)\\n# 堆叠残差结构\\n# blocks表示堆叠数量\\nx = stack(x, filters=64, blocks=3, strides=1)\\nx = stack(x, filters=128, blocks=4, strides=2)\\nx = stack(x, filters=256, blocks=6, strides=2)\\nx = stack(x, filters=512, blocks=3, strides=2)\\n# 根据特征图大小进行平均池化，池化后得到 2 维数据\\nx = GlobalAvgPool2D()(x)\\nx = Dense(num_classes, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(inputs=inputs,outputs=x)\\n……\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 423, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 424\\n……\\n……\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/100\\n34/34 [==============================] - 27s 786ms/step - loss: 2.48\\n03 - accuracy: 0.2114 - val_loss: 2.8556 - val_accuracy: 0.0588\\nEpoch 2/100\\n34/34 [==============================] - 14s 401ms/step - loss: 1.82\\n87 - accuracy: 0.4017 - val_loss: 2.9926 - val_accuracy: 0.0588\\n……\\nEpoch 99/100\\n34/34 [==============================] - 14s 406ms/step - loss: 0.00\\n44 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.8088\\nEpoch 100/100\\n34/34 [==============================] - 14s 407ms/step - loss: 0.00\\n43 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.8088\\nSE-ResNet50 用plot_model 画出来的图会很大，大家可以自己运行，下面我就给大家\\n看一下SE-ResNet50 其中一个残差单元的图，如图12.12 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 424, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 425\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 425, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 426\\n图12.12 SE-ResNet50 残差单元\\n12.11 使用预训练模型进行迁移学习\\n12.11.1 使用训练好的模型进行图像识别\\n本章前面的内容中，我们主要是学习了模型搭建方法，这一小节我们将学习使用迁移学\\n习的方式来训练图像识别模型。图像识别的迁移学习简单的来说就是使用一个已经经过预训\\n练的模型，在这个预训练的模型基础上稍作修改，然后训练自己的数据集，也称为微调\\n（Finetune）。这里的预训练模型通常都是使用ImageNet比赛数据集训练出来的模型。\\nTensorflow 中有很多官方提供的使用ImageNet数据集训练好的预训练模型，我们可以直\\n接下载使用，如图12.13 所示。\\n图12.13 可用预训练模型\\n下面我们先看一下如何使用预训练模型来进行图像识别，第一次载入模型需要从网上下\\n载模型，下载的模型会存放在你的用户目录下.keras隐藏文件夹下的models文件夹中（比\\n如C:\\\\User\\\\qin\\\\.keras\\\\models）。我自己准备了一些图片存放在“test”文件夹中用于测\\n试，如代码12-13 所示。\\n代码12-13：使用训练好的 ResNet50 进行图像识别\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 426, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 427\\n# imagenet数据处理工具\\nfrom tensorflow.keras.applications.imagenet_utils import decode_predictions,preprocess_in\\nput\\nfrom tensorflow.keras.preprocessing.image import img_to_array,load_img\\nimport matplotlib.pyplot as plt\\nimport os\\nimport numpy as np\\n# 图片大小\\nimage_size = 224\\n# 存放测试图片的文件夹\\nimage_dir = 'test'\\n# 载入使用imagenet训练好的预训练模型\\n# include_top=True表示模型包含全连接层\\n# include_top=False表示模型不包含全连接层\\n# 下载的程序会存放在你的用户目录下.keras隐藏文件夹下的models文件夹中\\nresnet50 = ResNet50(weights='imagenet',include_top=True, input_shape=(image_size,ima\\nge_size,3))\\n# 循环目录下的图片并进行显示预测\\nfor file in os.listdir(image_dir):\\n# 测试图片完整路径\\nfile_dir = os.path.join(image_dir,file)\\n# 读入图片，并resize 为224*224大小\\nimg = load_img(file_dir, target_size=(224, 224))\\n# 显示图片\\nplt.imshow(img)\\nplt.axis('off')\\nplt.show()\\n# 将图片转化为array\\nx = img_to_array(img)\\n# 增加1 个维度变成 4 维数据\\n# (224, 224, 3)->(1, 224, 224, 3)\\nx = np.expand_dims(x, axis=0)\\n# 把像素数值归一化为(-1,1)之间，并让RGB通道减去对应均值\\nx = preprocess_input(x)\\n# preds.shap->(1, 1000),1000个概率值\\npreds = resnet50.predict(x)\\n# decode_predictions用于预测结果解码\\n# 将测试结果解码为如下形式：\\n# [(编码1, 英文名称1, 概率1),(编码 2, 英文名称2, 概率2)...]\\n# top=1 表示概率最大的1 个结果，top=3 表示概率最大的3 个结果\\npredicted_classes = decode_predictions(preds, top=1)\\nimagenet_id, name, confidence = predicted_classes[0][0]\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 427, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 428\\n# 打印结果\\nprint(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100))\\n运行结果如下：\\nThis is a sandbar with 44.15% confidence!\\nThis is a soup_bowl with 61.99% confidence!\\nThis is a tabby named chouchou with 90.97% confidence!\\n12.11.2 使用训练好的模型进行迁移学习\\n现在我们要使用预训练的模型来训练自己的数据集了，为了方便，我还是使用 17flowers\\n的数据集，如果大家有其他数据集的话也可以使用。使用VGG16 完成迁移学习的代码如代\\n码12-14 所示。\\n代码12-14：使用VGG16 完成迁移学习\\nfrom tensorflow.keras.applications.vgg16 import VGG16\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dropout,Flatten,Dense\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 428, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 429\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load\\n_img\\nimport json\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 类别数\\nnum_classes = 17\\n# 批次大小\\nbatch_size = 32\\n# 周期数\\nepochs = 40\\n# 图片大小\\nimage_size = 224\\n# 训练集数据进行数据增强\\ntrain_datagen = ImageDataGenerator(\\nrotation_range = 20, # 随机旋转度数\\nwidth_shift_range = 0.1, # 随机水平平移\\nheight_shift_range = 0.1,# 随机竖直平移\\nrescale = 1/255, # 数据归一化\\nshear_range = 10, # 随机错切变换\\nzoom_range = 0.1, # 随机放大\\nhorizontal_flip = True, # 水平翻转\\nbrightness_range=(0.7, 1.3), # 亮度变化\\nfill_mode = 'nearest', # 填充方式\\n)\\n# 测试集数据只需要归一化就可以\\ntest_datagen = ImageDataGenerator(\\nrescale = 1/255, # 数据归一化\\n)\\n# 训练集数据生成器，可以在训练时自动产生数据进行训练\\n# 从'data/train'获得训练集数据\\n# 获得数据后会把图片resize 为image_size×image_size的大小\\n# generator每次会产生batch_size个数据\\ntrain_generator = train_datagen.flow_from_directory(\\n'data/train',\\ntarget_size=(image_size,image_size),\\nbatch_size=batch_size,\\n)\\n# 测试集数据生成器\\ntest_generator = test_datagen.flow_from_directory(\\n'data/test',\\ntarget_size=(image_size,image_size),\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 429, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 430\\nbatch_size=batch_size,\\n)\\n# 字典的键为17 个文件夹的名字，值为对应的分类编号\\nlabel = train_generator.class_indices\\n# 把字典的键值对反过来\\n# 分类编号为键，分类名称为值\\nlabel = dict(zip(label.values(),label.keys()))\\n# 保存到json 文件中\\nfile = open('label_flower.json','w',encoding='utf-8')\\njson.dump(label, file)\\n# 载入使用imagenet训练好的预训练模型\\n# include_top=True表示模型包含全连接层\\n# include_top=False表示模型不包含全连接层\\nvgg16 = VGG16(weights='imagenet',include_top=False, input_shape=(image_size,image_s\\nize,3))\\n# 搭建全连接层，连接在VGG16 模型后面\\n# 我们主要是利用VGG16 卷积网络已经训练好的特征提取能力来提取特征\\n# 然后搭建新的全连接层来进行新图片类型的分类\\ntop_model = Sequential()\\ntop_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\\ntop_model.add(Dense(256,activation='relu'))\\ntop_model.add(Dropout(0.5))\\ntop_model.add(Dense(num_classes,activation='softmax'))\\nmodel = Sequential()\\nmodel.add(vgg16)\\nmodel.add(top_model)\\n# 定义优化器，代价函数，训练过程中计算准确率，设置一个较小的学习率\\nmodel.compile(optimizer=SGD(lr=1e-\\n3,momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])\\n# Tensorflow2.1版本之前可以使用fit_generator训练模型\\n# history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc\\nhs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\\n# Tensorflow2.1版本(包括2.1)之后可以直接使用fit 训练模型\\nhistory = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator)\\n运行结果如下：\\nTrain for 34 steps, validate for 9 steps\\nEpoch 1/40\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 430, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 431\\n34/34 [==============================] - 15s 440ms/step - loss: 2.83\\n96 - accuracy: 0.1131 - val_loss: 2.2644 - val_accuracy: 0.2904\\nEpoch 2/40\\n34/34 [==============================] - 14s 406ms/step - loss: 1.97\\n65 - accuracy: 0.3713 - val_loss: 1.3263 - val_accuracy: 0.6029\\n……\\nEpoch 39/40\\n34/34 [==============================] - 14s 402ms/step - loss: 0.00\\n62 - accuracy: 0.9991 - val_loss: 0.1977 - val_accuracy: 0.9632\\nEpoch 40/40\\n34/34 [==============================] - 14s 399ms/step - loss: 0.01\\n21 - accuracy: 0.9945 - val_loss: 0.1575 - val_accuracy: 0.9706\\n# 画出训练集准确率曲线图\\nplt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy')\\n# 画出验证集准确率曲线图\\nplt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy')\\n# 图例\\nplt.legend()\\n# x坐标描述\\nplt.xlabel('epochs')\\n# y坐标描述\\nplt.ylabel('accuracy')\\n# 显示图像\\nplt.show()\\n# 模型保存\\nmodel.save('vgg16.h5')\\n运行结果如下：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 431, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 432\\n从结果我们可以看到是用了预训练的 VGG16 模型来训练17flowers数据集，模型的收\\n敛速度非常快，只训练几个周期就得到了很好的结果。并且训练 40 个周期以后，模型的验\\n证集达到了97%非常高的准确率。\\n12.11.3 载入训练好的模型进行预测\\n上一小节我们训练好了一个97%准确率的 17 种花的识别模型并保存为“vgg16.h5“模\\n型文件，这个小节我们要重新载入这个训练好的模型，使用它对其他图片进行预测。模型分\\n类编号跟分类名称的对应关系在上小节的程序里面也已经保存在“label_flower.json”文件\\n中，可以直接载入。我准备了几张测试图片存放在“flowers_test”文件夹中，测试图片的\\n文件名就是该图片的分类名称，如代码 12-15 所示。\\n代码12-15：载入训练好的模型进行预测（片段1）\\nfrom tensorflow.keras.models import load_model\\nfrom tensorflow.keras.preprocessing.image import img_to_array,load_img\\nimport json\\nimport os\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 测试图片存放位置\\nimage_dir = 'flowers_test'\\n# 载入标签json 文件\\nfile = open('label_flower.json','r',encoding='utf-8')\\nlabel = json.load(file)\\n# 键为分类编号，值为分类名称\\nprint(label)\\n运行结果如下：\\n{'0': 'flower0', '1': 'flower1', '2': 'flower10', '3': 'flower11', '4\\n': 'flower12', '5': 'flower13', '6': 'flower14', '7': 'flower15', '8\\n': 'flower16', '9': 'flower2', '10': 'flower3', '11': 'flower4', '12\\n': 'flower5', '13': 'flower6', '14': 'flower7', '15': 'flower8', '16\\n': 'flower9'}\\n代码12-15：载入训练好的模型进行预测（片段2）\\n# 载入训练好的模型\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 432, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 433\\nmodel = load_model('VGG16.h5')\\n# 预测函数\\ndef model_predict(file_dir):\\n# 读入图片，并resize 为224*224大小\\nimg = load_img(file_dir, target_size=(224, 224))\\n# 显示图片\\nplt.imshow(img)\\nplt.axis('off')\\nplt.show()\\n# 将图片转化为array\\nx = img_to_array(img)\\n# 增加1 个维度变成 4 维数据\\n# (224, 224, 3)->(1, 224, 224, 3)\\nx = np.expand_dims(x, axis=0)\\n# 模型预测结果\\n# predict_classes直接返回预测分类结果，比如:[2]\\npreds = model.predict_classes(x)\\n# label字典中的键为字符串，所以这里需要把 preds[0]转为str\\n# 根据分类编号查询label中对应的分类名称\\npreds = label[str(preds[0])]\\nreturn preds\\n# 循环测试文件夹\\nfor file in os.listdir(image_dir):\\n# 测试图片完整路径\\nfile_dir = os.path.join(image_dir,file)\\n# 打印文件路径\\nprint(file_dir)\\n# 传入文件路径进行预测\\npreds = model_predict(file_dir)\\nprint('predict:',preds)\\nprint('-'*20)\\n运行结果如下：\\nflowers_test\\\\flower0.jpg\\npredict: flower0\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 433, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 434\\n--------------------\\nflowers_test\\\\flower10.jpg\\npredict: flower10\\n--------------------\\nflowers_test\\\\flower5.jpg\\npredict: flower5\\n--------------------\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 434, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 435\\n第 13 章-验证码识别项目实战\\n本章属于内外兼修的章节，既有多任务学习和 CTC 算法介绍，又有大量Tensorflow 应\\n用技巧，如tf.data的使用，如何自定义数据生成器，如何自定义Callbacks，多种\\nCallbacks用法，多任务模型的定义和训练。\\n本章模型训练所需时间较长，如果情况允许的情况下，建议大家使用 GPU来训练模型，\\n提高效率。如果使用CPU训练本章模型，每个模型大约需要 2 天时间。\\n13.1 多任务学习介绍\\n多任务学习（Multi-task Learning）是深度学习中很常用的一种模型训练策略，意思\\n其实也很简单，就是同时训练多个任务，给大家举两个例子大家就明白了。比如目标检测项\\n目中，我们既要知道目标所在的位置（也就是预测框坐标值），也要知道预测框内是什么物\\n体。预测框的坐标值是连续型数据，所以是一个回归任务；预测框的物体是一个具体的类\\n别，所以是一个分类任务。如图13.1 所示。\\n图13.1 目标检测任务\\n图中的task1 和task2 可以共享卷积层。task1 就是目标检测的回归任务，用来预测目标\\n框的位置，我们只要知道目标框左上角的(x1,y1)坐标和右下角的(x2,y2)坐标就可以把目标框\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 435, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 436\\n给画出来，所以task1 中需要4 个神经元来预测4 个回归值。task2 的作用是判断目标框内\\n是什么物体，假设我们这个目标检测任务一共有 5 个分类，那么就需要5 个神经元来预测5\\n个分类结果。\\n再给大家举一个例子，比如我们在做人脸识别的时候，我们不仅可以识别人脸所在的位\\n置，还可以识别人的年龄，表情，性别等特征。使用多任务学习的方式，我们可以让模型同\\n时训练多个任务，模型训练好以后，输入一张图片，模型就可以输出人脸的位置，以及人的\\n年龄，表情，性别，如图13.2 所示。\\n图13.2 人脸识别任务\\n如图所示，task1 任务是识别人脸所在位置，属于回归任务；task2 任务是识别人的年\\n龄，也是回归任务；task3 任务是识别人的表情，人的表情可以人为的标注几个类别，属于\\n分类任务；task4 任务是识别人的性别，当然也是分类任务。所以我们可以看到使用多任务\\n学习模型可以同时训练多个任务，在模型预测阶段也可以同时对多个任务进行预测。\\n我前面提到的多任务人脸识别的例子中，不同的任务其实也可以共享卷积层。因为卷积\\n层的作用主要是特征提取，先提取图像的特征，然后再使用这些特征来预测人的年龄，表\\n情，性别。用于特征提取的卷积层可以共享，不过不同的任务还需要有自己的 task layer，\\n专门用于训练特定任务。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 436, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 437\\n13.2 验证码数据集生成\\n验证码想必大家都很熟悉了，下面我们就来介绍一下我们本章要使用的验证码数据集。\\n有一个python模块是专门用来生成验证码图片的，打开命令提示符输入命令：\\npip install captcha\\n验证码图片生成的代码如代码13-1 所示。\\n代码 13-1：验证码生成\\n# 安装验证码生成库:pip install captcha\\nfrom captcha.image import ImageCaptcha\\nimport random\\nimport string\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits+string.ascii_letters\\n# 随机产生验证码，长度为4\\ndef random_captcha_text(char_set=characters, captcha_size=4):\\n# 验证码列表\\ncaptcha_text = []\\nfor i in range(captcha_size):\\n# 随机选择\\nc = random.choice(char_set)\\n# 加入验证码列表\\ncaptcha_text.append(c)\\nreturn captcha_text\\n# 生成字符对应的验证码\\ndef gen_captcha_text_and_image():\\n# 验证码图片宽高可以设置，默认width=160, height=60\\nimage = ImageCaptcha(width=160, height=60)\\n# 获得随机生成的验证码\\ncaptcha_text = random_captcha_text()\\n# 把验证码列表转为字符串\\ncaptcha_text = ''.join(captcha_text)\\n# 保存验证码图片\\nimage.write(captcha_text, 'captcha/' + captcha_text + '.jpg')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 437, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 438\\n# 产生1000 次随机验证码\\n# 真正的数量可能会少于1000\\n# 因为重名的图片会被覆盖掉\\nnum = 1000\\nfor i in range(num):\\ngen_captcha_text_and_image()\\nprint(\"生成完毕\")\\n程序运行后会在‘captcha’文件夹下产生差不多1000 张验证码的图片，虽然生成验证\\n码的程序运行了1000 次，不过有可能会产生两张重名的图片，第二张图片会把第一张图片\\n给覆盖掉，所以实际图片可能不到1000 张。运行程序后得到的验证码图片如图13.3 所示。\\n图13.3 验证码图片\\n13.3 tf.data 介绍\\ntf.data是一个很好用的数据读取管道搭建的API，具有高性能并且简洁易用的特点。我\\n们可以使用tf.data来定义数据从哪里获取，获取以后如何对数据进行处理，处理以后还可以\\n打乱数据，给数据进行分批次等，总而言之 tf.data的作用就是用来获取并处理数据的。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 438, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 439\\ntf.data最常用的用法就是使用tf.data.Dataset.from_tensor_slices 来获取数据，例如：\\ndataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n(x_train, y_train)是训练集数据和对应标签。\\ntf.data.Dataset支持一类特殊的操作：Transformation。一个Dataset通过\\nTransformation 可以变成一个新的Dataset。通常我们就是使用Transformation 来对数据\\n进行处理的。例如：\\n1.使用shuffle来打乱数据：\\ndataset_train = dataset_train.shuffle(buffer_size=1000)\\n2.使用map进行数据处理。map可以接收一个自定义数据处理函数，Dataset中的数\\n据会传入map中的函数进行处理，并返回处理后的数据作为新的Dataset：\\ndataset_train = dataset_train.map(image_function)\\n3.使用repeat 来重复数据。repeat可以将数据序列重复n 次，其实也就是重复n 个周\\n期epoch。一般我认为就只重复1 个周期比较好，因为模型训练的时候(model.fit)还会再设\\n置模型训练周期：\\ndataset_train = dataset_train.repeat(1)\\n4.使用batch来设置数据产生的批次大小：\\ndataset_train = dataset_train.batch(batch_size)\\n这几个Transformation 是用得比较多的，还有其他的一些 Transformation 这里我们就\\n不一一列出了。\\n定义好Dataset以后我们可以使用：\\nx,y = next(iter(dataset_test))\\n来获得一个批次的数据和标签，查看数据的情况。\\n也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次数据：\\nfor x,y in dataset_test:\\npass\\n模型训练阶段可以把Dataset传入model.fit中进行训练：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 439, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 440\\nmodel.fit(x=dataset_train)\\n除非是在本书相关的实际应用中用到，否则我就不展开介绍 Tensorflow 的一些细节上的\\n使用了，如果不结合实际应用很多内容感觉说不明白。更多 tf.data的使用方法可以参考\\nTensorflow 官方指南（https://tensorflow.google.cn/guide/data）。\\n13.4 使用 tf.data 完成多任务学习-验证码识\\n别\\n13.4.1 使用 tf.data 完成多任务学习模型训练\\n本小节我们将介绍使用多任务学习的方法来进行验证码识别，比如我们要识别的验证码\\n有4 个字符，我们可以给模型定义 4 个任务，每个任务负责识别1 个字符。第一个任务识别\\n第一个字符，第二个任务识别第二个字符，第三个任务识别第三个字符，第四个任务识别第\\n四个字符。模型框架如图13.4 所示。\\n13.4 验证码识别模型框架\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 440, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 441\\n图中的4 个输出表示 4 个任务，每个输出都是62 分类是由于我们使用的验证码的字符是\\n数字加上大小写英文字母所以一共62 种字符。\\n代码13-2：tf.data-多任务学习-验证码识别（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\nfrom tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc\\neLROnPlateau\\nimport string\\nimport numpy as np\\nimport os\\nfrom plot_model import plot_model\\n# 字符包含所有数字和所有小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数62\\nnum_classes = len(characters)\\n# 批次大小\\nbatch_size = 64\\n# 周期数\\nepochs=100\\n# 训练集数据，大约50000张图片\\n# 事先用captcha 模块生成，长度都是 4\\ntrain_dir = \"./captcha/train/\"\\n# 测试集数据，大约10000张图片\\n# 事先用captcha 模块生成，长度都是 4\\ntest_dir = \"./captcha/test/\"\\n# 图片宽度\\nwidth=160\\n# 图片高度\\nheight=60\\n# 获取所有验证码图片路径和标签\\ndef get_filenames_and_classes(dataset_dir):\\n# 存放图片路径\\nphoto_filenames = []\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 441, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 442\\n# 存放图片标签\\ny = []\\nfor filename in os.listdir(dataset_dir):\\n# 获取文件完整路径\\npath = os.path.join(dataset_dir, filename)\\n# 保存图片路径\\nphoto_filenames.append(path)\\n# 取文件名前4 位，也就是验证码的标签\\ncaptcha_text = filename[0:4]\\n# 定义一个空label\\nlabel = np.zeros((4, num_classes), dtype=np.uint8)\\n# 标签转独热编码\\nfor i, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\n# characters.find(ch)得到ch 在 characters中的位置，可以理解为ch 的编号\\nlabel[i, characters.find(ch)] = 1\\n# 保存独热编码的标签\\ny.append(label)\\n# 返回图片路径和标签\\nreturn np.array(photo_filenames),np.array(y)\\n# 获取训练集图片路径和标签\\nx_train,y_train = get_filenames_and_classes(train_dir)\\n# 获取测试集图片路径和标签\\nx_test,y_test = get_filenames_and_classes(test_dir)\\n# 图像处理函数\\n# 获得每一条数据的图片路径和标签\\ndef image_function(filenames, label):\\n# 根据图片路径读取图片内容\\nimage = tf.io.read_file(filenames)\\n# 将图像解码为jpeg 格式的3 维数据\\nimage = tf.image.decode_jpeg(image, channels=3)\\n# 归一化\\nimage = tf.cast(image, tf.float32) / 255.0\\n# 返回图片数据和标签\\nreturn image, label\\n# 标签处理函数\\n# 获得每一个批次的图片数据和标签\\ndef label_function(image, label):\\n# transpose 改变数据的维度，比如原来的数据shape 是(64,4,62)\\n# 这里的64 是批次大小，验证码长度为4 有4 个标签，62 是62 个不同的字符\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 442, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 443\\n# tf.transpose(label,[1,0,2])计算后得到的shape 为(4,64,62)\\n# 原来的第1 个维度变成了第0 维度，原来的第0 维度变成了1 维度，第2 维不变\\n# (64,4,62)->(4,64,62)\\nlabel = tf.transpose(label,[1,0,2])\\n# 返回图片内容和标签，注意这里标签的返回，我们的模型会定义4 个任务，所以这里返\\n回4 个标签\\n# 每个标签的shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签\\nreturn image, (label[0],label[1],label[2],label[3])\\n# 创建dataset对象，传入训练集图片路径和标签\\ndataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n# 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值\\n# reshuffle_each_iteration=True，每次迭代都会随机打乱\\ndataset_train = dataset_train.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\\n# map-可以自定义一个函数来处理每一条数据\\ndataset_train = dataset_train.map(image_function)\\n# 数据重复生成1 个周期\\ndataset_train = dataset_train.repeat(1)\\n# 定义批次大小\\ndataset_train = dataset_train.batch(batch_size)\\n# 注意这个map 和前面的map 有所不同，第一个map 在batch 之前，所以是处理每一条数\\n据\\n# 这个map 在batch 之后，所以是处理每一个 batch 的数据\\ndataset_train = dataset_train.map(label_function)\\n# 创建dataset对象，传入测试集图片路径和标签\\ndataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\n# 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值\\n# reshuffle_each_iteration=True，每次迭代都会随机打乱\\ndataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\\n# map-可以自定义一个函数来处理每一条数据\\ndataset_test = dataset_test.map(image_function)\\n# 数据重复生成1 个周期\\ndataset_test = dataset_test.repeat(1)\\n# 定义批次大小\\ndataset_test = dataset_test.batch(batch_size)\\n# 注意这个map 和前面的map 有所不同，第一个map 在batch 之前，所以是处理每一条数\\n据\\n# 这个map 在batch 之后，所以是处理每一个 batch 的数据\\ndataset_test = dataset_test.map(label_function)\\n# 生成一个批次的数据和标签\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 443, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 444\\n# 可以用于查看数据和标签的情况\\nx,y = next(iter(dataset_test))\\nprint(x.shape)\\nprint(np.array(y).shape)\\n结果输出为：\\n(64, 60, 160, 3)\\n(4, 64, 62)\\n代码13-2：tf.data-多任务学习-验证码识别（片段2）\\n# 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次\\n# for x,y in dataset_test:\\n# pass\\n# 载入预训练的resnet50 模型\\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)\\n)\\n# 设置输入\\ninputs = Input((height,width,3))\\n# 使用resnet50 进行特征提取\\nx = resnet50(inputs)\\n# 平均池化\\nx = GlobalAvgPool2D()(x)\\n# 把验证码识别的4 个字符看成是4 个不同的任务\\n# 每个任务负责识别1 个字符\\n# 任务1 识别第1 个字符，任务2 识别第 2 个字符，任务3 识别第3 个字符，任务4 识别第\\n4 个字符\\nx0 = Dense(num_classes, activation='softmax', name='out0')(x)\\nx1 = Dense(num_classes, activation='softmax', name='out1')(x)\\nx2 = Dense(num_classes, activation='softmax', name='out2')(x)\\nx3 = Dense(num_classes, activation='softmax', name='out3')(x)\\n# 定义模型\\nmodel = Model(inputs, [x0,x1,x2,x3])\\n# 画图\\nplot_model(model,style=0)\\n# 4 个任务我们可以定义4 个loss\\n# loss_weights可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样\\nmodel.compile(loss={'out0':'categorical_crossentropy',\\n'out1':'categorical_crossentropy',\\n'out2':'categorical_crossentropy',\\n'out3':'categorical_crossentropy'},\\nloss_weights={'out0':1,\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 444, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 445\\n'out1':1,\\n'out2':1,\\n'out3':1},\\noptimizer=SGD(lr=1e-2,momentum=0.9),\\nmetrics=['acc'])\\n# 监控指标统一使用val_loss\\n# 可以使用EarlyStopping来让模型停止，连续6 个周期val_loss没有下降就结束训练\\n# CSVLogger保存训练数据\\n# ModelCheckpoint保存所有训练周期中 val_loss最低的模型\\n# ReduceLROnPlateau学习率调整策略，连续3 个周期val_loss没有下降当前学习率乘以\\n0.1\\ncallbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),\\nCSVLogger('Captcha_tfdata.csv'),\\nModelCheckpoint('Best_Captcha_tfdata.h5', monitor='val_loss', save_best_only=Tr\\nue),\\nReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\\n# 训练模型\\n# 把之前定义的dataset_train和dataset_test传入进行训练\\nmodel.fit(x=dataset_train,\\nepochs=epochs,\\nvalidation_data=dataset_test,\\ncallbacks=callbacks)\\n结果输出为：\\nTrain for 781 steps, validate for 156 steps\\nEpoch 1/100\\n781/781 [==============================] - 96s 123ms/step - loss: 7.\\n1427 - out0_loss: 1.3058 - out1_loss: 2.1121 - out2_loss: 2.0675 - ou\\nt3_loss: 1.6573 - out0_acc: 0.6824 - out1_acc: 0.4488 - out2_acc: 0.4\\n548 - out3_acc: 0.5494 - val_loss: 16.5515 - val_out0_loss: 9.0025 -\\nval_out1_loss: 3.4140 - val_out2_loss: 2.1353 - val_out3_loss: 1.999\\n7 - val_out0_acc: 0.0323 - val_out1_acc: 0.2611 - val_out2_acc: 0.472\\n8 - val_out3_acc: 0.4884\\n……\\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999019\\n782991e-06.\\n781/781 [==============================] - 88s 113ms/step - loss: 0.\\n0088 - out0_loss: 0.0028 - out1_loss: 0.0020 - out2_loss: 0.0018 - ou\\nt3_loss: 0.0021 - out0_acc: 1.0000 - out1_acc: 0.9999 - out2_acc: 1.0\\n000 - out3_acc: 1.0000 - val_loss: 0.6167 - val_out0_loss: 0.2020 - v\\nal_out1_loss: 0.1470 - val_out2_loss: 0.1508 - val_out3_loss: 0.1168\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 445, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 446\\n- val_out0_acc: 0.9550 - val_out1_acc: 0.9644 - val_out2_acc: 0.9647\\n- val_out3_acc: 0.9708\\nEpoch 00023: early stopping\\n模型的初始学习率为0.01，随着模型训练学习率会逐渐降低，最后模型训练了 23 周期\\n就提前停止了。我们可以看到训练集的 4 个任务准确率基本上都已经是1 了，测试集的4 个\\n任务准确率大约为0.96 左右，有一定的过拟合现象也是正常的。\\n别看0.96 的准确率好像挺高的，验证码识别可是要 4 个验证码都识别正确，最后的结果\\n才算正确。所以真正的识别正确率大约是 4 个任务的正确率相乘约等于0.86，结果也还可\\n以，不过这么看好像就不算非常高了。\\n13.4.2 使用 tf.data 完成多任务学习模型预测\\n下面我们再来看一下载入训练好的模型进行准确率计算和验证码结果预测的程序，如代\\n码13-3 所示。。\\n代码13-3：tf.data-多任务学习-验证码识别-模型预测（片段1）\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import load_model\\nimport matplotlib.pyplot as plt\\nimport os\\nimport numpy as np\\nimport string\\n# 载入之前训练好的模型\\nmodel = load_model('Best_Captcha_tfdata.h5')\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数\\nnum_classes = len(characters)\\n# 批次大小\\nbatch_size = 64\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 446, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 447\\n# 测试集数据，大约10000张图片\\n# 事先用captcha 模块生成，长度都是 4\\ntest_dir = \"./captcha/test/\"\\n# 获取所有验证码图片路径和标签\\ndef get_filenames_and_classes(dataset_dir):\\n# 存放图片路径\\nphoto_filenames = []\\n# 存放图片标签\\ny = []\\nfor filename in os.listdir(dataset_dir):\\n# 获取文件完整路径\\npath = os.path.join(dataset_dir, filename)\\n# 保存图片路径\\nphoto_filenames.append(path)\\n# 取文件名前4 位，也就是验证码的标签\\ncaptcha_text = filename[0:4]\\n# 定义一个空label\\nlabel = np.zeros((4, num_classes), dtype=np.uint8)\\n# 标签转独热编码\\nfor i, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\n# characters.find(ch)得到ch 在 characters中的位置，可以理解为ch 的编号\\nlabel[i, characters.find(ch)] = 1\\n# 保存独热编码的标签\\ny.append(label)\\n# 返回图片路径和标签\\nreturn np.array(photo_filenames),np.array(y)\\n# 获取测试集图片路径和标签\\nx_test,y_test = get_filenames_and_classes(test_dir)\\n# 图像处理函数\\n# 获得每一条数据的图片路径和标签\\ndef image_function(filenames, label):\\n# 根据图片路径读取图片内容\\nimage = tf.io.read_file(filenames)\\n# 将图像解码为jpeg 格式的3 维数据\\nimage = tf.image.decode_jpeg(image, channels=3)\\n# 归一化\\nimage = tf.cast(image, tf.float32) / 255.0\\n# 返回图片数据和标签\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 447, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 448\\nreturn image, label\\n# 标签处理函数\\n# 获得每一个批次的图片数据和标签\\ndef label_function(image, label):\\n# transpose 改变数据的维度，比如原来的数据shape 是(64,4,62)\\n# 这里的64 是批次大小，验证码长度为4 有4 个标签，62 是62 个不同的字符\\n# tf.transpose(label,[1,0,2])计算后得到的shape 为(4,64,62)\\n# 原来的第1 个维度变成了第0 维度，原来的第0 维度变成了1 维度，第2 维不变\\n# (64,4,62)->(4,64,62)\\nlabel = tf.transpose(label,[1,0,2])\\n# 返回图片内容和标签，注意这里标签的返回，我们的模型会定义4 个任务，所以这里返\\n回4 个标签\\n# 每个标签的shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签\\nreturn image, (label[0],label[1],label[2],label[3])\\n# 创建dataset对象，传入测试集图片路径和标签\\ndataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\\n# 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值\\n# reshuffle_each_iteration=True，每次迭代都会随机打乱\\ndataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\\n# map-可以自定义一个函数来处理每一条数据\\ndataset_test = dataset_test.map(image_function)\\n# 数据重复生成1 个周期\\ndataset_test = dataset_test.repeat(1)\\n# 定义批次大小\\ndataset_test = dataset_test.batch(batch_size)\\n# 注意这个map 和前面的map 有所不同，第一个map 在batch 之前，所以是处理每一条数\\n据\\n# 这个map 在batch 之后，所以是处理每一个 batch 的数据\\ndataset_test = dataset_test.map(label_function)\\n# 用于统计准确率\\nacc_sum = 0\\n# 统计批次数量\\nn = 0\\nfor x,y in dataset_test:\\n# 计算批次数量\\nn+=1\\n# 进行一个批次的预测\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred, axis=-1)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 448, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 449\\n# 获得标签数据\\nlabel = np.argmax(y, axis=-1)\\n# 计算这个批次的准确率然后累加到总的准确率统计中\\nacc_sum += (pred == label).all(axis=0).mean()\\n# 计算测试集准确率\\nprint(acc_sum / n)\\n结果输出为：\\n0.8631052107614607\\n代码13-3：tf.data-多任务学习-验证码识别-模型预测（片段2）\\n# 把标签编号变成字符串\\n# 如[2,34,22,45]->\\'2ymJ\\'\\ndef labels_to_text(labels):\\nret = []\\nfor l in labels:\\nret.append(characters[l])\\nreturn \"\".join(ret)\\n# 把一个批次的标签编号都变成字符串\\ndef decode_batch(labels):\\nret = []\\nfor label in labels:\\nret.append(labels_to_text(label))\\nreturn np.array(ret)\\n# 获得一个批次数据\\nx,y = next(iter(dataset_test))\\n# 预测结果\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred, axis=-1)\\n# shape 转换\\n# (4,64)->(64,4)\\npred = pred.T\\n# 获得标签数据\\nlabel = np.argmax(y, axis=-1)\\n# (4,64)->(64,4)\\nlabel = label.T\\n# 根据编号获得对应验证码\\npred = decode_batch(pred)\\n# 根据编号获得对应验证码\\nlabel = decode_batch(label)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 449, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 450\\n# 获取前3 张图片数据\\nfor i,image in enumerate(x[:3]):\\n# 显示图片\\nplt.imshow(image)\\n# 设置标题\\nplt.title('real:%s\\\\npred:%s'%(label[i],pred[i]))\\nplt.show()\\n结果输出为：\\n我们可以看到，要把4 个验证码都预测正确其实还是挺难的，因为我这里做的验证码识\\n别是需要区分大小写的，比如第一张图片中的第 3 个字符正确标签是小x，模型预测结果是\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 450, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 451\\n大X，这确实很容易判断错误。还有0 小o大O等这些都比较容易混淆，所以能得到86%\\n的准确率也还算不错了。\\n13.5 使用自定义数据生成器完成验证码识别\\n13.5.1 使用自定义数据生成器完成模型训练\\n我们之前有用过Tensorflow.keras 自带的一个专门用来处理图片数据的生成器\\nImageDataGenerator，它可以从电脑硬盘读取数据，然后进行数据增强处理，再生成一个\\n一个批次的数据，在model.fit中进行模型训练。\\n我们现在要做的验证码识别项目使用的数据集是一个 python模块自动生成的，所以在\\n训练模型的时候我们可以一边生成数据集一边训练模型，那么我们可以自定义一个生成器来\\n完成这个数据生成的工作。本小节我们也将使用多任务学习的方式来完成验证码识别的模型\\n训练，不过我们这次不是用tf.data来获取和处理数据，我们将通过自定义数据生成器来完成\\n数据的产生和处理，如代码13-4 所示。。\\n代码13-4：自定义数据生成器-验证码识别（片段1）\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\nfrom tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D\\nfrom tensorflow.keras.models import Model,Sequential\\nfrom tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc\\neLROnPlateau\\nfrom captcha.image import ImageCaptcha\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport random\\nimport string\\nfrom plot_model import plot_model\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 451, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 452\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数\\nnum_classes = len(characters)\\n# 批次大小\\nbatch_size = 64\\n# 训练集批次数\\n# 训练集大小相当于是64*1000=64000\\ntrain_steps = 1000\\n# 测试集批次数\\n# 测试集大小相当于是64*100=6400\\ntest_steps = 100\\n# 周期数\\nepochs=100\\n# 图片宽度\\nwidth=160\\n# 图片高度\\nheight=60\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\n# 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的，\\n# 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次，\\n# Sequence一般是定义一个训练周期内每个批次的数据如何产生。\\n# 我们这里的验证码数据集使用captcha 模块生产出来的，一边生产一边训练，可以认为数\\n据集是无限的。\\nclass CaptchaSequence(Sequence):\\n# __getitem__和__len__是必须定义的两个方法\\ndef __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60):\\n# 字符集\\nself.characters = characters\\n# 批次大小\\nself.batch_size = batch_size\\n# 生成器生成多少个批次的数据\\nself.steps = steps\\n# 验证码长度\\nself.n_len = n_len\\n# 验证码图片宽度\\nself.width = width\\n# 验证码图片高度\\nself.height = height\\n# 字符集长度\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 452, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 453\\nself.num_classes = len(characters)\\n# 用于产生验证码图片\\nself.image = ImageCaptcha(width=self.width, height=self.height)\\n# 用于保存最近一个批次验证码字符\\nself.captcha_list = []\\n# 获得index位置的批次数据\\ndef __getitem__(self, index):\\n# 初始化数据用于保存验证码图片\\nx = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\\n# 初始化数据用于保存标签\\n# n_len是多任务学习的任务数量，这里是4 个任务，batch 批次大小，num_classes分\\n类数量\\ny = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8)\\n# 数据清0\\nself.captcha_list = []\\n# 生产一个批次数据\\nfor i in range(self.batch_size):\\n# 随机产生验证码\\ncaptcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\\nself.captcha_list.append(captcha_text)\\n# 生产验证码图片数据并进行归一化处理\\nx[i] = np.array(self.image.generate_image(captcha_text)) / 255.0\\n# j(0-3),i(0-61),ch(单个字符)\\n# self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号\\nfor j, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\ny[j, i, self.characters.find(ch)] = 1\\n# 返回一个批次的数据和标签\\nreturn x, [y[0],y[1],y[2],y[3]]\\n# 返回批次数量\\ndef __len__(self):\\nreturn self.steps\\n# 测试生成器\\n# 一共一个批次，批次大小也是1\\ndata = CaptchaSequence(characters, batch_size=1, steps=1)\\nfor i in range(2):\\n# 产生一个批次的数据\\nx, y = data[0]\\n# 显示图片\\nplt.imshow(x[0])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 453, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 454\\n# 验证码字符和对应编号\\nplt.title(data.captcha_list[0])\\nplt.show()\\n结果输出为：\\n代码13-4：自定义数据生成器-验证码识别（片段2）\\n# 载入预训练的resnet50 模型\\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)\\n)\\n# 设置输入\\ninputs = Input((height,width,3))\\n# 使用resnet50 进行特征提取\\nx = resnet50(inputs)\\n# 平均池化\\nx = GlobalAvgPool2D()(x)\\n# 把验证码识别的4 个字符看成是4 个不同的任务\\n# 每个任务负责识别1 个字符\\n# 任务1 识别第1 个字符，任务2 识别第 2 个字符，任务3 识别第3 个字符，任务4 识别第\\n4 个字符\\nx0 = Dense(num_classes, activation='softmax', name='out0')(x)\\nx1 = Dense(num_classes, activation='softmax', name='out1')(x)\\nx2 = Dense(num_classes, activation='softmax', name='out2')(x)\\nx3 = Dense(num_classes, activation='softmax', name='out3')(x)\\n# 定义模型\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 454, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 455\\nmodel = Model(inputs, [x0,x1,x2,x3])\\n# 画图\\nplot_model(model,style=0)\\n# 4 个任务我们可以定义4 个loss\\n# loss_weights可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样\\nmodel.compile(loss={'out0':'categorical_crossentropy',\\n'out1':'categorical_crossentropy',\\n'out2':'categorical_crossentropy',\\n'out3':'categorical_crossentropy'},\\nloss_weights={'out0':1,\\n'out1':1,\\n'out2':1,\\n'out3':1},\\noptimizer=SGD(lr=1e-2,momentum=0.9),\\nmetrics=['acc'])\\n# 监控指标统一使用val_loss\\n# 可以使用EarlyStopping来让模型停止，连续6 个周期val_loss没有下降就结束训练\\n# CSVLogger保存训练数据\\n# ModelCheckpoint保存所有训练周期中 val_loss最低的模型\\n# ReduceLROnPlateau学习率调整策略，连续3 个周期val_loss没有下降当前学习率乘以\\n0.1\\ncallbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),\\nCSVLogger('Captcha.csv'),\\nModelCheckpoint('Best_Captcha.h5', monitor='val_loss', save_best_only=True),\\nReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\\n# 训练模型\\nmodel.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),\\nepochs=epochs,\\nvalidation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_st\\neps),\\ncallbacks=callbacks)\\n结果输出为：\\nTrain for 1000 steps, validate for 100 steps\\nEpoch 1/100\\n1000/1000 [==============================] - 164s 164ms/step - loss:\\n10.0266 - out0_loss: 2.3069 - out1_loss: 2.7054 - out2_loss: 2.6668\\n- out3_loss: 2.3474 - out0_acc: 0.3711 - out1_acc: 0.3144 - out2_acc:\\n0.3197 - out3_acc: 0.3896 - val_loss: 3.8732 - val_out0_loss: 1.1623\\n- val_out1_loss: 0.9057 - val_out2_loss: 0.9186 - val_out3_loss: 0.8\\n866 - val_out0_acc: 0.6719 - val_out1_acc: 0.7352 - val_out2_acc: 0.7\\n278 - val_out3_acc: 0.7531\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 455, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 456\\n……\\nEpoch 00050: ReduceLROnPlateau reducing learning rate to 9.999998837\\n88405e-07.\\n1000/1000 [==============================] - 160s 160ms/step - loss:\\n0.1092 - out0_loss: 0.0254 - out1_loss: 0.0295 - out2_loss: 0.0283 -\\nout3_loss: 0.0260 - out0_acc: 0.9901 - out1_acc: 0.9880 - out2_acc:\\n0.9885 - out3_acc: 0.9902 - val_loss: 0.1104 - val_out0_loss: 0.0260\\n- val_out1_loss: 0.0304 - val_out2_loss: 0.0273 - val_out3_loss: 0.02\\n67 - val_out0_acc: 0.9902 - val_out1_acc: 0.9877 - val_out2_acc: 0.99\\n00 - val_out3_acc: 0.9881\\nEpoch 00050: early stopping\\n由于使用自定义数据生成器可以生产出无数张图片，所以相当于模型的训练数据比之前\\n用tf.data从硬盘中读取数据要多了很多。最终我们也可以看到更多的训练数据得到的结果也\\n会更好。\\n13.5.2 使用自定义数据生成器完成模型预测\\n下面我们来看一下关于模型预测部分的程序，如代码13-5 所示。\\n代码13-5：自定义数据生成器-验证码识别-模型预测（片段1）\\nfrom tensorflow.keras.models import load_model\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\nfrom captcha.image import ImageCaptcha\\nimport numpy as np\\nimport string\\nimport matplotlib.pyplot as plt\\nimport random\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 批次大小\\nbatch_size = 64\\n# 载入训练好的模型\\nmodel = load_model('Best_Captcha.h5')\\n# 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的，\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 456, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 457\\n# 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次，\\n# Sequence一般是定义一个训练周期内每个批次的数据如何产生。\\n# 我们这里的验证码数据集使用captcha 模块生产出来的，一边生产一边训练，可以认为数\\n据集是无限的。\\nclass CaptchaSequence(Sequence):\\n# __getitem__和__len__是必须定义的两个方法\\ndef __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60):\\n# 字符集\\nself.characters = characters\\n# 批次大小\\nself.batch_size = batch_size\\n# 生成器生成多少个批次的数据\\nself.steps = steps\\n# 验证码长度\\nself.n_len = n_len\\n# 验证码图片宽度\\nself.width = width\\n# 验证码图片高度\\nself.height = height\\n# 字符集长度\\nself.num_classes = len(characters)\\n# 用于产生验证码图片\\nself.image = ImageCaptcha(width=self.width, height=self.height)\\n# 用于保存最近一个批次验证码字符\\nself.captcha_list = []\\n# 获得index位置的批次数据\\ndef __getitem__(self, index):\\n# 初始化数据用于保存验证码图片\\nx = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\\n# 初始化数据用于保存标签\\n# n_len是多任务学习的任务数量，这里是4 个任务，batch 批次大小，num_classes分\\n类数量\\ny = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8)\\n# 数据清0\\nself.captcha_list = []\\n# 生产一个批次数据\\nfor i in range(self.batch_size):\\n# 随机产生验证码\\ncaptcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\\nself.captcha_list.append(captcha_text)\\n# 生产验证码图片数据并进行归一化处理\\nx[i] = np.array(self.image.generate_image(captcha_text)) / 255.0\\n# j(0-3),i(0-61),ch(单个字符)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 457, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 458\\n# self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号\\nfor j, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\ny[j, i, self.characters.find(ch)] = 1\\n# 返回一个批次的数据和标签\\nreturn x, [y[0],y[1],y[2],y[3]]\\n# 返回批次数量\\ndef __len__(self):\\nreturn self.steps\\n# 测试模型，随机生成验证码\\n# 一共一个批次，批次大小也是1\\ndata = CaptchaSequence(characters, batch_size=1, steps=1)\\nfor i in range(2):\\n# 产生一个批次的数据\\nx, y = data[0]\\n# 预测结果\\npred = model.predict(x)\\n# 获得对应编号\\ncaptcha = np.argmax(pred,axis=-1)[:,0]\\n# 根据编号获得对应验证码\\npred = ''.join([characters[x] for x in captcha])\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred))\\nplt.show()\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 458, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 459\\n代码13-5：自定义数据生成器-验证码识别-模型预测（片段2）\\n# 自定义验证码生成和预测\\n# 生成自定义验证码\\ncaptcha_text = '0oO0'\\nimage = ImageCaptcha(width=160, height=60)\\n# 数据归一化\\nx = np.array(image.generate_image(captcha_text)) / 255.0\\n# 给数据增加一个维度变成4 维\\nx = np.expand_dims(x, axis=0)\\n# 预测结果\\npred = model.predict(x)\\n# 获得对应编号\\ncaptcha = np.argmax(pred,axis=-1)[:,0]\\n# 根据编号获得对应验证码\\npred = ''.join([characters[x] for x in captcha])\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title('real:%s\\\\npred:%s'%(captcha_text,pred))\\nplt.show()\\n结果输出为：\\n代码13-5：自定义数据生成器-验证码识别-模型预测（片段3）\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 459, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 460\\n# 计算准确率，区分大小写\\ndef accuracy(test_steps=100):\\n# 用于统计准确率\\nacc_sum = 0\\nfor x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):\\n# 进行一个批次的预测\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred, axis=-1)\\n# 获得标签数据\\nlabel = np.argmax(y, axis=-1)\\n# 计算这个批次的准确率然后累加到总的准确率统计中\\nacc_sum += (pred == label).all(axis=0).mean()\\n# 返回平均准确率\\nreturn acc_sum / test_steps\\n# 计算准确率，区分大小写\\nprint(accuracy())\\n结果输出为：\\n0.956875\\n代码13-5：自定义数据生成器-验证码识别-模型预测（片段4）\\n# 计算准确率，忽略大小写\\ndef accuracy2(test_steps=100):\\n# 用于统计准确率\\nacc_sum = 0\\nfor x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):\\n# 进行一个批次的预测\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred,axis=-1).T\\n# 保存预测值\\npred_list = []\\n# 把验证码预测值转小写后保存\\nfor c in pred:\\n# 根据编号获得对应验证码\\ntemp_c = ''.join([characters[x] for x in c])\\n# 字母都转小写后保存\\npred_list.append(temp_c.lower())\\n# 获得标签数据\\nlabel = np.argmax(y, axis=-1).T\\n# 保存标签\\nlabel_list = []\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 460, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 461\\n# # 把验证码标签值转小写后保存\\nfor c in label:\\n# 根据编号获得对应验证码\\ntemp_c = ''.join([characters[x] for x in c])\\n# 字母都转小写后保存\\nlabel_list.append(temp_c.lower())\\n# 计算这个批次的准确率然后累加到总的准确率统计中\\nacc_sum += (np.array(pred_list) == np.array(label_list)).mean()\\n# 返回平均准确率\\nreturn acc_sum / test_steps\\n# 计算准确率，忽略大小写\\nprint(accuracy2())\\n结果输出为：\\n0.98546875\\n我们从测试结果可以看到使用自定义数据生成器产生更多的训练数据以后，模型的准确\\n率提高到了95.69%（区分大小写）非常高的准确率，如果不区分大小写准确率可以进一步\\n提高到98.55%。\\n在自定义验证码程序段中，我生成了一个“0oO0”验证码，就问大家能不能分辨出哪个\\n是0，哪个是o，哪个是O，反正我肯定是分不出来，但是这个模型还能识别正确（当然这\\n个难度还是很大的，不能保证它每一次都能识别正确）。我觉得我们训练的这个模型在这种\\n类型的验证码识别准确率上应该是超过了人类。\\n13.6 挑战变长验证码识别\\n13.6.1 挑战变长验证码识别模型训练\\n前面我们生成的验证码是固定4 位长度的，下面我们将增加难度，挑战不固定长度的验\\n证码识别，验证码长度我设置为3-6 位的随机4 种长度。程序大体框架跟“代码13-4：自\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 461, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 462\\n定义数据生成器-验证码识别”差不多，主要是自定义数据生成器的部分做了一些修改，让数\\n据生成器会产生随机长度的验证码。\\n不过为了保证标签对齐，所以我们还是需要固定标签的数量和多任务学习任务的数量。\\n因为验证码最长是6，所以我们把标签的长度和多任务学习任务数量固定为 6，标签不足长\\n度6 的情况我们会把标签填充到 6。模型的类别数会增加一个空白类别，用于填充。\\n另外我还给模型增加了一个新的任务，用于预测验证码的长度，这个任务其实可有可\\n无，不过用作演示还是加上给大家看看效果，模型结构如图 13.5 所示。\\n图13.5 变长验证码识别\\n图中有一共有7 个输出，其中6 个输出表示验证码识别的6 个任务，每个任务有 63 个\\n类别（62 个字符加一个空白符）。还有一个输出表示验证码的长度，有4 个类别，分别表示\\n3，4，5，6，一共 4 种验证码的长度。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 462, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 463\\n挑战变长验证码识别的代码如代码13-6 所示。\\n代码13-6：挑战变长验证码识别（片段1）\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\nfrom tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D\\nfrom tensorflow.keras.models import Model,Sequential\\nfrom tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc\\neLROnPlateau\\nfrom captcha.image import ImageCaptcha\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport random\\nimport string\\nfrom plot_model import plot_model\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数，包含一个空白符类别\\nnum_classes = len(characters)+1\\n# 批次大小\\nbatch_size = 64\\n# 训练集批次数\\n# 训练集大小相当于是64*1000=64000\\ntrain_steps = 1000\\n# 测试集批次数\\n# 测试集大小相当于是64*100=6400\\ntest_steps = 100\\n# 周期数\\nepochs=100\\n# 图片宽度\\nwidth=160\\n# 图片高度\\nheight=60\\n# 最长验证码\\nmax_len = 6\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\n# 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的，\\n# 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次，\\n# Sequence一般是定义一个训练周期内每个批次的数据如何产生。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 463, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 464\\n# 我们这里的验证码数据集使用captcha 模块生产出来的，一边生产一边训练，可以认为数\\n据集是无限的。\\nclass CaptchaSequence(Sequence):\\n# __getitem__和__len__是必须定义的两个方法\\ndef __init__(self, characters, batch_size, steps, width=160, height=60):\\n# 字符集\\nself.characters = characters\\n# 批次大小\\nself.batch_size = batch_size\\n# 生成器生成多少个批次的数据\\nself.steps = steps\\n# 验证码长度随机，3-6 位\\nself.n_len = np.random.randint(3,7)\\n# 验证码图片宽度\\nself.width = width\\n# 验证码图片高度\\nself.height = height\\n# 字符集长度\\nself.num_classes = num_classes\\n# 用于产生验证码图片\\nself.image = ImageCaptcha(width=self.width, height=self.height)\\n# 用于保存最近一个批次验证码字符\\nself.captcha_list = []\\n# 获得index位置的批次数据\\ndef __getitem__(self, index):\\n# 初始化数据用于保存验证码图片\\nx = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\\n# 初始化数据用于保存标签\\n# 6 个验证码识别任务，batch 批次大小，num_classes分类数量\\ny = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32)\\n# 数据清0\\nself.captcha_list = []\\n# 初始化数据用于保存判断验证码长度的标签，一共 4 种情况\\nlen_captcha = np.zeros((self.batch_size, 4), dtype=np.int)\\n# 生产一个批次数据\\nfor i in range(self.batch_size):\\n# 随机产生验证码\\nself.n_len = np.random.randint(3,7)\\n# 设置标签，独热编码one-hot格式，一共4 种情况\\nlen_captcha[i, self.n_len-3] = 1\\n# 转字符串\\ncaptcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\\n# 保存验证码\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 464, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 465\\nself.captcha_list.append(captcha_text)\\n# 生产验证码图片数据并进行归一化处理\\nx[i] = np.array(self.image.generate_image(captcha_text)) / 255.0\\n# j(0-3),i(0-61),ch(单个字符)\\n# self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号\\nfor j, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\ny[j, i, self.characters.find(ch)] = 1\\n# 如果验证码长度不是6，则需要设置空白字符的标签为 1\\n# 空白字符在-1 位置\\nfor k in range(len(captcha_text),max_len):\\n# 空白字符\\ny[k, i, -1] = 1\\n# 返回一个批次的数据和标签\\nreturn x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]\\n# 返回批次数量\\ndef __len__(self):\\nreturn self.steps\\n# 测试生成器\\n# 一共一个批次，批次大小也是1\\ndata = CaptchaSequence(characters, batch_size=1, steps=1)\\nfor i in range(2):\\n# 产生一个批次的数据\\nx, y = data[0]\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title(data.captcha_list[0])\\nplt.show()\\n结果输出为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 465, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 466\\n代码13-6：挑战变长验证码识别（片段2）\\n# 载入预训练的resnet50 模型\\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)\\n)\\n# 设置输入图片\\ninputs = Input((height,width,3))\\n# 使用resnet50 进行特征提取\\nx = resnet50(inputs)\\n# 平均池化\\nx = GlobalAvgPool2D()(x)\\n# 每个任务负责识别1 个字符\\nx0 = Dense(num_classes, activation='softmax', name='out0')(x)\\nx1 = Dense(num_classes, activation='softmax', name='out1')(x)\\nx2 = Dense(num_classes, activation='softmax', name='out2')(x)\\nx3 = Dense(num_classes, activation='softmax', name='out3')(x)\\nx4 = Dense(num_classes, activation='softmax', name='out4')(x)\\nx5 = Dense(num_classes, activation='softmax', name='out5')(x)\\n# 预测验证码长度3-6，4 种情况所以定义4 个分类\\nnum_x = Dense(4, activation='softmax', name='out_num')(x)\\n# 定义模型\\nmodel = Model(inputs, [x0,x1,x2,x3,x4,x5,num_x])\\n# 画图\\nplot_model(model,style=0,dpi=200)\\n# loss_weights可以用来设置不同任务的权重，验证码识别的 6 个任务权重都一样\\n# 相对而言out_num更重要一些，因为如果验证码的长度判断错误，那么识别结果一定是错\\n的\\n# 所以可以给out_num更大一点的权重\\nmodel.compile(loss={'out0':'categorical_crossentropy',\\n'out1':'categorical_crossentropy',\\n'out2':'categorical_crossentropy',\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 466, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 467\\n'out3':'categorical_crossentropy',\\n'out4':'categorical_crossentropy',\\n'out5':'categorical_crossentropy',\\n'out_num':'categorical_crossentropy'},\\nloss_weights={'out0':1,\\n'out1':1,\\n'out2':1,\\n'out3':1,\\n'out4':1,\\n'out5':1,\\n'out_num':2},\\noptimizer=SGD(lr=1e-2,momentum=0.9),\\nmetrics=['acc'])\\n# 监控指标统一使用val_loss\\n# 可以使用EarlyStopping来让模型停止，连续6 个周期val_loss没有下降就结束训练\\n# CSVLogger保存训练数据\\n# ModelCheckpoint保存所有训练周期中 val_loss最低的模型\\n# ReduceLROnPlateau学习率调整策略，连续3 个周期val_loss没有下降当前学习率乘以\\n0.1\\ncallbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),\\nCSVLogger('Captcha2.csv'),\\nModelCheckpoint('Best_Captcha2.h5', monitor='val_loss', save_best_only=True),\\nReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\\n# 训练模型\\nmodel.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),\\nepochs=epochs,\\nvalidation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_\\nsteps),\\ncallbacks=callbacks)\\n结果输出为：\\nTrain for 1000 steps, validate for 100 steps\\nEpoch 1/100\\n1000/1000 [==============================] - 184s 184ms/step - loss:\\n14.0520 - out0_loss: 2.2189 - out1_loss: 2.6810 - out2_loss: 2.9503\\n- out3_loss: 2.5608 - out4_loss: 1.8766 - out5_loss: 1.0524 - out_num\\n_loss: 0.3560 - out0_acc: 0.4063 - out1_acc: 0.3020 - out2_acc: 0.244\\n7 - out3_acc: 0.3636 - out4_acc: 0.5493 - out5_acc: 0.7673 - out_num_\\nacc: 0.8614 - val_loss: 13.9098 - val_out0_loss: 2.5258 - val_out1_lo\\nss: 1.9578 - val_out2_loss: 2.3671 - val_out3_loss: 2.5046 - val_out4\\n_loss: 1.6575 - val_out5_loss: 0.9196 - val_out_num_loss: 0.9887 - va\\nl_out0_acc: 0.4391 - val_out1_acc: 0.5095 - val_out2_acc: 0.4242 - va\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 467, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 468\\nl_out3_acc: 0.4322 - val_out4_acc: 0.6039 - val_out5_acc: 0.7880 - va\\nl_out_num_acc: 0.8316\\n……\\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837\\n88405e-08.\\n1000/1000 [==============================] - 178s 178ms/step - loss:\\n0.2524 - out0_loss: 0.0436 - out1_loss: 0.0534 - out2_loss: 0.0558 -\\nout3_loss: 0.0457 - out4_loss: 0.0341 - out5_loss: 0.0173 - out_num_\\nloss: 0.0013 - out0_acc: 0.9825 - out1_acc: 0.9796 - out2_acc: 0.9800\\n- out3_acc: 0.9823 - out4_acc: 0.9870 - out5_acc: 0.9930 - out_num_a\\ncc: 0.9997 - val_loss: 0.2374 - val_out0_loss: 0.0452 - val_out1_los\\ns: 0.0515 - val_out2_loss: 0.0498 - val_out3_loss: 0.0404 - val_out4_\\nloss: 0.0307 - val_out5_loss: 0.0174 - val_out_num_loss: 0.0012 - val\\n_out0_acc: 0.9823 - val_out1_acc: 0.9786 - val_out2_acc: 0.9792 - val\\n_out3_acc: 0.9841 - val_out4_acc: 0.9886 - val_out5_acc: 0.9931 - val\\n_out_num_acc: 0.9997\\nEpoch 00036: early stopping\\n从模型最后的结果看来预测验证码长度的任务准确率几乎达到了 1，也就是说模型预测验\\n证码的长度是非常准了。6 个验证码预测任务中准确率最高的是 out5，也就是最后1 位验证\\n码的预测。out5 准确率明显高于其他任务是因为验证码的长度是3-6，也就是说只要验证码\\n的长度判断正确，那么有75%的可能性最后 1 位验证码它就是空白符，所以准确率比较高。\\n相对而言out0-out2 的准确率就会偏低一些了，因为不可能会有空白符。\\n13.6.2 挑战变长验证码识别模型预测\\n实现变长验证码识别-模型预测的代码如代码13-7 所示。\\n代码13-7：变长验证码识别-模型预测（片段1）\\nfrom tensorflow.keras.models import load_model\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\nfrom captcha.image import ImageCaptcha\\nimport numpy as np\\nimport string\\nimport matplotlib.pyplot as plt\\nimport random\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 468, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 469\\n# 载入训练好的模型\\nmodel = load_model('Best_Captcha2.h5')\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 预测阶段使用的字符多一个空白符在最后\\npred_characters = characters + ' '\\n# 类别数，包含一个空白符类别\\nnum_classes = len(characters)+1\\n# 批次大小\\nbatch_size = 64\\n# 最长验证码\\nmax_len = 6\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\n# 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的，\\n# 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次，\\n# Sequence一般是定义一个训练周期内每个批次的数据如何产生。\\n# 我们这里的验证码数据集使用captcha 模块生产出来的，一边生产一边训练，可以认为数\\n据集是无限的。\\nclass CaptchaSequence(Sequence):\\n# __getitem__和__len__是必须定义的两个方法\\ndef __init__(self, characters, batch_size, steps, width=160, height=60):\\n# 字符集\\nself.characters = characters\\n# 批次大小\\nself.batch_size = batch_size\\n# 生成器生成多少个批次的数据\\nself.steps = steps\\n# 验证码长度随机，3-6 位\\nself.n_len = np.random.randint(3,7)\\n# 验证码图片宽度\\nself.width = width\\n# 验证码图片高度\\nself.height = height\\n# 字符集长度\\nself.num_classes = num_classes\\n# 用于产生验证码图片\\nself.image = ImageCaptcha(width=self.width, height=self.height)\\n# 用于保存最近一个批次验证码字符\\nself.captcha_list = []\\n# 获得index位置的批次数据\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 469, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 470\\ndef __getitem__(self, index):\\n# 初始化数据用于保存验证码图片\\nx = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\\n# 初始化数据用于保存标签\\n# 6 个验证码识别任务，batch 批次大小，num_classes分类数量\\ny = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32)\\n# 数据清0\\nself.captcha_list = []\\n# 初始化数据用于保存判断验证码长度的标签，一共 4 种情况\\nlen_captcha = np.zeros((self.batch_size, 4), dtype=np.int)\\n# 生产一个批次数据\\nfor i in range(self.batch_size):\\n# 随机产生验证码\\nself.n_len = np.random.randint(3,7)\\n# 设置标签，独热编码one-hot格式，一共4 种情况\\nlen_captcha[i, self.n_len-3] = 1\\n# 转字符串\\ncaptcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\\n# 保存验证码\\nself.captcha_list.append(captcha_text)\\n# 生产验证码图片数据并进行归一化处理\\nx[i] = np.array(self.image.generate_image(captcha_text)) / 255.0\\n# j(0-3),i(0-61),ch(单个字符)\\n# self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号\\nfor j, ch in enumerate(captcha_text):\\n# 设置标签，独热编码one-hot格式\\ny[j, i, self.characters.find(ch)] = 1\\n# 如果验证码长度不是6，则需要设置空白字符的标签为 1\\n# 空白字符在-1 位置\\nfor k in range(len(captcha_text),max_len):\\n# 空白字符\\ny[k, i, -1] = 1\\n# 返回一个批次的数据和标签\\nreturn x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]\\n# 返回批次数量\\ndef __len__(self):\\nreturn self.steps\\n# 测试模型\\n# 一共一个批次，批次大小也是1\\ndata = CaptchaSequence(characters, batch_size=1, steps=1)\\nfor i in range(2):\\n# 产生一个批次的数据\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 470, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 471\\nx, y = data[0]\\n# 预测结果\\npred = model.predict(x)\\n# 0 表示长度 3，1 表示长度4，2 表示长度5，3 表示长度6\\ncaptcha_len = np.argmax(pred[6],axis=-1)[0]+3\\n# 打印验证码长度\\nprint('验证码长度：',captcha_len)\\n# 获得对应编号\\ncaptcha = np.argmax(pred[:6],axis=-1)[:,0]\\n# 根据编号获得对应验证码\\n# 注意这里需要使用pred_characters，包含空白符\\npred = ''.join([pred_characters[x] for x in captcha])\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred))\\nplt.show()\\n结果输出为：\\n验证码长度： 6\\n验证码长度： 5\\n代码13-7：变长验证码识别-模型预测（片段2）\\n# 自定义验证码生成和预测\\n# 生成自定义验证码\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 471, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 472\\ncaptcha_text = 'oOxXvV'\\nimage = ImageCaptcha(width=160, height=60)\\n# 数据归一化\\nx = np.array(image.generate_image(captcha_text)) / 255.0\\n# 给数据增加一个维度变成4 维\\nx = np.expand_dims(x, axis=0)\\n# 预测结果\\npred = model.predict(x)\\n# 获得对应编号\\ncaptcha = np.argmax(pred[:6],axis=-1)[:,0]\\n# 根据编号获得对应验证码\\npred = ''.join([pred_characters[x] for x in captcha])\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title('real:%s\\\\npred:%s'%(captcha_text,pred))\\nplt.show()\\n结果输出为：\\n代码13-7：变长验证码识别-模型预测（片段3）\\n# 计算准确率，区分大小写\\ndef accuracy(test_steps=100):\\n# 用于统计准确率\\nacc_sum = 0\\nfor x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):\\n# 进行一个批次的预测\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred[:6], axis=-1)\\n# 获得标签数据\\nlabel = np.argmax(y[:6], axis=-1)\\n# 计算这个批次的准确率然后累加到总的准确率统计中\\nacc_sum += (pred == label).all(axis=0).mean()\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 472, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 473\\n# 返回平均准确率\\nreturn acc_sum / test_steps\\n# 打印区分大小写准确率\\nprint(accuracy())\\n结果输出为：\\n0.913125\\n代码13-7：变长验证码识别-模型预测（片段4）\\n# 计算准确率，忽略大小写\\ndef accuracy2(test_steps=100):\\n# 用于统计准确率\\nacc_sum = 0\\nfor x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):\\n# 进行一个批次的预测\\npred = model.predict(x)\\n# 获得对应编号\\npred = np.argmax(pred[:6],axis=-1).T\\n# 保存预测值\\npred_list = []\\n# 把验证码预测值转小写后保存\\nfor c in pred:\\n# 根据编号获得对应验证码\\ntemp_c = ''.join([pred_characters[x] for x in c])\\n# 字母都转小写后保存\\npred_list.append(temp_c.lower())\\n# 获得标签数据\\nlabel = np.argmax(y[:6], axis=-1).T\\n# 保存标签\\nlabel_list = []\\n# # 把验证码标签值转小写后保存\\nfor c in label:\\n# 根据编号获得对应验证码\\ntemp_c = ''.join([pred_characters[x] for x in c])\\n# 字母都转小写后保存\\nlabel_list.append(temp_c.lower())\\n# 计算这个批次的准确率然后累加到总的准确率统计中\\nacc_sum += (np.array(pred_list) == np.array(label_list)).mean()\\n# 返回平均准确率\\nreturn acc_sum / test_steps\\n# 打印忽略大小写准确率\\nprint(accuracy2())\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 473, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 474\\n0.963125\\n程序运行结果我们可以看到，这个模型可以自动判断验证码的长度，并做出正确识别。\\n就连“oOxXvV”这种几乎不可能识别正确的验证码图片它也能识别正确。不过由于变长验\\n证码难度更大，并且验证码的位数有可能比原来的 4位更多，所以验证码的综合准确率相比\\n之前有所下降。\\n13.7 CTC 算法\\n13.7.1 CTC 算法介绍\\nCTC(Connectionist Temporal Classification)是用来解决输入序列和输出序列难以一\\n一对应的问题，主要用于语音识别和OCR(Optical Character Recognition)领域。语音识\\n别如图13.6 所示。\\n图 13.6 语音识别\\n比如在语音识别任务中，我们需要将一大段语音跟一段文本对应。最容易想到的方式就\\n是把一大段语音切分为语音片段，然后每个语音片段对应一个字或一个词。但是每个人说话\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 474, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 475\\n的语速不同，这个切分的规则很难定义。如果每一段语音都通过人为手动切分，虽然方法可\\n行，但是工作量非常大。\\n同样的在OCR领域也会遇到同样的对齐困难，如图13.7 所示。\\n图13.7 数据对齐困难\\nCTC 就是用来解决输入数据和输出数据的对齐问题，我们可以通过下面的例子来理解。\\n不管是语音识别或是OCR还是其他类似任务，假设我们先以一定的方法（比如卷积）对输\\n入数据进行特征提取，然后得到6 个数据特征，如图 13.8 中的𝑥 -𝑥 。\\n\" (cid:226)\\n图 13.8 数据对齐\\n6 个特征𝑥 -𝑥 分别预测出对应的6 个字符，然后我们可以将相邻并重复的字符删除，得\\n\" (cid:226)\\n到最后的结果。这个对齐方式有两个问题，第一个问题是在语音识别，有些音频片段可能是\\n无声的，这个时候应该是没有字符输出的。第二个问题是有些单词本身就存在重复单词，比\\n如“hello”，如果去重的话就会变成“helo”。\\n为了解决这两个问题，CTC 引入了一个空白占位符，用来表示空白输出，这里我们用𝜖来\\n表示，加入空白符以后输入和输出就可以合理的对应上了，如图 13.9 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 475, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 476\\n图13.9 引入空白符\\n在这个对齐方式中，如果标签文本存在重复字符，对齐过程中会在两个重复字符当中插\\n入空白符隔开，这样“hello”就不会变成“helo”了。\\n假设标签文本为“cat”，图13.10 中左边的部分都是正确的结果，右边的部分都是错误\\n的结果。\\n图13.10 正确对齐和错误对齐\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 476, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 477\\n13.7.2 贪心算法（ Greedy Search）和集束搜索算法（ Beam\\nSearch）\\n下面我们进一步考虑更多的细节，比如我们把一段“hello”的语音进行特征提取，然后\\n再把提取后的特征传入RNN 网络中，每传入1 个特征RNN 网络就会输出一组结果，如图\\n13.11。\\n图 13.11 CTC 算法\\n图中RNN 的每次输出都有5 种可能的结果，这5 种可能的结果有不同的概率值（图中\\n不同的背景颜色深度表示不同的概率值，颜色越深表示概率越大）。对于一组输入输出(X,Y)\\n来说，CTC 的目标是最大化条件概率，公式为13.1。\\n𝑇\\n𝑝(𝑌|𝑋) = ? ª𝑝 (𝑎 |𝑋) (13.1)\\n𝑡 𝑡\\n𝐴∈𝐴 𝑡=1\\n𝑋,𝑌\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 477, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 478\\n𝑝 (𝑎 |𝑋)表示RNN 每个时间序列的输出概率分布，t表示RNN里第t个序列，\\nˆ ˆ\\n∏~ 𝑝 (𝑎 |𝑋)表示一条路径所有字符概率相乘，∑ ∏~ 𝑝 (𝑎 |𝑋)表示多条路径概率相\\nˆA\" ˆ ˆ (cid:231)∈(cid:231)Ł,Ø ˆA\" ˆ ˆ\\n加。\\n其实有多条路径可以得到“hello”的结果，比如序列长度为10，“heeϵlϵloϵϵ”,\\n“hϵϵeeϵlϵlo”, “ϵϵhheϵlϵlo”, “hϵeeϵlϵloϵ”等结果其实都是表示“hello”。所以\\n“hello”的概率应该是所有有效的“hello”路径概率的总和。\\nP(“hello”)=P(“heeϵlϵloϵϵ”)+P(“hϵϵeeϵlϵlo”)+P(“ϵϵhheϵlϵlo”)+P(“hϵeeϵlϵl\\noϵ”)+……\\n可以想象对于一个输出，可以得到这个输出的路径肯定是非常多的。在实际应用中我们\\n不会将所有路径的概率都计算出来，主要是计算量太大了，所以我们需要采用动态规划的思\\n想来计算。CTC 主要采用两种动态规划的算法，贪心算法（Greedy Search）和集束搜索算\\n法（Beam Search）。\\n下面我们举两个简单的例子来说明，贪心算法就是在序列输出的每一个阶段都选取概率\\n最大的一个输出值，比如我们有一个序列有 3 种输出“a”，“b”，“-”。“-”表示空白\\n符，贪心算法输出的结果如下图13.12 所示。\\n图13.12 贪心算法（Greedy Search）\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 478, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 479\\nt0 阶段概率最大的是“-”为0.8，t1 阶段概率最大的是“-”为0.6，所以贪心算法的输\\n出结果为“--”，概率为0.8×0.6=0.48。一般来说贪心算法计算量小，效果也不错。但有时\\n候贪心算法得到的结果不一定是最好的。如图 13.13 所示。\\n图13.13 贪心算法失效\\n比如我们计算一下“a”的输出概率：\\nP(“a”）=P(“aa”)+P(“a-”)+P(“-a”)= 0.2×0.4+0.2×0.6+0.8×\\n0.4=0.52>0.48。所以贪心算法得到的结果不一定是最好的，我们可以使用beam search。\\nbeam search跟贪心算法不同的地方在于beam search会计算当前最好的N个结果，\\nN可以人为设定。还是使用上面的例子，当N等于2 时，可以得到图13.14 所示。\\n图 13.14 beam search\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 479, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 480\\n我们来分析一下，t0 时“a”的概率为0.2，空白符“-”的概率为0.8，所以t0 我们选\\n出最好的两个结果就是“a”和“-”。t1 时我们得到的组合有“aa”，“ab”，“a”，\\n“b”，“”，我们一个一个来分析。\\nt1 时输出“aa”是不可能的，因为如果真的要输出“aa”，必须至少要有一个空白符在\\n两个“a”中间，如“a-a”->“aa”。\\nt1 时输出“ab”也不可能，因为t1 时“b”的概率为0。\\nt1 时输出“b”也不可能，因为t1 时“b”的概率为0。\\nt1 时输出“a”可以。t0 输出“a”，t1 输出“a”或“-”，最后的结果都是“a”；t0\\n输出“-”，t1 输出“a”，也可以得到“a”。总概率前面我们计算过为0.52。\\nt1 时输出空白“”可以。t0 输出“-”，t1 也输出“-”，最后得到“”。概率为0.48。\\n如果有更长的序列，我们将沿着这个结果继续往下分析，并且每个序列只保存概率最大\\n的两个输出。\\n13.7.3 CTC 存在的问题\\n最后总结一下CTC 的几个问题：\\n1.条件独立性。CTC 做了一个假设就是不同时间序列的输出之间是独立的。这个假设对\\n于很多序列问题来说并不成立，输出序列之间往往存在联系。\\n2.单调对齐。CTC 只允许单调对齐，这在语音识别，OCR等领域中可能是有效的。但是\\n在机器翻译中，比如有些中文句子后面的词可能对应于英文句子中前面的词，这个 CTC 无法\\n做到。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 480, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 481\\n3.多对一映射。CTC 的输入和输出是多对一的关系。这意味着输出长度不能超过输入长\\n度，这在语音识别，OCR等领域问题不大，但是对于某些输出长度大于输入长度的应用CTC\\n就无法处理了。\\n13.8 CTC 算法-验证码识别\\n13.8.1 使用 CTC 算法训练验证码模型\\n下面我们要学习的CTC 算法-验证码识别程序要注意的点挺多的，我在程序注释中都已经\\n详细的写清楚了。这里再稍微提一下，由于 Tensorflow.keras 中没有实现CTC 算法的相关\\n功能，所以CTC 算法相关计算需要调用Tensorflow 中的程序实现，如代码13-8 所示。\\n代码13-8：CTC 算法-验证码识别（片段1）\\nfrom tensorflow.keras.optimizers import SGD\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\nfrom tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda\\nfrom tensorflow.keras.models import Model,Sequential\\nfrom tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc\\neLROnPlateau\\nfrom tensorflow.keras import backend as K\\nfrom captcha.image import ImageCaptcha\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport random\\nimport string\\nfrom plot_model import plot_model\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数+空白字符\\nnum_classes = len(characters)+1\\n# 批次大小\\nbatch_size = 64\\n# 训练集批次数\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 481, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 482\\n# 训练集大小相当于是64*1000=64000\\ntrain_steps = 1000\\n# 测试集批次数\\n# 测试集大小相当于是64*100=6400\\ntest_steps = 100\\n# 周期数\\nepochs=100\\n# 图片宽度\\nwidth=160\\n# 图片高度\\nheight=60\\n# RNN 的cell 数量\\nRNN_cell = 128\\n# 最长验证码\\nmax_len = 6\\n# 用于自定义数据生成器\\nfrom tensorflow.keras.utils import Sequence\\n# 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的，\\n# 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次，\\n# Sequence一般是定义一个训练周期内每个批次的数据如何产生。\\n# 我们这里的验证码数据集使用captcha 模块生产出来的，一边生产一边训练，可以认为数\\n据集是无限的。\\nclass CaptchaSequence(Sequence):\\n# __getitem__和__len__是必须定义的两个方法\\ndef __init__(self, characters, batch_size, steps, n_len=max_len, width=160, height=60,\\ninput_len=10, label_len=max_len):\\n# 字符集\\nself.characters = characters\\n# 批次大小\\nself.batch_size = batch_size\\n# 生成器生成多少个批次的数据\\nself.steps = steps\\n# 验证码长度随机，3-6 位\\nself.n_len = np.random.randint(3,7)\\n# 验证码图片宽度\\nself.width = width\\n# 验证码图片高度\\nself.height = height\\n# 输入长度10，注意这里输入长度指的是 RNN 模型输出的序列长度，具体要看下面模\\n型搭建部分\\n# RNN 模型输出序列长度为10 表示模型最多可以输入10 个字符(包含空白符在内)\\nself.input_len = input_len\\n# 标签长度\\nself.label_len = label_len\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 482, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 483\\n# 字符集长度\\nself.num_classes = num_classes\\n# 用于产生验证码图片\\nself.image = ImageCaptcha(width=self.width, height=self.height)\\n# 用于保存最近一个批次验证码字符\\nself.captcha_list = []\\n# 获得index位置的批次数据\\ndef __getitem__(self, index):\\n# 初始化数据用于保存验证码图片\\nx = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\\n# 初始化数据用于保存标签\\ny = np.zeros((self.batch_size, self.label_len), dtype=np.int8)\\n# 输入长度\\ninput_len = np.ones(self.batch_size)*self.input_len\\n# 标签长度\\nlabel_len = np.ones(self.batch_size)*self.label_len\\n# 数据清0\\nself.captcha_list = []\\n# 生产一个批次数据\\nfor i in range(self.batch_size):\\n# 随机产生验证码\\nself.n_len = np.random.randint(3,7)\\n# 转字符串\\ncaptcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\\n# 保存验证码\\nself.captcha_list.append(captcha_text)\\n# 生产验证码图片数据并进行归一化处理\\nx[i] = np.array(self.image.generate_image(captcha_text)) / 255.0\\nfor j, ch in enumerate(captcha_text):\\n# 设置标签，这里不需要独热编码\\ny[i, j] = self.characters.find(ch)\\n# 如果验证码长度不是6，则需要设置空白字符\\nfor k in range(len(captcha_text),self.label_len):\\n# 空白字符编号为num_classes-1\\ny[i, k] = num_classes-1\\n# 返回一个批次的数据和标签\\n# 注意这里的标签np.ones(self.batch_size)是没有意义的，只是由于返回的数据必须要\\n有标签\\nreturn [x, y, input_len, label_len], np.ones(self.batch_size)\\n# 返回批次数量\\ndef __len__(self):\\nreturn self.steps\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 483, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 484\\n# 测试生成器\\n# 一共一个批次，批次大小也是1\\ndata = CaptchaSequence(characters, batch_size=1, steps=1)\\nfor i in range(2):\\n# 产生一个批次的数据\\n[x, y, _, _], _ = data[0]\\n# 显示图片\\nplt.imshow(x[0])\\n# 验证码字符和对应编号\\nplt.title(data.captcha_list[0])\\nplt.show()\\n结果输出为：\\n代码13-8：CTC 算法-验证码识别（片段2）\\n# Keras调用Tensorflow 中的ctc_batch_cost\\n# x是模型输出，shape-(?,10,63)\\n# labels是验证码的标签，shape-(?,max_len)\\n# input_len是x的长度，shape-(?,1)，x的长度为10\\n# label_len是labels的的长度，shape-(?,1)，labels的长度为max_len\\ndef ctc_lambda_func(args):\\nx, labels, input_len, label_len = args\\n# Tensorflow 中封装的ctc 计算\\nreturn K.ctc_batch_cost(labels, x, input_len, label_len)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 484, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 485\\n# 载入预训练的resnet50 模型，不包含全连接层\\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)\\n)\\n# 设置输入\\nimage_input = Input((height,width,3), name='image_input')\\n# 使用resnet50 进行特征提取\\nx = resnet50(image_input)\\n# resnet50 计算后得到的数据shape 为(?,2,5,2048)\\n# 10 个输入最多对应10 个输出，验证码最长为6，理论上只要不出现6 个字符都相同的极\\n端情况，长度是够用的。\\n# 比如极端情况'aaaaaa'，'-'表示空白符，模型输出'a-a-a-a-a-a'至少需要11 的长度。\\n# 不过长度不够可能会影响对连续重复字符的判断效果，比如'aaaa'可能会被识别为'aaa'\\n# 如果要增加输入长度，可以通过增大输入图片的大小或修改网络结构的方式实现\\n# 这里Reshape的作用是将卷积输出的4 维数据转化为RNN 输入所要求的3 维数据，\\n2*5=10表示序列长度\\nx = Reshape((10,2048))(x)\\n# Bidirectional为双向RNN，可以把RNN/LSTM/GRU 传入Bidirectional中\\n# GRU 中的return_sequences=True表示返回所有序列的结果\\n# 比如在本程序中return_sequences=True返回的结果shape 为(?,10,256)\\n# GRU 中的return_sequences=False表示只返回序列last output的结果\\n# 比如在本程序中return_sequences=False返回的结果shape 为(?,256)\\nx = Bidirectional(GRU(RNN_cell, return_sequences=True))(x)\\nx = Bidirectional(GRU(RNN_cell, return_sequences=True))(x)\\nx = Dense(num_classes, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(image_input, x)\\n# 定义标签输入\\nlabels = Input(shape=(max_len), name='max_len')\\n# 输入长度\\ninput_len = Input(shape=(1), name='input_len')\\n# 标签长度\\nlabel_len = Input(shape=(1), name='label_len')\\n# Lambda的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理\\nctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len, label_len])\\n# 定义模型\\nctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out)\\n# 画图\\nplot_model(ctc_model,style=0,show_layer_names=True)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 485, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 486\\n代码13-8：CTC 算法-验证码识别（片段3）\\nfrom tensorflow.keras.callbacks import Callback\\n# 编号转成字符串\\ndef labels_to_text(labels):\\nret = []\\nfor l in labels:\\n# -1 是空白符\\nif l == -1:\\nret.append(\\'\\')\\nelse:\\nret.append(characters[l])\\nreturn \"\".join(ret)\\n# 把一个批次的编号转为字符串\\ndef decode_batch(labels):\\nret = []\\nfor label in labels:\\nret.append(labels_to_text(label))\\nreturn np.array(ret)\\n# 自定义Callback\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 486, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 487\\nclass Evaluate(Callback):\\ndef __init__(self):\\npass\\n# 自定义准确率计算\\ndef accuracy(self, model, batch_size=batch_size, steps=test_steps):\\n# 准确率统计\\nbatch_acc = 0\\n# 产生测试数据\\nvalid_data = CaptchaSequence(characters, batch_size, steps)\\nfor [X_test, y_test, _, _], _ in valid_data:\\n# 特别要注意，空白字符的编号为-1\\n# 这里可以先将我们自定义的空白符标签变成-1\\nfor i,label in enumerate(y_test):\\nfor j,l in enumerate(label):\\nif l == num_classes-1:\\ny_test[i,j] = -1\\n# 将一个批次的标签数据转为字符串形式\\ny_test = decode_batch(y_test)\\n# 得到预测结果\\ny_pred = model.predict(X_test)\\n# shape[0]为batch_size，shape[1]为max_len\\nshape = y_pred.shape\\n# ctc_decode默认使用贪心算法计算出ctc 的预测结果\\n# get_value获得ctc_decode的数值返回numpy array格式的数据\\nout = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[\\n0][0])\\n# 将一个批次的预测数据转为字符串形式\\nout = decode_batch(out)\\n# 对比一个批次的标签和预测数据，计算准确率\\nbatch_acc += (y_test == out).mean()\\n# 返回准确率\\nreturn batch_acc / steps\\n# 顾名思义，在一个训练周期的末尾会自动调用这个方法\\n# 这里的epoch 是当前训练的周期数\\n# logs是一个字典用来记录一些模型训练的信息\\ndef on_epoch_end(self, epoch, logs):\\n# 计算准确率\\nacc = self.accuracy(model)\\n# 记录val_acc\\nlogs['val_acc'] = acc\\n# 打印\\nprint(f'\\\\nacc: {acc*100:.4f}')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 487, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 488\\n# 除了on_epoch_end以外，自定义Callback还可以定义很多方法，比如：\\n# def on_epoch_begin(self, epoch, logs=None):\\n# def on_batch_begin(self, batch, logs=None):\\n# def on_batch_end(self, batch, logs=None):\\n# 等等，有兴趣的同学可以看tensorflow 源码进一步研究。\\n# loss的计算是在K.ctc_batch_cost中实现的，所以这里定义了一个假的loss，没什么意\\n义，也没有作用，但是必须要定义\\nctc_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=SGD(lr=1e-\\n2,momentum=0.9))\\n# 监控指标统一使用val_acc\\n# 可以使用EarlyStopping来让模型停止，连续6 个周期val_acc没有上升就结束训练\\n# CSVLogger保存训练数据\\n# ModelCheckpoint保存所有训练周期中 val_acc最高的模型\\n# ReduceLROnPlateau学习率调整策略，连续3 个周期val_acc没有上升当前学习率乘以\\n0.1\\ncallbacks = [Evaluate(),\\nEarlyStopping(monitor='val_acc', patience=6, verbose=1),\\nCSVLogger('Captcha_ctc.csv'),\\nModelCheckpoint('Best_Captcha_ctc.h5', monitor='val_acc', save_best_only=True),\\nReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=3, verbose=1)\\n]\\n# 训练模型\\nctc_model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),\\nepochs=epochs,\\nvalidation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test\\n_steps),\\ncallbacks=callbacks)\\n结果输出为：\\nTrain for 1000 steps, validate for 100 steps\\nEpoch 1/100\\n999/1000 [============================>.] - ETA: 0s - loss: 5.8164\\nacc: 33.6562\\n1000/1000 [==============================] - 313s 313ms/step - loss:\\n5.8136 - val_loss: 4.2324\\nEpoch 2/100\\n999/1000 [============================>.] - ETA: 0s - loss: 1.7650\\nacc: 62.4844\\n……\\nEpoch 36/100\\n999/1000 [============================>.] - ETA: 0s - loss: 0.3042\\nacc: 89.7344\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 488, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 489\\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837\\n88405e-08.\\n1000/1000 [==============================] - 306s 306ms/step - loss:\\n0.3042 - val_loss: 0.2984\\nEpoch 00036: early stopping\\n13.8.2 使用 CTC 算法训练验证码模型-模型预测\\n关于模型测试阶段，我们需要注意的是使用 load_weights 的方式载入模型权值，而不\\n能直接用load_model 载入模型。因为keras 中没有封装ctc 的loss，ctc 的loss是在 tens\\norflow 中定义的，属于keras 外部自定义 loss。模型save 的时候如果包含了自定义loss，\\n那么在load_model 的时候也需要声明自定义loss。在这个应用中还是重新搭建一遍模型并\\n使用load_weights 载入模型权值比较简单，如代码13-9 所示。\\n代码13-9：CTC 算法-验证码识别-模型预测（片段1）\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\nfrom tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras import backend as K\\nfrom captcha.image import ImageCaptcha\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport string\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个\\ncharacters = string.digits + string.ascii_letters\\n# 类别数+空白字符\\nnum_classes = len(characters)+1\\n# 图片宽度\\nwidth=160\\n# 图片高度\\nheight=60\\n# RNN 的cell 数量\\nRNN_cell = 128\\n# 最长验证码\\nmax_len = 6\\n# Keras调用Tensorflow 中的ctc_batch_cost\\n# x是模型输出，shape-(?,10,63)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 489, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 490\\n# labels是验证码的标签，shape-(?,max_len)\\n# input_len是x的长度，shape-(?,1)，x的长度为10\\n# label_len是labels的的长度，shape-(?,1)，labels的长度为max_len\\ndef ctc_lambda_func(args):\\nx, labels, input_len, label_len = args\\n# Tensorflow 中封装的ctc 计算\\nreturn K.ctc_batch_cost(labels, x, input_len, label_len)\\n# 载入预训练的resnet50 模型\\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)\\n)\\n# 设置输入\\nimage_input = Input((height,width,3), name='image_input')\\n# 使用resnet50 进行特征提取\\nx = resnet50(image_input)\\n# 搭建RNN 网络\\nx = Reshape((10,2048))(x)\\nx = Bidirectional(GRU(RNN_cell, return_sequences=True))(x)\\nx = Bidirectional(GRU(RNN_cell, return_sequences=True))(x)\\nx = Dense(num_classes, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(image_input, x)\\n# 定义标签输入\\nlabels = Input(shape=(max_len), name='max_len')\\n# 输入长度\\ninput_len = Input(shape=(1), name='input_len')\\n# 标签长度\\nlabel_len = Input(shape=(1), name='label_len')\\n# Lambda的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理\\nctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len, label_len])\\n# 定义模型\\nctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out)\\n# 注意这里是load_weights，载入权值，这里不能直接用load_model载入模型\\n# 因为keras中没有封装ctc 的loss，ctc 的loss是在tensorflow 中定义的，属于keras外部\\n自定义loss\\n# 模型save 的时候如果包含了自定义loss，那么在load_model的时候也需要声明自定义\\nloss。\\n# 在这个应用中还是重新搭建一遍模型并使用 load_weights载入模型权值比较简单\\nmodel.load_weights('Best_Captcha_ctc.h5')\\n# 用于预测的字符集多一个空白符\\npre_characters = characters + '-'\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 490, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 491\\n# 使用贪心算法预测结果\\ndef greedy(captcha_text):\\n# 自定义产生一个验证码\\ncaptcha_text = captcha_text\\n# 产生验证码并归一化\\nimage = ImageCaptcha(width=160, height=60)\\nx = np.array(image.generate_image(captcha_text)) / 255.0\\n# 变成4 维数据\\nX_test = np.expand_dims(x, axis=0)\\n# 用模型进行预测\\ny_pred = model.predict(X_test)\\n# 查看y_pred 的shape\\nprint(\"y_pred shape:\",y_pred.shape)\\n# 获得每个序列最大概率的输出所在位置，其实也就是字符编号\\nargmax = np.argmax(y_pred[0], axis=-1)\\nprint(\\'id\\',\\'\\\\t\\',\\'characters\\')\\nfor x in argmax:\\n# 打印字符编号和对应的字符\\nprint(x,\\'\\\\t\\',pre_characters[x])\\n# 使用贪心算法计算预测结果\\nout = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.\\nshape[1], greedy=True)[0][0])\\n# 把预测结果转化为字符串\\nout = \\'\\'.join([characters[x] for x in out[0]])\\n# 显示图片\\nplt.imshow(X_test[0])\\n# 设置title\\nplt.title(\\'pred:\\' + out + \\'\\\\ntrue: \\' + captcha_text)\\n# show\\nplt.show()\\n# 生产特定验证码并进行识别\\ngreedy(\\'a0b1C3\\')\\n结果输出为：\\ny_pred shape: (1, 10, 63)\\nid characters\\n10 a\\n0 0\\n11 b\\n1 1\\n38 C\\n3 3\\n62 -\\n62 -\\n62 -\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 491, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 492\\n62 -\\n代码13-9：CTC 算法-验证码识别-模型预测（片段2）\\n# 生产特定验证码并进行识别\\n# 模型训练阶段我们使用的验证码都是 3-6 位的\\n# 预测阶段使用2 位长度的验证码也可以识别正确\\ngreedy('aa')\\n结果输出为：\\ny_pred shape: (1, 10, 63)\\nid characters\\n10 a\\n62 -\\n10 a\\n10 a\\n62 -\\n62 -\\n62 -\\n62 -\\n62 -\\n62 -\\n代码13-9：CTC 算法-验证码识别-模型预测（片段3）\\n# 生产特定验证码并进行识别\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 492, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 493\\n# 模型训练阶段我们使用的验证码都是 3-6 位的\\n# 预测阶段使用7 位长度的验证码也可以识别正确\\n# 不过由于我们的模型输入输出长度最多为 10，并且模型训练阶段，验证码最多为6 位\\n# 所以如果验证码长度超过6 的话识别的效果可能不太理想\\ngreedy('abcdefg')\\n结果输出为：\\ny_pred shape: (1, 10, 63)\\nid characters\\n10 a\\n11 b\\n12 c\\n13 d\\n14 e\\n15 f\\n16 g\\n62 -\\n62 -\\n62 -\\n代码13-9：CTC 算法-验证码识别-模型预测（片段4）\\n# 使用beam search 预测结果\\ndef beam_search(captcha_text):\\n# 自定义产生一个验证码\\ncaptcha_text = captcha_text\\n# 产生验证码并归一化\\nimage = ImageCaptcha(width=160, height=60)\\nx = np.array(image.generate_image(captcha_text)) / 255.0\\n# 变成4 维数据\\nX_test = np.expand_dims(x, axis=0)\\n# 用模型进行预测\\ny_pred = model.predict(X_test)\\n# 最好的3 个结果\\ntop_paths = 3\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 493, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 494\\n# 保存最好的3 个结果\\nouts = []\\nfor i in range(top_paths):\\nlabels = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_\\npred.shape[1],\\ngreedy=False,top_paths=top_paths)[0][i])[0]\\nouts.append(labels)\\n# 最好的3 个结果分别显示出来\\nfor out in outs:\\n# 转字符串\\nout = ''.join([characters[x] for x in out])\\n# 显示图片\\nplt.imshow(X_test[0])\\n# 设置title\\nplt.title('pred:' + out + '\\\\ntrue: ' + captcha_text)\\n# show\\nplt.show()\\n# 生产特定验证码并进行识别\\nbeam_search('AbCd70')\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 494, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 495\\n从CTC 算法模型测试结果可以看出，就算训练阶段验证码长度是3-6 位，模型也能预测\\n少于3 位或多于 6 位的验证码结果。在使用beam search算法后，模型可以给出概率最大\\n的几个输出结果。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 495, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 496\\n第 14 章-自然语言处理 NLP 发展历程\\n（上）\\n本章主要给大家介绍NLP(Natural Language Processing)技术的发展历程，不过必须先\\n要说清楚的是NLP技术是AI技术领域的一个大方向，所以真的要把 NLP发展历程介绍清楚\\n那至少要写一两本书。所以本章介绍的内容主要是近年来 NLP与深度学习结合的最重要和最\\n新的一些成果。由于内容比较多，所以分上下两个部分给大家介绍。\\n14.1 NLP 应用介绍\\n在介绍NLP的具体技术之前，我们先来了解一下NLP的一些实际应用。NLP的任务基\\n本上都可以使用序列模型来完成，如果大家对前面的序列模型忘记了可以先回头看一下。\\nNLP应用中大部分的任务都可以使用seq2seq架构来完成，seq2seq计算细节我们在后面\\n再详细介绍。\\n14.1.1 文本分类/情感分类\\n如图14.1：\\n图 14.1 文本分类\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 496, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 497\\n文本分类就是把一段文本划分到不同的类别；情感分类就是对一段文本中所包含的情感\\n进行分类。其实文本分类或文章句子的情感分类本质上都是一样，都是属于分类任务，套用\\n序列模型里面我们讲过的框架，属于多对一框架。输入一篇文章或句子可以看出是一个序\\n列，整个序列输入结束后我们只需要获得序列最后一个输出即可。对最后一个序列的输出信\\n号进行分类，得到分类结果。\\n14.1.2 分词标注\\n这个应用在序列模型的章节中也有介绍过，可以使用多对多架构完成，序列的每个输入都\\n会得到一个对应的输出结果。给一段文字做分词标注，标注每个字对应的标号。假如使用 4-\\ntag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S\\n表示单字词。可以得到类似如下结果：\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n14.1.3 机器翻译\\n如图14.2：\\n图14.2 机器翻译\\n机器翻译是典型的seq2seq应用，比如输入一段中文，中文句子就是一段序列。输出得\\n到一段英文，英文句子也是一段序列。类似这种问题都可以使用 seq2seq架构来完成。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 497, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 498\\n14.1.4 聊天机器人\\n如图14.3：\\n图14.3 聊天机器人\\n聊天机器人也是典型的seq2seq应用，输入一个句子输出一个句子。不过目前的技术发\\n展还不够成熟，纯娱乐性质的聊天机器人用处不大，因为你稍微跟它多聊几句可能就会发现\\n它是个智障。你只能跟它聊今天星期几，明天什么天气之类的话题，无法实现复杂对话。\\n不过聊天机器人在某些特定领域，如机器人客服领域，还是发挥了很大的作用。很多电\\n商，银行都已经上线了机器人客服的应用，因为在特定领域，大家的聊天内容相对固定，所\\n以比较容易判断用户的意图，然后给出相应的回复。\\n不过大家要注意像机器人客服这样的应用并不是一个模型就可以搞定所有的事情，虽然\\n模型也会用，不过很多用户意图的判断和对话的回复还是通过规则来实现的。比如匹配句子\\n是否出现了某个词，假设出现“发货”这个词，那说明用户可能想咨询发货相关的问题；假\\n如出现“信用卡”，那用户可能是要咨询信用卡相关业务。并且机器人的回复也不是自动生\\n成的回复，机器人回复的内容基本上也是事先人工设置好的内容。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 498, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 499\\n14.1.5 自动摘要\\n自动摘要很容易理解，就是阅读文章后产生出文章的标题，也是属于 seq2seq架构。这\\n要求模型具备极强的核心内容提取概括能力，听起来就很难。所以目前自动摘要技术做得也\\n不算非常好，有些时候效果不错，有些时候效果很差。\\n14.1.6 文章生成\\n可以给模型输入一段话或者是一大段文章，然后让模型自动生成接下来的内容，生成的\\n文章长度可以人为控制，这也是seq2seq模型。这个应用听起来就是即神奇有趣又不靠谱。\\n下面我们可以看一下实际模型得到的效果，使用金庸小说训练后的模型，给它输入一段文字\\n让它进行后续文章的生成（结果来自：\\nhttps://github.com/bojone/bert4keras/blob/master/examples/task_language_model.\\npy）。\\n输入：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。\\n输出：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。这时见他手中所握，竟是\\n一柄特制的短剑，心中大喜，叫道：：原来是金蛇郎君的剑！原来你便是金蛇郎君的弟子，\\n这一下可要叫我失望了。那人哈哈一笑，说道：好啊！好啊，好啊！我的金蛇剑是我的，不\\n过我是你的。这人道：我姓杨名过，名字叫过。你是我儿子，是我女儿，是不是？你这么大\\n的年纪，怎地自称金刀驸马？我这就给你取个名字，叫作过儿。\\n输入：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n外，但听她呼吸调匀，正自香梦沉酣。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 499, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 500\\n输出：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n外，但听她呼吸调匀，正自香梦沉酣。次日清晨，张无忌便和赵敏去买了一匹高头大马，自\\n己骑了随伴。那马甚有神骏，三十六斤重的身躯之中，竟无一头白马。他心中怦怦乱跳，暗\\n想：若能将赵敏引出迷城，我决不致再和她相会，但若和赵姑娘相遇，我一生一世决计再难\\n相见。何况我是她的私生女儿，这般亲热，岂不是好？我如何能和她相见？今后我要教训教\\n训她才好？我教教她，教训她，要她心里快快活活的。他心如刀割，当即回到客店，将张无\\n忌的所在说了。\\n这是什么玩意儿？目前看来除了搞笑以外，没有其他作用。\\n另外诗歌生成也是类似的，我们可以给模型传入诗歌的标题，模型就可以产生一首诗出\\n来。\\n14.1.7 图片描述\\n图片描述是计算机视觉与NLP相结合的一个技术，首先使用一个预训练的CNN 模型对\\n图片数据进行特征提取，然后把CNN 模型提取的图像特征传给RNN网络进行文字生成，如\\n图14.4：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 500, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 501\\n图14.4 图片描述模型\\n有些图片得到的效果挺好的，如图 14.5：\\n图14.5 图片描述1\\n臭臭躺在床上，不过光看背景也不太看得出是床，所以描述是 laying on a couch也是\\n合理的。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 501, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 502\\n有些图片描述的效果就比较奇怪了，如图 14.6：\\n图14.6 图片描述2\\n一个女人站在人行道上，穿着粉红色的雨伞……很显然该模型不具备生活的常识，生活的\\n常识就是人是不会穿雨伞的，它只是把它识别到的物体给拼凑到一起了。\\n图片描述在某些特定场景下可以得到不错的效果，不过整体而言效果还是差强人意的。\\nNLP的应用还有很多，这里我们就不举太多例子了，大家有兴趣可以再自行研究。\\n14.2 从传统语言模型到神经语言模型\\n传统的自然语言处理也叫统计自然语言处理，听名字我们就知道传统的自然语言处理技\\n术主要是使用数学和统计学。这跟神经网络/深度学习在自然语言处理中的技术截然不同，神\\n经网络/深度学习主要使用的是数学和玄学（开玩笑）。由于技术上的巨大差异，下面关于统\\n计自然语言处理的部分我们只做简单介绍，重点还是介绍神经网络/深度学习在自然语言处理\\n方面的应用。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 502, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 503\\n14.2.1 规则模型[1]\\n在上世纪60 年代左右，学术界对人工智能和自然语言处理的普遍理解是：要让机器完成\\n翻译或语言识别等只有人类才能做的事情，就必须先让计算机理解自然语言，而做到这一点\\n就必须让计算机拥有类似我们人类这样的智能。（真正做到这点确实很难，直到今天计算机\\n也没能做到这一步，所以现在几乎所有科学家都不再坚持这一点）。\\n那么要如何让计算机理解自然语言呢，当时科学家得出的结论是分析语句和获取语义。\\n我们在学校学习外语的时候都要学习语法规则（Grammar Rules），词性（Part of\\nSpeech）和构词法（Morphologie）等，这些内容对于我们学习外语有一定的帮助，并且\\n比较容易用计算机的算法描述。大家以为这会是一条正确的道路。\\n在上世纪80 年代以前，自然语言处理工作中的文法规则都是人工写的，直到2000 年\\n后，很多公司还是靠人工来总结文法规则。通过人工设计的规则来分析句子虽然可能会有些\\n效果，但是总体而言不太靠谱。比如有下面 3 个问题：\\n问题1：我们人类的语言博大精深，几乎有无数种不同的句子，如果真的能有一套规则能\\n描述好每一个句子，那这套规则得有多少条，几亿条还是几百亿条还是更多？这么复杂的一\\n套规则即使真的存在，我们人类可能无法把它写出来。\\n问题2：我们人类设计的文法规则通常是上下文无关文法（Context Independent\\nGrammar），而实际句子的文法其实应该是跟上下文相关的，属于上下文相关文法\\n（Context Dependent Grammar）。两者的设计难度和计算量都无法相提并论。\\n问题3：我们人类的语言有些是需要常识来进行判断的。比如“吃饭前我想方便一下”，\\n“你方便的时候我想请你吃饭”，“你方不方便你去方便的时候问你吃饭的事”，这里的\\n“方便”我们都能理解什么意思，但是要跟老外解释清楚就不容易了，更别说计算机。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 503, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 504\\n14.2.2 统计语言模型[1]\\n在上世纪80 年代末，随着计算能力的提升和数据量的不断增加，过去看似不可能通过统\\n计模型完成的任务，渐渐都变得可能了。到了上世纪 90 年代末期，大家发现通过统计得到\\n的句法规则甚至比语言学家总结的更有说服力。2005 年以后，Google 基于统计方法的翻译\\n系统全面超过基于规则的SysTran翻译系统，宣告规则方法学派的全面溃败。\\n统计语言模型简单来说就是通过统计得到的语言模型。规则模型的主要思想是通过人工\\n设定的规则来描述语言，而统计语言模型是通过统计学找到语言的规律。比如一个句子：\\n“我爱北京天安门，天安门上太阳升”。\\n意思清晰句子通顺。如果我们调整一些词的位置，得到：\\n“我爱天安门北京，太阳升上天安门”\\n虽然句子有些不够通顺，但是意思我们还是可以看懂的，假设我们再调整一下句子，得\\n到：\\n“爱北京天安我门，升门天安上太阳”\\n这句话就基本看不懂什么意思了，为什么会这样？规则方法学派的科学家认为一个句子\\n是否能理解，要看句子是否合乎语法，句子中的语义是否清晰。他们的想法有一定的道理，\\n但是在规则方法学这条路上的困难要远大于方法，所以这条路是走不通的。\\n著名的语音识别和自然语言处理的专家弗莱德里克·贾里尼克（Frederick Jelinek）提出\\n了一个新的思路，可以使用简单的统计模型来分析描述一个句子。其实方法很简单，一个句\\n子是否合理，我们不需要分析它的语法语义，只需要分析这句话出现的概率。比如上面我们\\n列举的三个天安门的句子，第一个句子出现概率可能是10(cid:127)\"<，第二个句子出现的概率可能是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 504, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 505\\n10(cid:127)$<，第三个句子出现的概率可能是10(cid:127)\"<<。第一个句子出现概率最大，所以最合理，第三\\n个句子概率最小所以最不合理。\\n比如用S 表示一个句子，一个句子由若干个顺序排列的词𝑤 , 𝑤 , 𝑤 ,…, 𝑤 组成。所以一\\n\" # $ @\\n个句子出现的概率就等于这个句子每一个词出现的条件概率相乘：\\n𝑃(𝑆) = 𝑃(𝑤 ,𝑤 ,…,𝑤 )\\n\" # @\\n= 𝑃(𝑤 ) ∙ 𝑃(𝑤 |𝑤 ) ∙ 𝑃(𝑤 |𝑤 ,𝑤 ) ∙∙∙ 𝑃(𝑤 |𝑤 ,𝑤 ,…,𝑤 ) (14.1)\\n\" # \" $ \" # @ \" # @(cid:127)\"\\n其中𝑃(𝑤 )表示第一个词出现的概率，𝑃(𝑤 |𝑤 )是在已知第一个词的前提下，第二个词出\\n\" # \"\\n现的概率；以此类推，词𝑤 的出现概率取决于它前面所有的词。\\n@\\n每个词出现的条件概率怎么统计？通常在训练 NLP模型的时候我们都会准备一个语料库\\n（Corpus），语料库其实就是一个数据集，这个数据集就是大量的文本数据。我们可以在这\\n个数据集中统计每个词𝑃(𝑤 )出现的概率，以及前后相邻的两个词𝑃(𝑤 |𝑤 )出现概率，前后\\nˆ ˆ ˆ(cid:127)\"\\n相邻的三个词，四个词，N个词的概率。\\n不过这个模型存在一个问题，就是计算量的问题。𝑃(𝑤 )很容易统计出来，𝑃(𝑤 |𝑤 )难度\\n\" # \"\\n也不是很大，𝑃(𝑤 |𝑤 ,𝑤 )难度就已经非常大了。并且这个计算量是指数级增长的，如果句子\\n$ \" #\\n比较长，𝑃(𝑤 |𝑤 ,𝑤 ,…,𝑤 )可能是无法计算出来的。\\n@ \" # @(cid:127)\"\\n好在这个问题存在可以简化的方式。20 世纪初，俄国数学家马尔可夫（Andrey\\nMarkov）提出每当遇到类似这种情况时，就假设任意一个词𝑤 出现的概率只与它前面的词\\nˆ\\n𝑤 相关，这样问题就变得简单了。这种假设在数学上称为马尔可夫假设。于是公式14.1 就\\nˆ(cid:127)\"\\n可以简化为：\\n𝑃(𝑆) = 𝑃(𝑤 ,𝑤 ,…,𝑤 )\\n\" # @\\n= 𝑃(𝑤 ) ∙ 𝑃(𝑤 |𝑤 ) ∙ 𝑃(𝑤 |𝑤 ) ∙∙∙ 𝑃(𝑤 | 𝑤 ) (14.2)\\n\" # \" $ # @ @(cid:127)\"\\n公式14.2 对应的统计语言模型是二元模型（Bigram Model）。一个词的出现概率只与\\n它前面一个词相关叫二元模型，一个词的出现概率与它前面两个词相关叫三元模型，一个词\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 505, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 506\\n的出现概率与它前面三个词相关叫四元模型。以此类推，一个词的出现概率由前面 N-1 个词\\n决定，称为N 元模型（N-Gram Model）。\\n可以想象N元模型中N的值越大就越接近句子真实的概率，当然N 的值越大计算量也\\n会越大。当N从1 到2，再从2 到3，模型的效果上升显著，而当模型从3 到4 时，效果的\\n提升就不是很明显了。所以一般三元或四元模型用得比较多，很少人会使用四元以上模型。\\n举例来说一下基于N-Gram 模型的应用，比如在进行文本分类应用的时候。我们可以根\\n据每个类别的语料库训练各自的语言模型，比如情绪二分类，正面情绪有一个语料库，可以\\n训练一个语言模型；负面情绪有一个语料库，可以训练一个语言模型。当新来一个文本的时\\n候，只要根据各自的语言模型，计算每个语言模型下这篇文本发生的概率。文本在哪个模型\\n的概率大，这篇文本就属于哪个类别。\\n比如在做语音识别的时候，我们识别出了一个句子的发音“woaibeijingtiananmen”，\\n正确的识别结果是“我爱北京天安门”。但其实这个句子的发音可以对应非常多的文本，比\\n如“我碍北京添安们”，“我爱北精天氨门”。通过 N-Gram 模型我们可以计算出“我爱北\\n京天安门”这句话出现概率是最大的。\\n统计语言模型可以很好地解决很多问题，但是该模型也存在很多问题：\\n问题1：很多时候，在计算条件概率时，𝑃(𝑤 |𝑤 )会得到0 值。也就是新文本中两个相\\nˆ ˆ(cid:127)\"\\n邻词𝑤 𝑤 在语料库中没有出现过。所以统计语言模型中需要设计各种平滑方法来处理这种\\nˆ(cid:127)\" ˆ\\n情况。\\n问题2：统计语言模型无法把 n 取得很大，最多就是3-gram 或4-gram。所以统计语言\\n模型无法建模语言中上下文较长的依赖关系。\\n问题3：统计语言模型无法表征词语之间的相似性。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 506, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 507\\n14.2.3 词向量（word embedding）\\n在介绍神经网络语言模型NNLM（Neural Net Language Model）之前，我们先聊\\n一下NNLM 中的核心思想-词向量（Word Embedding），word embedding也可以翻译\\n为词嵌入，本书把它称之为词向量。\\n我们在处理图像时，图像数据就是一个密集的矩阵，矩阵中的每个数值对应着图片中的\\n每个像素点，我们所需的全部信息都储存在原始数据中。如图14.7：\\n图14.7 图像数据\\n所以我们把这个图像数据对应的矩阵分析好就行了。如果是分析文本数据，我们通常会\\n给每个词进行编号，比如“猫”的编号是 343，“狗”的编号是452。每个词的编号大小一\\n般是跟该词在语料库中出现的频率相关（也有可能是其他编号方式或人为设置的编号），出\\n现的频率越高，编号就越小。从词的编号我们无法知道这个词所包含的含义，也无法知道词\\n与词之间的相关性。\\n接下来我们可能还会对编号进行one-hot独热编码处理。假设语料库中一共有10000 个\\n词，经过独热编码处理后，每个词的数据长度都为 10000，其中只有一个1，其余的位置都\\n是0，如：\\n杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0]\\n上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 507, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 508\\n宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0]\\n北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0]\\n注意，虽然独热编码处理后，每个词变成了一个向量，但是这种独热编码类型的向量可\\n不是前面我们说的词向量（Word Embedding）。独热编码的向量虽然在某些简单场景下也\\n可以得到不错的效果，但是复杂一些的场景就无法得到好的效果了。我们把一个词看成是 1\\n行10000 列的数据，把一个句子看成是一个矩阵，那么这个矩阵将会是一个非常稀疏的矩\\n阵，大部分的值都是0，这个稀疏的矩阵也没有多少可以分析的价值。\\n所以传统的方式不管是将词变成编号还是将词再转成独热编码，都无法对词包含的信息\\n进行一个很好的描述。那么如何才能比较好的去描述一个词呢？用一个向量来描述一个词，\\n或许是一个不错的方法，这就是我们所说的词向量。\\n为什么用一个向量来描述一个词会是一个有效的方法？通常词向量的长度都是人为设置\\n的，比如我们设置词向量的长度为128，也就是说每个词都会使用一个128 维的向量来表\\n示，这个向量的每一个维度都具有抽象的含义（具体的含义我们是无法知道的）。我举一个\\n不是很恰当的例子，假设词向量的某一个维度 d表示该词跟我们日常生活的相关性，相关越\\n大，d的数值就越大。比如“猫”这个词在我们日常生活中经常出现，那么“猫”这个词的\\n词向量中维度d的数值就会比较大；而“引力红移”（广义相对论预言的一种电磁辐射波长\\n变长，频率降低的效应）这个词在我们日常生活中几乎不会出现，所以“引力红移”这个词\\n的词向量中维度d的数值就会比较小。如果每一个词都有128 个维度可以用来描述它，那么\\n理论上就可以把这个词包含的信息描述得比较好。最后再强调一下，词向量中每个维度的含\\n义是抽象的，无法知道它们的具体含义。\\n词向量的思想从NNLM 中提出，并一直沿用至今，是深度学习在NLP领域中使用的既\\n是基础又是核心的思想。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 508, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 509\\n14.2.4 神经语言模型\\n2003 年Bengio在他的经典论文《A Neural Probabilistic Language Model》[2]中首\\n次将神经网络融入到语言模型中，并经过训练得到神经网络语言模型NNLM（Neural Net\\nLanguage Model）。NNLM 的模型结构可以看下图 14.8：\\n图14.8 神经语言模型NNLM[2]\\n图中output表示输出；Matrix表示矩阵；Table look-up in C表示在矩阵C中查询；\\nshared parameters across words表示参数共享。\\n下面我们说一下NNLM 的训练过程，其实很简单，就是传入前面几个词，然后再预测下\\n一个词是什么。具体流程是我们会分析语料库并构建一个字典 V，所有的词都在这个字典\\n中，并且每个词在字典中有唯一编号。NNLM每次训练时从语料库中选取一段长度为n 的文\\n本（𝑤 ,…, 𝑤 ,𝑤 ,𝑤 ）。比如t=10，n=5，那么文本就是（𝑤 ,𝑤 ,𝑤 ,𝑤 ,𝑤 ）。n 可\\nˆ(cid:127)@(cid:151)\" ˆ(cid:127)# ˆ(cid:127)\" ˆ (cid:226) (cid:236) (cid:201) (cid:237) \"<\\n以人为设置，这里的n 有点像n-gram 模型中的n 的意思，分析连续的n 个词。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 509, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 510\\n接下来我们把长度为n 的文本序列用它们所对应的编号来替代，例如：\\n（𝑤 ,𝑤 ,𝑤 ,𝑤 ,𝑤 ）就变成了类似（26,42,267,6582,64）这样的编号。\\n(cid:226) (cid:236) (cid:201) (cid:237) \"<\\n然后再将编号变为one-hot独热编码格式。假设字典V 中一共有10000 个词，本文序\\n列长度为5，经过独热编码的处理后文本数据就变成了 5 行10000 列的矩阵，类似下面这\\n样：\\n[[0,…,0,…,1,…,0,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n[0,…,0,…,0,…,1,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n[0,…,0,…,0,…,0,…,0,…,1,…,0,…,0,…0,…,0,…0,…0]\\n[0,…,0,…,0,…,0,…,0,…,0,…,0,…,0,…0,…,0,…1,…0]\\n[0,…,0,…,0,…,0,…,1,…,0,…,0,…,0,…0,…,0,…1,…0]]\\n然后把最后一个词的独热编码作为模型预测的标签值，其他词的独热编码作为输入传给\\n模型。图14.8 中的C称为词特征层，该层有一个权值矩阵 Matrix C可以理解为所有词的词\\n向量矩阵（Matrix C在训练开始的时候都是随机值，没有任何意义，经过模型训练以后才能\\n得到有意义的词向量）。比如词向量的长度为 128，那么Matrix C可能就是一个10000 行\\n128 列的权值矩阵，矩阵中的一行表示一个词的词向量。\\n每个词的独热编码与Matrix C相乘，得到该词对应的词向量的值，如图14.9：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 510, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 511\\n图14.9 得到每个词的词向量\\n图14.8 中的𝐶(𝑤 )表示𝑤 的词向量，𝐶(𝑤 )表示𝑤 的词向量，𝐶(𝑤 )表示\\nˆ(cid:127)@(cid:151)\" ˆ(cid:127)@(cid:151)\" ˆ(cid:127)# ˆ(cid:127)# ˆ(cid:127)\"\\n𝑤 的词向量。得到输入的每个词的词向量以后，对这些词向量进行拼接\\nˆ(cid:127)\"\\n（concatenation），比如对4 个长度为128 维的词向量进行拼接，得到512 维的数据。公\\n式14.3 表示多个词向量进行拼接得到 x：\\n𝑥 = (𝐶(𝑤 ),𝐶(𝑤 ),…,𝐶(𝑤 ),) (14.3)\\nˆ(cid:127)\" ˆ(cid:127)# ˆ(cid:127)@(cid:151)\"\\n模型最终的输出值y 的计算公式为：\\n𝑦 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑏 + 𝑊𝑥 + 𝑈𝑡𝑎𝑛ℎ(𝑑 + 𝐻𝑥)) (14.4)\\n可以对照着图14.8 来看，x为多个词向量拼接后的信号，H 为x到隐藏层之间的权值矩\\n阵，d为隐藏层的偏置值，tanh为隐藏层的激活函数，U为隐藏层到输出层之间的权值矩\\n阵。b+Wx为图14.8 中的虚线部分，b是偏置值，W是权值矩阵，虚线就是表示可有可\\n无，如果设置了b和W不为0，则计算b+Wx，相当于x可以传给输出层。如果设置\\nb=W=0，相当于不把x直接传给输出层。模型输出神经元的数量等于字典中的词汇数量，\\n最后softmax得到每个词的预测概率值。\\nNNLM 模型就是在训练一个传入前面几个词，然后预测下一个词的模型。这个模型训练\\n好之后，就得到了我们想要的词向量，词向量就保存在前面提到的 Matrix C中。Matrix C\\n中的每一行就对应了一个词的词向量，Matrix C的列数表示词向量的长度，可以人为设置。\\nNNLM 能够对句子中更长的依赖关系进行建模，并且得到了每个词的数值表示，然后可\\n以使用词向量来计算词与词之间的相似性，这些都是传统统计模型无法做到的。将词表征为\\n一个向量形式，这个思想直接启发了后来的 word2vec的工作。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 511, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 512\\n14.3 word2vec\\n14.3.1 word2vec 介绍\\n词向量的思想最早源于2003 年Bengio的论文，但是真正发扬光大是在10 年后的\\n2013 年。2013 年托马斯·米科洛夫（Tomas Mikolov）在Google 带领的研究团队创造了\\n一套word embedding训练的方法，称之为word2vec。最早提出word2vec的论文是\\n《Efficient estimation of word representations in vector space》[3]。\\nword2vec就是word to vector的缩写，中文意思就是将词转化为向量。词向量的思想\\n2003 年就已经提出，之所以没有得到大规模的应用，一方面是传统统计语言模型在 NLP领\\n域已经大规模应用，并且效果也还不错，想要撼动它的地位不容易；另一方面是词向量的思\\n想虽然看起来很美好，但是实际用起来效果也不算很突出。其实词向量的思想是一个正确的\\n方向，为什么实际应用效果不够突出，主要是词向量的训练方法不够好。而 word2vec正是\\n一种更好的词向量训练方法。\\n14.3.2 word2vec 模型训练[4]\\nword2vec的模型训练有两种方式，分别是连续词袋模型CBOW（Continuous Bag-\\nof-Words）和 Skip-Gram 模型。这两个模型都很简单，CBOW模型是给神经网络传入上\\n下文词汇，然后预测目标词汇。比如我们有一个用于训练的句子是“我爱北京天安门“，可\\n以给模型传入“爱”和“天安门“，然后用”北京“作为要预测的目标词汇。而最简单的\\nCBOW模型就是传入前一个词然后再预测后一个词，如图 14.10：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 512, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 513\\n14.10 简单CBOW模型[4]\\n图中的Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n层。\\n这是一个带有一个隐藏层的简单神经网络。数据预处理的部分跟 NNLM一样，先准备一\\n个语料库，然后利用语料库构建一个字典，每个词都有一个编号，再把编号变成独热编码。\\n训练模型的时候就把语料库中的句子相邻的两个词作为一组。比如把“我爱北京天安门”变\\n成“我，爱”，“爱，北京”，“北京，天安门”，然后传给模型，前一个词作为输入，后\\n一个词作为标签。图中的输入为词的独热编码，W为保存词向量的矩阵，字典中一共有V 个\\n词，人为设置的词向量长度为N，所以词向量矩阵W是V 行N列。词向量的长度其实是通\\n过神经网络隐藏层的神经元个数来设置的，隐藏层的神经元个数等于词向量的长度。隐藏层\\n到输出层之间的权值矩阵W’是N行 V 列，最后得到V 个词的概率分布。\\n这个简单的CBOW模型训练好以后，每个词的词向量组成的矩阵就是输入层到输出层之\\n间的权值矩阵W，W中的每一行就是一个词的词向量。那么更复杂一些的CBOW模型如图\\n14.11：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 513, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 514\\n图14.11 标准CBOW模型[4]\\n图中的Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n层。\\n标准CBOW模型跟前面的简单CBOW模型类似，只不过是使用上下文的词汇来预测目\\n标词汇。具体是使用前后一个词还是前后两个词或是前后三个词可以人为设定。输入的每个\\n词都共用一个权值矩阵W，而模型训练好以后，输入层到隐藏层之间的权值矩阵W就是词\\n向量矩阵。\\nSkip-Gram 模型跟CBOW模型相反，给模型传入一个词汇，然后预测上下文的词汇。\\n比如给模型传入”北京“，然后把”爱“和”天安门“作为要预测的词汇。如图 14.12：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 514, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 515\\n图 14.12 Skip-Gram 模型[4]\\n图中的Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n层。\\n传入一个词汇以后要预测多少个上下文词汇，都是可以人为设置的。模型训练好以后输\\n入层到隐藏层之间的权值矩阵W就是词向量矩阵。\\nCBOW和Skip-Gram 这两种方式都可以用于训练词向量。\\n14.3.3 word2vec 训练 trick 和可视化效果\\nword2vec训练过程中有两个trick，主要是用于加速模型训练。分别是层次softmax\\n（Hierarchical Softmax）和 负采样（Negative Sampling）。这两个trick并不是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 515, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 516\\nword2vec的精髓，只是训练技巧，所以这里我们只做个简单介绍，大家有兴趣可以再自行\\n研究。\\nhierarchical softmax最早源于2005 年Bengio的论文《Hierarchical Probabilistic\\nNeural Network Language Model》[5]。训练word2vec词向量的时候，模型的输出是一\\n个多分类，并且由于字典中词汇数量巨大，导致分类数量巨大。hierarchical softmax的本\\n质是把N分类问题变成了log(N)次二分类问题，可以加快模型训练速度。不过随着计算能力\\n的提升，以及GPU加速和TPU加速的应用，现在hierarchical softmax已经用得不多了。\\nnegative sampling源自2013 年Mikolov自己的论文《Distributed Representations\\nof Words and Phrases and their Compositionality 》[6]。假设训练word2vec词向量\\n时，词典的大小为30000，那么最后softmax分类就会有30000 个结果。如果我们用的是\\nCBOW模型，传入上下文词汇，预测目标词汇。我们把标签词汇看成是正样本，其他词汇看\\n成是负样本。那么在模型训练时，模型输出会最大化正样本（也就是标签词汇）的概率，同\\n时最小化负样本（除标签词汇以外的词汇）的概率，而正样本只有 1 个，负样本有29999\\n个，负样本的数量巨大，所以计算量比较大。负采样的做法是，每次训练时在所有负样本中\\n选取部分（论文作者的建议是小数据集 5-20 个，大数据集2-5 个）进行训练，由于只选取\\n了少量的负样本进行训练，所以在进行模型计算和权值更新时，计算量减少了很多。\\nword2vec训练得到的词向量通常都比较长，词向量的效果怎么样，我们可以通过可视化\\n的方式来查看。比如如图14.13：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 516, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 517\\n图14.13 word2vec可视化1\\n这是对word2vec训练得到的词向量进行了降维可视化的结果。图中我们可以看到从男\\n人到女人的向量与从国王到皇后的向量是差不多的，也就是从男人变成女人的这个过程与从\\n国王变成女王的过程差不多，似乎有些道理。\\n图14.14 中也是词向量可视化的结果：\\n图14.14 word2vec可视化2\\n图中国王的词向量减去男人的词向量再加上女人的词向量得到的结果约等于皇后的词向\\n量。\\n从这些可视化的结果我们可以看出，word2vec训练出来的词向量确实包含了词语的信\\n息，可以对词语进行比较好的描述。由于 word2vec在实际应用中取得了比较好的效果，基\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 517, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 518\\n于word2vec，后来又出现了 phrase2vec（把词组/短语变成向量表示）, sentence2vec\\n（把句子变成向量表示）和doc2vec（把文章段落变成向量表示），NLP技术的发展一下子\\n变成了embedding的世界。\\n14.4 CNN 在 NLP 领域的使用\\n说到CNN 大家可能会立马想到计算机视觉。确实，CNN 广泛应用于计算机视觉领域，\\n并取得了非常好的效果。不过CNN 不仅可以用于计算机视觉，在 NLP领域同样可以使用，\\n并且效果也很好。下面我们通过一个文本分类的例子来学习 NLP领域如何使用CNN 网络，\\n这个例子主要参考2015 年的一篇论文《A Sensitivity Analysis of (and Practitioners’\\nGuide to) Convolutional Neural Networks for Sentence Classification》[7]。\\n这篇论文是在word2vec之后发表的，所以用到了词向量的思想。数据处理以及模型计\\n算的流程如图14.15：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 518, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 519\\n图14.15 使用CNN 进行文本分类[7]\\n图中“I like this movie very much!”表示一个英文的句子，中文意思是“我非常喜欢\\n这个电影”；d表示词向量长度；Sentence matrix表示把句子看成是一个矩阵；\\nconvolution 表示卷积；activation function表示激活函数；3 region sizes(2,3,4)表示卷积\\n窗口的大小为(2,3,4)；2 filters for each region size 表示每个尺度的卷积有2 个滤波器；\\ntotally 6 filters 表示总共6 个滤波器；2 feature maps for each region size 表示每个尺度\\n的卷积有2 张特征图；max-pooling 表示最大池化；6 univariate vectors concatenated\\ntogether to form a single feature vector表示池化后的6 张特征图组合起来得到一个新的\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 519, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 520\\n特征向量。softmax function regularization in this layer 表示使用softmax激活函数；2\\nclasses 表示2 分类。\\n我们可以对照着图来看下面具体模型计算和训练步骤：\\n1.首先对要分类的句子进行分词，然后获得每个词的词向量。这里关于词向量如何获取和\\n训练要说明一下。有三种方式，一：载入预训练的词向量。预训练的词向量就是收集大量语\\n料库，使用word2vec的方法训练出每个词的词向量，然后直接载入现在的模型中。词向量\\n载入后数值是固定的，只做计算，不参与训练。二：与方式一相同，载入预训练的词向量，\\n不过方式二中词向量会跟模型一起在新数据集中进行微调 finetune。三：随机初始化新的词\\n向量，在新数据集中进行训练。通常来说使用方法二训练效果会稍微更好一些，如果训练数\\n据集比较大的话，用方法三随机初始化新的词向量进行训练也可以。\\n2.把一个句子的信息看成一个矩阵，矩阵的行是每个词汇，列是每个词汇的词向量，所以\\n行数等于词汇数，列数等于词向量长度，然后对这个矩阵进行卷积。这里的卷积计算跟图像\\n中卷积的计算是一样的，我们可以设置卷积核大小和步长。不过要注意的是卷积核的大小通\\n常指的是卷积窗口的行数，比如可以设置为 2,3,4 等；卷积窗口的列数等于词向量的长度，\\n也就是等于矩阵的列数（图中的d=5 就是词向量的长度为5，主要是为了画图方便，实际应\\n用中词向量的长度可能是128，256，300 等这些值）。卷积步长一般设置为1。我们可以像\\nInception结构一样，设置多个不同尺度的卷积来提取不同尺度的信息。比如使用一些 2 行\\n的卷积，使用一些3 行的卷积，使用一些 4 行的卷积。这就有点像是2 行的卷积是对相邻的\\n2 个词进行特征提取，3 行卷积对相邻的3 个词进行特征提取，4 行卷积对相邻4 个词进行\\n特征提取。\\n3.卷积计算后会得到一些特征图，接下来我们可以对这些特征图进行池化，这里的池化用\\n的是最大池化，池化窗口大小等于特征图的大小，也就是提取每个特征图的最大值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 520, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 521\\n4.把池化后的数据进行拼接（concatenate）。\\n5.池化数据拼接后与最后的输出层进行全连接，得到分类结果。输出层神经元个数等于分\\n类类别数。\\n14.5 RNN 在 NLP 领域的使用\\nRNN 是专门用来处理序列问题的，所以RNN 在NLP领域的应用很容易理解。这里的\\nRNN 指的是所有的 RNN 类似的模型，包括SimpleRNN，LSTM，GRU，Bidirectional\\nRNN 和多层RNN 等，下面我们举两个例子来说明。\\n14.5.1 使用 RNN 进行文本分类\\n数据的预处理跟CNN 在NLP领域应用一样。先对句子进行分词，分词后获得每个词的\\n词向量（前面我们说过了有3 种方式获取并训练词向量）。然后再把每个词的词向量按照序\\n列的顺序传入RNN 模型即可，如图14.16：\\n图14.16 RNN应用于文本分类\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 521, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 522\\n图中𝑥 , 𝑥 , 𝑥 分别为三个词的词向量，ℎ , ℎ , ℎ 分别表示RNN隐藏状态Hidden State\\n< \" # < \" #\\n（比如LSTM 的 memory block 输出），RNN的Hidden State 加上一个用于分类的全连\\n接层，得到RNN 的预测结果y。𝑦 , 𝑦 , 𝑦 分别为RNN 的3 个序列的输出。由于我们的任务\\n< \" #\\n是文本分类，所以我们通常只需要关心序列的最后一个输出即可，用序列最后一个输出与真\\n实标签进行对比得到loss训练模型。\\n14.5.2 使用 RNN 进行中文分词标注\\n我们先简单介绍一下中文分词，在中文分词的任务中，句子中的每个字都会被打上标签。\\n假如使用4-tag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E表示词的结\\n束位置，S 表示单字词。可以得到类似如下结果：\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n在这里我们需要把每个字都变成向量，也就是把每个字都看成是一个“词”。同样的我\\n们也是有3 种方式获取并训练词向量，跟前面我们提到的一样。然后再把每个字的词向量按\\n照序列的顺序传入RNN 模型即可，如图14.17：\\n图14.17 RNN应用于中文分词标注\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 522, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 523\\n图中𝑥 - 𝑥 分别为句子每个字的词向量，𝑦 - 𝑦 分别为RNN 的8 个序列的输出。由于我\\n< (cid:236) < (cid:236)\\n们的任务是中文分词标注，所以RNN 模型的每个输出我们都需要得到。把RNN 模型的每个\\n输出跟真实标签进行对比得到loss训练模型。\\n14.6 Seq2Seq 模型在 NLP 领域的使用\\nSeq2Seq 模型本质上其实也是RNN，只不过它稍微特殊一些，它是由两个RNN 组成。\\n一个RNN 是编码器 Encoder，另一个RNN 是解码器Decoder。Seq2Seq 可以完成很多\\nNLP的应用，比如机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。下面我们将\\n使用机器翻译的例子给大家讲解Seq2Seq 的工作流程，参考Google 在2014 年的论文\\n《Sequence to Sequence Learning with Neural Networks》[8]，这篇论文也是比较早期\\n的一篇Seq2Seq 的论文，应用于机器翻译，并取得了不错的效果。\\nSeq2Seq 应用于机器翻译如图14.18：\\n图14.18 Seq2Seq 应用于机器翻译\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 523, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 524\\n左边部分为编码器Encoder，输入一个句子每个字的词向量进行计算，𝑥 - 𝑥 表示\\n< $\\nEncoder序列4 个输入的词向量值。Encoder的作用是将整个序列的信息压缩成一个向量表\\n示，所以Encoder不需要进行预测。\\n经过Encoder计算后会得到C，C称为上下文向量（Context Vector），用来表示整个\\n序列的信息。C的实际内容是Encoder最后一个序列的状态，也就是Hidden State，这里\\n我们称为State 好了。\\n图中右边部分为解码器Decoder。得到C以后，我们可以用C给Decoder的State 进\\n行初始化（Encoder和Decoder使用的 RNN 结构一致，所以Encoder最后一个序列的\\nState 可以传给Decoder的State 进行初始化），然后给 Decoder传入句子起始符\\n“<start>”的词向量，起始符可以自己定义，起始符的词向量跟其他词的词向量一样会跟着\\n模型参数一起训练。传入起始符词向量后计算得到𝑦R，然后再把𝑦R的词向量作为下一个序列\\n< <\\n的输入进行计算得到𝑦R，然后再把𝑦R的词向量作为下一个序列的输入进行计算得到𝑦R。𝑦R是\\n\" \" # #\\n“<end>”符号，表示Decoder输出结束。“<end>”符号是句子结束符，可以自定义。\\n以上是Seq2Seq 的计算过程，训练过程只要将真实标签跟 Decoder序列输出进行对比\\n得到loss更新网络权值即可。\\n这里再重复强调一下，Encoder和Decoder的基本架构可以使用SimpleRNN，\\nLSTM，GRU，双向RNN 和多层RNN 等。在实际应用中，Seq2Seq 模型可能会更多地使\\n用多层RNN 或多层双向 RNN，提升模型拟合能力。如图14.19 是一个三层的Seq2Seq 模\\n型：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 524, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 525\\n图14.19 多层Seq2Seq 模型\\n由此我们可以看到使用Seq2Seq 模型就可以使得输入序列的长度和输出序列的长度不再\\n受到限制，可以输入任意长度的序列得到任意长度的输出序列。Seq2Seq 的变化形式很多，\\n所以大家也有可能会见到跟上面介绍略有不同的 Seq2Seq 模型。我们主要理解Seq2Seq 的\\n设计思路，细节上的实现可以有多种形式。\\n14.7 Attention 机制\\n14.7.1 Attention 思想的介绍\\nAttention也就是注意力机制，主要是一种思想，就是我们在做某些应用的时候可以把注\\n意力放在某些重要的信息上，同时忽视一些没这么重要的信息。其实之前我们介绍的 SENet\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 525, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 526\\n的核心技术就是一种Attention的思想，把注意力集中在某些比较重要的特征图通道上。\\nAttention的这种思想在自然语言处理，图像，语音等领域都可以使用，不过一般在自然语\\n言处理领域用得更多。\\n下面我们还是通过机器翻译的例子来给大家讲解一下 Seq2Seq 模型如何与Attention进\\n行结合。我们在做机器翻译时，使用Seq2Seq 模型的Encoder把整个句子压缩成一个上下\\n文向量C，然后把C传给Decoder得到翻译结果。这样做其实有个缺点，翻译时，翻译的\\n结果过分依赖于上下文向量C，C是通过一整个句子压缩得来的，那么在压缩的过程中不可\\n避免会造成信息的丢失，翻译的结果也不会特别准确。如何可以改进这种情况呢，可以考虑\\n使用Attention机制，如图14.20：\\n图14.20 Seq2Seq with Attention\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 526, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 527\\n还是熟悉的例子，这个图不是一个真实的 Attention模型，主要是先让大家了解一下\\nAttention的思想。这里主要有两点我们需要注意：\\n1.在带有Attention的Seq2Seq 模型中，上下文向量 C的并不是Encoder最后一个序\\n列的State，而是通过Encoder所有序列的State 计算得到。\\n2.Decoder中每个序列的计算都需要用到不同的上下文向量 C。\\n当我们得到Encoder所有序列的State 后，Decoder在进行计算时，可以重点关注对当\\n前输出重要的Encoder State，而忽视不重要的Encoder State。比如翻译的第一个英文单\\n词“deep”，主要是通过“深”，“度”这两个输入得到的，在计算时应该重点关注“深”\\n和“度”所对应的State；第二个英文单词“learning”，主要是通过“学”，“习”这两个\\n输入得到的，在计算时应该重点关注“学”和“习”所对应的 State。如图14.21：\\n图14.21 不同序列有不同的attention\\n那么如何可以得知Encoder中所有的State，与当前Decoder序列相关性的强弱呢？想\\n要得到这个问题的答案，必须建立起Encoder中State 与Decoder序列中的State 的关\\n系，这也是Attention模型的关键。图14.20 中的模型显然没有做到这一点。后面我们将介\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 527, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 528\\n绍几个实际的Attention模型，由于Attention的各种变化形式很多，这里主要给大家介绍\\n2 种比较常见的 Attention，Bahdanau Attention和Luong Attention。\\n14.7.2 Bahdanau Attention 介绍\\n最早提出Bahdanau Attention的论文是 2014 年的一篇论文《Neural machine\\ntranslation by jointly learning to align and translate》[9]，论文的第一作者为Dzmitry\\nBahdanau，所以论文中所使用的Attention也称为Bahdanau Attention。对于\\nBahdanau Attention的计算流程，我们还是看图片更容易理解，如图 14.22：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 528, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 529\\n图14.22 Bahdanau Attention\\n这个图画完，我的第一感觉是像极了 PCB 电路板设计，这些方块就像是贴片元器件的焊\\n盘，连线就像是电路走线。我在大学做了 3 年PCB 电路设计，看来对我的绘图风格产生了深\\n远的影响……\\n言归正传，Bahdanau Attention的计算流程图基本上跟上一小节Seq2Seq with\\nAttention的图差不多。Encoder没什么好说的，获得所有序列的State。Decoder有些小\\n细节我们要注意，使用Encoder最后一个序列的State 作为Decoder的初始化State，传入\\n起始信号<start>，起始信号可以人为设定，计算得到Decoder的State 信号ℎR，并预测出\\n<\\n翻译结果𝑦R，𝑦R假设我们得到“deep”。在进行下一次预测的时候，我们就要开始计算上下\\n< <\\n文向量𝐶 了，注意看𝐶 的信号是通过Encoder所有的State 和Decoder中上一个序列的\\n\" \"\\nState 信号ℎR共同计算得到的，具体怎么计算等下再说。计算得到𝐶 后，𝐶 与上一个序列的预\\n< \" \"\\n测结果“deep”对应的词向量进行拼接（concatenate），然后传入RNN 中进行计算得到\\nState 信号ℎR，并预测出翻译结果𝑦R。后面的计算以此类推，直到得到句子结束符<end>。\\n\" \"\\n下面我们来说一下Bahdanau Attention 的上下文向量C具体怎么算。首先我们要知道\\nC是通过Encoder中所有的State 计算出来的，我们会根据Attention，给Encoder中的\\nState 分配不同的权重。因此有公式：\\n~\\n𝑐 = ?𝛼 ℎ (14.5)\\n( ((cid:129) (cid:129)\\n(cid:129)A\"\\n公式中𝑐 表示Decoder中第i 序列的上下文向量 C，𝛼 表示Decoder中第i 序列对\\n( ((cid:129)\\nEncoder中第j 序列的Attention权重，ℎ 表示Encoder中第j 序列的State，T 表示\\n(cid:129)\\nEncoder一共有T 个序列。举个具体例子大家可能更好理解，比如“深”，“度”，\\n“学”，“习”分别传入Encoder中得到的State 是ℎ ,ℎ ,ℎ ,ℎ 。Decoder在翻译\\n< \" # $\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 529, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 530\\n“learning”的时候，假设对ℎ ,ℎ ,ℎ ,ℎ 的权重是0.05，0.05，0.6，0.3（注意这里权重的\\n< \" # $\\n和为1，“learning”对“学”和“习”的权重相对较大），那么在翻译“learning”的时\\n候上下文向量𝐶 = 0.05ℎ +0.05ℎ +0.6ℎ +0.3ℎ 。\\n(cid:132)⁄(cid:240)(cid:156)@(@(cid:209) < \" # $\\n接下来再说一下Attention权重𝛼具体怎么得到，计算𝛼的公式为：\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊 ∙ 𝑡𝑎𝑛ℎ (𝑊 ∙ 𝐻((cid:127)\" + 𝑊 ∙ 𝐻 )) (14.6)\\n( (cid:240) æ æ ⁄ ⁄\\n这里的𝛼计算有点像是一个神经网络的计算。𝛼 为Decoder中第i 个序列的Attention\\n(\\n权重，𝐻((cid:127)\"为Decoder 中第i-1 序列的Hidden State，𝐻 为Encoder中所有序列的\\næ ⁄\\nHidden State。𝑊 和𝑊分别为𝐻((cid:127)\"和𝐻 对应的权值矩阵会跟着模型一起训练，tanh为神经\\næ ⁄ æ ⁄\\n网络第一层的激活函数。𝑊 为第二层的权值矩阵会跟着模型一起训练，softmax为第二层的\\n(cid:240)\\n激活函数。\\n我们通过图片的方式来仔细理解一下这里的计算，为了画图方便，假设 Encoder和\\nDecoder输出的 Hidden State 都是4 个值，Encoder的序列长度为2。我们将计算过程分\\n为几步来讲解，第一步𝑊 ∙𝐻((cid:127)\"和𝑊 ∙𝐻 的计算如图14.23：\\næ æ ⁄ ⁄\\n图14.23 Attention权值计算第一步\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 530, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 531\\n第二步计算𝑡𝑎𝑛ℎ (𝑊 ∙𝐻((cid:127)\" +𝑊 ∙𝐻 )，如图14.24：\\næ æ ⁄ ⁄\\n图14.24 Attention权值计算第二步\\n第三步计算𝑊 ∙𝑡𝑎𝑛ℎ (𝑊 ∙𝐻((cid:127)\" +𝑊 ∙𝐻 )，如图14.25：\\n(cid:240) æ æ ⁄ ⁄\\n图14.25 Attention权值计算第三步\\n第四步计算𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊 ∙𝑡𝑎𝑛ℎ (𝑊 ∙𝐻((cid:127)\" +𝑊 ∙𝐻 ))，如图14.26：\\n(cid:240) æ æ ⁄ ⁄\\n图14.26 Attention权值计算第四步\\n由于在这个例子中，Encoder的序列长度为2，所以这里会计算得到两个权重的值，那\\n么最后的上下文向量𝐶 计算如图14.27：\\n(\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 531, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 532\\n图14.27 上下文向量C计算\\nBahdanau Attention的论文中还给了一些可视化结果，英文翻译成法文时，英文单词和\\n法文单词之间的Attention权重如图14.28：\\n图14.28 英文单词和法文单词之间的Attention权重[9]\\n14.7.3 Luong Attention 介绍\\n最早提出Luong Attention的论文是 2015 年的一篇论文《Effective Approaches to\\nAttention-based Neural Machine Translation》[10]，论文的第一作者为Minh-Thang\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 532, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 533\\nLuong ，所以论文使用的Attention也称为Luong Attention。Luong Attention基本思\\n想跟Bahdanau Attention差不多，不过总的来说要比 Bahdanau Attention更复杂一些，\\n同时也考虑得更加全面。Luong Attention的计算流程图如图14.29：\\n图14.29 Luong Attention\\n我们来看看Luong Attention的计算，Encoder也是计算得到所有序列的State。\\nDecoder部分的 RNN 也是用Encoder最后输出的State 信号ℎ 进行State 初始化，然后传\\n$\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 533, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 534\\n入<start>句子起始符，得到State 信号ℎR。接下来计算上下文向量𝐶 ，𝐶 是使用Encoder\\n< < <\\n所有序列的State 和Decoder的State 信号ℎR一起计算出来的，具体的怎么算等下再说。得\\n<\\n后与ℎR进行拼接（concatenate），ℎ(cid:242)R的计算公式为：\\n到𝐶\\n< < <\\n(cid:243)\\nℎ′ = 𝑡𝑎𝑛ℎ (𝑊 [𝐶 ;ℎ′ ]) (14.7)\\n0 (cid:211) < 0\\n其中[𝐶 ;ℎR]表示𝐶 与ℎR进行拼接（concatenate），𝑊为权值矩阵会跟着模型一起训\\n< < < < (cid:211)\\n练，tanh为激活函数。最后输出𝑦R的计算公式为：\\n<\\n(cid:243)\\n𝑦′ = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 (𝑊ℎ′ ) (14.8)\\n0 (cid:222) 0\\n其中𝑊为权值矩阵会跟着模型一起训练，softmax为激活函数。假如预测得到结果\\n(cid:222)\\n“deep”，在进行下一个序列的计算时会把“deep”对应的词向量和ℎ(cid:242)R一起作为输入传入\\n<\\nRNN 中。后面的计算以此类推，直到得到句子结束符<end>。\\n下面我们来看一下 Luong Attention的上下文向量C怎么计算，C的计算公式跟\\nBahdanau Attention一样为公式14.5，不过Luong Attention中Attention权重𝛼的计算\\n方式不同。Luong Attention论文中给出了三种计算 Attention权重𝛼的方法：\\n第一种称为“dot”，也就是dot product点乘的意思，公式为14.9：\\n(ℎ⊺ℎı\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 ) (14.9)\\nˆ (cid:222)\\nstate“，所以ℎı\\nLuong Attention论文中把Encoder中的State 称为“source 表示所\\n(cid:222)\\n有Encoder的State。Decoder中的State 称为”target state“，所以ℎ 为Decoder 中的\\nˆ\\nState，ℎ⊺表示ℎ 转置的意思。举个例子吧，假设Decoder和Encoder的State 都是输出 4\\nˆ ˆ\\n个值，Encoder总共有2 个序列，如图14.30：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 534, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 535\\n图14.30 dot\\n使用“dot”方式计算Attention权重𝛼是最简单的了，并且计算过程中没有额外的权重\\n需要训练。\\n第二种方式称为“general”，公式为：\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 (ℎ⊺𝑊 ℎı ) (14.10)\\nˆ (cid:240) (cid:222)\\n“general”方式跟“dot”方式其实差不多，只是在计算dot product时加入一个可以\\n训练的权值矩阵。\\n第三种方式称为“concat”，公式为：\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 (𝑣⊺𝑡𝑎𝑛ℎ(𝑊 [ℎ ;ℎı ])) (14.11)\\n(cid:240) (cid:240) ˆ (cid:222)\\n第三种方式其实跟Bahdanau Attention计算Attention权重𝛼的公式是一样的。\\n最后我们再简单说一下Luong Attention论文中提到的“Global attentional model”\\n和“Local attention model”。作者对 Attention的细节做了更多的考虑，“Global\\nattentional model”指的是在计算Attention权重𝛼时，考虑Encoder中所有序列的\\nState，如图14.31：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 535, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 536\\n图14.31 Global attentional model[10]\\n图中的Attention Layer 表示注意力层；Context vector表示上下文向量；Global align\\nweights表示全局权重。\\n“Local attention model“指的是在计算 Attention 权重𝛼时，只考虑Encoder中部分\\n序列的State，如图14.32：\\n图14.32 Local attention model[10]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 536, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 537\\n图中的Attention Layer 表示注意力层；Context vector表示上下文向量；Local\\nweights表示局部权重；Aligned position 表示对齐位置。\\n我觉得这一部分已经不是Attention最核心的内容了，所以就不展开介绍了，大家有兴\\n趣可以自行阅读论文中的说明。\\n14.7.4 谷歌机器翻译系统 GNMT 介绍\\n2006 年是谷歌翻译推出的年份，10 年后的2016 年谷歌发布了基于深度学习机器翻译系\\n统GNMT(Google's Neural Machine Translation )。谷歌称GNMT 与之前采用的基于短语\\n的机器翻译算法(PBMT)相比，翻译误差降低了55%-85%，并且多种语言互译已经接近人类\\n水平，比如英法互译，英语西班牙语互译，我们最关心的中英互译跟人类还是有些差距，不\\n过也已经提高了很多。而GNMT 所使用的模型正是Seq2Seq with Attention，最早提出\\nGNMT 的论文是《Google's Neural Machine Translation System: Bridging the Gap\\nbetween Human and Machine Translation》[11]。\\n下面我们简单介绍一下GNMT 的内容，GNMT 中使用的是8 层的LSTM-Encoder，8\\n层的LSTM-Decoder，并且Encoder的第一层是双向LSTM，如图14.33：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 537, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 538\\n图14.33 GNMT 结构[11]\\n图中的GPU1-GPU8 表示使用多个GPU加速训练，Encoder的第一层如图14.34：\\n图14.34 双向LSTM[11]\\n大家仔细观察一下GNMT 的结构还会发现，在多层LSTM 结构中竟然还加上了类似\\nResNet的残差设计，如图14.35：\\n图14.35 残差设计[11]\\n深度学习在计算机视觉，自然语言处理和语音等方面的应用很多地方是相通的，所以可\\n以互相学习和借鉴。\\nGNMT 还有更多的细节内容，如为了加快翻译速度，在模型计算过程中使用低精度计算\\n（模型中部分参数使用8bit计算）。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 538, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 539\\n为了减少词汇数量，使用WordPiece 技术，就是把一些词拆成一片一片，比如\\n“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，“saving”，\\n“saved”，“saves”都是保存的意思，是不是有点重复？使用WordPiece拆分后会得到\\n“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很\\n多。\\n其他细节内容大家有兴趣可以再进一步研究。\\n14.7.5 Attention 机制在视觉和语音领域的应用\\nAttention机制虽然一般是应用在NLP领域，不过在计算机视觉和语音领域也有着不少\\n应用。2015 年的一篇论文《Show, Attend and Tell: Neural Image Caption Generation\\nwith Visual Attention》[12]展示了Attention机制在图像标题生成应用中效果，如图\\n14.36：\\n图14.36 Image Caption Generation with Visual Attention[12]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 539, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 540\\n图片下面的句子为深度学习网络生成的图片标题，标题中带有下划线的单词所 Attention\\n的区域为图片中白色的部分。比如“dog”所Attention的区域就是图片中的狗头，\\n“stop”所Attention的区域为图片中的stop指示牌，“trees”所Attention的区域为除\\n了长颈鹿以外的背景区域。\\n2015 年的一篇论文《Listen, Attend and Spell》[13]展示了Attention在语音识别领域\\n的应用效果，如图14.37：\\n图14.37 Speech Recognition with Attention[13]\\n图中的Audio 表示语音；Hypothesis 表示预测结果；Time 表示时间。\\n图中我们可以看到语音识别的结果与原始语音片段之间的关系，语音识别结果的每个词\\n都会Attention原始语音片段的某些特定区域。\\nAttention作为一种思想可以应用于各种领域中，大家在研究一些新的问题时也可以考虑\\n加入Attention机制，说不定会得到意想不到的效果。\\n14.8 参考文献\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 540, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 541\\n[1] 吴军.数学之美[M].北京:人民邮电出版社\\n[2] Kandola E J , Hofmann T , Poggio T , et al. A Neural Probabilistic Language\\nModel[J]. Studies in Fuzziness & Soft Computing, 2006, 194:137-186.\\n[3] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations\\nin vector space[J]. arXiv preprint arXiv:1301.3781, 2013.\\n[4] Rong X. word2vec parameter learning explained[J]. arXiv preprint\\narXiv:1411.2738, 2014.\\n[5] Morin F, Bengio Y. Hierarchical probabilistic neural network language\\nmodel[C]//Aistats. 2005, 5: 246-252.\\n[6] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and\\nphrases and their compositionality[C]//Advances in neural information processing\\nsystems. 2013: 3111-3119.\\n[7] Zhang Y, Wallace B. A sensitivity analysis of (and practitioners' guide to)\\nconvolutional neural networks for sentence classification[J]. arXiv preprint\\narXiv:1510.03820, 2015.\\n[8] Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural\\nnetworks[C]//Advances in neural information processing systems. 2014: 3104-3112.\\n[9] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to\\nalign and translate[J]. arXiv preprint arXiv:1409.0473, 2014.\\n[10] Luong M T, Pham H, Manning C D. Effective approaches to attention-based\\nneural machine translation[J]. arXiv preprint arXiv:1508.04025, 2015.\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 541, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 542\\n[11] Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system:\\nBridging the gap between human and machine translation[J]. arXiv preprint\\narXiv:1609.08144, 2016.\\n[12] Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation\\nwith visual attention[C]//International conference on machine learning. 2015: 2048-\\n2057.\\n[13] Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint\\narXiv:1508.01211, 2015.\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 542, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 543\\n第 15 章-自然语言处理 NLP 发展历程\\n（下）\\n15.1 NLP 新的开始-Transformer 模型[1]\\nTransformer 可能很多人都知道，就是“变形金刚”嘛，电影我们都看过，下面我们要\\n了解的内容正是NLP领域的“变形金刚”-Transformer模型。为什么说Transformer是\\nNLP新的开始？因为Transformer 模型的出现给混乱的NLP领域发展指引了新的方向。\\nNLP领域在2015-2017 年左右这段时间发展有些混乱，因为传统的基于统计的NLP模型还\\n有着很多应用，而基于深度学习的CNN，RNN等模型也展现出了不错的效果，未来应该往\\n哪个方向发展，大家都说不准。这时谷歌 2017 年的一篇论文给我们指引了新的方向，论文\\n很直接，标题直接告诉了我们答案：《Attention is all you need》[2]。没错，NLP新的发\\n展方向既不是CNN 也不是RNN，而是Attention。Transformer 模型的重要性不在于它刷\\n新了多少项NLP的记录，而在于它提出了一个新的建模方式，为后续的很多“刷榜”模型提\\n供了基础。\\n15.1.1 Transformer 模型结构和输入数据介绍\\n下面我们使用机器翻译的例子来讲解 Transformer。Transformer的基本框架用的也是\\nSeq2Seq 模型，注意这里的Seq2Seq， 里面没有用到RNN，原始的Transformer 用的是\\n6 层的编码器（Encoder）和6 层的解码器（Decoder），如图15.1 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 543, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 544\\n图15.1 Transformer 的Seq2Seq 结构\\n图中的6 个 Encoder是相同的结构，6 个Decoder也是相同的结构，但Encoder和\\nDecoder的结构有些不同。每个 Encoder中有两个结构，每个Decoder中有三个结构，如\\n图15.2 所示。\\n图15.2 Encoder 和Decoder内部结构\\nTransformer 中最核心的结构应该就是 Self-Attention，Self-Attention具体是什么后\\n面再说。Feed Forward 其实就是两个全连接层，并且不会改变数据维度，这里我们就不多\\n做介绍了。每个Encoder和Decoder中都有一个Self-Attention结构和Feed Forward 结\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 544, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 545\\n构。在Decoder中间还有一个Encoder-Decoder-Attention层，Encoder部分最后输出的\\nAttention信息会传给这个层，告诉Decoder要重点关注输入序列的哪些内容。\\nTransformer 的Encoder最开始的输入为每个词的编号，经过一个Embedding层得到\\n单词的词向量，词向量长度为512。Embedding层的权值矩阵会随机初始化然后跟着模型\\n一起训练，为了画图方便，下面图中的词向量长度为 4（我们把它想象成长度为512 就可以\\n了），如图15.3 所示。\\n图15.3 Encoder词向量输入\\n图中的𝑥 - 𝑥 为序列输入，注意Transformer 的Encoder 中没有使用RNN，所以序列输\\n\" #\\n入不需要每次传入一个值，而是可以一次性传入所有词的词向量。不过一次性传入所有词的\\n词向量会丢失每个词的位置信息，所以除了词向量 Embedding以外，输入信息中还会加上\\n一个表示每个词位置的信息Positional Encoding，所以实际的Encoder输入是词向量\\nEmbedding加上位置信息Positional Encoding，如图15.4 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 545, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 546\\n图15.4 Encoder输入\\n图中INPUT 表示输入；POSITIONAL ENCODING表示位置信息；EMBEDDING WITH\\nTIME SIGNAL 表示包含时序信息的信号。\\nPositional Encoding可以通过固定公式计算出来，也可以通过一个神经网络训练出来，\\n并且效果相差不大。论文中使用的是固定公式计算，其实固定公式也有很多种，论文中使用\\n的固定公式为\\n𝑝𝑜𝑠\\n𝑃𝐸 = 𝑠𝑖𝑛(cid:139) (cid:140) (15.1)\\n((cid:154)(cid:210)(cid:222),#() #(\\n10000æ\\n(cid:246)(cid:247)łøœ\\n𝑝𝑜𝑠\\n𝑃𝐸 = 𝑐𝑜𝑠(cid:139) (cid:140) (15.2)\\n((cid:154)(cid:210)(cid:222),#((cid:151)\") #(\\n10000æ\\n(cid:246)(cid:247)łøœ\\n公式中PE为Positional Encoding得到的值，跟词向量长度一样。pos表示当前词在句\\n子中的位置，𝑑 为词向量长度512，𝑃𝐸 表示偶数维度的计算公式，𝑃𝐸 表示\\n(cid:130)(cid:210)æ⁄(cid:132) ((cid:154)(cid:210)(cid:222),#() ((cid:154)(cid:210)(cid:222),#((cid:151)\")\\n奇数维度的计算公式。词向量长度为512，句子长度为50，PE的值如图15.5 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 546, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 547\\n图15.5 Positional Encoding\\n横坐标为512 个维度的值，纵坐标为句子的50 个词，这个图看起来有点玄学的感觉。\\n其实这里的核心在于句子中每个词的Positional Encoding不同就可以，所以可以有多种方\\n式计算Positional Encoding的数值。\\n词向量Embedding和Positional Encoding相加以后传入第一个Encoder的Self-\\nAttention，如图15.6 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 547, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 548\\n图 15.6 输入Encoder\\n15.1.2 Self-Attention 介绍\\nSelf-Attention是Transformer 模型中所使用的Attention，基本思想跟我们之前介绍\\n过的Attention差不多。不过Self-Attention主要是计算一个句子中一个词与其他词之间的\\nAttention，所以名字中有个“Self”。比如我们看下面这个例子：\\nThe animal didn't cross the street because it was too tired.\\n句子中的“it”指的是“animal”还是“street”，我们很容易判断，不过机器是比较难判\\n断的。使用Self-Attention可以让机器把“it”和“animal”联系起来，如图15.7 所示。\\n图15.7 Self-Attention\\n下面我们来看一下Self-Attention的具体计算：\\n第一步——在Self-Attention的计算中会引入 3 个新的向量，分别是Query，Key，\\nValue。这3 个向量是Self-Attention的输入向量x分别乘以3 个不同的权值矩阵\\nWQ,WK,WV而得到的。权值矩阵是随机初始化的，维度是（64，512），其中512 需要与\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 548, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 549\\nSelf-Attention输入向量维度一致，其实64 和512 都是人为设置的，理论上都可以修改。\\nQuery，Key，Value 的计算如图15.8 所示。\\n图15.8 Self-Attention计算1\\n第二步——计算 Self-Attention 的分数值，每个词都会与句子中的所有词计算一个分数\\n值，这个分数值表示该词与句子中所有词之间的关注度。计算方法是该词的 Query 与每个词\\n的Key做点乘，比如针对例子中“deep”这个词，计算出该词与句子中所有词的分数，假设\\n计算q1·k1 得到112，假设计算q1·k2 得到96，如图15.9 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 549, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 550\\n图15.9 Self-Attention计算2\\n第三步——把前面计算的Score 除以g𝑑 ，这里的𝑑 为Query，Key，Value 的权值矩\\n(cid:131) (cid:131)\\n阵的行数，论文中为64。g𝑑 就是8，Score 除以8 主要是为了模型训练时得到比较稳定的\\n(cid:131)\\n梯度，理论上取其他值也可以。然后再进行 softmax计算，得到当前的词与其他所有词的相\\n关性大小，如图15.10 所示。\\n图15.10 Self-Attention计算3\\n第四步——把Value 的值与Softmax的结果进行相乘，然后再相加，比如z1=v1×\\n0.88+v2×0.12，如图15.11 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 550, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 551\\n图15.11 Self-Attention计算4\\n每个词都可以计算出一个z值，z值相当于是每个词的Self-Attention特征。以上就是\\nSelf-Attention层的主要计算内容了。\\n在实际应用的时候，一般都是以矩阵的形式来进行计算的，输入 Self-Attention层的数\\n据也是一个矩阵，如图15.12 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 551, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 552\\n图15.12 矩阵形式的 Self-Attention计算1\\n图中的X 中的行数表示输入词汇数量，2 行表示2 个词；X 中的列数表示词向量长度，\\n实际应用中为512。W中的行数为词向量长度，实际应用中为512；W中的列数实际应用中\\n为64。接下来再进行如前面描述的Self-Attention计算，如图15.13 所示。\\n图15.13 矩阵形式的 Self-Attention计算2\\n15.1.3 Multi-Head Attention 介绍\\n作者为了增强Self-Attention的表达效果，使用了“Multi-Head Attention”，中文就\\n是“多头注意力机制”，虽然名字有点奇怪，但是作用很大。这个“多头注意力机制”理解\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 552, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 553\\n起来很容易，上一小节我们介绍了Self-Attention的计算流程，我们所介绍的Self-\\nAttention计算就是一个头（Head）。那我们初始化多个Query，Key，Value 权值矩阵，\\n进行多次独立地计算，就是“多头注意力机制”了。“多头注意力机制”的主要作用是给模\\n型引入更多的训练参数，可以使得不同的“头”起到不同的 Self-Attention的表达效果。我\\n觉得有点像在图像识别中，卷积网络使用多个滤波器，提取图像不同的特征。“Multi-Head\\nAttention”计算如图15.14 所示。\\n图15.14 Multi-Head Attention计算1\\n论文中作者用了8 个Attention Head，那么每个词就可以计算得到8 组Z 值了，从𝑍 −\\n<\\n𝑍 ，如图15.15 所示。\\n(cid:236)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 553, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 554\\n图15.15 Multi-Head Attention计算2\\n得到8 组Z 值以后进行拼接（concatenate），然后还需要再乘以一个权值矩阵𝑊(cid:252)，得\\n到Self-Attention层的最终输出Z，如图15.16 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 554, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 555\\n图15.16 Multi-Head Attention计算3\\n注意Self-Attention层的最终输出的行数等于句子的词汇数，比如“Thinking\\nMachines”就 2 个词所以Z 只有2 行，Z 的列数等于最开始时的词向量长度512。\\n总结一下，“Multi-Head Attention”的整个流程如图15.17 所示。\\n图15.17 Multi-Head Attention计算全流程\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 555, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 556\\n使用了Multi-Head Attention”以后，我们可以看到不同的两个Attention Head 会关\\n注句子中不同的部位，如图15.18 所示。\\n图15.18 两个 Attention Head 关注点不同\\n对于“it”这个词，一个头主要关注“tired”这个词，另一个头主要关注“The\\nanimal”。如果是8 个头的话可能会得到下面结果，如图 15.19 所示。\\n图15.19 8 个Attention Head\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 556, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 557\\n15.1.4 Layer Normalization 介绍\\n在Transformer 中，每一个子层（Self-Attention，Feed forward）之后都会加上残差\\n模块和Layer Normmalization[3]，如图15.20 所示。\\n图15.20 残差结构和Layer Normmalization\\n残差结构应该不需要多说了，跟ResNet中差不多，这里的残差结构是一个恒等映射。\\n如图X+Z 的结果会进行Layer Normmalization。Layer Normmalization 看名字就知道跟\\nBatch Normmalization 应该是差不多的。Batch Normalization 是计算一个批次中，每个\\n特征维度的平均值和标准差，然后再对每个特征维度进行标准化计算，如图 15.21 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 557, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 558\\n图15.21 Batch Normalization\\nLayer Normmalization 是计算一个数据中，所有特征维度的平均值和标准差，然后再对\\n这个数据进行标准化计算，如图15.22 所示。\\n图15.22 Layer Normmalization\\nBatch Normalization 和Layer Normmalization 都可以起到数据标准化的效果，不同\\n的场景下可能会得到不同的效果。在Transformer 的模型中使用Layer Normmalization 效\\n果会更好。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 558, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 559\\n15.1.5 Decoder 结构介绍\\nTransformer 叠加了6 个相同结构的Encoder，Encoder最后的输出结果会传给所有\\nDecoder中的 Encoder-Decoder Attention层进行计算，如图15.23 所示。\\n图15.23 Encoder-Decoder\\n我们也可以看一下《Attention is all you need》论文中的结构图，不过论文中的结构只\\n画出来一个Encoder和一个Decoder（实际上Encoder和Decoder都各有6 个），如图\\n15.24 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 559, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 560\\n图15.24 Transformer结构[2]\\n图中Inputs表示输入；Output表示输出；Positional Encoding表示位置信息；\\nOutput Probabilities 表示输出概率；Linear 表示全连接层。\\n我们可以看到在Decoder中有两个Multi-Head Attention，这两个Multi-Head\\nAttention跟Encoder中的Multi-Head Attention差不多，具体一些细节上的不同后面详\\n细说明。\\nDecoder阶段的最后 Softmax层计算下一个输出单词的概率。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 560, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 561\\n15.1.6 Decoder 中的 Multi-Head Attention 和模型训练\\n下面我们来仔细分析一下Decoder中的Multi-Head Attention，先说一下第一个\\nMulti-Head Attention。第一个Multi-Head Attention采用了Mask操作，因为在翻译的\\n时候，我们是先翻译第一个词，然后翻译第二个词，再翻译第三个词。在 Decoder的时候，\\n需要根据之前的翻译结果来预测当前的最佳输出。\\n这里的Mask 指的是在模型训练时遮挡住一部分的信息，当前预测结果可以回顾之前的\\n标签信息，但是不能“偷看”之后的标签信息。比如我们有一对训练数据，中文是“我有一\\n只猫”，英文是“I have a cat”。“我有一只猫”的数据会传给Encoder，“<start> I\\nhave a cat”会传给Decoder。Decoder的输出标签为“I have a cat <end>”，如图\\n15.25：\\n图 15.25 Decoder预测\\nMask的作用就是我们在预测“have”的时候，我们可以借鉴”<start>”和“I”的信\\n息，但是不能偷看“have”，“a”和“cat”的信息。我们在预测“a”的时候，可以借鉴\\n“<start>”，“I”和“have”的信息，但是不能偷看“a”和“cat”的信息。具体的做法\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 561, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 562\\n是，假设这里的英文句子有5 个单词，我们会得到一个 5×5 的Mask矩阵，被Mask的部分\\n值为负无穷-inf，没有Mask的部分值为1，如图15.26 所示。\\n图15.26 Mask矩阵\\nSelf-Attention中Query和Key的计算跟Encoder中的一致，使用矩阵的方式计算，\\n如图15.27 所示。\\n图15.27 Decoder-Self-Attention计算1\\n得到𝑄𝐾~之后需要进行softmax计算得到Attention Score，在进行softmax计算之前\\n需要先使用Mask矩阵遮挡住每一个单词之后的信息，如图15.28 所示。\\n图15.28 Decoder-Self-Attention计算2\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 562, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 563\\n得到𝑀𝑎𝑠𝑘 𝑄𝐾~以后再对𝑀𝑎𝑠𝑘 𝑄𝐾~每一行进行softmax计算，计算后每一行的和都为\\n1。之后再与 Value 矩阵相乘，得到Z，如图15.29 所示。\\n图15.29 Decoder-Self-Attention计算3\\n矩阵Z 中第1 行只包含单词1 的信息，第2 行包含单词1 和单词2 的信息，以此类推，\\n第5 行包含所有单词信息。\\n后面的计算跟Encoder中的Multi-Head Attention类似，Multi-Head Attention得到\\n多个Z 矩阵，然后再乘以一个权值矩阵𝑊(cid:252)得到Mask Self-Attention 的输出。\\nDecoder中的第二个 Multi-Head Attention层（也就是Encoder-Decoder Attention\\n层）中，会使用Encoder的最终输出C作为Multi-Head Attention的输入来计算Key和\\nValue 矩阵，而Query矩阵则是使用上一个Multi-Head Attention的输出进行计算。每个\\nDecoder的Encoder-Decoder Attention层都使用Encoder的输出信息C来计算Key和\\nValue 矩阵，有助于Decoder将注意力集中在输入序列中的适当位置。\\n经过6 个叠加的 Decoder计算得到最终输出的 Z 矩阵，因为使用了Mask，所以Z 矩阵\\n的第1 行只包含单词 1 的信息，第2 行包含单词1 和单词2 的信息，以此类推。模型最后\\nsoftmax输出的矩阵每一行会预测一个单词，如图15.30 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 563, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 564\\n图 15.30 softmax输出\\n因为在训练阶段Decoder输入序列的长度是等于标签序列长度的，比如：输入序列为\\n“<start> I have a cat”一共5 个词，标签序列为“I have a cat <end>”也是5 个词。所\\n以Transformer 的训练可以并行计算，在训练阶段 Encoder的一次前向计算就可以获得\\nEncoder信息C，Decoder的一次前向计算就可以获得序列的预测结果，把预测结果跟标签\\n进行对比，计算loss，使用反向传播算法就可以更新模型参数了。\\n在模型预测阶段，label是未知的，Decoder就无法进行并行计算了，只能像普通的\\nSeq2Seq 模型一样，1 次计算得到1 个预测结果。然后再运行一遍Decoder计算，把第1\\n次得到的结果传入，得到第2 个预测结果；再运行一遍 Decoder，传入第1 次和第2 次的结\\n果，得到第3 个预测，一直循环，直到出现结束符。\\n15.2 BERT 模型\\nTransformer 模型是NLP发展历程新的起点，而真正做到大放异彩，取得重大突破的是\\nBERT 模型。2018 年底谷歌新论文《BERT: Pre-training of Deep Bidirectional\\nTransformers for Language Understanding》[4]在11 种不同的NLP测试中获得最佳成\\n绩，并且在机器阅读理解顶级水平测试 SQuAD1.1[5]中超过人类水平。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 564, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 565\\n我们先说一下它的名字，BERT 的全称为 Bidirectional Encoder Representations from\\nTransformers，我怀疑这个名字的全称是BERT 作者强行拼凑的。大家有没有看过一个\\n1969 年美国的喜剧动画芝麻街（Sesame Street），如图15.31 所示。\\n15.31 芝麻街（Sesame Street）\\n我也没看过。在2018 年初AllenNLP发布了一个新模型ELMo，ELMo 是一种比\\nword2vec更好的训练词向量的模型，在BERT 发布之前也小火了一把。由于ELMo 跟\\nTransformer 模型没什么关系，这里我们就不详细介绍了。这里我想说的是 ELMo 是芝麻街\\n这个动画片的人物，图中最左边的。BERT 也是芝麻街的人物，图中从左往右数第三个。所\\n以BERT 名字的真正来源，应该是来自于芝麻街。\\n15.2.1 BERT 模型介绍\\nBERT 模型在结构上几乎没有创新，因为 BERT 模型的结构就是Transformer的\\nEncoder结构，只是具体参数上有些小改动。BERT 真正创新的地方在于模型的训练方法，\\n具体如何训练后面会详细介绍。\\nBERT 论文中训练了两种 BERT 模型，分别是BERT （L=12，H=768，A=12，总共\\n$%&’\\n参数=110M）和BERT （L=24，H=1024，A=16，总共参数=340M）。其中的 L 表示\\n(%)*’\\n模型层数，L=12表示有12 个Encoder层；H 表示词向量长度，H=768表示词向量长度为\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 565, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 566\\n768；A表示Multi-Head Attention中有多少个Head，A=12，表示有12 个Head。一般\\n情况下BERT 模型效果会比BERT 更好一些，BERT 结构如图15.32 所示。\\n(%)*’ $%&’\\n图15.32 两种BERT 模型\\n这些超参数其实都是可以人为设置的，论文作者选用了这两组参数来进行建模，其实也\\n可以使用其他参数。\\n接下来说一下BERT 的输入信号，BERT 输入信号跟Transformer有一点不同。\\nTransformer 输入信号的组成为分词向量（Token Embeddings）和位置向量（Position\\nEmbeddings）；BERT 输入信号的组成为分词向量（Token Embeddings），段落向量\\n（Segment Embeddings）和位置向量（Position Embeddings）。\\n关于分词元素（Token），之前的内容一直都没有特别详细的说明这个问题，这里刚好\\n可以说明一下。token就是分词后的结果，这里的“词”不一定是一个词汇，也有可能是一\\n个字符或其他自定义元素。我们最开始使用的分词方式是，比如英文中使用空格作为分词\\n符，中文中需要一些分词算法，把句子分为一个一个的词汇（word）。在后来的一些研究中\\n发现字符级别（character）的分词方法也能得到同样的效果，有时候效果甚至会更好。比如\\n把“hello world”，分为“h”，“e”，“l”，“l”，“o”，“w”，“o”，“r”，\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 566, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 567\\n“l”，“d”，把“我有一只猫”分为“我”，“有”，“一”，“只”，“猫”。而在\\nBERT 中使用的是 WordPiece[6]，WordPiece技术之前我们有介绍过，就是把一些词拆成一\\n片一片，比如“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，\\n“saving”，“saved”，“saves”都是保存的意思，使用WordPiece拆分后会得到\\n“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很\\n多。所以BERT 中的token指的是使用WordPiece技术分词后得到的分词元素。BERT 输入\\n信号如图15.33 所示。\\n图15.33 BERT 输入信号[4]\\nToken Embeddings 就是每个token对应的向量，BERT 中向量长度为768，\\n$%&’\\nBERT 中向量长度为1024。\\n(%)*’\\nSegment Embeddings 举例说明比较容易理解，BERT 可以传入一个句子或者两个句\\n子，假设传入一个句子，句子可以分为 5 个token，那么Segment Embeddings 就是[0，\\n0，0，0，0]；假设传入两个句子，第一个句子可以分为 4 个token，第二个句子可以分为5\\n个token，那么Segment Embeddings 就是[0，0，0，0，1，1，1，1，1]。所以\\nSegment Embeddings 就是标注哪几个token是第一个句子，哪几个token是第二个句\\n子。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 567, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 568\\nPosition Embeddings 的作用跟Transformer模型一样，表示每个token的位置信\\n息。不过在BERT 模型中的Position Embeddings 使用的是可以训练的参数，不是预先设定\\n好的值。\\n15.2.2 BERT 模型训练\\nBERT 模型的最大创新在于模型训练。作者使用了两个任务来训练，一个任务是掩码语言\\n模型（Masked Language Model），简称MLM，简单的说就是完形填空；另一个任务是\\n预测下一个句子（Next Sentence Prediction），简称NSP，就是字面意思预测下一个句\\n子。\\n我们先来说一下MLM，也就是完形填空。模型训练时会随机 mask 一个句子中15%的\\ntoken（使用“[MASK]”符号替代掉原来的字符），然后将“[MASK]”位置的输出信号传\\n给softmax层预测被遮挡的 token具体是什么。不过这么做可能会有一个问题，就是所有的\\ntoken中有15%被遮挡住了，有可能导致某些token模型从来没见过。所以作者还做了如下\\n细节处理，比如有一个句子“my dog is hairy”，我们要遮挡的词是“hairy”， 那么：\\nl 有80%的概率正常使用“[MASK]”，“my dog is hairy”会变成 my dog is [MASK]”。\\nl 有10%的概率随机取一个词来替代 mask 的词，“my dog is hairy”可能会变成my\\ndog is apple”。\\nl 有10%的概率句子保持不变，“my dog is hairy”可能还是“my dog is hairy”。\\n随机替换发生的概率只有15%×10%=1.5%，所以基本不会影响模型的语言理解能力。\\nMLM 训练如图15.34 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 568, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 569\\n图 15.34 MLM 训练\\n下面我们再来说一下NSP，也就是预测下一个句子。其实很简单，就是模型训练时会传\\n入两个句子，模型要做的就是判断这两个句子是不是连续的两个句子。比如输入“[CLS] the\\nman went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] “，中文是\\n“男人去商店买牛奶”，所以Label=IsNext，这是两个连续的句子。这里的“[CLS]”字符\\n是表示用于预测结果的字符，“[CLS]”位置的输出信号会传给softmax判断这两个句子是\\n不是连续的。“[MASK]”字符前面介绍过了，用作随机遮挡一部分 token。“[SEP]”字符\\n用于表示句子结束，我们可以看到前面的句子中有两个“[SEP]”，第一个“[SEP]”表示第\\n一个句子的结束，第二个“[SEP]”表示第二个句子的结束。这些特殊字符的Token\\nEmbeddings 跟其他的Token Embeddings 一样都会跟着模型参数一起训练。假设有个句\\n子是“[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flightless birds\\n[SEP]“，中文是”男人去商店，企鹅是不会飞的鸟“，所以Label=NotNext，显然第二句\\n话并不是第一句话的下一句。NSP训练如图15.35 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 569, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 570\\n图15.35 NSP训练\\nBERT 模型使用了大量没有人工标注，但是又自带标签的数据来进行训练（MLM 和NSP\\n都可以看成语料本身就已经自带标签）。BERT 论文中使用的训练数据集为BooksCorpus[7]\\n（800M words）和英文的Wikipedia（2500M words），总共33 亿个词。谷歌使用64\\n块TPU训练BERT 花了4 天时间，租用这些TPU训练一次模型的价格大约是30 万人民\\n(%)*’\\n币，所以一般情况下我们就不要想复现模型了，直接使用谷歌发布的预训练模型就可以。\\n15.2.3 BERT 模型应用\\n使用上一小节介绍的方式把BERT 模型训练好之后，就可以使用BERT 来完成各种NLP\\n任务了，BERT 论文中测试的NLP任务大部分都是GLUE(General Language\\nUnderstanding Evaluation)中的任务，GLUE是一个自然语言任务集合。除了GLUE以\\n外，作者也测试了其他一些任务，BERT 论文中涉及的11 个NLP任务如图15.36 所示\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 570, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 571\\n名称 全名 用途\\nmulti-genre natural language inference 判断两个句子是蕴含关系、矛盾关系还是中立关系，\\n(a)MNLI\\n多类型文本蕴含关系识别 3分类\\nquora question pairs\\n(a)QQP 判断两个问题是不是等价，2分类\\n文本匹配\\nquestion natural language inference 判断两个句子（前面句子是一个问题），\\n(a)QNLI\\n自然语言问题推理 后一个句子是否包含前一个句子的答案，2分类\\nthe semantic textual similarity benchmark\\n(a)STS-B 判断两个句子相似性，有5个等级，5分类\\n语义文本相似度数据集\\nmicrosoft research paraphrase corpus\\n(a)MRPC 判断两个文本对语音信息是否等价，2分类\\n微软研究院释义语料库\\nrecognizing textual entailment\\n(a)RTE 类似于MNLI，只不过是2分类\\n识别文本蕴含关系\\nthe situations with adversarial generations dataset\\n(a)SWAG 从四个句子中选择可能是前一句下文的那个，4分类\\n情景对抗生成数据集\\nthe stanford sentiment treebank\\n(b)SST-2 电影评论的情感分类，2分类\\n斯坦福情感分类任务\\nthe corpus of linguistic acceptability\\n(b)CoLA 判断一个句子语法是否正确，2分类\\n语言可接受性语料库\\nthe standFord question answering dataset 传入两个句子，前一个句子是问题，后一个句子是文本段落。\\n(c)SQuAD v1.1\\n斯坦福问答数据集 判断问题的答案在文本段落的哪个部分。\\nthe conference on natural language learning NER命名实体识别，判断一个句子中的单词是不是\\n(d)CoNLL-2003\\n自然语言学习会议 人名，机构名，地名，以及其他所有以名称为标识的实体\\n图15.36 BERT 测试的NLP任务\\nBERT 作者把这 11 个应用分为了(a)，(b)，(c)，(d)四个大类，下面我们逐一来介绍，第\\n一个类别是Sentence Pair Classification Tasks，两个句子的分类任务，如图15.37 所示。\\n图15.37 Sentence Pair Classification Tasks[4]\\n图中的Class Label 表示类别；Sentence Pair Classification Tasks 表示句子对分类任\\n务。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 571, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 572\\n也就是传入两个句子，得到分类结果。对应的任务有MNLI，QQP，QNLI，STS-B，\\nMRPC，RTE，SWAG。我们随便举个例子，比如QQP，就是传入两个句子（这两个句子是\\n两个问题），判断这两个问题是不是等价，属于二分类问题。[CLS]对应的输出加上一个用于\\n分类的全连接层，然后Finetune 整个模型包括最后的全连接层就可以进行训练了。\\n第二个类别是Single Sentence Classification，一个句子的分类任务，如图15.38 所\\n示。\\n图15.38 Single Sentence Classification[4]\\n图中的Class Label 表示类别；Single Sentence Classification Tasks 表示单个句子分\\n类任务。\\n比如情感分类，传入一个句子，判断这个句子是正面情感还是负面情感，属于二分类问\\n题。训练跟第一类差不多，[CLS]对应的输出加上一个用于分类的全连接层，然后 Finetune\\n整个模型包括最后的全连接层就可以进行训练了。\\n第三个类别是Question Answering Tasks，问答任务，如图15.39 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 572, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 573\\n图15.39 Question Answering Tasks[4]\\n图中的Start表示句子的起始；End表示句子的结束；Span表示句子的跨度；Question\\n表示问题；Paragraph表示答案所在段落；Question Answering Tasks 表示问答任务。\\n问答任务，传入两个句子，第一个句子是问题，第二个句子是一段文本，问题的答案在\\n第二个句子中，模型要预测的是答案的位置。有一个权值向量 S 和一个权值向量E用于预测\\n答案的起始位置和结束位置，每个Paragraph中的token对应的输出为TR −TR ，假设标签\\n\" +\\n中i 表示答案的起始，j 表示答案的结束，j≥i。训练阶段最大化i 作为起始位置的概率𝑃 =\\n(\\n⁄-∙.” ⁄/∙.»\\n和j 作为结束位置的概率𝑃 = 。然后Finetune 整个模型包括S 和E就可以进行\\n»⁄-∙.» (cid:129) »⁄-∙.»\\n∑ ∑\\n训练了。预测阶段计算从m 到n 的区间分数：𝑆∙𝑇 +𝐸 ∙𝑇 (𝑛 ≥ 𝑚)，计算得到最大的区间\\n(cid:130) @\\n分数并且n≥m 就是预测的答案区间。\\n第四个类别是Single Sentence Tagging，一个句子的标注任务，如图15.40 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 573, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 574\\n图15.40 Single Sentence Tagging[4]\\n图中Single Sentence 表示单个句子；Single Sentence Tagging Tasks 表示单个句子\\n的标记任务。\\n标注任务，比如我们之前说过的分词标注或者是图中的命名实体识别NER（Named\\nEntity Recognition）。命名实体识别就是判断一个句子中的单词是不是人名，机构名，地\\n名，以及其他所有以名称为标识的实体。模型训练就是传入一个句子，句子的每个token的\\n输出都会经过一个全连接层预测是不是命名实体或者命名实体的类型。然后 Finetune 整个\\n模型包括最后的全连接层就可以进行训练了。\\n很显然BERT 的应用范围不止于此，并且 BERT 也只是一个新的开端。在BERT 模型发布\\n以后，很多类似BERT 的模型不断被推出，不断刷新着NLP任务的新纪录，NLP领域也因此\\n迎来了新一轮的快速发展。\\n15.3 参考文献\\n[1] Alammar, Jay (2018). The Illustrated Transformer [Blog post]. Retrieved\\nfrom https://jalammar.github.io/illustrated-transformer/\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 574, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 575\\n[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in\\nneural information processing systems. 2017: 5998-6008.\\n[3] Ba J L, Kiros J R, Hinton G E. Layer Normalization[J]. arXiv preprint\\narXiv:1607.06450, 2016.\\n[4] Devlin J, Chang M W, Lee K, et al. BERT: Pre-training of Deep Bidirectional\\nTransformers for Language Understanding J]. arXiv preprint arXiv:1810.04805, 2018.\\n[5] Rajpurkar P, Zhang J, Lopyrev K, et al. Squad: 100,000+ questions for\\nMachine Comprehension of Text[J]. arXiv preprint arXiv:1606.05250, 2016.\\n[6] Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system:\\nBridging the gap between human and machine translation[J]. arXiv preprint\\narXiv:1609.08144, 2016.\\n[7] Zhu Y, Kiros R, Zemel R, et al. Aligning Books and Movies: Towards Story-like\\nVisual Explanations by Watching Movies and Reading Books[C]//Proceedings of the\\nIEEE international conference on computer vision. 2015: 19-27.\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 575, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 576\\n第 16 章- NLP 任务项目实战\\n这个章节的内容为14，15 章节NLP内容的项目实战部分。在前两个章节中我们介绍了\\n多种NLP的技术，涉及的内容比较多，所以本章会选取部分内容完成相关项目的代码实战。\\n相关理论介绍主要参考14，15 章的内容，这个章节就不做过多介绍了。\\n16.1 一维卷积英语电影评论情感分类项目\\n16.1.1 项目数据和模型说明\\n在14 章的内容中我们有介绍过卷积在文本分类中的使用，当时介绍的是二维卷积在文本\\n分类中的应用。本章的第一个程序我们先来一个开胃菜，先做一个简单一点的程序，使用一\\n维卷积对英语文本进行情感分类，二维卷积的程序我们留在后面再做。这里说的简单，并不\\n是二维卷积比一维卷积难，其实二维卷积和一维卷积在文本分类中的使用几乎没什么区别。\\n这里说的简单指的是数据处理上的简单，我们要使用的数据集是 IMDB 电影评论数据集，数\\n据分为正面评论和负面评论。这个数据集直接从 Tensorflow 中获得：\\nfrom tensorflow.keras.datasets import imdb\\n我们不需要进行任何数据处理就可以直接载入数据，数据的训练集有 25000 条评论数\\n据，正面评论12500 条，负面评论12500 条。测试集数据也是25000 条数据，正负样本各\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 576, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 577\\n占50%。并且句子已经做好了分词，而且还把每个词都变成了编号（词出现的频率越高，编\\n号越小）。例如，测试集第0 行的数据如图 16.1 所示。\\n图16.1 具体数据展示\\n下面我们再说一下一维卷积在文本分类中的应用，如图 16.2 所示。\\n图16.2 一维卷积在文本分类中的应用[1]\\n我们可以用一个简单的方式来理解一维卷积和二维卷积的区别，二维卷积它的\\nkernel_size 也是两维的，并且可以沿两个方向进行移动（比如水平方向和竖直方向），二维\\n卷积计算时要求输入数据必须是4 维的（数据数量，图片高度，图片宽度，通道数\\nchannels）；一维卷积它的kernel_size 是一维的，并且只能沿一个方向进行移动，一维卷\\n积计算时要求输入数据必须时3 维的（数据数量，序列长度，通道数channels）。在文本分\\n类中，使用一维卷积和二维卷积都可以。\\n如果是使用一维卷积相当于是对一个序列进行特征提取，如上图中假设我们使用一维卷\\n积，词汇数相当于是序列长度，每个词的词向量长度相当于是通道数 channels。我们把\\nkernel_size 设置为3，也就是每次卷积会对图中3 行数据进行卷积计算（图中的列数其实就\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 577, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 578\\n是通道数channels），步长一般设置为1 就可以，每次走一步。卷积计算后得到特征图，接\\n下来再进行max-pooling 计算，最后再进行全连接得到分类结果。\\n16.1.2 一维卷积英语电影评论情感分类程序\\n实现一维卷积英语电影评论情感分类的代码如代码16-1 所示。\\n代码16-1：一维卷积英语电影评论情感分类（片段1）\\nfrom tensorflow.keras.preprocessing import sequence\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Dropout\\nfrom tensorflow.keras.layers import Embedding\\nfrom tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D\\nfrom tensorflow.keras.datasets import imdb\\nfrom plot_model import plot_model\\n# 最大词汇数量\\nmax_words = 10000\\n# 最长句子设置为400\\n# 这里句子长度值的是句子词汇数量，句子有 100 个词则长度为100\\nmaxlen = 400\\n# 批次大小\\nbatch_size = 32\\n# 词向量长度\\nembedding_dims = 128\\n# 训练周期\\nepochs = 3\\n# 滤波器数量\\nfilters = 64\\n# 卷积核大小\\nkernel_size = 3\\n# 载入imdb 评论数据集，设置最大词汇数，只保留出现频率最高的前 max_words个词\\n# 出现频率越高，编号越小。词的编号从 4 开始，也就是频率最大的词编号为4。\\n# 编号0 表示padding，1 表示句子的开始(每个句子第一个编号都是1)，2 表示OOV，3 表\\n示预留(所有的数据中都没有3)\\n# Out-of-vocabulary,简称OOV,表示不在字典中的词\\n# 数据的标签为0 和1。0 表示负面情感，1 表示正面情感。\\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\\n# 查看测试集第0 个句子\\nprint(x_test[0])\\n结果输出为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 578, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 579\\n[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 576\\n0, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 48\\n8, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 1\\n4, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 45\\n1, 202, 14, 6, 717]\\n代码16-1：一维卷积英语电影评论情感分类（片段2）\\n# 获得imdb 数据集的字典，字典的键是英语词汇，值是编号\\n# 注意这个字典的编词汇编号跟数据集中的词汇编号是不对应的\\n# 数据集中的编号减三才能得到这个字典的编号，举个例子：\\n# 比如在x_train 中'a'的编号为6，在word2id中'a'的编号为3\\nword2id = imdb.get_word_index()\\n# 把字典的键值对反过来：键是编号，值是英语词汇\\n# 编号数值范围：0-88587\\n# value+3把字典中词汇的编号跟x_train 和x_test数据中的编号对应起来\\nid2word = dict([(value+3, key) for (key, value) in word2id.items()])\\n# 设置预留字符\\nid2word[3] = '[RESERVE]'\\n# 设置Out-of-vocabulary字符\\nid2word[2] = '[OOV]'\\n# 设置起始字符\\nid2word[1] = '[START]'\\n# 设置填充字符\\nid2word[0] = '[PAD]'\\n# 在词典中查询得到原始英语句子，如果编号不在字典用则用'?'替代\\ndecoded_review = ' '.join([id2word.get(i, '?') for i in x_test[0]])\\nprint(decoded_review)\\n结果输出为：\\n[START] please give this one a miss br br [OOV] [OOV] and the rest of\\nthe cast rendered terrible performances the show is flat flat flat br\\nbr i don't know how michael madison could have allowed this one on hi\\ns plate he almost seemed to know this wasn't going to work out and his\\nperformance was quite [OOV] so all you madison fans give this a miss\\n代码16-1：一维卷积英语电影评论情感分类（片段3）\\n# 序列填充，因为模型结构是固定的而句子的长度是不固定的，所以我们需要把句子变成相\\n同的长度\\n# 如果句子长度不足maxlen，则把句子填充到maxlen 的长度，如果句子长度超过maxlen，\\n则取句子前maxlen 个词\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 579, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 580\\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\\n# 填充后所有句子都变成了400 的长度\\nprint('x_train shape:', x_train.shape)\\nprint('x_test shape:', x_test.shape)\\nprint(x_test[0])\\n结果输出为：\\nx_train shape: (25000, 400)\\nx_test shape: (25000, 400)\\n[ 0 0 0 0 0 0 0 0 0 0 0 0 0 …… 0\\n0 0 0 0 0 0 0 0 0 1 591 202 14 31 6\\n717 10 10 2 2 5 4 360 7 4 177 5760 394 354\\n4 123 9 1035 1035 1035 10 10 13 92 124 89 488 7944 100\\n28 1668 14 31 23 27 7479 29 220 468 8 124 14 286 1\\n70 8 157 46 5 27 239 16 179 2 38. 32 25 7944 451\\n202 14 6 717]\\n代码16-1：一维卷积英语电影评论情感分类（片段4）\\n# 构建模型\\nmodel = Sequential()\\n# Embedding是一个权值矩阵，包含所有词汇的词向量，Embedding的行数等于词汇数，列\\n数等于词向量长度\\n# Embedding的作用是获得每个词对应的词向量，这里的词向量是没有经过预训练的随机\\n值，会跟随模型一起训练\\n# max_words词汇数，embedding_dims词向量长度\\n# 模型训练时数据输入为(batch, maxlen)\\nmodel.add(Embedding(max_words,\\nembedding_dims))\\n# 设置一个一维卷积\\nmodel.add(Conv1D(filters,\\nkernel_size,\\nstrides=1,\\npadding='same',\\nactivation='relu'))\\n# 卷积计算后得到的数据为(batch, maxlen, filters)\\n# GlobalMaxPooling1D-全局最大池化计算每一张特征图的最大值\\n# 池化后得到(batch, filters)\\nmodel.add(GlobalMaxPooling1D())\\n# 加上Dropout\\nmodel.add(Dropout(0.5))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 580, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 581\\n# 最后2 分类，设置2 个神经元\\nmodel.add(Dense(2,activation='softmax'))\\n# 画图\\nplot_model(model)\\n结果输出为：\\n代码16-1：一维卷积英语电影评论情感分类（片段5）\\n# sparse_categorical_crossentropy和 categorical_crossentropy都是交叉熵代价函数\\n# categorical_crossentropy需要把标签变成独热编码 one-hot\\n# sparse_categorical_crossentropy不需要把标签变成独热编码 one-hot(不是真的不需要，\\n而且程序中会自动帮你做转换)\\n# 所以这个程序中的标签没有转独热编码 one-hot\\nmodel.compile(loss='sparse_categorical_crossentropy',\\noptimizer='adam',\\nmetrics=['accuracy'])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 581, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 582\\n# 训练模型\\nmodel.fit(x_train, y_train,\\nbatch_size=batch_size,\\nepochs=epochs,\\nvalidation_data=(x_test, y_test))\\n结果输出为：\\nTrain on 25000 samples, validate on 25000 samples\\nEpoch 1/3\\n25000/25000 [==============================] - 31s 1ms/sample - los\\ns: 0.4680 - accuracy: 0.7660 - val_loss: 0.3246 - val_accuracy: 0.863\\n5\\nEpoch 2/3\\n25000/25000 [==============================] - 31s 1ms/sample - los\\ns: 0.2997 - accuracy: 0.8777 - val_loss: 0.2927 - val_accuracy: 0.876\\n6\\nEpoch 3/3\\n25000/25000 [==============================] - 31s 1ms/sample - los\\ns: 0.2161 - accuracy: 0.9168 - val_loss: 0.2991 - val_accuracy: 0.877\\n2\\n16.2 二维卷积中文微博情感分类项目\\n上一小节我们使用一维卷积完成了英语情感分类项目，不过大家应该更关心中文的情感\\n分类要怎么做。这一小节我们将从头到尾完整地完成一个中文微博情感分类项目。这里我使\\n用的数据集是从新浪微博收集的12万条数据，正负样本各一半。标签中1 表示正面评论，0\\n表示负面评论。数据来源为\\nhttps://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_sen\\nti_100k/intro.ipynb。如果大家有其他数据的话，也可以使用其他数据。\\n这一次我们使用的数据需要自己做处理，所以我们需要对句子进行分词，分词后再对每\\n个词根据频率来进行编号。这里我们要使用的分词工具是结巴分词，结巴分词是一个很好用\\n的中文分词工具，安装方式为打开命令提示符，然后输入命令：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 582, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 583\\npip install jieba\\n安装好以后在python程序中直接 import jieba就可以使用了。\\n实现二维卷积中文微博情感分类的代码如代码 16-2 所示。\\n代码16-2：二维卷积中文微博情感分类（片段1）\\n# 安装结巴分词\\n# pip install jieba\\nimport jieba\\nimport pandas as pd\\nimport numpy as np\\nfrom tensorflow.keras.layers import Dense, Input, Dropout\\nfrom tensorflow.keras.layers import Conv2D, GlobalMaxPool2D, Embedding, concatenate\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nfrom tensorflow.keras.models import Model,load_model\\nfrom tensorflow.keras.backend import expand_dims\\nfrom tensorflow.keras.layers import Lambda\\nimport tensorflow.keras.backend as K\\nfrom sklearn.model_selection import train_test_split\\nimport json\\n# 批次大小\\nbatch_size = 128\\n# 训练周期\\nepochs = 3\\n# 词向量长度\\nembedding_dims = 128\\n# 滤波器数量\\nfilters = 32\\n# 这个数据前半部分都是正样本，后半部分都是负样本\\ndata = pd.read_csv('weibo_senti_100k.csv')\\n# 查看数据前5 行\\ndata.head()\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 583, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 584\\n代码16-2：二维卷积中文微博情感分类（片段2）\\n# 计算正样本数量\\nposlen = sum(data['label']==1)\\n# 计算负样本数量\\nneglen = sum(data['label']==0)\\nprint('正样本数量：', poslen)\\nprint('负样本数量：', neglen)\\n结果输出为：\\n正样本数量： 59993\\n负样本数量： 59995\\n代码16-2：二维卷积中文微博情感分类（片段3）\\n# 测试一下结巴分词的使用\\nprint(list(jieba.cut('做父母一定要有刘墉这样的心态，不断地学习，不断地进步')))\\n结果输出为：\\n['做', '父母', '一定', '要', '有', '刘墉', '这样', '的', '心态', '，', '不\\n断', '地', '学习', '，', '不断', '地', '进步']\\n代码16-2：二维卷积中文微博情感分类（片段4）\\n#定义分词函数，对传入的x进行分词\\ncw = lambda x: list(jieba.cut(x))\\n# apply传入一个函数，把cw 函数应用到data['review']的每一行\\n# 把分词后的结果保存到data['words']中\\ndata['words'] = data['review'].apply(cw)\\n# 再查看数据前5 行\\ndata.head()\\n结果输出为：\\n代码16-2：二维卷积中文微博情感分类（片段5）\\n# 计算一条数据最多有多少个词汇\\nmax_length = max([len(x) for x in data['words']])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 584, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 585\\n# 打印看到结果为202，最长的句子词汇数不算太多\\n# 后面就以202 作为标准，把所有句子的长度都填充到 202 的长度\\n# 比如最长的句子为2000，那么说明有些句子太长了，我们可以设置一个小一点的值作为所\\n有句子的标准长度\\n# 比如设置1000，那么超过1000 的句子只取前面 1000个词，不足1000 的句子填充到\\n1000 的长度\\nprint(max_length)\\n结果输出为：\\n202\\n代码16-2：二维卷积中文微博情感分类（片段6）\\n# 把data[\\'words\\']中所有的list都变成字符串格式\\ntexts = [\\' \\'.join(x) for x in data[\\'words\\']]\\n# 查看一条评论，现在数据变成了字符串格式，并且词与词之间用空格隔开\\n# 这是为了满足下面数据处理对格式的要求，下面要使用 Tokenizer对数据进行处理\\nprint(texts[4])\\n结果输出为：\\n\\'梦想 有 多 大 ， 舞台 就 有 多 大 ! [ 鼓掌 ]\\'\\n代码16-2：二维卷积中文微博情感分类（片段7）\\n# 实例化Tokenizer，设置字典中最大词汇数为30000\\n# Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n\\ntokenizer = Tokenizer(num_words=30000)\\n# 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小，\\ntokenizer.fit_on_texts(texts)\\n# 把词转换为编号，编号大于30000的词会被过滤掉\\nsequences = tokenizer.texts_to_sequences(texts)\\n# 把序列设定为max_length的长度，超过 max_length的部分舍弃，不到max_length则补\\n0\\n# padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充\\nX = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\')\\n# 获取字典\\ndict_text = tokenizer.word_index\\n# 在字典中查询词对应编号\\nprint(dict_text[\\'梦想\\'])\\n结果输出为：\\n581\\n代码16-2：二维卷积中文微博情感分类（片段8）\\n# 把token_config保存到json 文件中，模型预测阶段可以使用\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 585, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 586\\nfile = open('token_config.json','w',encoding='utf-8')\\n# 把tokenizer变成json 数据\\ntoken_config = tokenizer.to_json()\\n# 保存json 数据\\njson.dump(token_config, file)\\nprint(X[4])\\n结果输出为：\\n[ 0 0 0 0 …… 0 0 0 0 0 0 581 18 75\\n77 1 1946 20 18 75 77 19]\\n代码16-2：二维卷积中文微博情感分类（片段9）\\n# 定义标签\\n# 01 为正样本，10 为负样本\\npositive_labels = [[0, 1] for _ in range(poslen)]\\nnegative_labels = [[1, 0] for _ in range(neglen)]\\n# 合并标签\\nY = np.array(positive_labels + negative_labels)\\n# 切分数据集\\nx_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)\\n# 定义函数式模型\\n# 定义模型输入，shape-(batch, 202)\\nsequence_input = Input(shape=(max_length,))\\n# Embedding层，30000表示30000个词，每个词对应的向量为128 维\\nembedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims)\\n# embedded_sequences的shape-(batch, 202, 128)\\nembedded_sequences = embedding_layer(sequence_input)\\n# embedded_sequences的shape 变成了(batch, 202, 128, 1)\\nembedded_sequences = K.expand_dims(embedded_sequences, axis=-1)\\n# 卷积核大小为3,列数必须等于词向量长度\\ncnn1 = Conv2D(filters=filters, kernel_size=(3,embedding_dims), activation='relu')(embedde\\nd_sequences)\\ncnn1 = GlobalMaxPool2D()(cnn1)\\n# 卷积核大小为4,列数必须等于词向量长度\\ncnn2 = Conv2D(filters=filters, kernel_size=(4,embedding_dims), activation='relu')(embedde\\nd_sequences)\\ncnn2 = GlobalMaxPool2D()(cnn2)\\n# 卷积核大小为5,列数必须等于词向量长度\\ncnn3 = Conv2D(filters=filters, kernel_size=(5,embedding_dims), activation='relu')(embedde\\nd_sequences)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 586, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 587\\ncnn3 = GlobalMaxPool2D()(cnn3)\\n# 合并\\nmerge = concatenate([cnn1, cnn2, cnn3], axis=-1)\\n# 全连接层\\nx = Dense(128, activation='relu')(merge)\\n# Dropout层\\nx = Dropout(0.5)(x)\\n# 输出层\\npreds = Dense(2, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(sequence_input, preds)\\nplot_model(model)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 587, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 588\\n代码16-2：二维卷积中文微博情感分类（片段10）\\n# 定义代价函数，优化器\\nmodel.compile(loss='categorical_crossentropy',\\noptimizer='adam',\\nmetrics=['acc'])\\n# 训练模型\\nmodel.fit(x_train, y_train,\\nbatch_size=batch_size,\\nepochs=epochs,\\nvalidation_data=(x_test, y_test))\\n# 保存模型\\nmodel.save('cnn_model.h5')\\n结果输出为：\\nTrain on 95990 samples, validate on 23998 samples\\nEpoch 1/3\\n95990/95990 [==============================] - 30s 318us/sample - lo\\nss: 0.0765 - acc: 0.9705 - val_loss: 0.0434 - val_acc: 0.9814\\nEpoch 2/3\\n95990/95990 [==============================] - 27s 282us/sample - lo\\nss: 0.0415 - acc: 0.9821 - val_loss: 0.0528 - val_acc: 0.9815\\nEpoch 3/3\\n95990/95990 [==============================] - 27s 282us/sample - lo\\nss: 0.0346 - acc: 0.9832 - val_loss: 0.0720 - val_acc: 0.9793\\n我们可以看到最后得到的准确率有点高，一般准确率太低我们需要分析原因，有时候准\\n确非常高我们也需要想一想是为什么。我们来看一下原始数据，如图 16.3 所示。\\n图16.3 微博情感分类数据集\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 588, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 589\\n可以看到原始数据中有大量表情符号，如[爱你]，[哈哈]，[鼓掌]，[可爱]等，这些表情符\\n号中对应的文字从较大程度上代表了这一句话的情感。所以我们做的这个项目之所以得到这\\n么高的准确率，跟这里的表情符号是有很大关系。大家如果使用其他数据集来做情感分类，\\n应该也会得到不错的结果，但是应该很难得到 98%这么高的准确率。\\n模型训练好以后，我们再来看看如何使用训练好的模型进行预测，如代码 16-3 所示。\\n代码16-3：中文情感分类模型预测（片段1）\\nfrom tensorflow.keras.models import load_model\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nfrom tensorflow.keras.preprocessing.text import tokenizer_from_json\\nimport jieba\\nimport numpy as np\\n# 载入tokenizer\\njson_file = open(\\'token_config.json\\',\\'r\\',encoding=\\'utf-8\\')\\ntoken_config = json.load(json_file)\\ntokenizer = tokenizer_from_json(token_config)\\n# 载入模型\\nmodel = load_model(\\'cnn_model.h5\\')\\n# 情感预测\\ndef predict(text):\\n# 对句子分词\\ncw = list(jieba.cut(text))\\n# list转字符串，元素之间用\\' \\'隔开\\ntexts = \\' \\'.join(cw)\\n# 把词转换为编号，编号大于30000的词会被过滤掉\\nsequences = tokenizer.texts_to_sequences([texts])\\n# model.input_shape为(None, 202)，202 为训练模型时的序列长度\\n# 把序列设定为202 的长度，超过202 的部分舍弃，不到202 则补0\\nsequences = pad_sequences(sequences, maxlen=model.input_shape[1], padding=\\'pre\\')\\n# 模型预测\\nresult = np.argmax(model.predict(sequences))\\nif(result==1):\\nprint(\"正面情绪\")\\nelse:\\nprint(\"负面情绪\")\\npredict(\"今天阳光明媚，手痒想打球了。\")\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 589, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 590\\n结果输出为：\\n正面情绪\\n代码16-3：中文情感分类模型预测（片段2）\\npredict(\"一大屋子人，结果清早告停水了，我崩溃到现在[抓狂]\")\\n结果输出为：\\n负面情绪\\n16.3 双向 LSTM 中文微博情感分类项目\\n上一小节我们讲解了CNN 在中文微博情感分类项目中的应用，这一小节我们改用 LSTM\\n来完成，前期数据处理部分都是一样的流程，只有建模部分的程序不同。由于之前是第一次\\n讲解完整流程所以加上了很多说明的步骤，下面这个程序把一些说明的步骤给去掉了，更加\\n精简一些，如代码16-4 所示。\\n代码16-4：双向LSTM 中文微博情感分类（片段1）\\n# 安装结巴分词\\n# pip install jieba\\nimport jieba\\nimport pandas as pd\\nimport numpy as np\\nfrom tensorflow.keras.layers import Dense,Input,Dropout,Embedding,LSTM,Bidirectional\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nfrom tensorflow.keras.models import Model\\nfrom sklearn.model_selection import train_test_split\\nimport json\\n# pip install plot_model\\nfrom plot_model import plot_model\\n# 批次大小\\nbatch_size = 128\\n# 训练周期\\nepochs = 3\\n# 词向量长度\\nembedding_dims = 128\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 590, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 591\\n# cell 数量\\nlstm_cell = 64\\n########step1-数据预处理########\\n# 这个数据前半部分都是正样本，后半部分都是负样本\\ndata = pd.read_csv(\\'weibo_senti_100k.csv\\')\\n# 计算正样本数量\\nposlen = sum(data[\\'label\\']==1)\\n# 计算负样本数量\\nneglen = sum(data[\\'label\\']==0)\\n#定义分词函数，对传入的x进行分词\\ncw = lambda x: list(jieba.cut(x))\\n# apply传入一个函数，把cw 函数应用到data[\\'review\\']的每一行\\n# 把分词后的结果保存到data[\\'words\\']中\\ndata[\\'words\\'] = data[\\'review\\'].apply(cw)\\n# 计算一条数据最多有多少个词汇\\nmax_length = max([len(x) for x in data[\\'words\\']])\\n# 把data[\\'words\\']中所有的list都变成字符串格式\\ntexts = [\\' \\'.join(x) for x in data[\\'words\\']]\\n# 实例化Tokenizer，设置字典中最大词汇数为30000\\n# Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n\\ntokenizer = Tokenizer(num_words=30000)\\n# 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小，\\ntokenizer.fit_on_texts(texts)\\n# 把词转换为编号，编号大于30000的词会被过滤掉\\nsequences = tokenizer.texts_to_sequences(texts)\\n# 把序列设定为max_length的长度，超过 max_length的部分舍弃，不到max_length则补\\n0\\n# padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充\\nX = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\')\\n########step2-保存tokenizer########\\n# 把token_config保存到json 文件中，模型预测阶段可以使用\\nfile = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\')\\n# 把tokenizer变成json 数据\\ntoken_config = tokenizer.to_json()\\n# 保存json 数据\\njson.dump(token_config, file)\\n########step3-定义标签切分数据########\\n# 定义标签\\n# 01 为正样本，10 为负样本\\npositive_labels = [[0, 1] for _ in range(poslen)]\\nnegative_labels = [[1, 0] for _ in range(neglen)]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 591, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 592\\n# 合并标签\\nY = np.array(positive_labels + negative_labels)\\n# 切分数据集\\nx_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)\\n########step4-搭建模型########\\n# 定义函数式模型\\n# 定义模型输入，shape-(batch, 202)\\nsequence_input = Input(shape=(max_length,))\\n# Embedding层，30000表示30000个词，每个词对应的向量为128 维\\nembedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims)\\n# embedded_sequences的shape-(batch, 202, 128)\\nembedded_sequences = embedding_layer(sequence_input)\\n# 双向LSTM\\nx = Bidirectional(LSTM(lstm_cell))(embedded_sequences)\\n# 全连接层\\nx = Dense(128, activation='relu')(x)\\n# Dropout层\\nx = Dropout(0.5)(x)\\n# 输出层\\npreds = Dense(2, activation='softmax')(x)\\n# 定义模型\\nmodel = Model(sequence_input, preds)\\n# 画图\\nplot_model(model)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 592, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 593\\n代码16-4：双向LSTM 中文微博情感分类（片段2）\\n########step5-模型训练和保存########\\n# 定义代价函数，优化器\\nmodel.compile(loss='categorical_crossentropy',\\noptimizer='adam',\\nmetrics=['acc'])\\n# 训练模型\\nmodel.fit(x_train, y_train,\\nbatch_size=batch_size,\\nepochs=epochs,\\nvalidation_data=(x_test, y_test))\\n# 保存模型\\nmodel.save('lstm_model.h5')\\n结果输出为：\\nTrain on 95990 samples, validate on 23998 samples\\nEpoch 1/3\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 593, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 594\\n95990/95990 [==============================] - 39s 410us/sample - lo\\nss: 0.1177 - acc: 0.9642 - val_loss: 0.0710 - val_acc: 0.9821\\nEpoch 2/3\\n95990/95990 [==============================] - 36s 370us/sample - lo\\nss: 0.0602 - acc: 0.9816 - val_loss: 0.0532 - val_acc: 0.9814\\nEpoch 3/3\\n95990/95990 [==============================] - 35s 367us/sample - lo\\nss: 0.0440 - acc: 0.9818 - val_loss: 0.0519 - val_acc: 0.9820\\n双向LSTM 模型最后得到的结果跟 CNN 差不多，都是98%左右的准确率。双向LSTM\\n模型的预测程序跟16-3 完全一样，把模型载入改成载入LSTM 模型即可。\\n16.4 堆叠双向 LSTM 中文分词标注项目\\n16.4.1 中文分词标注模型训练\\n中文分词标注在之前的内容中我们有介绍过，常用的是 4-tag(BMES)标注标签，B 表示\\n词的起始位置，M 表示词的中间位置，E表示词的结束位置，S 表示单字词。分词标注的数\\n据需要对每一个字都进行标注。使用的是微软亚洲研究院开源的数据集\\n（http://sighan.cs.uchicago.edu/bakeoff2005/），我会把数据跟书的代码放在一起给大\\n家下载。实现堆叠双向LSTM 中文分词标注的代码如代码16-5 所示。\\n代码16-5：堆叠双向LSTM 中文分词标注（片段1）\\nimport re\\nimport numpy as np\\nimport pandas as pd\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidir\\nectional\\nfrom tensorflow.keras.models import Model\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 594, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 595\\nfrom sklearn.model_selection import train_test_split\\n# pip install plot_model\\nfrom plot_model import plot_model\\nimport json\\n# 批次大小\\nbatch_size = 256\\n# 训练周期\\nepochs = 30\\n# 词向量长度\\nembedding_dims = 128\\n# cell 数量\\nlstm_cell = 64\\n# 最长的句子设置为128，只保留长度小于 128 的句子，最好不要截断句子\\n# 大部分的句子都是小于128 长度的\\nmax_length=128\\n# 读入数据\\n# {b:begin, m:middle, e:end, s:single}，分别代表每个状态代表的是该字在词语中的位置，\\n# b 代表该字是词语中的起始字，m 代表是词语中的中间字，e 代表是词语中的结束字，s则\\n代表是单字成词\\ntext = open('msr_train.txt').read()\\n# 根据换行符切分数据\\ntext = text.split('\\\\n')\\n# 得到所有的数据和标签\\ndef get_data(s):\\n# 匹配(.)/(.)格式的数据\\ns = re.findall('(.)/(.)', s)\\nif s:\\ns = np.array(s)\\n# 返回数据和标签，0 为数据，1 为标签\\nreturn s[:,0],s[:,1]\\n# 数据\\ndata = []\\n# 标签\\nlabel = []\\n# 循环每个句子\\nfor s in text:\\n# 分离文字和标签\\nd = get_data(s)\\nif d:\\n# 0 为数据\\ndata.append(d[0])\\n# 1 为标签\\nlabel.append(d[1])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 595, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 596\\n# 存入DataFrame\\ndf = pd.DataFrame(index=range(len(data)))\\ndf[\\'data\\'] = data\\ndf[\\'label\\'] = label\\n# 只保留长度小于max_length的句子\\ndf = df[df[\\'data\\'].apply(len) <= max_length]\\n# 把data中所有的list都变成字符串格式\\ntexts = [\\' \\'.join(x) for x in df[\\'data\\']]\\n# 实例化Tokenizer，设置字典中最大词汇数为num_words\\n# Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n\\ntokenizer = Tokenizer()\\n# 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小，\\ntokenizer.fit_on_texts(texts)\\n# 把词转换为编号，编号大于num_words的词会被过滤掉\\nsequences = tokenizer.texts_to_sequences(texts)\\n# 把序列设定为max_length的长度，超过 max_length的部分舍弃，不到max_length则补\\n0\\n# padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充\\nX = pad_sequences(sequences, maxlen=max_length, padding=\\'post\\')\\n# 把token_config保存到json 文件中，模型预测阶段可以使用\\nfile = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\')\\n# 把tokenizer变成json 数据\\ntoken_config = tokenizer.to_json()\\n# 保存json 数据\\njson.dump(token_config, file)\\n# 计算字典中词的数量，由于有填充的词，所有加 1\\n# 中文的单字词数量一般比较少，这个数据集只有 5000多个词\\nnum_words = len(tokenizer.index_word)+1\\n# 相当于是把字符类型的标签变成了数字类型的标签\\ntag = {\\'o\\':0, \\'s\\':1, \\'b\\':2, \\'m\\':3, \\'e\\':4}\\nY = []\\n# 循环原来的标签\\nfor label in df[\\'label\\']:\\ntemp = []\\n# 把sbme 转变成 1234\\ntemp = temp + [tag[l] for l in label]\\ntemp = temp + [0]*(max_length-len(temp))\\nY.append(temp)\\nY = np.array(Y)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 596, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 597\\n# 切分数据集\\nx_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)\\n# 定义模型\\nsequence_input = Input(shape=(max_length))\\n# Embedding层，\\n# mask_zero=True，计算时忽略0 值，也就是填充的数据不参与计算\\nembedding_layer = Embedding(num_words, embedding_dims, mask_zero=True)(sequence\\n_input)\\n# 双向LSTM，因为我们的任务是分词标签，因此需要LSTM每个序列的Hidden State 输出\\n值\\n# return_sequences=True表示返回所有序列LSTM 的输出，默认只返回最后一个序列\\nLSTM的输出\\nx = Bidirectional(LSTM(lstm_cell, return_sequences=True))(embedding_layer)\\n# 堆叠多个双向LSTM\\nx = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x)\\nx = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x)\\n# TimeDistributed该包装器可以把一个层应用到输入的每一个时间步上\\n# 也就是说LSTM每个序列输出的Hidden State 都应该连接一个Dense 层并预测出5 个结\\n果\\n# 这5 个结果分别对应：sbmeo。o 为填充值，对应标签0。\\npreds = TimeDistributed(Dense(5, activation='softmax'))(x)\\n# 定义模型输入输出\\nmodel = Model(inputs=sequence_input, outputs=preds)\\n# 画图\\nplot_model(model)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 597, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 598\\n代码16-5：堆叠双向LSTM 中文分词标注（片段2）\\n# 定义代价函数，优化器\\n# 使用sparse_categorical_crossentropy，标签不需要转变为独热编码one-hot\\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accurac\\ny'])\\n# 训练模型\\nmodel.fit(x_train, y_train,\\nbatch_size=batch_size,\\nepochs=epochs,\\nvalidation_data=(x_test, y_test))\\n# 保存模型\\nmodel.save('lstm_tag.h5')\\n结果输出为：\\nTrain on 68496 samples, validate on 17124 samples\\nEpoch 1/30\\n68496/68496 [==============================] - 35s 514us/sample - lo\\nss: 0.2811 - accuracy: 0.6381 - val_loss: 0.1426 - val_accuracy: 0.85\\n18\\n……\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 598, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 599\\nEpoch 29/30\\n68496/68496 [==============================] - 22s 320us/sample - lo\\nss: 0.0122 - accuracy: 0.9892 - val_loss: 0.0604 - val_accuracy: 0.95\\n78\\nEpoch 30/30\\n68496/68496 [==============================] - 22s 319us/sample - lo\\nss: 0.0114 - accuracy: 0.9900 - val_loss: 0.0629 - val_accuracy: 0.95\\n63\\n最后训练得到的准确率在95%左右。\\n16.4.2 维特比算法（Viterbi Algorithm）\\n这一小节我们要介绍维特比算法（Viterbi Algorithm），因为中文分词标注模型预测阶\\n段需要用到。维特比算法是应用最广泛的动态规划算法之一，主要应用在数字通信，语音识\\n别，机器翻译，分词等领域。\\n就用分词来举例，我们在进行分词的时候，可能会有多种分词结果，把每一种分词结果\\n看成是一条路径，如图16.4 所示。\\n16.4 多种分词路径\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 599, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 600\\n图中的O表示填充标注，B 代表该字是词语中的起始字，M 代表是词语中的中间字，E\\n代表是词语中的结束字，S 则代表是单字成词。如果我们要遍历所有路径找到概率最大的路\\n径（最优路径），计算量是非常大的。\\n维特比算法就是用来解决的最优路径问题的，我没有想到特别简洁又清晰的表达方式把\\n维特比算法给描述清楚，所以我打算直接用一个实际例子来给大家讲解维特比算法的计算流\\n程。这里我使用的是一个真实的分词例子，例子中所有的数值都是真实计算得到的数值。\\n首先我们先说一下状态转移矩阵，我们把 osbme 看成是5 种状态，这5 种状态之间的\\n转移是有一定概率的。比如跟o相关的状态转移（o->s，e->o等）都是不存在的，因为正\\n真分词的时候是不可能出现o这个标注的；再比如 s->m，s->e，b->s，b->b，m->s，\\nm->b，e->m，e->e 这些状态也都是不可能存在的，这不符合我们的标注规则。这些不可\\n能出现的状态转移我们可以把它们的值设置为-inf（负无穷）。那么存在的状态转移s->s，\\ns->b，b->m，b->e，m->m，m->e，e->s，e->b应该要怎么确定状态转移权重呢？最\\n简单的方式是全都设置为1，表示这些合理的状态转移概率都相等。更好一些的方法可以使\\n用二元模型，统计语料库里s->s的概率，s->b 的概率，一直到e->b的概率。还有再更好\\n一些的方法可以使用条件随机场CRF（Conditional Random Field）。状态转移矩阵的计\\n算不属于维特比算法的内容。这里我们就用一个相对简单的方法——二元模型来进行计算\\n（具体操作在后面程序中），得到的状态转移矩阵如图 16.5 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 600, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 601\\n图16.5 状态转移矩阵\\n比如我们要对“深度学习”这4 个字进行分词，那么我们就要把“深”，“度”，\\n“学”，“习”这4 个字对应的词向量传入到模型中，模型的输出结果是“o”，“s”，\\n“b”，“m”，“e”这5 个结果的分类概率（“o”表示用了填充的标注）。如图16.6 所\\n示。\\n图16.6 维特比算法1\\n我们先把这个图看懂，每个字传入模型中，就会得到 5 种标注的预测概率值，图中的T\\n表示状态转移矩阵。每一时刻，我们都根据上一时刻的情况和当前时刻的情况来计算当前每\\n个状态的最佳路径，这句话可能有点难理解，但这是维特比算法的核心内容。\\n假设“度”的标注是“s”，那么路径可能是o->s，s->s，b->s，m->s，e->s。每条\\n路径我们都会计算一个分数（score），我们可以认为分数越高这条路径越好。分数的计算如\\nscore(o->s)=𝑃(cid:210) +𝑇 +𝑃(cid:222)，𝑃(cid:210)为模型输入“深”得到“o”的概率，我的模型计算得到的\\n< (cid:210)(cid:222) \" <\\n值为5.24×10(cid:127)(cid:201)；𝑇 为转移矩阵中o->s的值，为-inf；𝑃(cid:222)为模型输入“度”得到“s”的概\\n(cid:210)(cid:222) \"\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 601, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 602\\n率，我的模型计算得到的值为6.39×10(cid:127)(cid:176)。所以score(o->s)=-inf。同样的方式，我们把\\no->s，s->s，b->s，m->s，e->s所有的分数计算出来，只保留最高的得分\\nscore(e->s)=0.17。\\n“度”的标注还可能是“o”，“b”，“m”，“e”。所以我们还需要分别计算上一时\\n刻的状态到“o”，“b”，“m”，“e”的最佳路径以及路径得分。最后得到的结果如图\\n16.7 所示。\\n图16.7 维特比算法2\\n图中的S 表示路径得分Score。接下来计算从“度”到“学”这一阶段。比如计算\\nscore(e->s)=使用上一时刻的得分𝑆 +状态转移得分𝑇 +这一时刻的得分𝑃(cid:222)。同样根据上一\\n⁄ ⁄(cid:222) #\\n时刻的情况和当前时刻的情况来计算当前每个状态的最佳路径，结果如图 16.8 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 602, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 603\\n图16.8 维特比算法3\\n最后得到的结果如图16.9 所示。\\n图16.9 维特比算法4\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 603, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 604\\n最后阶段得到5 条最佳路径，o->o->o->o，b->e->s->s，b->e->s->b，\\nb->e->b>m，b->e->b->e。最高得分是4.67，所以最后我们选择的分词标注为\\nb->e->b->e，所以分词结果为：\\n['深度', '学习']\\n最后总结一下，路径的分数是由模型预测的概率作为分数再加上转移矩阵的分数得到\\n的。也就是说如果每个序列模型预测的结果非常准确，其实状态转移矩阵的分数也就不太重\\n要了，甚至可以忽略状态转移矩阵的分数；如果每个序列模型预测的结果不够准确，那么状\\n态转移矩阵的分数就比较关键了，甚至可以适当增加状态转移矩阵分数的权重。所以在早期\\n的一些NLP应用中，模型预测的结果准确率不够高，可能需要使用条件随机场CRF 来训练\\n出一个好的状态转移矩阵，这样可以使得标注结果更好。而现在如果我们使用 BERT 模型来\\n预测序列结果，由于BERT 模型预测准确率很高，所以状态转移矩阵就不一定是关键影响因\\n素了。\\n16.4.3 中文分词标注模型预测\\n实现中文分词标注模型预测的代码如代码 16-6 所示。\\n代码16-6：中文分词标注模型预测（片段 1）\\nimport numpy as np\\nimport re\\nfrom tensorflow.keras.models import load_model\\nfrom tensorflow.keras.preprocessing.text import tokenizer_from_json\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nimport json\\n# 句子长度，需要跟模型训练时一致\\nmax_length = 128\\n# 载入tokenizer\\njson_file = open('token_config.json','r',encoding='utf-8')\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 604, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 605\\ntoken_config = json.load(json_file)\\ntokenizer = tokenizer_from_json(token_config)\\n# 获得字典，键为字，值为编号\\nword_index = tokenizer.word_index\\n# 载入模型\\nmodel = load_model('lstm_tag.h5')\\n# 载入数据集做处理主要是为了计算状态转移概率\\n# 读入数据\\ntext = open('msr_train.txt', encoding='gb18030').read()\\n# 根据换行符切分数据\\ntext = text.split('\\\\n')\\n# 得到所有的数据和标签\\ndef get_data(s):\\n# 匹配(.)/(.)格式的数据\\ns = re.findall('(.)/(.)', s)\\nif s:\\ns = np.array(s)\\n# 返回数据和标签，0 为数据，1 为标签\\nreturn s[:,0],s[:,1]\\n# 数据\\ndata = []\\n# 标签\\nlabel = []\\n# 循环每个句子\\nfor s in text:\\n# 分离文字和标签\\nd = get_data(s)\\nif d:\\n# 0 为数据\\ndata.append(d[0])\\n# 1 为标签\\nlabel.append(d[1])\\n# texts 二维数据，一行一个句子\\n# 比如ngrams(texts,2,2)，只计算2-grams\\n# 比如ngrams(texts,2,4)，计算2-grams，3-grams，4-grams\\ndef ngrams(texts, MIN_N, MAX_N):\\n# 定义空字典记录\\nngrams_dict = {}\\n# 循环每一个句子\\nfor tokens in texts:\\n# 计算一个句子token 数量\\nn_tokens = len(tokens)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 605, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 606\\n# 词汇组合统计\\nfor i in range(n_tokens):\\nfor j in range(i+MIN_N, min(n_tokens, i+MAX_N)+1):\\n# 词汇组合list转字符串\\ntemp = ''.join(tokens[i:j])\\n# 字典计数加一\\nngrams_dict[temp] = ngrams_dict.get(temp, 0) + 1\\n# 返回字典\\nreturn ngrams_dict\\n# 统计状态转移次数\\nngrams_dict = ngrams(label,2,2)\\nprint(ngrams_dict)\\n结果输出为：\\n{'sb': 600115, 'be': 1039906, 'es': 659674, 'ss': 427204, 'bm': 21514\\n9, 'me': 215149, 'mm': 211874, 'eb': 594480}\\n代码16-6：中文分词标注模型预测（片段 2）\\n# 计算状态转移总次数\\nsum_num = 0\\nfor value in ngrams_dict.values():\\nsum_num = sum_num + value\\n# 计算状态转移概率\\np_sb = ngrams_dict['sb']/sum_num\\np_be = ngrams_dict['be']/sum_num\\np_es = ngrams_dict['es']/sum_num\\np_ss = ngrams_dict['ss']/sum_num\\np_bm = ngrams_dict['bm']/sum_num\\np_me = ngrams_dict['me']/sum_num\\np_mm = ngrams_dict['mm']/sum_num\\np_eb = ngrams_dict['eb']/sum_num\\n# p_oo 用于表示不可能的转移，-np.inf负无穷\\np_oo = -np.inf\\n# 使用条件随机场CRF来计算转移矩阵有可能效果会更好\\n# 这里我们用简单的二元模型来定义状态转移矩阵\\n# oo,os,ob,om,oe,\\n# so,ss,sb,sm,se\\n# bo,bs,bb,bm,be\\n# mo,ms,mb,mm,me\\n# eo,es,eb,em,ee\\n# 其中sm,se,bs,bb,ms,mb,em,ee 这几个状态转移是不存在的\\n# o 为填充状态，跟o 相关的转移也都不需要考虑\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 606, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 607\\ntransition_params = [[p_oo,p_oo,p_oo,p_oo,p_oo],\\n[p_oo,p_ss,p_sb,p_oo,p_oo],\\n[p_oo,p_oo,p_oo,p_bm,p_be],\\n[p_oo,p_oo,p_oo,p_mm,p_me],\\n[p_oo,p_es,p_eb,p_oo,p_oo]]\\n# 维特比算法\\ndef viterbi_decode(sequence, transition_params):\\n\"\"\"\\nArgs:\\nsequence: 一个[seq_len, num_tags]矩阵\\ntransition_params: 一个[num_tags, num_tags]矩阵\\nReturns:\\nviterbi: 一个[seq_len]序列\\n\"\"\"\\n# 假设状态转移共有num_tags种状态\\n# 创建一个跟sequence相同形状的网格\\nscore = np.zeros_like(sequence)\\n# 创建一个跟sequence相同形状的 path，用于记录路径\\npath = np.zeros_like(sequence, dtype=np.int32)\\n# 起始分数\\nscore[0] = sequence[0]\\nfor t in range(1, sequence.shape[0]):\\n# t-1 时刻score 得分加上trans分数，得到下一时刻所有状态转移\\n[num_tags, num_tags]的得分\\nT = np.expand_dims(score[t - 1], 1) + transition_params\\n# t时刻score = 计算每个状态转移的最大得分 + 下个序列预测得分\\nscore[t] = np.max(T, 0) + sequence[t]\\n# 记录每个状态转移的最大得分所在位置\\npath[t] = np.argmax(T, 0)\\n# score[-1]为最后得到的num_tags种状态得分\\n# np.argmax(score[-1])找到最高分数所在位置\\nviterbi = [np.argmax(score[-1])]\\n# 回头确定来的路径，相当于知道最高分以后从后往前走\\nfor p in reversed(path[1:]):\\nviterbi.append(p[viterbi[-1]])\\n# 反转viterbi 列表，把viterbi 变成正向路径\\nviterbi.reverse()\\n# 计算最大得分，如果需要可以return\\n# viterbi_score = np.max(score[-1])\\nreturn Viterbi\\n# 小句分词函数\\ndef cut(sentence):\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 607, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 608\\n# 如果句子大于最大长度，只取max_length个词\\nif len(sentence) >= max_length:\\nseq = sentence[:max_length]\\n# 如果不足max_length，则填充\\nelse:\\nseq = []\\nfor s in sentence:\\ntry:\\n# 在字典里查询编号\\nseq.append(word_index[s])\\nexcept:\\n# 如果不在字典里填充0\\nseq.append(0)\\nseq = seq + [0]*(max_length-len(sentence))\\n# 获得预测结果，shape(32,5)\\npreds = model.predict([seq])[0]\\n# 维特比算法\\nviterbi = viterbi_decode(preds, transition_params)\\n# 只保留跟句子相同长度的分词标注\\ny = viterbi[:len(sentence)]\\n# 分词\\nwords = []\\nfor i in range(len(sentence)):\\n# 如果标签为s或b，append到结果的 list中\\nif y[i] in [1, 2]:\\nwords.append(sentence[i])\\nelse:\\n# 如果标签为m 或e，在list最后一个元素中追加内容\\nwords[-1] += sentence[i]\\nreturn words\\n# 根据符号断句\\ncuts = re.compile(u'([\\\\da-zA-Z ]+)|[。，、？！\\\\.\\\\?,!()（）]')\\n# 先分小句，再对小句分词\\ndef cut_word(s):\\nresult = []\\n# 指针设置为0\\ni = 0\\n# 根据符号断句\\nfor c in cuts.finditer(s):\\n# 对符号前的部分分词\\nresult.extend(cut(s[i:c.start()]))\\n# 加入符号\\nresult.append(s[c.start():c.end()])\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 608, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 609\\n# 移动指针到符号后面\\ni = c.end()\\n# 对最后的部分进行分词\\nresult.extend(cut(s[i:]))\\nreturn result\\nprint(cut_word('针对新冠病毒感染，要做好“早发现、早报告、早隔离、早治疗”，及时给予临\\n床治疗的措施。'))\\n结果输出为：\\n['针对', '新冠', '病毒', '感染', '，', '要', '做好', '“', '早', '发现',\\n'、', '早', '报告', '、', '早', '隔离', '、', '早', '治疗', '”', '，', '及\\n时', '给予', '临床', '治疗', '的', '措施', '。']\\n代码16-6：中文分词标注模型预测（片段 3）\\nprint(cut_word ('广义相对论是描写物质间引力相互作用的理论'))\\n结果输出为：\\n['广义', '相对论', '是', '描写', '物质', '间', '引力', '相互', '作用', '的\\n', '理论']\\n代码16-6：中文分词标注模型预测（片段 4）\\nprint(cut_word('阿尔法围棋（AlphaGo）是第一个击败人类职业围棋选手、第一个战胜围棋\\n世界冠军的人工智能，是谷歌（Google）旗下DeepMind公司戴密斯·哈萨比斯领衔的团队开\\n发。'))\\n结果输出为：\\n['阿尔法围棋', '（', 'AlphaGo', '）', '是', '第一个', '击败', '人类', '职\\n业', '围棋', '选手', '、', '第一个', '战胜', '围棋', '世界', '冠军', '的',\\n'人工', '智能', '，', '是', '谷歌', '（', 'Google', '）', '旗', '下', 'De\\nepMind', '公司', '戴密斯·哈萨比斯', '领衔', '的', '团队', '开发', '。']\\n经过测试我们看到模型可以得到较好的分词结果，对公司名，人名等这些命名实体也可\\n以得到很好的识别效果。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 609, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 610\\n16.5 最新的一些激活函数介绍\\nNLP实战章节突然又讲到激活函数，大家不要觉得奇怪，肯定是因为下面的NLP实战内\\n容有涉及到新的激活函数的使用。BERT 中使用的激活函数为GELU(Gaussian Error Linear\\nUnit)函数[2]，不再是我们熟悉的ReLU函数。在近年的深度学习技术发展中又诞生了许多新\\n的激活函数，既然要介绍GELU函数，那干脆把一些新的激活函数都一起介绍一下吧。\\n之前我们有介绍过Sign，Sigmoid，Tanh，Softsign，ReLU这些激活函数，这些激活\\n函数中表现最好的自然是ReLU。ReLU的优点是计算简单，可以避免梯度消失。下面要介绍\\n的这些激活函数大部分都跟ReLU有点关系。新的一些激活函数有部分在 Tensorflow 中可\\n以直接调用，有部分在Tensorflow 中没有，需要自行定义，如何自定义激活函数可以参考\\n后面BERT 的源代码。\\n16.5.1 Leaky ReLU\\n带泄露修正线性单元Leaky ReLU[3]算是ReLU函数的一个变种，可以简写为LReLU，\\n公式为：\\n𝑥 𝑖𝑓(𝑥 > 0)\\n𝐿𝑅𝑒𝐿𝑈(𝑥) = 1 (16.1)\\n𝛼𝑥 𝑖𝑓(𝑥 ≤ 0)\\nLReLU的导数公式为：\\n1 𝑖𝑓(𝑥 > 0)\\n𝐿𝑅𝑒𝐿𝑈R(V) = 1 (16.2)\\n𝛼 𝑖𝑓(𝑥 ≤ 0)\\n这里的𝛼是一个人为设置的超参数，一般取值范围是 0.1-0.3。𝛼为0.3 时，Leaky ReLU\\n函数图像如图16.10 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 610, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 611\\n图16.10 Leaky ReLU\\nLeaky ReLU函数的导数图像如图16.11 所示。\\n图16.11 Leaky ReLU函数导数\\n从图中我们就可以看出Leaky ReLU的特点是当x取值为负时，函数也有对应的输出，\\n并且x取值为负时也存在较小的梯度。可以解决ReLU函数中当x取值为负时，函数只能输\\n出0，并且导数也为 0 的问题。其实总的来说ReLU和Leaky ReLU效果差不多，只不过有\\n些时候使用Leaky ReLU可以得到更好的效果。\\n16.5.2 ELU\\n指数线性单元ELU(Exponential Linear Unit)[4]也是一个跟ReLU类似的激活函数，公\\n式为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 611, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 612\\n𝑥 𝑖𝑓(𝑥 > 0)\\n𝐸𝐿𝑈(𝑥) = 1 (16.3)\\n𝛼(𝑒V − 1) 𝑖𝑓(𝑥 ≤ 0)\\nELU的导数为公式：\\n1 𝑖𝑓(𝑥 > 0)\\n𝐸𝐿𝑈R(V) = 1 (16.4)\\n𝛼𝑒V 𝑖𝑓(𝑥 ≤ 0)\\n这里的𝛼是一个人为设置的超参数，一般取值范围是 0.1-0.3。𝛼为0.3 时，ELU函数图像\\n如图16.12 所示。\\n图16.12 ELU\\nELU函数的导数图像如图 16.13 所示。\\n图 16.13 ELU函数导数\\n从图中我们就可以看出ELU跟Leaky ReLU挺像的，当x取值为负时，函数也有对应的\\n输出，并且x取值为负时也存在较小的梯度。只不过ELU中有指数计算，x的值越小，梯度\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 612, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 613\\n的值也会越接近于0。一般来说使用ELU作为激活函数，模型的效果可能会比使用ReLU要\\n稍微好一些。\\n16.5.3 SELU\\n扩展指数线性单元SELU(Scaled Exponential Linear Unit)[5]看名字就知道应该是跟\\nELU差不多，SELU的公式为：\\n𝑥 𝑖𝑓(𝑥 > 0)\\n𝑆𝐸𝐿𝑈(𝑥) = 𝜆 × 1 (16.5)\\n𝛼(𝑒V − 1) 𝑖𝑓(𝑥 ≤ 0)\\nSELU的导数为公式：\\n1 𝑖𝑓(𝑥 > 0)\\n𝑆𝐸𝐿𝑈R(V) = 𝜆 × 1 (16.6)\\n𝛼𝑒V 𝑖𝑓(𝑥 ≤ 0)\\n比ELU公式中多了一个𝜆，大家可能会想又多了一个参数，调参岂不是更困难。这个大家\\n可以放心，作者用一篇包含300 多个公式推导的100 页左右的论文告诉我们：\\n𝛼 ≈ 1.6732632423543772848170429916717\\n𝜆 ≈ 1.0507009873554804934193349852946\\n具体的推导过程估计没几个人会去看，大家有兴趣的话可以自行研究。总之得到𝛼和𝜆这\\n两个具体的数值以后，神经网络每一层的激活值都会满足均值接近于 0，标准差接近于1 的\\n正态分布。可以有效的解决梯度消失问题，同时加快模型收敛速度，这跟 Batch\\nNormalization 比较类似。而使用了SELU激活函数的网络也被称为自归一化神经网络\\n(Self-Normalizing Neural Networks)，简称SNN。\\nSNN 模型训练有一个条件，就是必须要对网络的权值进行标准化的权值初始化，比如可\\n以使用 lecun_normal(参考内容来自http://yann.lecun.com/exdb/publis/pdf/lecun-\\n98b.pdf)初始化网络权值，否则可能会训练失败。另外如果网络中需要使用Dropout的话，\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 613, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 614\\n最好使用Alpha Dropout。Alpha Dropout是一种保持信号均值和方差不变的Dropout，\\n该层的作用是即使在Dropout的时候也保持数据的自规范性。\\nSELU函数图像如图16.14 所示。\\n图16.14 SELU\\nSELU函数的导数图像如图16.15 所示。\\n图16.15 SELU函数导数\\nSELU良好的自归一化特性使得它在很多任务中都会比ReLU得到更好的效果。\\n16.5.4 GELU\\n高斯误差线性单元GELU(Gaussian Error Linear Unit)[6]，BERT模型中使用的激活函\\n数就是GELU。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 614, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 615\\nGELU的公式为：\\n𝐺𝐸𝐿𝑈(𝑥) = 𝑥𝑃(𝑋 ≤ 𝑥) = 𝑥Φ(𝑥) (16.7)\\n其中𝑃(𝑋 ≤ 𝑥)表示概率值，Φ(𝑥)指的是 x的正态分布的累积分布函数：\\n(6(cid:127)7)(cid:157)\\nV 𝑒(cid:127) #8(cid:157)\\n𝐺𝐸𝐿𝑈(𝑥) = 𝑥𝑃(𝑋 ≤ 𝑥) = 𝑥5 𝑑𝑋 (16.8)\\n√2𝜋𝜎\\n(cid:127):\\n计算结果可以约等于：\\n2\\n𝐺𝐸𝐿𝑈(𝑥) = 0.5𝑥(cid:139)1 + tanh(cid:138)o (𝑥 + 0.044715𝑥$)(cid:141)(cid:140) (16.9)\\n𝜋\\nGELU的导数为公式：\\n𝐺𝐸𝐿𝑈R(V) = 0.5tanh(0.0356774𝑥$ + 0.797885𝑥) +\\n(0.0535161𝑥$ + 0.398942𝑥) ×\\n𝑠𝑒𝑐ℎ#(0.0356774𝑥$ + 0.797885𝑥) + 0.5 (16.10)\\n概率𝑃(𝑋 ≤ 𝑥)中的x表示当前神经元的激活值输入，X 的正态分布的累积分布Φ(𝑥)是随\\n着x的变化而变化的。当神经元激活值输入x增大，Φ(𝑥)也会增大；当x减小，Φ(𝑥)也会减\\n小。如果x很小，Φ(𝑥)的值会接近于0，神经元的输出值会接近于0，相当于神经元被\\nDropout；如果x比较大，Φ(𝑥)的值会接近于1，相当于神经元会保留。\\nGELU的函数图像如图16.16 所示。\\n图16.16 GELU\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 615, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 616\\nGELU函数的导数图像如图16.17 所示。\\n图16.17 GELU函数导数\\nGELU激活函数在很多实验中也表现出了比 ReLU和ELU更好的效果。\\n16.5.5 Swish\\nSwish[7]是由谷歌提出的一个激活函数，谷歌也是做了很多实验证明 Swish 比Relu要更\\n好，甚至比LReLU，ELU，SELU，GELU这些ReLU的变形还要好。当然Swish 真正的效果\\n如何，大家不妨在之后的项目中尝试使用看看，对比一下其他的激活函数就知道了。\\nSwish 的公式为：\\n𝑆𝑤𝑖𝑠ℎ(𝑥) = 𝑥 × 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥) (16.11)\\n这里的𝛽是一个人为设置的参数值，也可以通过模型训练得到。\\nSwish 的导数为公式：\\n𝑆𝑤𝑖𝑠ℎR(𝑥) = 𝛽𝑆𝑤𝑖𝑠ℎ(𝑥) + 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥) ×\\n(cid:142)1 − 𝛽𝑆𝑤𝑖𝑠ℎ(𝑥)(cid:143) (16.12)\\nSwish 的函数图像如图 16.18 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 616, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 617\\n图16.18 Swish\\nSwish 函数的导数图像如图 16.19 所示。\\n图16.19 Swish 函数导数\\n16.6 BERT 模型简单使用\\n16.6.1 安装 tf2-bert 模块并准备预训练模型\\n我参考Github上一个做得比较好的BERT 开源项目bert4kera(参考内容来自\\nhttps://github.com/bojone/bert4keras)，在它的基础上进行了进一步的精简，只留下跟\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 617, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 618\\nBERT 相关的最核心的代码，并把它变成了“全注释代码”，主要是方便大家学习和基本使\\n用。我精简和注释过的项目发布在我的 Github上：https://github.com/Qinbf/tf2_bert。\\nBERT模型的完整实现即便是做了很多的精简，整个程序也还是有 1000 多行的代码。所\\n以在这里我们就不讲解BERT 模型实现的细节了，大家可以到我的 Github上下载程序来进\\n行学习。下面我们主要讲一下如何使用 BERT 来完成NLP相关的一些任务。首先我们需要先\\n安装tf2_bert 模块，安装方式为打开命令提示符运行命令：\\npip install tf2-bert\\n模块安装好以后我们还需要下载预训练模型，可以通过网址\\n（https://github.com/google-research/bert）下载谷歌官方的预训练模型，谷歌提供的\\n预训练模型大部分都是使用英文语料训练出来的。如果大家要使用中文语料训练的 BERT 模\\n型，推荐大家使用哈工大提供的预训练模型，网址为：\\nhttps://github.com/ymcui/Chinese-BERT-wwm。\\n我在哈工大提供的预训练模型中下载了一个简称为“RoBERTa-wwm-ext, Chinese”的\\n模型，下载地址为：\\nhttp://pan.iflytek.com/#/link/98D11FAAF0F0DBCB094EE19CCDBC98BF，密码为\\nXe1p。下载好以后得到一个名为“chinese_roberta_wwm_ext_L-12_H-768_A-12”的文件\\n夹，文件夹中的文件如图16.20 所示。\\n图16.20 模型文件\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 618, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 619\\n其中“bert_config.json”是BERT 模型相关的一些配置文件，“vocab.txt”为BERT 模\\n型训练时用到的词表，剩下的3 个为 Tensorflow 的模型文件。“ckpt”为“checkpoint”\\n的缩写，“ckpt”这种模型保存格式在Tensorflow1.0 中用得比较多，也可以沿用至\\nTensorflow2。\\n16.6.2 使用 BERT 进行文本特征提取\\n准备工作做好以后，下面我们开始进行 BERT 模型的使用，首先我们先用预训练的 BERT\\n模型来进行文本特征提取，如代码16-7 所示。\\n代码16-7：使用 BERT 进行文本特征提取（片段1）\\nfrom tf2_bert.models import build_transformer_model\\nfrom tf2_bert.tokenizers import Tokenizer\\nimport numpy as np\\n# 定义预训练模型路径\\nmodel_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12'\\n# BERT参数\\nconfig_path = model_dir+'/bert_config.json'\\n# 保存模型权值参数的文件\\ncheckpoint_path = model_dir+'/bert_model.ckpt'\\n# 词表\\ndict_path = model_dir+'/vocab.txt'\\n# 建立分词器\\ntokenizer = Tokenizer(dict_path)\\n# 建立模型，加载权重\\nmodel = build_transformer_model(config_path, checkpoint_path)\\n# 句子0\\nsentence0 = '机器学习'\\n# 句子1\\nsentence1 = '深度学习'\\n# 用分词器对句子分词\\ntokens = tokenizer.tokenize(sentence0)\\n# 分词后自动在句子前加上[CLS]，在句子后加上[SEP]\\nprint(tokens)\\n结果输出为：\\n['[CLS]', '机', '器', '学', '习', '[SEP]']\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 619, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 620\\n代码16-7：使用 BERT 进行文本特征提取（片段2）\\n# 编码测试\\ntoken_ids, segment_ids = tokenizer.encode(sentence0)\\n# [CLS]的编号为101，机为3322，器为 1690，学为2110，习为739，[SEP]为102\\nprint('token_ids:',token_ids)\\n# 因为只有一个句子所以segment_ids都是0\\nprint('segment_ids:',segment_ids)\\n结果输出为：\\ntoken_ids: [101, 3322, 1690, 2110, 739, 102]\\nsegment_ids: [0, 0, 0, 0, 0, 0]\\n代码16-7：使用 BERT 进行文本特征提取（片段3）\\n# 编码测试\\ntoken_ids, segment_ids = tokenizer.encode(sentence0,sentence1)\\n# 可以看到两个句子分词后的结果为：\\n# ['[CLS]', '机', '器', '学', '习', '[SEP]', '深', '度', '学', '习', [SEP]]\\nprint('token_ids:',token_ids)\\n# 0 表示第一个句子的token，1 表示第二个句子的token\\nprint('segment_ids:',segment_ids)\\n结果输出为：\\ntoken_ids: [101, 3322, 1690, 2110, 739, 102, 3918, 2428, 2110, 739, 1\\n02]\\nsegment_ids: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\\n代码16-7：使用 BERT 进行文本特征提取（片段4）\\n# 增加一个维度表示批次大小为1\\ntoken_ids = np.expand_dims(token_ids,axis=0)\\n# 增加一个维度表示批次大小为1\\nsegment_ids = np.expand_dims(segment_ids,axis=0)\\n# 传入模型进行预测\\npre = model.predict([token_ids, segment_ids])\\n# 得到的结果中1 表示批次大小，11 表示 11 个token，768 表示特征向量长度\\n# 这里就是把句子的token 转化为了特征向量\\nprint(pre.shape)\\n结果输出为：\\n(1, 11, 768)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 620, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 621\\n16.6.3 使用 BERT 进行完形填空\\n使用BERT 进行完形填空其实就是使用 BERT 的掩码语言模型MLM 来对包\\n含”[MASK]”符号的句子进行预测，把”[MASK]”符号变成合理的词填入到句子中，如代\\n码16-8 所示。\\n代码16-8：使用 BERT 进行完形填空（片段1）\\nfrom tf2_bert.models import build_transformer_model\\nfrom tf2_bert.tokenizers import Tokenizer\\nimport numpy as np\\n# 定义预训练模型路径\\nmodel_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12'\\n# BERT参数\\nconfig_path = model_dir+'/bert_config.json'\\n# 保存模型权值参数的文件\\ncheckpoint_path = model_dir+'/bert_model.ckpt'\\n# 词表\\ndict_path = model_dir+'/vocab.txt'\\n# 建立分词器\\ntokenizer = Tokenizer(dict_path)\\n# 建立模型，加载权重\\n# with_mlm=True表示使用mlm的功能，模型结构及最后的输出会发生一些变化，可以用来\\n预测被mask的token\\nmodel = build_transformer_model(config_path, checkpoint_path, with_mlm=True)\\n# 分词并转化为编码\\ntoken_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科')\\n# 把“学”字和“习”字变成“[MASK]”符号\\ntoken_ids[3] = token_ids[4] = tokenizer._token_dict['[MASK]']\\n# 增加一个维度表示批次大小为1\\ntoken_ids = np.expand_dims(token_ids,axis=0)\\n# 增加一个维度表示批次大小为1\\nsegment_ids = np.expand_dims(segment_ids,axis=0)\\n# 传入模型进行预测\\npre = model.predict([token_ids, segment_ids])[0]\\n# 我们可以看到第3，4 个位置经过模型预测，[MASK]变成了“学习”\\nprint(tokenizer.decode(pre[3:5].argmax(axis=1)))\\n结果输出为：\\n学习\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 621, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 622\\n代码16-8：使用 BERT 进行完形填空（片段2）\\n# 分词并转化为编码\\ntoken_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科')\\n# 把“交”字和“叉”字变成“[MASK]”符号\\ntoken_ids[8] = token_ids[9] = tokenizer._token_dict['[MASK]']\\n# 增加一个维度表示批次大小为1\\ntoken_ids = np.expand_dims(token_ids,axis=0)\\n# 增加一个维度表示批次大小为1\\nsegment_ids = np.expand_dims(segment_ids,axis=0)\\n# 传入模型进行预测\\npre = model.predict([token_ids, segment_ids])[0]\\n# 我们可以看到第8，9 个位置经过模型预测，[MASK]变成了“什么”，句子变成了一个疑问句\\n# 虽然模型没有预测出原始句子的词汇，不过作为完形填空，填入一个“什么”句子也是正确\\nprint(tokenizer.decode(pre[8:10].argmax(axis=1)))\\n结果输出为：\\n什么\\n16.7 BERT 电商用户多情绪判断项目\\n16.7.1 项目背景介绍\\n之前我们使用的情感分类数据都是网上可以找到的开源数据，并且相对简单。这一小节\\n我们来点更硬核的内容，给大家介绍一个我之前给某化妆品公司做的电商用户多种情绪判断\\n的项目，项目用到的部分标注好的数据我会跟本书的代码一起开放给大家下载，供大家学习\\n和研究使用。项目背景大概就是化妆品公司希望可以通过分析自己用户的评论数据，挖掘影\\n响产品购买的因素，提供产品建议或策略指导，进而提升效率。了解对方需求后，我对用户\\n评论的分析并不只是针对好评还是差评这一个维度来判断，只判断好评差评维度太单一，无\\n法挖掘出更深层次的内容。因此我把用户评论的分析分为了7 个不同维度，分别是总体评\\n论，是否为老用户，是否是参与活动购买，产品质量评价，性价比评价，客户物流包装等服\\n务评价，是否考虑在再次购买，如图16.21：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 622, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 623\\n图16.21 用户评论7 个维度分析\\n每个维度都有3 个分类，在数据的标注中使用 1，0，-1 来标注。具体情况如图16.22\\n所示。\\n图16.22 7 个维度具体标注情况\\n获得用户评论中更多维度的信息以后就可以对用户评论进行更深入的挖掘和更全面的分\\n析。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 623, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 624\\n16.7.2 模型训练\\n实现BERT 电商用户多情绪判断-模型训练的代码如代码 16-9 所示。\\n代码16-9：BERT 电商用户多情绪判断-模型训练（片段1）\\nfrom tf2_bert.models import build_transformer_model\\nfrom tf2_bert.tokenizers import Tokenizer\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.layers import Lambda,Dense,Input,Dropout\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.callbacks import ModelCheckpoint\\nimport numpy as np\\nimport pandas as pd\\nfrom plot_model import plot_model\\n# 周期数\\nepochs = 5\\n# 批次大小\\nbatch_size = 16\\n# 验证集占比\\nvalidation_split = 0.2\\n# 句子长度\\nseq_len = 256\\n# 载入数据\\ndata = pd.read_excel('reviews.xlsx')\\n# 查看数据前5 行\\ndata.head()\\n结果输出为：\\n代码16-9：BERT 电商用户多情绪判断-模型训练（片段2）\\n# 定义预训练模型路径\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 624, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 625\\nmodel_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12'\\n# BERT参数\\nconfig_path = model_dir+'/bert_config.json'\\n# 保存模型权值参数的文件\\ncheckpoint_path = model_dir+'/bert_model.ckpt'\\n# 词表\\ndict_path = model_dir+'/vocab.txt'\\n# 建立分词器\\ntokenizer = Tokenizer(dict_path)\\n# 建立模型，加载权重\\nbert_model = build_transformer_model(config_path, checkpoint_path)\\ntoken_ids = []\\nsegment_ids = []\\n# 循环每个句子\\nfor s in data['评论'].astype(str):\\n# 分词并把token 变成编号\\ntoken_id,segment_id = tokenizer.encode(s, first_length=seq_len)\\ntoken_ids.append(token_id)\\nsegment_ids.append(segment_id)\\ntoken_ids = np.array(token_ids)\\nsegment_ids = np.array(segment_ids)\\nlabel = []\\n# 定义标签\\ndef LabelEncoder(y):\\n# 增加一个维度\\ny = y[:,np.newaxis]\\n# 原始标签把-1,0,1变成0,1,2\\ny = y+1\\ny = y.astype('uint8')\\n# 转成独热编码\\ny = to_categorical(y, num_classes=3)\\nreturn y\\n# 获取7 个维度的标签，并把每个维度的标签从-1,0,1变成0,1,2\\nlabel = [(LabelEncoder(np.array(data[columns]))) for columns in data.columns[1:]]\\nlabel = np.array(label)\\nprint(label.shape)\\n结果输出为：\\n(7, 10000, 3)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 625, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 626\\n代码16-9：BERT 电商用户多情绪判断-模型训练（片段3）\\n# token 输入\\ntoken_in = Input(shape=(None,))\\n# segment输入\\nsegment_in = Input(shape=(None,))\\n# 使用BERT进行特征提取\\nx = bert_model([token_in, segment_in])\\n# 每个序列的第一个字符是句子的分类[CLS],该字符对应的embedding可以用作分类任务中\\n该序列的总表示\\n# 说白了就是用句子第一个字符的embedding来表示整个句子\\n# 取出每个句子的第一个字符对应的embedding\\nx = Lambda(lambda x: x[:, 0])(x)\\n# 多任务学习\\n# 性价比输出层\\nx0 = Dropout(0.5)(x)\\npreds0 = Dense(3, activation='softmax',name='out0')(x0)\\n# 产品质量输出层\\nx1 = Dropout(0.5)(x)\\npreds1 = Dense(3, activation='softmax',name='out1')(x1)\\n# 参加活动输出层\\nx2 = Dropout(0.5)(x)\\npreds2 = Dense(3, activation='softmax',name='out2')(x2)\\n# 客服物流包装输出层\\nx3 = Dropout(0.5)(x)\\npreds3 = Dense(3, activation='softmax',name='out3')(x3)\\n# 是否为老顾客输出层\\nx4 = Dropout(0.5)(x)\\npreds4 = Dense(3, activation='softmax',name='out4')(x4)\\n# 是否会再买输出层\\nx5 = Dropout(0.5)(x)\\npreds5 = Dense(3, activation='softmax',name='out5')(x5)\\n# 总体评论输出层\\nx6 = Dropout(0.5)(x)\\npreds6 = Dense(3, activation='softmax',name='out6')(x6)\\n# 定义模型\\nmodel = Model([token_in, segment_in], [preds0,preds1,preds2,preds3,preds4,preds5,preds\\n6])\\n# 画出模型结构\\nplot_model(model,dpi=200)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 626, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 627\\n代码16-9：BERT 电商用户多情绪判断-模型训练（片段4）\\n# 定义模型训练的loss，loss_weights，optimizer\\n# loss_weights表示每个任务的权重，可以看情况设置\\nmodel.compile(loss={\\n'out0': 'categorical_crossentropy',\\n'out1': 'categorical_crossentropy',\\n'out2': 'categorical_crossentropy',\\n'out3': 'categorical_crossentropy',\\n'out4': 'categorical_crossentropy',\\n'out5': 'categorical_crossentropy',\\n'out6': 'categorical_crossentropy'},\\nloss_weights={\\n'out0': 1.,\\n'out1': 1.,\\n'out2': 1.,\\n'out3': 1.,\\n'out4': 1.,\\n'out5': 1,\\n'out6': 2.},\\noptimizer=Adam(1e-5),\\nmetrics=['accuracy'])\\n# 保存val_loss最低的模型\\ncallbacks = [ModelCheckpoint(filepath='bert_model/'+'{epoch:02d}.h5',\\nmonitor='val_loss',\\nverbose=1,\\nsave_best_only=True)]\\n# 训练模型\\nmodel.fit([token_ids, segment_ids], [label[0],label[1],label[2],label[3],label[4],label[5],label[6]]\\n,\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 627, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 628\\nbatch_size=batch_size,\\nepochs=epochs,\\nvalidation_split=validation_split,\\ncallbacks=callbacks)\\n结果输出为：\\nTrain on 8000 samples, validate on 2000 samples\\nEpoch 1/5\\n7984/8000 [============================>.] - ETA: 0s - loss: 3.4144 -\\nout0_loss: 0.2809 - out1_loss: 0.6564 - out2_loss: 0.2141 - out3_los\\ns: 0.4407 - out4_loss: 0.4736 - out5_loss: 0.2666 - out6_loss: 0.5410\\n- out0_accuracy: 0.9176 - out1_accuracy: 0.7325 - out2_accuracy: 0.9\\n400 - out3_accuracy: 0.8403 - out4_accuracy: 0.8391 - out5_accuracy:\\n0.9163 - out6_accuracy: 0.8111\\n……\\nEpoch 5/5\\n7984/8000 [============================>.] - ETA: 0s - loss: 0.9488 -\\nout0_loss: 0.0636 - out1_loss: 0.2589 - out2_loss: 0.0501 - out3_los\\ns: 0.0752 - out4_loss: 0.1288 - out5_loss: 0.0652 - out6_loss: 0.1535\\n- out0_accuracy: 0.9797 - out1_accuracy: 0.9023 - out2_accuracy: 0.9\\n862 - out3_accuracy: 0.9757 - out4_accuracy: 0.9543 - out5_accuracy:\\n0.9770 - out6_accuracy: 0.9461\\nEpoch 00005: val_loss did not improve from 2.51170\\n8000/8000 [==============================] - 287s 36ms/sample - los\\ns: 0.9486 - out0_loss: 0.0635 - out1_loss: 0.2588 - out2_loss: 0.0500\\n- out3_loss: 0.0751 - out4_loss: 0.1293 - out5_loss: 0.0651 - out6_l\\noss: 0.1534 - out0_accuracy: 0.9797 - out1_accuracy: 0.9022 - out2_ac\\ncuracy: 0.9862 - out3_accuracy: 0.9758 - out4_accuracy: 0.9540 - out5\\n_accuracy: 0.9770 - out6_accuracy: 0.9461 - val_loss: 3.0706 - val_ou\\nt0_loss: 0.1404 - val_out1_loss: 0.5145 - val_out2_loss: 0.2064 - val\\n_out3_loss: 0.1928 - val_out4_loss: 0.3246 - val_out5_loss: 0.2494 -\\nval_out6_loss: 0.7211 - val_out0_accuracy: 0.9580 - val_out1_accurac\\ny: 0.8125 - val_out2_accuracy: 0.9515 - val_out3_accuracy: 0.9450 - v\\nal_out4_accuracy: 0.9015 - val_out5_accuracy: 0.9185 - val_out6_accu\\nracy: 0.8260\\n16.7.3 模型预测\\n实现BERT 电商用户多情绪判断-模型预测的代码如代码 16-10 所示。\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段1）\\nfrom tf2_bert.models import build_transformer_model\\nfrom tf2_bert.tokenizers import Tokenizer\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 628, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 629\\nfrom tensorflow.keras.models import load_model\\nimport numpy as np\\n# 载入模型\\nmodel = load_model('bert_model.h5')\\n# 词表路径\\ndict_path = './chinese_roberta_wwm_ext_L-12_H-768_A-12'+'/vocab.txt'\\n# 建立分词器\\ntokenizer = Tokenizer(dict_path)\\n# 预测函数\\ndef predict(text):\\n# 分词并把token 变成编号，句子长度需要与模型训练时一致\\ntoken_ids, segment_ids = tokenizer.encode(text, first_length=256)\\n# 增加一个维度表示批次大小为1\\ntoken_ids = np.expand_dims(token_ids,axis=0)\\n# 增加一个维度表示批次大小为1\\nsegment_ids = np.expand_dims(segment_ids,axis=0)\\n# 模型预测\\npre = model.predict([token_ids, segment_ids])\\n# 去掉一个没用的维度\\npre = np.array(pre).reshape((7,3))\\n# 获得可能性最大的预测结果\\npre = np.argmax(pre,axis=1)\\ncomment = ''\\nif(pre[0]==0):\\ncomment += '性价比差,'\\nelif(pre[0]==1):\\ncomment += '-,'\\nelif(pre[0]==2):\\ncomment += '性价比好,'\\nif(pre[1]==0):\\ncomment += '质量差,'\\nelif(pre[1]==1):\\ncomment += '-,'\\nelif(pre[1]==2):\\ncomment += '质量好,'\\nif(pre[2]==0):\\ncomment += '希望有活动,'\\nelif(pre[2]==1):\\ncomment += '-,'\\nelif(pre[2]==2):\\ncomment += '参加了活动,'\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 629, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 630\\nif(pre[3]==0):\\ncomment += \\'客服物流包装差,\\'\\nelif(pre[3]==1):\\ncomment += \\'-,\\'\\nelif(pre[3]==2):\\ncomment += \\'客服物流包装好,\\'\\nif(pre[4]==0):\\ncomment += \\'新用户,\\'\\nelif(pre[4]==1):\\ncomment += \\'-,\\'\\nelif(pre[4]==2):\\ncomment += \\'老用户,\\'\\nif(pre[5]==0):\\ncomment += \\'不会再买,\\'\\nelif(pre[5]==1):\\ncomment += \\'-,\\'\\nelif(pre[5]==2):\\ncomment += \\'会继续购买,\\'\\nif(pre[6]==0):\\ncomment += \\'差评\\'\\nelif(pre[6]==1):\\ncomment += \\'中评\\'\\nelif(pre[6]==2):\\ncomment += \\'好评\\'\\nreturn pre,comment\\npre,comment = predict(\"还没用，不知道怎么样\")\\nprint(\\'pre:\\',pre)\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [1 1 1 1 1 1 1]\\ncomment: -,-,-,-,-,-,中评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段2）\\npre,comment = predict(\"质量不错，还会再来，价格优惠\")\\nprint(\\'pre:\\',pre)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 630, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 631\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [2 2 1 1 1 2 2]\\ncomment: 性价比好,质量好,-,-,-,会继续购买,好评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段3）\\npre,comment = predict(\"好用不贵物美价廉，用后皮肤水水的非常不错\")\\nprint(\\'pre:\\',pre)\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [2 2 1 1 1 1 2]\\ncomment: 性价比好,质量好,-,-,-,-,好评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段4）\\npre,comment = predict(\\'一直都用这款产品，便宜又补水，特别好用，今后要一直屯下去。\\')\\nprint(\\'pre:\\',pre)\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [2 2 1 1 2 2 2]\\ncomment: 性价比好,质量好,-,-,老用户,会继续购买,好评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段5）\\npre,comment = predict(\\'趁着搞活动又囤了几盒，很划算，天天用也不心疼，补水效果还可以\\n的\\')\\nprint(\\'pre:\\',pre)\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [2 2 2 1 1 1 2]\\ncomment: 性价比好,质量好,参加了活动,-,-,-,好评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段6）\\npre,comment = predict(\\'我周六买的，星期一才发货，问客服没有回复，不过速度还是快，星\\n期二收到的。发货速度有待改进。\\')\\nprint(\\'pre:\\',pre)\\nprint(\\'comment:\\',comment)\\n结果输出为：\\npre: [1 1 1 0 1 1 0]\\ncomment: -,-,-,客服物流包装差,-,-,差评\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 631, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 632\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段7）\\npre,comment = predict('人生中第一次差评，差评一是给这个产品，用了过敏；二是给这个客\\n服，说过敏仅支持退货并且运费自理。我的天！那我就不退了吧。只能说自己倒霉咯，过敏\\n了没人管，退货还得自掏腰包，最惨不过我')\\nprint('pre:',pre)\\nprint('comment:',comment)\\n结果输出为：\\npre: [1 0 1 0 1 1 0]\\ncomment: -,质量差,-,客服物流包装差,-,-,差评\\n代码16-10：BERT 电商用户多情绪判断-模型预测（片段8）\\npre,comment = predict('自从朋友推荐就一直使用这款面膜，哈哈哈哈，这款面膜一件用了很\\n久了，每次活动买，比较实惠划算，比较适合我自己。唯一感觉不足的就是乳液太少。发货\\n也特别快，值得购买。会在买的。')\\nprint('pre:',pre)\\nprint('comment:',comment)\\n结果输出为：\\npre: [2 2 2 2 2 2 2]\\ncomment: 性价比好,质量好,参加了活动,客服物流包装好,老用户,会继续购买,好评\\n16.8 参考文献\\n[1] Kim Y . Convolutional Neural Networks for Sentence Classification[J]. Eprint Arxiv,\\n2014.\\n[2] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint\\narXiv:1606.08415, 2016.\\n[3] Maas A L, Hannun A Y, Ng A Y. Rectifier nonlinearities improve neural network\\nacoustic models[C]//Proc. icml. 2013, 30(1): 3.\\n[4] Clevert D A, Unterthiner T, Hochreiter S. Fast and accurate deep network learning\\nby exponential linear units (elus)[J]. arXiv preprint arXiv:1511.07289, 2015.\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 632, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 633\\n[5] Klambauer G, Unterthiner T, Mayr A, et al. Self-normalizing neural\\nnetworks[C]//Advances in neural information processing systems. 2017: 971-980.\\n[6] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint\\narXiv:1606.08415, 2016.\\n[7]Ramachandran P, Zoph B, Le Q V. Searching for activation functions[J]. arXiv\\npreprint arXiv:1710.05941, 2017.\\n第 17 章 音频信号处理\\n深度学习目前应用最广泛的3 大领域就是计算机视觉，自然语言处理和语音。计算机视\\n觉和自然语言处理的内容在前面我们都已经有所了解，这一章节我们就来介绍一下语音方面\\n的任务。本章出现的新概念比较多，要想把这一章的内容学好，最好把这些新概念的中英文\\n名称都记住，对应的含义都理解清楚。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 633, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 634\\n17.1 深度学习在声音领域的应用介绍\\n1. 音频分类\\n音频分类算是音频领域的一个基本应用，就是判断一段音频数据是属于哪一种分类，比\\n如分类可以是人的说话声，飞机轰鸣声，汽车声音，火车声音，小孩哭声，玻璃破碎声，狗\\n叫声，警报声等等，如图17.1 所示。\\n图 17.1 语音分类\\n2.音频事件检测\\n音频事件检测（Audio Event Detection）其实跟音频分类有点像，就是实时监测环境中\\n的音频事件，这里的音频事件可以看成是某种声音的分类。比如一对新婚夫妻生了一个小婴\\n儿，父母睡眠质量都比较好并且对婴儿哭声不太敏感，半夜婴儿肚子饿，哭了半天父母才能\\n醒过来。如果要解决这个问题我们可以把婴儿的哭声作为要检测的音频事件，检测到婴儿的\\n哭声后，可以触发一个音量比较大的闹钟铃声唤醒婴儿的父母。如图 17.2 所示。\\n图17.2 音频事件检测\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 634, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 635\\n3. 语音识别\\n语音识别大家应该比较熟悉，就是把语音信息转化为文字信息。在我们的日常生活中语\\n音识别已经得到了较大规模的应用，日常用语的语音识别效果已经可以达到非常高的准确\\n率。\\n4．音乐检索\\n音乐检索就是通过一小段音乐去检索出该音乐出自哪一首歌曲，也就是我们日常所说的\\n听歌识曲。不少音乐类APP现在都已经实现了该功能。\\n5. 音乐生成\\nAI与音乐的结合在这几年变得越来越频繁，在2019 年中国数字音乐产业发展峰会上，\\n有音乐制作公司在现场演示了AI作曲的操作，只需要给AI算法随意唱几个音符，它就可以\\n作出一首完整的歌曲。美国网红歌手Taryn Southern 跟AI一起创作了一首歌《Break\\nFree》。AI技术用于音乐生成目前还处于比较早期的阶段，相信在未来我们可以听到更多更\\n好的AI音乐作品。\\n6. 语音合成\\n语音合成包括把文本文字合成人声。近几年有部分广告推销电话已经开始时候语音合成\\n技术，使用机器来给我们打电话。如果不仔细分辨的话，有可能还不知道对方是机器人。当\\n然，目前这个技术还不算特别成熟，机器人的声音相比于普通人的声音来说会显得更僵硬一\\n些，说话方式没有人这么自然。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 635, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 636\\n7. 语音克隆\\n语音克隆技术指的是克隆某个人的声音。给算法输入某个人的一个声音片段，算法会学\\n习这个人的方式，然后再把这种说话方法跟其他的人声相结合。比如你想模仿“小团团”魔\\n性的声音，就准备一段“小团团”的语言片段传给算法学习，然后算法就可以把你的说话声\\n音变成“小团团”的声音了。\\n17.2 MFCC 和 Mel Filter Banks\\n这一小节我们来介绍一下自动语言识别(Automatic Speech Recognition，简称ASR)\\n领域中最常用的两种语音处理方法： 梅尔滤波器组（Mel Filter Banks）和梅尔频率倒谱系\\n数 (Mel-frequency cepstral coefficients，简称MFCC )。\\n语音数据处理的流程如图17.3 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 636, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 637\\n图17.3 语音数据处理的流程\\n17.2.1 音频数据采集\\n首先我们来大概了解一下语音中的一些基本概念，语音信号在自然界中是属于模拟信号\\n（Analog Signal），模拟信号是指用连续变化的物理量表示的信号。我们需要把模拟信号\\n变成数字信号（Digital Signal）以后才能进行后续的分析和建模，数字信号指的是离散的\\n数值信号。所以一般我们可以使用数字麦克风（可以直接输出数字信号的麦克风），或者模\\n拟麦克风（输出模拟信号的麦克风）加上模数转换芯片（把模拟信号变成数字信号的芯片）\\n得到数字信号。\\n在采集声音数据的时候，可以通过设置采样频率（Sampling frequency）来控制信号\\n采集的快慢，比如采样频率为8kHz 时，表示每秒可以采集到8000 个数据。一个数据就是\\n一个数值，数值的大小表示信号的强弱。我们人耳的听力范围一般是 20Hz-20kHz，根据\\nNyquist采样定理，采样频率至少是信号中的最高频率的两倍，也就是说要采样 20Hz-\\n20kHz 的信号，需要至少40kHz 以上的采样频率。在 CD中采用了44.1kHz 的采样频率，\\n所以CD可以保存高质量的音频信号。采样频率也不是越高越好，因为采样频率越高，采集\\n到的数据就越多，音频文件也会变得越大。人耳对低频声音比较敏感，对高频声音不太敏\\n感，并且人说话的声音频率也比较低，所以在普通的录音应用中 8kHz 或16kHz 的采样频率\\n会用的比较多。\\n除了采样频率以外，量化位数（Quantization Bits）也会影响音频文件的大小，量化位\\n数是对模拟信号进行数字化时的精度。比如 8 位就是用8bit来表示音频信号，16 位就是用\\n16bit来表示音频信号。位数越高，数字化后的音频信号就越可能接近原始信号，但所需的\\n存储空间也越大。通常8 位和16 位用得比较多。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 637, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 638\\n17.2.2 分帧加窗\\n我们在分析视频数据的时候会把连续的视频数据拆分为一帧一帧的图像数据来进行分析。处\\n理语音数据的时候也是如此，我们会把一长串语音数据拆分为一帧一帧的数据进行处理。语\\n音数据中的帧指的是一小段语音数据，一般情况下我们会把 20-40ms的数据看成是一帧。\\n选择20-40ms这个长度主要是我们假设在短时尺度上音频信号没有太大的变化，如果帧的\\n长度更短的话，我们没有足够的样本来获取可靠的频谱估计，如果帧更长的话，信号在整个\\n帧中变化太大。比较常用的帧长为20-25ms，帧移为10ms，如图17.4 所示。\\n图17.4 分帧\\n图中的Amplitude 表示振幅；Time 表示时间；seconds表示秒。\\n分帧后一般还会有一个加窗的操作，如常用的窗口有 Rectangular Window，\\nHamming Window和Hanning Window等，如图17.5 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 638, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 639\\n图 17.5 各种窗口\\nRectangular Window其实就是保留分帧后的数据不做处理，Hamming Window和\\nHanning Window效果差不多，就是增强每一帧数据中间部分的信号，减弱每一帧数据边缘\\n的信号。一般来说Hamming Window和Hanning Window用得比较多。\\n17.2.3 傅里叶变换\\n分帧加窗做好以后，下一步就要对每帧数据进行傅里叶变换（Fourier Transform），\\n如图17.6 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 639, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 640\\n图17.6 对每帧数据进行傅里叶变换\\n因为我们使用的数据都是离散的数值信号，对离散的数值信号进行的傅里叶变换也称为\\n离散傅里叶变换（Discrete Fourier Transform，简称DFT）。在计算机中一般会使用更\\n高效，更快速的离散傅里叶变换，称为快速傅里叶变换（Fast Fourier Transform，简称\\nFFT），FFT 是DFT的快速算法。\\n我们这里的具体操作是将信号加上滑动时间窗，并对每个时间窗口内的数据进行 FFT，\\n这种操作有一个专门的名词，称为短时傅里叶变换（short-term Fourier transform，简\\n称STFT）。\\n下面我们就拿FFT 来说明一下，傅里叶变换具体是一种什么变换。如果用一句话来说\\n明，傅里叶变换就是将时域（Time Domain）信号转换为频域（Frequency Domain）信\\n号。时域信号就是信号强弱与时间的关系，比如一段语音信号跟时间的关系，如图 17.7 所\\n示。\\n图 17.7 时域信号\\n图中的Amplitude 表示振幅；Time 表示时间；seconds表示秒。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 640, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 641\\n任何一段复杂的声音信号我们都可以看成是很多个正余弦波叠加得到的，如图 17.8 所\\n示。\\n图17.8 时域转频域\\n我们用FFT 算法把这图17.8 段语音信号转换为频域信号以后，会得到图 17.9 所示。\\n图 17.9 频域信号\\n图中Magnitude 表示重要性；Frequency 表示频率。\\n频域信号就是信号强弱与频率的关系，横坐标为频率，纵坐标为重要性，信号频率与强\\n弱的关系图也称为频谱图（Spectrum）。这是一段人说话的语音片段，转换为频域信号后\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 641, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 642\\n我们可以看到在这段语音中低频的信号比较强，比如 250Hz和450Hz左右的信号是最强\\n的，高频的信号很弱。关于FFT 的具体细节大家有兴趣的话可以再自行研究，这里我们就不\\n展开介绍了。\\n对一段语音数据进行STFT 以后，得到的结果如图 17.10 所示。\\n图17.10 STFT\\n图中FFT 的结果可以看到不同的频率有不同的灰度值，这里的灰度值表示数值大小，颜\\n色越深表示该频率的振幅越大。使用STFT 计算后得到的二维信号我们称之为声谱图\\n（Spectrogram）。\\n17.2.4 梅尔滤波器组（Mel Filter Banks）\\n梅尔滤波器组是模拟人耳听力特点设计出来的一组滤波器。前面我们有提到过人耳对低\\n频信号比较敏感，对高频信号不太敏感。比如我们很容易区分 500Hz和1000Hz这两个声\\n音信号，但是比较难区分18000Hz和 18500Hz这两个声音信号。梅尔滤波器可以模拟人类\\n对声音频率非线性的感知能力，对信号进行进一步的特征提取。梅尔 m与赫兹f的转换关系\\n如下：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 642, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 643\\n𝑓\\n𝑚 = 2595𝑙𝑜𝑔 (1 + ) (17.1)\\n\"<\\n700\\n(cid:130)\\n𝑓 = 700(10#(cid:176)(cid:237)(cid:176) − 1) (17.2)\\n梅尔Mels 与赫兹Hz的关系如图17.11 所示。\\n图17.11 梅尔（Mels）与赫兹（Hz）的关系\\n下面举例说明一下这些滤波器如何生成。梅尔滤波器组的个数是可以人为设置的，一般\\n设置为40。假设现在我们设置为10 个滤波器，10 个滤波器需要10+2=12 个频率点（这里\\n的2 表示最小频率点和最大频率点）。比如我们使用的采样频率是 8000Hz，根据Nyquist\\n采样定理，我们采集到的信号频率上限为 4000Hz，4000Hz根据公式17.1 计算约等于\\n2146.06Mels。现在我们从 0-2146.06 均匀划分12 个点，得到：\\nm(i) = 0，195.10，390.19，585.29，780.39，975.48，1170.58，1365.68，\\n1560.77，1755.87，1950.97，2146.06\\n这12 个Mels 转换为Hz等于：\\nh(i) = 0，132.30，289.60，476.64，699.02，963.44，1277.83，1651.64，\\n2096.10，2624.56，3252.90，4000\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 643, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 644\\n根据这12 个Hz频率点可以得到10 个三角滤波器。三角滤波器的特点是三角形区域以\\n外的信号都会被过滤掉，在三角形区域内中间的信号比较强，两边的信号会被减弱。第一个\\n滤波器从第1 个频率点开始，在第 2 个频率点达到最大值1，然后在第3 个频率点降为0；\\n第二个滤波器从第2 个频率点开始，在第 3 个频率点达到最大值1，然后在第4 个频率点降\\n为0。以此类推得到 10 个三角滤波器，如图17.12 所示。\\n图17.12 10 个梅尔滤波器组\\n图中Amplitude 表示重要性；Frequency 表示频率。\\n接下来使用梅尔滤波器组对经过STFT 计算后得到的声谱图Spectrogram 进行滤波，得\\n到梅尔频谱（Mel Spectrogram），如图17.13 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 644, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 645\\n图17.13 梅尔频谱（Mel Spectrogram）\\n图17.13 为图 17.7 语音数据对应的梅尔频谱，梅尔滤波器组的个数为 40。到这里通过\\n梅尔滤波器组（Mel Filter Banks）计算得到的梅尔频谱（Mel Spectrogram）就可以用来\\n作为这一段语音的特征数据了。然后再使用 CNN 或者是RNN网络就可以对于这段语音的特\\n征数据进行进一步的分析和预测。\\n17.2.5 梅尔频率倒谱系数 MFCC\\n在介绍MFCC 具体怎么计算之前，我们先介绍一下相关背景。如图17.14 所示为一段语\\n音的频谱图。\\n图17.14 频谱图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 645, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 646\\n峰值就表示语音的主要频率成分，我们把这些峰值称为共振峰（Formants）。共振峰携\\n带了声音的辨识属性，用它就可以识别不同的声音。 我们可以把共振峰提取出来，不仅要提\\n取共振峰的位置，还要提取它们的变化过程，得到包络（Spectral Envelope）。包络就是\\n一条将所有共振峰连接起来的平滑曲线，如图 17.15 所示。\\n图17.15 包络\\n我们可以认为频谱信号是由包络和包络细节（Spectral Details）组成，如图17.16 所\\n示。\\n图17.16 频谱信号的组成\\n我们可以认为包络是比较重要的特征，包络细节是不太重要的特征，甚至可能是噪声。\\n现在我们要转换一下思维，如果我们把图中的横坐标 Frequency 看成是时间，把包络和包络\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 646, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 647\\n细节看成是波形。那包络的波形属于低频信号，包络细节的波形属于高频信号。那也就是说\\n频谱图中的低频信号是重要特征，高频信号不太重要。\\n所以我们可以对频谱图再做一次FFT，得到频谱图的倒谱（Cepstrum）。倒谱这个词的\\n英文Cepstrum实际上就是频谱图的英文Spectrum 前四个字母顺序颠倒过来得到的。在倒\\n谱中的频率称为伪频率（Pseudo-Frequency），因为它不是真正的音频信号的频率，它表\\n示的是频谱图中波形的频率。\\n根据我们前面所说，倒谱中的伪频率低频信号是重要特征，所以我们可以只取倒谱中低\\n频信号的特征值，舍弃倒谱中高频信号的特征。具体取多少个倒谱中的低频信号，可以人为\\n设置，对于ASR任务一般取前12-20 个。\\nMFCC 信号的具体计算是对梅尔频谱再做一次离散余弦变换（Discrete Fourier\\nTransform，简称DCT），DCT 类似于DFT，DCT 只使用实数。然后取倒谱中前n 个低频\\n信号，n 可以人为设置。MFCC 可以看成是对梅尔频谱的进一步特征提取，可以得到更适合\\nASR任务的特征。语音信号是时域连续的，分帧提取的信息只反应了本帧语音的特性，我们\\n还可以计算MFCC 的差分信号，常用的是一阶差分和二阶差分，差分的简单计算公式如下：\\n𝑐 − 𝑐\\nˆ(cid:151)\" ˆ(cid:127)\"\\n𝑑(𝑡) = (17.3)\\n2\\n其中c 为MFCC 中的倒谱特征，t为时间，也可以理解为第t帧，d为差分特征。使用原\\n始MFCC 的值可以计算出一阶差分∆𝑀𝐹𝐶𝐶，然后使用∆𝑀𝐹𝐶𝐶又可以计算出二阶差分\\n∆#𝑀𝐹𝐶𝐶。实际计算时差分计算公式不一定用的是这一个，也可以使用其他的差分计算公\\n式。图17.7 语音数据的MFCC，∆𝑀𝐹𝐶𝐶，∆#𝑀𝐹𝐶𝐶结果如图17.17 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 647, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 648\\n图17.17 MFCC 及其一阶差分和二阶差分\\n差分信号可以计算也可以不计算，计算差分信号相当于可以得到多一些特征。得到\\nMFCC 后再使用CNN 或者是RNN 网络就可以对于这段语音的特征数据进行进一步的分析\\n和预测。\\n17.3 语音分类项目\\n17.3.1 音频处理库 librosa 介绍\\n语音信号有很多复杂的处理流程，因此使用一个封装好的 python模块会让事情变得简\\n单很多，下面我们要使用一个专门做音频数据处理的模块 librosa。首先，先进行librosa的\\n安装，同样也是打开命令提示符，输入命令：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 648, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 649\\npip install librosa\\n安装好以后就可以使用librosa进行一些音频数据的处理了，我们需要准备一些音频文\\n件，如果你暂时找不到音频文件，那么在下面这个地址可以下载到一些音频文件的 demo：\\nhttp://www.voiptroubleshooter.com/open_speech/american.html。\\nlibrosa基本操作的代码如代码17-1 所示。\\n代码17-1：librosa基本操作（片段1）\\nimport matplotlib.pyplot as plt\\nimport librosa\\nimport librosa.display\\nimport sklearn\\nimport IPython.display as ipd\\n# 播放音频文件\\nipd.Audio('OSR_us_000_0010_8k.wav')\\n# 读取一段音频文件\\n# sr=None 表示不设置采样率，默认会使用音频文件自身的采样率\\n# duration=3.5表示读取该文件前 3.5秒的数据\\n# 读取文件后返回文件数据signal和采样率sample_rate\\nsignal,sample_rate = librosa.load('OSR_us_000_0010_8k.wav', sr=None, duration=3.5)\\nprint('sample_rate:',sample_rate)\\nprint('signal:',len(signal))\\n结果输出为：\\nsample_rate: 8000\\nsignal: 28000\\n代码17-1：librosa基本操作（片段2）\\n# 画出音频数据的波形图\\nlibrosa.display.waveplot(signal, sample_rate)\\nplt.show()\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 649, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 650\\n代码17-1：librosa基本操作（片段3）\\n# 提取梅尔频谱特征\\n# n_fft为FFT窗口长度，hop_length为帧移，n_mels为滤波器个数\\nmelspec = librosa.feature.melspectrogram(signal, sample_rate, n_fft=1024, hop_length=51\\n2, n_mels=40)\\n# 取对数\\nlogmelspec = librosa.power_to_db(melspec)\\n# 画出梅尔频谱特征Mel Spectrogram\\n# fmax为最大频率\\nlibrosa.display.specshow(logmelspec, sr=sample_rate, fmax=4000, x_axis='time', y_axis='h\\nz')\\n# 设置title\\nplt.title('Mel Spectrogram')\\n# 显示颜色数值\\nplt.colorbar()\\nplt.show()\\n结果输出为：\\n代码17-1：librosa基本操作（片段4）\\n# 计算mfcc,n_mfcc 为每帧数据mfcc 特征数量\\nmfcc = librosa.feature.mfcc(signal,sample_rate,n_mfcc=20)\\n# 数据标准化\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 650, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 651\\nmfcc = sklearn.preprocessing.scale(mfcc, axis=1)\\n# 画出mfcc 频谱图\\nlibrosa.display.specshow(mfcc,sr=sample_rate)\\nplt.title(\\'MFCC\\')\\nplt.colorbar()\\nplt.show()\\n结果输出为：\\n17.3.2 音频分类项目-模型训练\\n这里我们使用的分类数据集为UrbanSound，数据集地址为\\nhttps://urbansounddataset.weebly.com/。如果大家有其他数据集的话也可以使用其他数\\n据集。UrbanSound数据集有10 个种类的声音，分别是0 冷气机，1 汽车喇叭，2 孩子声\\n音，3 狗叫声，4 电钻声，5 发动机声音，6 枪声，7 手提钻，8 警报声，9 街头音乐声。原\\n始数据一共有10 个文件夹，每个文件夹里有800 多个音频文件，每个文件为某种声音类型\\n的音频数据，时长为几秒。由于数据比较大，所以只使用了其中 3 个文件夹，大约2500 个\\n音频文件。音频文件名中包含标签信息，标签为文件名中的第二个数字，如“7061-6-0-\\n0.wav”标签为6 枪声，“9031-3-2-0.wav”标签为3 狗叫声，具体实现代码如代码 17-2\\n所示。\\n代码17-2：音频分类项目-模型训练（片段1）\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\nimport glob\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 651, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 652\\nimport os\\n# 需要安装tqdm，用于查看进度条\\n# pip install tqdm\\nfrom tqdm import tqdm\\n# pip install librosa\\nimport librosa\\nimport numpy as np\\nimport sklearn\\nfrom sklearn.model_selection import train_test_split\\n# pip install plot_model\\nfrom plot_model import plot_model\\n# 音频文件存放位置\\n# 在'audio/'文件夹下还有fold1，fold2，fold3 这3 个文件夹\\naudio_dir = 'audio/'\\n# 批次大小\\nbatch_size = 64\\n# 训练周期\\nepochs = 500\\n# 获取所有wav文件\\ndef get_wav_files(audio_dir):\\n# 用于保存音频文件路径\\naudio_files = []\\n# 循环文件夹\\nfor sub_file in os.listdir(audio_dir):\\n# 得到文件完整路径\\nfile = os.path.join(audio_dir,sub_file)\\n# 如果是文件夹\\nif os.path.isdir(file):\\n# 得到file 文件夹下所有'*.wav'文件\\naudio_files += glob.glob(os.path.join(file, '*.wav'))\\nreturn audio_files\\n# 获取文件mfcc 特征和对应标签\\ndef extract_features(audio_files):\\n# 用于保存mfcc 特征\\naudio_features = []\\n# 用于保存标签\\naudio_labels = []\\n# 由于特征提取需要时间比较长，可以加上tqdm 实时查看进度\\nfor audio in tqdm(audio_files):\\n# 读入音频文件\\n# 由于音频文件原始采样率高低不一，这里我们把采样率固定为 22050\\nsignal,sample_rate = librosa.load(audio,sr=22050)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 652, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 653\\n# 由于音频长度长短不一，基本上都在 4 秒左右，所以我们把所有音频数据的长度都固\\n定为4 秒\\n# 采样率22050，时长为4 秒，所以信号数量为22050*4=88200\\n# 小于88200填充\\nif len(signal)<88200:\\n# 给signal 信号前面填充0 个数据，后面填充88200-len(signal)个数据，填充值为0\\nsignal = np.pad(signal,(0,88200-len(signal)),'constant',constant_values=(0))\\n# 大于88200，只取前面88200个数据\\nelse:\\nsignal = signal[:88200]\\n# 获取音频mfcc 特征，然后对数据进行转置\\n# 原始mfcc 数据shape 为(mfcc 特征数，帧数)->(帧数，mfcc 特征数)\\n# 相当于把序列长度的维度放前面，特征数的维度放后面\\nmfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0])\\n# 数据标准化\\nmfcc = sklearn.preprocessing.scale(mfcc, axis=0)\\n# 保存mfcc 特征\\naudio_features.append(mfcc.tolist())\\n# 获取label\\n# 获取文件名第2 个数字，第2 个数字为标签\\nlabel = audio.split('/')[-1].split('-')[1]\\n# 保存标签\\naudio_labels.append(int(label))\\nreturn np.array(audio_features), np.array(audio_labels)\\n# 获取所有wav文件\\naudio_files = get_wav_files(audio_dir)\\nprint('文件数量：',len(audio_files))\\n结果输出为：\\n文件数量： 2685\\n代码17-2：音频分类项目-模型训练（片段2）\\n# 获取文件mfcc 特征和对应标签\\naudio_features,audio_labels = extract_features(audio_files)\\n# 切分训练集和测试集\\nx_train,x_test,y_train,y_test = train_test_split(audio_features,audio_labels)\\nfrom tensorflow.keras.models import Sequential,Model\\nfrom tensorflow.keras.layers import Conv1D,GlobalMaxPool1D,AlphaDropout,Dense,Input,c\\noncatenate\\nfrom tensorflow.keras.optimizers import Adam\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 653, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 654\\nfrom tensorflow.keras.activations import selu\\nfrom tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc\\neLROnPlateau\\nfrom tensorflow.keras.regularizers import l2\\n# 定义模型输入\\ninputs = Input(shape=(x_train.shape[1:]))\\n# 定义1 维卷积，权值初始化使用lecun_normal，主要是为了跟selu 搭配\\nx0 = Conv1D(filters=256, kernel_size=3, activation='selu', kernel_initializer='lecun_normal',\\nkernel_regularizer=l2(0.0001))(inputs)\\nx0 =GlobalMaxPool1D()(x0)\\n# 定义1 维卷积\\nx1 = Conv1D(filters=256, kernel_size=4, activation='selu', kernel_initializer='lecun_normal',\\nkernel_regularizer=l2(0.0001))(inputs)\\nx1 =GlobalMaxPool1D()(x1)\\n# 定义1 维卷积\\nx2 = Conv1D(filters=256, kernel_size=5, activation='selu', kernel_initializer='lecun_normal',\\nkernel_regularizer=l2(0.0001))(inputs)\\nx2 =GlobalMaxPool1D()(x2)\\n# 合并特征\\nx = concatenate([x0,x1,x2],axis=-1)\\n# 可以用AlphaDropout保持信号均值和方差不变，AlphaDropout一般跟selu 搭配\\nx = AlphaDropout(0.5)(x)\\n# 10 分类\\npreds = Dense(10, activation='softmax', kernel_initializer='lecun_normal')(x)\\n# 定义模型\\nmodel = Model(inputs, preds)\\n# 画结构图\\nplot_model(model, dpi=200)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 654, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 655\\n代码17-2：音频分类项目-模型训练（片段3）\\n# 定义优化器\\n# 因为标签没有转独热编码，所以loss用sparse_categorical_crossentropy\\nmodel.compile(optimizer=Adam(0.01),\\nloss='sparse_categorical_crossentropy',\\nmetrics=['accuracy'])\\n# 监控指标统一使用val_accuracy\\n# 可以使用EarlyStopping来让模型停止，连续40 个周期val_accuracy没有下降就结束训练\\n# ModelCheckpoint保存所有训练周期中 val_accuracy最高的模型\\n# ReduceLROnPlateau学习率调整策略，连续20 个周期val_accuracy没有提升，当前学习\\n率乘以0.1\\ncallbacks = [EarlyStopping(monitor='val_accuracy', patience=40, verbose=1),\\nModelCheckpoint('audio_model/'+'cnn_{val_accuracy:.4f}.h5', monitor='val_accurac\\ny', save_best_only=True),\\nReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=20, verbose=1)]\\n# 模型训练\\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data\\n=(x_test, y_test), callbacks=callbacks)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 655, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 656\\n模型训练最后得到测试集准确率大概为 90%左右。\\n17.3.3 音频分类项目-模型预测\\n下面我们再看一下模型预测程序，单独准备一些音频测试文件，存放在”audio_test”\\n文件夹下面，具体实现如代码17-3 所示。\\n代码17-3：音频分类项目-模型预测（片段1）\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\nimport librosa\\nfrom tensorflow.keras.models import load_model\\nimport glob\\nimport os\\nfrom tqdm import tqdm\\nimport numpy as np\\nimport sklearn\\n# 测试文件存放路径\\naudio_dir = \\'audio_test/\\'\\n# 载入模型\\nmodel = load_model(\\'audio_model/cnn_0.8943.h5\\')\\n# 获取文件mfcc 特征和对应标签\\ndef extract_features(audio_files):\\n# 用于保存mfcc 特征\\naudio_features = []\\n# 用于保存标签\\naudio_labels = []\\n# 由于特征提取需要时间比较长，可以加上tqdm 实时查看进度\\nfor audio in tqdm(audio_files):\\n# 读入音频文件\\n# 由于音频文件原始采样率高低不一，这里我们把采样率固定为 22050\\nsignal,sample_rate = librosa.load(audio,sr=22050)\\n# 由于音频长度长短不一，基本上都在 4 秒左右，所以我们把所有音频数据的长度都固\\n定为4 秒\\n# 采样率22050，时长为4 秒，所以信号数量为22050*4=88200\\n# 小于88200填充\\nif len(signal)<88200:\\n# 给signal 信号前面填充0 个数据，后面填充88200-len(signal)个数据，填充值为0\\nsignal = np.pad(signal,(0,88200-len(signal)),\\'constant\\',constant_values=(0))\\n# 大于88200，只取前面88200个数据\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 656, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 657\\nelse:\\nsignal = signal[:88200]\\n# 获取音频mfcc 特征，然后对数据进行转置\\n# 原始mfcc 数据shape 为(mfcc 特征数，帧数)->(帧数，mfcc 特征数)\\n# 相当于把序列长度的维度放前面，特征数的维度放后面\\nmfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0])\\n# 数据标准化\\nmfcc = sklearn.preprocessing.scale(mfcc, axis=0)\\n# 保存mfcc 特征\\naudio_features.append(mfcc.tolist())\\n# 获取label\\n# 获取文件名第2 个数字，第2 个数字为标签\\nlabel = audio.split('/')[-1].split('-')[1]\\n# 保存标签\\naudio_labels.append(int(label))\\nreturn np.array(audio_features), np.array(audio_labels)\\n# 获取所有wav文件\\naudio_files = glob.glob(os.path.join(audio_dir, '*.wav'))\\nprint('文件数量：',len(audio_files))\\n结果输出为：\\n文件数量： 10\\n代码17-3：音频分类项目-模型预测（片段2）\\n# 获取文件mfcc 特征和对应标签\\naudio_features,audio_labels = extract_features(audio_files)\\n# 把测试数据当作一个批次进行预测\\npreds = model.predict_on_batch(audio_features)\\n# 计算概率最大的类别\\npreds = np.argmax(preds, axis=1)\\nprint('真实标签为：',audio_labels)\\nprint('预测结果为：',preds)\\n结果输出为：\\n真实标签为： [3 0 5 1 8 7 9 5 2 1]\\n预测结果为： [3 0 5 1 8 7 9 5 2 1]\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 657, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 658\\n第 18 章 图像风格转换\\n图像风格转换对应的英文为Image Style Transfer，意思将两个图像，一张内容图像\\nA，一张风格图像B 混合在一起，使得输出的图像内容像A，风格像B，如图18.1 所示。\\n图18.1 图像风格转换[1]\\n18.1 图像风格转换实现原理\\n下面主要以《A Neural Algorithm of Artistic Style》[1]这篇论文的思路给大家介绍一下\\n图像风格转换如何实现。我们在之前学习卷积网络的时候有介绍过，卷积的功能主要是特征\\n提取，那么经过大量训练的卷积网络就可以具备良好的特征提取能力。并且，不同的卷积层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 658, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 659\\n可以提取不同的特征。一般来说，浅层的卷积主要是提取图像边缘轮廓的特征，而深层的卷\\n积则是提取图像更抽象的特征。因此我们可以选用一个经过预训练的图像识别卷积网络来作\\n为特征提取器，比如可以选择VGG16。\\n图像风格转换的模型训练其实跟其他的深度学习模型训练类似，模型中有一些需要训练\\n的权值，在图像风格变换中模型需要训练的权值是生成图片的像素值。我们一般使用内容图\\n片来初始化生成图片的像素值，之后生成图片的像素值会随着模型的训练不断变化。我们还\\n需要定义一个代价函数，然后使用优化器最小化代价函数的值。所以这里的重点在于这个代\\n价函数如何定义。\\n18.1.1 代价函数的定义\\n我们把代价函数分为内容content loss和风格style loss。Content loss表示生成出来\\n的新图片与作为内容的图片A之间的loss；style loss表示生成出来的新图片与作为风格的\\n图片B 之间的loss，总的代价函数公式为：\\n𝐿 = 𝛼𝐿 + 𝛽𝐿 (18.1)\\nˆ(cid:210)ˆ(cid:240)(cid:132) (cid:211)(cid:210)@ˆ⁄@ˆ (cid:222)ˆ—(cid:132)⁄\\n其中𝐿 表示content loss，𝐿 表示style loss，𝛼表示content loss的权重，𝛽表\\n(cid:211)(cid:210)@ˆ⁄@ˆ (cid:222)ˆ—(cid:132)⁄\\n示style loss的权重，权重的值可以人为设定。𝐿 和𝐿 的计算如图18.2 所示。\\n(cid:211)(cid:210)@ˆ⁄@ˆ (cid:222)ˆ—(cid:132)⁄\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 659, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 660\\n图18.2 loss计算\\n图中的卷积网络为一个经过预训练的 VGG16 模型，在计算𝐿 时使用的卷积层为\\n(cid:222)ˆ—(cid:132)⁄\\nConv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1，𝐿 的计算公式为：\\n(cid:222)ˆ—(cid:132)⁄\\n𝐸 = ?(𝐺= − 𝑆=)# (18.2)\\n=\\n𝐿 = ?𝑤 𝐸 (18.3)\\n(cid:222)ˆ—(cid:132)⁄ (cid:132) (cid:132)\\n其中L 表示不同的卷积层，G为生成图片的特征图计算得到的格拉姆矩阵（Gram\\nMatrix），S 为风格图片的特征图计算得到的格拉姆矩阵。这里计算格拉姆的原因是我们可\\n以使用格拉姆矩阵来表示一副图片的风格，关于格拉姆矩阵的具体计算后面再介绍。总之，\\n我们可以计算出风格图片和生成图片Conv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1\\n这5 个卷积层输出的特征图所计算得到的 Gram 矩阵𝑆=和𝐺=，根据𝑆=和𝐺=来计算𝐸 。把所有\\n=\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 660, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 661\\n𝐸 乘以对应权重𝑤 ，再累加起来得到𝐿 。权重𝑤 可以人为设置，一般设置为1/5，即所有\\n(cid:132) (cid:132) (cid:222)ˆ—(cid:132)⁄ (cid:132)\\n卷积层的特征权重相等。\\n在计算𝐿 时使用的是Conv5_2 输出的特征图，也可以取多个卷积层输出，不过效果\\n(cid:211)(cid:210)@ˆ⁄@ˆ\\n变化不大，𝐿 的计算公式为：\\n(cid:211)(cid:210)@ˆ⁄@ˆ\\n𝐿 = ?(𝐺(cid:132) − 𝐶(cid:132))# (18.3)\\n(cid:211)(cid:210)@ˆ⁄@ˆ\\n其中𝐺(cid:132)为生成图片 Conv5_2 输出的特征图，𝐶(cid:132)为内容图片Conv5_2 输出的特征图。注\\n意在计算𝐿 的时候这里是直接对比特征图𝐺(cid:132)和特征图𝐶(cid:132)，并没有计算Gram 矩阵。因为\\n(cid:211)(cid:210)@ˆ⁄@ˆ\\n计算Gram 矩阵可以得到特征图和特征图之间的相关性，对于表示图片的风格是有意义的，\\n跟图片的内容关系不大。\\n当我们使用优化器最小化代价函数的时候，相当于是在对比风格图片和生成图片的图像\\n风格，然后使得图片风格的差异越小越好；然后再对比生成图片和内容图片的内容特征，然\\n后使得图片内容特征的差异越小越好。生成图片的像素值经过不断的变化，就可以得到风格\\n转换后的结果。\\n18.1.2 格拉姆矩阵（Gram Matrix）介绍\\n上一小节我们有提到，在计算图像风格的时候用到了格拉姆矩阵（Gram Matrix），那\\n么这一小节我们主要来介绍一下格拉姆矩阵是如何计算的。\\n我们使用图像经过卷积计算后得到的特征图来计算 Gram 矩阵，然后用Gram 矩阵表示图像\\n风格。在计算Gram 矩阵前，我们先把2 维的特征图变成1 维的特征向量，如图18.3 所\\n示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 661, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 662\\n图18.3 把 2 维特征图变成1 维特征向量\\n假设我们现在一共有5 张特征图，如图所示。特征图的宽为𝑛 ，高为𝑛 ，所以展开成1\\n> ?\\n维后，得到的特征图矩阵的列数为𝑛 ×𝑛 ，行数为特征图数量5。\\n? >\\n接下来的计算如图18.4 所示。\\n图 18.4 Gram 矩阵计算\\n把前面得到的特征图矩阵乘以该特征图矩阵的转置，得到的结果就是 Gram 矩阵。在上\\n面这个例子中，因为一共有5 张特征图，所以最后得到的 Gram 矩阵为5×5 的矩阵。Gram\\n矩阵可以把图像特征之间的联系提取出来，也就是可以得到特征之间的相关性。所以在图像\\n风格转换中，可以使用Gram 矩阵来表示图像的特征。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 662, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 663\\n18.2 图像风格转换项目实战\\n在运行程序之前，大家可以自己收集一些风格图片和内容图片，然后尝试使用不同的照\\n片看看可以得到什么结果。也可以尝试设置不同的 loss权重，看看图片的变化情况。实现图\\n像风格装换的代码如代码18-1 所示。\\n代码18-1：图像风格转换（片段1）\\nimport matplotlib.pyplot as plt\\nimport tensorflow as tf\\nimport numpy as np\\nfrom PIL import Image\\n# 设置最长的一条边的长度\\nmax_dim = 800\\n# 内容图片路径\\ncontent_path = '臭臭.jpeg'\\n# 风格图片路径\\nstyle_path = 'starry_night.jpg'\\n# 风格权重\\nstyle_weight=10\\n# 内容权重\\ncontent_weight=1\\n# 全变差正则权重\\ntotal_variation_weight=1e5\\n# 训练次数\\nstpes = 301\\n# 是否保存训练过程中产生的图片\\nsave_img = True\\n# 载入图片\\ndef load_img(path_to_img):\\n# 读取文件内容\\nimg = tf.io.read_file(path_to_img)\\n# 变成3 通道图片数据\\nimg = tf.image.decode_image(img, channels=3, dtype=tf.float32)\\n# img = tf.image.convert_image_dtype(img, tf.float32)\\n# 获得图片高度和宽度，并转成float 类型\\nshape = tf.cast(tf.shape(img)[:-1], tf.float32)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 663, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 664\\n# 最长的边的长度\\nlong_dim = max(shape)\\n# 图像缩放，把图片最长的边变成max_dim\\nscale = max_dim / long_dim\\nnew_shape = tf.cast(shape * scale, tf.int32)\\n# resize 图片大小\\nimg = tf.image.resize(img, new_shape)\\n# 增加1 个维度，变成 4 维数据\\nimg = img[tf.newaxis, :]\\nreturn img\\n# 用于显示图片\\ndef imshow(image, title=None):\\n# 如图是4 维度数据\\nif len(image.shape) > 3:\\n# 去掉size 为1 的维度如(1,300,300,3)->(300,300,3)\\nimage = tf.squeeze(image)\\n# 显示图片\\nplt.imshow(image)\\nif title:\\n# 设置图片title\\nplt.title(title)\\nplt.axis('off')\\nplt.show()\\n# 载入内容图片\\ncontent_image = load_img(content_path)\\n# 载入风格图片\\nstyle_image = load_img(style_path)\\n# 显示内容图片\\nimshow(content_image, 'Content Image')\\n# 显示风格图片\\nimshow(style_image, 'Style Image')\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 664, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 665\\n代码18-1：图像风格转换（片段2）\\n# 用于计算content loss\\n# 这里只取了一层的输出进行对比，取多层输出效果变化不大\\ncontent_layers = ['block5_conv2']\\n# 用于计算风格的卷积层\\nstyle_layers = ['block1_conv1',\\n'block2_conv1',\\n'block3_conv1',\\n'block4_conv1',\\n'block5_conv1']\\n# 计算层数\\nnum_content_layers = len(content_layers)\\nnum_style_layers = len(style_layers)\\n# 创建一个新模型，输入与vgg16 一样，输出为指定层的输出\\ndef vgg_layers(layer_names):\\n# 载入VGG16 的卷积层部分\\nvgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\\n# VGG16 的模型参数不参与训练\\nvgg.trainable = False\\n# 获取指定层的输出值\\noutputs = [vgg.get_layer(name).output for name in layer_names]\\n# 定义一个新的模型，输入与vgg16 一样，输出为指定层的输出\\nmodel = tf.keras.Model([vgg.input], outputs)\\n# 返回模型\\nreturn model\\n# 获得输出风格层特征的模型\\nstyle_extractor = vgg_layers(style_layers)\\n# 图像预处理，主要是减去颜色均值，RGB转BGR\\npreprocessed_input = tf.keras.applications.vgg16.preprocess_input(style_image*255)\\n# 风格图片传入style_extractor，提取风格层的输出\\nstyle_outputs = style_extractor(preprocessed_input)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 665, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 666\\n# Gram矩阵的计算\\ndef gram_matrix(input_tensor):\\n# 爱因斯坦求和，bijc表示input_tensor中的4 个维度，bijd 表示input_tensor中的 4 个维\\n度\\n# 例如input_tensor的shape 为(1,300,200,32)，那么b=1,i=300,j=200,c=32,d=32\\n# ->bcd 表示计算后得到的数据维度为(1,32,32),得到的结果表示特征图与特征图之间的相\\n关性\\nresult = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\\n# 特征图的shape\\ninput_shape = tf.shape(input_tensor)\\n# 特征图的高度乘以宽度得到特征值数量\\nnum_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\\n# 除以特征值的数量\\nreturn result/(num_locations)\\n# 构建一个返回风格特征和内容特征的模型\\nclass StyleContentModel(tf.keras.models.Model):\\ndef __init__(self, style_layers, content_layers):\\nsuper(StyleContentModel, self).__init__()\\n# 获得输出风格层和内容层特征的模型\\nself.vgg = vgg_layers(style_layers + content_layers)\\n# 用于计算风格的卷积层\\nself.style_layers = style_layers\\n# 用于计算content loss的卷积层\\nself.content_layers = content_layers\\n# 风格层的数量\\nself.num_style_layers = len(style_layers)\\ndef call(self, inputs):\\n# 图像预处理，主要是减去颜色均值，RGB转BGR\\npreprocessed_input = tf.keras.applications.vgg16.preprocess_input(inputs*255.0)\\n# 图片传入模型，提取风格层和内容层的输出\\noutputs = self.vgg(preprocessed_input)\\n# 获得风格特征输出和内容特征输出\\nstyle_outputs, content_outputs = (outputs[:self.num_style_layers],\\noutputs[self.num_style_layers:])\\n# 计算风格特征的Gram矩阵\\nstyle_outputs = [gram_matrix(style_output) for style_output in style_outputs]\\n# 把风格特征的Gram矩阵分别存入字典\\nstyle_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outp\\nuts)}\\n# 把内容特征存入字典\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 666, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 667\\ncontent_dict = {content_name:value for content_name, value in zip(self.content_layers\\n, content_outputs)}\\n# 返回结果\\nreturn {'content':content_dict, 'style':style_dict}\\n# 构建一个返回风格特征和内容特征的模型\\nextractor = StyleContentModel(style_layers, content_layers)\\n# 计算得到风格图片的风格特征\\nstyle_targets = extractor(style_image)['style']\\n# 计算得到内容图片的内容特征\\ncontent_targets = extractor(content_image)['content']\\n# 初始化要训练的图片\\nimage = tf.Variable(content_image)\\n# 定义优化器\\nopt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\\n# 把数值范围限制在0-1 之间\\ndef clip_0_1(image):\\nreturn tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\\n# 定义风格和内容loss\\ndef style_content_loss(outputs):\\n# 模型输出的风格特征\\nstyle_outputs = outputs['style']\\n# 模型输出的内容特征\\ncontent_outputs = outputs['content']\\n# 计算风格loss\\nstyle_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2)\\nfor name in style_outputs.keys()])\\nstyle_loss *= style_weight / num_style_layers\\n# 计算内容loss\\ncontent_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-\\ncontent_targets[name])**2)\\nfor name in content_outputs.keys()])\\ncontent_loss *= content_weight / num_content_layers\\n# 风格加内容loss\\nloss = style_loss + content_loss\\nreturn loss\\n# 施加全变差正则，全变差正则化常用于图片去噪，可以使生成的图片更加平滑自然\\ndef total_variation_loss(image):\\nx_deltas = image[:,:,1:,:] - image[:,:,:-1,:]\\ny_deltas = image[:,1:,:,:] - image[:,:-1,:,:]\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 667, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 668\\nreturn tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)\\n# 我们可以用@tf.function 装饰器来将 python 代码转成tensorflow 的图表示代码，用于加速\\n代码运行速度\\n@tf.function()\\n# 定义一个训练模型的函数\\ndef train_step(image):\\n# 固定写法，使用tf.GradientTape()来计算梯度\\nwith tf.GradientTape() as tape:\\n# 传入图片获得风格特征和内容特征\\noutputs = extractor(image)\\n# 计算风格和内容loss\\nloss = style_content_loss(outputs)\\n# 再加上全变差正则loss\\nloss += total_variation_weight*total_variation_loss(image)\\n# 传入loss和模型参数，计算权值调整\\ngrad = tape.gradient(loss, image)\\n# 进行权值调整，这里要调整的权值就是image 图像的像素值\\nopt.apply_gradients([(grad, image)])\\n# 把数值范围限制在0-1 之间\\nimage.assign(clip_0_1(image))\\n# 训练steps次\\nfor n in range(stpes):\\n# 训练模型\\ntrain_step(image)\\n# 每训练5 次打印一次图片\\nif n%5==0:\\nimshow(image.read_value(), \"Train step: {}\".format(n))\\n# 保存图片\\nif save_img==True:\\n# 去掉一个维度\\ns_image = tf.squeeze(image)\\n# 把array变成Image 对象\\ns_image = Image.fromarray(np.uint8(s_image.numpy()*255))\\n# 设置保存路径保存图片\\ns_image.save(\\'temp/\\'+\\'steps_\\'+str(n)+\\'.jpg\\')\\n结果输出为：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 668, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 669\\n……\\n……\\n18.3 遮挡图像风格转换项目实战\\n我们可以自己制作图片中某些物体的遮挡（Mask），这样可以在做风格转换的时候图片\\n中的某些部分进行了风格转换，某些部分还是保持原有的样子。如图 18.5 和图18.6 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 669, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 670\\n图18.5 遮挡图像风格转换（1）\\n图18.6 遮挡图像风格转换（2）\\n图中的左上角的图片内容图片，右上角为风格图片，左下角为遮挡图片，遮挡图片从内\\n容图片中获得，需要自己手动制作。遮挡图片中的白色部分会进行图像风格转换，黑色部分\\n保持不变。右下角为风格转换后的效果。\\n遮挡图像风格转换其实就是多了一个 Mask，其他部分跟之前的图像风格转换是一样的，\\n所以下面只给出遮挡部分的代码，这部分代码放在图像风格转换的代码后面即可，如代码\\n18-2 所示。。\\n代码18-2：遮挡图像风格转换\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 670, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 671\\n……\\n# mask图片路径\\nmask_path = 'mask.jpg'\\n# 载入mask图片\\ndef load_mask(mask_path, shape):\\n# 读取文件\\nmask = tf.io.read_file(mask_path)\\n# 变成图片格式\\nmask = tf.image.decode_image(mask, channels=1)\\nmask = tf.image.convert_image_dtype(mask, tf.float32)\\n# 获得生成图片的宽度和高度\\n_, width, height, _ = shape\\n# 把mask图片shape 变得跟生成图片一样\\nmask = tf.image.resize(mask, (width, height))\\nreturn mask\\n# 把mask应用到生成的图片中\\ndef mask_content(content, generated, mask):\\n# 生成图片的shape\\nwidth, height, channels = generated.shape\\n# 把内容图片变成numpy格式\\ncontent = content.numpy()\\n# 把生成图片变成numpy格式\\ngenerated = generated.numpy()\\n# mask图片黑色部分，把内容图片的像素值填充到生成图片中\\nfor i in range(width):\\nfor j in range(height):\\nif mask[i, j] == 0.:\\ngenerated[i, j, :] = content[i, j, :]\\nreturn generated\\n# 载入mask图片\\nmask = load_mask(mask_path, image.shape)\\n# 3 维降2 维\\ns_mask = tf.squeeze(mask)\\n# 4 维降3 维\\ns_image = tf.squeeze(image)\\n# 4 维降3 维\\ns_content_image = tf.squeeze(content_image)\\n# 把mask应用到生成的图片中\\nimg = mask_content(s_content_image,s_image,s_mask)\\n# 显示图片\\nimshow(img)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 671, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 672\\n18.4 参考文献\\n[1] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv\\npreprint arXiv:1508.06576, 2015.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 672, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 673\\n第 19 章 生成对抗网络 GANs\\n生成对抗网络（Generative Adversarial Networks，简称GANs）是近几年深度学习领\\n域一个非常热门的新的研究方向。最早是由“深度学习三巨头”之一 Yoshua Bengio的学\\n生Ian Goodfellow提出，相关论文为《Generative Adversarial Nets》[1]。经过几年时间\\n的发展，生成对抗网络已经从深度学习的一个新方向发展成为一个庞大的分支，是目前深度\\n学习领域最有发展潜力的算法之一。本书的内容主要还是以入门为主，所以本章节主要还是\\n介绍关于生成对抗网络的基础知识和基本应用。\\n19.1 生成对抗网络的应用\\nGANs的应用非常多，下面列举了部分 GANs的常见应用。\\n1.图像生成\\n你能猜出图19.1 中这些人脸的共同点吗？\\n图 19.1 人脸图片[2]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 673, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 674\\n这些图片中的人都不是真人，他们都是由 GANs产生的假图片。GANs最擅长做的事就\\n是生成假图片，不只可以生成假的人脸，理论上什么类型的图片它都可以生成。\\n2.向量空间运算\\n如图19.2 所示，我们可以看到戴眼镜的男人减去男人加上女人可以得到戴眼镜的女人。\\n图19.2 向量空间运算[3]\\n3.图像转换\\n如图19.4 所示，通过简笔画可以转换为真实的物体图像。\\n图 19.3 图像转换[4]\\n4.图像风格转换\\n如图19.4，最左边的一张图片可以转换为右边的 4 种不同的图像风格。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 674, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 675\\n图19.4 图像风格转换[5]\\n5.文字转图像\\n如图19.5，给模型传入一段文字，输出的结果为一张图片。\\n图 19.5 文字转图像[6]\\n6.图像渐变\\n如图19.6，一张图片逐渐变化成另一张图片。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 675, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 676\\n19.6 图像渐变[7]\\n7.超分辨率\\n如图19.7 所示，提升图像的分辨率。\\n图 19.7 超分辨率[8]\\n19.2 DCGAN 介绍\\n19.2.1 DCGAN 原理\\n下面我们主要以DCGAN为例，给大家介绍DCGAN的模型设计思路和程序实现，最早\\n提出DCGAN的论文是《Unsupervised Representation Learning with Deep\\nConvolutional Generative Adversarial Networks》[3]。\\n生成对抗网络的核心思想是同时训练两个相互协作，同时又相互竞争的深度神经网络，\\n一个称为生成器 （Generator），另一个称为判别器 （Discriminator）。生成器用来生成\\n假图片，而判别器用来判断图片的真假。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 676, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 677\\n比如我们可以把警察看成是判别器，把制造假币的犯罪份子看成是生成器。在一开始的\\n时候警察是不知道如何判断真钱和假币的，犯罪份子也不知道如何制造假币，他们会同时开\\n始学习。一段时间后警察的判断能力提高了，他可以识别出哪些是犯罪份子制作的假币，哪\\n些是真钱了，并把识别的过程告诉犯罪份子。犯罪份子根据警察的反馈改进自己的制作工\\n艺，制作出更逼真的假币给警察识别。警察在识别假币的过程中判别能力不断提升，犯罪份\\n子在制作假币的过程中制假能力不断提升。最终犯罪份子可以制作出警察无法判断真假的假\\n币，这个时候模型训练就成功了。\\n19.2.2 转置卷积（Transposed Convolution）介绍\\n生成器网络中使用到了转置卷积（Transposed Convolution），所以这里我们先来了\\n解一下。普通的卷积操作是一种下采样（Subsampled）操作，会使得图像的分辨率从大变\\n小。而转置卷积是一种上采样（Upsampling）操作，会使得图像的分辨率从小变大。\\n下面举两个例子给大家说明。\\n比如我们使用3×3 的卷积核对4×4 的图像进行卷积计算，步长为1，Valid Padding，\\n卷积计算后可以得到2×2 的特征图，如图 19.8 所示。\\n图19.8 普通卷积（1）\\n当我们使用同样的条件：3×3 的卷积核，步长为 1，Valid Padding对2×2 的图像进行\\n转置卷积就可以得到4×4 的特征图，如图 19.9 所示。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 677, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 678\\n图19.9 转置卷积（1）\\n比如我们使用3×3 的卷积核对5×5 的图像进行卷积计算，步长为2，Valid Padding，\\n卷积计算后可以得到2×2 的特征图，如图 19.10 所示。\\n图19.10 普通卷积（2）\\n当我们使用同样的条件：3×3 的卷积核，步长为 2，Valid Padding对2×2 的图像进行\\n转置卷积就可以得到5×5 的特征图，如图 19.11 所示。\\n图19.11 转置卷积（2）\\n大家应该能从这里找到些规律了，同样的条件下，对卷积后得到的特征图进行转置卷积\\n可以得到原始图像的大小。不过要注意只是恢复图像的大小，图像的数值不一定会恢复。因\\n为转置卷积的本质还是卷积，转置卷积中的卷积计算跟普通卷积一致，卷积核的具体数值也\\n是需要通过模型训练得到。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 678, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 679\\n19.2.3 DCGAN 模型结构\\n下面我们以MNIST 数据生成为例来介绍DCGAN的模型结构。DCGAN由两部分模型组\\n成，生成器和判别器，如图19.12 所示。\\n图19.12 生成器和判别器\\n判别器的作用是判断一张图片是真还是假，属于二分类问题，所以模型的最后输出只需\\n要1 个神经元。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 679, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 680\\n而生成器的作用是生成假图片，生成器的输入是一个 100 维的随机数，其实也不一定要\\n是100 维，其他任意维度也可以。把随机数加上全连接层再Reshape就可以变成4 维图像\\n数据。然后再进行几次转置卷积，使得图像大小不断变大，最后输出 28×28 的图片。\\n我们把MNIST 数据集中的原始数据看成是真图片，然后把生成器生成的图片看成是假图\\n片。把真图片和假图片都传给判别器进行学习，提升判别器的判断能力，同时利用判别器来\\n提升生成器的造假能力。\\n19.3 手写数字图像生成\\n实现手写数字图像生成的代码如代码19-1 所示。\\n代码19-1：手写数字图像生成（片段1）\\nfrom tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Conv2DTransp\\nose,Reshape,Conv2D,Dropout,Flatten\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\n# Dataset中的buffer\\nbuffer_size = 60000\\n# 批次大小\\nbatch_size = 256\\n# 训练周期\\nepochs = 51\\n# 100 维的随机噪声\\nnoise_dim = 100\\n# 载入MNNIST数据，只需要训练集的图片就可以\\n(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\\n# reshape为4 维数据\\ntrain_images = train_images.reshape(-1, 28, 28, 1).astype('float32')\\n# 将图片归一化到 [0, 1] 区间内\\ntrain_images = train_images/ 255.0\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 680, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 681\\n# 定义Dataset，用于生成打乱后的批次数据\\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(\\nbatch_size)\\n# 定义生成器\\ndef generator_model():\\n# 顺序模型\\nmodel = tf.keras.Sequential()\\n# 传入噪声数据，然后与7*7*256个神经元进行全连接\\n# 7*7*256主要是为了后面可以Reshape变成(7, 7, 256)\\nmodel.add(Dense(7*7*256, input_shape=(noise_dim,)))\\nmodel.add(BatchNormalization())\\nmodel.add(LeakyReLU())\\n# 变成4 维图像数据(-1,7,7,256)\\nmodel.add(Reshape((7, 7, 256)))\\n# 转置卷积，图像shape 变成(-1,7,7,128)\\nmodel.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\\nmodel.add(BatchNormalization())\\nmodel.add(LeakyReLU())\\n# 转置卷积，图像shape 变成(-1,14,14,64)\\nmodel.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\\nmodel.add(BatchNormalization())\\nmodel.add(LeakyReLU())\\n# 转置卷积，图像shape 变成(-1,28,28,1)\\n# 激活函数使用sigmoid，主要是因为我们把MNIST数据图片归一化为[0,1]之间了，生成\\n的假图片要跟真实图片数据匹配\\nmodel.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='sigmoi\\nd'))\\nreturn model\\n# 定义判别器\\ndef discriminator_model():\\n# 顺序模型\\nmodel = tf.keras.Sequential()\\n# 传入一张图片数据进行卷积，卷积后图像shape 为(1,14,14,64)\\nmodel.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\\nmodel.add(LeakyReLU())\\nmodel.add(Dropout(0.3))\\n# 卷积后图像shape 为(1,7,7,128)\\nmodel.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\\nmodel.add(LeakyReLU())\\nmodel.add(Dropout(0.3))\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 681, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 682\\nmodel.add(Flatten())\\n# 最后输出一个值，激活函数为sigmoid函数，用于判断图片的真假\\nmodel.add(Dense(1, activation='sigmoid'))\\nreturn model\\n# 创建生成器模型\\ngenerator = generator_model()\\n# 创建判别器模型\\ndiscriminator = discriminator_model()\\n# 生成随机数\\nnoise = tf.random.normal([1, noise_dim])\\n# 传入生成器生成一张图片\\ngenerated_image = generator(noise, training=False)\\n# 显示出图片，刚开始模型还没有训练，所以生成的图片会得到噪声图片\\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')\\nplt.show()\\n结果输出为：\\n代码19-1：手写数字图像生成（片段2）\\n# 定义2 分类交叉熵代价函数\\ncross_entropy = tf.keras.losses.BinaryCrossentropy()\\n# 判别器loss，传入对真实图片的判断结果以及对假图片的判断结果\\ndef discriminator_loss(real_output, fake_output):\\n# tf.ones_like(real_output)表示对真实图片的判断结果应该全为1\\nreal_loss = cross_entropy(tf.ones_like(real_output), real_output)\\n# tf.zeros_like(fake_output)表示对假图片的判断结果应该全为 0\\nfake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\\n# 求总loss，再返回\\ntotal_loss = real_loss + fake_loss\\nreturn total_loss\\n# 生成器loss，传入判别器对假图片的判断结果\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 682, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 683\\ndef generator_loss(fake_output):\\n# 对于生成器来说，生成器希望判别器对假图片的判断结果都是1\\n# 所以标签设定为tf.ones_like(fake_output)，全为1\\n# 生成器模型在训练过程中会不断优化自身参数，使得模型生成逼真的假图片\\nreturn cross_entropy(tf.ones_like(fake_output), fake_output)\\n# 由于我们需要分别训练两个网络，判别器和生成器的优化器是不同的。\\ngenerator_optimizer = tf.keras.optimizers.Adam(3e-4)\\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\\n# 把生成器模型和判别器模型以及对应的优化器存入 checkpoint\\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\\ndiscriminator_optimizer=discriminator_optimizer,\\ngenerator=generator,\\ndiscriminator=discriminator)\\n# 用于管理模型\\n# checkpoint为需要保存的内容\\n# 'checkpoint_dir'为模型保存位置\\n# max_to_keep设置最多保留几个模型\\nmanager = tf.train.CheckpointManager(checkpoint, 'checkpoint_dir', max_to_keep=3)\\n# 我们将重复使用该随机数，这个随机数用于在训练过程中生成图片并显示和保存\\nseed = tf.random.normal([16, noise_dim])\\n# 我们可以用@tf.function 装饰器来将 python 代码转成tensorflow 的图表示代码，用于加速\\n代码运行速度\\n@tf.function\\n# 定义模型的训练\\ndef train_step(images):\\n# 生成一个批次的随机数，这个随机数用于模型训练\\nnoise = tf.random.normal([batch_size, noise_dim])\\n# 固定写法，使用tf.GradientTape()来计算梯度\\nwith tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\\n# 产生一个批次的假图片\\ngenerated_images = generator(noise, training=True)\\n# 传入真图片到判别器中，得到预测结果\\nreal_output = discriminator(images, training=True)\\n# 传入假图片到判别器中，得到预测结果\\nfake_output = discriminator(generated_images, training=True)\\n# 计算生成器loss\\ngen_loss = generator_loss(fake_output)\\n# 计算判别器loss\\ndisc_loss = discriminator_loss(real_output, fake_output)\\n# 传入loss和模型参数，计算生成器的权值调整\\ngradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 683, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 684\\n# 传入loss和模型参数，计算判别器的权值调整\\ngradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variabl\\nes)\\n# 生成器的权值调整\\ngenerator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_var\\niables))\\n# 判别器的权值调整\\ndiscriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trai\\nnable_variables))\\n# 生成图片并保存显示\\ndef generate_and_save_images(model, epoch, test_input):\\n# 注意training设定为False，所有层都在预测模式下运行\\npredictions = model(test_input, training=False)\\n# 画16 张子图\\nfor i in range(16):\\nplt.subplot(4, 4, i+1)\\n# 显示图片\\nplt.imshow(predictions[i, :, :, 0], cmap='gray')\\n# 不显示刻度\\nplt.axis('off')\\n# 保存图片\\nplt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\\n# 显示图片\\nplt.show()\\n# 训练模型\\ndef train(dataset, epochs):\\n# 训练epochs周期\\nfor epoch in range(epochs):\\n# 每次获得一个批次的真实图片传入 train_step函数进行训练\\nfor image_batch in dataset:\\ntrain_step(image_batch)\\n# 显示和保存图片\\ngenerate_and_save_images(generator, epoch, seed)\\n# 每 5 个 epoch 保存一次模型\\nif epoch % 5 == 0:\\n# 保存模型\\n# checkpoint_number设置模型编号\\nmanager.save(checkpoint_number=epoch)\\n# 模型训练\\ntrain(train_dataset, epochs)\\n结果输出为：\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 684, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 685\\n……\\n……\\n最后训练得到的生成图片已经比较接近真实的 MNIST 数据集的图片了，有些假图片看起\\n来就跟真的一样。\\n19.4 参考文献\\n[1] Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative adversarial\\nnets[C]//Advances in neural information processing systems. 2014: 2672-2680.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 685, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 686\\n[2] Karras T, Laine S, Aila T. A style-based generator architecture for generative\\nadversarial networks[C]//Proceedings of the IEEE conference on computer vision and\\npattern recognition. 2019: 4401-4410.\\n[3] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep\\nConvolutional Generative Adversarial Networks [J]. arXiv preprint arXiv:1511.06434,\\n2015.\\n[4] Isola P, Zhu J Y, Zhou T, et al. Image-to-image translation with conditional\\nadversarial networks[C]//Proceedings of the IEEE conference on computer vision and\\npattern recognition. 2017: 1125-1134.\\n[5] Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-\\nconsistent adversarial networks[C]//Proceedings of the IEEE international conference\\non computer vision. 2017: 2223-2232.\\n[6] Zhang H, Xu T, Li H, et al. Stackgan: Text to photo-realistic image synthesis with\\nstacked generative adversarial networks[C]//Proceedings of the IEEE international\\nconference on computer vision. 2017: 5907-5915.\\n[7] Brock A, Donahue J, Simonyan K. Large scale gan training for high fidelity natural\\nimage synthesis[J]. arXiv preprint arXiv:1809.11096, 2018.\\n[8] Ledig C, Theis L, Huszár F, et al. Photo-realistic single image super-resolution\\nusing a generative adversarial network[C]//Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition. 2017: 4681-4690.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 686, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 687\\n第 20 章 模型部署\\n这一章节我们来了解一下模型部署。深度学习的模型训练好以后要在工程中应用，需要\\n部署到服务器中。其实就是我们需要运行一个用于数据预测的后台服务程序，这个后台服务\\n程序中运行着我们训练好的模型，然后等待其他客户端程序把数据传给用于数据预测的后台\\n服务程序。后台服务程序把接收到的数据传给模型进行预测，再把模型的预测结果返回给客\\n户端程序。如图20.1 所示。\\n图20.1\\n后台的服务程序可以自行编写，也可以使用谷歌官方提供的模型部署工具 Tensorflow\\nServing。推荐在 Docker中搭建Tensorflow Serving。\\n20.1 Tensorflow Serving 环境部署\\nTensorflow Serving是一个用于为机器学习模型提供灵活高性能服务的系统，专为生产\\n环境设计。使用Tensorflow Serving我们可以很容易的部署新的模型到生产环境中。\\nTensorflow Serving有多种安装方式，不过Tensorflow 官方建议我们使用Docker来\\n安装Tensorflow Serving，所以下面给大家介绍在Docker中搭建Tensorflow Serving的\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 687, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 688\\n环境的方法。Docker是一种轻量级的虚拟化技术，和传统的虚拟机不同，Docker启动速度\\n更快，性能更好，占用的内存和硬盘空间小，并且具有更好的迁移性，所以近几年得到了快\\n速发展和大规模的应用。\\n20.1.1 安装 Docker\\n首先第一步我们需要先安装Docker，Docker可以在Linux，MacOS 和Windows环境\\n下安装，软件下载的官网地址为：https://docs.docker.com/get-docker/。具体安装方式\\n可以查看官网说明。\\n如果我们需要使用GPU的话，还需要安装NVIDIA的Docker工具nvidia-docker，安\\n装方式可以查看：https://github.com/NVIDIA/nvidia-docker#quick-start。不过nvidia-\\ndocker目前只支持Linux的系统。\\n20.1.2 拉取 Tensorflow Serving 镜像\\n安装并运行Docker以后，在命令提示符中执行：\\ndocker pull tensorflow/serving\\n默认下载最新版本的Tensorflow Serving 镜像。如果是下载最新版本的GPU版本的镜\\n像，可以执行：\\ndocker pull tensorflow/serving:latest-gpu\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 688, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 689\\n20.2 运行客户端和服务器程序\\n20.2.1 准备 SavedModel 模型\\n在本书第7 章，介绍Tensorflow 模型的保存和载入的时候，有介绍过SavedModel 是\\nTensorflow 中一种模型的格式，它的优点是与语言无关。在Tensorflow Serving中所使用\\n的模型要求必须为SavedModel 格式的模型。下面作为演示，我们可以先产生一个\\nSavedModel 模型，如代码20-1 所示。\\n代码20-1：生成SavedModel 模型\\nimport tensorflow as tf\\nfrom tensorflow.keras.optimizers import SGD\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# 把训练集和测试集的标签转为独热编码\\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n# 模型定义\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Flatten(input_shape=(28, 28), name='image'),\\ntf.keras.layers.Dense(10, activation='softmax', name='output')\\n])\\n# 定义优化器，代价函数\\nsgd = SGD(0.2)\\nmodel.compile(optimizer=sgd,\\nloss='mse',\\nmetrics=['accuracy'])\\n# 传入训练集数据和标签训练模型\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 689, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 690\\nmodel.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test,y_test))\\n# 保存模型为SavedModel格式\\n# 1 在这里用于表示模型的版本号\\nmodel.save('my_model/1')\\n结果输出为：\\nTrain on 60000 samples, validate on 10000 samples\\nEpoch 1/3\\n60000/60000 [==============================] - 2s 32us/sample - los\\ns: 0.0368 - accuracy: 0.7843 - val_loss: 0.0212 - val_accuracy: 0.880\\n8\\nEpoch 2/3\\n60000/60000 [==============================] - 2s 33us/sample - los\\ns: 0.0202 - accuracy: 0.8820 - val_loss: 0.0175 - val_accuracy: 0.896\\n4\\nEpoch 3/3\\n60000/60000 [==============================] - 2s 30us/sample - los\\ns: 0.0177 - accuracy: 0.8937 - val_loss: 0.0160 - val_accuracy: 0.904\\n0\\n我们训练了一个MNIST 图像识别模型，设置了模型的输入名称为“image”，模型的输\\n出名称为“output”，后面会用到。然后把模型保存到“my_model/1”文件夹中，这里的\\n1 表示模型的版本号。\\n20.2.2 启动 Tensorflow Serving 服务器程序\\n接下来我们就可以启动Tensorflow Serving的服务器程序了，就是我们需要运行一个后\\n台程序，在这个后台程序中载入SavedModel 模型，等待客户端程序传输数据。\\nTensorflow Serving支持gRPC和REST API两种请求方式。\\n我们需要在命令提示符中运行下面格式的命令，如图 20.2 所示。\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 690, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 691\\n图20.2 启动服务器程序命令\\n首先大家要注意这是一条比较长的命令，为了让大家看清楚，所以我把这条长命令分为\\n了很多行。大家在命令行中运行的时候需要把“\\\\”符号去掉，然后组成一条连续的长命令。\\n还有就是大家需要注意什么地方有空格，什么地方没有空格，需要跟图中一致。比如\\n“run”，“-p”，“--mount”，“-e”，”-t”,“ {gRPC}:{gRPC}”，\\n“{Model_Name}”等后面是有空格的；”type=bind,””{SavedModel_Path},”后面是\\n没有空格的。\\ndocker run 表示在Docker中运行，{gRPC}表示填入gRPC端口号，可以自定义，\\n{REST API}表示填入 REST API端口号，可以自定义。Source={SavedModel_Path}表示填\\n入我们准备的SavedModel 模型的路径，注意要填入SavedModel 模型所在的绝对路径，\\n不包括版本号。target=/models/{Model_Name}表示把SavedModel 模型挂载到Docker\\n中的/models/{Model_Name}文件夹。MODEL_NAME={Model_Name}表示设置模型名\\n字，{Model_Name}表示模型名字，可以自定义。最后的 tensorflow/serving表示运行\\ntensorflow/serving。如果要用GPU的话可以改成tensorflow/serving:latest-gpu。当然\\n前提是前面已经安装nvidia-docker并拉取tensorflow/serving:latest-gpu 镜像。\\n我的SavedModel 保存在$(pwd)/my_model/1 文件夹下，下面给大家看一下我这里运\\n行的一个完整命令，$(pwd)表示当前位置的绝对路径：\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 691, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 692\\ndocker run -p 8500:8500 -p 8501:8501 --mount\\ntype=bind,source=$(pwd)/my_model,target=/models/my_model -e\\nMODEL_NAME=my_model -t tensorflow/serving\\n如果运行成功的话，会看到很多输出信息，如：\\n2020-05-23 10:04:05.996573: I tensorflow_serving/model_servers/serve\\nr.cc:86] Building single TensorFlow model file config: model_name: m\\ny_model model_base_path: /models/my_model\\n2020-05-23 10:04:05.998649: I tensorflow_serving/model_servers/serve\\nr_core.cc:462] Adding/updating models.\\n2020-05-23 10:04:05.998684: I tensorflow_serving/model_servers/serve\\nr_core.cc:573] (Re-)adding model: my_model\\n2020-05-23 10:04:06.126071: I tensorflow_serving/core/basic_manager.\\ncc:739] Successfully reserved resources to load servable {name: my_mo\\ndel version: 1}\\n2020-05-23 10:04:06.126126: I tensorflow_serving/core/loader_harnes\\ns.cc:66] Approving load for servable version {name: my_model version:\\n1}\\n2020-05-23 10:04:06.126144: I tensorflow_serving/core/loader_harnes\\ns.cc:74] Loading servable version {name: my_model version: 1}\\n2020-05-23 10:04:06.126589: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/reader.cc:31] Reading SavedModel from: /models/my_model/\\n1\\n2020-05-23 10:04:06.133228: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/reader.cc:54] Reading meta graph with tags { serve }\\n2020-05-23 10:04:06.133263: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/loader.cc:264] Reading SavedModel debug info (if presen\\nt) from: /models/my_model/1\\n2020-05-23 10:04:06.134544: I external/org_tensorflow/tensorflow/cor\\ne/platform/cpu_feature_guard.cc:142] Your CPU supports instructions\\nthat this TensorFlow binary was not compiled to use: AVX2 FMA\\n2020-05-23 10:04:06.184545: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/loader.cc:203] Restoring SavedModel bundle.\\n2020-05-23 10:04:06.241474: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/loader.cc:152] Running initialization op on SavedModel b\\nundle at path: /models/my_model/1\\n2020-05-23 10:04:06.245208: I external/org_tensorflow/tensorflow/cc/\\nsaved_model/loader.cc:333] SavedModel load for tags { serve }; Statu\\ns: success: OK. Took 118607 microseconds.\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 692, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 693\\n2020-05-23 10:04:06.246544: I tensorflow_serving/servables/tensorflo\\nw/saved_model_warmup.cc:105] No warmup data file found at /models/my\\n_model/1/assets.extra/tf_serving_warmup_requests\\n2020-05-23 10:04:06.258998: I tensorflow_serving/core/loader_harnes\\ns.cc:87] Successfully loaded servable version {name: my_model versio\\nn: 1}\\n2020-05-23 10:04:06.265112: I tensorflow_serving/model_servers/serve\\nr.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ...\\n[warn] getaddrinfo: address family for nodename not supported\\n2020-05-23 10:04:06.272848: I tensorflow_serving/model_servers/serve\\nr.cc:378] Exporting HTTP/REST API at:localhost:8501 ...\\n[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\\n大家看到类似信息说明Tensorflow Serving的服务程序已经在后台运行了，在打印的信\\n息中我们可以看到“Running gRPC ModelServer at 0.0.0.0:8500”和\\n“Exporting HTTP/REST API at:localhost:8501”，这两个信息在客户端程序中需\\n要使用。\\n20.2.3 Tensorflow Serving 客户端 gRPC 程序\\n使用gPRC程序我们需要先安装tensorflow-serving-api，打开命令提示符，输入命\\n令：\\npip install tensorflow-serving-api\\n然后我们还需要在命令行使用saved_model_cli 命令查看SavedModel 模型的一些基本\\n信息：\\nsaved_model_cli show --dir my_model/1 --all\\n这里的my_model/1 为我的SavedModel 模型位置。运行该命令后我们会看到很多输\\n出信息，其中比较重要的部分如下：\\nsignature_def['serving_default']:\\nThe given SavedModel SignatureDef contains the following input(s):\\ninputs['image_input'] tensor_info:\\ndtype: DT_FLOAT\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 693, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 694\\nshape: (-1, 28, 28)\\nname: serving_default_image_input:0\\nThe given SavedModel SignatureDef contains the following output(s):\\noutputs[\\'output\\'] tensor_info:\\ndtype: DT_FLOAT\\nshape: (-1, 10)\\nname: StatefulPartitionedCall:0\\nMethod name is: tensorflow/serving/predict\\n这里我们可以看到模型的签名signature 为[\\'serving_default\\']，我们之前没有设置过模\\n型的签名，所以这里使用的是默认签名。模型的输入 inputs 为[\\'image_input\\']，其实就是在\\n我之前设置的模型输入名称“image”基础上增加了“_input”。模型的输出outputs为\\n[\\'output\\']，跟我之前设置的模型输出名一样。实现客户端gRPC程序的代码如代码20-2 所\\n示。\\n代码20-2：客户端gRPC程序（片段1）\\nfrom tensorflow_serving.apis import predict_pb2\\nfrom tensorflow_serving.apis import prediction_service_pb2_grpc\\nimport grpc\\n# 向TensorFlow Serving 服务请求预测结果。\\ndef request_server(img, server_url):\\n# 为服务器创建一个通道\\nchannel = grpc.insecure_channel(server_url)\\n# 在客户端中实现stub，利用这个stub 可以调用相应的服务器中的服务\\nstub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\\n# 定义请求\\nrequest = predict_pb2.PredictRequest()\\n# 设置模型名称，需要跟启动tf-serving 服务器时模型的名字一样\\nrequest.model_spec.name = \"my_model\"\\n# 模型签名，可以使用saved_model_cli命令查看\\nrequest.model_spec.signature_name = \"serving_default\"\\n# 模型输入名称为\"image_input\"，之前模型保存的时候设置为\"image\"后面的\"_input\"是程\\n序自动加上的\\n# 设置要传输的数据img，数据的格式 tf.float32，数据的形状img.shape\\nrequest.inputs[\"image_input\"].CopyFrom(tf.make_tensor_proto(img, dtype=tf.float32, sha\\npe=img.shape))\\n# 传数据获得预测结果，最多等待5 秒\\nresponse = stub.Predict(request, 5.0)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 694, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 695\\n# output为模型输出名称，之前模型保存的时候设置的，变成 array后返回\\nreturn np.asarray(response.outputs[\"output\"].float_val)\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# x_test中第5 张图片标签为1\\nplt.imshow(x_test[5],cmap=\\'gray\\')\\n# 显示图片\\nplt.show()\\n结果输出为：\\n代码20-2：客户端gRPC程序（片段2）\\n# grpc地址及端口，启动tf-serving 服务器程序的时候有看到过\\nserver_url = \\'0.0.0.0:8500\\'\\n# 预测一个数据\\npre = request_server(x_test[5], server_url)\\nprint(\"预测结果为：\",np.argmax(pre))\\n结果输出为：\\n预测结果为： 1\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 695, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 696\\n代码20-2：客户端gRPC程序（片段3）\\n# 预测一个批次的数据，比如一次性预测 16 个数据\\nnum = 16\\n# 获得预测结果\\npre = request_server(x_test[:num], server_url)\\n# reshape变成16 行10 列\\npre = pre.reshape((num,10))\\nprint(\"预测结果为：\",np.argmax(pre,axis=1))\\nprint(\"真实标签为：\",y_test[:num])\\n结果输出为：\\n预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5]\\n真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\\n20.2.4 Tensorflow Serving 客户端 REST API 程序\\nTensorflow Serving还可以使用REST API请求，并且REST API看起来更简单一些。\\n实现客户端REST API程序的代码如代码 20-3 所示。\\n代码20-3：客户端REST API程序\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n# 载入数据集\\nmnist = tf.keras.datasets.mnist\\n# 载入数据，数据载入的时候就已经划分好训练集和测试集\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n# 对训练集和测试集的数据进行归一化处理\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\nimport json\\nimport numpy\\nimport requests\\n# 定义模型签名，可以使用saved_model_cli命令查看\\n# 定义instances，一次性传入16 张图进行预测\\ndata = json.dumps({\"signature_name\": \"serving_default\",\\n\"instances\": x_test[0:16].tolist()})\\n# 定义headers\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 696, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 697\\nheaders = {\"content-type\": \"application/json\"}\\n# 定义url，启动tf-serving 服务器程序的时候有看到过\\n# /models/my_model为模型挂载到Docker中的位置\\nurl = \\'http://localhost:8501/v1/models/my_model:predict\\'\\n# 传输数据进行预测，得到返回结果\\njson_response = requests.post(url, data=data, headers=headers)\\n# 对结果进行解析，然后变成array\\npre = numpy.array(json.loads(json_response.text)[\"predictions\"])\\nprint(\"预测结果为：\",np.argmax(pre,axis=1))\\nprint(\"真实标签为：\",y_test[:16])\\n结果输出为：\\n预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5]\\n真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 697, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 698\\n专业术语汇总\\n前言\\n全注释代码：本书中所使用的代码风格，最大的特点是注释所有程序。\\n第 1 章-深度学习介绍\\n深度学习（Deep Learning）：多层神经网络算法。上世纪60 年代叫做感知器，上世纪80 年\\n代叫做神经网络，21 世纪后改名为深度学习。\\n人工智能（Artificial Intelligence）：1956 年美国达特茅斯会上提出的一个抽象概念，它不\\n是任何具体的机器或算法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工\\n智能。\\n图灵测试（Turing Test）：具体解释见正文。\\n机器学习（Machine Learning）：人工智能是抽象的概念，那么就需要具体的算法让它落地，\\n机器学习就是一大类具体智能算法的统称。机器学习不是一个算法，而是很多算法的统称。使\\n用机器学习算法我们可以解决生活中如人脸识别，垃圾邮件分类，语音识别等具体问题。\\n训练集（Training Set）：可以用来训练，构建模型。\\n验证集（Validation Set）：模型训练阶段测试模型的效果。\\n测试集（Testing Set）：模型训练好之后最后再用于测试模型的效果。\\nK折交叉检验（K-fold Cross-Validation）：具体解释见正文。\\n监督学习（Supervised Learning）：具体解释见正文。\\n分类（Classification）：预测类别，并且类别是已知的。比如图像识别，文本分类都是属于分\\n类任务。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 698, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 699\\n回归（Regression）：预测数值，可以是连续型的数值。比如预测国家人口增长，公司销售业\\n绩等。\\n标签（Label）：数据的标签。\\n非监督学习（Unsupervised Learning）：具体解释见正文。\\n聚类（Clustering）：把数据划分成不同的类别，并且类别是未知的。比如某电商平台可以根\\n据用户的行为数据把用户划分为不同的聚类。\\n半监督学习（Semi-Supervised Learning）：具体解释见正文。\\n强化学习（Reinforcement Learning）：具体解释见正文。\\n决策树（Decision Tree）：具体解释见正文。\\n线性回归（Linear Regreesion）：具体解释见正文。\\nKNN（K-Nearest Neighbor）：具体解释见正文。\\n欧氏距离（Euclidean Distance）：也叫欧几里得距离，欧几里得空间中两点间直线的距离，\\n也就是我们日常生活中用得最多的距离计算方法。\\nK-Means：具体解释见正文。\\n神经网络（Neural Network）：具体解释见正文。\\n输入层（Input Layer）：神经网络的信号输入层。\\n隐藏层（Hidden Layers）：神经网络的中间的网络层。\\n输出层（Output Layer）：神经网络信号输出的层。\\n神经元（Neuron）：神经网络中的基本结构，大量的神经元组成了神经网络。\\n权值（Weights）：神经网络中可以变化的参数，神经网络的训练就是训练网络的权值。\\n激活函数（Activation Function）：神经元在进行信号汇总以后会经过一个激活函数后再输\\n出，激活函数的主要作用是给网络增加非线性。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 699, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 700\\n朴素贝叶斯（Naive Bayes）：经典的机器学习算法，朴素贝叶斯法是基于贝叶斯定理与特征\\n条件独立假设的分类方法。\\n支持向量机（Support Vector Machine）：简称SVM，经典的机器学习算法，支持向量机是\\n一类按监督学习方式对数据进行二分类的广义线性分类器，其决策边界是对学习样本求解的最\\n大边距超平面。\\nAdaboost：经典的机器学习算法，Adaboost是一种迭代算法，其核心思想是针对同一个训\\n练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分\\n类器（强分类器）。\\n弱人工智能（Weak AI）：具体解释见正文。\\n强人工智能（Strong AI）：具体解释见正文。\\n人工神经网络（Artificial Neural Networks）：简称ANN，人工构建的神经网络算法。\\n控制论（Cybernetics）：控制论看作是一门研究机器、生命社会中控制和通讯的一般规律的\\n科学，是研究动态系统在变的环境条件下如何保持平衡状态或稳定状态的科学。\\n联结主义（Connectionism）：又称为仿生学派（Bionicsism）或生理学派（Physiologism），\\n其原理主要为神经网络及神经网络间的连接机制与学习算法。\\n卷积神经网络（Convolutional Neural Network）：简称CNN，一种包含卷积计算的多层\\n网络结构，深度学习代表算法之一。在计算机视觉领域有着非常多的应用。\\n长短时记忆网络（Long Short Term Memory Network）：简称LSTM 是一种时间循环神\\n经网络，是为了解决一般的RNN（循环神经网络）存在的长期依赖问题而专门设计出来的。\\n深度残差网络（Deep Residual Network）：一种深度的卷积神经网络，网络层数可以多达上\\n百层，其中的残差结构是它的特色。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 700, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 701\\n感知器（Perceptron）：早期的神经网络模型，只有输入层和输出层，只能用于线性问题的求\\n解，不能解决非线性问题。\\nHopfield神经网络：Hopfield 神经网络是一种递归神经网络，由约翰·霍普菲尔德在1982 年\\n发明，现在已经基本不用了。\\n玻尔兹曼机（Boltzmann Machine）：是一种可通过输入数据集学习概率分布的随机生成神\\n经网，现在已经基本不用了。\\n受限玻尔兹曼机（Restricted Boltzmann Machine）：对玻尔兹曼机的改良，现在已经基本\\n不用了。\\nBP（Back Propagation）算法：多层感知器的误差反向传播算法，BP 神经网络也是整个神\\n经网络体系中的精华，广泛应用于分类识别，逼近，回归，压缩等领域。该算法从1986 年一\\n直沿用至今，在实际应用中，包括深度学习在内的大部分的神经网络都使用了 BP 算法。\\nBP 神经网络（Back Propagation Neural network）：主要指的是 20 世纪80-90 年代使用\\nBP 算法的多层神经网络。\\n深度置信网络（Deep Belief Net：DBN）：多个受限玻尔兹曼机堆叠而成，深度学习灵感的\\n开端。现在已经基本不用了。\\nNLP (Natural Language Processing) ：自然语言处理。\\nGPU（Graphics Processing Unit）：图形处理器，可用于打游戏，图像渲染或高性能计算。\\nTPU（Tensor Processing Unit）：Tensor处理器，专门用于机器学习计算。\\n第 3 章-单层感知器与线性神经网络\\n偏置值（Bias）：与输入信号无关的偏置信号。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 701, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 702\\nsign(x)激活函数：神经网络中最早使用的激活函数，当 x＞0 时，输出值为 1；当 x＝0 时，\\n输出值为0,；当x＜0 时，输出值为-1。\\n学习率（Learning Rate）：可以用来调节模型训练的速度快慢。\\n代价函数（Loss Function）：也称为目标函数或损失函数，通常用来定义模型的误差。\\n迭代周期（Epoch）：迭代周期。把所有训练集数据训练一次称为训练一个周期。\\n超参数（Hyperparameters）：机器学习或者深度学习中经常用到的一个概念，我们可以认为\\n是根据经验来人为设置的一些模型相关的参数。\\n参数（Parameters）：一般指的是模型中需要训练的变量，如模型的权值和偏置值。\\npurelin 函数：线性函数，y=x。\\n第 4 章-BP 神经网络\\n均方差（Mean-Square Error, MSE）：也称为二次代价函数，用来表示模型的误差，多用于\\n回归问题。\\n二次代价函数：也就是均方差代价函数。\\n导数（Derivative）：具体解释见正文。\\n偏导数（Partial Derivative）：具体解释见正文。\\n方向导数（Directional Derivative）：具体解释见正文。\\n梯度（Gradient）：具体解释见正文。\\n梯度下降法（Gradient Descent）：神经网络的常用的优化算法，用于最小化代价函数的值。\\n全局最小值（Global Minimum）：代价函数的最小值，只有一个。\\n局部极小值（Local Minimum）：代价函数的局部最小值，可能会有多个。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 702, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 703\\nsigmoid 函数：也称为逻辑函数。上世纪 80 年代，BP 神经网络中最开始使用的 S 型非线性\\n激活函数。取值范围0-1 之间，导数范围0-0.25 之间。\\ntanh函数：一种S 型非线性激活函数，取值范围-1-1 之间，导数范围0-1 之间。\\nsoftsign函数：一种S 型非线性激活函数，取值范围-1-1 之间，导数范围0-1 之间。\\nReLU 函数（The Rectified Linear Unit）：ReLU的中文名称是校正线性单元，一种模拟生\\n物神经元激活函数的新型非线性激活函数，广泛应用于深度学习中，可以用来抵抗梯度消失问\\n题。\\n欠拟合（Under-Fitting）：模型的拟合程度不够，训练集和测试集都无法得到很好的结果。\\n过拟合（Over-Fitting）：模型对训练集拟合程度过好，使得模型在训练集的预测结果比较好，\\n在测试集的预测结果比较差。\\n梯度消失（Vanishing Gradient）：误差反向传播过程中学习信号越来越小的现象。\\n梯度爆炸（Exploding Gradient）：误差反向传播过程中学习信号越来越大的现象。\\n稀疏性（Sparsity）：神经网络的稀疏性指的是网络中神经元输出为0 的数量，输出为 0 的神\\n经元数量越多，网络越稀疏。\\nL1正则化（L1 Regularization）：一种正则化手段，可以使得神经网络变得稀疏，所有网络\\n权值都会趋近于0，部分网络权值会变成 0。\\nDropout：一种正则化手段，在神经网络训练过程中让网络变稀疏进行训练。\\n准确率（Accuracy）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n精确率（查准率，Precision）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n召回率（查全率，Recall）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n第 6 章-网络优化方法\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 703, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 704\\n交叉熵（Cross Entropy）：一种代价函数，用于表示模型的误差，主要用于分类任务。\\n对数似然（Log Likelihood）代价函数：一种代价函数，用于表示模型的误差，主要用于分类\\n任务，与softmax函数搭配使用。\\n标签平滑（Label Smoothing）：也称为标签平滑正则化(label-smoothing regularization)，\\n简称LSR，一种正则化方法。通过调节数据标签的数值来达到抵抗过拟合的效果。\\n数据增强（Data Augmentation）：对现有数据进行处理，生成更多训练数据的方法。\\nEarly-Stopping：一种提前停止模型训练的策略。\\nL2 正则化（L2 Regularization）：一种正则化手段，会使所有网络权值都会趋近于 0，但是\\n一般不会等于0。\\n第 8 章-卷积神经网络 CNN\\nCV(Computer Vision)：计算机视觉。\\n卷积窗口（Convolution Window）：进行卷积计算的一个窗口。\\n特征图（Feature Map）：卷积计算后得到的用于表示图像特征的图。\\n视觉感受野（Receptive field of vision）：视网膜上一定的区域或范围。\\n局部感受野（Local Receptive Field）：卷积网络中的局部感受野指的是后一层神经元只连接\\n前一层的部分神经元。\\n权值共享（Weight Sharing）：同一卷积层中的同一个卷积窗口的权值是共享的。\\n卷积核（Convolution Kernel）：就是卷积窗口。\\n池化（Pooling）：卷积网络中常用的一种特征提取的计算。\\n最大池化（Max-Pooling）：提取池化窗口中的最大值。\\n平均池化(Mean-Pooling)：提取池化窗口中的平均值。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 704, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 705\\n随机池化(Stochastic Pooling)：提取池化窗口中随机一个值。\\nValid Padding：不会进行填充的一种 padding。\\nSame Padding：可能会进行填充的一种 padding。\\n滤波器（Filter）：由一个或多个不同的卷积核组成，一个滤波器可以产生一个特征图。\\n第 9 章-序列模型\\n循环神经网络（Recurrent Neural Network）：简称 RNN，一种常用的深度学习算法，专门\\n用来处理序列数据。\\nSimple Recurrent Networks (SRN)：早期的结构比较简单的循环神经网络。\\nSimpleRNN：早期的结构比较简单的循环神经网络。\\nSeq2Seq：Sequence to Sequence 模型，由编码器Encoder和解码器Decoder组成。可\\n以用于机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。\\n记忆块（Memory Block）：LSTM 网络中的核心结构。\\n遗忘门（Forget Gate）：LSTM 网络中用于控制信号遗忘的控制门。\\n输入门（Input Gate）：LSTM 网络中用于控制信号输入的控制门。\\n输出门（Output Gate）：LSTM 网络中用于控制信号输出的控制门。\\n记忆单元（Cell）：LSTM 网络中用于保存信号的单元。\\nHidden State：LSTM 的memory block 输出信号。\\nCell State：LSTM 的memory block 中间Cell位置的信号。\\n双向 RNN（Bidirectional RNN）：同时利用前向传递和反向传递的信号进行计算的 RNN。\\n第 10 章-经典图像识别模型介绍(上)\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 705, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 706\\n迁移学习（Transfer Learning）：深度学习中的迁移学习指的是把训练好的模型经过少量修\\n改和训练后，即可用于新的类似的任务中。\\n模型融合（Ensemble Model）：把多个不同的模型组合起来进行训练或预测，有可能会得到\\n更好的结果。\\nLRN（Local Response Normalization）：局部响应归一化。一种数据归一化计算，在AlexNet\\n和GoogleNet中曾使用。\\n批量标准化（Batch Normalization）：深度学习中常用的一种网络标准化操作，可以使得网\\n络输入的数据分布相对稳定，加速模型的训练。\\n退化问题（Degradation Problem）：网络模型层数越多，效果越差的现象。\\n残差块（Residual Block）：残差网络（ResNet）中的基本组成单元，用于解决退化问题。\\n第 11 章-经典图像识别模型介绍(下)\\n分组卷积（Group Convolution）：将特征图分为不同的组，再对每组特征图分别进行卷积。\\n第 12 章-图像识别项目实战\\n微调（Finetune）：对预训练的模型参数进行微调。\\n第 13 章-验证码识别项目\\n多任务学习（Multi-task Learning）：同时训练多个不同的任务。\\nCTC(Connectionist Temporal Classification)：用来解决输入序列和输出序列难以一一对\\n应的问题。主要用于语音识别和OCR(Optical Character Recognition)领域\\nOCR(Optical Character Recognition)：光学字符识别。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 706, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 707\\n贪心算法（Greedy Search）：对问题求解时，总是做出当前看来最好的选择，不一定能得到\\n全局最优解。\\n集束搜索算法（Beam Search）：对问题求解时，做出当前看来最好的N 个选择，不一定能得\\n到全局最优解。当N等于1 时就是贪心算法。\\n第 14 章-自然语言处理 NLP 发展历程（上）\\n语法规则（Grammar Rules）：语言使用的规则。\\n词性（Part of Speech）：词的词性，如名词，动词，形容词等\\n构词法（Morphologie）：研究词形变化现象和规则的学问。\\n上下文无关文法（Context Independent Grammar）：跟上下文无关的文法规则。\\n上下文相关文法（Context Dependent Grammar）：跟上下文相关的文法规则。\\n语料库（Corpus）：大量文本的数据集。\\n二元模型（Bigram Model）：一个词的出现概率只与它前面一个词相关。\\nN 元模型（N-Gram Model）：一个词的出现概率由前面 N-1 个词决定。\\n神经网络语言模型NNLM（Neural Net Language Model）：最早基于神经网络训练出来\\n的语言模型。\\n词向量（Word Embedding）：用一个向量来表达一个词包含的信息。\\nWord2vec：word to vector，将词转化为向量的一套训练方法。\\n连续词袋模型CBOW（Continuous Bag-of-Words）：通过上下文词汇预测中间词汇。\\nSkip-Gram 模型：通过中间词汇预测上下文词汇。\\n层次softmax（Hierarchical Softmax）：对softmax进行优化的一种策略，可以加快模型\\n训练速度。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 707, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 708\\n负采样（Negative Sampling）：具体解释见正文。\\n上下文向量（Context Vector）：Seq2Seq 中用来表示Encoder中整个序列的信息。\\nWordPiece：为了减少词汇数量，把词拆分为一片一片。\\n第 15 章-自然语言处理 NLP 发展历程（下）\\nLayer Normmalization：与 Batch Normalization 类似的一种归一化计算。 Layer\\nNormmalization 是计算一个数据中，所有特征维度的平均值和标准差，然后再对这个数据进\\n行归一化计算。\\n分词向量（Token Embeddings）：也就是词向量。\\n位置向量（Position Embeddings）：表示每个token的位置信息。\\n段落向量（Segment Embeddings）：用来标注哪几个token是第一句话，哪几个 token是\\n第二句话。\\n分词元素（Token）：分词的基本单位，可以是一个词汇或一个字符或其他自定义元素。\\n掩码语言模型（Masked Language Model）：简称MLM，Bert 模型中使用的训练方法，简\\n单的说就是完形填空。\\nMLM：掩码语言模型（Masked Language Model）。\\n预测下一个句子（Next Sentence Prediction）：简称 NSP，Bert 模型中使用的训练方法，\\n意思就是预测下一个句子。\\nNSP：预测下一个句子（Next Sentence Prediction）。\\nGLUE(General Language Understanding Evaluation): GLUE是一个自然语言任务集合\\n命名实体识别NER（Named Entity Recognition）：判断一个句子中的单词是不是人名，机\\n构名，地名，以及其他所有以名称为标识的实体。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 708, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 709\\n第 16 章-NLP 任务项目实战\\n维特比算法（Viterbi Algorithm）：维特比算法是应用最广泛的动态规划算法之一，主要应用\\n在数字通信，语音识别，机器翻译，分词等领域，用于求解最优路径问题。\\n条件随机场CRF（Conditional Random Field）：主要用于分词标注，词性标注，命名实体\\n识别等序列标注任务的无向图模型。\\n带泄露修正线性单元Leaky ReLU：ReLU的变形，当输入为负数时也有输出值和梯度都不为\\n0。\\n指数线性单元 ELU(Exponential Linear Unit)：ReLU的变形，当输入为负数时也有输出值\\n和梯度都不为0。\\n扩展指数线性单元SELU(Scaled Exponential Linear Unit)：ReLU的变形，可以使得神经\\n网络每一层的激活值都会满足均值接近于 0，标准差接近于1 的正态分布。\\n自归一化神经网络(Self-Normalizing Neural Networks)：简称为SNN，表示使用了SELU\\n激活函数的网络。\\nSNN：自归一化神经网络。\\nAlpha Dropout：Alpha Dropout是一种保持信号均值和方差不变的 Dropout，改层的作用\\n是即使在Dropout的时候也保持数据的自规范性\\n高斯误差线性单元GELU(Gaussian Error Linear Unit)：BERT 模型中使用的激活函数。\\nSwish：谷歌提出的一种较新的激活函数。\\n第 17 章-音频信号处理\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 709, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 710\\n自动语言识别(Automatic Speech Recognition)：简称ASR，将人的语音转换为文本的技\\n术。\\n梅尔滤波器组（Mel Filter Banks）：模拟人耳听力特点设计出来的一组滤波器。\\n梅尔频率倒谱系数 (Mel-frequency cepstral coefficients)：简称MFCC，梅尔频谱进行离\\n散余弦变换后得到的音频特征。\\n模拟信号（Analog Signal）：连续变化的物理量表示的信号。\\n数字信号（Digital Signal）：离散的数值信号。\\n采样频率（Sampling frequency）：信号采集速率。\\n量化位数（Quantization Bits）：对模拟信号进行数字化时的精度。\\n傅里叶变换（Fourier Transform）：将时域（Time Domain）信号转换为频域（Frequency\\nDomain）信号。\\n离散傅里叶变换（Discrete Fourier Transform）：简称 DFT，对离散的数值信号进行的傅里\\n叶变换。\\n快速傅里叶变换（Fast Fourier Transform）：简称FFT，FFT 是DFT的快速算法。\\n短时傅里叶变换（short-term Fourier transform）：简称 STFT，将信号加上滑动时间窗，\\n并对每个时间窗口内的数据进行FFT 称为 STFT。\\n时域（Time Domain）信号：表示信号强弱与时间的关系。\\n频域（Frequency Domain）信号：表示信号强弱与频率的关系。\\n频谱图（Spectrum）：一段时间内信号频率与强弱的关系图，可以通过傅里叶变换得到。\\n声谱图（Spectrogram）：由一段时间内的多张频谱图组成。\\n梅尔频谱（Mel Spectrogram）：声谱图经过梅尔滤波器组后得到梅尔频谱。\\n共振峰（Formants）：语音的主要频率成分。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 710, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 711\\n包络（Spectral Envelope）：将所有共振峰连接起来的平滑曲线。\\n包络细节（Spectral Details）:频谱曲线的高频信号。\\n倒谱（Cepstrum）：对频谱图再做一次傅里叶变换后得到。\\n伪频率（Pseudo-Frequency）：倒谱中的频率，并不是真正的音频信号的频率，它表示的是\\n频谱图中波形的频率。\\n离散余弦变换（Discrete Fourier Transform）：简称DCT，DCT 类似于DFT，DCT 只使用\\n实数。\\n第 18 章-图像风格转移\\n格拉姆矩阵（Gram Matrix）：计算图像特征图的 Gram 矩阵可以用于表示图像的风格，具体\\n计算见正文。\\n第 19 章-生成对抗网络 GANs\\n转置卷积（Transposed Convolution）：转置卷积又名反卷积（deconvolution）或是分数\\n步长卷积（fractially straced convolutions）。是一种上采样操作，卷积后可以得到分辨率更\\n大的图像。\\n下采样（Subsampled）：通过某些操作增加图像的分辨率。\\n上采样（Upsampling）：通过某些操作减小图片的分辨率。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 711, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 712\\n结束语\\n这本书的内容暂时到这里就结束了，不过对于大家的人工智能之旅才刚刚开始。这本书\\n的内容对大家来说只是一个起点，人工智能/深度学习领域还有更多更深入更有趣的技术和应\\n用等待大家学习和发现。\\n这本书对于我来说也只是一个新的起点，我之后还会不断更新更多人工智能相关的开源\\n教程。本书涉及的代码和资料也可以到我的 Github上查看和下载。\\n本书主页，以及源代码，资料下载：\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2\\n免费学习人工智能的慕课平台AI MOOC：\\nhttps://mooc.ai-xlab.com\\n提交错误或意见反馈可以到Github Issues页面提交：\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2/issues\\n我的B 站主页：\\nhttps://space.bilibili.com/390756902\\n我的微信公众号：\\nAI MOOC人工智能平台\\n联系邮箱：\\nqinbf@ai-xlab.com\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 712, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(\"深度学习从0到1-基于Tensorflow2.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "148b4a22-88db-4b18-aaaa-82a8e52da64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:40:11.688862Z",
     "iopub.status.busy": "2023-11-30T06:40:11.687780Z",
     "iopub.status.idle": "2023-11-30T06:40:11.703605Z",
     "shell.execute_reply": "2023-11-30T06:40:11.702613Z",
     "shell.execute_reply.started": "2023-11-30T06:40:11.688862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c5b993a-ec36-46d9-8df0-57a9a11050f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:40:11.704609Z",
     "iopub.status.busy": "2023-11-30T06:40:11.704609Z",
     "iopub.status.idle": "2023-11-30T06:40:11.719528Z",
     "shell.execute_reply": "2023-11-30T06:40:11.718558Z",
     "shell.execute_reply.started": "2023-11-30T06:40:11.704609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'file_path', 'page', 'total_pages', 'Title', 'Producer', 'Creator', 'CreationDate', 'ModDate'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "097bb8ab-fdbc-4628-bce7-e614f8724a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:41:18.368612Z",
     "iopub.status.busy": "2023-11-30T06:41:18.368612Z",
     "iopub.status.idle": "2023-11-30T06:41:18.380238Z",
     "shell.execute_reply": "2023-11-30T06:41:18.380238Z",
     "shell.execute_reply.started": "2023-11-30T06:41:18.368612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com 100\\n我们在图中随机选取两个w1 和w2 的初始值p1 和p2，然后从p1,p2 这两个初始位置\\n开始使用梯度下降法优化网络参数，得到如图 4.6 所示的结果。\\n图4.6 从p1,p2初始点开始优化网络\\n图4.6 中可以看到网络参数的优化过程其实就是p1,p2两个“小球“从初始点开始，每次\\n移动一步，不断向坡底进行移动。在这个过程中整个网络的 loss值是在不断变小的。\\n同时我们还可以观察到一个现象， p1“小球“最后走到了图中的 全局最小值（Global\\nMinimum），而p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我\\n们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果，有些时候我们可以\\n得到loss的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是 loss的局\\n部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存\\n在的一个缺点。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'file_path': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 100, 'total_pages': 713, 'Title': 'Microsoft Word - 深度学习从0到1-基于Tensorflow2的副本.docx', 'Producer': 'macOS 版本10.15.6（版号19G73） Quartz PDFContext', 'Creator': 'Word', 'CreationDate': \"D:20200902012857Z00'00'\", 'ModDate': \"D:20200902012857Z00'00'\"})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f452547-096c-4cd6-ac05-f7f137ec50db",
   "metadata": {},
   "source": [
    "# UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44729e44-ed46-43ee-95e1-c39fad21a5c5",
   "metadata": {},
   "source": [
    "## 不使用mode=\"elements\"\n",
    "\n",
    "直接加载一整个文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e373f5b2-d827-406a-aa18-b0f85b4d4db0",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T06:28:55.139363Z",
     "iopub.status.busy": "2023-11-30T06:28:55.139363Z",
     "iopub.status.idle": "2023-11-30T06:29:50.954150Z",
     "shell.execute_reply": "2023-11-30T06:29:50.954150Z",
     "shell.execute_reply.started": "2023-11-30T06:28:55.139363Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n0\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n说明\\n\\n本电子书为书籍原稿的开源版本，基本上没有进行什么排版，纸质书籍估计要 2021 年 3\\n\\n月后才能购买。\\n\\n本书虽然为开源电子书，但仅供个人学习使用。未经许可不能用于个人或企业的商业用\\n\\n途，违法盗版和销售，必究其法律责任。\\n\\n本书主页，以及源代码，资料下载：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2\\n\\n本书配套免费视频教程可以到免费学习人工智能的慕课平台 AI MOOC 学习：\\n\\nhttps://mooc.ai-xlab.com\\n\\n提交错误或意见反馈可以到 Github Issues 页面提交：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2/issues\\n\\n我的 B 站主页：\\n\\nhttps://space.bilibili.com/390756902\\n\\n我的微信公众号：\\n\\nAI MOOC 人工智能平台\\n\\n联系邮箱：\\n\\nqinbf@ai-xlab.com\\n\\n1\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n本书谨献给我的妻子刘露斯，以及正在阅读此书的各位读者朋友。\\n\\n愿人工智能给我们带来更美好的未来。\\n\\n2\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n序言\\n\\n本书的由来\\n\\n本书的序言可能有点长，因为这是我和大家的第一次见面，我希望可以把关于我和这本书\\n\\n的故事讲清楚，让大家对我有一个更好的了解，说不定哪天我们会成为朋友。\\n\\n大约在 3 年前的某个下午，电子工业出版社的张迪编辑联系到我，让我写一本关于人工智\\n\\n能的书。第一次有人找我写书，不免还是有些小激动，想象中写书是一件很酷的事情，真正写\\n\\n的时候才知道写书是一件很苦的事情。\\n\\n我毕业于上海大学物理系本科，大学期间做过很多嵌入式软硬件相关的开发项目。由于觉\\n\\n得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用，所以我在大学校内开过\\n\\n一年的嵌入式培训班，以更通俗易懂的方式和切合实际应用的内容给几百个本校同学（包括本\\n\\n科/硕士/博士）上过课。\\n\\n我最早是从 2015 年开始接触人工智能技术，公司内部刚好需要开发人工智能相关的产品。\\n\\n当时谷歌的深度学习框架 Tensorflow 都还没有开源，我主要是学习了一些机器学习相关的算\\n\\n法和应用。随着 Tensorflow 在 2015 年 11 月开源，AlphaGo 在 2016 年 3 月战胜人类顶级\\n\\n围棋选手，我知道新的人工智能的时代就要到来。2016 年我学习了当时最热门的两个深度学\\n\\n习框架 Tensorflow 和 Caffe 并用这两个框架完成了公司里面的一些深度学习项目。\\n\\n当时市面上关于深度学习的书籍和学习资料都非常少，所以在 2017 年的时候我录制了一\\n\\n些深度学习相关的视频教程放到了网上，就有了后来出版社找我写书的故事。几乎每个月都会\\n\\n有出版社的人联系我出书，我才知道原来获得出书的机会不难，真正难的是认真坚持把一本书\\n\\n3\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n给写完。这本书历时 3 年，不过也不是真的写了 3 年，写的过程中断断续续也暂停了很多次。\\n\\n我估算了一下真正写书的时间大概是用了 1200 个小时。\\n\\n最近两年我做了很多场人工智能的线下培训，给中国移动，中国电信，中国银行，华夏银\\n\\n行，太平洋保险，国家电网，中海油，格力电器等企业以及多个研究所的科研人员和多个高校\\n\\n的老师上过课，大家学完后的反馈基本上都是挺好的。虽然我这两年一直在从事人工智能的教\\n\\n育培训工作，但是我也一直没有真正下定决心要做人工智能教育培训这件事。因为现如今人工\\n\\n智能的各种学习资料已经很多了，网上也有各种人工智能专家大师的课程，这些专家大师基本\\n\\n上都是博士，教授或来自名企。并且从课程的包装上看，内容还是不错的。\\n\\n不过长期以来，我一直在关注人工智能技术和教育培训的发展。人工智能目前还处于高速\\n\\n发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分\\n\\n令人满意，还存在着许多问题。这些问题并不是几个专家大师所能解决的，而是需要更多人的\\n\\n努力和付出。\\n\\n人工智能教育是一件很有意义的事情，因为它有可能关乎国家，甚至人类的未来。尽管将\\n\\n会面临无数困难，我还是决定加入其中，以这本书作为开始。\\n\\n免费人工智能慕课平台 AI MOOC\\n\\nAI MOOC 是我自己创办的一个免费的人工智能慕课平台，网站地址为 https://mooc.ai-\\n\\nxlab.com。以后我会在上面不断更新最新的人工智能课程。我的目标是让所有人都能有机会\\n\\n学习到最前沿最好的人工智能课程。\\n\\n如果大家觉得我创作的内容不错，可以帮我多多宣传，感谢。\\n\\n4\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n人工智能的学习\\n\\n这里想跟大家简单聊一下关于人工智能的学习，人工智能是一门需要“内外兼修”的学科，\\n\\n既要修炼外功招式，又要进行内功修行。这里的外功招式主要指的是使用编程语言去实现一些\\n\\n人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。\\n\\n很多时候武功招式是很容易学的，可以短时间内快速提升，但同时也很容易达到一定的上\\n\\n限。如果想要突破上限更进一步，就要把内功给修炼好。所以我们在学习人工智能相关技术的\\n\\n时候，尽量把相关算法理论理解清楚，同时要多写代码提高编程能力，并在实践过程中加深对\\n\\n算法的理解。\\n\\n本书的特色\\n\\n本书的脉络框架主要是根据深度学习知识由浅入深的发展来编写的，对于 Tensorflow 的\\n\\n使用技巧基本上不会单独讲解，而是会结合深度学习理论知识或实际应用案例来讲解。所以很\\n\\n多 Tensorflow 的使用技巧在目录上可能没有得到很好的体现，这些 Tensorflow 使用技巧的\\n\\n彩蛋在书里的程序中等着大家发现哦！相信大家看完这本书以后就可以熟练掌握 Tensorflow\\n\\n的使用了。\\n\\n本书是一本“内外兼修”的书，既包含详细的算法理论的介绍，又包括详细的代码讲解。\\n\\n我一直在思考人工智能技术的教学方式，所以也形成了自己的教学风格和对教育的理解。这一\\n\\n套方式方法收到过很多同学的积极反馈，但也不一定适合所有人。我觉得不同的教学风格就像\\n\\n是不同类型的音乐，每个人喜欢的音乐类型可能都会不一样。AI 教育的发展需要各种类型的\\n\\n教学方式百花齐放。\\n\\n本书的主要特色总结如下：\\n\\n5\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n一.所有公式推导都有详细步骤，并解释每个符号。数学公式是算法的根本，要理解算法的\\n\\n本质就要理解数学公式的含义，所以掌握一些基础的深度学习相关的数学内容也是很重要的。\\n\\n大家看到数学一般都会比较头疼，所以本书中所有数学公式都会列出详细推导步骤，并解释每\\n\\n个相关符号的含义，帮助大家理解。\\n\\n二.注释每一行代码。我一直觉得我在教学中使用的代码具有一定个人风格，代码逻辑结构\\n\\n清晰，程序在容易理解的基础上尽量精简，最大的特点可能就是注释比代码多。我给这种代码\\n\\n风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得\\n\\n对于初学者而言，最好是可以理解每一行代码，每个函数，函数中所使用的每个参数，这样学\\n\\n习会感觉比较扎实。所以本书中所有代码都是全注释代码。\\n\\n三. 程序皆为完整程序。本书一共 82 个代码应用案例，所有的代码都是可以从头到尾运\\n\\n行的完整程序，并附带真实运行结果，不存在程序片段样例。我觉得程序片段对于初学者的学\\n\\n习不太友好，大家拿到一个程序片段往往还是不知道如何使用，或者用起来的时候出现很多错\\n\\n误，所以我在书中使用的所有程序都是可以从头到尾直接运行的完整程序。\\n\\n四.一图胜千言。深度学习中很多模型结构，计算流程之类的内容很难用公式或者语言表达\\n\\n清楚，但往往一张好的图片就可以说明一切。本书一共使用了约 500 张图片，在本书的创作\\n\\n过程中，大约有 200 个小时是花在画图以及思考如何画图上。\\n\\n五.逻辑结构清晰，讲解细致。这个不需要多介绍，大家看的时候就知道了。\\n\\n勘误和支持\\n\\n6\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7\\n\\n本书很多思想和知识体系都是我基于自己的理解建立的，由于本人水平有限，本书一定存\\n\\n在不少理解不当或者不准确的地方，恳请大家批评指正。如果大家有更多宝贵意见，欢迎发送\\n\\n邮件至邮箱 qinbf@ai-xlab.com\\n\\n， 或 者 到 我 的 Github 留言 ： https://github.com/Qinbf/Deep-Learning-\\n\\nTensorflow2/issues。期待大家的真挚反馈和支持。\\n\\n致谢\\n\\n在本书的撰写和研究期间，感谢我的妻子刘露斯对我的支持和鼓励。感谢我的朋友王惠东\\n\\n对本书部分章节的校阅。感谢电子工业出版社张迪编辑的耐心等待，感谢出版社对本书的耐心\\n\\n修订和整理。最后感谢各位读者朋友选择了这本书，感谢大家的信任。\\n\\n覃秉丰\\n\\n2020 年 9 月于上海\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n目录\\n\\n前言 第 1 章 深度学习背景介绍 1.1 人工智能 1.2 机器学习 1.2.1 训练数据，验证数据和测试数据 1.2.2 学习方式 1.2.3 机器学习常用算法 1.3 人工智能，机器学习，神经网络以及深度学习之间的关系 1.4 深度学习应用 1.5 神经网络深度学习发展史 1.5.1 神经网络诞生-20 时间 40-60 年代 1.5.2 神经网络复兴-20 时间 80-90 年代 1.5.3 深度学习-2006 年至今 1.6 深度学习领域重要人物 1.7 新一轮人工智能爆发的三要素\\n\\n第 2 章 搭建 Python 编程环境 2.1 Python 介绍 2.2 Anaconda 安装 2.3 Jupyter Notebook 的简单使用 2.3.1 启动 Jupyter Notebook 2.3.2 修改 Jupyter Notebook 默认启动路径 2.3.3 Jupyter Notebook 浏览器无法打开 2.3.4 Jupyter Notebook 基本操作\\n\\n第 3 章 单层感知器与线性神经网络 3.1 生物神经网络 3.2 单层感知器 3.2.1 单层感知器介绍 3.2.2 单层感知器计算举例 3.2.3 单层感知器的另一种表达形式 3.3 单层感知器的学习规则 3.3.1 单层感知器的学习规则介绍 3.3.2 单层感知器的学习规则计算举例 3.4 学习率 3.5 模型的收敛条件 3.6 模型的超参数和参数的区别 3.7 单层感知器分类案例 3.8 线性神经网络 3.8.1 线性神经网络介绍\\n\\n8\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 3.8.2 线性神经网络分类案例 3.9 线性神经网络处理异或问题\\n\\n第 4 章 单层感知器与线性神经网络 4.1 BP 神经网络介绍及发展背景 4.2 代价函数 4.3 梯度下降法 4.3.1 梯度下降法（Gradient Descent）介绍 4.3.2 梯度下降法（Gradient Descent）二维例子 4.3.3 梯度下降法（Gradient Descent）三维例子 4.4 Delta 学习规则 4.5 常用激活函数讲解 4.5.1 Sigmoid 函数 4.5.2 Tanh 函数 4.5.3 Softsign 函数 4.5.4 ReLU 函数 4.6 BP 网络模型和公式推导 4.6.1 BP 网络模型 4.6.2 BP 算法推导 4.6.3 BP 算法推导补充说明 4.7 BP 算法推导结论总结 4.8 梯度消失与梯度爆炸 4.8.1 梯度消失 4.8.2 梯度爆炸 4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题 4.9 使用 BP 神经网络解决异或问题 4.10 分类模型评估方法 4.10.1 准确率/精确率/召回率/F1 值 4.10.2 混淆矩阵 4.11 独热编码（One-Hot Encoding） 4.12 BP 神经网络完成手写数字识别 4.13 Sklearn 手写数字识别\\n\\n第 5 章 深度学习框架 Tensorflow 基础使用 5.1 Tensorflow 介绍 5.1.1 Tensorflow 简介 5.1.2 静态图和动态图机制 Eager Execution 5.1.3 tf.keras 5.2 Tensorflow-cpu 安装 5.2.1 Tensorflow-cpu 在线安装 5.2.2 安装过程中可能遇到的问题汇总 5.2.3 Tensorflow-cpu 卸载 5.2.4 Tensorflow-cpu 更新\\n\\n9\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 5.2.5 Tensorflow-cpu 指定版本的安装 5.3 Tensorflow-gpu 安装 5.3.1 Tensorflow-gpu 了解最新版本情况 5.3.2 Tensorflow-gpu 安装 CUDA 5.3.3 Tensorflow-gpu 安装 cuDNN 库 5.3.4 Tensorflow-gpu 在线安装 5.3.5 Tensorflow-gpu 卸载 5.3.6 Tensorflow-gpu 更新 5.4 Tensorflow 基本概念 5.5 Tensorflow 基础使用 5.5.1 TF1 转 TF2 工具 5.5.2 Tensorflow 基本操作 5.5.3 拟合线性函数 5.5.4 拟合非线性函数 5.6 手写数字图片分类任务 5.6.1 MNIST 数据集介绍 5.6.2 Softmax 函数介绍 5.6.3 简单 MNIST 数据集分类模型-没有高级封装 5.6.4 简单 MNIST 数据集分类模型-keras 高级封装\\n\\n第 6 章 网络优化方法 6.1 交叉熵代价函数 6.1.1 均方差代价函数的缺点 6.1.2 引入交叉熵代价函数 6.1.3 交叉熵代价函数推导过程 6.1.4 Softmax 与对数似然代价函数 6.1.5 交叉熵程序 6.2 过拟合（Over-Fitting） 6.2.1 什么是过拟合 6.2.2 抵抗过拟合的方法 6.3 数据增强（Data Augmentation） 6.4 提前停止训练（Early-Stopping） 6.5 Dropout 6.5.1 Dropout 介绍 6.5.2 Dropout 程序 6.6 正则化（Regularization） 6.6.1 正则化介绍 6.6.2 正则化程序 6.7 标签平滑（Label Smoothing） 6.7.1 标签平滑（Label Smoothing）介绍 6.7.2 标签平滑（Label Smoothing）程序 6.8 优化器（Optimizer） 6.8.1 梯度下降法 SGD\\n\\n10\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 6.8.2 Momentum 6.8.3 NAG（Nesterov Accelerated Gradient） 6.8.4 Adagrad 6.8.5 Adadelta 6.8.6 RMRprop 6.8.7 Adam 6.8.8 优化器程序\\n\\n第 7 章 Tensorflow 模型的保存和载入 7.1 交叉熵代价函数 7.1.1 Keras 保存模型 7.1.2 Keras 载入模型 7.2 SavedModel 模型保存和载入 7.2.1 SavedModel 保存模型 7.2.2 SavedModel 载入模型 7.3 单独保存模型结构 7.3.1 保存模型结构 7.3.2 载入模型结构 7.4 单独保存模型参数 7.4.1 保存模型参数 7.4.2 载入模型参数 7.5 ModelCheckpoint 自动保存模型 7.6 Checkpoint 模型保存和载入 7.6.1 Checkpoint 模型保存 7.6.2 Checkpoint 模型载入\\n\\n第 8 章 卷积神经网络 CNN 8.1 计算机视觉介绍 8.1.1 计算机视觉应用介绍 8.1.2 计算机视觉技术介绍 8.2 卷积神经网络简介 8.2.1 BP 神经网络存在的问题 8.2.2 局部感受野和权值共享 8.3 卷积的具体计算 8.4 卷积的步长 8.5 不同的卷积核 8.6 池化（Pooling） 8.7 Padding 8.8 常见的卷积计算总结 8.8.1 对 1 张图像进行卷积生成 1 张特征图 8.8.2 对 1 张图像进行卷积生成多张特征图 8.8.3 对多张图像进行卷积生成 1 张特征图 8.8.4 对多张图像进行卷积生成多张特征图\\n\\n11\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 8.9 经典的卷积神经网络 8.10 卷积神经网络应用于 MNIST 数据集分类 8.11 识别自己写的数字图片 8.12CIFAR-10 数据集分类\\n\\n第 9 章 序列模型 9.1 序列模型应用 9.2 循环神经网络 RNN 9.2.1 循环神经网络介绍 9.2.2 Elman network 和 Jordan network 9.3 RNN 的不同架构 9.3.1 一对一架构 9.3.2 多对一架构 9.3.3 多对多架构 9.3.4 一对多架构 9.3.5 Seq2Seq 架构 9.4 传统 RNN 的缺点 9.5 长短时记忆网络 LSTM 9.6 Peephole LSTM 和 FC-LSTM 9.6.1 Peephole LSTM 介绍 9.6.2 FC-LSTM 介绍 9.7 其他 RNN 模型 9.7.1 门控循环单元 GRU 9.7.2 双向 RNN（Bidirectional RNN） 9.7.3 Stacked Bidirectional RNN 9.8 LSTM 网络应用于 MNIST 数据集分类\\n\\n第 10 章 经典图像识别模型介绍（上） 10.1 图像数据集 ImageNet 10.1.1 ImageNet 介绍 10.1.2 李飞飞简介 10.1.3 ImageNet 的深远影响 10.1.4 ImageNet Challenge 历年优秀作品 10.2 AlexNet 10.3 VGGNet 10.4 GoogleNet 10.4.1 1×1 卷积介绍 10.4.2 Inception 结构 10.4.3 GoogleNet 网络结构 10.5 Batch Normalization 10.5.1 Batch Normalization 提出背景 10.5.2 数据标准化（Normalization） 10.5.3 Batch Normalization 模型训练阶段\\n\\n12\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 10.5.4 Batch Normalization 模型预测阶段 10.5.5 Batch Normalization 作用分析 10.6 ResNet 10.6.1 ResNet 背景介绍 10.6.2 残差块（Residual Block）介绍 10.6.3 ResNet 网络介绍 10.6.4 ResNet-V2\\n\\n第 11 章 经典图像识别模型介绍（下） 11.1 Inception 模型系列 11.1.1 Inception-v2/v3 优化策略 11.1.2 Inception-v2/v3 模型结构 11.1.3 Inception-v4 和 Inception-ResNet 介绍 11.2 ResNeXt 11.2.1 分组卷积（Group Convolution）介绍 11.2.2 ResNeXt 中的分组卷积 11.2.3 ResNeXt 的网络结构 11.3 SENet 11.3.1 SENet 介绍 11.3.2 SENet 结果分析\\n\\n第 12 章 图像识别项目实战 12.1 图像数据准备 12.1.1 数据集介绍 12.1.2 数据集准备 12.1.3 切分数据集程序 12.2 AlexNet 图像识别 12.3 VGGNet 图像识别 12.4 函数式（functional）模型 12.4.1 函数式（functional）模型介绍 12.4.2 使用函数式模型进行 MNIST 图像识别 12.5 模型可视化 plot_model 12.5.1 使用 plot_model 进行模型可视化 12.5.2 plot_model 升级版 12.6 GoolgeNet 图像识别 12.7 Batch Normalization 使用 12.8 ResNet 图像识别 12.9 ResNeXt 图像识别 12.10 SENet 图像识别 12.11 使用预训练模型进行迁移学习 12.11.1 使用训练好的模型进行图像识别 12.11.2 使用训练好的模型进行迁移学习 12.11.3 载入训练好的模型进行预测\\n\\n13\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 13 章 验证码识别项目实战 13.1 多任务学习介绍 13.2 验证码数据集生成 13.3 tf.data 介绍 13.4 使用 tf.data 完成多任务学习-验证码识别 13.4.1 使用 tf.data 完成多任务学习模型训练 13.4.2 使用 tf.data 完成多任务学习模型预测 13.5 使用自定义数据生成器完成验证码识别 13.5.1 使用自定义数据生成器完成模型训练 13.5.2 使用自定义数据生成器完成模型预测 13.6 挑战变长验证码识别 13.6.1 挑战变长验证码识别模型训练 13.6.2 挑战变长验证码识别模型预测 13.7 CTC 算法 13.7.1 CTC 算法介绍 13.7.2 贪心算法（Greedy Search）和集束搜索算法（Beam Search） 13.7.3 CTC 存在的问题 13.8 CTC 算法-验证码识别 13.8.1 使用 CTC 算法训练验证码模型 13.8.2 使用 CTC 算法训练验证码预测\\n\\n第 14 章 自然语言处理 NLP 发展历程（上） 14.1 多任务学习介绍 14.1.1 文本分类/情感分类 14.1.2 分词标注 14.1.3 机器翻译 14.1.4 聊天机器人 14.1.5 自动摘要 14.1.6 文章生成 14.1.7 图片描述 14.2 从传统语言模型到神经语言模型 14.2.1 规则模型 14.2.2 统计语言模型 14.2.3 词向量（word embedding） 14.2.4 神经语言模型 14.3 word2vec 14.3.1 word2vec 介绍 14.3.2 word2vec 模型训练 14.3.3 word2vec 训练 trick 和可视化效果 14.4 CNN 在 NLP 领域的使用 14.5 RNN 在 NLP 领域的使用 14.5.1 使用 RNN 进行文本分类\\n\\n14\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 14.5.2 使用 RNN 进行中文分词标注 14.6 Seq2Seq 模型在 NLP 领域的使用 14.7 Attention 机制 14.7.1 Attention 思想的介绍 14.7.2 Bahdanau Attention 介绍 14.7.3 Luong Attention 介绍 14.7.4 谷歌机器翻译系统 GNMT 介绍 14.7.5 Attention 机制在视觉和语音领域的应用\\n\\n第 15 章 自然语言处理 NLP 发展历程（下） 15.1 NLP 新的开始-Transformer 模型 15.1.1 Transformer 模型结构和输入数据介绍 15.1.2 Self-Attention 介绍 15.1.3 Multi-Head Attention 介绍 15.1.4 Layer Normalization 介绍 15.1.5 Decoder 结构介绍 15.1.6 Decoder 中的 Multi-Head Attention 和模型训练 15.2 BERT 模型 15.2.1 BERT 模型介绍 15.2.2 BERT 模型训练 15.2.3 BERT 模型应用\\n\\n第 16 章 NLP 任务项目实战 16.1 Python 介绍 16.1.1 项目数据和模型说明 16.1.2 一维卷积英语电影评论情感分类程序 16.2 二维卷积中文微博情感分类项目 16.3 双向 LSTM 中文微博情感分类项目 16.4 堆叠双向 LSTM 中文分词标注项目 16.4.1 中文分词标注模型训练 16.4.2 维特比算法（Viterbi Algorithm） 16.4.3 中文分词标注模型预测 16.5 最新的一些激活函数介绍 16.5.1 Leaky ReLU 16.5.2 ELU 16.5.3 SELU 16.5.4 GELU 16.5.5 Swish 16.6 BERT 模型简单使用 16.6.1 安装 tf2-bert 模块并准备预训练模型 16.6.2 使用 BERT 进行文本特征提取 16.6.3 使用 BERT 进行完形填空 16.7 BERT 电商用户多情绪判断项目\\n\\n15\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 16.7.1 项目背景介绍 16.7.2 模型训练 16.7.3 模型预测\\n\\n第 17 章 音频信号处理 17.1 深度学习在声音领域的应用介绍 17.1.1 音频分类 17.1.2 音频事件检测 17.1.3 语音识别 17.1.4 音乐检索 17.1.5 音乐生成 17.1.6 语音合成 17.1.7 语音克隆 17.2 MFCC 和 Mel Filter Banks 17.2.1 音频数据采集 17.2.2 分帧加窗 17.2.3 傅里叶变换 17.2.4 梅尔滤波器（Mel Filter Banks） 17.2.5 梅尔频率倒谱系数 MFCC 17.3 语音分类项目 17.3.1 音频处理库 librosa 介绍 17.3.2 音频分类项目-模型训练 17.3.3 音频分类项目-模型预测\\n\\n第 18 章 图像风格转换 18.1 图像风格转换实现原理 18.1.1 代价函数的定义 18.1.2 格拉姆矩阵（Gram Matrix）介绍 18.2 图像风格转换项目实战 18.3 遮挡图像风格转换项目实战\\n\\n第 19 章 生成对抗网络 GANs 19.1 生成对抗网络的应用 19.1.1 图像生成 19.1.2 向量空间运算 19.1.3 改变年龄或美颜 19.1.4 图像转换 19.1.5 文本转图像 19.1.6 超分辨率 19.1.7 换脸 19.2 DCGAN 介绍 19.2.1 DCGAN 原理 19.2.2 转置卷积（Transposed Convolution）介绍\\n\\n16\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 19.2.3 DCGAN 模型结构 19.3 手写数字图像生成\\n\\n第 20 章 模型部署 20.1 Tensorflow Serving 环境部署 20.1.1 安装 Docker 20.1.2 拉取 Tensorflow Serving 镜像 20.2 运行客户端和服务器程序 20.2.1 准备 SavedModel 模型 20.2.2 启动 Tensorflow Serving 服务器程序 20.2.3 Tensorflow Serving 客户端 gRPC 程序 20.2.4 Tensorflow Serving 客户端 REST API 程序\\n\\n专业术语汇总 结束语\\n\\n17\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 1 章-深度学习背景介绍\\n\\n本章主要介绍人工智能，机器学习，神经网络，深度学习相关的一些概念，应用，发展史\\n\\n以及重要人物等背景信息。这些背景知识虽然对我们的实际应用没有直接帮助，但是可以加深\\n\\n我们对人工智能这个行业的理解，属于内功修行的范畴。\\n\\n1.1 人工智能\\n\\n1997 年 5 月 3 日-1997 年 5 月 11 日一场别开生面的比赛在纽约的公平大厦举行，吸引\\n\\n了全世界的关注。对垒的双方分别是世界国际象棋冠军卡斯帕罗夫和 IBM 的超级计算机“深\\n\\n蓝”。经过六场激烈的比赛，“深蓝”最终战胜了卡斯帕罗夫，赢得了具有特殊意义的胜利。\\n\\n而这一次比赛也载入了人类的史册。\\n\\n而另一场可以载入人类史册的人机大战发生在 2016 年 3 月 9 日-2016 年 3 月 15 日。这\\n\\n一次比赛双方是世界顶级围棋棋手李世石和 Google 的人工智能 AlphaGo。赛前有很多人并\\n\\n不看好 AlphaGo，认为 AlphaGo 会惨败。没想到 AlphaGo 最终以 4:1 大胜李世石，从而一\\n\\n战成名。由于 AlphaGo 的胜利，AlphaGo 用到的深度学习（Deep Learning）技术以及人\\n\\n工智能（Artificial Intelligence）也成为了当下最热门的技术话题。\\n\\n人工智能（Artificial Intelligence），英文缩写 AI。AI 第一次被提出来是在 1956 年，是\\n\\n由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议 （Dartmouth\\n\\nConference）上一同定义出来的。人工智能只是一个抽象概念，它不是任何具体的机器或算\\n\\n法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。比如几年前我们\\n\\n去洗车的时候会看到洗车店写着自动化洗车，看起来很高级。今天我们再去看，可能它改成了\\n\\n18\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n人工智能洗车，看起来更高级。实际上它的技术并没有改变，只是改了一个名字。随着人工智\\n\\n能技术的大热，很多商品都挂上了人工智能的标签，实际上任何看起来有一点智能的算法和机\\n\\n器都可以称为人工智能，所以人工智能这个标签并不能代表某个商品的技术水平。\\n\\n提到人工智能，不得不说到一个非常著名的关于人工智能的测试，图灵测试（Turing Test）。\\n\\n图灵测试是由计算机科学之父图灵提出来的，指的是测试者和被测试者（被测试者有可能是人\\n\\n或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之\\n\\n后，如果有 30%的测试者不能确定被测试者是人还是机器，那么说明这台机器通过了测试。\\n\\n虽然图灵测试早在 1950 年被提出，但是至今没有机器能够很好地通过图灵测试。偶尔会\\n\\n有一些新闻报道说某某机器通过了图灵测试，但是这些通过图灵测试的机器往往会受到很多人\\n\\n质疑，并且经不住多次实验。\\n\\n人工智能早期阶段，迅速解决了一些对于人类来说比较困难，但是对于计算机来说相对容\\n\\n易的问题，比如下棋，推理，路径规划等等。我们下象棋的时候，通常需要思考很久才能推算\\n\\n出几步棋之后棋盘战局的变化，并且经常还会有看错看漏的情况。而计算机能在一瞬间计算出\\n\\n七八步棋甚至十几步棋之后棋盘的情况，并从中选出对自己最有利的下法来与对手对弈。面对\\n\\n如此强大的对手，人类早在 20 年前就已经输了。可能有人会想到人工智能在象棋领域早就战\\n\\n胜了人类最顶尖的选手，为什么在围棋领域一直到 2016 年才出了个 AlphaGo 把人类顶级棋\\n\\n手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋 AI 的时候可\\n\\n以使用暴力计算的方法，把几步之内所有可能的走法都遍历一次，然后选一个最优下法。同样\\n\\n的方法放到围棋上就行不通了，围棋每一步的可能性都太多了，用暴力计算法设计出来的围棋\\n\\nAI，它的棋力是很差的。虽然 AlphaGo 的计算非常快，可以在短时间完成大量运算，但是\\n\\nAlphaGo 比其他棋类 AI 强的地方并不是计算能力，而是它的算法，也可以理解为它拥有更强\\n\\n大的“智慧”。就像是进行小学速算比赛，题目是 100 以内的加减法，10 个小学生为一队，\\n\\n19\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1 个数学系的博士为另一队。如果比赛内容是 1 分钟哪个队做的正确题目多，小学生队肯定是\\n\\n能够战胜数学博士的。如果是进行大学生数学建模比赛，那 10000 个小学生也赢不了 1 个数\\n\\n学博士。对于解决复杂的问题，需要的往往不只是计算速度，更多的应该是智慧。\\n\\n对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完\\n\\n成得很差。人类的视觉从眼睛采集信息开始，但起到主要作用的是大脑。人类的每个脑半球中\\n\\n都有着非常复杂的视觉皮层，包含着上亿个神经元以及几百亿条神经元之间的连接。人类的大\\n\\n脑就像是一台超级计算机，可以轻松处理非常复杂的图像问题。神经元之间的电信号可以快速\\n\\n传递，但是就像前面说到的，对于复杂的问题，计算速度只是一方面。人类的视觉能力是通过\\n\\n几亿年地不断进化，不断演变最终才得到的，更强的视觉和听觉能力使得人类可以拥有更强的\\n\\n生存能力。\\n\\n在人工智能的早期阶段，计算机的智能通常是基于人工制定的“规则”，我们可以通过详\\n\\n细的规则去定义下棋的套路，推理的方法，以及路径规划的方案。但是我们却很难用规则去详\\n\\n细描述图片中的物体，比如我们要判断一张图片中是否存在猫。那我们首先要通过规则去定义\\n\\n一只猫，如图 1.1 所示。\\n\\n图 1.1 猫（Cat）\\n\\n观察图 1.1 中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身\\n\\n体，和一条长尾巴，然后可以定义一套规则在图片中寻找猫。这看起来好像是可行的，但是\\n\\n20\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n如果我们遇到的是图 1.2，图 1.3 中的猫该怎么办？（我家领养的猫，刚来的时候上厕所比较\\n\\n臭，故取名“臭臭”）\\n\\n图 1.2 藏起来的“臭臭”\\n\\n图 1.3 盘成一团的“臭臭”\\n\\n猫可能只露出身体的一部分，可能会摆出奇怪的造型，那么我们又要针对这些情况定义\\n\\n新的规则。从这个例子中大家应该能看得出来，即使是一只很普通的家养宠物，都可能会出\\n\\n现无数种不同的外形。如果我们使用人工定义的规则去定义这个物体，那么可能需要设置非\\n\\n常大量的规则，并且效果也不一定会很好。仅仅一个物体就这么复杂，而现实中常见的各种\\n\\n21\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n物体成千上万，所以在图像识别领域，使用使用人为定义的规则去做识别肯定是行不通的。\\n\\n很多其他的领域也同样存在这种问题。\\n\\n1.2 机器学习\\n\\n由于人们没有办法设计出足够复杂的规则来精确描述世界，所以 AI 系统需要具备自我学\\n\\n习的能力，即从原始数据中获取有用的知识。这种能力被称为机器学习（Machine Learning）。\\n\\n人工智能是抽象的概念，而机器学习是具体的可以落地的算法。机器学习不是一个算法，\\n\\n而是一大类具体智能算法的统称。使用机器学习算法我们可以解决生活中如人脸识别，垃圾邮\\n\\n件分类，语音识别等具体问题。\\n\\n机器学习其实与人类学习的过程类似。打个比方：假如我们现在都是原始人，并不知道太\\n\\n阳和月亮是什么东西。但是我们可以观察天上的太阳和月亮，并且把太阳出来时候的光线和温\\n\\n度记录下来，把月亮出来时候的光线和温度记录下来（这就相当于是收集数据）。观察了 100\\n\\n天之后，我们进行思考，总结这 100 天的规律我们可以发现，太阳和月亮是交替出现的（偶尔\\n\\n同时出现可以忽略）。出太阳的时候光线比较亮，温度比较高。月亮出来的时候光线比较暗，\\n\\n温度比较低（这相当于是分析数据，建立模型）。之后我们看到太阳准备落山，月亮准备出来\\n\\n的时候我们就知道温度要降低可能要多穿树叶或毛皮（原始人没有衣服），光线也准备要变暗\\n\\n了（预测未来的情况）。机器学习也可以利用已有的数据进行学习，获得一个训练好的模型，\\n\\n然后可以利用此模型预测未来的情况。\\n\\n22\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.4 中表现了机器学习与人类思维的对比。我们可以使用历史数据来训练一个机器学习\\n\\n的模型，模型训练好之后，再放入新的数据，模型就可以对新的数据进行预测分析。人类也善\\n\\n于从以往的经验中总结规律，当遇到新的问题时，我们可以根据之前的经验来预测未来的结果。\\n\\n图 1.4 机器学习与人类思维的对比\\n\\n1.2.1 训练数据，验证数据和测试数据\\n\\n通常我们在做机器学习分析的时候，会把数据分成两大部分。一部分是训练数据（Training\\n\\nData），可以用来训练，构建模型。另一部分是测试数据（Testing Data），可以用来验证模\\n\\n型的好坏。这两部分就有点像我们上学时课本中的习题。正文中的例题是训练数据，有答案和\\n\\n详细讲解，是用来教我们学习新知识的，可以看作是用来对我们进行训练。而课后习题是测试\\n\\n数据，我们要先做题，做完之后再对答案，是用来检查我们学习效果的。\\n\\n有时我们会把数据分成三部分，即训练集（Training Set）、验证集（Validation Set）\\n\\n和测试集（Testing Set）。训练集还是用来训练模型。验证集是在模型的训练阶段评估模型的\\n\\n好坏，可以用于确定模型的参数或结构。等模型训练好，并且结构和参数都调整好之后，再用\\n\\n测试集来评估模型的好坏。通常我们可以把所有数据的 60%分配给训练集，20%分配的验证\\n\\n集，20%分配给测试集。或者 80%分配给训练集，10%分配给验证集，10%分配给测试集。\\n\\n23\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过这个数据划分不是绝对的，还需要看具体情况。有时候我们只划分训练集和测试集，训练\\n\\n集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。\\n\\nK 折交叉检验(K-fold Cross-Validation) —— K 折交叉检验的大致思想是把数据集分\\n\\n成 K 份，每次取一份作为测试集，取余下的 K-1 份作为训练集。重复训练 K 次，每次训练都\\n\\n从 K 个部分中选一个不同的部分作为测试集（要保证 K 个部分的数据都分别做过测试），剩下\\n\\n的 K-1 份做训练集。最后把得到的 K 个结果做平均。\\n\\n1.2.2 学习方式\\n\\n在机器学习或者人工智能领域，不同的问题可能会有不同的学习方式。主要的学习方法有：\\n\\n监督学习（Supervised Learning） —— 监督学习也称为有监督学习，通常可以用于\\n\\n分类（Classification）以及回归（Regression）的问题。它的主要特点是，所有的数据都有\\n\\n与之相对应的标签（Label）。比如我们想做一个识别手写数字的模型，那么我们的数据集就是\\n\\n大量手写数字的图片，并且每一张图片都有对应的标签，如图 1.5：\\n\\n图 1.5 标签为 3\\n\\n图片是一个手写数字 3，所以这张图片的标签可以设置为 3。同样的，如果是一张手写\\n\\n数字 8 的图片，那么该图片的标签就可以是 8。或者我们要建立一个判别垃圾邮件的模型，\\n\\n24\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n那我们先要对邮件进行标记，标记出哪些属于垃圾邮件，哪些不属于垃圾邮件，然后建立模\\n\\n型。\\n\\n监督学习在建模过程中，会将预测结果与训练数据的实际结果（也就是标签）做对比，\\n\\n如果预测结果跟实际结果不符合，将通过一些方式去调整模型的参数，直到模型的预测结果\\n\\n能达到比较高的准确率。\\n\\n非监督学习（Unsupervised Learning)）—— 非监督学习也称为无监督学习，通常可\\n\\n以用于聚类（Clustering）的问题。非监督学习中，所有的数据都是没有标签的。可以使用\\n\\n机器学习的方法让数据自动聚类。例如许多公司都拥有庞大的客户信息数据库，使用非监督\\n\\n学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我\\n\\n们对不同细分市场的客户进行更有效的销售或者广告推送。或许我们事先并不知道有哪些细\\n\\n分市场，也不知道哪些客户属于细分市场 A，哪些客户属于细分市场 B。不过没关系，我们\\n\\n可以让非监督学习算法在数据中挖掘这一切信息。\\n\\n半监督学习（Semi-Supervised Learning）—— 半监督学习是监督学习和非监督学\\n\\n习相结合的一种学习方式，通常可以用于分类以及回归问题。主要是用来解决使用少量带标\\n\\n签的数据和大量没有标签的数据进行训练和分类的问题。此类算法首先试图对没有标签的数\\n\\n据进行建模，然后再对带有标签的数据进行预测。说个题外话，半监督学习一般用得比较\\n\\n少，原因很简单，因为标签不足的情况通常很容易解决，只要找很多人来打标签就可以了。\\n\\n大型 AI 公司可能会有几百人的数据标注团队，每天的工作就是给各种数据打标签。因为顶尖\\n\\n大公司 AI 技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所\\n\\n以现在有一句叫做人工智能，先有人工，后有智能，有多少人工，就有多少智能。这是玩笑\\n\\n话，大家看看就好，标签很重要，不过人工智能的核心还是算法，说不定以后有一天我们可\\n\\n以开发出不需要标签就可以什么都学会的算法。\\n\\n25\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n强化学习（Reinforcement Learning）—— 强化学习灵感来源于心理学中的行为主\\n\\n义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能\\n\\n够获得最大利益的习惯性行为。强化学习没有任何的标签来告诉算法应该怎么做，它会先去\\n\\n尝试做一些动作，然后得到一个结果，通过判断这个结果是对还是错来对之前的动作进行反\\n\\n馈。AlphaGo 中就用到了强化学习。不过目前强化学习的落地应用还比较少，大部分的应用\\n\\n还都只是用于打游戏。\\n\\n1.2.3 机器学习常用算法\\n\\n机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n\\n所示。\\n\\n图 1.6 决策树(Decision Tree)\\n\\n26\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n\\n这些数据来建立回归模型，如图 1.7 所示。\\n\\n图 1.7 线性回归(Linear Regreesion)\\n\\n模型建立好之后，我们可以得到一条最符合房屋面积跟房屋价格关系的直线。根据这个\\n\\n模型，我们可以把一个新的房屋面积输入，就能得到该房屋的价格预测值。\\n\\nKNN（K-Nearest Neighbor） —— KNN 算法又称为 k 近邻分类(k-nearest neighbor\\n\\nclassification)算法，是一种监督学习算法。最简单的最近邻算法就是遍历所有已知标签的样\\n\\n本集中的数据，计算它们和需要分类的样本之间的距离（这里的距离一般指的是 欧氏距离\\n\\n（Euclidean Distance)），同时记录目前的最近点。KNN 查找的是已知标签的样本集中跟需\\n\\n要分类的样本最邻近的 K 个样本，需要分类的样本最终的标签是由这 K 个样本的标签决定的，\\n\\n采用的方式是“多数表决”。也就是在这 K 个样本中哪种标签最多，那么需要分类的样本就归\\n\\n为哪一类。下图中，方形表示分类 1，圆形表示分类 2，图中正中心的五角星表示需要分类的\\n\\n样本。当 K 等于 1 时，其实就是计算距离五角星最近的样本属于哪一个分类。图 1.8 中，我们\\n\\n可以看到距离五角星最近的是方形，属于分类 1，所以我们可以把五角星归为分类 1。\\n\\n27\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.8 KNN 分类，K 等于 1\\n\\n当我们取 K=5 时，其实就是找出距离五角星最近的 5 个样本，然后统计这 5 个样本哪\\n\\n种分类比较多。图 1.9 中我们可以看到，有 1 个方形和 4 个圆形，那么圆形比较多，所以我\\n\\n们可以把五角星归为分类 2。\\n\\n图 1.9 KNN 分类，K 等于 5\\n\\n这里我们可以看到，五角星最终的分类跟 K 的取值有很大关系。K 值取多少，模型的效\\n\\n果才比较好呢？这可能需要对模型进一步调试，才能得到答案，比如我们可以不断改变 K\\n\\n值，然后用测试集来做测试，最终选取一个可以使得测试误差比较小的 K 值。\\n\\n28\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nK-Means —— K-Means 是一种无监督学习算法，通常可以用于聚类分析。所谓聚类\\n\\n问题，就是给定一个元素集合 A，集合中的每个元素有 n 个可观测的属性。我们需要使用某\\n\\n种方法把 A 划分为 k 个子集，并且要使得每个子集内部元素之间的差异尽可能小，不同子集\\n\\n之间元素的差异尽可能大。K-Means 算法的计算过程比较直观也比较简单：\\n\\n（1）先从没有标签的元素集合 A 中随机取 k 个元素，作为 k 个子集各自的重心。\\n\\n（2）分别计算剩下的元素到 k 个子集重心的距离（这里的距离也可以使用欧氏距离），\\n\\n根据距离将这些元素分别划归到最近的子集。\\n\\n（3）根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的\\n\\n算数平均数）。\\n\\n（4）将集合 A 中全部元素按照新的重心然后再重新聚类。\\n\\n（5）重复第（4）步，直到聚类结果不再发生变化。\\n\\nK-Means 运行过程如图 1.10~图 1.12 所示。\\n\\n图 1.10 K-Means 算法，第 1 次迭代\\n\\n29\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.11 K-Means 算法，第 5 次迭代\\n\\n图 1.12 K-Means 算法，第 9 次迭代\\n\\n聚类模型一共迭代了 9 次，最终收敛。从图中我们可以看得出来第 1 次迭代的时候，模\\n\\n型的聚类效果是很差的，一看就不太合理。迭代了 5 次之后，模型有了一些改善，聚类的效\\n\\n果已经不错了，不过看得出来还有一些提高的空间。迭代 9 次之后，模型就训练好了，很好\\n\\n地把没有标签的数据分成了 4 类。相同类别之间的差距比较小，不同类别之间的差距比较\\n\\n大。\\n\\n神经网络（Neural Network）—— 神经网络是一种模拟人类大脑神经网络结构构建\\n\\n出来的算法。神经网络的结构可以有多层，多层的神经网络可以由输入层（Input Layer），\\n\\n隐藏层（Hidden Layers）以及输出层（Output Layer）组成。其中隐藏层可能有 0 到多\\n\\n30\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n个，所以最简单的神经网络就只有输入层和输出层。神经网络的每一层都由若干个神经元\\n\\n（Neuron）节点组成。\\n\\n信号从输出层传入网络，与神经元的权值（Weights）作用后再经过激活函数\\n\\n（Activation Function）传入下一层。每一层信号的输出都是下一层的输入，直到把信号\\n\\n传到输出层得出结果。网络结构如图 1.13 所示：\\n\\n图 1.13 神经网络（Neural Network）\\n\\n神经网络是深度学习的重要基础，在后面的章节中我们会从头开始详细学习神经网络的\\n\\n搭建以及应用，这里只是先做一个简单介绍。\\n\\n除了上面介绍的这些算法以外，机器学习领域还有很多其他的算法，如朴素贝叶斯\\n\\n(Naive Bayes)，支持向量机 SVM(Support Vector Machine)， Adaboost 等。\\n\\n31\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.3 人工智能、机器学习，神经网络以及深度学\\n\\n习之间的关系\\n\\n新闻媒体在报道 AlphaGo 的时候，可能人工智能，机器学习，神经网络和深度学习这\\n\\n几个词都有用到过。对于初学者来说，难免容易混淆。\\n\\n人工智能 —— 我们先说说人工智能，人工智能是这几个词中最早出现的。1956 年，\\n\\n在美国达特茅斯会议（Dartmouth Conference）上被提出。人工智能其实是一种抽象的概\\n\\n念，并不是指任何实际的算法。人工智能可以对人的意识、思维进行模拟，但又不是人的智\\n\\n能。有时候我们还会把人工智能分为弱人工智能（Weak AI）和强人工智能（Strong AI）。\\n\\n弱人工智能是擅长于单个方面技能的人工智能。比如 AlphaGo 能战胜了众多世界围棋\\n\\n冠军的，在围棋领域所向披靡，但它只会下围棋，做不了其他事情。我们目前的人工智能相\\n\\n关的技术，比如图像识别，语言识别，自然语言处理等等，基本都是处于弱人工智能阶段。\\n\\n强人工智能指的是在各方面都能和人类智能差不多的人工智能，人类能干的脑力劳动它\\n\\n都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一\\n\\n些科幻电影中才能看到。著名的教育心理学教授 Linda Gottfredson 把智能定义为“一种宽\\n\\n泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从\\n\\n经验中学习等操作。”强人工智能在进行这些操作时应该跟人类一样得心应手。\\n\\n机器学习 —— 机器学习是最近 20 多年兴起的一门多领域交叉学科，涉及概率论、统\\n\\n计学、逼近学、凸分析、计算复杂性理论等多门学科。关于机器学习，上一小节我们已经做\\n\\n了一些讨论说明，我们可以发现机器学习包含很多具体的算法。既然人工智能是飘在天上的\\n\\n32\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n概念，那我们就需要一些具体的算法使得人工智能可以落地应用，而一般来说，这些具体的\\n\\n智能算法可以统称为机器学习算法。\\n\\n神经网络 —— 神经网络是众多机器学习算法中的其中一个，是模仿人类大脑神经结构\\n\\n构建出来的一种算法，构建出来的网络称为人工神经网络（Artificial Neural Networks，\\n\\nANN）。神经网络算法在机器学习中并不算特别出色，所以一开始的时候并没有引起人们的\\n\\n特别关注。神经网络的发展已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代神经网络\\n\\n的雏形出现在控制论（Cybernetics）中，20 世纪 80 年代到 90 年代表现为联结主\\n\\n（Connectionism）。直到 2006 年神经网络重新命名为深度学习，再次兴起。\\n\\n深度学习 —— 深度学习的基础其实就是神经网络，之所以后来换了一种叫法，主要是\\n\\n由于之前的神经网络算法中网络的层数不能太深，也就是不能有太多层网络，网络层数过多\\n\\n会使得网络无法训练。随着神经网络理论的发展，科学家研究出了多种方式使得训练深层的\\n\\n网络也成为可能，深度学习由此诞生。如卷积神经网络（Convolutional Neural\\n\\nNetwork, CNN），长短时记忆网络（Long Short Term Memory Network, LSTM），深\\n\\n度残差网络（Deep Residual Network）等都属于深度学习，其中深度残差网络的深度可\\n\\n以到达 1000 层，甚至更多。深层的网络有助于挖掘数据中深层的特征，可以使得网络拥有\\n\\n更强大的性能。\\n\\n图 1.14 描绘了人工智能、机器学习、神经网络和深度学习之间的关系。\\n\\n33\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.14 人工智能、机器学习、神经网络和深度学习之间的关系\\n\\n1.4 深度学习应用\\n\\n深度学习最早兴起于图像识别，在最近几年可以说是已经深入各行各业。深度学习在计算\\n\\n机视觉，语音识别，自然语言处理，机器人控制，生物信息，医疗，法律，金融，推荐系统，\\n\\n搜索引擎，电脑游戏，娱乐等领域均有应用。\\n\\n图像识别 —— 图像识别可以说是深度学习最早实现突破性成就的领域。如今计算机对\\n\\n图片的识别能力已经跟人类不相上下。我们把一张图片输入神经网络，经过网络的运算，最后\\n\\n可以得到图片的分类。如图 1.15 所示，我们可以看到，对于每一张图片，神经网络都给出了\\n\\n5 个最有可能的分类，排在最上面的可能性最大。图中的置信度表示的就是该图片的概率值。\\n\\n34\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.15 图像识别\\n\\n目标检测 —— 利用深度学习我们还可以识别图片中的特定物体，然后对该物体进行标\\n\\n注，如图 1.16 所示。\\n\\n图 1.16 目标检测[1]\\n\\n人脸识别 —— 深度学习还可以识别图像中的人脸，判断是男人还是女人，判断人的年龄，\\n\\n判断图像中的人是谁等，如图 1.17 所示。\\n\\n35\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.17 人脸识别\\n\\n目标分割 —— 目标分割识别出图中的物体，并且可以划分出物体的边界，如图 1.18 所\\n\\n示。\\n\\n图 1.18 目标分割[2]\\n\\n描述图片 —— 把一张图片输入神经网络中，就可以输出对这张图片的文字描述，如图\\n\\n1.19 所示。\\n\\n36\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.19 图片描述\\n\\n图片风格转换 —— 利用深度学习实现一张图片加上另一张图片的风格，然后生成一张\\n\\n新的图片，如图 1.20 所示。\\n\\n37\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.20 图片风格转换[3]\\n\\n语音识别 —— 深度学习还可以用来识别人说的话，把语音数据转换为文本数据，如图\\n\\n1.21 所示。\\n\\n图 1.21 语音识别\\n\\n文本分类 —— 使用深度学习对多个文本进行分类，比如判断一个评论是好评还是差评，\\n\\n或者判断一篇新闻是属于娱乐新闻，体育新闻还是科技新闻，如图 1.22 所示。\\n\\n38\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.22 文本分类\\n\\n机器翻译 —— 使用深度学习进行机器翻译，如图 1.23 所示。\\n\\n图 1.23 机器翻译\\n\\n诗词生成 —— 把一个诗词的题目传入神经网络，就可以生成一篇诗词，如图 1.24 所示，\\n\\n其就是 AI 写的一首诗。虽然这首诗有些看不太懂，但是已经“有内味了”。\\n\\n图 1.24 诗句生成\\n\\n39\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站\\n\\nhttps://make.girls.moe/#/，设置好动漫人物的头发颜色，头发长度，眼睛颜色，是否戴帽\\n\\n子等信息就可以生成符合条件的动漫人物。并且可以生成无数张不重复的照片，如图 1.25 所\\n\\n示。\\n\\n图 1.25 图像生成\\n\\n这里只是列举了非常少量的例子，深度学习的已经逐渐深入各行各业，深入我们的生活\\n\\n中。\\n\\n1.5 神经网络深度学习发展史\\n\\n神经网络的发展历史中有过三次热潮，分别发展在 20 世纪 40 年代到 60 年代，20 世纪\\n\\n80 年代到 90 年代，以及 2006 年至今。每一次神经网络的热潮都伴随着人工智能的兴起，人\\n\\n工智能和神经网络一直以来都有着非常密切的关系。\\n\\n40\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.5.1 神经网络诞生-20 世纪 40-60 年代\\n\\n1943 年，神经病学家和神经元解剖学家 W.S.McCulloch 和数学家 W.A.Pitts在生物物理\\n\\n学期刊发表文章提出神经元的数学描述和结构。并且证明了只要有足够的简单神经元，在这些\\n\\n神经元互相连接并同步运行的情况下，可以模拟任何计算函数，这种神经元的数学模型称为 M-\\n\\nP 模型。该模型把神经元的动作描述为：1.神经元的活动表现为兴奋或抑制的二值变化；2.任\\n\\n何兴奋性突触输入激励后，使神经元兴奋；3.任何抑制性突触有输入激励后，使神经元抑制；\\n\\n4.突触的值不随时间改变；5.突触从感知输入到传送出一个输出脉冲的延时时间是 0.5ms。\\n\\n尽管现在看来 M-P 模型过于简单，并且观点也不是完全正确，不过这个模型被认为是第\\n\\n一个仿生学的神经网络模型，他们提出的很多观点一直沿用至今，比如说他们认为神经元有两\\n\\n种状态，要不就是兴奋，要不就是抑制。这跟后面要提到的单层感知器非常类似，单层感知器\\n\\n的输出要不就是 0 要不就是 1。他们最重要的贡献就是开创了神经网络这个研究方向，为今天\\n\\n神经网络的发展奠定了基础。\\n\\n1949 年 ，另一 位心 理学 家\\n\\nDonald Olding Hebb 在他的 一 本名为\\n\\n《The organization of behavior: A neuropsychological theory》[4]的书提出了 Hebb 算\\n\\n法。他也是首先提出“连接主义”（connectionism）这一名词的人之一，这个名词的含义是\\n\\n大脑的活动是靠脑细胞的组合连接实现的。Hebb 认为，如果源和目的神经元均被激活兴奋时，\\n\\n它们之间突触的连接强度将会增强。他指出在神经网络中，信息存储在连接权值中。并提出假\\n\\n设神经元 A 到神经元 B 连接权与从 B 到 A 的连接权是相同的。他这里提到的这个权值的思想\\n\\n也被应用到了我们目前所使用的神经网络中，我们通过调节神经元之间的连接权值来得到不同\\n\\n的神经网络模型，实现不同的应用。虽然这些理论在今天看来是理所当然的，不过在当时看来\\n\\n这是一种全新的想法，算得上是开创性的理论。\\n\\n41\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1958 年 ， 计算 机学 家 Frank Rosenblatt 提 出 了 一种神经网络 结 构，称为 感 知 器\\n\\n(Perceptron)。他提出的这个感知器可能是世界上第一个真正意义上的人工神经网络。感知\\n\\n器提出之后在 60 年代就掀起了神经网络研究的第一次热潮。很多人都认为只要使用成千上万\\n\\n的神经元，他们就能解决一切问题。现在看来可能会让人感觉 too young too naive，不过感\\n\\n知器在当时确实是影响非凡。\\n\\n这股感知器热潮持续了 10 年，直到 1969 年，人工智能的创始人之一的 M.Minsky 和\\n\\nS.Papert 出版了一本名为《感知器》[5]的书，书中指出简单神经网络只能运用于线性问题的求\\n\\n解，能够求解非线性问题的网络应具有隐层，而从理论上还不能证明将感知器模型扩展到多层\\n\\n网络是有意义的。由于 Minsky 在学术界的地位和影响，其悲观论点极大地影响了当时的人工\\n\\n神经网络研究，为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。这本书出版不不久之后，\\n\\n几乎所有为神经网络提供的研究基金都枯竭了，没有人愿意把钱浪费在没有意义的事情上。\\n\\n1.5.2 神经网络复兴-20 世纪 80-90 年代\\n\\n1982 年，美国加州理工学院的优秀物理学家 John J.Hopfield 博士提出了 Hopfield 神\\n\\n经网络。Hopfield 神经网络引用了物理力学的分析方法，把网络作为一种动态系统并研究这\\n\\n种网络动态系统的稳定性。\\n\\n1985 年，G.E.Hinton 和 T.J.Sejnowski借助统计物理学的概念和方法提出了一种随机神\\n\\n经网络模型——玻尔兹曼机(Boltzmann Machine)。一年后他们又改进了模型，提出了受限\\n\\n玻尔兹曼机(Restricted Boltzmann Machine)。\\n\\n1986 年，Rumelhart，Hinton，Williams 提出了 BP(Back Propagation)算法[6]（多层\\n\\n感知器的误差反向传播算法）。到今天为止，这种多层感知器的误差反向传播算法还是非常基\\n\\n础的算法，凡是学神经网络的人，必然要学习 BP 算法。我们现在的深度网络模型基本上都是\\n\\n42\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在这个算法的基础上发展出来的。使用 BP 算法的多层神经网络也称为 BP 神经网络（Back\\n\\nPropagation Neural network）。BP 神经网络主要指的是 20 世纪 80-90 年代使用 BP 算\\n\\n法的神经网络，虽然现在的深度学习也用 BP 算法，不过网络名称已经不叫 BP 神经网络了。\\n\\n早期的 BP 神经网络的神经元层数不能太多，一旦网络层数过多，就会使得网络无法训练，具\\n\\n体原因在后面的章节中会详细说明。\\n\\nHopfield 神经网络，玻尔兹曼机以及受限玻尔兹曼机由于目前已经较少使用，所以本书\\n\\n后面章节不再详细介绍这三种网络。\\n\\n1.5.3 深度学习-2006 年至今\\n\\n2006 年，多伦多大学的教授 Geoffrey Hinton 提出了深度学习。他在世界顶级学术期刊\\n\\n《 Science 》上发表了 一篇论 文《 Reducing the dimensionality of data with neural\\n\\nnetworks》[7]，论文中提出了两个观点：①多层人工神经网络模型有很强的特征学习能力，深\\n\\n度学习模型学习得到的特征数据对原始数据有更本质的代表性，这将大大便于分类和可视化问\\n\\n题；②对于深度神经网络很难训练达到最优的问题，可以采用逐层训练方法解决。将上层训练\\n\\n好的结果作为下层训练过程中的初始化参数。在这一文献中深度模型的训练过程中逐层初始化\\n\\n采用无监督学习方式。\\n\\nHinton 在论文中提出了一种新的网络结构深度置信网络（Deep Belief Net：DBN），这\\n\\n种网络使得训练深层的神经网络成为可能。深度置信网络由于目前已经较少使用，所以本书后\\n\\n面章节不再详细介绍这种网络。\\n\\n2012 年，Hinton 课题组为了证明深度学习的潜力，首次参加 ImageNet 图像识别比赛，\\n\\n通过 CNN 网络 AlexNet 一举夺得冠军。也正是由于该比赛，CNN 吸引了众多研究者的注意。\\n\\n43\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n44\\n\\n2014 年，香港中文大学教授汤晓鸥领导的计算机视觉研究组开发了名为 DeepID 的深度\\n\\n学习模型， 在 LFW (Labeled Faces in the Wild，人脸识别使用非常广泛的测试基准)数据库\\n\\n上获得了 99.15%的识别率，人用肉眼在 LFW 上的识别率为 97.52%，深度学习在学术研究层\\n\\n面上已经超过了人用肉眼的识别。\\n\\n2016 年 3 月人工智能围棋比赛，由位于英国伦敦的谷歌（Google）旗下 DeepMind 公\\n\\n司的开发的 AlphaGo 战胜了世界围棋冠军、职业九段选手李世石，并以 4:1 的总比分获胜。\\n\\n2018 年 6 月，OpenAI 的研究人员开发了一种技术，可以在未标记的文本上训练 AI，可\\n\\n以大量减少人工标注的时间。几个月后谷歌推出了一个名为 BERT 的模型，该模型在学习了几\\n\\n百万个句子 以 后 学 会 了如何预 测 漏掉的单词。 在多 项\\n\\nNLP (Natural Language\\n\\nProcessing) 测试中，它的表现都接近人类。\\n\\n2020 年 6 月，OpenAI 发布了有史以来最大的 NLP 模型 GPT-3，GPT-3 模型参数达到\\n\\n了 1750 亿个参数，模型训练花费了上千万美元。GPT-3 训练方法很简单，但是却非常全能，\\n\\n可以完成填空，翻译，问答，阅读理解，数学计算，语法纠错等多项任务。随着 NLP 技术的\\n\\n发展，相信在将来 AI 可以逐渐理解我们的语言，跟我们进行顺畅的对话，甚至成为我们的保\\n\\n姆，老师或朋友。\\n\\n今天，人脸识别技术已经应用在了我们生活的方方面面，比如上下班打卡，飞机高铁出行，\\n\\n出门住酒店，刷脸支付等。我们已经离不开深度学习技术，而深度学习技术仍在快速发展中。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.6 深度学习领域重要人物\\n\\n深度学习领域有很多做出过卓越贡献的大师，下面简单介绍几位。前面的 3 位大师\\n\\nGeoffrey Hinton、Yann LeCun、Yoshua Bengio 江湖人称“深度学习三巨头”，为了表彰 3\\n\\n位大师对于神经网络深度学习领域的贡献，2018 年计算机领域最高奖项图灵奖颁给了他们。\\n\\n1.Geoffrey Hinton\\n\\n英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。Hinton 是反向传\\n\\n播算法和对比散度算法的发明人之一，也是深度学习的积极推动者。目前担任多伦多大学计\\n\\n算机科学系教授。\\n\\n2013 年 3 月加入 Google，领导 Google Brain 项目。\\n\\nHinton 被人们称为“深度学习教父”，可以说是目前对深度学习领域影响最大的人。而\\n\\n且如今在深度学习领域活跃的大师，有很多都是他的弟子，可以说是桃李满天下。\\n\\n2.Yann LeCun\\n\\n法国出生的计算机科学家，他最著名的工作是光学字符识别和计算机视觉上使用卷积神经\\n\\n网络（CNN），他也被称为卷积网络之父。\\n\\n曾在多伦多大学跟随 Geoffrey Hinton 做博士后。1988 年加入贝尔实验室，在贝尔实验\\n\\n室工作期间开发了一套能够识别手写数字的卷积神经网络系统，并把它命名为 LeNet。这个系\\n\\n统能自动识别银行支票。\\n\\n2003 年去了纽约大学担任教授，现在是纽约大学终身教授。\\n\\n2013 年 12 月加入了 Facebook，成为 Facebook 人工智能实验室的第一任主任。\\n\\n3.Yoshua Bengio\\n\\n45\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n毕业于麦吉尔大学，在 MIT 和贝尔实验室做过博士后研究员，自 1993 年之后就在蒙特\\n\\n利尔大学任教。在预训练问题，自动编码器降噪等领域做出重大贡献。\\n\\n这“三巨头”中的前两人早已投身工业界，而 Bengio 仍留在学术界教书，他曾说过：\\n\\n“我留在学术圈是为全人类作贡献，而不是为某一公司赚钱”。他说这句话一定是因为他很有\\n\\n钱，开个玩笑。每个领域的发展不仅需要做前沿的研究，还需要不断培养新的新鲜血液加入\\n\\n到这个行业中，所以如果大学教授都去工作的话，上课教书的人就少了。所以 Bengio 能留\\n\\n在学术圈，对行业的发展也是一件好事。\\n\\n2017 年初 Bengio 选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他\\n\\n指的显然是 Google 和 Facebook）成为人工智能变革中的唯一大玩家，这对研究社区没有\\n\\n好处，对人类也没有好处。\\n\\n4.Andrew Ng（吴恩达）\\n\\nAndrew Ng 是美籍华人，曾经是斯坦福大学计算机科学系和电气工程系的副教授，斯\\n\\n坦福人工智能实验室主任。他还与 Daphne Koller 一起创建了在线教育平台 Coursera。\\n\\n2011 年，Andrew Ng 在 Google 创建了 Google Brain 项目，通过分布式集群计算机\\n\\n开发超大规模的人工神经网络。\\n\\n2014 年 5 月，Andrew Ng 加入百度，负责百度大脑计划，并担任百度公司首席科学\\n\\n家。\\n\\n2017 年 3 月，Andrew Ng 从百度离职，目前自己创业。\\n\\nLeCun 是 Hinton 的 博士生，另一位人工智能大师 Jordan 曾经申请过 Hinton 的博士\\n\\n生，Bengio 是 Jordan 的博士后，Andrew Ng 是 Jordan 的博士生，LeCun 与 Bengio 曾\\n\\n经是同事。这个圈子很小，大家都认识，这几位大师互相之间有着很深的渊源。\\n\\n46\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n曾经神经网络的圈子很小，基本上入了这个圈以后就没什么前途了。正是由于这个圈子\\n\\n里的这些大师前辈们的不懈努力，把神经网络算法不断优化，才有了今天的深度学习和今天\\n\\n人工智能的新局面。\\n\\n1.7 新一轮人工智能爆发的三要素\\n\\n这一轮人工智能大爆发的主要原因有 3 个，深度学习算法，大数据，以及高性能计算。\\n\\n深度学习算法 —— 之前人工智能领域的实际应用主要是使用传统的机器学习算法，虽\\n\\n然这些传统的机器学习算法在很多领域都取得了不错的效果，不过仍然有非常大的提升空间。\\n\\n深度学习出现后，计算机视觉，自然语言处理，语音识别等领域都取得了非常大的进步。\\n\\n大数据 —— 如果把人工智能比喻成一个火箭，那么这个火箭需要发射升空，它的燃料就\\n\\n是大数据。以前在实验室环境下很难收集到足够多的样本，现在的数据相对以前在数量、覆盖\\n\\n性和全面性方面都获得了大幅提升。一般来说深度学习模型想要获得好的效果，就需要把大量\\n\\n的数据放到模型中进行训练。\\n\\n高性能计算 —— 以前高性能计算大家 用的是 CPU 集群，现在做深度学习都是 用\\n\\nGPU(Graphics Processing Unit)或 TPU(Tensor Processing Unit)。想要使用大量的数据\\n\\n来训练复杂的深度学习模型那就必须要具备高性能计算能力。GPU 就是我们日常所说的显卡，\\n\\n平时主要用于打游戏。但是 GPU 不仅可以用于打游戏，还可以用来训练模型，性价比很高，\\n\\n买显卡的理由又多了一个。如果只是使用几个 CPU 来训练一个复杂模型可能会需要花费几周\\n\\n甚至几个月的时间。把数百块 GPU 连接起来做成集群，用这些集群来训练模型，原来一个月\\n\\n才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时\\n\\n47\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n间。TPU 是谷歌专门为机器学习量身定做的处理器，执行每个操作所需的晶体管数量更少，效\\n\\n率更高。\\n\\n工欲善其事，必先利其器。下一章节我们将介绍如何搭建 python 开发环境，为我们后续\\n\\n的学习做准。\\n\\n1.8 参考文献\\n\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\n\\narXiv:1804.02767, 2018.\\n\\n[2] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\n\\ninternational conference on computer vision. 2017: 2961-2969.\\n\\n[3] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint\\n\\narXiv:1508.06576, 2015.\\n\\n[4] Hebb D O. The organization of behavior: A neuropsychological theory[M].\\n\\nPsychology Press, 2005.\\n\\n[5] Minsky M, Papert S A. Perceptrons: An introduction to computational\\n\\ngeometry[M]. MIT press, 2017.\\n\\n[6] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-\\n\\npropagating errors[J]. nature, 1986, 323(6088): 533-536.\\n\\n[7] Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets[J].\\n\\nNeural computation, 2006, 18(7): 1527-1554.\\n\\n48\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 章-搭建 Python 编程环境\\n\\n本章节内容与深度学习没有直接关系，不过随着人工智能技术的发展，Python 已经成为\\n\\n时下最热门的编程语言之一，广泛应用于机器学习和深度学习的应用中。目前大多数深度学习\\n\\n框架的主要编程语言都是 Python，Python 可谓是目前人工智能领域的第一语言。本书中使\\n\\n用的所有代码都是 python 程序，所以这一章节我们主要学习 python 编程环境的搭建。\\n\\n如果大家之前有 python 基础那这一章节的内容就比较简单了，直接跳过也可以。如果大\\n\\n家之前完全没有学过 python，那么建议大家还是先学习 python 的使用，不然后续编程实践\\n\\n的内容可能会碰到很多问题。\\n\\n2.1 Python 介绍\\n\\nPython 是一种面向对象的解释型计算机程序设计语言，由荷兰人 Guido van Rossum 于\\n\\n1989 年发明。Python 具有丰富强大的库，常被称为“胶水语言”，因为它能够把其他语言（尤\\n\\n其是 C/C++）制作各种模块轻松联结在一起。\\n\\nPython 的主要优点是开发效率高，可移植性强，可拓展性强，应用广泛等，主要的缺点\\n\\n是程序运行效率相比 C/C++来说比较慢。\\n\\nPython 的主要应用领域有系统编程，网络爬虫，人工智能，科学计算，WEB 开发，系统\\n\\n运维，大数据，云计算，量化交易，金融分析，图形界面。\\n\\n谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google\\n\\n广告等项目都在大量使用 Python 开发。\\n\\nCIA: 美国中情局网站就是用 Python 开发的。\\n\\n49\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nNASA: 美国航天局(NASA)大量使用 Python 进行数据分析和运算。\\n\\nYouTube:世界上最大的视频网站 YouTube 就是用 Python 开发的。\\n\\nDropbox:美国最大的在线云存储网站，全部用 Python 实现，每天网站处理 10 亿个文件\\n\\n的上传和下载。\\n\\nInstagram:美国最大的图片分享社交网站，每天超过 3 千万张照片被分享，全部用 python\\n\\n开发。\\n\\nFacebook:大量的基础库均通过 Python 实现的。\\n\\nRedhat: 世界上最流行的 Linux 发行版本中的 yum 包管理工具就是用 python 开发的。\\n\\n豆瓣: 公司几乎所有的业务均是通过 Python 开发的。\\n\\n知乎: 国内最大的问答社区，通过 Python 开发。\\n\\n2.2 Anaconda 安装\\n\\n推荐的 Python 安装方式是使用 Anaconda 对 Python 进行安装。Anaconda 是一个开源\\n\\n的 Python 发行版本，其中包含了 Numpy,Pandas,Matplotlib 等多个常用的 Python 包和依\\n\\n赖项。Anaconda 的官方下载地址为：https://www.anaconda.com/download/。官方下载\\n\\n地址上大家看到的是最新的 python 安装包的下载，如果想下载之前版本的 python，可以通\\n\\n过下面这个地址：https://repo.continuum.io/archive/。\\n\\n目前 Python 常用的版本有 2.7 和 3.6/3.7/3.8 版本，python 官方已经宣布以后 python2\\n\\n将会停止维护，python 以后会逐渐往 python3 的方向发展，所以推荐大家学习 python3。\\n\\n之后 python 的版本还会不断更新，可能还会继续推出 3.9/3.10/4.0 等。\\n\\n50\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nPython2 和 python3 稍微有些差异，python3.6/3.7/3.8 之间的差异就不大了，所以我\\n\\n们不一定要安装最新的 python，因为有些软件可能跟最新的 python 会不兼容。比如现在\\n\\npython 的最新版本是 3.8，那么我们可以安装 3.6/3.7 的版本，这样兼容性会稍微好一些。\\n\\nPython 程序在 Windows,Linux,MacOS 下基本是差不多的，所以在 Windows 上可以运\\n\\n行的 Python 程序，在其他系统一般也能运行。\\n\\n下面我们主要讲解 Anaconda 在 Windows 环境下的安装，其他系统的安装方式略有不\\n\\n同，如果你熟悉其他系统的话，安装起来应该也是很简单的。如果我们要安装最新版本的\\n\\nAnaconda，首先打开 Anaconda 下载网址，根据系统选择相应的 Anaconda 安装包。选择\\n\\nPython3.7 版本、64 位的安装包进行下载，如图 2.1 所示。\\n\\n图 2.1 Anaconda 下载\\n\\n如果我 们 要安装之前 版 本 的\\n\\nAnaconda ， 可 以打开网 址\\n\\nhttps://repo.continuum.io/archive/，出现如图 2.2 所示的界面。\\n\\n51\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.2 各种版本的 Anaconda\\n\\nAnaconda2 表示安装 python2，Anaconda3 表示安装 python3，具体是 python3.X，\\n\\n从安装包的文件名是看不出来的。Windows/MacOSX/Linux 表示对应的操作系统。有 64 表\\n\\n示 64 位的系统，没有 64 表示 32 位的系统。\\n\\n安装包下载好之后，双击安装包进行安装。如图 2.3 所示，单击 Next 按钮,。\\n\\n52\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.3 Anaconda 安装流程（1）\\n\\n然后单击 I Agree 按钮，如图 2.4 所示。\\n\\n图 2.4 Anaconda 安装流程（2）\\n\\n接下来可以选择 All Users，单击 Next 按钮，如图 2.5 所示。\\n\\n53\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.5 Anaconda 安装流程（3）\\n\\n接下来选择一个 Anaconda 的安装路径，如图 2.6 所示，可以是任何路径，不一定要跟\\n\\n图中的路径一致。\\n\\n图 2.6 Anaconda 安装流程（4）\\n\\n最后勾选“Add Anaconda to the system PATH environment variable”和\\n\\n“Register Anaconda as the system Python3.6”，然后单击 Install 按钮，Anaconda 就\\n\\n开始安装了。这里注意，一定要勾选相应选项，其目的是让软件帮我们自动配置环境变量，\\n\\n如图 2.7 所示。\\n\\n54\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.7 Anaconda 安装流程（5）\\n\\n安装的过程大家不要心急，耐心等待，不要随意关闭软件的窗口，等确认软件已经安装\\n\\n完毕再关闭窗口。后面软件会有提示是否要安装 VSCode，VSCode 是一款很好用的编译\\n\\n器，可以用于开发各种编程语言写的程序，包括 python。大家感兴趣的话可以安装，不安\\n\\n装也可以。\\n\\n2.3 Jupyter Notebook 的简单使用\\n\\nPython 有非常多的集成开发环境可以使用，比如 Jupyter Notebook，Spyder，\\n\\nPyCharm，Eclipse，VSCode 等等，每种开发环境都各有优缺点，这里就不一一介绍了。如\\n\\n果大家之前已经有熟悉并喜欢的开发环境可以继续使用，如果大家是初学者对各种开发环境\\n\\n不了解的话推荐大家可以先使用 Jupyter Notebook。Jupyter Notebook 的优点是界面和\\n\\n55\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n功能都比较简洁，并且可以实时运行查看程序结果，还可以把程序运行的结果保存在文件\\n\\n中。缺点是不太好开发大型程序，不过对于初学者来说，我们可能暂时还不会接触到大型程\\n\\n序，Jupyter Notebook 基本就够用了。本书中的程序基本都是在 Jupyter Notebook 中完\\n\\n成的，它是安装完 Anaconda 后自带的一个 Python 开发环境。界面简洁，使用简单，适合\\n\\n快速实验和用于学习。\\n\\n我会给大家提供书中 Jupyter Notebook 的程序文件以及 python 的程序文件。Jupyter\\n\\nNotebook 的程序文件是以“.ipynb”结尾，只能在 Jupyter Notebook 中运行，不能在命\\n\\n令提示符/终端运行；python 的程序文件是以“.py”结尾，不能在 Jupyter Notebook 中运\\n\\n行，可以在其他 python 集成开发环境或者命令提示符/终端运行。Jupyter Notebook 的程\\n\\n序文件可以在 Jupyter Notebook 环境中转成 python 程序文件。\\n\\n2.3.1 启动 Jupyter Notebook\\n\\nAnaconda 安装完成后桌面上不会增加新的图标，我们需要搜索 Jupyter Notebook，\\n\\n找到这个开发环境，Jupyter 的图标如图 2.8 所示，找到后可以右键单击图标，然后发送到\\n\\n桌面快捷方式。\\n\\n图 2.8 Jupyter Notebook\\n\\n双击 Jupyter Notebook，打开后可以看到 Jupyter 是在网页中进行编程的，在 Jupyter\\n\\n的界面中我们可以对我们电脑本地的文件进行新建，删除和修改，如图 2.9 所示\\n\\n56\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.9 Jupyter 主界面\\n\\n2.3.2 修改 Jupyter Notebook 默认启动路径\\n\\n大家打开 Jupyter 后，可能会在的主界面中看到一些熟悉的文件，这些文件正是我们电\\n\\n脑本地的一些文件，其实 Jupyter 的主界面对应的是我们电脑中的一个路径，这个路径是可\\n\\n以修改的，我们可以创建一个新的文件夹，专门用于写 python 程序。\\n\\nJupyter Notebook 的默认启动路径为：”C:\\\\User\\\\你的用户名\\\\”。所以第一次打开\\n\\nJupyter Notebook 我们会看到”C:\\\\User\\\\你的用户名\\\\”这个路径的文件出现在 Jupyter\\n\\nNotebook 的主界面。其实 Jupyter Notebook 的启动路径不一定要修改，如果你想使\\n\\n用”C:\\\\User\\\\你的用户名\\\\”或者你觉得修改 Jupyter Notebook 默认路径比较麻烦，那么你\\n\\n可以使用默认的”C:\\\\User\\\\你的用户名\\\\”路径作为 Jupyter Notebook 的工作路径。只要把\\n\\npython 相关的程序（比如书中代码）复制到”C:\\\\User\\\\你的用户名\\\\”路径下，在 Jupyter\\n\\nNotebook 的主界面就可以看到你复制的程序，然后在 Jupyter Notebook 环境中就可以对\\n\\n这些程序进行修改和运行了。\\n\\n如果希望把程序存放在其他路径，使用其他路径作为 Jupyter Notebook 的工作路径，\\n\\n那么就进行下面的操作：\\n\\n首先我们要右键 Jupyter Notebook 的图标，查看属性，然后看到目标，目标最后如果\\n\\n有%USERPROFILE%，则把后面的%USERPROFILE%删掉，如图 2.10 所示。\\n\\n57\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.10 删除%USERPROFILE%\\n\\n下一步需要生成配置文件，打开命令提示符执行：jupyter notebook --generate-config，\\n\\n我们会看到如图 2.11 所示的结果。\\n\\n图 2.11 生成配置文件\\n\\n我 们 可 以看到 配置文件生成 的 位置， 本 书例子中配置文件生成 的 位置\\n\\n是 C:\\\\Users\\\\qin\\\\.jupyter\\\\jupyter_notebook_config.py，进入系统盘，用户文件下，可以看\\n\\n到一个.jupyter 的文件，如图 2.12 所示\\n\\n图 2.12 .jupyter 文件\\n\\n58\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n进入.jupyter 文件夹中找到 jupyter_notebook_config.py 文件，用文本工具打开\\n\\njupyter_notebook_config.py 文件，找 c.NotebookApp.notebook_dir 配置，“#”为注\\n\\n释，先把它前面的“#”给去掉，然后填入你想要的 Python 程序存放路径。如图 2.13 所\\n\\n示。\\n\\n图 2.13 修改 Jupyter 工作路径\\n\\n图中的例子是在“E/test”，大家不一定要使用这个路径，可以任意设置其他路径。注意\\n\\n这里设置的路径必须是本地已经存在的路径。注意路径最好是全英文，如果路径有中文需要\\n\\n把 jupyter_notebook_config.py 文件另存为 UTF-8 的格式。注意路径中的斜杠是“/”不是\\n\\n“\\\\”。\\n\\n顺利的话，重新启动 Jupyter Notebook 就可以看到 Jupyter 的主界面跳转到了你设置\\n\\n的路径。\\n\\n如果是使用 Linux 或者 MacOS 的话可以先在终端用 cd 命令跳转到你的程序所在路径，\\n\\n然后使用命令：\\n\\njupyter notebook\\n\\n打开 Jupyter Notebook 软件，这时你会看到你的程序所在路径已经成为你的 Jupyter\\n\\nNotebook 的工作路径。\\n\\n59\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n2.3.3 Jupyter Notebook 浏览器无法打开\\n\\n如果电脑的浏览器太老，有可能会出现 Jupyter Notebook 无法打开的情况，Jupyter\\n\\nNotebook 闪退，或者是浏览器一片空白。这个时候可以下载安装一个新的谷歌浏览器，然\\n\\n后再打开 Jupyter Notebook 的配置文件，在任意位置加入如下命令：\\n\\nimport webbrowser\\n\\nwebbrowser.register(\"chrome\",None,webbrowser.GenericBrowser(u\"C:/ProgramFile\\n\\ns(x86)/Google/Chrome/Application/chrome.exe\"))\\n\\nc.NotebookApp.browser = \\'chrome\\'\\n\\n该命令的作用是把 Jupyter Notebook 的默认浏览器设置为谷歌浏览器，其中\\n\\n\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\"为谷歌浏览器的执行\\n\\n文件所在位置，每台电脑位置可能不同，需要自己查看修改。\\n\\n2.3.4 Jupyter Notebook 基本操作\\n\\n接下来新建一个文件，单击右上角的 New 按钮，然后单击 Python 选项，这样就可以创\\n\\n建一个新的文件，如图 2.14 所示。\\n\\n图 2.14 创建新文件\\n\\n创建好文件之后，可以看到如图 2.15 所示的界面。\\n\\n60\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.15 Jupyter 编译界面\\n\\n单击 Untitled 的位置可以修改文件名字，如图 2.16 所示。\\n\\n图 2.16 Jupyter 修改文件名\\n\\n然后就可以开始编程了，按照惯例，我们先来写一个“hello world”，写完之后，按\\n\\n“Shift+Enter”组合键执行程序，按住 Shift 不要放手，然后按 Enter。如图 2.17 所示。\\n\\n图 2.17 执行 hello world\\n\\n一个框内可以执行多行代码，如图 2.18 所示。\\n\\n61\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.18 执行多行代码\\n\\n把光标移动到函数的内部，然后按“Shift+Tab”组合键可以查看该函数的使用方法，先按\\n\\n住 Shift 不要放手，然后按两下 Tab，如图 2.19 所示。\\n\\n图 2.19 查看函数说明\\n\\nJupyter 还有很多神奇的用法，大家有兴趣可以去探索，这里就不过多介绍了。\\n\\n下一章我们将正式开始进入神经网络深度学习的大门。\\n\\n62\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 3 章-单层感知器与线性神经网络\\n\\n本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络 ANN 的设\\n\\n计实际上是从生物体的神经网络结构获得的灵感。模仿生物神经网络我们构造出了单层感知器，\\n\\n在单层感知器的基础上经过不断地优化才得到了后来的神经网络算法。\\n\\n3.1 生物神经网络\\n\\n生物神经网络一般是指生物的大脑神经元，细胞等组成的网络，用于产生生物的意识，帮\\n\\n助生物进行思考和行动。\\n\\n神经细胞构是构成神经系统的基本单元，简称为神经元。神经元主要由三部分构成：①细\\n\\n胞体；②轴突；③树突。如 3.1 图所示。\\n\\n图 3.1 生物神经元结构\\n\\n每个神经元伸出的突起分 2 种，树突和轴突。树突分支比较多，每个分支还可以再分支，\\n\\n长度一般比较短，作用是接受信号。轴突只有一个，从细胞体的一个凸出部分伸出，长度一般\\n\\n63\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n比较长，作用是把从树突和细胞表面传入细胞体的神经信号传出到其他神经元。轴突的末端分\\n\\n为许多小支，连接到其他神经元的树突上。\\n\\n大脑可视作为 1000 多亿神经元组成的神经网络。神经元的信息传递和处理是一种电化学\\n\\n活动。树突由于电化学作用接受外界的刺激，通过胞体内的活动体现为轴突电位，当轴突电位\\n\\n达到一定的值则形成神经脉冲或动作电位；再通过轴突末梢传递给其它的神经元。从控制论的\\n\\n观点来看，这一过程可以看作一个多输入单输出非线性系统的动态过程。\\n\\n3.2 单层感知器\\n\\n3.2.1 单层感知器介绍\\n\\n受到生物神经网络的启发，计算机学家 Frank Rosenblatt 在 20 世纪 60 年代提出了一种\\n\\n模拟生物神经网络的的人工神经网络结构，称为感知器（Perceptron）。图 3.1 为单层感知器\\n\\n结构图。\\n\\n图 3.1 单层感知器\\n\\n图中𝑥\"，𝑥#，𝑥$为输入信号，类似于生物神经网络中的树突。\\n\\n64\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n65\\n\\n𝑤\"，𝑤#，𝑤$分别为𝑥\"，𝑥#，𝑥$的权值，它可以调节输入信号的值的大小，让输入信号变大\\n\\n(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突\\n\\n传递到细胞核的过程中信号会发生变化。\\n\\n公式∑ (𝑤(𝑥() + 𝑏\\n\\n(\\n\\n表示细胞的输入信号在细胞核的位置进行汇总 ∑ 𝑤(𝑥(\\n\\n(\\n\\n，然后再加上该细\\n\\n胞本身自带的信号 b。b一般称为偏置值（Bias），相当于是神经元内部自带的信号。\\n\\nf(x)称为激活函数，可以理解为信号在轴突上进行的线性或非线性变化。在单层感知器中\\n\\n最开始使用的激活函数是 sign(x)激活函数。该函数的特点是当 x＞0 时，输出值为 1；当 x＝\\n\\n0 时，输出值为 0,；当 x＜0 时，输出值为-1。sign(x)函数图像如图 3.2 所示。\\n\\n图 3.2 sign 函数图像\\n\\ny 就是𝑓(∑ (𝑤(𝑥() + 𝑏 (\\n\\n)，为单层感知器的输出结果。\\n\\n3.2.2 单层感知器计算举例\\n\\n假如有一个单层感知器有 3 个输入𝑥\"，𝑥#，𝑥$，同时已知 b=-0.6，𝑤\"=𝑤#=𝑤$=0.5，那\\n\\n么根据单层感知器的计算公式𝑓(∑ (𝑤(𝑥() + 𝑏\\n\\n(\\n\\n)我们就可以得到如图 3.3 计算结果。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.3 单层感知器计算\\n\\n𝑥\"=0,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 1 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1\\n\\n𝑥\"=1,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=1,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 1 − 0.6) = 1\\n\\n𝑥\"=1,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 0 − 0.6) = 1\\n\\n𝑥\"=1,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1\\n\\n3.2.3 单层感知器的另一种表达形式\\n\\n单层感知器的另一种表达形式如图 3.4。\\n\\n66\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.4 单层感知器的另一种表达形式\\n\\n其实这种表达形式跟 3.2.1 中的单层感知器是一样的。只不过是把偏置值 b 变成了输入\\n\\n𝑤< × 𝑥<，其中𝑥<=1。所以𝑤< × 𝑥<实际上就是𝑤<，把∑ (𝑤(𝑥()\\n\\n(\\n\\n公式展开得到：𝑤\" × 𝑥\" + 𝑤# × 𝑥# +\\n\\n𝑤$ × 𝑥$ + 𝑤<。所以这两个单层感知器的表达不一样，但是计算结果是一样的。如图 3.4 的表\\n\\n达形式更加简洁，更适合使用矩阵来进行运算。\\n\\n3.3 单层感知器的学习规则\\n\\n3.3.1 单层感知器的学习规则介绍\\n\\n感知器的学习规则就是指感知器中的权值参数训练的方法，在本章节中我们暂时先不解释\\n\\n这个学习规则是怎么推导出来的。等第 4 章我们讲到 Delta 学习规则的时候我们再来解释感\\n\\n知器的学习规则是如何推导的。在这里我们可以先接受下面的公式即可。\\n\\n在 3.2.3 中我们已知单层感知器表达式可以写成：\\n\\n67\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n公式(3.1)中：y 表示感知器的输出；f 是 sign 激活函数；n 是输入信号的个数 i=0,1,2...\\n\\n∆𝑤( = 𝜂(𝑡 − 𝑦)𝑥(\\n\\n公式(3.2)中：∆𝑤(表示第 i 个权值的变化；𝜂表示学习率(Learning Rate)，用来调节权值\\n\\n变化的大小；t 是正确的标签(target)。\\n\\n因为单层感知器的激活函数为 sign 函数，所以 t 和 y 的取值都为±1\\n\\nt=y 时，∆𝑤(为 0；t=1，y=-1 时，∆𝑤(为 2；t=-1，y=1 时，∆𝑤(为-2。由式(3.2)可以推\\n\\n出：\\n\\n∆𝑤( = ±2𝜂𝑥(\\n\\n权值的调整公式为：\\n\\n𝑤( = 𝑤( + ∆𝑤(\\n\\n3.3.2 单层感知器的学习规则计算举例\\n\\n假设有一个单层感知器如图 3.1 所示，已知有三个输入 x0=1，x1=0，x2=-1，权值\\n\\nw0=-5，w1=0，w2=0，学习率𝜂=1，正确的标签 t=1。(注意在这个例子中偏置值 b 用\\n\\n𝑤< × 𝑥<来表示，x0 的值固定为 1)\\n\\nStep1：我们首先计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n= sign(−5 × 1 + 0 × 0 + 0 × (−1) + 0)\\n\\n= sign(−5)\\n\\n= −1\\n\\n68\\n\\n(3.1)\\n\\n(3.2)\\n\\n(3.3)\\n\\n(3.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。\\n\\n∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2\\n\\n∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0\\n\\n∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2\\n\\n𝑤< = 𝑤< + ∆𝑤< = −5 + 2 = −3\\n\\n𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0\\n\\n𝑤# = 𝑤# + ∆𝑤# = 0 − 2 = −2\\n\\nStep2：重新计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n= sign(−3 × 1 + 0 × 0 + (−2) × (−1) + 0)\\n\\n= sign(−1)\\n\\n= −1\\n\\n由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。\\n\\n∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2\\n\\n∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0\\n\\n∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2\\n\\n𝑤< = 𝑤< + ∆𝑤< = −3 + 2 = −1\\n\\n𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0\\n\\n𝑤# = 𝑤# + ∆𝑤# = −2 − 2 = −4\\n\\nStep3：重新计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n69\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n= sign(−1 × 1 + 0 × 0 + (−4) × (−1) + 0)\\n\\n= sign(3)\\n\\n= 1\\n\\n由于 y=1 与正确的标签 t=1 相同，说明感知器经过训练后得到了我们想要的结果，我们\\n\\n就可以结束训练了。\\n\\n把上面的例子写成 python 程序的话，可以得到代码 3-1。\\n\\n代码 3-1：单层感知器学习规则计算举例\\n\\n# 导入 numpy 科学计算包 import numpy as np # 定义输入 x0 = 1\\n\\nx1 = 0\\n\\nx2 = -1 # 定义权值 w0 = -5\\n\\nw1 = 0\\n\\nw2 = 0 # 定义正确的标签 t = 1 # 定义学习率 lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如 100 for i in range(100): # 打印权值 print(w0,w1,w2) # 计算感知器的输出 y = np.sign(w0 * x0 + w1 * x1 + w2*x2) # 如果感知器输出不等于正确的标签 if(y != t): # 更新权值 w0 = w0 + lr * (t-y) * x0\\n\\nw1 = w1 + lr * (t-y) * x1\\n\\n70\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nw2 = w2 + lr * (t-y) * x2 # 如果感知器输出等于正确的标签 else: # 训练结束 print(\\'done\\') # 退出循环 break\\n\\n运行结果如下： -5 0 0 -3 0 -2 -1 0 -4 done\\n\\n下面我们还可以用矩阵运算的方式来完成同样的计算，代码 3-2 为矩阵运算的方式来进\\n\\n行单层感知器学习规则的计算。\\n\\n代码 3-2：单层感知器学习规则计算举例(矩阵计算)\\n\\n# 导入 numpy 科学计算包 import numpy as np # 定义输入，用大写字母表示矩阵 # 一般我们习惯用一行来表示一个数据，如果存在多个数据就用多行来表示 X = np.array([[1,0,-1]]) # 定义权值，用大写字母表示矩阵 # 神经网络中权值的定义可以参考神经网络的输入是输出神经元的个数 # 在本例子中输入神经元个数为 3 个，输出神经元个数为 1 个，所以可以定义 3 行 1 列的 W W = np.array([[-5], [0], [0]]) # 定义正确的标签 t = 1 # 定义学习率 lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如 100 for i in range(100): # 打印权值 print(W) # 计算感知器的输出，np.dot 可以看做是矩阵乘法 y = np.sign(np.dot(X,W)) # 如果感知器输出不等于正确的标签\\n\\n71\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com if(y != t): # 更新权值 # X.T 表示 X 矩阵的转置 # 这里一个步骤可以完成代码 3-1 中下面 3 行代码完成的事情 # w0 = w0 + lr * (t-y) * x0 # w1 = w1 + lr * (t-y) * x1 # w2 = w2 + lr * (t-y) * x2 W = W + lr * (t - y) * X.T # 如果感知器输出等于正确的标签 else: # 训练结束 print(\\'done\\') # 退出循环 break 运行结果如下： [[-5] [ 0] [ 0]] [[-3] [ 0] [-2]] [[-1] [ 0] [-4]] done\\n\\n3.4 学习率\\n\\n学习率是人为设定的一个超参数，主要是在训练阶段用来控制模型参数调整的快慢。关于\\n\\n学习率主要有 3 个要点需要注意：\\n\\n（1）学习率𝜼取值一般取 0-1 之间；\\n\\n（𝟐）学习率太大容易造成权值调整不稳定；\\n\\n（3）学习率太小，模型参数调整太慢，迭代次数太多。\\n\\n72\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n你可以想象一下在洗热水澡的时候：如果每次调节的幅度很大，那水温要不就是太热，\\n\\n要不就是太冷，很难得到一个合适的水温；如果一开始的时候水很冷，每次调节的幅度都非\\n\\n常小，那么需要调节很多次，花很长时间才能得到一个合适的水温。学习率的调整也是这样\\n\\n一个道理。图 3.5 表示不同大小的学习率对模型训练的影响。\\n\\n图 3.5 不同大小的学习率对模型训练的影响\\n\\n图中的纵坐标 loss 代表代价函数（Loss Function），在后面的章节中有更详细的介\\n\\n绍，这里我们可以把它近似理解为模型的预测值与真实值之间的误差。我们训练模型的主要\\n\\n目的就是为了降低 loss 值，减少模型预测值与真实值之间的误差。横坐标 Epoch 代表模型\\n\\n的迭代周期，把所有训练数据都训练一遍可以称为迭代了一个周期。\\n\\n从图中我们可以看到，如果使用非常大的学习率（very high lr）来训练模型，loss 会一\\n\\n直处于一个比较大的位置，模型不能收敛，这肯定不是我们想要的结果。如果使用比较大的\\n\\n学习率（high lr）来训练模型，loss 会下降很快，但是最后 loss 最终不能得到比较比较小的\\n\\n值，所以结果也不理想。如果使用比较小的学习率（low lr）来训练模型，模型收敛的速度\\n\\n会很慢，需要等待很长时间模型才能收敛。最理想的结果是使用合适的学习率（good lr）来\\n\\n73\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n训练模型，使用合适的学习率，模型的 loss 值下降得比较快，并且最后的 loss 也能够下降\\n\\n到一个比较小的位置，结果最理想。\\n\\n看到这里大家可能会有一个疑问，学习率的值到底取多少比较合适？这个问题其实是没\\n\\n有明确答案的，需要根据建模的经验以及测试才能找到合适的学习率。不过学习率的选择也\\n\\n有一些小的 trick 可以使用，比如说最开始我们设置一个学习率为 0.01，经过测试我们发现\\n\\n学习率太小了需要调大一点，那么我们可以改成 0.03。如果 0.03 还需要调大，我们可以调\\n\\n到 0.1。同理，如果 0.01 太大了，需要调小，那么我们可以调到 0.003。如果 0.003 还需要\\n\\n调小，我们可以调到 0.001。所以常用的学习率可以选择：\\n\\n1，0.3，0.1，0.03，0.01，0.003，0.001，0.0003，0.0001 ...\\n\\n当然这也不是绝对的，其他的学习率的取值你也可以去尝试。\\n\\n3.5 模型的收敛条件\\n\\n通常模型的收敛条件可以有以下 3 个：\\n\\n（1）loss 小于某个预先设定的较小的值；\\n\\n（2）两次迭代之间权值的变化已经很小了；\\n\\n（3）设定最大迭代次数，当迭代超过最大次数就停止。\\n\\n第一种很容易理解，模型的训练目的就是为了减少 loss 值，那么我们可以设定一个比较\\n\\n小的数值，每一次训练的时候我们都同时计算一下 loss 值的大小，当 loss 值小于某个预先设\\n\\n定的阈值，就可以认为模型收敛了。那么就可以结束训练。\\n\\n74\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第二种的意思是，每一次训练我们可以记录模型权值的变化，如果我们发现两次迭代之间\\n\\n模型的权值变化已经很小，那么说明模型已经几乎不需要做权值地调整了，那么就可以认为模\\n\\n型收敛，可以结束训练。\\n\\n第三种是用得最多的方式。我们可以预先设定一个比较大的模型迭代周期，比如迭代 100\\n\\n次，或者 10000 次，或者 1000000 次等（需要根据实际情况来选择）。模型完成规定次数的\\n\\n训练之后我们就可以认为模型训练完毕。如果达到我们设置的训练次数以后我们发现模型还没\\n\\n有训练好的话，我们可以继续增加训练次数，让模型继续训练就可以了。\\n\\n3.6 模型的超参数和参数的区别\\n\\n模型的超参数（Hyperparameters）是机器学习或者深度学习中经常用到的一个概念，\\n\\n我们可以认为是根据经验来人为设置的一些模型相关的参数。比如说前面提到的学习率，学习\\n\\n率需要根据经验来人为设置。比如模型的迭代次数，也是需要在模型训练之前预先进行人为设\\n\\n置。\\n\\n而前面提到的权值和偏置值则是参数（Parameters），一般指的是模型中需要训练的变量。\\n\\n我们会给权值和偏置值进行随机初始化赋值，模型在训练过程中会不断调节这些参数，进行模\\n\\n型优化。\\n\\n75\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n3.7 单层感知器分类案例\\n\\n题目：假设我们有 4 个 2 维的数据，数据的特征分别是(3,3),(4,3),(1,1),(2,1)。(3,3),(4,3)\\n\\n这两个数据的标签为 1，(1,1),(2,1)这两个数据的标签为-1。构建神经网络来进行分类。\\n\\n思路：我们要分类的数据是 2 维数据，所以只需要 2 个输入节点（一般输入数据有几个特\\n\\n征，我们就设置几个输入神经元），我们可以把神经元的偏置值也设置成一个输入节点，使用\\n\\n3.2.3 中的方式。这样我们需要 3 个输入节点。\\n\\n输入数据有 4 个(1,3,3),(1,4,3),(1,1,1),(1,2,1)\\n\\n数据对应的标签为(1,1,-1,-1)\\n\\n初始化权值 w1,w2,w3 取 0 到 1 的随机数\\n\\n学习率 lr(learning rate)设置为 0.1\\n\\n激活函数为 sign 函数\\n\\n我们可以构建一个单层感知器如图 3.6 所示。\\n\\n图 3.6 单层感知器\\n\\n代码 3-3 为单层感知器应用案例。\\n\\n代码 3-3：单层感知器案例\\n\\n76\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3], [1,4,3], [1,1,1], [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1], [1], [-1], [-1]])\\n\\n# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 同时计算 4 个数据的预测值 # Y 的形状为(4,1)-4 行 1 列 Y = np.sign(np.dot(X,W)) # T - Y 得到 4 个的标签值与预测值的误差 E。形状为(4,1) E = T - Y # X.T 表示 X 的转置矩阵，形状为(3,4) # 我们一共有 4 个数据，每个数据 3 个值。定义第 i 个数据的第 j 个特征值为 xij # 如第 1 个数据，第 2 个值为 x12 # X.T.dot(T - Y)为一个 3 行 1 列的数据： # 第 1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第 1 个神经元对应的权值 # 第 2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第 2 个神经元对应的权值 # 第 3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整 3 个神经元对应的权值 # X.shape 表示 X 的形状 X.shape[0]得到 X 的行数，表示有多少个数据\\n\\n# X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式 3.2 看起来有些不同，原因是这里的计算是矩阵运算，书中公\\n\\n式 3.2 是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的 delta_W = lr * (X.T.dot(E)) / X.shape[0]\\n\\nW = W + delta_W\\n\\n# 训练 100 次\\n\\n77\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com for i in range(100): #更新一次权值 train() # 打印当前训练次数 print(\\'epoch:\\',i + 1) # 打印当前权值 print(\\'weights:\\',W) # 计算当前输出 Y = np.sign(np.dot(X,W)) # .all()表示 Y 中的所有值跟 T 中所有值都对应相等，结果才为真 if(Y == T).all(): print(\\'Finished\\') # 跳出循环 break\\n\\n#————————以下为画图部分————————# # 正样本的 xy 坐标 x1 = [3,4] y1 = [3,3] # 负样本的 xy 坐标 x2 = [1,2] y2 = [1,1]\\n\\n# 计算分类边界线的斜率以及截距 # 神经网络的信号总和为 w0×x0+w1×x1+w2×x2 # 当信号总和大于 0 再进过激活函数，模型的预测值会得到 1 # 当信号总和小于 0 再进过激活函数，模型的预测值会得到-1 # 所以当信号总和 w0×x0+w1×x1+w2×x2=0 时为分类边界线表达式 # 我们在画图的时候把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d = -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,\\'r\\') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c=\\'b\\') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c=\\'y\\') # 显示图案 plt.show() 运行结果如下：\\n\\n78\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com epoch: 1 weights: [[0.83669451] [0.58052698] [0.25564497]] epoch: 2 weights: [[0.73669451] [0.43052698] [0.15564497]] epoch: 3 weights: [[0.63669451] [0.28052698] [0.05564497]] …… epoch: 16 weights: [[-0.01330549] [ 0.13052698] [ 0.20564497]] epoch: 17 weights: [[-0.11330549] [-0.01947302] [ 0.10564497]] Finished\\n\\n因为权值的初始化使用的是随机的初始化方式，所以每一次训练的周期以及画出来的图\\n\\n可能都是不一样的。这里我们可以看到单层感知器的一个问题，虽然单层感知器可以顺利地\\n\\n完成分类任务，但是使用单层感知器来做分类的时候，最后得到的分类边界距离某一个类别\\n\\n比较近，而距离另一个类别比较远，并不是一个特别理想的分类效果。图 3.7 中的分类效果\\n\\n应该才是比较理想的分类效果，分界线在两个类别比较中间的位置。\\n\\n79\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.7 单层感知器比较理想的分类边界\\n\\n3.8 线性神经网络\\n\\n3.8.1 线性神经网络介绍\\n\\n线性神经网络跟单层感知器非常类似，只是把单层感知器的 sign 激活函数改成了 purelin\\n\\n函数：\\n\\n𝑦 = 𝑥\\n\\npurelin 函数也称为线性函数，函数图像如图 3.8 所示。\\n\\n80\\n\\n(3.5)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.8 线性函数\\n\\n3.8.2 线性神经网络分类案例\\n\\n参考“单层感知器案例”，我们这次使用线性神经网络来完成相同的任务。线性神经网络的\\n\\n程序跟单层感知器的程序非常相似，大家可以思考一下需要修改哪些地方。\\n\\n大家可以仔细阅读代码 3-4，找到修改了的部分。\\n\\n代码 3-4：线性神经网络案例\\n\\nimport numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3], [1,4,3], [1,1,1], [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1], [1], [-1], [-1]])\\n\\n# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 同时计算 4 个数据的预测值 # Y 的形状为(4,1)-4 行 1 列 Y = np.dot(X,W)\\n\\n81\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # T - Y 得到 4 个的标签值与预测值的误差 E。形状为(4,1) E = T - Y # X.T 表示 X 的转置矩阵，形状为(3,4) # 我们一共有 4 个数据，每个数据 3 个值。定义第 i 个数据的第 j 个特征值为 xij # 如第 1 个数据，第 2 个值为 x12 # X.T.dot(T - Y)为一个 3 行 1 列的数据： # 第 1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第 1 个神经元对应的权值 # 第 2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第 2 个神经元对应的权值 # 第 3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整 3 个神经元对应的权值 # X.shape 表示 X 的形状 X.shape[0]得到 X 的行数，表示有多少个数据 # X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式 3.2 看起来有些不同，原因是这里的计算是矩阵运算，书中公式 3.2 是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的 delta_W = lr * (X.T.dot(E)) / X.shape[0]\\n\\nW = W + delta_W\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train()\\n\\n#————————以下为画图部分————————# # 正样本的 xy 坐标 x1 = [3,4] y1 = [3,3] # 负样本的 xy 坐标 x2 = [1,2] y2 = [1,1]\\n\\n# 计算分类边界线的斜率以及截距 # 神经网络的信号总和为 w0×x0+w1×x1+w2×x2 # 当信号总和大于 0 再进过激活函数，模型的预测值会得到 1 # 当信号总和小于 0 再进过激活函数，模型的预测值会得到-1 # 所以当信号总和 w0×x0+w1×x1+w2×x2=0 时为分类边界线表达式 # 我们在画图的时候把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d = -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,\\'r\\') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c=\\'b\\')\\n\\n82\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 用黄色的点来画出负样本 plt.scatter(x2,y2,c=\\'y\\') # 显示图案 plt.show() 运行结果如下：\\n\\n线性神经网络的程序有两处是对单层感知器程序进行了修改。\\n\\n第一处是在 train()函数中，将 Y = np.sign(np.dot(X,W))改成了 Y = np.dot(X,W)。因为线性\\n\\n神经网络的激活函数是 y=x，所以这里就不需要 np.sign()了。\\n\\n第二处是在 for i in range(100)中，把原来的：\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train() # 打印当前训练次数 print(\\'epoch:\\',i + 1) # 打印当前权值 print(\\'weights:\\',W) # 计算当前输出 Y = np.sign(np.dot(X,W)) # .all()表示 Y 中的所有值跟 T 中所有值都对应相等，结果才为真 if(Y == T).all(): print(\\'Finished\\') # 跳出循环 break\\n\\n改成了：\\n\\n# 训练 100 次\\n\\n83\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com for i in range(100): #更新一次权值 train()\\n\\n在单层感知器中，当 y 等于 t 时，∆𝑤就会为 0，模型训练就结束了，所以可以提前跳出\\n\\n循环。单层感知器使用的模型收敛条件是两次迭代模型的权值已经不再发生变化，则可以认\\n\\n为模型收敛。\\n\\n而在线性神经网络中，y 会一直逼近 t 的值，不过一般不会得到等于 t 的值，所以可以对\\n\\n模型不断进行优化。线性神经网络使用的模型收敛条件是设置一个最大迭代次数，当训练了\\n\\n一定次数后就可以认为模型收敛了。\\n\\n对比单层感知器和线性神经网络所得到的结果，我们可以看得出线性神经网络所得到的\\n\\n结果会比单层感知器得到的结果更理想。但是线性神经网络也还不够优秀，当使用它处理非\\n\\n线性问题的时候，它就不能很好完成工作了。\\n\\n3.9 线性神经网络处理异或问题\\n\\n首先我们先来回顾一下异或运算：\\n\\n（1）0 与 0 异或等于 0；\\n\\n（2）0 与 1 异或等于 1；\\n\\n（3）1 与 0 异或等于 1；\\n\\n（4）1 与 1 异或等于 0。\\n\\n线性神经网络-处理异或问题的代码如代码 3-5 所示。\\n\\n代码 3-5：线性神经网络-处理异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt\\n\\n84\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 输入数据 # 4 个数据分别对应 0 与 0 异或，0 与 1 异或，1 与 0 异或，1 与 1 异或 X = np.array([[1,0,0], [1,0,1], [1,1,0], [1,1,1]]) # 标签，分别对应 4 种异或情况的结果 # 注意这里我们使用-1 作为负标签 T = np.array([[-1], [1], [1], [-1]])\\n\\n# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1])\\n\\n# 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 计算网络预测值 Y = np.dot(X,W) # 计算权值的改变 delta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n\\n# 更新权值 W = W + delta_W\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train()\\n\\n#————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1]\\n\\n85\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n#计算分界线的斜率以及截距 k = - W[1] / W[2] d = - W[0] / W[2]\\n\\n# 设定两个点 xdata = (-2,3) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,\\'r\\') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c=\\'b\\') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c=\\'y\\') # 显示图案 plt.show() 运行结果如下：\\n\\n从结果我们能够看出用一条直线并不能把异或问题中的两个类别给划分开来，因为这是一\\n\\n个非线性的问题，可以使用非线性的方式来进行求解。\\n\\n其中一种方式是我们可以给神经网络加入非线性的输入。代码 3-5 中的输入信号只有 3 个\\n\\n信 号 x0,x1,x2 ， 我 们 可 以利用 这 3 个 信 号得到 带 有非 线性特征的输入：\\n\\nx0,x1,x2,x1×x1,x1×x2,x2×x2，其中 x1×x1,x1×x2,x2×x2 为非线性特征。引入非线性输入\\n\\n的线性神经网络如图 3.9 所示。\\n\\n86\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.9 引入非线性输入的线性神经网络\\n\\n线性神经网络引入非线性特征解决异或问题的代码如代码 3-6 所示。\\n\\n代码 3-6：线性神经网络引入非线性特征解决异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt # 输入数据 # 原来 X 的 3 个特征分别为：x0,x1,x2 # X = np.array([[1,0,0], # [1,0,1], # [1,1,0], # [1,1,1]]) # 给网络输入非线性特征 # 现在 X 的 6 个特征分别为：x0,x1,x2,x1×x1,x1×x2,x2×x2 X = np.array([[1,0,0,0,0,0], [1,0,1,0,0,1], [1,1,0,1,0,0], [1,1,1,1,1,1]]) # 标签，分别对应 4 种异或情况的结果 T = np.array([[-1], [1], [1], [-1]]) # 权值初始化，6 行 1 列\\n\\n87\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # np.random.random 可以生成 0-1 的随机数 W = np.random.random([6,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 计算网络预测值 Y = np.dot(X,W) # 计算权值的改变 delta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n\\n# 更新权值 W = W + delta_W\\n\\n# 训练 1000 次 for i in range(1000): #更新一次权值 train()\\n\\n# 计算模型预测结果并打印 Y = np.dot(X,W) print(Y)\\n\\n#————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1]\\n\\n# 神经网络信号的总合为：w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2 # 当 w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2=0 时为分类边界线 # 其中 x0 为 1，我们可以把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1x + w2y + w3xx + w4xy + w5yy = 0 # 通分可得：w5y² + (w2+w4x)y + w0 + w1x + w3x² = 0 # 其中 a = w5, b = w2+w4x, c = w0 + w1x + w3x² # 根据一元二次方程的求根公式：ay²+by+c=0，y=[-b±(b^2-4ac)^(1/2)]/2a def calculate(x,root): # 定义参数 a = W[5]\\n\\n88\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com b = W[2] + x * W[4] c = W[0] + x * W[1] + x * x * W[3] # 有两个根 if root == 1: return (- b + np.sqrt(b * b - 4 * a * c)) / (2 * a) if root == 2: return (- b - np.sqrt(b * b - 4 * a * c)) / (2 * a)\\n\\n# 从-1 到 2 之间均匀生成 100 个点 xdata = np.linspace(-1,2,100) # 使用第一个求根公式计算出来的结果画出第一条红线 plt.plot(xdata,calculate(xdata,1),\\'r\\') # 使用第二个求根公式计算出来的结果画出第二条红线 plt.plot(xdata,calculate(xdata,2),\\'r\\') # 蓝色点表示正样本 plt.plot(x1,y1,\\'bo\\') # 黄色点表示负样本 plt.plot(x2,y2,\\'yo\\') # 绘图 plt.show() 运行结果如下： [[-0.98650596] [ 0.990989 ] [ 0.990989 ] [-0.99302749]]\\n\\n从输出的预测值我们可以看出，预测值与真实标签的数值是非常接近的，几乎相等，说\\n\\n明预测值很符合我们想要的结果。而从输出图片中也能观察到两条曲线的内部是负样本所属\\n\\n的类别，两条曲线的外部是正样本所属的类别。这两条曲线很好地把两个类别区分开了。\\n\\n89\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性神经网络可以通过引入非线性的输入特征来解决非线性问题，但这并不是一种非常好\\n\\n的解决方案。\\n\\n下一章节我们将介绍一种新的神经网络，BP 神经网络。通过学习 BP 神经网络我们可以获\\n\\n得更好的解决问题的思路。\\n\\n90\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 4 章-BP 神经网络\\n\\n这一章节可能是本书在数学上最难的一章，详细介绍了 BP 算法的具体推导流程。BP 算\\n\\n法是神经网络深度学习中最重要的算法之一，了解 BP 算法可以让我们更理解神经网络深度学\\n\\n习模型优化训练的本质，属于内功修行的基础内容。\\n\\n不过作为初学者我们也要学会量力而行，BP 算法的推导对于初学者来说我觉得可以作为\\n\\n选学的知识，也就是可学可不学。如果大家数学基础比较好的话，可以好好看一下本章的推导\\n\\n过程，为后面的学习打好基础。如果数学基础没这么好也没关系，关于 BP 算法的推导可以先\\n\\n跳过，我们大概知道它是神经网络深度学习的核心优化算法即可，并不会影响到我们对后面知\\n\\n识的学习，也不会影响到我们写程序做应用。我们在学习的过程中如果遇到困难，不要被它卡\\n\\n住，可以先暂时放一放，等自身积累足够多之后再回过头来看之前遇到的问题，或许就可以迎\\n\\n刃而解了。\\n\\n4.1 BP 神经网络介绍及发展背景\\n\\nBP(back propagation)神经网络是 1986 年由 Rumelhart 和 McClelland 为首的科学家\\n\\n提出的概念，他们在《Parallel Distributed Processing》[1]一书中对 BP 神经网络进行了详细\\n\\n的分析。BP 神经网络是一种按照误差逆向传播算法训练的多层前馈神经网络，它是 20 世纪\\n\\n末期神经网络算法的核心，也是如今深度学习算法的基础。\\n\\n感知器对人工神经网络的发展发挥了极大的作用，但是它的结构只有输入层和输出层，不\\n\\n能解决非线性问题的求解。Minsky 和 Papert 在颇具影响力的《Perceptron》一书中指出，\\n\\n简单的感知器只能求解线性问题，能够求解非线性问题的网络应该具有隐藏层，但是对隐藏层\\n\\n91\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n神经元的学习规则还没有合理的理论依据。从前面介绍的感知器学习规则来看，其权值的调整\\n\\n取决于期望输出与实际输出之差：\\n\\n∆𝑤( = 𝜂(𝑡 − 𝑦)𝑥(\\n\\n但是对于各个隐藏层的节点来说，不存在已知的期望输出，因而该学习规则不能用于隐藏\\n\\n层的权值调整。\\n\\nBP 算法的基本思想是，学习过程由信号的正向传播和误差的反向传播两个过程组成。\\n\\n正向传播时，把样本的特征从输入层进行输入，信号经过各个隐藏层逐层处理后，最后从\\n\\n输出层传出。对于网络的实际输出与期望输出之间的误差，把误差信号从最后一层逐层反传，\\n\\n从而获得各个层的误差学习信号，再根据误差学习信号来修正各个层神经元的权值。\\n\\n这种信号正向传播与误差反向传播，然后各个层调整权值的过程是周而复始地进行的。权\\n\\n值不断调整的过程，也就是网络学习训练的过程。进行此过程直到网络输出误差减小到预先设\\n\\n置的阈值以下，或者是超过预先设置的最大训练次数。\\n\\n4.2 代价函数\\n\\n代价函数也称为损失函数，英文称为 loss function 或 cost function，有些地方我们会看\\n\\n到使用 loss 表示代价函数的值，有些地方我们会看到用 cost 表示代价函数的值。为了统一规\\n\\n范，本书中我们统一使用代价函数这个名字，英文使用 loss。\\n\\n代价函数并没有准确的定义，一般我们可以理解为是一个人为定义的函数，我们可以利用\\n\\n这个函数来优化模型的参数。最简单常见的一个代价函数是 均方差（Mean-Square Error,\\n\\nMSE）代价函数，也称为二次代价函数：\\n\\n92\\n\\n(4.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸 =\\n\\n1 2𝑁\\n\\n(𝑇 − 𝑌)# =\\n\\n1 2𝑁\\n\\nP ?(𝑡( − 𝑦()# (A\"\\n\\n矩阵可以用大写字母来表示，这里的 T 表示真实标签，Y 表示网络输出，i 表示第 i 个数\\n\\n据。N 表示训练样本的个数(注意这里的 N 是一个大于 0 的整数，不是矩阵)\\n\\nT-Y 可以到每个训练样本与真实标签的误差。误差的值有正有负，我们可以求平方，把所\\n\\n有的误差值都变成正的，然后除以 2N。这里 2 没有特别的含义，主要是我们对均方差代价函\\n\\n数求导的时候，公式中的 2 次方的 2 可以跟分母中的 2 约掉，使得公式推导看起来更加整齐\\n\\n简洁。除以 N 表示求每个样本误差平均的平均值。\\n\\n公式可以用矩阵形式来表达，也可以拆分为用Σ来累加各个训练样本的真实标签与网络输\\n\\n出的误差的平方。\\n\\n4.3 梯度下降法\\n\\n4.3.1 梯度下降法（Gradient Descent）介绍\\n\\n在求解机器学习算法的模型参数时，梯度下降法是最常用的方法之一。在学习梯度下降法\\n\\n之前 我 们先来 了 解 一 下 导 数 （ Derivative ）、 偏导 数 （ Partial Derivative ）、 方向 导 数\\n\\n（Directional Derivative）和梯度(Gradient)的概念。\\n\\n导数 —— 导数的概念就如图 4.1 所示。\\n\\n93\\n\\n(4.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.1 导数\\n\\n导数的定义如下：\\n\\n𝑓R(𝑥<) = lim UV→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim UV→<\\n\\n𝑓(𝑥< + Δ𝑥) − 𝑓(𝑥<) Δ𝑥\\n\\n𝑓R(𝑥<)表示函数 f 在 x0 处的导数\\n\\n𝛥𝑥表示 x 的变化量\\n\\n𝛥𝑦:\\t𝑓(𝑥< + 𝛥𝑥) − 𝑓(𝑥<)表示函数的增量\\n\\n𝑙𝑖𝑚 ^V→<\\n\\n表示𝛥𝑥趋近于 0\\n\\ndx 表示 x 的变化量𝛥𝑥趋近于 0\\n\\ndy 表示𝑓R(𝑥<)𝑑𝑥\\n\\n总的来说𝑓R(𝑥<)反映的是函数𝑦 = 𝑓(𝑥)在 x 轴上某一点处沿 x 轴正方向的变化率/变化趋\\n\\n势。也就是在 x 轴上的某一点，如果𝑓′(𝑥)＞0，说明𝑓(𝑥)的函数值在 x 点沿 x 轴正方向是趋\\n\\n向于增加的；如果𝑓′(𝑥) < 0，说明𝑓(𝑥)的函数值在 x 点沿 x 轴正方向是趋向于减小的。\\n\\n偏导数 —— 偏导数的定义如下：\\n\\n94\\n\\n(4.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝜕 𝜕𝑥(\\n\\n𝑓(𝑥<, 𝑥\", … , 𝑥@) = lim UV→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim UV→<\\n\\n𝑓(𝑥<, … , 𝑥( + Δ𝑥, … , 𝑥@) − 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) Δ𝑥\\n\\n可以看到，导数与偏导数本质是一致的，都是当自变量的变化量趋近于 0 时，函数值的\\n\\n变化量与自变量变化量比值的极限。直观地说，偏导数也就是函数在某一点上沿坐标轴正方\\n\\n向的的变化率。\\n\\n区别在于：\\n\\n导数，指的是一元函数中，函数𝑦 = 𝑓(𝑥)在某一点处沿 x 轴正方向的变化率；\\n\\n偏导数，指的是多元函数中，函数𝑦 = 𝑓(𝑥<, 𝑥\", … , 𝑥@)在某一点处沿某一坐标轴\\n\\n(𝑥<, 𝑥\", … , 𝑥@)正方向的变化率。\\n\\n方向导数 —— 方向导数的定义如下：\\n\\n𝜕 𝜕𝑙\\n\\n𝑓(𝑥<, 𝑥\", … , 𝑥@) = lim Ue→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim Ue→<\\n\\n𝑓(𝑥< + Δ𝑥<, … , 𝑥( + Δ𝑥(, … , 𝑥@ + Δ𝑥@) − 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) 𝜌\\n\\n其中𝜌 = g(Δ𝑥<)# + ⋯ + (Δ𝑥()# + ⋯ + (Δ𝑥@)#\\n\\n𝑙表示某个方向\\n\\n在前面导数和偏导数的定义中，均是沿坐标轴正方向讨论函数的变化率。那么当我们讨\\n\\n论函数沿任意方向的变化率时，也就引出了方向导数的定义，即：某一点在某一趋近方向上\\n\\n的导数值。\\n\\n通俗的解释是：\\n\\n我们不仅要知道函数在坐标轴正方向上的变化率（即偏导数），而且还要设法求得函数在\\n\\n其他特定方向上的变化率。而方向导数就是函数在其他特定方向上的变化率。\\n\\n梯度 —— 梯度的定义如下：\\n\\n95\\n\\n(4.4)\\n\\n(4.5)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑔𝑟𝑎𝑑𝑓(𝑥<, 𝑥\", … , 𝑥@) = l\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥(\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥@\\n\\nm\\n\\n对 于 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) 上 的 某 一 点 来 说存在很 多个方向导数，梯度的方向是函数\\n\\n𝑓(𝑥<, … , 𝑥(, … , 𝑥@)在某一点增长最快的方向，梯度的模则是该点上方向导数的最大值，梯度的\\n\\n模等于：\\n\\n|𝑔𝑟𝑎𝑑𝑓(𝑥<, 𝑥\", … , 𝑥@)| = o(\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n)# + ⋯ + l\\n\\n𝜕𝑓 𝜕𝑥(\\n\\nm\\n\\n#\\n\\n+ ⋯ + (\\n\\n𝜕𝑓 𝜕𝑥@\\n\\n)#\\n\\n这里注意三点：\\n\\n1. 梯度是一个向量，即有方向有大小\\n\\n2. 梯度的方向是最大方向导数的方向\\n\\n3. 梯度的值是最大方向导数的值\\n\\n梯度下降法 —— 既然在变量空间的某一点处，函数沿梯度方向具有最大的变化率，那么\\n\\n在优化代价函数的时候，就可以沿着负梯度方向去减小代价函数的值。计算过程可以描述如下：\\n\\n𝑅𝑒𝑝𝑒𝑎𝑡{\\n\\n𝑥< = 𝑥< − 𝜂\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n………\\n\\n𝑥( = 𝑥( − 𝜂\\n\\n𝜕𝑓 𝜕𝑥(\\n\\n………\\n\\n𝑥@ = 𝑥@ − 𝜂\\n\\n𝜕𝑓 𝜕𝑥@\\n\\n}\\n\\n𝑅𝑒𝑝𝑒𝑎𝑡表示不断重复\\n\\n96\\n\\n(4.6)\\n\\n(4.7)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑥 = 𝑥 − 𝜂\\n\\nuv\\n\\nuV\\n\\n表示参数调整，𝜂表示学习率\\n\\n4.3.2 梯度下降法（Gradient Descent）二维例子\\n\\n4.2 中我们已经知道了代价函数的定义，代价函数的值越小，说明模型的预测值越接近真\\n\\n实标签的值。代价函数中的预测值 y 是跟神经网络中的参数 w 和 b 相关的。我们可以先考虑\\n\\n一个简单的情况，假如神经网络只有一个参数 w，参数 w 与代价函数 loss 的关系如图 4.2 所\\n\\n示。\\n\\n图 4.2 参数 w 与代价函数 loss 的关系图\\n\\n假设 w 的初始值是-3，我们需要使用梯度下降法来不断优化 w 的取值，使得 loss 值不\\n\\n断减少，首先我们应该先计算 w=-3 时的梯度，如图 4.3 所示。\\n\\n97\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n98\\n\\n图 4.3 w 为-3 时的梯度\\n\\n从图 4.3 中我们可以看出，当 w 为-3 时，w 所处位置的梯度应该是一个负数，梯度下降\\n\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个正数，\\n\\nw 的值应该变大。根据梯度下降法的优化公式：\\n\\n𝑤 = 𝑤 − 𝜂\\n\\n𝜕𝑓 𝜕𝑤\\n\\n(4.8)\\n\\n学习率𝜂一般是一个大于 0 的数，\\n\\nuv\\n\\nux\\n\\n为负数，我们可以判断出 w 的值会变大。变大的数值\\n\\n跟学习率大小𝜂有关，也跟函数 f 在 w 处的梯度大小有关。\\n\\n假设 w 变大移动到了 w=2 的位置，我们需要再次计算 w=2 时的梯度，如图 4.4 所示。\\n\\n图 4.4 w 为 2 时的梯度\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从图 4.4 中我们可以看出，当 w 为 2 时，w 所处位置的梯度应该是一个正数，梯度下降\\n\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个负数，\\n\\nw 的值应该变小。\\n\\n学习率𝜂一般是一个大于 0 的数，\\n\\nuv\\n\\nux\\n\\n为正数，我们可以判断出 w 的值会变小。变小的数值\\n\\n跟学习率大小𝜂有关，也跟函数 f 在 w 处的梯度大小有关。\\n\\n我们可以发现不管 w 处于那一个位置，当 w 向着负梯度的方向进行移动时，实际上就是\\n\\n向着可以使 loss 值减小的方向进行移动。这就有点类似一个小球在山坡上面，它总是往坡底\\n\\n的方向进行移动，只不过它每一次是移动一步，这个步子的大小会受到学习率和所处位置梯度\\n\\n的大小所影响。\\n\\n4.3.3 梯度下降法（Gradient Descent）三维例子\\n\\n我们可以再考虑一个稍微复杂一点点的情况，假如神经网络有两个参数 w1 和 w2，参数\\n\\nw1 和 w2 与代价函数 loss 的关系如图 4.5 所示。\\n\\n图 4.5 w1 和 w2 与 loss 的关系图\\n\\n99\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们在图中随机选取两个 w1 和 w2 的初始值 p1 和 p2，然后从 p1,p2 这两个初始位置\\n\\n开始使用梯度下降法优化网络参数，得到如图 4.6 所示的结果。\\n\\n图 4.6 从 p1,p2 初始点开始优化网络\\n\\n图 4.6 中可以看到网络参数的优化过程其实就是 p1,p2 两个“小球“从初始点开始，每次\\n\\n移动一步，不断向坡底进行移动。在这个过程中整个网络的 loss 值是在不断变小的。\\n\\n同时我们还可以观察到一个现象， p1“小球“最后走到了图中的 全局最小值（ Global\\n\\nMinimum），而 p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我\\n\\n们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果，有些时候我们可以\\n\\n得到 loss 的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是 loss 的局\\n\\n部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存\\n\\n在的一个缺点。\\n\\n100\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过大家不用太担心这个问题，一般实际模型训练的时候局部极小值的情况不常出现。如\\n\\n果我们担心模型得到的结果是局部极小值的话可以让模型多训练几次，然后取最好的那一次结\\n\\n果作为模型的最终结果就可以了。\\n\\n4.4 Delta 学习规则\\n\\n1986 年，认知心理学家 McClelland 和 Rumelhart 在神经网络训练中引入了𝛿（Delta）\\n\\n规则，该规则也可以称为连续感知器学习规则。\\n\\n𝛿（Delta）学习规则是一种利用梯度下降法的一般性的学习规则，其实就是利用梯度下降\\n\\n法来最小化代价函数。比如代价函数为前面公式 4.2 介绍的均方差代价函数，为了简单我们只\\n\\n计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。一个样\\n\\n本\\n\\n的均方差公式定义\\n\\n如下\\n\\n：\\n\\n𝐸 =\\n\\n\"\\n\\n#\\n\\n(𝑇 − 𝑌)# =\\n\\n\"\\n\\n#\\n\\n(𝑡 − 𝑦)# =\\n\\n\"\\n\\n#\\n\\n(𝑡 − 𝑓(𝑊𝑋))#\\n\\n误差 E 是 W 的函数，我们可以使用梯度下降法来最小化 E 的值，权值矩阵的变化∆W等\\n\\n于负的学习率−𝜂乘以 E 对 W 进行求导：\\n\\n∆𝑊 = −𝜂𝐸R = 𝜂𝑋~(𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑋~𝛿\\n\\n注意这里的 X 和 W 都是矩阵，所以这里求导的时候是对矩阵 W 进行求导，矩阵求导的\\n\\n方式跟单个元素求导的方式有一些不同。下面公式是单个 w 元素的权值变化计算：\\n\\n∆𝑤( = −𝜂𝐸R = 𝜂𝑥((𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑥(𝛿\\n\\n这里的𝛿（Delta）符号没有什么特别的含义，就是用来替代(𝑡 − 𝑦)𝑓R(𝑊𝑋)。∆𝑤(表示第 i\\n\\n个权值的变化。\\n\\n101\\n\\n(4.9)\\n\\n(4.10)\\n\\n(4.11)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在上一章节中关于单层感知器的权值变化公式是如何得到的还没有解释，这里我们可以看\\n\\n到当我们使用线性激活函数 y=x 时，激活函数的导数𝑓R(𝑊𝑋) = 1，所以：\\n\\n∆𝑤( = −𝜂𝐸R = 𝜂𝑥((𝑡 − 𝑦)\\n\\n公式 4.12 跟感知器的学习规则公式 3.2 是一样的，所以使用 Delta 学习规则我们可以推\\n\\n导出感知器的学习规则。\\n\\n4.5 常用激活函数讲解\\n\\n神经网络的激活函数其实有很多种，在前面的章节中我们介绍过两种激活函数，sign 函\\n\\n数和 purelin 函数。sign 函数也称为符号函数，因为 sign(x)中 x＞0，函数结果为 1；sign(x)\\n\\n中 x＜0，函数结果为-1。purelin 函数也称为线性函数，表达式为 y=x。这两种激活函数在处\\n\\n理复杂非线性问题的时候都不能得到很好的结果，线性函数的分类边界也是线性的，所以不能\\n\\n区别非线性的复杂边界，比如一条直线不能区分异或问题的两个类别。下面我们介绍几个在 BP\\n\\n神经网络中常用的非线性激活函数，sigmoid 函数，tanh 函数，softsign 函数和 ReLU 函\\n\\n数，使用这些非线性激活函数可以帮助我们解决复杂的非线性问题。\\n\\n4.5.1 sigmoid 函数\\n\\nsigmoid 函数 —— sigmoid 函数也称为逻辑函数(logical function)，函数的公式为\\n\\n𝑓(𝑥) =\\n\\n1 1 + 𝑒(cid:127)V\\n\\n函数图像如图 4.7 所示。\\n\\n102\\n\\n(4.12)\\n\\n(4.13)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.7 sigmoid 函数图像\\n\\n图中我们可以看出函数的取值范围是 0-1 之间，当 x 趋向于-∞的时候函数值趋向于 0；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n4.5.2tanh 函数\\n\\ntanh 函数 —— tanh 函数也称为双曲正切函数，函数的公式为\\n\\n𝑓(𝑥) =\\n\\n𝑒 V − 𝑒(cid:127)V 𝑒V + 𝑒(cid:127)V\\n\\n函数图像如图 4.8 所示。\\n\\n103\\n\\n(4.14)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.8 tanh 函数图像\\n\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n4.5.3 softsign 函数\\n\\nsoftsign 函数 —— softsign 函数的公式为： 𝑥 1 + |𝑥|\\n\\n𝑓(𝑥) =\\n\\n函数图像如图 4.9 所示。\\n\\n图 4.9 softsign 函数图像\\n\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n我们可以通过图 4.10 对比一下这三种函数的区别。\\n\\n104\\n\\n(4.15)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.10 三种函数对比\\n\\n它们这三个激活函数都是 S 形函数，形状相似，只不过 sigmoid 函数取值范围是 0-1 之\\n\\n间，tanh 函数和 softsign 函数取值范围是-1-1 之间。我们还可以观察到 softsign 函数相对\\n\\n于 tanh 函数而言过渡更加平滑，在 x 等于 0 附近函数的数值改变更缓慢。\\n\\n4.5.4 ReLU 函数\\n\\n该函数最早源自 2011 年的一篇论文《Deep Sparse Rectifier Neural Networks》[2]。\\n\\n它是模拟生物神经元的激活函数设计出来的一个人工神经网络激活函数。图 4.11 为生物神经\\n\\n元放电曲线图。\\n\\n105\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.11 生物神经元放电曲线图[2]\\n\\n图 4.11 中可以看到当输入电压不足时，生物神经元放电为 0，电压达到一定的阈值以后\\n\\n生物神经元才会开始放电，并且放电速率跟输入电压成正相关关系。\\n\\nReLU 函数 —— ReLU(The Rectified Linear Unit)函数的公式为\\n\\n𝑓(𝑥) = max\\t(0, 𝑥)\\n\\n函数图像如图 4.12 所示。\\n\\n图 4.12 ReLU 函数图像\\n\\n106\\n\\n(4.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n当 x 小于 0 时，y 等于 0。当 x 大于 0 时，y 等于 x。ReLU 的中文名称是校正线性单\\n\\n元，虽然在 x 小于 0 时函数是线性的，x 大于 0 时函数也是线性的，但是组合起来之后，函\\n\\n数就具有了非线性的特征。这种非线性的特征是怎么体现的呢，我们可以观察下面的一系列\\n\\n图片，首先看到图 4.13。\\n\\n图 4.13 使用 tanh 作为激活函数的分类边界\\n\\n图 4.13 使用的是 tanh 作为激活函数训练出来的分类模型，其实使用 sigmoid 或者\\n\\nsoftsign 函数也可以得到类似结果。我使用了带有 4 个隐藏层的神经网训练了出了这个模\\n\\n型，图中有两个类别的数据，并且我们可以观察到一个类似椭圆形的分类边界把两个类别给\\n\\n区分开了。我们再观察图 4.14：\\n\\n107\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.14 使用 ReLu 作为激活函数的分类边界\\n\\n我使用带有 4 个隐藏层的神经网络训练出了这个模型。我们发现使用 ReLU 激活函数得\\n\\n到的分类边界跟使用 tanh 激活函数得到分类边界是差不多的，并不能看出 ReLU 函数的特\\n\\n点。同样的一个学习任务和数据，我改变了神经网络的层数，只使用 2 个隐藏层，依然使用\\n\\nReLU 激活函数得到了图 4.15 所示的结果。\\n\\n图 4.15 使用 ReLU 作为激活函数的分类边界\\n\\n我们观察图 4.15 可以得到一些结论：\\n\\n（1）我们可以发现 ReLU 激活函数所描绘出来的边界其实是一条一条的直线构成的，不\\n\\n存在曲线。图 4.14 中的边界看起来像一个椭圆，实际上它也是由一段一段很小的直线构成\\n\\n的。\\n\\n（2）神经网络的层数会影响模型的拟合效果，层数越多，模型就可以拟合出更复杂的分\\n\\n类边界。\\n\\n模型的拟合效果其实还跟其他一些因素相关，比如说每一层隐藏层的神经元越多，那么模\\n\\n型的拟合能力也就越强。模型训练的周期越多，模型的拟合能力就越强。关于模型拟合强弱的\\n\\n问题，再后面的章节中我们还会进一步讨论。\\n\\n108\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n另外我们再来看一下 ReLU 应用于回归预测时的特点，我看一下图 4.16 和图 4.17。\\n\\n图 4.16 使用 tanh 激活函数训练的回归模型\\n\\n图 4.17 使用 ReLU 激活函数训练的回归模型\\n\\n我们发现了跟分类中类似的情况，tanh 激活函数得到的回归线是一条曲线，而 ReLU 激\\n\\n活函数得到的是由一段一段直线构成的回归线。\\n\\n大家可以思考一个问题，上面介绍的这几个激活函数，哪一个效果比较好，为什么？这\\n\\n个问题在 4.8 小节中我们再继续讨论。\\n\\n109\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.6 BP 网络模型和公式推导\\n\\n这一小节我们将学习 BP 算法的推导流程，如果觉得这个小节内容有一定难度可以直接跳\\n\\n到下一小节进行学习。BP 算法其实是在 Delta 学习规则的基础上做了进一步的推广，Delta 是\\n\\n对单层感知器定义了计算流程和代价函数，然后用梯度下降法来最小化代价函数。BP 算法是\\n\\n对多层神经网络定义了计算流程和代价函数，然后再使用梯度下降法来最小化代价函数。由于\\n\\nBP 算法的广泛使用，所以一般的全连接多层神经网络我们也称为 BP 神经网络。\\n\\nBP 网络中不仅有输入层和输出层，在输入层和输出层中间还可以添加隐藏层。输入层的\\n\\n神经元个数一般跟输入数据相关，输出层的神经元个数一般跟标签相关，而网络中间的隐藏层\\n\\n的层数和隐藏层神经元的个数都是超参数。也就是说隐藏层的层数以及隐藏层每一层的神经元\\n\\n个数我们都可以随意设置，主要靠经验和实验来决定。通常来说隐藏层的层数越多，隐藏层每\\n\\n一层神经元个数越多，这个神经网络结构就越复杂，越能拟合复杂的函数曲线，处理复杂的分\\n\\n类回归问题。反之，隐藏层层数越少，隐藏层每一层神经元个数越少，网络结构就越简单，它\\n\\n所能够拟合的函数曲线就越简单，比较适合处理简单的分类回归问题。\\n\\n网络的结构不是越复杂越好，也不是越简单越好。网络的结构复杂度需要跟我们要解决的\\n\\n问题相关，如果问题越复杂，那么网络结构就要越复杂；如果问题简单，那么就要用结构简单\\n\\n的网络来建模。如果网络结构的复杂度跟要解决的问题不匹配的话就会出现 欠拟合（Under-\\n\\nFitting）或者过拟合（Over-Fitting）。什么是欠拟合（Under-Fitting）和过拟合（Over-Fitting），\\n\\n在后面的章节中再详细介绍。总之一个好的网络结构是需要很多的经验加大量的实验才能获得。\\n\\n110\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.6.1 BP 网络模型[3]\\n\\n假设我们有一个 2 层（统计神经网络层数的时候一般输入层忽略不计）的神经网络如图\\n\\n4.18 所示。\\n\\n图 4.18 BP 神经网络\\n\\n该网络的输入向量为𝑋 = (𝑥\", 𝑥#, … , 𝑥(, … , 𝑥@)，图中𝑥< = 1表示输入层偏置值。隐藏层输\\n\\n出向量为𝑌\" = (𝑦\"\\n\\n\", 𝑦#\\n\\n\", … , 𝑦(cid:129)\\n\\n\", … , 𝑦(cid:130)\\n\\n\" )，图中𝑦<\\n\\n\" = 1表示隐藏层偏置值。输出层输出向量为𝑌# =\\n\\n#, 𝑦#\\n\\n#, … , 𝑦(cid:131)\\n\\n#, … , 𝑦(cid:132)\\n\\n(𝑦\"\\n\\n#)。期望输出𝑇 = (𝑡\", 𝑡#, … , 𝑡(cid:131), … , 𝑡(cid:132))。输入层到隐藏层之间的权值用矩阵\\n\\n𝑊\"表示，𝑤((cid:129)\\n\\n\" 表示𝑊\"矩阵中第 i 行第 j 列的权值。隐藏层到输出层之间的权值用矩阵𝑊#表\\n\\n# 表示𝑊#矩阵中第 j 行第 k 列的权值。另外我们定义𝑛𝑒𝑡\"为隐藏层中权值𝑊\"乘以输入\\n\\n示，𝑤(cid:129)(cid:131)\\n\\n层信号𝑋的总和，𝑛𝑒𝑡(cid:129)\\n\\n\"表示隐藏层中第 j 个神经元得到的输入信号总和。𝑛𝑒𝑡#为输出层中权值\\n\\n𝑊#乘以隐藏层信号𝑌\"的总和，𝑛𝑒𝑡(cid:131)\\n\\n#表示输出层中第 k 个神经元得到的输入信号总和。\\n\\n对于隐藏层有：\\n\\n111\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n@ \" = ? 𝑤((cid:129) (A< \" = 𝑓(𝑛𝑒𝑡(cid:129) 𝑦(cid:129)\\n\\n\" 𝑥(\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 1,2, … , 𝑚\\n\\n𝑛𝑒𝑡(cid:129)\\n\\n\")\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 1,2, … , 𝑚\\n\\n对于输出层有：\\n\\n(cid:130) # = ? 𝑤(cid:129)(cid:131) (cid:129)A<\\n\\n# 𝑦(cid:129)\\n\\n\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘 = 1,2, … , 𝑙\\n\\n𝑛𝑒𝑡(cid:131)\\n\\n# = 𝑓(𝑛𝑒𝑡(cid:131) 𝑦(cid:131)\\n\\n#)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘 = 1,2, … , 𝑙\\n\\n公式 4.18 和 4.20 中的激活函数假设我们都使用 sigmoid 函数，sigmoid 函数的公式在\\n\\n上文中的公式 4.13。sigmoid 函数具有连续、可导的特点，它的导数为：\\n\\n𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]\\n\\n4.6.2 BP 算法推导\\n\\n根据上文中提到的代价函数，当网络输出与期望输出不同时，会存在输出误差 E，为了简\\n\\n单我们只计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。\\n\\n一个样本的均方差公式定义如下：\\n\\n𝐸 =\\n\\n1 2\\n\\n(𝑇 − 𝑌#)# =\\n\\n1 2\\n\\n(cid:132) ?(𝑡(cid:131) − 𝑦(cid:131) (cid:131)A\"\\n\\n#)#\\n\\n将以上误差定义式展开至隐藏层：\\n\\n𝐸 =\\n\\n1 2\\n\\n(cid:132) ?[𝑡(cid:131) − 𝑓(𝑛𝑒𝑡(cid:131) (cid:131)A\"\\n\\n#)\\t]#\\n\\n=\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n再进一步展开至输入层：\\n\\n112\\n\\n(4.17)\\n\\n(4.18)\\n\\n(4.19)\\n\\n(4.20)\\n\\n(4.21)\\n\\n(4.22)\\n\\n(4.23)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n113\\n\\n𝐸 =\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n# 𝑓(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n\"(cid:143)\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n=\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n@ # 𝑓 >? 𝑤((cid:129) (A<\\n\\n\" 𝑥(\\n\\nB\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n(4.24)\\n\\n从公式 4.23 和 4.24 中可以看出，网络的误差 E 是跟神经网络各层权值𝑤((cid:129)\\n\\n\" 和𝑤(cid:129)(cid:131)\\n\\n# 相关的，\\n\\n因此调整各层的权值，就可以改变误差 E 的值。我们的目标就是要得到比较小的误差值，所以\\n\\n我们可以采用梯度下降法来最小化误差 E 的值。根据梯度下降法，我们可以得到：\\n\\n\" = −𝜂\\n\\n∆𝑤((cid:129)\\n\\n𝜕𝐸 𝜕𝑤((cid:129)\\n\\n\" \\t\\t\\t\\t\\t\\t\\t\\t𝑖 = 0,1,2, … , 𝑛; 𝑗 = 1,2, … , 𝑚\\n\\n(4.25)\\n\\n# = −𝜂\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n𝜕𝐸 𝜕𝑤(cid:129)(cid:131)\\n\\n# \\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 0,1,2, … , 𝑚; 𝑘 = 1,2, … , 𝑙\\n\\n(4.26)\\n\\n在下面的推导过程中均默认对于隐藏层有 ：𝑖 = 0,1,2, … , 𝑛; 𝑗 = 1,2, … , 𝑚；对于输出层有：\\n\\n𝑗 = 0,1,2, … , 𝑚; 𝑘 = 1,2, … , 𝑙。\\n\\n根据微积分的链式法则可以得到，对于隐藏层有：\\n\\n\" = −𝜂\\n\\n∆𝑤((cid:129)\\n\\n𝜕𝐸 𝜕𝑤((cid:129)\\n\\n\" = −𝜂\\n\\n𝜕𝐸 \" 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" 𝜕𝑛𝑒𝑡(cid:129) \" 𝜕𝑤((cid:129)\\n\\n(4.27)\\n\\n根据微积分的链式法则可以得到，对于输出层有：\\n\\n# = −𝜂\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n𝜕𝐸 𝜕𝑤(cid:129)(cid:131)\\n\\n# = −𝜂\\n\\n𝜕𝐸 # 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# 𝜕𝑛𝑒𝑡(cid:131) # 𝜕𝑤(cid:129)(cid:131)\\n\\n(4.28)\\n\\n我们可以定义一个误差信号，命名为𝛿（Delta），令：\\n\\n\" = − δ(cid:129)\\n\\n𝜕𝐸 \" 𝜕𝑛𝑒𝑡(cid:129)\\n\\n(4.29)\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 # 𝜕𝑛𝑒𝑡(cid:131)\\n\\n(4.30)\\n\\n综合公式 4.17,4.27,4.29，可以得到输入层到隐藏层的权值调整公式为：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n114\\n\\n\" = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n\"𝑥(\\n\\n(4.31)\\n\\n综合公式 4.19,4.28,4.30，可以得到隐藏层到输出层的权值调整公式为：\\n\\n# = 𝜂δ(cid:131)\\n\\n\" #𝑦(cid:129)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n(4.32)\\n\\n可以看出在公式 4.31 和 4.32 中，只要求出δ(cid:129)\\n\\n\"和δ(cid:131)\\n\\n#的值，就可以计算出∆𝑤((cid:129)\\n\\n\" 和∆𝑤(cid:129)(cid:131)\\n\\n# 的值\\n\\n了。\\n\\n对于隐藏层，δ(cid:129)\\n\\n\"可以展开为：\\n\\n\" = − δ(cid:129)\\n\\n𝜕𝐸 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" = −\\n\\n𝜕𝐸 \" 𝜕𝑦(cid:129)\\n\\n\" 𝜕𝑦(cid:129) 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" = −\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\"(cid:143) \" 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n(4.33)\\n\\n对于输出层，δ(cid:131)\\n\\n#可以展开为：\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# = −\\n\\n𝜕𝐸 # 𝜕𝑦(cid:131)\\n\\n# 𝜕𝑦(cid:131) 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# = −\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n#) # 𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n(4.34)\\n\\n在公式 4.33 和 4.34 中，求网络误差对各层输出的偏导，对于输出层：\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n#) # = −(𝑡(cid:131) − 𝑦(cid:131)\\n\\n(4.35)\\n\\n对于隐藏层：\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\" =\\n\\n𝜕\\n\\n1 2\\n\\n(cid:132) (cid:131)A\"\\n\\n(cid:130) (cid:129)A<\\n\\n∑ (cid:146)𝑡(cid:131) − 𝑓(cid:142)∑ 𝑤(cid:129)(cid:131) \" 𝜕𝑦(cid:129)\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:143)\\t(cid:147)\\n\\n#\\n\\n(cid:132)\\n\\n(cid:130)\\n\\n(cid:130)\\n\\n= − ? (cid:148)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131)\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:140)(cid:149) 𝑓R (cid:139)? 𝑤(cid:129)(cid:131)\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:140)\\n\\n# 𝑤(cid:129)(cid:131)\\n\\n(cid:131)A\"\\n\\n(cid:129)A<\\n\\n(cid:129)A<\\n\\n(cid:132)\\n\\n= − ?(𝑡(cid:131) − 𝑦(cid:131)\\n\\n#) #)𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n# 𝑤(cid:129)(cid:131)\\n\\n(4.36)\\n\\n(cid:131)A\"\\n\\n将式（4.35）带入式（4.34），再根据 sigmoid 函数的求导式（4.21），可以得到：\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n# 𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n#) = (𝑡(cid:131) − 𝑦(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#) #(1 − 𝑦(cid:131)\\n\\n(4.37)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n\" = − δ(cid:129)\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\" 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n(cid:132) \"(cid:143) = >?(𝑡(cid:131) − 𝑦(cid:131) (cid:131)A\"\\n\\n#) #)𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n# B 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n(cid:132)\\n\\n= >?(𝑡(cid:131) − 𝑦(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#) #(1 − 𝑦(cid:131)\\n\\n# B 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n(cid:131)A\"\\n\\n(cid:132) # = >? δ(cid:131) (cid:131)A\"\\n\\n# B 𝑦(cid:129)\\n\\n\"(cid:142)1 − 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n将公式 4.37 带入 4.32 中，得到隐藏层到输出层权值调整：\\n\\n# = 𝜂δ(cid:131)\\n\\n#𝑦(cid:129)\\n\\n\" = 𝜂(𝑡(cid:131) − 𝑦(cid:131)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#(1 − 𝑦(cid:131)\\n\\n\" #)𝑦(cid:129)\\n\\n将公式 4.38 带入 4.31 中，得到输入层到隐藏层权值调整：\\n\\n(cid:132)\\n\\n\" = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n# \"𝑥( = 𝜂 >? δ(cid:131)\\n\\n# B 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:142)1 − 𝑦(cid:129)\\n\\n\"(cid:143)𝑥(\\n\\n(cid:131)A\"\\n\\n对于一个多层的神经网络，假设一共有 h 个隐藏层，按顺序将各隐藏层节点数分别记\\n\\n为：𝑚\", 𝑚#, … , 𝑚(cid:150)，输入神经元个数为 n，输出神经元个数为𝑙；各隐藏层输出分别记为：\\n\\n𝑌\", 𝑌#, … , 𝑌(cid:150)，输入层的输入记为：𝑋，输出层的输出记为：𝑌(cid:150)(cid:151)\"；各层权值矩阵分别记为：\\n\\n𝑊\", 𝑊#, … , 𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输\\n\\n出层的权值矩阵；各层学习信号分别记为：𝜹\", 𝜹#, … , 𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信\\n\\n号；则各层权值调整计算公式为：\\n\\n对于输出层：\\n\\n(cid:153)(cid:151)\" = 𝜂δ(cid:131)\\n\\n(cid:150)(cid:151)\"𝑦(cid:129)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n(cid:150) = 𝜂(cid:142)𝑡(cid:131) − 𝑦(cid:131)\\n\\n(cid:150)(cid:151)\"(cid:143)𝑦(cid:131)\\n\\n(cid:150)(cid:151)\"(cid:142)1 − 𝑦(cid:131)\\n\\n(cid:150) (cid:150)(cid:151)\"(cid:143)𝑦(cid:129)\\n\\n𝑗 = 0,1,2, … , 𝑚(cid:150); 𝑘 = 1,2, … , 𝑙\\n\\n对于第 h 隐藏层：\\n\\n(cid:132)\\n\\n(cid:153) = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n(cid:150)𝑦(\\n\\n(cid:150)(cid:127)\" = 𝜂 >? δ(cid:131)\\n\\n(cid:150)(cid:151)\"\\n\\n(cid:150)(cid:151)\"B 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n(cid:150)(cid:142)1 − 𝑦(cid:129)\\n\\n(cid:150)(cid:143)𝑦(\\n\\n(cid:150)(cid:127)\"\\n\\n(cid:131)A\"\\n\\n𝑖 = 0,1,2, … , 𝑚(cid:150)(cid:127)\"; 𝑗 = 1,2, … , 𝑚(cid:150)\\n\\n按照以上规律逐层类推，则第一个隐藏层的权值调整公式为：\\n\\n115\\n\\n(4.38)\\n\\n(4.39)\\n\\n(4.40)\\n\\n(4.41)\\n\\n(4.42)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n(cid:130)(cid:157)\\n\\n\" = 𝜂δ(cid:155)\\n\\n# \"𝑥(cid:154) = 𝜂 (cid:139)? δ(cid:156)\\n\\n∆𝑤(cid:154)(cid:155)\\n\\n# (cid:140) 𝑦(cid:155)\\n\\n\"(cid:142)1 − 𝑦(cid:155)\\n\\n𝑤(cid:155)(cid:156)\\n\\n\"(cid:143)𝑥(cid:154)\\n\\n(cid:156)A\" 𝑝 = 0,1,2, … , n; 𝑞 = 1,2, … , 𝑚\"\\n\\n4.6.3 BP 算法推导的补充说明\\n\\n我们已经从头到尾详细推导了一遍 BP 算法的整个流程，在这一小节中对 BP 算法再做两\\n\\n点补充说明。\\n\\n1.网络的偏置值\\n\\n在上文中我们的推导过程一直是使用权值 w 来进行计算的，如果我们把偏置值独立出来，\\n\\n那么偏置值的参数应该怎么调整呢？\\n\\n我们可以看到公式 4.31 以及 4.32，在公式 4.31 中，把 i 的取值设置为 0，并且我们知道\\n\\n𝑥< = 1，所以我们可以得到：\\n\\n\" \" = 𝜂δ(cid:129)\\n\\n∆𝑏(cid:129)\\n\\n在公式 4.31 中，把 j 的取值设置为 0，并且我们知道𝑦< = 1，所以我们可以得到：\\n\\n# # = 𝜂δ(cid:131)\\n\\n∆𝑏(cid:131)\\n\\n如果是把偏置值单独拿出来计算的话就是公式 4.44 和 4.45 的表达式。\\n\\n2.用矩阵形式来表达 BP 学习算法\\n\\n下面我们直接给出 BP 学习算法矩阵表达形式的结果，具体推导过程跟上文中的推导过程\\n\\n类似，不过会涉及到矩阵求导的相关知识，大家有兴趣的话可以自己推导一下。如果是把 BP\\n\\n学习算法写成矩阵的形式来表达，假设一共有 h 个隐藏层。输入数据的矩阵为𝑋，𝑋中的每一\\n\\n行表示一个数据，列表示数据的特征。比如我们一次性输入 3 个数据，每个数据有 4 个特\\n\\n征，那么𝑋就是一个 3 行 4 列的矩阵。\\n\\n116\\n\\n(4.43)\\n\\n(4.44)\\n\\n(4.45)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n各隐藏层输出分别记为：𝑌\", 𝑌#, … , 𝑌(cid:150)，输出层的输出记为：𝑌(cid:150)(cid:151)\"。𝑌中的每一个行表示\\n\\n一个数据的标签。比如我们有 3 个数据，每个数据有 1 个标签，那么𝑌就是一个 3 行 1 列的\\n\\n矩阵。\\n\\n各层权值矩阵分别记为：𝑊\", 𝑊#, … , 𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，\\n\\n𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输出层的权值矩阵。权值矩阵的行等于前一层的神经元个数，权\\n\\n值矩阵的列对应于后一层的神经元个数。比如在输入层和第一个隐藏层之间的权值矩阵是\\n\\n𝑊\"，输入层有 3 个神经元，第一个隐藏层有 10 个神经元，那么𝑊\"就是一个 3 行 10 列的矩\\n\\n阵。\\n\\n各层学习信号分别记为：𝜹\", 𝜹#, … , 𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信号。\\n\\n对于输出层的学习信号𝜹(cid:150)(cid:151)\"：\\n\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t= (𝑇 − 𝑌ℎ+1) ∘ 𝑌ℎ+1 ∘ (1 − 𝑌ℎ+1)\\n\\n公式 4.46 中的\" ∘ \"符号是 element-wise multiplication，意思是矩阵中的元素对应相\\n\\n乘。例如下面的例子：\\n\\n𝑎\"\" 𝑎\"# 𝑎\"$ 𝑎#\" 𝑎## 𝑎#$ 𝑎$\" 𝑎$# 𝑎$$\\n\\n>\\n\\nB ∘ >\\n\\n𝑏\"\" 𝑏\"# 𝑏\"$ 𝑏#\" 𝑏## 𝑏#$ 𝑏$\" 𝑏$# 𝑏$$\\n\\nB = >\\n\\n𝑎\"\"𝑏\"\" 𝑎\"#𝑏\"# 𝑎\"$𝑏\"$ 𝑎#\"𝑏#\" 𝑎##𝑏## 𝑎#$𝑏#$ 𝑎$\"𝑏$\" 𝑎$#𝑏$# 𝑎$$𝑏$$\\n\\nB\\n\\n对于第 h 隐藏层的学习信号𝜹(cid:150)：\\n\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ) \\t\\t\\t\\t\\t\\t\\t\\t\\t= 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑌ℎ ∘ (1 − 𝑌ℎ)\\n\\n对于第 1 隐藏层的学习信号𝜹\"：\\n\\n𝛅\" = 𝛅#(𝑊#)~ ∘ 𝑓R(𝑋𝑊1) \\t\\t\\t\\t\\t\\t\\t\\t\\t= 𝛅#(𝑊#)~ ∘ 𝑌1 ∘ (1 − 𝑌1)\\n\\n对于输出层的权值矩阵𝑊(cid:150)(cid:151)\"：\\n\\n∆𝑊ℎ+1 = 𝜂(𝑌ℎ)~𝛅(cid:150)(cid:151)\"\\n\\n117\\n\\n(4.46)\\n\\n(4.47)\\n\\n(4.48)\\n\\n(4.49)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n对于第 h 隐藏层权值矩阵𝑊(cid:150)：\\n\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~𝛅(cid:150)\\n\\n对于第 1 隐藏层权值矩阵𝑊\"：\\n\\n∆𝑊1 = 𝜂(𝑋)~𝛅\"\\n\\n4.7 BP 算法推导结论总结\\n\\n上一小节我们推导了 BP 算法的公式，可能部分同学暂时先跳过了详细推导的部分。如果\\n\\n推导过程看起来有点复杂，我们只看最后推导得到的结论即可。最后推导的结论也就是权值调\\n\\n整的公式为：\\n\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~𝛅(cid:150)\\n\\n这里的∆𝑊(cid:150)表示第 h 层权值矩阵 W 的变化，𝜂表示学习率，𝑌(cid:150)(cid:127)\"表示网络第 h-1 层的输\\n\\n出，𝜹(cid:150)表示第 h 层的学习信号。\\n\\n𝜂学习率是为人设置的超参数，𝑌(cid:150)(cid:127)\"网络第 h-1 层的输出只要把数据传入网络中就可以计\\n\\n算出来，所以这里要重点关注的是第 h 层的学习信号𝜹(cid:150)。学习信号有两个不同的公式，输出层\\n\\n的学习信号公式为：\\n\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1)\\n\\n这里的𝜹(cid:150)(cid:151)\"表示输出层的学习信号，T 表示数据的标签值，𝑌(cid:150)(cid:151)\"表示模型的预测值，𝑓R表\\n\\n示激活函数的导数，𝑌(cid:150)𝑊(cid:150)(cid:151)\"表示输出层信号的汇总。\\n\\nT 是已知的数据标签，Y(cid:153)(cid:151)\"可以传入数据计算得到，激活函数确定以后𝑓R也是已知的，𝑌(cid:150)\\n\\n传入数据可以计算得到，𝑊(cid:150)(cid:151)\"在网络进行随机初始化以后也确定下来了。所以这个公式里面\\n\\n118\\n\\n(4.50)\\n\\n(4.51)\\n\\n(4.52)\\n\\n(4.53)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的所有值都是已知的，或者可以计算得到，把𝜹(cid:150)(cid:151)\"计算出来以后再带入到 4.52 的公式中就可\\n\\n以计算出输出层的权值矩阵要怎么要调整了。\\n\\n除了输出层以外，剩下的网络层的学习信号的公式都是：\\n\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ)\\n\\n从这个公式我们可以看到，第 h 层的学习信号𝜹(cid:150)，跟它的下一层 h+1 层的学习信号𝜹(cid:150)(cid:151)\"\\n\\n有关系，还跟它的下一层 h+1 层的权值矩阵的转置(𝑊(cid:150)(cid:151)\")~有关系，以及跟𝑓R(𝑌(cid:150)(cid:127)\"𝑊(cid:150))相关。\\n\\n所以我们在使用 BP 算法的时候需要先根据网络预测的误差计算最后一层的学习信号，然\\n\\n后再计算倒数第二层的学习信号，然后再计算倒数第三层的学习信号以此类推，从后向前计算，\\n\\n因此 BP 算法叫做误差反向传播算法。计算得到每一层的学习信号以后再根据公式 4.52 来计\\n\\n算每一层的权值矩阵如何调整，最后对所有层的权值矩阵进行更新。\\n\\n4.8 梯度消失与梯度爆炸\\n\\n前面给大家留了一个思考题，在我们介绍的几种激活函数中，哪种激活函数的效果是最好\\n\\n的。其实这个问题的答案很简单，在介绍它们的时候，一般排在越后面的说明效果就越好，所\\n\\n以 ReLU 是最好的。开个玩笑，下面我们来具体分析一下这几个激活函数的不同效果。\\n\\n4.8.1 梯度消失\\n\\n根据上文 BP 算法中的推导，我们从公式 4.49,,4.50,4.51 中可以知道，权值的调整∆𝑊是\\n\\n跟学习信号𝛿相关的。同时我们从 4.46,4.47,4.48 中可以知道在学习信号𝛿表达式中存在\\n\\n𝑓R(𝑥)。也就是说激活函数的导数会影响学习信号𝛿的值，而学习信号𝛿的值会影响权值调整\\n\\n119\\n\\n(4.54)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n120\\n\\n∆𝑊的值。那么激活函数的值越大，∆𝑊的值就越大；激活函数的值越小，∆𝑊的值也就越\\n\\n小。\\n\\n假设激活函数为 sigmoid 函数，前文中我们已经知道了 sigmoid 函数的表达式为：𝑓(𝑥) =\\n\\n\"\\n\\n\"(cid:151)⁄¥ƒ，sigmoid 函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]，我们可以画出 sigmoid 函数的导数\\n\\n图像如图 4.19 所示。\\n\\n图 4.19 sigmoid 函数导数\\n\\n这里我们发现当 x=0 时，sigmoid 函数导数可以取得最大值 0.25。x 取值较大或较小时，\\n\\nsigmoid 函数的导数很快就趋向于 0。不管怎么样，sigmoid 函数的导数都是一个小于 1 的\\n\\n数，学习信号𝛿乘以一个小于 1 的数，那么𝛿就会减小。学习信号从输出层一层一层向前反向传\\n\\n播的时候，每传播一层学习信号就会变小一点，经过多层传播后，学习信号就会接近于 0，从\\n\\n而使得权值∆𝑊调整接近于 0。∆𝑊接近于 0 那就意味着该层的参数不会发生改变，不能进行优\\n\\n化。参数不能优化，那整个网络就不能再进行学习了。学习信号随着网络传播逐渐减小的问题\\n\\n也被称为梯度消失（Vanishing Gradient）的问题。\\n\\n我们再考虑一下 tanh 函数的导数，tanh 函数的表达式为：𝑓(𝑥) = ⁄ƒ(cid:127)⁄¥ƒ\\n\\n⁄ƒ(cid:151)⁄¥ƒ，tanh 函数的\\n\\n导数为：𝑓R(𝑥) = 1 − (cid:142)𝑓(𝑥)(cid:143)\\n\\n#\\n\\n，tanh 函数的导数如图 4.20 所示。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n121\\n\\n图 4.20 tanh 函数导数\\n\\ntanh 函数导数图像看起来比 sigmoid 函数要好一些，x=0 时，tanh 函数导数可以取得\\n\\n最大值 1。x 取值较大或较小时，tanh 函数的导数很快就趋向于 0。不管怎么样，tanh 函数\\n\\n导数的取值总是小于等于 1 的，所以 tanh 作为激活函数也会存在梯度消失的问题。\\n\\n对于 softsign 函数，softsign 函数的表达式为：𝑓(𝑥) = V\\n\\n\"(cid:151)|V|\\n\\n，softsign 函数的导数为：\\n\\n𝑓R(𝑥) = \"\\n\\n(\"(cid:151)|V|)(cid:157)，softsign 函数的导数如图 4.21 所示。\\n\\n图 4.21 softsign 函数导数\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nsoftsign 函数 x=0 时，softsign 函数导数可以取得最大值 1。x 取值较大或较小时，\\n\\nsoftsign 函数的导数很快就趋向于 0。不管怎么样，softsign 函数导数的取值总是小于等于\\n\\n1 的，所以 softsign 作为激活函数也会存在梯度消失的问题。\\n\\n4.8.2 梯度爆炸\\n\\n当我们使用 sigmoid,tanh 和 softsign 作为激活函数时，它们的导数取值范围都是小于等\\n\\n于 1 的，所以会产生梯度消失的问题。那么我们可能会想到，如果使用导数大于 1 的函数作为\\n\\n激活函数，情况会如何？\\n\\n如果学习信号𝛿乘以一个大于 1 的数，那么δ就会变大。学习信号从输出层一层一层向前\\n\\n反向传播的时候，每传播一层学习信号就会变大一点，经过多层传播后，学习信号就会接近于\\n\\n无穷大，从而使得权值∆𝑊调整接近于无穷大。∆𝑊接近于无穷大那就意味着该层的参数，处于\\n\\n一种极不稳定的状态，那么网络就不能正常工作了。学习信号随着网络传播逐渐增大的问题也\\n\\n被称为梯度爆炸（Exploding Gradient）的问题。\\n\\n既然激活函数的导数不能小于 1 也不能大于 1，我们可能会想到，能不能使用线性函数\\n\\ny=x，这个函数的导数是 1。它既不会梯度消失，也不会梯度爆炸。确实如此，线性函数导数\\n\\n为 1 的特性是很好，但是，它是一个线性函数，也就是说，它不能处理非线性问题，比如异或\\n\\n分类问题，它就无法解决。而在实际应用中，非常多的应用都是属于非线性问题，所以使用线\\n\\n性函数来作为激活函数存在很大的局限性，所以也不适合。\\n\\n4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题\\n\\n我们知道 ReLU 的表达式为：𝑓(𝑥) = 𝑚𝑎𝑥\\t(0, 𝑥)。当 x 小于 0 时，𝑓(𝑥)的取值为 0；当 x\\n\\n大于 0 时，𝑓(𝑥)的取值等于 x。ReLU 函数的导数如图 4.22 所示。\\n\\n122\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.22 ReLU 函数导数\\n\\n前面我们讨论了当激活函数的导数小于 1 时，网络会产生梯度消失，激活函数的导数大\\n\\n于 1 时，网络会产生梯度爆炸。那么当我们使用 ReLU 作为激活函数的时候，x 小于 0 时，\\n\\nReLU 的导数为 0；x 大于 0 时，ReLU 的导数为 1。导数为 1 是一个很好的特性，不会使得\\n\\n学习信号越来越小，也不会让学习信号越来越大，可以让学习信号比较稳定地从后向前传\\n\\n播。解决了梯度消失和梯度爆炸的问题，同时计算方便，可以加速网络的训练。\\n\\nReLU 函数还有一个优点，它是一个非线性的激活函数，可以用来处理非线性问题，它\\n\\n的非线性特性在 4.5 小节中已经介绍过。\\n\\n认真思考的同学这个时候可能会发现，ReLU 函数看起来是挺好的，既是非线性函数，\\n\\n导数又为 1，但是它好像也存在一些问题，当 x 小于 0 时，ReLU 函数输出为 0，导数也为\\n\\n0，有些信号不就丢失掉了吗？\\n\\n如果你是这么想的，那你就想对了，确实是丢失了一些信号，但是没关系。在神经网络\\n\\n中，信号是冗余的，也就是说其实网络最后在做预测的时候并不需要从前面传过来的所有的\\n\\n信号，实际上只需要一部分的信号，网络就可以进行预测。并且使用部分信号来进行预测与\\n\\n使用全部信号来进行预测得到的结果相差不大。\\n\\n123\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n比如我们把网络中输出为 0 的神经元看成是不工作的神经元，那么使用 ReLU 函数以后会\\n\\n产生大量不工作的神经元。网络中存在不工作的神经元，我们可以称这个网络具有一定的稀疏\\n\\n性（Sparsity）。不工作的神经元越多，网络就越稀疏。使得网络产生稀疏性的方式很多，除\\n\\n了使用 ReLU 激活函数以外，还可以使用 L1 正则化（L1 Regularization）和 Dropout，这\\n\\n两个技术在后面的章节中会有详细介绍。所以使得神经网络变稀疏并不是什么稀奇的事，也不\\n\\n一定是坏事。\\n\\n稀疏性这一特性也存在于生物体内的神经网络中，大脑中神经网络的稀疏性高达 95%-\\n\\n99%，也就是说在同一时刻其实大脑中大部分的神经元都是不工作。人工神经网络中比较常见\\n\\n的网络稀疏性是 50%-80%。\\n\\n4.9 使用 BP 神经网络解决异或问题\\n\\nBP 神经网络解决异或问题的代码如代码 4-1 所示。\\n\\n代码 4-1：BP 神经网络解决异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt\\n\\n# 输入数据 X = np.array([[0,0], [0,1], [1,0], [1,1]]) # 标签 T = np.array([[0], [1], [1], [0]])\\n\\n124\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义一个 2 层的神经网络：2-10-1 # 输入层 2 个神经元，隐藏层 10 个神经元，输出层 1 个神经元 # 输入层到隐藏层的权值初始化，2 行 10 列 W1 = np.random.random([2,10]) # 隐藏层到输出层的权值初始化，10 行 1 列 W2 = np.random.random([10,1]) # 初始化偏置值，偏置值的初始化一般可以取 0，或者一个比较小的常数，如 0.1 # 隐藏层的 10 个神经元偏置 b1 = np.zeros([10]) # 输出层的 1 个神经元偏置 b2 = np.zeros([1]) # 学习率设置 lr = 0.1 # 定义训练周期数 epochs = 100001 # 定义测试周期数 test = 5000\\n\\n# 定义 sigmoid 函数 def sigmoid(x): return 1/(1+np.exp(-x))\\n\\n# 定义 sigmoid 函数导数 def dsigmoid(x): return x*(1-x)\\n\\n# 更新权值和偏置值 def update(): global X,T,W1,W2,lr,b1,b2\\n\\n# 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2)\\n\\n# 求输出层的学习信号 delta_L2 = (T - L2) * dsigmoid(L2) # 隐藏层的学习信号 delta_L1 = delta_L2.dot(W2.T) * dsigmoid(L1)\\n\\n# 求隐藏层到输出层的权值改变 # 由于一次计算了多个样本，所以需要求平均 delta_W2 = lr * L1.T.dot(delta_L2) / X.shape[0] # 输入层到隐藏层的权值改变\\n\\n125\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 由于一次计算了多个样本，所以需要求平均 delta_W1 = lr * X.T.dot(delta_L1) / X.shape[0]\\n\\n# 更新权值 W2 = W2 + delta_W2 W1 = W1 + delta_W1\\n\\n# 改变偏置值 # 由于一次计算了多个样本，所以需要求平均 b2 = b2 + lr * np.mean(delta_L2, axis=0) b1 = b1 + lr * np.mean(delta_L1, axis=0)\\n\\n# 定义空 list 用于保存 loss loss = [] # 训练模型 for i in range(epochs): # 更新权值 update() # 每训练 5000 次计算一次 loss 值 if i % test == 0: # 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2) # 计算 loss 值 print(\\'epochs:\\',i,\\'loss:\\',np.mean(np.square(T - L2) / 2)) # 保存 loss 值 loss.append(np.mean(np.square(T - L2) / 2))\\n\\n# 画图训练周期数与 loss 的关系图 plt.plot(range(0,epochs,test),loss) plt.xlabel(\\'epochs\\') plt.ylabel(\\'loss\\') plt.show()\\n\\n# 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2) print(\\'output:\\') print(L2)\\n\\n# 因为最终的分类只有 0 和 1，所以我们可以把 # 大于等于 0.5 的值归为 1 类，小于 0.5 的值归为 0 类\\n\\n126\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com def predict(x): if x>=0.5: return 1 else: return 0\\n\\n# map 会根据提供的函数对指定序列做映射 # 相当于依次把 L2 中的值放到 predict 函数中计算 # 然后打印出结果 print(\\'predict:\\') for i in map(predict,L2): print(i) 运行结果如下： epochs: 0 loss: 0.2382731940835196 epochs: 5000 loss: 0.1206923173399693 epochs: 10000 loss: 0.0790971946756123 epochs: 15000 loss: 0.02378338344093093 epochs: 20000 loss: 0.008377749771590743 epochs: 25000 loss: 0.004291050338268038 epochs: 30000 loss: 0.002694668764968099 epochs: 35000 loss: 0.0018982939821333231 epochs: 40000 loss: 0.0014365256397058071 epochs: 45000 loss: 0.001140826866565359 epochs: 50000 loss: 0.0009377943334308873 epochs: 55000 loss: 0.0007910315050028132 epochs: 60000 loss: 0.000680683460806228 epochs: 65000 loss: 0.0005950985467089836 epochs: 70000 loss: 0.0005270339320851203 epochs: 75000 loss: 0.00047177302525578296 epochs: 80000 loss: 0.0004261243077828677 epochs: 85000 loss: 0.00038785770517095713 epochs: 90000 loss: 0.0003553718177062329 epochs: 95000 loss: 0.0003274893656556488 epochs: 100000 loss: 0.00030332701795183955\\n\\n127\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\noutput: [[0.02462022] [0.97697496] [0.97534433] [0.02612291]] predict: 0 1 1 0\\n\\n4.10 分类模型评估方法\\n\\n4.10.1 准确率/精确率/召回率/F1 值\\n\\n机器学习中有很多分类模型评估指标，比如 准确率（Accuracy），精确率（查准率，\\n\\nPrecision）和召回率（查全率，Recall）都是比较常见的。\\n\\n我们先来说一下准确率，准确也是我们日常生活中用得较多的一个判断指标，准确率的计\\n\\n算很简单，准确率=所有预测正确的结果除以所有结果。比如一个模型要识别 5 张图片，最后\\n\\n识别正确 4 张图片，错了 1 张，那么准确率就是 4/5=80%。\\n\\n128\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n倘若某人声称创建了一个能够识别登上飞机的恐怖分子的模型，并且准确率（accuracy）\\n\\n高达 99%。这能算是个好模型吗？已知美国全年平均有 8 亿人次的乘客，并且在 2000-\\n\\n2017 年间共发现了 19 名恐怖分子。如果有一个模型将从美国机场起飞的所有乘客都标注为\\n\\n非恐怖分子，那么这个模型达到了接近完美的准确率——99.99999%。这听起来确实令人印\\n\\n象深刻，但是美国国土安全局肯定不会购买这个模型。尽管这个模型拥有接近完美的准确率，\\n\\n但是在这个问题中准确率显然不是一个合适的度量指标。\\n\\n恐怖分子检测是一个不平衡的分类问题：我们需要鉴别的类别有两个，恐怖分子和非恐怖\\n\\n分子，其中一个类别代表了极大多数的数据，而另一个类别数据却很少。比如我们把恐怖分子\\n\\n定义为正例，非恐怖分子定义为负例，那么正例类别——恐怖分子，远远少于负例类别——非\\n\\n恐怖分子的数量。这种数据不均衡的问题是数据科学中比较常见的，在数据不均衡的情况下使\\n\\n用准确率并不是评估模型性能的很好的衡量标准。当然，如果是数据比较均衡的情况下，我们\\n\\n还是可以使用准确率来作为分类模型的评估指标。\\n\\n所以在数据不均衡的场景下，我们应该考虑的评估指标应该是精确率和召回率。我们先看\\n\\n一下图 4.23。\\n\\n图 4.23 真实标注与模型预测对比\\n\\n图中的 True Positive(TP)表示模型预测结果是恐怖分子，数据的真实标注也是恐怖分子；\\n\\nFalse Positive(FP)表示模型预测结果是恐怖分子，数据的真实标注是非恐怖分子； False\\n\\n129\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n130\\n\\nNegative(FN) 表示模 型预 测结 果是非恐 怖分子 ，数据的真 实 标 注是恐 怖分子；\\n\\nTrue\\n\\nNegative(TN)表示模型预测结果是非恐怖分子，数据的真实标注也是非恐怖分子。\\n\\n这里的 True/Fasle 和 Positive/Negative 我们可以这么来理解，True 或 Fasle 表示模型\\n\\n预测结果是否正确，如果预测正确就是 True，预测错误就是 Fasle。所以相当于 TP 和 TN 都\\n\\n表示模型预测是正确的，FP 和 FN 表示模型预测不正确。Positive 或 Negative 表示模型的预\\n\\n测结果。TP 和 FP 模型预测结果都是 Positive，TN 和 FN 模型预测结果都是 Negative。\\n\\n看懂这个图以后我们来看一下召回率（recall）的公式：\\n\\n𝑟𝑒𝑐𝑎𝑙𝑙 =\\n\\n𝑇𝑃 𝑇𝑃 + 𝐹𝑁\\n\\n(4.55)\\n\\n召回率描述的是模型对于正例——恐怖分子的召回能力，也就是找到恐怖分子的能力。比\\n\\n如一共有 19 名恐怖分子，模型可以正确识别出 10 名恐怖分子，有 9 名恐怖分子没有识别出\\n\\n来。那么 TP=10，FN=9，recall=10/(10+9)=52.63%。比如一共有 19 名恐怖分子，模型可\\n\\n以正确识别出 18 名恐怖分子，有 1 名恐怖分子没有识别出来，那么 TP=18，FN=1，\\n\\nrecall=18/(18+1)=94.74%。召回率越高说明模型找到恐怖分子的能力越强。\\n\\n我们再来看一下精确率（precision）的公式：\\n\\n𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =\\n\\n𝑇𝑃 𝑇𝑃 + 𝐹𝑃\\n\\n(4.56)\\n\\n精确率描述的是模型对于正例-恐怖分子的判断能力。比如模型可以正确识别出 10 名恐\\n\\n怖分子，另外还有 40 人模型判断是恐怖分子，其实这 40 人是非恐怖分子。那么 TP=10，\\n\\nFP=40，precision=10/(10+40)=20%。比如模型可以正确识别 9 名恐怖分子，另外还有 1\\n\\n人模 型判断是恐 怖分子 ， 其实这\\n\\n1 人 是非恐 怖分子 。那么\\n\\nTP=9 ， FP=1 ，\\n\\nprecision=9/(9+1)=90%。精确率越高说明模型对于恐怖分子的识别越精准。\\n\\n准确率（accuracy）的公式为：\\n\\n𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =\\n\\n𝑇𝑃 + 𝑇𝑁 𝑇𝑃 + 𝐹𝑁 + 𝐹𝑃 + 𝑇𝑁\\n\\n(4.57)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n也就是所有识别正确的结果除以所有结果。\\n\\n针对不同的问题，我们所关注的评估指标可能也会有所不同。比如 2020 年初新型冠状病\\n\\n毒爆发时期，我们更关注召回率，因为我们要尽量找到所有带有新型冠状病毒的病人，然后把\\n\\n病人进行隔离观察治疗，宁可抓错 100，也不能放过 1 个。\\n\\n再举一个信息检索中比较极端的例子，假如一个搜索引擎有 10000 个网站，其中有 100\\n\\n个深度学习相关的网站。当我们搜索“深度学习是什么？”的时候，如果搜索引擎想提高精确\\n\\n率，那么它可以只返回一个跟深度学习相关度最高的网站，如果这个结果是我们想要的，那么\\n\\n精确率就是 100%，不过这样做，召回率只有 1%。如果搜索引擎想提高召回率，那么它可以\\n\\n返回 10000 个网站，这样做召回率就可以有 100%，不过精确率只有 1%。\\n\\n所以判断一个搜索引擎好坏，主要看的是前面几十条结果的精确率，因为我们通常只会查\\n\\n看最前面的几十条结果，特别是最前面的几条结果。最前面的几条结果是我们想要的，我们就\\n\\n会认为这个搜索引擎很好。我们并不是很在意搜索引擎的召回率，比如一共有 10000 条结果\\n\\n是符合我们想要的结果，搜索引擎给我们返回了 1000 条还是 9000 条，其实我们并不在意，\\n\\n因为我们只会看最前面的几十条结果。\\n\\n在实际应用中，最理想的情况是精确率和召回率都比较高，不过一般来说，很难得到精确\\n\\n率和召回率都很高的结果。很多时候是提高了精确率，召回率就会降低；提高召回率，精确率\\n\\n就会降低。所以我们还需要一个综合评估指标，也就是 F 值，F 值是精确率(P)和召回率(R)的\\n\\n加权调和平均，公式为：\\n\\n𝐹 =\\n\\n((𝛼# + 1) × 𝑃 × 𝑅) 𝛼# × 𝑃 + 𝑅\\n\\n当参数𝛼 = 1时，就是最常见的的 F1 值，即：\\n\\n𝐹1 =\\n\\n2 × 𝑃 × 𝑅 𝑃 + 𝑅\\n\\n131\\n\\n(4.58)\\n\\n(4.59)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nF1 值综合了 P 和 R 的结果，可用于综合评价分类结果的质量。\\n\\n准确率，召回率，精确率，F1 值都是在 0-1 之间，并且都是越大越好。\\n\\n最后我再举一个例子，帮助大家理解这 4 个评估指标的计算。比如一个预测恐怖分子的模\\n\\n型结果如图 4.24 所示。\\n\\n图 4.24 模型结果\\n\\n有 10 个恐怖分子模型预测结果也是恐怖分子（TP）\\n\\n有 10 个非恐怖分子模型预测结果是恐怖分子（FP）\\n\\n有 5 个恐怖分子模型预测结果是非恐怖分子（FN）\\n\\n有 75 个非恐怖分子模型预测结果是非恐怖分子（TN）\\n\\n准确率计算：(TP+TN)/(TP+FN+FP+TN)=(10+75)/(10+5+10+75)=85%\\n\\n召回率计算：TP/(TP+FN)=10/(10+5)=66.67%\\n\\n精确率计算：TP/(TP+FP)=10/(10+10)=50%\\n\\nF1 值：(2×50%×66.67%)/(50%+66.67%)=57.14%\\n\\n4.10.2 混淆矩阵(Confusion Matrix)\\n\\n在机器学习领域，混淆矩阵又称为可能性表格或者是错误矩阵。它是一种特定的矩阵用来\\n\\n呈现算法的效果。我们还是通过例子来讲解，假设有一个人，狗，猫的分类系统，我们的测试\\n\\n样本一共有 10 个人，15 只狗，5 只猫，得到如下混淆矩阵，如图 4.25 所示。\\n\\n132\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n模型预测\\n\\n真实标签\\n\\n猫 狗\\n\\n猫 3 3\\n\\n狗 1 11\\n\\n人 1 1\\n\\n人\\n\\n1\\n\\n2\\n\\n7\\n\\n图 4.25 混淆矩阵\\n\\n图中表达的意思是，一共有 5 只猫，其中 3 中预测正确了，有 1 只猫被预测成了狗，有\\n\\n1 只猫被预测成了人；一共有 15 只狗，其中有 3 只狗被预测成了猫，有 11 只狗预测正确，\\n\\n有 1 只狗被预测成了人；一共有 10 个人，其中有 1 个人被预测成了猫，有两个人被预测成\\n\\n了狗，有 7 个人预测正确。\\n\\n4.11 独热编码（One-Hot Encoding）\\n\\n在神经网络，深度学习的分类问题中，我们通常会把分类问题的标签转化为独热编码的格\\n\\n式。比如在手写数字识别的任务中，数字有 0-9 一共 10 中状态，所以每个数字都可以转换为\\n\\n长度为 10 的编码：\\n\\n0->1000000000\\n\\n1->0100000000\\n\\n2->0010000000\\n\\n3->0001000000\\n\\n4->0000100000\\n\\n5->0000010000\\n\\n6->0000001000\\n\\n133\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7->0000000100\\n\\n8->0000000010\\n\\n9>-0000000001\\n\\n比如对于根据图片判断性别的模型：\\n\\n男性可以编码为：10\\n\\n女性可以编码为：01\\n\\n比如给花的品种进行分类的模型，假设有红黄蓝三种花：\\n\\n红花可以编码为：100\\n\\n黄花可以编码为：010\\n\\n蓝花可以编码为：001\\n\\n根据以上的几个例子大家应该都可以了解独热编码是怎么回事了，在后面的分类应用中我\\n\\n们经常会把分类的标签处理成为独热编码的格式，然后用来训练模型。\\n\\n4.12 BP 神经网络完成手写数字识别\\n\\n这一小节中我们要自己搭建一个 BP 网络来完成手写数字识别的功能，我们使用到的训练\\n\\n集是 sklearn 中自带的手写数字数据集。首先我们先看一下数据集，如代码 4-2 所示。\\n\\n代码 4-2：手写数字数据集介绍\\n\\nfrom sklearn.datasets import load_digits import matplotlib.pyplot as plt\\n\\n# 载入手写数字数据 digits = load_digits() # 打印数据集的 shape，行表示数据集个数，列表示每个数据的特征数\\n\\n134\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com print(\\'data shape:\\',digits.data.shape) # 打印数据标签的 shape，数据标签的值为 0-9 print(\\'target shape:\\',digits.target.shape) # 准备显示第 0 张图片，图片为灰度图 plt.imshow(digits.images[0],cmap=\\'gray\\') # 显示图片 plt.show() 运行结果如下： data shape: (1797, 64) target shape: (1797,)\\n\\n观察 4-2 程序的输出我们可以发现这个数据集中每个数据的图片是一张 8×8 的图片，分\\n\\n别对应数字 0-9。所以我们可以考虑构建一个输入层为 64 个神经元的神经网络，64 个神经\\n\\n元对应于图片中的 64 个像素点。假设我们设置一层隐藏层，隐藏层有 100 个神经元。最后\\n\\n设置一个输出层，我们会把标签转变为独热编码(one-hot)的格式，数字 0-9 一共 10 个状\\n\\n态，所以输出层我们可以设置 10 个神经元。数字识别网络结构图如图 4.26 所示。\\n\\n135\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.26 数字识别网络结构图\\n\\nBP 网络完成手写数字识别的代码如代码 4-3 所示。\\n\\n代码 4-3：BP 网络完成手写数字识别\\n\\n# 导入 numpy 科学计算库 import numpy as np # 载入画图工具包 import matplotlib.pyplot as plt # 导入手写数字数据集 from sklearn.datasets import load_digits # 用于标签二值化处理，把标签转成独热编码 one-hot 的格式 from sklearn.preprocessing import LabelBinarizer # 用于把数据集拆分为训练集和测试集 from sklearn.cross_validation import train_test_split # 用于评估分类结果 from sklearn.metrics import classification_report,confusion_matrix\\n\\n# 定义 sigmoid 函数 def sigmoid(x): return 1/(1+np.exp(-x))\\n\\n# 定义 sigmoid 函数的导数 def dsigmoid(x): return x*(1-x)\\n\\n# 定义神经网络类\\n\\n136\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com class NeuralNetwork: # 初始化网络，定义网络结构 # 假设传入(64,100,10)，说明定义： # 输入层 64 个神经元，隐藏层 100 个神经元，输出层 10 个神经元 def __init__(self,layers): # 权值的初始化，范围-1 到 1 self.W1 = np.random.random([layers[0],layers[1]])*2-1 self.W2 = np.random.random([layers[1],layers[2]])*2-1 # 初始化偏置值 self.b1 = np.zeros([layers[1]]) self.b2 = np.zeros([layers[2]]) # 定义空 list 用于保存 list self.loss = [] # 定义空 list 用于保存 self.accuracy = []\\n\\n# 训练模型 # X 为数据输入 # T 为数据对应的标签 # lr 学习率 # steps 训练次数 # batch 批次大小 # 使用批量随机梯度下降法，每次随机抽取一个批次的数据进行训练 def train(self,X,T,lr=0.1,steps=20000,test=5000,batch=50): # 进行 steps+1 次训练 for n in range(steps+1): # 随机选取一个批次数据 index = np.random.randint(0,X.shape[0],batch) x = X[index] # 计算隐藏层输出 L1 = sigmoid(np.dot(x,self.W1)+self.b1) # 计算输出层输出 L2 = sigmoid(np.dot(L1,self.W2)+self.b2) # 求输出层的学习信号 delta_L2 = (T[index]-L2)*dsigmoid(L2) # 求隐藏层的学习信号 delta_L1= delta_L2.dot(self.W2.T)*dsigmoid(L1) # 求隐藏层到输出层的权值改变 # 由于一次计算了多个样本，所以需要求平均 self.W2 += lr * L1.T.dot(delta_L2) / x.shape[0] # 求输入层到隐藏层的权值改变 # 由于一次计算了多个样本，所以需要求平均 self.W1 += lr * x.T.dot(delta_L1) / x.shape[0] # 改变偏置值\\n\\n137\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.b2 = self.b2 + lr * np.mean(delta_L2, axis=0) self.b1 = self.b1 + lr * np.mean(delta_L1, axis=0)\\n\\n# 每训练 5000 次预测一次准确率 if n%test==0: # 预测测试集的预测结果 Y2 = self.predict(X_test) # 取得预测结果最大的所在的索引 # 例如最大值所在的索引是 3，那么预测结果就是 3 predictions = np.argmax(Y2,axis=1) # 计算准确率 # np.equal(predictions,y_test)判断预测结果和真实标签是否相等，相等返回 True，不相等返回 False # np.equal(predictions,y_test)执行后得到一个包含多个 True 和 False 的列表 # 然后用 np.mean 对列表求平均 True 为 1，False 为 0。 # 例如一共有 10 个结果，9 个 True，一个 False，平均后的结果为 0.9，即预测的 准确率为 90% acc = np.mean(np.equal(predictions,y_test)) # 计算 loss l = np.mean(np.square(y_test - predictions) / 2) # 保存准确率 self.accuracy.append(acc) # 保存 loss 值 self.loss.append(l) # 打印训练次数,准确率和 loss print(\\'steps:%d accuracy:%.3f loss:%.3f\\' % (n,acc,l))\\n\\n# 模型预测结果 def predict(self,x): L1 = sigmoid(np.dot(x,self.W1)+self.b1)#隐层输出 L2 = sigmoid(np.dot(L1,self.W2)+self.b2)#输出层输出 return L2\\n\\n# 程序从这里开始运行 # 定义训练次数 steps = 30001 # 定义测试周期数 test = 3000 # 载入数据 digits = load_digits() # 得到数据 X = digits.data # 得到标签 y = digits.target\\n\\n138\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 输入数据归一化，有助于加快训练速度 # X 中原来的数值范围是 0-255 之间，归一化后变成 0-1 之间 X -= X.min() X /= X.max() - X.min() # 分割数据 1/4 为测试数据，3/4 为训练数据 # 有 1347 个训练数据，450 个测试数据 X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\\n\\n# 创建网络,输入层 64 个神经元，隐藏层 100 个神经元，输出层 10 个神经元 nm = NeuralNetwork([64,100,10]) # 标签转化为独热编码 one-hot 的格式 labels_train = LabelBinarizer().fit_transform(y_train)\\n\\n# 开始训练 print(\\'Start training\\') nm.train(X_train,labels_train,steps=steps,test=test)\\n\\n# 预测测试数据 predictions = nm.predict(X_test) # predictions.shape 为(450,10) # y_test.shape 为(450,) # 所以需要取得预测结果最大的所在的索引，该索引就是网络预测的结果 # np.argmax(predictions,axis=1)执行后得到的形状也变成了(450,) predictions = np.argmax(predictions,axis=1) # 对比测试数据的真实标签与网络预测结果，得到准确率，召回率和 F1 值 print(classification_report(y_test,predictions)) # 对于测试数据的真实标签与网络预测结果，得到混淆矩阵 print(confusion_matrix(y_test,predictions))\\n\\n# 训练次数与 loss 的关系图 plt.plot(range(0,steps+1,test),nm.loss) plt.xlabel(\\'steps\\') plt.ylabel(\\'loss\\') plt.show()\\n\\n# 训练次数与 accuracy 的关系图 plt.plot(range(0,steps+1,test),nm.accuracy) plt.xlabel(\\'steps\\') plt.ylabel(\\'accuracy\\') plt.show() 运行结果如下： Start training steps:0 accuracy:0.111 loss:10.206 steps:3000 accuracy:0.922 loss:0.777\\n\\n139\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com steps:6000 accuracy:0.960 loss:0.469 steps:9000 accuracy:0.964 loss:0.389 steps:12000 accuracy:0.967 loss:0.361 steps:15000 accuracy:0.964 loss:0.416 steps:18000 accuracy:0.971 loss:0.342 steps:21000 accuracy:0.969 loss:0.378 steps:24000 accuracy:0.971 loss:0.342 steps:27000 accuracy:0.971 loss:0.360 steps:30000 accuracy:0.971 loss:0.360 precision recall f1-score support\\n\\n0 1.00 0.98 0.99 45 1 0.93 0.98 0.95 41 2 0.98 1.00 0.99 50 3 1.00 0.93 0.96 40 4 0.98 0.98 0.98 48 5 0.94 0.98 0.96 51 6 0.98 1.00 0.99 42 7 1.00 1.00 1.00 45 8 0.93 0.91 0.92 44 9 0.98 0.95 0.97 44\\n\\navg / total 0.97 0.97 0.97 450\\n\\n[[44 0 0 0 1 0 0 0 0 0] [ 0 40 0 0 0 0 0 0 1 0] [ 0 0 50 0 0 0 0 0 0 0] [ 0 0 0 37 0 2 0 0 1 0] [ 0 0 0 0 47 0 0 0 0 1] [ 0 0 0 0 0 50 1 0 0 0] [ 0 0 0 0 0 0 42 0 0 0] [ 0 0 0 0 0 0 0 45 0 0] [ 0 3 1 0 0 0 0 0 40 0] [ 0 0 0 0 0 1 0 0 1 42]]\\n\\n140\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.13 Sklearn 手写数字识别\\n\\n上一小节我们学习了如何从头开始搭建一个 BP 神经网络来完成手写数字识别，其实搭\\n\\n建 BP 神经网络还有更简单快捷的方法，就是使用 scikit-learn 模块。scikit-learn 是一个常\\n\\n用的 python 模型，里面封装了大量机器学习算法，其中就包括 BP 神经网络。下面我们来\\n\\n看一下如何使用 scikit-learn 中的神经网络算法来进行手写数字识别，如代码 4-4 所示。\\n\\n代码 4-4：BP 网络完成手写数字识别(使用 scikit-learn 中的神经网络算法)\\n\\n# 载入 BP 神经网络算法 from sklearn.neural_network import MLPClassifier from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report\\n\\n141\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import matplotlib.pyplot as plt #载入数据 digits = load_digits() #数据 x_data = digits.data #标签 y_data = digits.target # X 中原来的数值范围是 0-255 之间，归一化后变成 0-1 之间 x_data -= x_data.min() x_data /= x_data.max() - x_data.min() # 分割数据 1/4 为测试数据，3/4 为训练数据 # 有 1347 个训练数据，450 个测试数据 x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.25) # 定义神经网络模型，模型输入神经元个数和输出神经元个数不需要设置 # hidden_layer_sizes 用于设置隐藏层结构： # 比如(50)表示有 1 个隐藏层，隐藏层神经元个数为 50 # 比如(100,20)表示有 2 个隐藏层，第 1 个隐藏层有 100 个神经元，第 2 个隐藏层有 20 个神 经元 # 比如(100,20,10)表示 3 个隐藏层，神经元个数分别为 100，20，10 # max_iter 设置训练次数 mlp = MLPClassifier(hidden_layer_sizes=(100,20), max_iter=500) # fit 传入训练集数据开始训练模型 mlp.fit(x_train,y_train) # predict 用于模型预测 predictions = mlp.predict(x_test) # 标签数据和模型预测数据进行对比，计算分类评估指标 print(classification_report(y_test, predictions)) 运行结果如下：\\n\\nprecision recall f1-score support\\n\\n0 1.00 1.00 1.00 35 1 0.98 1.00 0.99 49 2 1.00 0.98 0.99 50 3 0.97 0.97 0.97 38 4 1.00 0.98 0.99 56 5 1.00 0.93 0.96 43 6 1.00 1.00 1.00 47 7 0.94 1.00 0.97 46 8 0.95 1.00 0.97 36 9 0.98 0.96 0.97 50\\n\\naccuracy 0.98 450 macro avg 0.98 0.98 0.98 450 weighted avg 0.98 0.98 0.98 450\\n\\n142\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n要注意的是 scikit-learn 中封装的神经网络只是普通的 BP 神经网络，不具备深度学习算\\n\\n法。如果要实现深度学习算法需要使用专门的深度学习框架，如 Tensorflow，在下一章节中\\n\\n我们会详细介绍。\\n\\n4.14 参考文献\\n\\n[1] McClelland J L, Rumelhart D E, PDP Research Group. Parallel Distributed\\n\\nProcessing [J]. Explorations in the Microstructure of Cognition, 1986, 2: 216-271.\\n\\n[2] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural\\n\\nnetworks[C]//Proceedings of the fourteenth international conference on artificial\\n\\nintelligence and statistics. 2011: 315-323.\\n\\n[3] 韩力群, 康芊. 人工神经网络理论, 设计及应用——神经细胞, 神经网络和神经系统[J].\\n\\n北京工商大学学报: 自然科学版, 2005, 23(1): 52-52.\\n\\n143\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 5 章-深度学习框架 Tensorflow 基础使\\n\\n用\\n\\n在介绍正式内容以前，我想先给大家说明一个基本情况，也就是目前深度学习还处于一\\n\\n个非常早期的，不成熟的阶段，所以我们会看到各种各样的人写着各种各样风格的代码。当\\n\\n我们想完成一个应用的时候，我们会有很多种方式和选择，有时候选择太多也不一定是好\\n\\n事，因为我们可能会面临选择的困难。虽然“条条大路通罗马”，但是有些路好走，有些路不\\n\\n好走；有些路部分人觉得好走，部分人觉得不好走。很多时候我们很难判断哪条路好，哪条\\n\\n路不好。\\n\\n给大家举一个例子来说明这个问题，如图 5.1 所示。\\n\\n图 5.1 条条大路通罗马\\n\\n比如我们想做一个图像识别的应用，那么首先我们有很多种深度学习的框架可以选择。\\n\\n如果是在 2016-2017 年左右，那么这个选择还是挺难的，因为每个深度学习的框架都有自己\\n\\n的优缺点，我们可能很难选择学习哪一个框架。当然，这个问题现在相对变得容易了，经过\\n\\n时间的考验，现在业内公认的首选的深度学习框架就是 Tensorflow 或者 Pytorch。Pytorch\\n\\n144\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n是最近一两年学术界最喜欢使用的深度学习框架，Tensorflow 是落地应用最多的深度学习框\\n\\n架。如果让我推荐的话，我会推荐两者都学，多学总不是坏事。我们这本书主要是以\\n\\nTensorflow 为重点，大家可以先跟着我把 Tensorflow 学好。\\n\\n深度学习框架选好之后，接下来要继续选择，每个框架在实现某个具体应用的时候通常\\n\\n都会有很多种实现方式。比如如何载入数据进行数据预处理有很多种方法，如何搭建网络有\\n\\n很多种方法，如何训练模型又有很多种方法。比如图 5.1 中，假设我们选择了 Tensorflow 作\\n\\n为我们的深度学习框架，那么我们在搭建网络结构的时候又可以选择使用 Tensorflow 的高\\n\\n级 API：Slim，TFLearn，tf.layers，tf.keras 或其他 API，最后完成图像识别的应用。由于\\n\\n各种方法比较多，我们全部都学并不是一个明智的选择，所以在本书中我会选择我认为比较\\n\\n容易理解和学习方法来教大家。Tensorflow2.0 推出以后，谷歌官方建议大家使用 tf.keras\\n\\n来搭建和训练模型。Keras 也是我非常喜欢的一款深度学习框架，它是所有深度学习框架中\\n\\n最容易使用的，没有之一，所以也比较适合初学者使用。鉴于 Keras 的简洁易用性以及容易\\n\\n理解和学习的特点，本书中关于深度学习的应用大部分都会基于 tf.keras 的 API 完成。\\n\\n5.1 Tensorflow 介绍\\n\\n5.1.1 Tensorflow 简介\\n\\nTensorflow 的官网是：https://tensorflow.google.cn/，不需要翻墙。\\n\\n还有一个需要翻墙的官网是：https://www.tensorflow.org。\\n\\n145\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 是谷歌基于 DisBelief 进行研发的第二代人工智能学习系统，并于 2015 年\\n\\n11 月 9 日开源。Tensorflow 可被用于图像识别，语音识别，文本处理等多项机器学习和深度\\n\\n学习领域。并且可以运行在智能手机，个人电脑，数据中心服务器等各种设备上。\\n\\n目前支持 Windows，MacOS，Linux 系统，支持 CPU/GPU 版本，支持单机和分布式版\\n\\n本。\\n\\nTensorflow 支持多种编程语言，目前有 Python，C++，GO，JAVA，R，SWIFT，JavaScript。\\n\\n最主流的编程语言是 Python，本书主要介绍的编程语言也是 Python。目前 Tensorflow 支持\\n\\n64 位的 Python3.5/3.6/3.7/3.8 版本。\\n\\n2019 年 3 月 8 日，Google 发布最新 Tensorflow2.0-Alpha 版本，并在 2019 年 10 月\\n\\n1 日发布了 Tensorflow2.0 正式版本。新版本的 Tensorflow 有很多新特性，更快更容易使用\\n\\n更人性化。因为新版本的 Tensorflow 有较大的更新，所以老版的 Tensorflow 程序在新版本\\n\\n中几乎都无法继续使用。\\n\\n如果是作为一个初学者，那么我们应该先学 Tensorflow1 呢，还是直接学习\\n\\nTensorflow2。学习 Tensorflow1 的理由是现在网上的 Tensorflow 开源程序以及比较成熟\\n\\n的 Tensorflow 项目基本上都是基于 Tensorflow1 的，Tensorflow2 刚出不久，资源相对来\\n\\n说肯定会比较少一些。不过 Tensorflow2 肯定是未来发展的趋势，虽然现在还比较新，但是\\n\\n我还是建议大家学习 Tensorflow2 为主。Tensorflow1 和 Tensorflow2 作为两个大的版本，\\n\\n它们之间肯定会有很多不同之处，下面我选取两个我觉得最大的变化来给大家进行说明。\\n\\n5.1.2 静态图和动态图机制 Eager Execution\\n\\nTensorflow1 版本跟很多其他的“老”深度学习框架一样，都是使用静态图机制，而\\n\\nTensorflow2 版本跟 Pytorch 一样都是使用现在最新潮的动态图机制。什么是动态图机制我\\n\\n146\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n觉得基本上不需要跟大家解释，动态图机制是一种跟我们平时写 Python 代码类似的一种机制，\\n\\n用起来很自然。比如代码 5-1 为 Tensorflow2 的程序。\\n\\n代码 5-1：动态图\\n\\nimport tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把 m1 和 m2 传入 product = tf.matmul(m1,m2) # 打印结果 print(product) 结果输出为： tf.Tensor([[20]], shape=(1, 1), dtype=int32)\\n\\n动态图程序看起来就跟一段普通的 Python 程序一样，没什么好特别说明的。不过静态图\\n\\n就没这么好理解了，因为静态图跟我们平时的编程习惯不符。在静态图机制中我们需要在一个\\n\\n计算图（Graph）中定义计算的流程，然后再创建一个会话（Session），在会话中执行计算图\\n\\n的计算。比如代码 5-2 为 Tensorflow1 的程序。\\n\\n代码 5-2：静态图（片段 1）\\n\\n# 这个程序我是在 Tensorflow1 的环境中运行的 import tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把 m1 和 m2 传入 product = tf.matmul(m1,m2) # Tensorflow1 的程序跟一般的 python 程序不太一样 # 这个时候打印 product，只能看到 product 的属性，不能计算它的值 # 应该这里我只定义了计算图，图必须在会话中运行，我们还没有定义会话 print(product) 结果输出为： Tensor(\"MatMul:0\", shape=(1, 1), dtype=int32)\\n\\n147\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 5-2：静态图（片段 2）\\n\\n# 定义一个会话 sess = tf.Session() # 调用 sess 的 run 方法来执行矩阵乘法 # 计算 product，最终计算的结果存放在 result 中 result = sess.run(product) print(result) # 关闭会话 sess.close() 结果输出为： [[20]]\\n\\n对比动态图和静态图这两个简单的程序我们就能看出还是动态图使用起来比较简单，也更\\n\\n加自然。这也是深度学习框架未来的发展趋势，以后静态图机制应该会被慢慢淘汰。\\n\\n5.1.3 tf.keras\\n\\n在说 tf.keras 之前我们先来说一下 Keras，Keras 是所有深度学习框架中最容易使用，最\\n\\n初是由 Google AI 研究人员 Francois Chollet 创建并开发的。Francois 于 2015 年 3 月\\n\\n27 日将 Keras 的第一个版本发布在他的 GitHub。Keras 是一个高度封装的深度学习框架，\\n\\n它的后端可以是 Theano，Tensorflow 或者 CNTK。很快，Keras 的易用性得到了广大深度学\\n\\n习研究开发者的认可，并引起了 Tensorflow 官方的注意。并从 Tensorflow1.10 版本开始加\\n\\n入 tf.keras 接口，也就是我们在 Tensorflow 中也可以使用 Keras 的方式来搭建和训练模型。\\n\\n不过 Keras 和 tf.keras 是分开的两个项目，它们使用起来基本上是一样的，只是在细节上\\n\\n会有一些小的不同。随着 Tensorflow2.0 的推出，谷歌宣布 Keras 现在是 Tensorflow 的官方\\n\\n高级 API，用于快速简单的模型设计和训练，并推荐大家使用。随着 Keras2.3.0 的发布，\\n\\nFrancois 也发表声明推荐深度学习从业人员都应该将代码转成 Tensorflow2.0 和 tf.keras，而\\n\\n不是继续使用 Keras。\\n\\n148\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n149\\n\\n在 Tensorflow1.0 中 如何完成 我 们 的深 度学 习模 型训练程 序 我 们 有非 常 多 选择，\\n\\nTensorflow2.0 把选择进行了简化，只保留了更好的几种。基于 Tensorflow 官方推荐以及我\\n\\n个人的使用经验，我认为在 Tensorflow2.0 的使用中，我们可以尽量多使用 tf.keras 的接口来\\n\\n完成我们的应用。\\n\\n前面我介绍了很多关于 Keras/tf.keras 的优点，Keras/tf.keras 的缺点是程序运行效率会\\n\\n比纯 Tensorflow 程序要稍微慢一点点。这和容易理解，程序封装越多，用起来越方便，运行\\n\\n起来自然就会慢一些。不过 Tensorflow 针对这个问题也做了很多优化，所以实际应用中其实\\n\\n纯 Tensorflow 和 tf.keras 速度的差距一般也不会很大。真正影响深度学习运行速度的主要影\\n\\n响因素是模型的复杂度和硬件条件，tf.keras 对于速度基本上影响不会很大。\\n\\n5.2 Tensorflow-cpu 安装\\n\\nhttps://tensorflow.google.cn/install/pip 官方 网 址可 以看到 关 于 使 用 pip 安装\\n\\nTensorflow 比较详细的说明。\\n\\n5.2.1 Tensorflow-cpu 在线安装\\n\\n使用 Windows 安装 Tensorflow 的同学要注意，从 Tensor F low 2.1.0 版本开始，需要\\n\\n安装\\n\\nvc_redist.x64.exe ， 进入链接\\n\\nhttps://support.microsoft.com/en-\\n\\nus/help/2977003/the-latest-supported-visual-c-downloads。下载 Visual Studio 2015，\\n\\n2017\\n\\nand\\n\\n2019 下 面 的 x64:vc_redist.x64.exe （或直 接 从\\n\\nhttps://aka.ms/vs/16/release/vc_redist.x64.exe 链接下载，下载后双击进行安装。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 在 Winodws/MacOS/Linux 环境下安装方式基本上都是一样的，首先先来\\n\\n介绍 CPU 版本的安装。安装 Tensorflow 之前，先要安装 Python 环境，Python 的安装在本\\n\\n书第二章节已经介绍过了，大家先要把 Anaconda 给安装好，如使用 Windows 系统，则需\\n\\n要安装 Python3.5/3.6/3.7 版本的 64 位的 Anaconda。如果大家跟着书中的步骤进行安装的\\n\\n话，先把安装流程全部看完再动手，不然可能会操作错误。Python 安装模块的方式都可以用\\n\\npip install 的命令进行安装。Tensorflow2.0 正式发布以后，现在 Tesnorflow 默认安装的版\\n\\n本就是 Tensorflow2 的版本，安装 Tensorflow 可以用管理员方式打开命令提示符，运行如下\\n\\n命令：\\n\\npip install tensorflow-cpu\\n\\n不过上面命令通常下载速度比较慢，推荐从国内源进行下载速度比较快，使用下面命令下\\n\\n载速度比较快：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\ni https://pypi.douban.com/simple 是国内下载源，安装其他 python 模型也可以使用\\n\\n该下载源。\\n\\n执行完之后会自动从网上下载 tensorflow 安装包并安装，安装 tensorflow 的同时也会\\n\\n安装和更新一些其他的 python 包。\\n\\n顺利的话就运行完这段命令 tensorflow 就安装好了，安装好之后我们可以在命令行安装\\n\\n的最后看到类似如下信息：\\n\\nSuccessfully installed absl-py-0.8.1 cachetools-3.1.1 certifi-2019.11.28 gast-0.2.2\\n\\ngoogle-auth-1.9.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 oauthlib-3.1.0\\n\\npyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0\\n\\ntensorboard-2.0.2 tensorflow-2.0.0 urllib3-1.25.7\\n\\n150\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过一般来说都不会这么顺利，关于可能会出现的问题以及如何解决问题后面会总结。\\n\\n假设安装没有问题，那么可以打开一个 python 的运行环境，比如 Jupyter，然后运行命\\n\\n令：\\n\\nimport tensorflow\\n\\n如果没有产生错误，那么就代表安装成功了。如果看到警告不要紧张，有警告是正常的，\\n\\n一般警告都可以忽略掉，如图 5.2 所示表示安装成功。\\n\\n图 5.2 Tensorflow 安装成功\\n\\n5.2.2 安装过程中可能遇到的问题汇总\\n\\n由于 Tensorflow 会不断地更新，每个 Tensorflow 版本我们可能会遇到的问题不同，每\\n\\n个人的电脑环境也有所不同，所以我这里总结的问题不一定跟大家碰到的问题相同，也可能会\\n\\n有缺漏，如果问题不同或者有缺漏，大家可以给我反馈，我再进行补充。\\n\\n问 题 1 ： 在安装 过程中出现“\\n\\nERROR: tensorboard 2.0.2 has requirement\\n\\ngrpcio>=1.24.3, but you\\'ll have grpcio 1.14.1 which is incompatible.\\n\\nERROR: keras 2.2.2 has requirement keras-applications==1.0.4, but you\\'ll have\\n\\nkeras-applications 1.0.8 which is incompatible.”或者类似错误。\\n\\n解决方法：这类错误可以忽略不处理。\\n\\n151\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n问题 2：在安装过程中出现“ERROR: Cannot uninstall \\'wrapt\\'. It is a distutils installed\\n\\nproject and thus we cannot accurately determine which files belong to it which would\\n\\nlead to only a partial uninstall.”。\\n\\n解决方法：用管理员方式打开命令提示符，然后运行：\\n\\npip install wrapt --upgrade --ignore-installed\\n\\n然后再次运行：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n如果出错的不是\\'wrapt\\'而是其他模块，类似的错误可以用类似的方法解决。\\n\\n问 题 3 ： 在安装 过程中出现“ distributed 1.21.8 requires msgpack,which is not\\n\\ninstalled.”类似错误。\\n\\n解决方法：安装“msgpack“，打开命令提示符，然后运行：\\n\\npip install msgpack -i https://pypi.douban.com/simple\\n\\n问题 4：某条命令在安装过程中出现“PermissionError：[WinError 5] 拒绝访问”。\\n\\n解决方法：这个错误主要是权限问题，关闭所有 python 相关软件，重新用管理员方式打\\n\\n开命令提示符，然后再次运行该命令。\\n\\n问题 5：在安装过程中模块下载中断并出现“ReadTimeoutError:HTTPSConnectionPoll”。\\n\\n解决方法：由于下载的资源在国外，所以网速不好可能会导致下载连接超时，可以尝试重\\n\\n新运行命令再次下载安装。也可以使用国内的下载源进行安装，一般速度会比较快，运行下面\\n\\n的命令使用国内的源进行安装：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n问题 6：在安装过程中模块下载中断并出现“拒绝访问”。\\n\\n152\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n153\\n\\n解决方法：系统权限问题，可以用管理员方式打开命令提示符，然后重新安装，或者是在\\n\\n安装命令后面加上“--user”，例如：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple --user\\n\\n问题 7：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n\\n“\\n\\nImportError:cannot\\n\\nimport\\n\\nname\\n\\n‘dense_features’from\\n\\n‘tensorflow.python.feature_column’”。\\n\\n解决方法：用管理员的方式打开命令提示符，先运行：\\n\\npip uninstall tensorflow_estimator\\n\\n再运行\\n\\npip install tensorflow_estimator\\n\\n问题 8：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n\\n“ImportError: DLL load failed with error code -1073741795 和 ImportError: No\\n\\nmodule named \\'_pywrap_tensorflow_internal\\'”。\\n\\n解决方法：由于电脑 CPU 太老导致的错误，解决方法一是安装老版本的 Tensorflow，比\\n\\n如 Tensorflow1.2.0 版本，但是不推荐。推荐的解决方法是换一台新一点的电脑。\\n\\n问题 9：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现：\\n\\nERROR:root:Internal Python error in the inspect module.Below is the traceback from\\n\\nthis internal error.\\n\\n解决方法：安装 vc_redist.x64.exe，具体查看 5.2.1 中说明。然后再重新安装 Tensorflow。\\n\\n问题 10：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现“No\\n\\nmodule named ‘tensorflow’”，说明 Tensorflow 还没有安装好。\\n\\n解决方法：打开命令提示符，重新安装：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n问题 11：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n\\n“ImportError：DLL load failed：找不到指定的模型”。\\n\\n解决方法：安装 vc_redist.x64.exe，具体查看 5.2.1 中说明。然后再重新安装 Tensorflow。\\n\\n5.2.3 Tensorflow-cpu 卸载\\n\\n如果已经安装好了 Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\n\\npip uninstall tensorflow-cpu\\n\\n5.2.4 Tensorflow-cpu 更新\\n\\n如果已经安装过 Tensorlfow，现在想把 Tensorflow 更新到最新版本，可以用管理员方式\\n\\n打开命令行，执行命令：\\n\\npip install tensorflow-cpu –upgrade\\n\\n5.2.5 Tensorflow-cpu 指定版本的安装\\n\\n如果我们想安装 Tensorflow 指定版本，比如老一点的版本，可以使用指定版本的安装方\\n\\n式，比如我们想安装 Tensorflow1.13.2 版本的话，可以用管理员方式打开命令行，执行命令：\\n\\npip install tensorflow==1.13.2\\n\\n154\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.3 Tensorflow-gpu 安装\\n\\n5.3.1 Tensorflow-gpu 了解最新版本情况\\n\\n先在\\n\\nTensorflow 官网查看\\n\\nTensorflow-gpu 最 新的安装 情况\\n\\n（https://tensorflow.google.cn/install/gpu），如图 5.3 所示。\\n\\n图 5.3 tensorflow-gpu 版本最新情况\\n\\n一般来说比较新的英伟达(NVIDIA)的 GPU 都可以支持。这里要注意的是 CUDA 的版本\\n\\n和 cuDNN 的版本。比如我们在图 5.3 中看到的 Tensorflow-gpu 版本需要安装 CUDA10.1\\n\\n的版本，cuDNN 的版本要求 7.6 以上。如果 Tensorflow 出了更新的版本，对应的 CUDA\\n\\n和 cuDNN 的版本可能也会发生变化。\\n\\n5.3.2 Tensorflow-gpu 安装 CUDA\\n\\nCUDA（Compute Unified Device Architecture）是英伟达 NVIDIA 推出的运算平台，\\n\\n是一种通用的并行计算机构，可以使得 GPU 能够解决复杂的计算问题。CUDA 的下载的地址\\n\\n为：https://developer.nvidia.com/cuda-toolkit-archive，如图 5.4 所示。\\n\\n155\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.4 不同版本 CUDA 下载\\n\\n比如我们想下载 CUDA10.1，可以点击 CUDA Tool k it10.1。如果点击右侧的 Online\\n\\nDocumentation 可以查看关于 CUDA 安装的一些说明。图 5.5 为 CUDA10.1 对于\\n\\nWindows 环境的一些要求。\\n\\n图 5.5 CUDA10.1 对 Windows 环境要求\\n\\n图中我们可以看到 CUDA10.1 要求的 Windows 系统在 Table1 中，比较常用的系统都可\\n\\n以满足。另外在 Table2 中我们看到安装 CUDA10.1 之前我们还需要安装 Visual Studio，推\\n\\n荐安装 Visual Studio15 或 Visual Studio17 版本。\\n\\n图 5.6 为 CUDA10.1 对于 Linux 环境的一些要求。\\n\\n156\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.6 CUDA10.1 对 Linux 环境要求\\n\\n准备好 CUDA10.1 要求的环境以后看我们进入 CUDA 下载界面，并根据情况做好选择，\\n\\n最后点击 Downdload，如图 5.7 所示。\\n\\n图 5.7 下载 CUDA\\n\\n安装很简单，跟普通软件一样，一直下一步就可以。\\n\\n157\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.3.3 Tensorflow-gpu 安装 cuDNN 库\\n\\ncuDNN 的全称为 NVIDIA CUDA® Deep Neural Network library，是 NVIDIA 专门针\\n\\n对深度神经网络（Deep Neural Networks）中的基础操作而设计基于 GPU 的加速库。cuDNN\\n\\n为深度神经网络中的标准流程提供了高度优化的实现方式，例如 convolution、pooling、\\n\\nnormalization 以及 activation layers 的前向以及后向过程。\\n\\ncuDNN 的下载地址为：https://developer.nvidia.com/cudnn。下载之前需要注册。\\n\\nTensorflow 的 GPU 版本对 cuDNN 的版本是有严格要求的，前面我们看到目前\\n\\nTensorflow2 支持的是 cuDNN7.6 以上版本。\\n\\n进入下载地址后，选择对应 CUDA10.1 版本和对应操作系统的 cuDNN 进行下载，如图\\n\\n5.8 所示。\\n\\n图 5.8 下载 cuDNN\\n\\n下载好了之后可以得到一个压缩包，解压完之后可以看到三个文件夹，我们要做的就是\\n\\n把这三个文件夹中的内容拷贝到 CUDA 安装目录下面所对应的三个文件夹中，如图 5.9（这\\n\\n是我之前配置 CUDA9.0 和对应 cuDNN 时的图，其他版本的 CUDA 和 cuDNN 也一样）所\\n\\n示。\\n\\n158\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.9 配置 cuDNN\\n\\n5.3.4 Tensorflow-gpu 在线安装\\n\\n安装方式跟 CPU 版本差不多，用管理员方式打开命令提示符，执行命令：\\n\\npip install tensorflow-gpu -i https://pypi.douban.com/simple\\n\\n5.3.5 Tensorflow-gpu 卸载\\n\\n如果已经安装好了 Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\n\\npip uninstall tensorflow-gpu\\n\\n5.3.6 Tensorflow-gpu 更新\\n\\n如果已经安装过 Tensorlfow，现在想把 Tensorflow 更新到最新版本，可以用管理员方式\\n\\n打开命令行，执行命令：\\n\\npip install tensorflow-gpu –upgrade\\n\\n159\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.4 Tensorflow 基本概念\\n\\nTensorflow 中的一些基本概念在 Tensorflow2 版本中已经被隐藏起来，或者已经不再使\\n\\n用了，不过我还是打算给大家简单介绍一些 Tensorflow 的基本概念，虽然之后可能不会用到。\\n\\nTensorflow 是一个编程系统，使用图(graphs)来表示计算任务，图(graphs)中的节点称\\n\\n之为 op(operation)，一个 op 获得 0 个或多个 Tensor，执行计算，产生 0 个或多个 Tensor，\\n\\nTensor 看作是一个 n 维的数据。Tensorflow1 中图必须在会话（Session）中运行，如图 5.10\\n\\n所示。\\n\\n图 5.10 会话 Session\\n\\n图中的 Tensor 表示数据，一般可以用在数据的输入，输出，以及计算的中间流程。Variable\\n\\n表示变量，一般用于记录一些需要变化的数值，比如需要训练的模型参数。虽然可以使用\\n\\nTensor 的地方都可以使用 Variable，不过它们还是有一些区别。\\n\\n图中的 Graph 表示一个完整的计算任务，最上面的 Tensor0 和 Variable0 一起传入一个\\n\\noperation0 里面，这个 operation0 可以是加法，减法，乘法，除法等运算。运算完了之后产\\n\\n160\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n生了一个 Tensor1，这个 Tensor1 跟 Tensor2 一起被送入了 operation1，在 operation1 中\\n\\n进行计算。\\n\\n再举一个更具体的例子，如图 5.11 所示。\\n\\n图 5.11 神经网络计算图\\n\\n图中的 x 是一个 Tensor，表示数据的输入，图中的 W 和 b 是 Variable，表示模型需要\\n\\n训练的参数。W 和 x 共同传入了 MatMul 的 operation 中，进行矩阵乘法的操作，计算完\\n\\n后得到的 Tensor0 会传入到 Add(operation)中，跟变量 b 一起进行加法操作，得到\\n\\nTensor1。Tensor1 传入 ReLU(operation)激活函数进行计算，然后得到 Tensor2 再继续传\\n\\n递信号，最终得到 Tensor3。\\n\\n在前面的内容中我们已经介绍过，在 Tensorflow2 中使用的是动态图机制，也就是说我\\n\\n们不再需要会话，我们可以在任意时候进行计算并得到结果，程序设计起来会更加方便，更\\n\\n加自然。\\n\\n161\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.5 Tensorflow 基础使用\\n\\n1．TF1 转 TF2 工具\\n\\nTensorflow2 安装好之后，会自带一个工具可以把 Tensorflow1 的程序转成 Tensorflow2\\n\\n的程序，使用方法是打开命令提示符，然后执行：\\n\\ntf_upgrade_v2 --infile input.py --outfile output.py\\n\\ntf_upgrade_v2 为转化工具，input.py 为 Tensorflow1 的程序路径，output.py 为新产\\n\\n生的 Tensorflow2 的程序保存路径。\\n\\n这个工具的转换效果不能算很好，并不是所有的 Tensorflow1 的程序都可以使用这个工\\n\\n具转变为 Tensorflow2 的程序。一些比较复杂的 Tensorflow1 的程序还是需要进行比较多的\\n\\n改写才能转成 Tensorflow2 的程序。所以大家需要把 Tensorflow1 转成 Tensorflow2 的时候\\n\\n可以尝试使用，如果发现不行的话可以再自行修改。\\n\\n2. Tensorflow 基本操作\\n\\nTensorflow 基本操作的代码如代码 5-3 所示。\\n\\n代码 5-3：Tensorflow 基本操作\\n\\nimport tensorflow as tf # 定义一个变量 x = tf.Variable([1,2]) # 定义一个常量 a = tf.constant([3,3]) # 减法 op sub = tf.subtract(x, a) # 加法 op add = tf.add(x,sub) print(sub) print(add)\\n\\n162\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 结果输出为： tf.Tensor([-2 -1], shape=(2,), dtype=int32)\\n\\ntf.Tensor([-1 1], shape=(2,), dtype=int32)\\n\\n3. 拟合线性函数\\n\\n拟合线性函数的代码如代码 5-4 所示。\\n\\n代码 5-4：拟合线性函数（片段 1）\\n\\nimport tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用 numpy 生成 100 个从 0-1 的随机点，作为 x x_data = np.random.rand(100) # 生成一些随机扰动 noise = np.random.normal(0,0.01,x_data.shape) # 构建目标值，符合线性分布 y_data = x_data*0.1 + 0.2 + noise # 画散点图 plt.scatter(x_data, y_data) plt.show() 结果输出为：\\n\\n代码 5-4：拟合线性函数（片段 2）\\n\\n# 构建一个顺序模型 # 顺序模型为 keras 中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # Dense 为全连接层\\n\\n163\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 在模型中添加一个全连接层 # units 为输出神经元个数，input_dim 为输入神经元个数 model.add(tf.keras.layers.Dense(units=1,input_dim=1)) # 设置模型的优化器和代价函数，学习率为 0.03 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.03),loss=\\'mse\\')\\n\\n# 训练 2001 个批次 for step in range(2001): # 训练一个批次数据，返回 cost 值 cost = model.train_on_batch(x_data,y_data) # 每 500 个 batch 打印一次 cost 值 if step % 500 == 0: print(\\'cost:\\',cost)\\n\\n# 使用 predict 对数据进行预测，得到预测值 y_pred y_pred = model.predict(x_data)\\n\\n# 显示随机点 plt.scatter(x_data,y_data) # 显示预测结果 plt.plot(x_data,y_pred,\\'r-\\',lw=3) plt.show() 结果输出为： cost: 0.33022374 cost: 0.0003510235 cost: 9.941429e-05 cost: 9.440048e-05 cost: 9.430057e-05\\n\\n164\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.拟合非线性函数\\n\\n拟合非线性函数的代码如代码 5-5 所示。\\n\\n代码 5-5：拟合非线性函数（片段 1）\\n\\nimport tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用 numpy 生成 200 个均匀分布的点，并新增一个维度 x_data = np.linspace(-0.5,0.5,200)[:,np.newaxis] # 生成一些跟 x_data 相同 shape 的随机值作为噪声数据 noise = np.random.normal(0,0.02,x_data.shape) # 构建目标值，符合非线性函数，另外再加上噪声值 y_data = np.square(x_data) + noise # 画散点图 plt.scatter(x_data,y_data) plt.show() 结果输出为：\\n\\n代码 5-5：拟合非线性函数（片段 2）\\n\\n# 构建一个顺序模型 # 顺序模型为 keras 中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # 因为要做非线性回归，所以需要一个带有隐藏层的神经网络 # 并且需要使用非线性的激活函数，比如 tanh 函数 # keras 中 input_dim 只需要在输入层设置，后面的网络可以自动推断出该层对应的输入 # keras 中定义网络结构已经默认设置好权值初始化，所以我们不需要额外进行设置 model.add(tf.keras.layers.Dense(units=10,input_dim=1,activation=\\'tanh\\')) model.add(tf.keras.layers.Dense(units=1,activation=\\'tanh\\'))\\n\\n165\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 设置模型的优化器和代价函数，学习率为 0.1 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.3),loss=\\'mse\\')\\n\\n# 训练 3001 个批次 for step in range(3001): # 训练一个批次数据，返回 cost 值 cost = model.train_on_batch(x_data,y_data) # 每 1000 个 batch 打印一次 cost 值 if step % 1000 == 0: # 定义一个 2*2 的图，当前是第 i/1000+1 个图 plt.subplot(2,2,step/1000+1) # 把 x_data 喂到模型中获得预测值 prediction_value = model.predict(x_data) # 画散点图 plt.scatter(x_data,y_data) # 画模型预测曲线图 plt.plot(x_data,prediction_value,\\'r-\\',lw=5) # 不显示坐标 plt.axis(\\'off\\') # 图片的标题设置 plt.title(\"picture:\" + str(int(step/1000+1))) plt.show() 结果输出为：\\n\\n从结果中我们能看得出，随着权值的调整，模型的预测结果也在不断地调整，最终得到比\\n\\n较好的拟合效果。\\n\\n166\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.6 手写数字图片分类任务\\n\\n5.6.1 MNIST 数据集介绍\\n\\nMNIST 是一个手写数字的数据集。其中训练集有 60000 张图片，测试集有 10000 张图\\n\\n片，每一张图片包含 28*28 个像素。数据集的下载网址为：\\n\\nhttp://yann.lecun.com/exdb/mnist/。MNIST 数据集的图片如图 5.12\\n\\n图 5.12 MNIST 数据集\\n\\nMNIST 数据集的标签是介于 0-9 的数字，有时候我们要把标签转化为独热编码(one-hot\\n\\nvectors)，然后再传给模型进行训练。\\n\\n5.6.2 Softmax 函数介绍\\n\\n在多分类问题中，我们通常会使用 softmax 函数作为网络输出层的激活函数，softmax\\n\\n函数可以对输出值进行归一化操作，把所有输出值都转化为概率，所有概率值加起来等于\\n\\n1，softmax 的公式为：\\n\\n167\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑥)( =\\n\\nexp\\t(𝑥() ∑ exp\\t(𝑥(cid:129))\\n\\n(cid:129)\\n\\n例如某个神经网络有 3 个输出值，为[1,5,3]。\\n\\n计算𝑒\" = 2.718，𝑒(cid:176) = 148.413，𝑒$ = 20.086，𝑒\" + 𝑒(cid:176) + 𝑒$ = 171.217。\\n\\n𝑝1 =\\n\\n⁄–\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.016，𝑝2 =\\n\\n⁄†\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.867，𝑝3 =\\n\\n⁄‡\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.117。\\n\\n所以加上 softmax 函数后数值变成了[0.016,0.867,0.117]。\\n\\n例如手写数字识别的网络最后的输出结果本来是[-0.124,-4.083,-0.62,0.899,-1.193,-0.70\\n\\n1,-2.834,6.925,-0.332,2.064]，加上 softmax 函数后会变成[0.001,0.0,0.001,0.002,0.0,0.0,\\n\\n0.0,0.987,0.001,0.008]。\\n\\n5.6.3 简单 MNIST 数据集分类模型-没有高级封装\\n\\n我们可以考虑先构建一个简单的神经网络，这个网络只有输入层和输出层，输入层有 784\\n\\n个神经元，对应每张图片的 784 个像素点，输出层有 10 个神经元，对应 one-hot 的标签值，\\n\\n如图 5.13：\\n\\n168\\n\\n(5.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.13 简单 MNIST 数据集分类模型\\n\\n大家刚开始学习 tensorflow，所以没有使用 tf.keras 高级封装的代码我也会准备一些给\\n\\n大家学习，代码 5-6 没有使用 tf.keras 来封装模型数据载入和模型训练的过程。\\n\\n代码 5-6：MNIST 数据集分类模型-没有高级封装\\n\\nimport tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象，使用 dataset 对象来管理数据 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期设置为 1（把所有训练集数据训练一次称为训练一个周期） mnist_train = mnist_train.repeat(1) # 批次大小设置为 32（每次训练模型传入 32 个数据进行训练） mnist_train = mnist_train.batch(32)\\n\\n# 创建 dataset 对象，使用 dataset 对象来管理数据 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期设置为 1（把所有训练集数据训练一次称为训练一个周期） mnist_test = mnist_test.repeat(1) # 批次大小设置为 32（每次训练模型传入 32 个数据进行训练） mnist_test = mnist_test.batch(32)\\n\\n# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n169\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 计算平均值 train_loss = tf.keras.metrics.Mean(name=\\'train_loss\\') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'train_accuracy\\') # 计算平均值 test_loss = tf.keras.metrics.Mean(name=\\'test_loss\\') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'test_accuracy\\')\\n\\n# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 # 定义一个训练模型的函数 @tf.function def train_step(data, label): # 固定写法，使用 tf.GradientTape()来计算梯度 with tf.GradientTape() as tape: # 传入数据获得模型预测结果 predictions = model(data) # 对比 label 和 predictions 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 传入 loss 和模型参数，计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)\\n\\n# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 # 定义一个模型测试的函数 @tf.function def test_step(data, label): # 传入数据获得模型预测结果 predictions = model(data) # 对比 label 和 predictions 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)\\n\\n170\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 训练 10 个周期（把所有训练集数据训练一次称为训练一个周期） EPOCHS = 10\\n\\nfor epoch in range(EPOCHS): # 训练集循环 60000/32=1875 次 for image, label in mnist_train: # 每次循环传入一个批次的数据和标签训练模型 train_step(image, label) # 测试集循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 每次循环传入一个批次的数据和标签进行测试 test_step(test_image, test_label)\\n\\n# 打印结果 template = \\'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}\\' print(template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result())) 结果输出为： Epoch 1, Loss: 0.017, Accuracy: 0.892, Test Loss: 0.0138, Test Accura cy: 0.909 Epoch 2, Loss: 0.015, Accuracy: 0.905, Test Loss: 0.0134, Test Accura cy: 0.911 Epoch 3, Loss: 0.014, Accuracy: 0.911, Test Loss: 0.0131, Test Accura cy: 0.913 Epoch 4, Loss: 0.0134, Accuracy: 0.914, Test Loss: 0.0129, Test Accur acy: 0.915 Epoch 5, Loss: 0.013, Accuracy: 0.917, Test Loss: 0.0127, Test Accura cy: 0.916 Epoch 6, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0126, Test Accur acy: 0.917 Epoch 7, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0125, Test Accur acy: 0.918 Epoch 8, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0124, Test Accur acy: 0.919 Epoch 9, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur acy: 0.919 Epoch 10, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122,Test Accur acy: 0.92\\n\\n171\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.6.4 简单 MNIST 数据集分类模型-keras 高级封装\\n\\n给大家介绍了没有使用高级封装的程序以后，下面要给大家介绍一下使用 tf.keras 高级封\\n\\n装的 MNIST 数据集分类程序，如代码 5-7 所示。\\n\\n代码 5-7：MNIST 数据集分类模型-keras 高级封装\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss=\\'mse\\'定义均方差代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 sgd = SGD(0.1) model.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 10（把所有训练集数据训练一次称为训练一个周期） # 批次大小为 32（每次训练模型传入 32 个数据进行训练）\\n\\n172\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # validation_data 设置验证集数据 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n\\n程序的输出结果为：\\n\\nTrain on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0374 - accuracy: 0.7822 - val_loss: 0.0214 - val_accuracy: 0.880 2 Epoch 2/10 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0203 - accuracy: 0.8816 - val_loss: 0.0175 - val_accuracy: 0.897 8 Epoch 3/10 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0177 - accuracy: 0.8932 - val_loss: 0.0160 - val_accuracy: 0.904 1 Epoch 4/10 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0165 - accuracy: 0.8994 - val_loss: 0.0151 - val_accuracy: 0.907 0 Epoch 5/10 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0157 - accuracy: 0.9031 - val_loss: 0.0145 - val_accuracy: 0.910 7 Epoch 6/10 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0151 - accuracy: 0.9063 - val_loss: 0.0140 - val_accuracy: 0.913 1 Epoch 7/10 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0147 - accuracy: 0.9090 - val_loss: 0.0137 - val_accuracy: 0.914 5 Epoch 8/10 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0143 - accuracy: 0.9112 - val_loss: 0.0134 - val_accuracy: 0.915 8 Epoch 9/10 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0140 - accuracy: 0.9122 - val_loss: 0.0132 - val_accuracy: 0.917 6 Epoch 10/10\\n\\n173\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 2s 36us/sample - los s: 0.0138 - accuracy: 0.9137 - val_loss: 0.0131 - val_accuracy: 0.918 4\\n\\n对比看来，使用了 tf.keras 高级封装的程序更简洁，同时也更容易理解，并且程序运行时\\n\\n的结果输出也更友好。我们在程序运行时可以实时看到模型训练一共要训练多少个周期，当前\\n\\n训练到第几个周期，当前周期的进度条，训练当前周期的剩余时间，当前训练集的准确率和 loss。\\n\\n训练完一个周期之后可以看到训练一个周期所花费的时间，如果设置了验证集，可以看到验证\\n\\n集的准确率和 loss。这些信息都是默认输出的，当然我们也可以把 fit 方法中的参数 verbose 设\\n\\n置为 0，让模型训练过程中不输出任何信息。不过推荐大家还是保持默认值 berbose=1，毕竟\\n\\n看到这些输出信息更有利于我们了解模型的训练情况。\\n\\n最后模型的测试集准确率大约是 92%左右，并不是特别高。\\n\\n如何可以进一步提升模型的效果，我们将在下一个章节介绍。\\n\\n174\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 6 章-网络优化方法\\n\\n本章节内容我们将学习神经网络的一些优化方法，包括使用交叉熵代价函数，抵抗过拟\\n\\n合的几种方法和使用不同的模型优化器。这些模型优化方法有些可以比较有效的提升模型收\\n\\n敛速度或模型的效果，有些只是有可能提升模型的效果。所以我们在选择使用不同的网络优\\n\\n化方法的时候，还是需要根据实际的测试情况来进行选择。\\n\\n6.1 交叉熵代价函数\\n\\n我们在读高中的时候，每天都会做大量的练习，很多课后作业。但是很多题目我们做错以\\n\\n后，下次再见到这个题目的时候已经不记得了，所以会再次做错同样的题目。因为做错普通的\\n\\n课后作业练习题并不能引起我们的重视，所以印象不深刻。\\n\\n如果是老师让我们单独上讲台做题目的话，每次遇到这种情况我们都会比较紧张，因为全\\n\\n班同学，包括我们的暗恋对象都在看着我们。如果在这个时候，我们把题目给做错了，那就丢\\n\\n人丢大了。而被我们做错的那个题目，也会让我们格外印象深刻，下次遇到这个题目的时候就\\n\\n不容易犯错了。\\n\\n也就是说我们在犯了更大的错误以后，往往会学到更多东西，进步更快。理想的情况下，\\n\\n我们也希望神经网络可以从错误中快速学习，最好是错误越大，学习越快，因此均方差代价函\\n\\n数通常用在回归任务中，分类任务中我们会使用交叉熵（Cross Entropy）作为代价函数。\\n\\n6.1.1 均方差代价函数的缺点\\n\\n我们先来重新思考一下均方差代价函数。\\n\\n175\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n先看一个小例子，假如有一个简单的神经网络，它只有一个权值 w 和偏置 b，一个输入 x\\n\\n和一个输出 y，激活函数为 sigmoid 函数，如图 6.1 所示。\\n\\n图 6.1 单输入单输出的简单神经网络\\n\\n我们要训练这个网络做一个简单的事情，给定 x，w 和 b 的值，可以计算出网络输出值\\n\\ny，已知网络的目标值 t，然后用梯度下降法来优化网络的参数 w 和 b，使得网络的 loss 值\\n\\n不断减小。这里我们先把代价函数定义为之前我们学过的均方差代价函数：\\n\\n𝐸 =\\n\\n1 2𝑁\\n\\n(𝑇 − 𝑌)# =\\n\\n1 2𝑁\\n\\nP ?(𝑡( − 𝑦()# (A\"\\n\\n第一次试验，x 的值为 1，w 的初始值设置为 0.6，b 的初始值设置为 0.9，目标值 t 的\\n\\n值为 0，使用梯度下降法学习率 0.15，训练 300 周期，网络的初始参数如图 6.2 所示。\\n\\n图 6.2 试验一初始状态\\n\\n实验一训练了 300 周期后的状态如图 6.3 所示。\\n\\n176\\n\\n(6.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.3 试验一训练 300 次之后的状态\\n\\n实验一 loss 的变化如图 6.4 所示。\\n\\n图 6.4 试验一 loss 变化\\n\\n第二次试验，x 的值为 1，w 的初始值设置为 1.85，b 的初始值设置为 1.85，目标值 t\\n\\n的值为 0，使用梯度下降法学习率 0.15，训练 300 周期，网络的初始参数如图 6.5 所示。\\n\\n图 6.5 试验二初始状态\\n\\n试验二训练了 300 周期后的状态如图 6.6 所示。\\n\\n图 6.6 试验二训练 300 次之后的状态\\n\\n177\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n实验二 loss 的变化如图 6.7 所示。\\n\\n图 6.7 试验二 loss 变化\\n\\n观察实验一和试验二我们会发现试验结果和我们理想的结果不同，我们理想的学习效果\\n\\n应该是误差越大，学习得越快。\\n\\n从两个试验的 loss 曲线我们能看到它们不同的学习速度。实验一的初始输出为 0.82，距\\n\\n离目标值 0 的误差相对比较小，但是初始学习速度比较快。实验二的初始输出为 0.99，距离\\n\\n目标值 0 的误差相对比较大，但是初始学习速度比较慢。这个现象不仅仅是在这个小实验\\n\\n中，也会在其他的神经网络应用中出现。我们想进一步理解这个现象，就要分析一下它的代\\n\\n价函数。当 N=1 时，二次代价函数为\\n\\n𝐸 =\\n\\n1 2\\n\\n(𝑦 − 𝑡)#\\n\\n其中 E 为代价函数，t 为目标输出，y 为神经网络的输出。因为激活函数为 sigmoid 函数，\\n\\n符号为𝜎，所以𝑦 = 𝜎(𝑧)，𝑧 = 𝑤𝑥 + 𝑏。使用链式法则来求权重和偏置的偏导数可以得到：\\n\\n𝜕𝐸 𝜕𝑤 𝜕𝐸 𝜕𝑏\\n\\n= (𝑦 − 𝑡)𝜎R(𝑧)𝑥\\n\\n= (𝑦 − 𝑡)𝜎R(𝑧)\\n\\n把 x=1 以及 t=0 带入公式 6.3 和公式 6.4，可以得到：\\n\\n178\\n\\n(6.2)\\n\\n(6.3)\\n\\n(6.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝜕𝐸 𝜕𝑤 𝜕𝐸 𝜕𝑏\\n\\n= 𝑦𝜎R(𝑧)\\n\\n= 𝑦𝜎R(𝑧)\\n\\n从公式 6.5 和公式 6.6 我们可以看出，权值和偏置值的调整是跟激活函数的导数成正比\\n\\n的，我们可以回忆一下 sigmoid 函数的图像，如图 6.8 所示。\\n\\n图 6.8 sigmoid 函数图像\\n\\n从图中我们可以看出，当神经元的输出接近 1 和 0 的时候，曲线变得非常平，也就意味\\n\\n着在输出接近 1 和 0 的位置函数的导数接近于 0。函数的导数接近于 0，那么公式 6.5 和 6.6\\n\\n的值就接近于 0，其实就是代表网络的参数调节的速度非常慢，网络的优化速度非常慢。\\n\\nsigmoid 函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]，实验一的初始输出为 0.82，初始导数\\n\\n为 0.1476。实验二的初始输出为 0.99，初始导数为 0.0099。所以实验一中网络权值的初始\\n\\n调节速度要比实验二中网络权值的初始调节速度快。但是违反了我们误差越大，应该学习越\\n\\n快的直觉。\\n\\n6.1.2 引入交叉熵代价函数\\n\\n我们换一个思路，不改变激活函数而是改变代价函数，改用交叉熵代价函数：\\n\\n179\\n\\n(6.5)\\n\\n(6.6)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n其中 N 是训练数据的总数，y 是网络的预测值，t 是网络的目标值。\\n\\n首先我们先观察一下这个函数的特性：\\n\\n1. 当我们使用 sigmoid 激活函数的时候，y 的取值范围是 0-1 之间，t 的取值为\\n\\n0 或 1，所以代价函数的值是非负的。\\n\\n2. 当目标值 t=0 时，预测值 y 越接近于 0，代价函数的值 E 越小，E 的最小值为\\n\\n0；当目标值 t=0 时，预测值 y 越接近于 1，代价函数的值 E 越大，E 的最大值为+∞。\\n\\n3. 当目标值 t=1 时，预测值 y 越接近于 1，代价函数的值 E 越小，E 的最小值为\\n\\n0；当目标值 t=1 时，预测值 y 越接近于 0，代价函数的值 E 越大，E 的最大值为+∞。\\n\\n综上所述，交叉熵的值是非负的，并且网络的预测值越接近于目标值，则交叉熵的值就越\\n\\n小，这些都是我们想要的代价函数的特性。均方差代价函数其实也是具备这些特性的。\\n\\n接下来我们对交叉熵求 w 的偏导数，当 N=1 时有：\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n= − ¶\\n\\n= − ¶\\n\\n𝑡( 𝜎(𝑧)( 𝑡 𝜎(𝑧)\\n\\n−\\n\\n−\\n\\n(1 − 𝑡() 1 − 𝜎(𝑧)( (1 − 𝑡) 1 − 𝜎(𝑧)\\n\\n\\n\\n𝜕𝜎 𝜕𝑤(cid:129)\\n\\n𝜎R(𝑧)𝑥(cid:129)\\n\\n= ¶\\n\\n𝜎R(𝑧)𝑥(cid:129) 𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n(𝜎(𝑧) − 𝑡)\\n\\nSigmoid 函数的导数为：\\n\\n𝜎R(𝑧) = \\t𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n所以：\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n= 𝑥(cid:129)(\\t𝜎(𝑧) − 𝑡)\\n\\n= 𝑥(cid:129)(\\t𝑦 − 𝑡)\\n\\n180\\n\\n(6.7)\\n\\n(6.8)\\n\\n(6.9)\\n\\n(6.10)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这是一个非常优美的公式，我们可以看出权重的学习速度是跟 y-t 成正比的。y-t 就是网\\n\\n络的误差值，误差越大，网络的学习速度越快，这正是我们想要的。sigmoid 函数与交叉熵配\\n\\n合使用可以加快网络收敛的速度。\\n\\n6.1.3 交叉熵代价函数推导过程\\n\\n以权值 b 为例，推导交叉熵代价函数，对 E 求 b 的偏导数有：\\n\\n𝜕𝐸 𝜕𝑏\\n\\n=\\n\\n𝜕𝐸 𝜕𝑦\\n\\n\\n\\n𝜕𝑦 𝜕𝑧\\n\\n\\n\\n𝜕𝑧 𝜕𝑏\\n\\n𝜕(𝑤𝑥 + 𝑏) 𝜕𝑏\\n\\n𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦\\n\\n𝜎R(𝑧) ∙\\n\\n=\\n\\n𝜎R(𝑧)\\n\\n=\\n\\n𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n=\\n\\n=\\n\\n𝑦(1 − 𝑦)\\n\\n我们希望 b 对 E 的导数是跟网络的误差 y-t 成正比的，因此我们可以让：\\n\\n𝜕𝐸 𝜕𝑏\\n\\n=\\n\\n𝜕𝐸 𝜕𝑦\\n\\n𝑦(1 − 𝑦) = 𝑦 − 𝑡\\n\\n即：\\n\\n𝜕𝐸 𝜕𝑦\\n\\n=\\n\\n𝑦 − 𝑡 𝑦(1 − 𝑦)\\n\\n= − l\\n\\n𝑡 𝑦\\n\\n−\\n\\n1 − 𝑡 1 − 𝑦\\n\\nm\\n\\n对等式两侧求积分，可以得到：\\n\\n𝐸 = −[𝑡𝑙𝑛𝑦 + (1 − 𝑡) ln(1 − 𝑦)]\\n\\n公式 6.14 就是前面介绍的交叉熵函数。\\n\\n181\\n\\n(6.11)\\n\\n(6.12)\\n\\n(6.13)\\n\\n(6.14)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.1.4 Softmax 与对数似然代价函数\\n\\n通过前面的内容我们可以知道 sigmoid 函数配合交叉熵代价函数的使用可以加快网络训\\n\\n练速度，而在处理多分类的任务时，我们经常会使用 softmax 函数作为输出层的激活函数。\\n\\n当我们使用 softmax 作为输出层的激活函数时，与之匹配的代价为对数似然（Log Likelihood）\\n\\n代价函数。\\n\\nsoftmax 函数与对数似然代价函数的组合跟 sigmoid 函数与交叉熵代价函数的组合类似。\\n\\nsoftmax 函数与对数似然代价函数在处理二分类问题的时候可以简化为 sigmoid 函数与交叉\\n\\n熵代价函数的形式。\\n\\n对数似然代价函数的公式为：\\n\\nP 𝐸 = − ? 𝑡(𝑙𝑜𝑔 (A\"\\n\\n(𝑦()\\n\\n其中，N 表示一共有 N 个输出神经元，也可以认为是 N 个分类，𝑡(表示第 i 个输出神经元\\n\\n的目标值，𝑦(表示第 i 个输出神经元预测值，取值范围是 0-1 之间。\\n\\n假设把一个样本输入到网络中，只有一个神经元对应了该样本的正确类别（样本的标签为\\n\\none-hot 格式），那么这个神经元输出的概率值越高，则公式 6.15 的代价函数的值就越小，反\\n\\n之，代价函数的值就越大。\\n\\nsoftmax 的公式为：\\n\\n𝑦( =\\n\\ne„” ∑ 𝑒 „» (cid:129)\\n\\n𝑦(表示输出层第 i 个神经元的输出，𝑧(表示输出层第 i 个神经元的输入，e 表示自然常数，\\n\\n∑ 𝑒 „»\\n\\n(cid:129) 表示输出层所有神经元的输入之和。\\n\\nsoftmax 的求导结果比较特别，需要分为两种情况：\\n\\n182\\n\\n(6.15)\\n\\n(6.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nif\\tj=i:\\n\\ne„” ∑ 𝑒 „» (cid:129) 𝜕𝑧(cid:129) e„” ∙ ∑ 𝑒 „» (cid:129) (cid:142)∑ 𝑒 „» (cid:143) (cid:129) e„” ∑ 𝑒 „» (cid:129)\\n\\n𝜕 l\\n\\nm\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n=\\n\\n− e„” ∙ e„”\\n\\n=\\n\\n#\\n\\ne„” ∑ 𝑒 „» (cid:129) \\t\\t\\t\\t\\t\\t\\t\\t= 𝑦((1 − 𝑦()\\n\\ne„” ∑ 𝑒 „» (cid:129)\\n\\n=\\n\\n−\\n\\n\\n\\nif\\tj≠i:\\n\\ne„” ∑ 𝑒 „» (cid:129) 𝜕𝑧(cid:129) 0 ∙ ∑ 𝑒 „» (cid:129) (cid:142)∑ 𝑒 „» (cid:129) e„» ∑ 𝑒 „» (cid:129) \\t\\t= −𝑦(cid:129)𝑦(\\n\\n𝜕 l\\n\\nm\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n=\\n\\n− e„» ∙ e„” #\\n\\n=\\n\\n(cid:143) e„” ∑ 𝑒 „» (cid:129)\\n\\n= −\\n\\n\\n\\n接下来我们对对数似然代价函数求 w 的偏导数：\\n\\n183\\n\\n(6.17)\\n\\n(6.18)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n184\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n=\\n\\n𝜕𝑧(cid:129) 𝜕𝐸 𝜕𝑧(cid:129) 𝜕𝑤(cid:129) P 𝜕(cid:142)∑ 𝑡(log\\t(𝑦() (cid:143) (A\" 𝜕𝑧(cid:129) P\\n\\n=\\n\\n\\n\\n\\n\\n𝜕(𝑤(cid:129)𝑥(cid:129) + 𝑏(cid:129)) 𝜕𝑤(cid:129)\\n\\n= −𝑥(cid:129) ? 𝑡(\\n\\n(A\"\\n\\n1 𝑦(\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n= −𝑥(cid:129) (cid:139)𝑡(cid:129)\\n\\n1 𝑦(cid:129)\\n\\n𝜕𝑦(cid:129) 𝜕𝑧(cid:129)\\n\\nP + ? 𝑡( (¿(cid:129)\\n\\n1 𝑦(\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n(cid:140)\\n\\n(cid:142)应用𝑠𝑜𝑓𝑡𝑚𝑎𝑥的导数(cid:143)\\n\\n= −𝑥(cid:129) (cid:148)𝑡(cid:129)\\n\\n1 𝑦(cid:129)\\n\\nP\\n\\n𝑦(cid:129)(cid:142)1 − 𝑦(cid:129)(cid:143) + ? 𝑡(\\n\\n(¿(cid:129)\\n\\n1 𝑦(\\n\\n(cid:142)−𝑦(cid:129)𝑦((cid:143)(cid:149)\\n\\nP\\n\\n= −𝑥(cid:129) (cid:139)𝑡(cid:129) − 𝑡(cid:129)𝑦(cid:129) − ? 𝑡(𝑦(cid:129)\\n\\n(cid:140)\\n\\n(¿(cid:129)\\n\\nP\\n\\n= −𝑥(cid:129) >𝑡(cid:129) − 𝑦(cid:129) ? 𝑡(\\n\\nB = 𝑥(cid:129)(cid:142)𝑦(cid:129) − 𝑡(cid:129)(cid:143)\\n\\n(6.19)\\n\\n(A\"\\n\\nP (A\" 表示所以输出的目标值累加，一般我们会把目标值转成 one-hot\\n\\n公式 6.19 最后的∑ 𝑡(\\n\\nP (A\" 的值为 1。从对数似然代价函数的梯度公式我们也能看出，网络权值\\n\\n的数据格式，所以∑ 𝑡(\\n\\n的调整是跟网络的误差相关的，误差越大则网络训练速度越快，跟交叉熵代价函数有类似的结\\n\\n果。\\n\\n6.1.5 交叉熵程序\\n\\n简单 MNIST 数据集分类模型-交叉熵的代码如代码 6-1 所示。\\n\\n代码 6-1：简单 MNIST 数据集分类模型-交叉熵（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model1 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n# sgd 定义随机梯度下降法优化器，学习率 0.1 # loss=\\'mse\\'定义均方差代价函数 # loss=\\'categorical_crossentropy\\'定义交叉熵代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 # model1 用均方差代价函数，model2 用交叉熵代价函数 sgd = SGD(0.1) model1.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\']) model2.compile(optimizer=sgd, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 8（把所有训练集数据训练一次称为训练一个周期） epochs = 8 # 批次大小为 32（每次训练模型传入 32 个数据进行训练）\\n\\n185\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0515 - accuracy: 0.6711 - val_loss: 0.0295 - val_accuracy: 0.853 0 Epoch 2/8 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0260 - accuracy: 0.8587 - val_loss: 0.0218 - val_accuracy: 0.881 9 …… Epoch 8/8 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0162 - accuracy: 0.9020 - val_loss: 0.0150 - val_accuracy: 0.909 1 Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] - 2s 35us/sample - los s: 0.4165 - accuracy: 0.8858 - val_loss: 0.3117 - val_accuracy: 0.912 4 Epoch 2/8 60000/60000 [==============================] - 2s 33us/sample - los s: 0.3144 - accuracy: 0.9114 - val_loss: 0.2916 - val_accuracy: 0.918 7 …... Epoch 8/8 60000/60000 [==============================] - 2s 32us/sample - los s: 0.2713 - accuracy: 0.9244 - val_loss: 0.2736 - val_accuracy: 0.923 3\\n\\n代码 6-1：简单 MNIST 数据集分类模型-交叉熵（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'mean_squared_error\\' )\\n\\n186\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'softmax_cross_entro py\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 结果输出为：\\n\\nhistory1.history 和 history2.history 保存着 mode1 和 model2 训练过程中每个训练周\\n\\n期的训练集准确率和训练集 loss 以及验证集准确率和验证集 loss。例如通过：\\n\\nhistory1.history[\\'accuracy\\']可以获得 model1 的训练集准确率\\n\\nhistory1.history[\\'loss\\']可以获得 model1 的训练集 loss\\n\\nhistory1.history[\\'val_accuracy\\']可以获得 model1 的验证集准确率\\n\\nhistory1.history[\\'val_loss\\']可以获得 model1 的验证集 loss\\n\\n从输出结果的图中我们可以看出使用交叉熵代价函数来训练模型可以使得模型的收敛速\\n\\n度更快，更少的训练次数和更少的训练时间就可以使得模型得到更好的效果。所以在分类模\\n\\n型中我们通常都是使用交叉熵代价函数。\\n\\n187\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.2 过拟合（Over-Fitting）\\n\\n6.2.1 什么是过拟合\\n\\n拟合可以分为三种情况，欠拟合（Under-Fitting），正确拟合（Right-Fitting）以及过拟\\n\\n合（Over-Fitting）。过拟合在机器学习和深度学习中经常会出现，简单说来其实就是我们所构\\n\\n建的模型在训练集中表现非常好，但是在测试集中表现得不够好。\\n\\n图 6.9 表示的是回归问题中的欠拟合，正确拟合以及过拟合的情况。我们使用相同的训练\\n\\n集和不同的模型来做训练，第一幅图使用比较简单的模型，第二幅图使用合适的模型，第三幅\\n\\n图使用比较复杂的模型。\\n\\n图 6.9 回归中的三种拟合情况\\n\\n188\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在图 6.9 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n\\n第二幅图的拟合效果比较好，并且回归线比较平滑，模型属于正确拟合；第三幅图拟合的效\\n\\n果非常好，预测的回归线与真实的训练样本数据分布的误差几乎为 0。假如我们把同样的模\\n\\n型应用到测试集中来做测试，如图 6.10 所示。\\n\\n图 6.10 把回归模型应用于测试集\\n\\n图 6.10 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n\\n的表现就不是特别好。\\n\\n在分类的任务中也有类似的情况。图 6.11 表示的是分类问题中的欠拟合，正确拟合以及\\n\\n过拟合的情况。我们使用相同的训练集和不同的模型来做训练，第一幅图使用比较简单的模型，\\n\\n第二幅图使用合适的模型，第三幅图使用比较复杂的模型：\\n\\n189\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.11 分类中的三种拟合情况\\n\\n在图 6.11 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n\\n第二幅图的拟合效果比较好，并且分类边界比较平滑，模型属于正确拟合；第三幅图拟合的\\n\\n效果非常好，分类的误差几乎为 0。假如我们把同样的模型应用到测试集中来做测试，如图\\n\\n6.12 所示。\\n\\n图 6.12 把分类模型应用于测试集\\n\\n190\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.12 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n\\n的表现就不是特别好。\\n\\n模型的复杂度与模型误差的关系如图 6.13 所示。\\n\\n图 6.13 模型复杂度与模型误差的关系\\n\\n模型复杂度在深度学习中主要指的是网络的层数以及每层网络神经元的各种，网络的层\\n\\n数越多越复杂，神经元的个数越多越复杂。从图 6.13 中我们可以看到，训练集的误差是随着\\n\\n模型复杂度的提升而不断降低的，测试集的误差是随着模型复杂度的提升而先下降后上升。\\n\\n训练集误差和测试集误差的曲线左端欠拟合的状态，训练误差和测试误差都比较高；中间部\\n\\n分是正确拟合的状态，训练误差和测试误差都比较低；右边部分是过拟合的状态，巡逻误差\\n\\n比较低，测试误差比较高。\\n\\n6.2.2 抵抗过拟合的方法\\n\\n常见的抵抗过拟合的方法有：增大数据集，提前停止(Early-Stopping)，Dropout，正则\\n\\n化等，标签平滑(label Smoothing)等。\\n\\n这几种方法我们单独拿出来放在后面的小节中讲解。\\n\\n191\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.3 数据增强（Data Augmentation）\\n\\n数据增强就是增加数据量，数据对于机器学习或者深度学习来说非常重要，有时候拥有更\\n\\n多的数据胜过拥有一个好的模型。一般来说更多的数据参与训练，训练得到的模型就更好。如\\n\\n果数据太少，而我们构建的神经网络又太复杂的话就比较容易产生过拟合的现象。\\n\\n例如在图像领域，数据增加的手段经常被使用，我们可以通过对图片进行一些调整来生成\\n\\n更多图片，常用的手段如下：\\n\\n1. 旋转 | 反射变换(Rotation/reflection): 随机旋转图像一定角度; 改变图像内\\n\\n容的朝向。\\n\\n2. 翻转变换(flip): 沿着水平或者垂直方向翻转图像。\\n\\n3. 缩放变换(zoom): 按照一定的比例放大或者缩小图像。\\n\\n4. 平移变换(shift): 在图像平面上对图像以一定方式进行平移。\\n\\n5. 尺度变换(scale): 对图像按照指定的尺度因子, 进行放大或缩小。\\n\\n6. 对比度变换(contrast): 在图像的 HSV 颜色空间，改变饱和度 S 和 V 亮度分\\n\\n量，保持色调 H 不变. 对每个像素的 S 和 V 分量进行指数运算(指数因子在 0.25 到 4\\n\\n之间), 增加光照变化。\\n\\n7. 噪声扰动(noise): 对图像的每个像素 RGB 进行随机扰动, 常用的噪声模式是\\n\\n椒盐噪声和高斯噪声。\\n\\n8. 颜色变换(color): 对训练集图像的颜色进行一些有规律的调整。\\n\\n比如水平翻转，如图 6.14 所示。\\n\\n192\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.14 水平翻转\\n\\n比如旋转一定角度，然后再随机裁剪，如图 6.15 所示。\\n\\n图 6.15 旋转裁剪\\n\\n比如调整图像的颜色，如图 6.16 所示。\\n\\n图 6.16 颜色变换\\n\\n193\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 中有封装好的程序可以非常方便的帮助我们实现图像数据增强的功能，如代\\n\\n码 6-2 所示。\\n\\n代码 6-2：图像数据增强\\n\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load _img import numpy as np\\n\\ndatagen = ImageDataGenerator( rotation_range = 40, # 随机旋转度数 width_shift_range = 0.2, # 随机水平平移 height_shift_range = 0.2,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 30, # 随机错切变换 zoom_range = 0.2, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range = (0.7,1.3), # 亮度变化 fill_mode = \\'nearest\\', # 填充方式\\n\\n) # 载入图片 img = load_img(\\'image.jpg\\') # 把图片变成 array，此时数据是 3 维 # 3 维(height,width,channel) x = img_to_array(img) # 在第 0 个位置增加一个维度 # 我们需要把数据变成 4 维，然后再做数据增强 # 4 维(1,height,width,channel) x = np.expand_dims(x,0) # 生成 20 张图片 i = 0 # 生成的图片都保存在 temp 文件夹中，文件名前缀为 new_cat,图片格式为 jpeg for batch in datagen.flow(x, batch_size=1, save_to_dir=\\'temp\\', save_prefix=\\'new_cat\\', save _format=\\'jpeg\\'): i += 1 if i==20: break\\n\\n使用 1 张原始图片，程序运行后在 temp 文件夹中产生了 20 张差异较大的图片，如图\\n\\n6.17 所示。\\n\\n194\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.17 图像数据增强\\n\\n6.4 提前停止训练（Early-Stopping）\\n\\nEarly-Stopping 是一种提前结束训练的策略用来防止过拟合。\\n\\n在训练模型的时候，我们往往会设置一个比较大的迭代次数 n。一般的做法是记录到目前\\n\\n为止最好的测试集准确率 p，之后连续 m 个周期没有超过最佳测试集准确率 p 时，则可以认\\n\\n为 p 不再提高了，此时便可以提前停止迭代(Early-Stopping)。代码 6-3 是在代码 5-7 的基础\\n\\n上进行修改得到，加上了 Early-Stopping 的功能。\\n\\n代码 6-3：简单 MNIST 数据集分类模型- Early_Stoppping\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD from tensorflow.keras.callbacks import EarlyStopping # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000）\\n\\n195\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss=\\'mse\\'定义均方差代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 sgd = SGD(0.5) model.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# EarlyStopping 是 Callbacks 的一种，callbacks 用于指定在每个 epoch 或 batch 开始和结 束的时候进行哪种特定操作 # monitor=\\'val_accuracy\\',监控验证集准确率 # patience=5,连续 5 个周期没有超过最高的 val_accuracy 值，则提前停止训练 # verbose=1，停止训练时提示 early stopping early_stopping = EarlyStopping(monitor=\\'val_accuracy\\', patience=5, verbose=1)\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 100（把所有训练集数据训练一次称为训练一个周期） # 批次大小为 32（每次训练模型传入 32 个数据进行训练） # validation_data 设置验证集数据 # callbacks=[early_stopping]设置 early_stopping model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test,y_test), callbacks=[early_stopping])\\n\\n结果输出为： Train on 60000 samples, validate on 10000 samples\\n\\n196\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 1/100 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0267 - accuracy: 0.8420 - val_loss: 0.0167 - val_accuracy: 0.899 9 Epoch 2/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0164 - accuracy: 0.8993 - val_loss: 0.0145 - val_accuracy: 0.909 5 Epoch 3/100 …… Epoch 30/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0108 - accuracy: 0.9329 - val_loss: 0.0111 - val_accuracy: 0.929 3 Epoch 31/100 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0108 - accuracy: 0.9330 - val_loss: 0.0111 - val_accuracy: 0.929 9 Epoch 32/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9332 - val_loss: 0.0110 - val_accuracy: 0.929 5 Epoch 33/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.929 9 Epoch 34/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9344 - val_loss: 0.0110 - val_accuracy: 0.929 6 Epoch 35/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0106 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.928 6 Epoch 36/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0106 - accuracy: 0.9347 - val_loss: 0.0110 - val_accuracy: 0.929 9 Epoch 00036: early stopping\\n\\n虽然我们设置了让模型训练 100 个周期，不过在训练到第 31 周期时模型得到了一个 val\\n\\n_accuracy 为 0.9299。之后连续 5 个周期模型的 val_accuracy 都没有超过第 31 周期的 val_\\n\\n197\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\naccuracy 值。我们可以认为继续训练模型可能也不会得到更好的结果了，反而可能会出现过\\n\\n拟合的情况，所以就让模型提前停止训练了。\\n\\n6.5 Dropout\\n\\n6.5.1 Dropout 介绍\\n\\nDropout 也是一种用于抵抗过拟合的技术，它试图改变网络本身来对网络进行优化。我\\n\\n们先来了解一下它的工作机制，当我们训练一个普通的神经网络时，网络的结构可能如图 6.18\\n\\n所示。\\n\\n图 6.18 普通的神经网络[1]\\n\\nDropout 通常是在神经网络隐藏层的部分使用，使用的时候会临时关闭掉一部分的神经\\n\\n元，我们可以通过一个参数来控制神经元被关闭的概率，网络结构如图 6.19 所示。\\n\\n198\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.19 使用 Dropout 的神经网络[1]\\n\\n更详细的流程如下：\\n\\n1. 在模型训练阶段我们可以先给 Dropout 参数设置一个值，例如 0.4。意思是\\n\\n大约 60%的神经元是工作的，大约 40%神经元是不工作的。\\n\\n2. 给需要进行 Dropout 的神经网络层的每一个神经元生成一个 0-1 的随机数(一\\n\\n般是对隐藏层进行 Dropout)。如果神经元的随机数小于 0.6，那么该神经元就设置为\\n\\n工作状态的；如果神经元的随机数大于等于 0.6，那么该神经元就设置为不工作的，不\\n\\n工作状态的意思就是不参与计算和训练，可以当这个神经元不存在。\\n\\n3. 设置好一部分神经元工作一部分神经元不工作之后，我们会发现神经网络的输\\n\\n出值会发现变化，如图 6.18 中，如果隐藏层有一半不工作，那么网络输出值就会比原\\n\\n来的值要小，因为计算 WX+b 时，如果 W 矩阵中，有一部分的值变成 0，那么最后\\n\\n的计算结果肯定会变小。所以为了使用 Dropout 的网络层神经元信号的总和不会发生\\n\\n太大的变化，对于工作的神经元的输出信号还需要除以 0.4。\\n\\n4. 训练阶段重复 1-3 步骤，每一次都随机选择部分的神经元参与训练。\\n\\n5. 在测试阶段所有的神经元都参与计算。\\n\\n199\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nDropout 为什么会起作用呢？这个问题很难通过数学推导来证明。我们在介绍 ReLU 激\\n\\n活函数的时候有提到过神经网络的信号是冗余的，神经网络在做预测时并不需要隐藏层所有神\\n\\n经元都工作，只需要一部分隐藏层神经元工作即可。我们可以抽象地来理解 Dropout，当我们\\n\\n使用 Dropout 的时候，就有点像我们在训练很多不同的结构更简单的神经网络，最后测试阶\\n\\n段再综合所有的网络结构得到结果。或者另外一种理解方式是我们使用 Dropout 的时候减少\\n\\n了神经元之间的相互关联，同时强制网络使用更少的特征来做预测，可以增加模型的健壮性。\\n\\n除了这两种理解方式之外还可以有其他的很多理解方式，深度学习中很多技巧都是不能用\\n\\n数学推导得到同时又比较难理解的。但重要的是这些技巧在实际应用中可以帮助我们得到更好\\n\\n的结果。\\n\\nDropout 比较适合应用于只有少量数据但是需要训练复杂模型的场景，这类场景在图像\\n\\n领域比较常见，所以 Dropout 经常用于图像领域。\\n\\n6.5.2 Dropout 程序\\n\\n这部分我们将看到一个 Dropout 在 MNIST 数据集识别中的应用，如代码 6-4 所示。\\n\\n代码 6-4：MNIST 数据集分类模型-Dropout（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\\n\\n200\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义，model1 使用 Dropout # Dropout(0.4)表示隐藏层 40%神经元不工作 model1 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dropout(0.4), Dense(units=100,activation=\\'tanh\\'), Dropout(0.4), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# 在定义一个一模一样的模型用于对比测试，model2 不使用 Dropout # Dropout(0)表示隐藏层所有神经元都工作，相当于没有 Dropout model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dropout(0), Dense(units=100,activation=\\'tanh\\'), Dropout(0), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss=\\'categorical_crossentropy\\'定义交叉熵代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\']) model2.compile(optimizer=sgd, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test))\\n\\n201\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s 62us/sample - los s: 0.4170 - accuracy: 0.8737 - val_loss: 0.2087 - val_accuracy: 0.937 0 Epoch 2/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.2808 - accuracy: 0.9165 - val_loss: 0.1627 - val_accuracy: 0.949 8 …… Epoch 30/30 60000/60000 [==============================] - 3s 52us/sample - los s: 0.1006 - accuracy: 0.9689 - val_loss: 0.0824 - val_accuracy: 0.977 3 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.2552 - accuracy: 0.9234 - val_loss: 0.1505 - val_accuracy: 0.954 2 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.1163 - accuracy: 0.9642 - val_loss: 0.1073 - val_accuracy: 0.966 4 …… Epoch 30/30 60000/60000 [==============================] - 3s 57us/sample - los s: 4.9737e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9818\\n\\n代码 6-4：MNIST 数据集分类模型-Dropout（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'Dropout\\') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'FC\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\')\\n\\n202\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 结果输出为：\\n\\n模型训练结果前 1-30 周期是使用了 Dropout 的结果，后面的 1-30 周期是没有使用\\n\\nDropout 的结果。观察结果我们发现使用了 Dropout 之后训练集准确率和验证集的准确率相\\n\\n差并不是很大，所以能看出 Dropout 确实是可以起到抵抗过拟合的作用。我们还可以发现一\\n\\n个有趣的现象就是前 1-30 周期 model1 的验证集准确率还高于训练集的准确率，这是因为模\\n\\n型在计算训练集准确率的时候模型还在使用 Dropout，在计算验证集准确率的时候已经不使\\n\\n用 Dropout 了。使用 Dropout 的时候模型的准确率会稍微降低一些。同时我们也可以发现，\\n\\n不用 Dropout 的 model2 中测试集的准确率看起来比使用 Dropout 的 model1 要更高。\\n\\n事实上使用 Dropout 之后模型的收敛速度会变慢一些，所以需要更多的训练次数才能得\\n\\n到最好的结果。代码 6-3 中不用 Dropout 的 model2 验证集训练 30 个周期最高准确率大概\\n\\n是 98.2%左右；使用 Dropout 的 model1 如果训练足够多的周期，验证集最高准确率可以达\\n\\n到 98.8%左右。\\n\\n203\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.6 正则化（Regularization）\\n\\n6.6.1 正则化介绍\\n\\n正则化也叫作规范化，通常用得比较多的方式是 L1 正则化和 L2 正则化。L1 和 L2 正则\\n\\n化的使用实际上就是在普通的代价函数（例如均方差代价函数或交叉熵代价函数）后面加上一\\n\\n个正则项，例如加上了 L1 正则项的交叉熵为：\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n+\\n\\n𝜆 2𝑁\\n\\n?|𝑤| x\\n\\n加上 L2 正则项的交叉熵为：\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n+\\n\\n𝜆 2𝑁\\n\\n? 𝑤# x\\n\\n公式 6.21 可以写成：\\n\\n𝐸 = 𝐸< +\\n\\n𝜆 2𝑁\\n\\n? 𝑤# x\\n\\n其中E<是原始的代价函数，𝜆是正则项的系数，𝜆是一个大于 0 的数，𝜆的值越大那么正则\\n\\n项的影响就越大，𝜆的值越小正则项的影响也就越小，当𝜆为 0 时，相当于正则项不存在。N 表\\n\\n示样本个数。w 代表所有的权值参数和偏置值。\\n\\n我们训练模型的过程中实际上就是使用梯度下降法来最小化代价函数的过程，交叉熵代价\\n\\n函数中的 t 和 y 的值越接近，那么代价函数的值就越接近于 0。观察带有正则项的代价函数表\\n\\n达式我们可以知道，最小化代价函数的过程中不仅要使得 t 的值接近于 y，还要使得神经网络\\n\\n的权值参数 w 的值趋近于 0。因为不管是对于 L1 正则项\\n\\n´\\n\\n#P\\n\\n∑ |𝑤|x 还是对于 L2 正则项\\n\\n´\\n\\n#P\\n\\n正则项的值都是大于 0 的，所以最小化正则项的值，实际上就是让 w 的值接近于 0。\\n\\nL1 正则项和 L2 正则项的区别在于：\\n\\n204\\n\\n(6.20)\\n\\n(6.21)\\n\\n(6.22)\\n\\n∑ 𝑤#\\n\\nx ，\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nL1 正则项会使得神经网络中的很多权值参数变为 0，如果神经网络中很多的权值都是 0 的\\n\\n话那么可以认为网络的复杂度降低了，拟合能力也降低了，因此不容易出现过拟合的情况。\\n\\nL2 正则项会使得神经网络的权值衰减，权值参数变为接近于 0 的值，注意这里的接近于 0\\n\\n不是等于零，L2 正则化很少会使权值参数等于 0。L2 正则项之所以有效是因为权值参数 w 变\\n\\n得很小之后 WX+b 的计算也是会变成一个接近于 0 的值。我们知道在使用 sigmoid(x)函数或\\n\\n者 tanh(x)函数时，当 x 的取值在 0 附近时，函数的曲线是非常接近于一条直线的，如图 6.20\\n\\n所示。\\n\\n图 6.20 tanh 函数图像\\n\\n所以神经网络中增加了很多线性特征减少了很多非线性的特征，网络的复杂度降低了，因\\n\\n此不容易出现过拟合。\\n\\n6.6.2 正则化程序\\n\\n这部分我们将看到一个正则化在 MNIST 数据集识别中的应用，如代码 6-5 所示。\\n\\n代码 6-5：MNIST 手写数字识别-正则化（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD\\n\\n205\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import matplotlib.pyplot as plt import numpy as np # 使用 l1 或 l2 正则化 from tensorflow.keras.regularizers import l1,l2\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义，model1 使用 l2 正则化 # l2(0.0003)表示使用 l2 正则化，正则化系数为 0.0003 model1 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\',kernel_regularizer=l2(0.0003)), Dense(units=100,activation=\\'tanh\\',kernel_regularizer=l2(0.0003)), Dense(units=10,activation=\\'softmax\\',kernel_regularizer=l2(0.0003)) ])\\n\\n# 在定义一个一模一样的模型用于对比测试，model2 不使用正则化 model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dense(units=100,activation=\\'tanh\\'), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss=\\'categorical_crossentropy\\'定义交叉熵代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\']) model2.compile(optimizer=sgd, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型\\n\\n206\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s 69us/sample - los s: 0.4083 - accuracy: 0.9208 - val_loss: 0.2928 - val_accuracy: 0.952 5 Epoch 2/30 60000/60000 [==============================] - 4s 59us/sample - los s: 0.2626 - accuracy: 0.9601 - val_loss: 0.2285 - val_accuracy: 0.966 2 …… Epoch 30/30 60000/60000 [==============================] - 4s 60us/sample - los s: 0.1380 - accuracy: 0.9835 - val_loss: 0.1492 - val_accuracy: 0.979 6 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 56us/sample - los s: 0.2563 - accuracy: 0.9222 - val_loss: 0.1415 - val_accuracy: 0.956 8 Epoch 2/30 60000/60000 [==============================] - 3s 53us/sample - los s: 0.1178 - accuracy: 0.9634 - val_loss: 0.1115 - val_accuracy: 0.965 7 …… Epoch 30/30 60000/60000 [==============================] - 3s 49us/sample - los s: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9817\\n\\n代码 6-5：MNIST 手写数字识别-正则化（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图\\n\\n207\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com plt.plot(np.arange(epochs),history1.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'L2 Regularization\\') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'FC\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 结果输出为：\\n\\n前 1-30 周期是使用 l2 正则化的 model1 的结果，后 1-30 周期是不使用正则化的 mod\\n\\nel2 的结果。从结果上看，使用正则化后 model1 的训练集准确率和验证集准确率相差不\\n\\n大，说明正则化确实是可以起到抵抗过拟合的作用。但是使用正则化之后验证集准确率的结\\n\\n果并不是非常理想，说明正则化并不是适用于所有场景。在神经网络结构比较复杂，训练数\\n\\n据量比较少的时候，使用正则化效果会比较好。如果网络不算太复杂的话，任务比较简单的\\n\\n时候，使用正则化可能准确率反而会下降。对于 Dropout 来说也有类似的情况。所以 Drop\\n\\nout 和正则化需要根据实际使用情况的好坏来决定是否使用。\\n\\n208\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n209\\n\\n6.7 标签平滑（Label Smoothing）\\n\\n6.7.1 标签平滑(Label Smoothing)介绍\\n\\n标签平滑（label smoothing）也称为标签平滑正则化（label-smoothing regularization），\\n\\n简称 LSR。从名字就可以看出标签平滑也是一种正则化策略。\\n\\n我们在做分类模型的时候通常会把标签变成独热编码（ one-hot），但是 变 成 独 热编 码的\\n\\n标签在模型训练时会使得模型变得“极度自信”，容易产生过拟合。独热编码（one-hot）可能\\n\\n存在的问题我给大家举个例子大家就容易理解了，如图 6.21 所示是我写的一个数字。\\n\\n图 6.21 一个数字\\n\\n这个数字你能说它 100%就是 6 吗，不一定吧，它也有点像 2，说不定还是 1 或者 7 只不\\n\\n过手滑了。所以让模型非常自信的认为图中的数字就是 6，独热编码(0,0,0,0,0,0,1,0,0,0)，不\\n\\n一定是合适的。可能把它的标签改成 (0,0.02,0.2,0.01,0.01,0.01,0.7,0.03,0.01,0.01)会比较好\\n\\n一点。\\n\\n在 MNIST 数据集里面实际上确实有一些数字会写得比较奇怪，让人也很难分辨，其它数\\n\\n据集也会有类似的问题，所以让模型“过度自信”就不一定是好事了。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n标签平滑的处理方式很简单，给大家举一个具体的例子大家就知道了。我们需要设置一个\\n\\n平滑系数，比如 0.1，假设一共有 10 个种类。某个数据的真实标签为：\\n\\n(0,0,0,0,0,1,0,0,0,0)\\n\\n经过标签平滑处理以后的标签为：\\n\\n(0.01,0.01,0.01,0.01,0.01,0.91,0.01,0.01,0.01,0.01)\\n\\n也就类似于下面程序，label_smoothing 为平滑系数：\\n\\nnew_onehot_labels = onehot_labels * (1 - label_smoothing)\\n\\n+ label_smoothing / num_classes\\n\\n6.7.2 标签平滑（Label Smoothing）程序\\n\\n实现 MNIST 手写数字识别-标签平滑的代码如代码 6-6 所示。\\n\\n代码 6-6：MNIST 手写数字识别-标签平滑（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD from tensorflow.keras.losses import CategoricalCrossentropy import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义，model1 不用 label smoothing model1 = Sequential([ Flatten(input_shape=(28, 28)),\\n\\n210\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Dense(units=200,activation=\\'tanh\\'), Dense(units=100,activation=\\'tanh\\'), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# 在定义一个一模一样的模型用于对比测试，model2 使用 label smoothing model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dense(units=100,activation=\\'tanh\\'), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# model1 不用 label smoothing loss1 = CategoricalCrossentropy(label_smoothing=0) # model2 使用 label smoothing loss2 = CategoricalCrossentropy(label_smoothing=0.1)\\n\\n# sgd 定义随机梯度下降法优化器 # loss 定义交叉熵代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss=loss1, metrics=[\\'accuracy\\']) model2.compile(optimizer=sgd, loss=loss2, metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30\\n\\n211\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 4s 62us/sample - los s: 0.2526 - accuracy: 0.9235 - val_loss: 0.1460 - val_accuracy: 0.957 1 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.1139 - accuracy: 0.9659 - val_loss: 0.0915 - val_accuracy: 0.970 0 …… Epoch 30/30 60000/60000 [==============================] - 3s 50us/sample - los s: 4.9963e-04 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9816 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.7274 - accuracy: 0.9243 - val_loss: 0.6323 - val_accuracy: 0.957 2 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.6139 - accuracy: 0.9663 - val_loss: 0.6093 - val_accuracy: 0.965 4 …… Epoch 30/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.5127 - accuracy: 0.9996 - val_loss: 0.5527 - val_accuracy: 0.981 7\\n\\n代码 6-6：MNIST 手写数字识别-标签平滑（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'without LSR\\') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'LSR\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 结果输出为：\\n\\n212\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从结果看来使用标签平滑 label_smoothing(LSR)后结果稍微好一点点的，不过不太明显。\\n\\n其实标签平滑 label_smoothing 作为一个优化策略也并不是每次都能使结果更好，不过它有\\n\\n机会可以让结果更好，所以有时候也值得我们尝试用一下。\\n\\n6.8 优化器（Optimizer）\\n\\n目前在 tf.keras.optimizers 中有下面这些优化器可以使用：\\n\\nAdadelta\\n\\nAdagrad\\n\\nAdam\\n\\nAdamax\\n\\nFtrl\\n\\nNadam\\n\\nRMSprop\\n\\nSGD\\n\\n213\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n优化器的种类很多，在 Keras 中只包含了部分常用的优化器，不是全部。之前我们经常使\\n\\n用的优化器是随机梯度下降法（SGD），使用 SGD 算法来最小化代价函数。其实其他的一些优\\n\\n化器的基础也是梯度下降法，只不过分别做了一些不同的调整或优化。\\n\\n下面我们选几种常用的优化器来重点介绍。\\n\\n6.8.1 梯度下降法 SGD\\n\\n梯度下降法有三种常见的变形，BGD,SGD,MBGD。我们通常把梯度下降法称为随机梯度\\n\\n下降法 SGD，但是梯度下降法通常的用的是 MBGD 算法。\\n\\nBGD 是 Batch gradient descent，表示每次训练都采用整个训练集数据来优化模型。BGD\\n\\n的优点是每次训练都考虑所有的样本，所以模型优化的方向会比较正确；缺点是每次训练都需\\n\\n要计算大量的数据，所以模型训练的速度比较慢。\\n\\nSGD 是 Stochastic gradient descent，表示每次训练都选择训练集中的一个样本来优化\\n\\n模型。SGD 的优点是每次只计算一个样本，权值调整速度比较快；缺点是每次只考虑了一个\\n\\n样本，所以模型优化的方向很可能是错误的。\\n\\nMBGD 是 Mini-batch gradient descent，表示每次训练都选择训练集中一个批次的数\\n\\n据来优化模型，这里的一个批次常用的取值是 32，64 等，当然如果取其他的数值也可以。\\n\\nMBGD 相当于是结合了 BGD 和 SGD 两者的优点，采用一个小批次的数据量来训练模型，这\\n\\n样训练的速度比较快，同时模型优化的方向也比较正确。所以目前带有小批次的训练方法是最\\n\\n主流的训练方法。一般我们提到梯度下降法，或者随机梯度下降法 SGD 的时候，默认就是使\\n\\n用 MBGD 的方法。\\n\\n梯度下降法的公式为：\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n214\\n\\n(6.23)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n其中 t 表示第 t 时刻，𝜂表示学习率，𝛻x𝑓(𝑊ˆ(cid:127)\")表示 t-1 时刻对代价函数 f 求 W 的导数。\\n\\n6.8.2 Momentum\\n\\nMomentum 是模拟物理中动量的概念，积累之前的动量来替代真正的梯度。\\n\\nMomentum 的公式为：\\n\\n𝑉ˆ = 𝛾𝑉ˆ(cid:127)\" + 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝑉ˆ\\n\\n𝛾为动力项，通常设置为 0.9。当前权值的改变会受到上一次权值改变的影响，类似于小球\\n\\n向下滚动的时候带上了惯性。这样可以加快小球的向下的速度，同时可以抑制小球振荡。\\n\\n6.8.3 NAG(Nesterov Accelerated Gradient)\\n\\nNAG 的公式为：\\n\\n𝑉ˆ = 𝛾𝑉ˆ(cid:127)\" + 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\" − 𝛾𝑉ˆ(cid:127)\")\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝑉ˆ\\n\\n𝛾为动力项，通常设置为 0.9。𝑊ˆ(cid:127)\" − 𝛾𝑉ˆ(cid:127)\"用来近似代价函数下一步的值，则计算的梯度\\n\\n不是当前位置的梯度，而是下一个位置的梯度。NAG 相当于是一个预先知道正确方向的更聪\\n\\n明的小球。\\n\\nMomentum 和 NAG 都是为了使得梯度更新更加灵活，不过学习率的设置仍然是一个问\\n\\n题，下面介绍的几种优化器针对学习率的问题做出优化，具有自适应学习率的能力。\\n\\n6.8.4 Adagrad\\n\\nAdagrad 的公式为：\\n\\n215\\n\\n(6.24)\\n\\n(6.25)\\n\\n(6.26)\\n\\n(6.27)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐺ˆ = 𝐺ˆ(cid:127)\" + 𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" −\\n\\n𝜂\\n\\ng𝐺ˆ(cid:127)\" + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\nε的作用是避免分母为 0，取值一般是10(cid:127)(cid:201)。Adagrad 其实是对学习率进行了一个约束。\\n\\nAdagrad 主要的优势是人为设定一个学习率后，这个学习率可以自动调节。它的缺点在于，\\n\\n随着迭代次数的增多，学习率也会越来越低，最终会趋向于 0。\\n\\n6.8.5 Adadelta\\n\\nAdadelta 的公式为：\\n\\n𝐺ˆ = 𝛾𝐺ˆ(cid:127)\" + (1 − 𝛾)𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝐸ˆ = 𝛾𝐸ˆ(cid:127)\" + (1 − 𝛾)(∆𝑊ˆ)#\\n\\n∆𝑊ˆ = −\\n\\ng𝐸ˆ(cid:127)\" + 𝜀 g𝐺ˆ + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ)\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" + ∆𝑊ˆ(cid:127)\"\\n\\n𝛾通常取 0.9，Adadelta 算是对 Adagrad 的改进，此时 Adadelta 已经不用依赖于全局\\n\\n学习率了。\\n\\n6.8.6 RMRprop\\n\\nRMSprop 可以算作 Adadelta 的一个特例，RMSprop 的公式为：\\n\\n𝐺ˆ = 𝛾𝐺ˆ(cid:127)\" + (1 − 𝛾)𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" −\\n\\n𝜂\\n\\ng𝐺ˆ(cid:127)\" + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n𝛾通常取 0.9，RMSprop 依然依赖于全局学习率，RMSprop 也算是 Adagrad 的一种发\\n\\n展。\\n\\n216\\n\\n(6.28)\\n\\n(6.29)\\n\\n(6.29)\\n\\n(6.30)\\n\\n(6.31)\\n\\n(6.32)\\n\\n(6.33)\\n\\n(6.34)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.8.7 Adam\\n\\nAdam(Adaptive Moment Estimation)本质上是带有动量项的 RMSprop，Adam 的公\\n\\n式为：\\n\\n𝑚ˆ = 𝛽\"𝑚ˆ(cid:127)\" + (1 − 𝛽\")𝛻x𝑓(𝑊ˆ)\\n\\n𝑣ˆ = 𝛽#𝑣ˆ(cid:127)\" + (1 − 𝛽#)𝛻x𝑓(𝑊ˆ)#\\n\\n𝑚(cid:204) ˆ =\\n\\n𝑣˝ˆ =\\n\\n𝑚ˆ ˆ 1 − 𝛽\" 𝑣ˆ ˆ 1 − 𝛽#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂\\n\\n𝑚(cid:204) ˆ g\\t𝑣˝ˆ + 𝜀\\n\\n𝛽\"通常取 0.9, 𝛽#通常取 0.999。其中𝑚ˆ，𝑣ˆ分别是对梯度的一阶矩估计和二阶矩估计，\\n\\n可以看作对期望𝐸|𝛻𝑤𝑓(𝑊𝑡)|，𝐸˛𝛻𝑤𝑓(𝑊𝑡)2˛的估计；\\t𝑚(cid:204) ˆ，\\t𝑣˝ˆ是对𝑚ˆ，𝑣ˆ的校正，这样可以近\\n\\n似为对期望的无偏估计。Adam 大多数情况下效果都比较好，所以目前用得最多的优化器就是\\n\\nAdam。Adam 与其他一些优化器在训练 MNIST 数据集时的对比，如图 6.22 所示。\\n\\n217\\n\\n(6.35)\\n\\n(6.36)\\n\\n(6.37)\\n\\n(6.38)\\n\\n(6.39)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.22 Adam 与其他优化器对比[2]\\n\\n从图 6.22 中我们能看出来，在使用多层神经网络训练 MNIST 数据集时，Adam 的优化\\n\\n速度是最快的。\\n\\n6.8.8 优化器程序\\n\\n如代码 6-7 所示，这里给出一个使用 Adam 优化器的例子，如果想使用其他优化器也类\\n\\n似，调用 tensorflow.keras.optimizers 里面的优化器即可。\\n\\n代码 6-7：MNIST 数据集分类模型-优化器（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD,Adam import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 model1 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n# 定义 sgd 优化器，学习率 0.1 sgd = SGD(0.1) # 定义 Adam 优化器，学习率 0.001,Adam 优化器学习率通常较低\\n\\n218\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com adam = Adam(0.001) # loss=\\'mse\\'定义均方差代价函数 # metrics=[\\'accuracy\\']模型在训练的过程中同时计算准确率 # model1 用 Adam 优化器，model2 用 sgd 优化器 model1.compile(optimizer=adam, loss=\\'mse\\', metrics=[\\'accuracy\\']) model2.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 6（把所有训练集数据训练一次称为训练一个周期） epochs = 6 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 2s 36us/sample - los s: 0.0196 - accuracy: 0.8819 - val_loss: 0.0131 - val_accuracy: 0.917 5 Epoch 2/6 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0129 - accuracy: 0.9182 - val_loss: 0.0118 - val_accuracy: 0.924 1 …… Epoch 6/6 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0107 - accuracy: 0.9327 - val_loss: 0.0109 - val_accuracy: 0.931 6 Train on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 3s 47us/sample - los s: 0.0499 - accuracy: 0.6986 - val_loss: 0.0285 - val_accuracy: 0.852 1 Epoch 2/6\\n\\n219\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0257 - accuracy: 0.8583 - val_loss: 0.0216 - val_accuracy: 0.878 9 …… Epoch 6/6 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0173 - accuracy: 0.8953 - val_loss: 0.0160 - val_accuracy: 0.903 3\\n\\n代码 6-7：MNIST 数据集分类模型-优化器（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'Adam\\') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'SGD\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 结果输出为：\\n\\n从结果对比我们可以看到使用 Adam 优化器之后模型的收敛速度加快了很多，最后得到\\n\\n了更好的训练效果。\\n\\n这一章节我们学习了很多模型优化方法，使用这些模型优化方法把模型训练好以后我们还\\n\\n需要把模型保存下来。如何保存模型将是我们下一章节要介绍的内容。\\n\\n220\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.9 参考文献\\n\\n[1] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural\\n\\nnetworks from overfitting[J]. The journal of machine learning research, 2014, 15(1):\\n\\n1929-1958.\\n\\n[2] Kingma D P, Ba J. Adam: A method for stochastic optimization[J]. arXiv preprint\\n\\narXiv:1412.6980, 2014.\\n\\n221\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 7 章-Tensorflow 模型的保存和载入\\n\\n在 Tensorflow1.0 中模型的保存和载入通常有两种方式，一种是 Checkpoint 的方式，\\n\\n还有一种是 Protocol buffer 的方式，这两种方式都有各自的一些特点。\\n\\n——Checkpoint 保存的模型通常以“.ckpt”结尾，保存后会得到 4 个文件，如图 7.1\\n\\n中的 4 个文件.\\n\\n图 7.1 Tensorflow 模型文件\\n\\nCheckpoint 是一个文本文件，记录了训练过程中保存的模型的名称，首行记录的是最\\n\\n后（最近）一次保存的模型名称。\\n\\n.data 文件保存的是模型的变量值。\\n\\n.index 文件保存的是.data 文件中的数据跟.meta 文件中的结构之间的对应关系\\n\\n.meta 文件以“protocol buffer”格式保存了整个模型的结构图，模型上定义的操作等\\n\\n信息。\\n\\n——Protocol buffer 的方式是把模型的参数转换为常量后进行保存，同时还会保存模型\\n\\n的结构，保存的模型通常以“.pb”结尾，只会得到一个文件。\\n\\n由于在 Tensorflow2 中很多时候我们都是使用 Tensorflow.keras 来搭建和训练模型，所\\n\\n以模型的保存一般也是使用 Tensorflow. keras的方式。Tensorflow1.0 中所使用的\\n\\nCheckpoint 模型保存方式在 Tensorflow2 中有时也会用到。\\n\\n222\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.1 Keras 模型保存和载入\\n\\n7.1.1 Keras 保存模型\\n\\n使用 Keras 保存模型操作很简单，如模型为 model，可以使用：\\n\\nmodel.save(\\'path_to_my_model.h5\\')\\n\\n来保存模型，\\'path_to_my_model\\'为模型保存路径，\\'h5\\'为 HDF5 文件格式。使用\\n\\nmodel.save 来保存模型，可以把模型的结构，权值参数和优化器设置，代价函数设置，\\n\\nmetrics 设置全部保存下来。Keras 模型保存参考代码如代码 7-1 所示。\\n\\n代码 7-1：Keras 模型保存\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n# 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n\\n223\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 保存模型 model.save(\\'my_model/mnist.h5\\') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 35us/sample - los s: 0.0379 - accuracy: 0.7752 - val_loss: 0.0214 - val_accuracy: 0.880 8 …… Epoch 5/5 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0156 - accuracy: 0.9043 - val_loss: 0.0145 - val_accuracy: 0.909 8\\n\\n模型训练好之后会生成一个 h5 模型文件保存在\\'my_model/mnist.h5\\'。\\n\\n7.1.2 Keras 载入模型\\n\\n使用 Keras 载入模型操作也很简单，可以使用：\\n\\ntensorflow.keras.models.load_model(\\'path_to_my_model.h5\\')\\n\\n来载入模型，\\'path_to_my_model\\'为模型所在路径。Keras 模型载入参考代码如代码\\n\\n7-2 所示。\\n\\n代码 7-2：Keras 模型载入\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 载入模型 model = load_model(\\'my_model/mnist.h5\\')\\n\\n224\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 再训练 5 个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0150 - accuracy: 0.9073 - val_loss: 0.0141 - val_accuracy: 0.913 7 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0137 - accuracy: 0.9139 - val_loss: 0.0130 - val_accuracy: 0.918 0\\n\\n从输出结果可以看到模型是在已经训练了 5 个周期的基础上继续训练的。并且使用\\n\\nmodel.save 保存模型的时候，不仅保存的模型的结构和权值参数，还保存了模型的优化\\n\\n器，代价函数，metrics 这些设置。所以在载入模型之后，我们不需要设置优化器，代价函\\n\\n数和 metrics，就可以直接使用 fit 对模型进行训练。\\n\\n7.2 SavedModel 模型保存和载入\\n\\n7.2.1 SavedModel 保存模型\\n\\nSavedModel 是 Tensorflow 中一种模型格式，SavedModel 的优点是与语言无关，比\\n\\n如可以用时 python 训练模型，然后在 Jave 中非常方便的加载模型。SavedModel 中包含了\\n\\n计算图和网络的权值，一个 SavedModel 模型包含以下内容：\\n\\nassets/\\n\\nsaved_model.pb\\n\\nvariables/\\n\\n225\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nvariables.data-00000-of-00001\\n\\nvariables.index\\n\\n其中 saved_model.pb 包含计算图结构，variables 文件夹保存模型训练得到的权值。\\n\\nassets 文件夹一般是空的，可以添加一些可能需要的外部文件。\\n\\n假设程序中训练好的模型为 model，那么可以使用：\\n\\nmodel.save(\\'path_to_saved_model\\')\\n\\n来保存模型，注意这里的\\'path_to_saved_model\\'为模型保存的路径，保存后会得到一个\\n\\n文件夹，所以\\'path_to_saved_model\\'不需要加后缀。\\n\\nmodel.save 可以保存两种格式的模型。当我们使用 model.save 的时候，如果\\n\\n\\'path_to_saved_model\\'没有后缀就是保存为 SavedModel 格式；如果\\n\\n\\'path_to_saved_model.h5\\'有\\'h5\\'这个后缀就是保存为 Keras 的 HDF5 格式的模型。\\n\\nSavedModel 保存模型参考代码如代码 7-3 所示。\\n\\n代码 7-3：SavedModel 模型保存\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n226\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))\\n\\n# 保存模型为 SavedModel 格式 model.save(\\'path_to_saved_model\\') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 37us/sample - los s: 0.0373 - accuracy: 0.7806 - val_loss: 0.0217 - val_accuracy: 0.877 6 …… Epoch 5/5 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0156 - accuracy: 0.9038 - val_loss: 0.0145 - val_accuracy: 0.909 3\\n\\n7.2.2 SavedModel 载入模型\\n\\nSavedModel 模型的载入也很简单，也是使用：\\n\\ntensorflow.keras.models.load_model(\\'path_to_my_model\\')\\n\\n来载入就可以了。载入模型以后再次训练的程序基本上跟代码 7-2 一样，如代码 7-4 所\\n\\n示。\\n\\n代码 7-4：SavedModel 模型载入\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0\\n\\n227\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 载入 SavedModel 模型 model = load_model(\\'path_to_saved_model\\')\\n\\n# 再训练 5 个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 36us/sample - los s: 0.0151 - accuracy: 0.9065 - val_loss: 0.0140 - val_accuracy: 0.913 3 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0138 - accuracy: 0.9141 - val_loss: 0.0130 - val_accuracy: 0.917 2\\n\\n7.3 单独保存模型结构\\n\\n7.3.1 保存模型结构\\n\\n有些时候，可能我们只对模型的结构感兴趣，只想保存模型的结构，而不保存模型的权\\n\\n值，优化器和代价函数等内容。那么我们可以使用：\\n\\nconfig = model.get_config()\\n\\n来保存模型结构，模型的结构数据是一个 python 的字典，使用这个模型结构我们可以\\n\\n重建一个一摸一样的模型，然后重新训练这个模型。\\n\\n另外还有一个保存模型结构的方式是使用：\\n\\njson_config = model.to_json()\\n\\n228\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n来保存模型结构。这个方法是使用 JSON 格式来保存模型结构。单独保存模型结构参考\\n\\n代码如代码 7-5 所示。\\n\\n代码 7-5：保存模型结构（片段 1）\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout\\n\\n# 模型定义 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dropout(0.4), Dense(units=100,activation=\\'tanh\\'), Dropout(0.4), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# 保存模型结构 config = model.get_config() print(config) 结果输出为： {\\'name\\': \\'sequential\\', \\'layers\\': [{\\'class_name\\': \\'Flatten\\', \\'config \\': {\\'name\\': \\'flatten\\', \\'trainable\\': True, \\'batch_input_shape\\': (Non e, 28, 28), \\'dtype\\': \\'float32\\', \\'data_format\\': \\'channels_last\\'}}, {\\' class_name\\': \\'Dense\\', \\'config\\': {\\'name\\': \\'dense\\', \\'trainable\\': True, \\'dtype\\': \\'float32\\', \\'units\\': 200, \\'activation\\': \\'tanh\\', \\'use_bias\\': True, \\'kernel_initializer\\': {\\'class_name\\': \\'GlorotUniform\\', \\'config \\': {\\'seed\\': None}}, \\'bias_initializer\\': {\\'class_name\\': \\'Zeros\\', \\'con fig\\': {}}, \\'kernel_regularizer\\': None, \\'bias_regularizer\\': None, \\'ac tivity_regularizer\\': None, \\'kernel_constraint\\': None, \\'bias_constrai nt\\': None}}, {\\'class_name\\': \\'Dropout\\', \\'config\\': {\\'name\\': \\'dropout\\', \\'trainable\\': True, \\'dtype\\': \\'float32\\', \\'rate\\': 0.4, \\'noise_shape\\': N one, \\'seed\\': None}}, {\\'class_name\\': \\'Dense\\', \\'config\\': {\\'name\\': \\'den se_1\\', \\'trainable\\': True, \\'dtype\\': \\'float32\\', \\'units\\': 100, \\'activat ion\\': \\'tanh\\', \\'use_bias\\': True, \\'kernel_initializer\\': {\\'class_name\\': \\'GlorotUniform\\', \\'config\\': {\\'seed\\': None}}, \\'bias_initializer\\': {\\'c lass_name\\': \\'Zeros\\', \\'config\\': {}}, \\'kernel_regularizer\\': None, \\'bia s_regularizer\\': None, \\'activity_regularizer\\': None, \\'kernel_constrai nt\\': None, \\'bias_constraint\\': None}}, {\\'class_name\\': \\'Dropout\\', \\'con fig\\': {\\'name\\': \\'dropout_1\\', \\'trainable\\': True, \\'dtype\\': \\'float32\\', \\' rate\\': 0.4, \\'noise_shape\\': None, \\'seed\\': None}}, {\\'class_name\\': \\'Den\\n\\n229\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com se\\', \\'config\\': {\\'name\\': \\'dense_2\\', \\'trainable\\': True, \\'dtype\\': \\'floa t32\\', \\'units\\': 10, \\'activation\\': \\'softmax\\', \\'use_bias\\': True, \\'kerne l_initializer\\': {\\'class_name\\': \\'GlorotUniform\\', \\'config\\': {\\'seed\\': N one}}, \\'bias_initializer\\': {\\'class_name\\': \\'Zeros\\', \\'config\\': {}}, \\'k ernel_regularizer\\': None, \\'bias_regularizer\\': None, \\'activity_regula rizer\\': None, \\'kernel_constraint\\': None, \\'bias_constraint\\': None}}]}\\n\\n代码 7-5：保存模型结构（片段 2）\\n\\nimport json # 保存 json 模型结构文件 with open(\\'model.json\\',\\'w\\') as m: json.dump(json_config,m)\\n\\nconfig 的内容跟 json_config 的内容是差不多的，所以这里附上一个输出结果。保存\\n\\njson 模型结构文件以后，在本地会得到一个 model.json 文件。\\n\\n7.3.2 载入模型结构\\n\\n模型结构保存后，可以使用 model_from_json 方法再重新把模型的结构载入，模型结构\\n\\n载入的参考代码如代码 7-6 所示。\\n\\n代码 7-6：载入模型结构\\n\\nimport tensorflow as tf import json\\n\\n# 读入 json 文件 with open(\\'model.json\\') as m: json_config = json.load(m)\\n\\n# 载入 json 模型结构得到模型 model model = tf.keras.models.model_from_json(json_config)\\n\\n# summary 用于查看模型结构 model.summary() 结果输出为： Model: \"sequential\" _________________________________________________________ Layer (type) Output Shape Param # =========================================================\\n\\n230\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com flatten (Flatten) (None, 784) 0 _________________________________________________________ dense (Dense) (None, 200) 157000 _________________________________________________________ dropout (Dropout) (None, 200) 0 _________________________________________________________ dense_1 (Dense) (None, 100) 20100 _________________________________________________________ dropout_1 (Dropout) (None, 100) 0 _________________________________________________________ dense_2 (Dense) (None, 10) 1010 ========================================================= Total params: 178,110 Trainable params: 178,110 Non-trainable params: 0 _________________________________________________________\\n\\n我们可以看到模型打印出来的结构跟代码 7-5 中定义的结构是一样的。\\n\\nmodel.summary()可以很方便的打印出模型的结构，并可以看到网络每一层的输出 shape\\n\\n和需要训练的参数 Param，最后还会统计所有需要训练的参数个数。想了解模型结构的时候\\n\\nmodel.summary()可以多使用。\\n\\n7.4 单独保存模型参数\\n\\n7.4.1 保存模型参数\\n\\n有时候我们只对模型的权值参数感兴趣，对模型框架不感兴趣。这个时候我们可以只获取\\n\\n模型的权值参数，我们可以使用：\\n\\nweights = model.get_weights()\\n\\n来获取模型的权值参数，权值保存后会得到一个 list，list 中保存了每一层权值参数的具\\n\\n体数值。获取模型参数以后可以使用：\\n\\nmodel.set_weights(weights)\\n\\n231\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n来对模型进行权值进行重新设置。\\n\\n如果我们想保存模型的参数可以使用：\\n\\nmodel.save_weights(\\'path_to_my_model.h5\\')\\n\\n来保存模型参数。参考代码如代码 7-7 所示。\\n\\n代码 7-7：保存模型参数\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout import numpy as np\\n\\n# 模型定义 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dropout(0.4), Dense(units=100,activation=\\'tanh\\'), Dropout(0.4), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# 保存模型参数 model.save_weights(\\'my_model/model_weights\\')\\n\\n# 获取模型参数 weights = model.get_weights() # 把 list 转变成 array weights = np.array(weights)\\n\\n# 循环每一层权值 # enumerate 相当于循环计数器，记录当前循环次数 # weights 保存的数据可以对照 print 输出查看 for i,w in enumerate(weights): if i%2==0: print(\\'{}:w_shape:{}\\'.format(int(i/2+1),w.shape)) else: print(\\'{}:b_shape:{}\\'.format(int(i/2+0.5),w.shape)) 结果输出为： 1:w_shape:(784, 200) 1:b_shape:(200,) 2:w_shape:(200, 100)\\n\\n232\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 2:b_shape:(100,) 3:w_shape:(100, 10) 3:b_shape:(10,)\\n\\n7.4.2 载入模型参数\\n\\n模型的参数载入很简单，使用：\\n\\nmodel.load_weights(\\'path_to_my_model.h5\\')\\n\\n就可以载入参数。不过要注意，载入模型参数之前需要把模型先定义好，或者使用\\n\\nmodel_from_json 方法先载入模型。并且如果我们想进一步训练模型的参数的话，不仅要定\\n\\n义好模型结构，载入模型参数。还需要定义 compile 中的内容，包括优化器和代价函数等。\\n\\n因为 model.save()会保存 compile 中的内容，而 model.save_weights 只会保存模型的参\\n\\n数。所以 load_weights 以后还需要重新定义 compile 的内容，才能进一步训练模型。\\n\\n载入模型参数的参考代码如代码 7-8 所示。\\n\\n代码 7-8：载入模型参数\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropou # 载入模型参数前需要先把模型定义好 # 模型结构需要与参数匹配 # 或者可以使用 tf.keras.models.model_from_json 载入模型结构 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation=\\'tanh\\'), Dropout(0.4), Dense(units=100,activation=\\'tanh\\'), Dropout(0.4), Dense(units=10,activation=\\'softmax\\') ])\\n\\n# 载入模型参数 model.load_weights(\\'my_model/model_weights.h5\\')\\n\\n233\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.5 ModelCheckpoint 自动保存模型\\n\\n在第 6 章的抵抗过拟合方法中我们学习了 Early-Stopping，我们在学习 Early-Stopping\\n\\n的时候使用了：\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n复习一下，EarlyStopping 是 Callbacks 的一种，callbacks 用于指定在每个 epoch 或\\n\\nbatch 开始和结束的时候进行哪种特定操作。这个部分我们要学习的 ModelCheckpoint 也\\n\\n是 Callbacks 中的一种，用于自动保存模型。\\n\\n其中参数 monitor 可以设置{\\'val_accuracy\\',\\'val_loss\\',\\'accuracy\\',\\'loss\\'}，如果设置监测\\n\\n{\\'val_accuracy\\',\\'accuracy\\'}，那么模型准确率大于最大{\\'val_accuracy\\',\\'accuracy\\'}的时候就\\n\\n会保存模型；如果设置监测{\\'val_loss\\',\\'loss\\'}，那么模型 loss 小于最小{\\'val_loss\\',\\'loss\\'}的时\\n\\n候就会保存模型。ModelCheckpoint 的使用方法和说明参数代码如代码 7-9 所示。\\n\\n代码 7-9：ModelCheckpoint 自动保存模型\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ])\\n\\n234\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 定义优化器，代价函数 adam = Adam(0.001) model.compile(optimizer=adam, loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# 模型保存位置 output_model = \\'ModelCheckpoint/\\' # log 保存位置 output_log = \\'log/\\'\\n\\n# ModelCheckpoint 用于自动保存模型 # filepath 可以设置模型保存位置以及模型信息，epoch 表示训练周期数，val_accuracy 表示 验证集准确值 # monitor 可选{\\'val_accuracy\\',\\'val_loss\\',\\'accuracy\\',\\'loss\\'},一般\\'val_accuracy\\'用得比较多 # verbose=1 表示保存模型的时候打印信息 # save_best_only=True 表示只保存>best_val_accuracy 的模型 # CSVLogger 也是 callbacks，用于生成模型训练的 log callbacks = [ ModelCheckpoint(filepath=output_model+\\'{epoch:02d}-{val_accuracy:.4f}.h5\\', monitor=\\'val_accuracy\\', verbose=1, save_best_only=True), CSVLogger(output_log + \\'log.csv\\') ]\\n\\n# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=6, batch_size=32, validation_data=(x_test,y_test),\\n\\ncallbacks=callbacks)\\n\\n结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 59744/60000 [============================>.] - ETA: 0s - loss: 0.371 1 - accuracy: 0.8957 ETA: 0s - loss: 0.3733 - accuracy: 0.89 Epoch 00001: val_accuracy improved from -inf to 0.91850, saving model to ModelCheckpoint/01-0.9185.h5 60000/60000 [==============================] - 2s 39us/sample - los s: 0.3709 - accuracy: 0.8958 - val_loss: 0.2899 - val_accuracy: 0.918 5 Epoch 2/6\\n\\n235\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 59072/60000 [============================>.] - ETA: 0s - loss: 0.287 5 - accuracy: 0.9185 Epoch 00002: val_accuracy improved from 0.91850 to 0.92120, saving mo del to ModelCheckpoint/02-0.9212.h5 60000/60000 [==============================] - 2s 39us/sample - los s: 0.2874 - accuracy: 0.9185 - val_loss: 0.2792 - val_accuracy: 0.921 2 Epoch 3/6 59872/60000 [============================>.] - ETA: 0s - loss: 0.276 5 - accuracy: 0.9224 Epoch 00003: val_accuracy improved from 0.92120 to 0.92200, saving mo del to ModelCheckpoint/03-0.9220.h5 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2763 - accuracy: 0.9225 - val_loss: 0.2813 - val_accuracy: 0.922 0 Epoch 4/6 58496/60000 [============================>.] - ETA: 0s - loss: 0.270 2 - accuracy: 0.9243 Epoch 00004: val_accuracy improved from 0.92200 to 0.92630, saving mo del to ModelCheckpoint/04-0.9263.h5 60000/60000 [==============================] - 2s 38us/sample - los s: 0.2701 - accuracy: 0.9243 - val_loss: 0.2696 - val_accuracy: 0.926 3 Epoch 5/6 59936/60000 [============================>.] - ETA: 0s - loss: 0.265 8 - accuracy: 0.9261 Epoch 00005: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2658 - accuracy: 0.9261 - val_loss: 0.2766 - val_accuracy: 0.925 4 Epoch 6/6 58816/60000 [============================>.] - ETA: 0s - loss: 0.261 7 - accuracy: 0.9269 Epoch 00006: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2624 - accuracy: 0.9267 - val_loss: 0.2866 - val_accuracy: 0.921 7\\n\\n从输出结果我们就可以看出并不是每一个周期模型都会保存，只有 val_accuracy 大于之\\n\\n前最大的 val_accuracy，模型才会保存。程序训练 6 个周期以后用来保存模型的文件夹得到\\n\\n了 4 个模型，如图 7.2 所示。\\n\\n236\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 7.2 ModelCheckPoint 自动保存模型\\n\\n从模型的文件名我们就可以看出模型是训练了多少个周期得到的，并且还可以看出模型\\n\\n的 val_accuracy 准确率，只有得到越来越大的 val_accuracy 模型才会保存。训练第 5 第 6\\n\\n周期的时候，模型的 val_accuracy 没有超过第 4 个周期的 0.9263，所以第 5 第 6 周期的模\\n\\n型没有保存。\\n\\n训练结束之后我们还会得到一个 CSV 格式的 log 文件，log 文件中的内容如图 7.3 所\\n\\n示。\\n\\n图 7.3 模型训练 log 文件\\n\\n在 log 文件中包含了模型训练每个周期的训练集准确率，训练集 loss，验证集准确率，\\n\\n验证集 loss。\\n\\n237\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.6 Checkpoint 模型保存和载入\\n\\n7.6.1 Checkpoint 模型保存\\n\\n在 Tensorflow2 中我们也可以使用 Checkpoint 来保存和载入模型，用法跟\\n\\nTensorflow1 有些区别，具体使用方法可以参考下面的例子，如代码 7-10 所示。\\n\\n代码 7-10：Checkpoint 模型保存\\n\\nimport tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建 dataset 对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练 loss train_loss = tf.keras.metrics.Mean(name=\\'train_loss\\') # 训练准确率计算\\n\\n238\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'train_accuracy\\') # 测试 loss test_loss = tf.keras.metrics.Mean(name=\\'test_loss\\') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'test_accuracy\\') # 模型训练 @tf.function def train_step(data, label): with tf.GradientTape() as tape: # 传入数据预测结果 predictions = model(data) # 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)\\n\\n# 模型测试 @tf.function def test_step(data, label): # 传入数据预测结果 predictions = model(data) # 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)\\n\\n# 定义模型保存，保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # 用于管理模型 # ckpt 为需要保存的内容 # \\'tf2_ckpts\\'为模型保存位置 # max_to_keep 设置最多保留几个模型 manager = tf.train.CheckpointManager(ckpt, \\'tf2_ckpts\\', max_to_keep=3)\\n\\nEPOCHS = 5 # 训练 5 个周期 for epoch in range(EPOCHS):\\n\\n239\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 循环 60000/32=1875 次 for image, label in mnist_train: # 训练模型 train_step(image, label) # 循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 测试模型 test_step(test_image, test_label)\\n\\n# 打印结果 template = \\'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}\\' print (template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result()))\\n\\n# 保存模型 # checkpoint_number 设置模型编号\\n\\nmanager.save(checkpoint_number=epoch)\\n\\n结果输出为： Epoch 1, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0125, Test Accur acy: 0.917 Epoch 2, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0124, Test Accur acy: 0.918 Epoch 3, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0123, Test Accur acy: 0.918 Epoch 4, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur acy: 0.919 Epoch 5, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122, Test Accur acy: 0.92\\n\\n7.6.2 Checkpoint 模型载入\\n\\n实现 Checkpoint 模型载入的代码如代码 7-11 所示。\\n\\n代码 7-11：Checkpoint 模型载入\\n\\nimport tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n240\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建 dataset 对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation=\\'softmax\\') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练 loss train_loss = tf.keras.metrics.Mean(name=\\'train_loss\\') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'train_accuracy\\') # 测试 loss test_loss = tf.keras.metrics.Mean(name=\\'test_loss\\') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\\'test_accuracy\\') # 模型训练 @tf.function def train_step(data, label): with tf.GradientTape() as tape: # 传入数据预测结果 predictions = model(data) # 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables))\\n\\n241\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)\\n\\n# 模型测试 @tf.function def test_step(data, label): # 传入数据预测结果 predictions = model(data) # 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)\\n\\n# 定义 Checkpoint，用于保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # restore 载入 Checkpoint # latest_checkpoint 表示载入编号最大的 Checkpoint ckpt.restore(tf.train.latest_checkpoint(\\'tf2_ckpts/\\')) # 载入模型后继续训练 EPOCHS = 5 # 训练 5 个周期 for epoch in range(EPOCHS): # 循环 60000/32=1875 次 for image, label in mnist_train: # 训练模型 train_step(image, label) # 循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 测试模型 test_step(test_image, test_label) # 打印结果 template = \\'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}\\' print (template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(),\\n\\ntest_accuracy.result()))\\n\\n结果输出为： Epoch 1, Loss: 0.0105, Accuracy: 0.934, Test Loss: 0.0116, Test Accur acy: 0.925\\n\\n242\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 243 Epoch 2, Loss: 0.0105, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 3, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 4, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 5, Loss: 0.0103, Accuracy: 0.936, Test Loss: 0.0116, Test Accur acy: 0.925\\n\\n这一章节我们学习了 Tensorflow2 中 3 种模型保存的方式，使用 tf.keras 接口把模型保\\n\\n存为 h5 的文件，保存 SavedModel 格式的模型以及保存 Checkpoint 模型。\\n\\n学习完神经网络和 Tensorflow 的基础知识，下一章节我们将开始介绍深度学习算法。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 8 章-卷积神经网络 CNN\\n\\n计算机视觉是人工智能领域最热门的研究领域之一，并且是近几年发展最快的人工智能领\\n\\n域之一 。 10 年 前 的 人 们 一 定想 象不 到如 今的 计算 机视觉可 以做到如此优秀的水平 ，\\n\\nCV(Computer Vision)领域的快速发展主要得益于卷积神经网络的使用。\\n\\n8.1 计算机视觉介绍\\n\\n8.1.1 计算机视觉应用介绍\\n\\n如今计算机视觉的应用已经深入到我们生活中的方方面面，有着许多的实际应用。\\n\\n人脸识别：使用在高铁进站，酒店住宿，公司门禁等场景下，如图 8.1 所示。\\n\\n图 8.1 人脸识别\\n\\n图像检索：使用在搜索引擎的图片搜索中，以及电商网站的商品检索等，如图 8.2 所示。\\n\\n244\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.2 图像检索\\n\\n监控：使用在公共场所中用于检测行人车辆的流量以及可疑行为等，如图 8.3 所示。\\n\\n图 8.3 监控\\n\\n光学字符识别 OCR：证件识别，车牌识别，文档识别，银行卡识别，名片识别，身份证识\\n\\n别等，如图 8.4 所示。\\n\\n245\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.4 OCR\\n\\n自动驾驶：检测交通标志，路上行人和车辆等，如图 8.5 所示。\\n\\n图 8.5 自动驾驶\\n\\n8.1.2 计算机视觉技术介绍\\n\\n计算机视觉包含很多中技术，下面我们简单介绍 5 种计算机视觉的常用技术。\\n\\n1.图像分类：\\n\\n246\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图像分类就是图像识别，识别一张图片中的物体，然后给出类别判断。一般对一张图片我\\n\\n们可能会得到多个类别判断，我们可以根据类别的置信度（模型认为图片属于该类别的概率）\\n\\n从高到低进行排序，然后得到可能性最大的几个类别，如图 8.6 所示。\\n\\n图 8.6 图像分类\\n\\n2.目标检测\\n\\n有时候我们不仅要识别图片是属于什么类别，还需要把它们给框选出来，\\n\\n确定它们在图片中的位置和大小。如图 8.7 所示。\\n\\n图 8.7 目标检测[1]\\n\\n3.目标跟踪\\n\\n247\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n目标跟踪是指在特定场景跟踪某一个或多个特定感兴趣对象的过程，如图 8.6 所示。\\n\\n图 8.6 目标跟踪[2]\\n\\n4.语义分割\\n\\n语义分割可以将图像分为不同的语义可解释类别，例如我们可能会把图片中汽车的颜色\\n\\n都用蓝色的表示，所有行人用红色表示。与图像分类或目标检测相比，语义分割可以让我们\\n\\n对图像有更加细致的了解，如图 8.7 所示。\\n\\n图 8.7 语义分割[3]\\n\\n5.实例分割\\n\\n实例分割可以将不同类型的实例进行分类，比如用 4 种颜色来表示 4 辆不同的汽车，用\\n\\n8 种颜色表示 8 个不同的人，如图 8.8 所示。\\n\\n248\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.8 实例分割[4]\\n\\n8.2 卷积神经网简介\\n\\n卷积神经网络就是一种包含卷积计算的神经网络。卷积计算是一种计算方式，有一个卷积\\n\\n窗口（Convolution Window）在一个平面上滑动，每次滑动会进行一次卷积计算得到一个\\n\\n数值，卷积窗口滑动计算完成后会得到一个用于表示图像特征的特征图（Feature Map）。下\\n\\n面是一个忽略具体数值计算的卷积计算流程，具体的卷积数值计算在后面的内容再进行详细介\\n\\n绍：用一个 3×3 的卷积窗口对 4×4 的图片求卷积，卷积的移动步长为 1，最后得到 2×2 的特\\n\\n征图，如图 8.9 所示。\\n\\n249\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.9 卷积计算\\n\\n8.2.1 BP 神经网络存在的问题\\n\\n在前面的章节中我们使用了 BP 神经网络来处理 MNIST 手写数字识别的任务，并且得到\\n\\n了还不错的识别效果。有一个细节问题当时我们可能没有注意到，当时我们使用的手写数字图\\n\\n片是 28×28 的黑白图片，输入数据一共有 28×28×1 个数据，所以输入层只需要 784 个神经\\n\\n元。假如我们有一张 1000×1000 的彩色图片，那么输入层神经元就需要 1000×1000×3 个，\\n\\n我们使用带有一个隐藏层的神经网络，隐藏层神经元个数为 1000，那么输入层和隐藏层之间\\n\\n权值的个数就会有 30 亿个，这是一个非常巨大的数字。\\n\\n如此大量的权值会带来两个问题，一个问题是计算量巨大，要计算这么多权值就需要花费\\n\\n大量时间。第二个问题是要训练这么多权值就需要大量的训练样本来进行训练，防止模型过拟\\n\\n合。\\n\\n因此我们需要使用卷积神经网络解决计算机视觉任务中权值数量巨大的问题。\\n\\n250\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.2.2 局部感受野和权值共享\\n\\n卷积网络跟神经网络一样，也是受到了生物学的启发。 20 世纪 60 年代神经生理学家\\n\\nHubel 和 Wiesel 通过研究猫的视觉感受野（Receptive field of vision）提出的视觉神经系\\n\\n统的层级结构模型，从简单细胞到复杂细胞、超复杂细胞的层级信息处理结构。他们的研究成\\n\\n果在 1981 年获得诺贝尔生理学或医学奖。\\n\\n卷积神经网络的设计借鉴了 Hubel 和 Wiesel 的研究，在卷积网络中使用了局部感受野\\n\\n（Local Receptive Field）。卷积层中的神经元连接不是全连接的，而是后一层的每个神经元\\n\\n连接前一层的一部分神经元。如图 8.10 所示，左边为 BP 网络的全连接结构，右边为卷积网\\n\\n络的局部连接结构。\\n\\n图 8.10 全连接和局部连接\\n\\n图中一条连线就是一个权值，如果神经元不是全连接，那么权值就减少了很多。此外卷积\\n\\n神经网络还用到了权值共享（Weight Sharing）。这里的权值共享指的是同一卷积层中的同\\n\\n一个卷积窗口的权值是共享的。使用 3×3 的卷积窗口（也就是后一层的一个神经元连接前一\\n\\n层 3×3 的区域）对 1000×1000 的图片求卷积， 那么大家思考一下输入层和卷积层之间一共\\n\\n有多少个权值需要训练？\\n\\n251\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n现在公布答案，使用 3×3 的卷积窗口对 1000×1000 的图片求卷积，一共有 9 个权值加\\n\\n1 个偏置值需要训练。3×3 的卷积窗口就有 9 个权值，1 个卷积窗口还会有 1 个偏置值。卷\\n\\n积窗口在进行滑动计算的时候窗口内的 9 个权值是权值共享的，所以一共只有 9 个权值。同\\n\\n理，假设使用 5×5 的卷积窗口对 500×500 的图片求卷积，一共有 25 个权值加 1 个偏置值\\n\\n训练训练。卷积层的权值数量跟被卷积的图片大小无关，跟卷积步长也无关，跟卷积窗口的\\n\\n大小相关。\\n\\n8.3 卷积的具体计算\\n\\n下面我们来讲解一下卷积的具体计算流程。卷积窗口又称为 卷积核（ Convolution\\n\\nKernel），卷积之后生成的图称为特征图。卷积窗口/卷积核一般都是使用正方形的，比如 1×\\n\\n1，3×3，5×5 等，极少数特殊情况才会使用长方形。对一张图片求卷积实际上就是卷积核在\\n\\n图片上面滑动，并进行卷积计算。卷积计算很简单，就是卷积核与图片中对应位置的数值相乘\\n\\n然后再求和。我们可以通过下面的具体例子来理解，假设我们有一个 3×3 的卷积核，如图 8.11\\n\\n所示。\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n图 8.11 3×3 的卷积核\\n\\n然后我们使用该卷积核，对 4×4 的图片求卷积，图片如下，图 8.12 所示。\\n\\n252\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n1\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n1\\n\\n图 8.12 4×4 的图片\\n\\n3×3 的卷积核对 4×4 的图片求卷积，步长为 1，可以分为 4 个步骤，第一步，对左上方\\n\\n9 个数求卷积，如图 8.13 所示。\\n\\n图 8.13 卷积第一步\\n\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n\\n卷积第二步如图 8.14 所示。\\n\\n253\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.14 卷积第二步\\n\\n具体卷积计算为：1×1+0×1+1×0+0×1+1×1+0×1+1×0+0×1+1×1=3。\\n\\n卷积第三步如图 8.15 所示。\\n\\n图 8.15 卷积第三步\\n\\n具体卷积计算为：1×0+0×1+1×1+0×0+1×0+0×1+1×0+0×0+1×0=2。\\n\\n卷积第四步如图 8.16 所示。\\n\\n254\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.16 卷积第四步\\n\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n\\n卷积的符号一般用“*”表示，上述的卷积计算如图 8.17 所示。\\n\\n图 8.17 卷积计算\\n\\n8.4 卷积的步长\\n\\n卷积的步长指的是卷积每一次移动的步数，前面我们列举的例子中，卷积的步长为 1，卷\\n\\n积的步长理论上可以取任意正整数。图 8.18 中的例子是步长为 2 的卷积.\\n\\n255\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.18 步长为 2 的卷积\\n\\n下图 8.19 为步长为 3 的卷积计算.\\n\\n图 8.19 步长为 3 的卷积\\n\\n8.5 不同的卷积核\\n\\n使用不同的卷积核来对同一张图片求卷积会得到不同的结果，如图 8.20 和图 8.21 所示。\\n\\n256\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.20 使用不同卷积核求卷积（1）\\n\\n图 8.21 使用不同卷积核求卷积（2）\\n\\n所以在卷积神经网络中，我们通常会使用多个不同的卷积核来对同一图像求卷积，目的\\n\\n就是为了可以提取出图像中多种不同的特征。\\n\\n那么卷积核的取值要怎么取？如果是使用传统的机器学习思维，我们能想到的方法可能\\n\\n是人为设计大量不同的卷积核，然后使用大量图片来做测试，最后分析哪种卷积核提取出来\\n\\n的特征比较有效。\\n\\n那在深度学习里面，卷积核中的数值实际上就是卷积核的权值。所以说卷积核的取值在\\n\\n卷积神经网络训练最开始的阶段是随机初始化的，之后结合误差反向传播算法，逐渐训练得\\n\\n到最终的结果。训练好的卷积核就可以作为特征提取器，用于提取图像特征，然后传到网络\\n\\n后面的全连接层，用于分类回归等任务。\\n\\n在同一个卷积核中的权值是共享的，在不同的卷积核中的权值是不共享的。假设使用 6\\n\\n个 5×5 的卷积核对一幅图像求卷积，会产 6×5×5=150 个权值加 6 个偏置值，卷积后会得\\n\\n到 6 个不同的特征图，如图 8.22 所示。\\n\\n257\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.22 使用多个卷积核计算\\n\\n8.6 池化（Pooling）\\n\\n一个经典的卷积层包含 3 部分，卷积计算->非线性激活函数->池化（Pooling），如图 8.23\\n\\n所示。\\n\\n图 8.23 经典卷积层的 3 部分\\n\\n池化也有一个滑动窗口在图像中进行滑动计算，这一点跟卷积有点类似，不过池化层中\\n\\n没有需要训练的权值。\\n\\n我们通常会使用多个不同的卷积核来对图像求卷积，之后生成很多个不同的特征图，卷\\n\\n积网络中的权值参数仍然是很多的。池化的一个作用是可以做进一步的特征提取，减少权值\\n\\n参数的个数。\\n\\n258\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n池化的另一个作用是使得网络的输入具有平移不变形。平移不变形指的是当我们对输入\\n\\n进行少量平移时，经过池化后的数值并不会发生太大变化。这是一个非常有用的性质，因为\\n\\n我们通常关心的是某个特征是否在图像中出现，而不是关心这个特征具体出现的位置。例如\\n\\n我们要判断一张图片中是否有猫，我们并不关心猫是出现在图片上方，还是下方，还是左\\n\\n边，还是右边，我们只关心猫是否出现在图片中，如图 8.24 所示。\\n\\n图 8.24 平移不变形\\n\\n不过稍微要注意的是我们对输入进行少量平移时，经过池化后的数值并不会发生太大变化。\\n\\n如果对输入平移太多时，池化后的数值还是会发生较大变化的。\\n\\n池化也有池化窗口，对图像进行扫描计算，这一点跟卷积类似。池化通常可以分为三种方\\n\\n式， 最大池化（ Max-Pooling），平均池化（ Mean-Pooling）和随机池化（ Stochastic\\n\\nPooling）。最大池化指的是提取池化窗口区域内的最大值，平均池化指的是提取池化窗口区\\n\\n域内的平均值，随机池化指的是提取池化窗口区域内的随机值，其中最常用的是最大池化。常\\n\\n用的池化窗口大小为 2×2，步长为 2。\\n\\n池化窗口大小为 2×2，步长为 2 的最大池化计算如图 8.25 所示。\\n\\n259\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.25 最大池化\\n\\n池化窗口大小为 2×2，步长为 2 的平均池化计算如图 8.26 所示。\\n\\n图 8.26 平均池化\\n\\n随机池化就是从池化窗口中随机取一个值，一般用得比较少。\\n\\n8.7 Padding\\n\\n在卷积神经网络中我们通常会堆叠多个卷积层的结构，形成一个深度的卷积神经网络。\\n\\n堆叠多个卷积层结构会碰到一个问题，那就是每一次做卷积，得到的特征图就会比原来的图\\n\\n像要变小一些，这样特征的数量会不断减少。例如使用 3×3 的卷积核对 4×4 的图像求卷\\n\\n积，步长为 1，卷积后得到一个 2×2 的特征图，如图 8.27 所示。\\n\\n260\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.27 卷积后得到的特征图比原图像小\\n\\n另外在计算卷积的时候图像中间的数据会重复使用多次，而图像边缘的数据可能只会被用\\n\\n到一次。图 8.28 表示，使用 3×3 的卷积核对 4×4 的图像求卷积，步长为 1。\\n\\n图 8.28 边缘数据计算次数较少\\n\\n图 8.28 中四个角的四个数据只计算了一次，而图像中心的四个数据则计算了四次，这就\\n\\n表示卷积容易丢失掉图像的边缘特征（不过其实边缘位置的信息一般来说也没这么重要）。\\n\\n针对上述两个问题，我们可以使用 Padding 的方式来解决。卷积和池化操作都可以使用\\n\\nPadding，Padding 一般有两种方式，一种是 Valid Padding，还有一种是 Same Padding。\\n\\n261\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nValid Padding 其实就是不填充。不填充数据那么卷积后得到的特征图就会比原始图像要\\n\\n小一点，如图 8.29 所示。\\n\\n图 8.29 Valid Padding\\n\\nSame Padding 指的是通过填充数据（一般都是填充 0），使得卷积后的特征图的大小跟\\n\\n原始的图像大小相同，如图 8.30 所示。\\n\\n图 8.30 Same Padding\\n\\n262\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n上图中使用 3×3 的卷积核对 5×5 的图像进行求卷积的操作，步长为 1。给原图像外圈填\\n\\n充 1 圈 0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同，也是 5×5 的大小。\\n\\n同理如果使用 5×5 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 2\\n\\n圈 0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n\\n如果使用 7×7 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 3 圈 0\\n\\n之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n\\n这也是为什么卷积核经常使用单数×单数，因为我们可以通过填充 0 的方式得到与原始图\\n\\n像大小相同的特征图。\\n\\nSame Padding 还有另外一种理解方式，就是当步长不为 1 的时候，Same Padding 指\\n\\n的是可能会给平面外部补 0。下面举两个例子：\\n\\n例 1：假如有一个 28×28 的图像，用 2×2 步长为 2 的池化窗口对其进行池化的操作，使\\n\\n用 Same Padding 的方式，池化后得到 14×14 的特征图；使用 Valid Padding 的方式，池化\\n\\n后得到 14×14 的特征图。两种 Padding 方式得到的结果是相同的。\\n\\n例 2：假如有一个 2×3 的图像，用 2×2 步长为 2 的池化窗口对其进行池化的操作，使用\\n\\nSame Padding 的方式，池化后得到 1×2 的特征图；使用 Valid Padding 的方式，池化后得\\n\\n到 1×1 的特征图。Same Padding 给原图像补了 0，所以可以进行 2 次池化计算，而 Valid\\n\\nPadding 不会给图像补 0，所以只能进行 1 次池化计算。\\n\\n263\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.8 常见的卷积计算总结\\n\\n8.8.1 对 1 张图像进行卷积生成 1 张特征图\\n\\n对 1 张图像进行卷积生成 1 张特征图是最简单的一种卷积方式，前面我们已经进行了详\\n\\n解的举例计算，如图 8.31 所示。\\n\\n图 8.31 对 1 张图像进行卷积生成 1 张特征图\\n\\n假如我们只统计乘法的计算量，图中一种进行了 3×3×4 次乘法计算。总共有 9 个权值和\\n\\n1 个偏置值需要训练。\\n\\n8.8.2 对 1 张图像进行卷积生成多张特征图\\n\\n生成多张特征图需要使用多个不同的卷积核，使用多个不同的卷积核来求卷积。这里我们\\n\\n使用 3 个不同的 5×5 大小的卷积核对 28×28 的图像求卷积，使用 Same Padding 的方式，\\n\\n步长为 1，卷积计算后生成 3 个不同的特征图，如图 8.32 所示。\\n\\n264\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.32 对 1 张图像进行卷积生成多张特征图\\n\\n因为每个卷积核中的权值不同，所以使用 3 个不同的卷积核求卷积会得到 3 个不同的特\\n\\n征图。一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28\\n\\n×28×3=58800。总共有 5×5×3=75 个权值和 3 个偏置值需要训练。偏置值数量主要跟特征\\n\\n图数量相关，每个特征图有 1 个偏置值。\\n\\n8.8.3 对多张图像进行卷积生成 1 张特征图\\n\\n比如我们多 1 张彩色图片求卷积，彩色图片可以看成是 RGB 三原色的组合，所以可以看\\n\\n成是 3 张图像。这里我们对 3 张 28×28 的图像求卷积，卷积窗口大小为 5×5，使用 Same\\n\\nPadding 的方式，步长为 1，卷积计算后生成 1 张特征图，如图 8.33 所示。\\n\\n265\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.33 对多张图像进行卷积生成 1 张特征图\\n\\n对 3 张图像进行卷积的时候先分别对每张图像进行卷积，得到 3 个大小相同，数值不同\\n\\n的特征图。然后再对每个特征图对应位置的数值进行相加，最后得到 1 个特征图。\\n\\n一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28×\\n\\n28×3=58800。这里要注意，我们对不同图像进行卷积的时候，所使用的卷积核也是不同的，\\n\\n所以总共有 5×5×3=75 个权值和 1 个偏置值需要训练。\\n\\n这里我们把对多张图像进行卷积的多个不同的卷积核称为一个滤波器（Filter），一个滤波\\n\\n器可以产生一个特征图。在我们写程序搭建网络结构的时候，我们需要定义卷积层 Filter 的数\\n\\n量，实际上就是在定义卷积后生成的特征图的数量。\\n\\n8.8.4 对多张图像进行卷积生成多张特征图\\n\\n对多张图像进行卷积生成多张特征图相对来说最难理解同时也是最常见的情况。在卷积网\\n\\n络中，很多时候都需要对多张图像进行卷积然后生成多张特征图。这里我们使用 128 个滤波\\n\\n266\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n器对 64 张 28×28 的图像求卷积，使用 Same Padding 的方式，步长为 1，卷积计算后生成\\n\\n128 个不同的特征图。每个滤波器由 64 个不同的 5×5 卷积核组成，如图 8.34 所示。\\n\\n图 8.34 对多张图像进行卷积生成多张特征图\\n\\n下面我们来分析一下上面这个例子的计算量和权值数量。1 个滤波器对 64 张图像进行卷\\n\\n积，得到 1 张特征图。1 个滤波器中有 64 个不同的 5×5 卷积核。每个 5×5 卷积核对 1 张图\\n\\n像求卷积。\\n\\n1 个卷积核对 1 张图片求卷积的计算量是 5×5×28×28，所以 1 个滤波器 64 个卷积核的\\n\\n计算量是 5×5×28×28×64。一共有 128 个不同的滤波器，所以总的计算量是 5×5×28×28\\n\\n×64×128=160563200。\\n\\n每个卷积核有 5×5 个权值，1 个滤波器有 64 个卷积核有 5×5×64 个权值，128 个滤波\\n\\n器有 5×5×64×128=204800 个权值，加上 128 个偏置值。\\n\\n267\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.9 经典的卷积神经网络\\n\\n前面的内容中我们介绍了很多卷积神经网络相关的知识点，不过大家可能对一个完整的卷\\n\\n积神经网络的结构可能还不太了解。常见的卷积神经网络结构实际上是多个卷积层叠加起来之\\n\\n后再加上全连接层构成的。有些卷积网络有几十层或者几百层，实际上就是因为网络内部的卷\\n\\n积层的数量比较多，如图 8.35 所示是一个比较典型卷积网络结构。\\n\\n图 8.35 识别猫的卷积神经网络\\n\\n卷积神经网前面的部分进行卷积池化相当于是进行特征提取，后面部分进行全连接相当于\\n\\n是利用提取出来的图像特征进行分类。\\n\\n我们还可以把卷积神经网络应用于 MNIST 手写数字识别，如图 8.36 所示。\\n\\n图 8.36 卷积神经网络应用于手写数字识别\\n\\n268\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n为了能让大家看到一目了然的图，我也特地花了一些时间来研究如何画网络结构以及如何\\n\\n表示图中的计算流程，后面的内容中大家还会看到更多类似上图的网络结构图。图中的 s 表示\\n\\nstride，s1 代表卷积或池化的步长为 1，s2 代表卷积或池化的步长为 2，以此类推；conv 是\\n\\n卷积（convolution）的缩写；pool 表示最大池化（max pooling），fc 表示全连接（fully\\n\\nconnected）。\\n\\n图中原始的手写数字的图片是一张 28×28 的图片，并且是黑白的，所以图片的通道数是\\n\\n1，输入数据是 28×28×1 的数据，如果是彩色图片，图片的通道数就为 3。\\n\\n该网络结构是一个 4 层的卷积神经网络（计算神经网络层数的时候，有权值的才算是一\\n\\n层，比如池化层就不能单独算一层）。第 1 层为卷积层，使用 32 个 5×5 的卷积核对原始图片\\n\\n求卷积，步长为 1，Same Padding。因为是 Same Padding 并且步长为 1，所以卷积后的特\\n\\n征图大小跟原图片一样，可以得到 32 张 28×28 的特征图。池化的计算是在卷积层中进行的，\\n\\n使用 2×2，步长为 2 的池化窗口做池化计算，池化后得到 32 张 14×14 的特征图。特征图的\\n\\n长宽都变成了之前的 1/2。权值的数量为 5×5×32=800，偏置值数量为 32（1 个特征图会有\\n\\n1 个偏置值）。\\n\\n第 2 层也是卷积层，使用 64 个 5×5 的卷积核对 32 张 14×14 的特征图求卷积，步长为\\n\\n1，Same Padding。因为是 Same Padding 并且步长为 1，所以卷积后的特征图大小跟原图\\n\\n片一样，可以得到 64 张 14×14 的特征图。这里对 32 个特征图求卷积产生出 64 个特征图涉\\n\\n及到前面我们介绍的对多张图像进行卷积生成多张特征图。\\n\\n对多张特征图求卷积，相当于是同时对多张特征图进行特征提取。同一个特征图中权值是\\n\\n共享的，不同的特征图之间权值是不同的。对 32 张图像求卷积产生 1 个特征图，需要使用 32\\n\\n个不同的 5×5 的卷积核，那么就会有 5×5×32=800 个连接，800 个权值。\\n\\n269\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n所以在我们现在看到的这个例子中，第 2 个卷积层卷积窗口大小 5×5，对 32 张图像求卷\\n\\n积产生 64 个特征图，参数个数是 5×5×32×64=51200 个权值加上 64 个偏置（1 个特征图\\n\\n会有 1 个偏置值）。\\n\\n池化的计算是在卷积层中进行的，使用 2×2，步长为 2 的池化窗口做池化计算，池化后\\n\\n得到 64 张 7×7 的特征图。特征图的长宽都变成了之前的 1/2。\\n\\n第 3 层是全连接层，第 2 个池化层之后的 64×7×7 个神经元跟 1024 个神经元做全连接。\\n\\n第 4 层是输出层，输出 10 个预测值，对应 0-9 的 10 个数字。\\n\\n这个例子中卷积后产生的特征图的个数 32，64 是属于卷积神经网络中的超参数，需要我\\n\\n们自己调节和设置，也可以修改为其他值，一般设置为 2 的倍数。特征图数量越多说明卷积网\\n\\n络提取的特征数量越多，如果特征图数量设置得太少容易出现欠拟合，如果特征图数量设置得\\n\\n太多容易出现过拟合，所以需要设置为合适的数值。\\n\\n8.10 卷积神经网络应用于 MNIST 数据集分类\\n\\n实现卷积神经网络应用于 MNIST 数据集分类的代码如代码 8-1 所示。\\n\\n代码 8-1：卷积神经网络应用于 MNIST 数据集分类\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam # 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在 tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式 # 这 4 个维度是(数据数量，图片高度，图片宽度，图片通道数)\\n\\n270\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 所以这里把数据 reshape 变成 4 维数据，黑白图片的通道数是 1，彩色图片通道数是 3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 定义顺序模型 model = Sequential() # 第一个卷积层 # input_shape 输入数据 # filters 滤波器个数 32，生成 32 张特征图 # kernel_size 卷积窗口大小 5*5 # strides 步长 1 # padding padding 方式 same/valid # activation 激活函数 model.add(Convolution2D( input_shape = (28,28,1), filters = 32, kernel_size = 5, strides = 1, padding = \\'same\\', activation = \\'relu\\' )) # 第一个池化层 # pool_size 池化窗口大小 2*2 # strides 步长 2 # padding padding 方式 same/valid model.add(MaxPooling2D( pool_size = 2, strides = 2, padding = \\'same\\', )) # 第二个卷积层 # filters 滤波器个数 64，生成 64 张特征图 # kernel_size 卷积窗口大小 5*5 # strides 步长 1 # padding padding 方式 same/valid # activation 激活函数 model.add(Convolution2D(64,5,strides=1,padding=\\'same\\',activation=\\'relu\\')) # 第二个池化层 # pool_size 池化窗口大小 2*2 # strides 步长 2 # padding padding 方式 same/valid\\n\\n271\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model.add(MaxPooling2D(2,2,\\'same\\')) # 把第二个池化层的输出进行数据扁平化 # 相当于把(64,7,7,64)数据->(64,7*7*64) model.add(Flatten()) # 第一个全连接层 model.add(Dense(1024,activation = \\'relu\\')) # Dropout model.add(Dropout(0.5)) # 第二个全连接层 model.add(Dense(10,activation=\\'softmax\\')) # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\']) # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test, y_test)) # 保存模型 model.save(\\'mnist.h5\\') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 73s 1ms/sample - los s: 0.3466 - accuracy: 0.8985 - val_loss: 0.0953 - val_accuracy: 0.970 6 Epoch 2/10 60000/60000 [==============================] - 72s 1ms/sample - los s: 0.0986 - accuracy: 0.9706 - val_loss: 0.0601 - val_accuracy: 0.980 4 …… Epoch 9/10 60000/60000 [==============================] - 71s 1ms/sample - los s: 0.0251 - accuracy: 0.9920 - val_loss: 0.0263 - val_accuracy: 0.990 9 Epoch 10/10 60000/60000 [==============================] - 72s 1ms/sample - los s: 0.0222 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.992 8\\n\\n使用卷积神经网络之后，MNIST 手写数字识别的测试集准确率可以提升到 99%以上的高水\\n\\n准。\\n\\n272\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.11 识别自己写的数字图片\\n\\n在识别 MNIST 数据集的程序中，我们直接调用了 tensorflow 打包过的数据，而不是一\\n\\n张一张的图片，所以整个流程可能不够直观。我们可以使用 MNIST 数据集训练好的模型来识\\n\\n别自己写的数字图片，来检测一下模型的识别效果。\\n\\n我们可以自己找一张白纸，写一个数字，注意数字要写得粗一些，并且写在图片中间的位\\n\\n置，跟 MNIST 数据集中的数字类似，如图 8.37 所示。\\n\\n图 8.37 手写数字 6\\n\\n然后通过代码 8-2 来完成数字图片的识别.\\n\\n代码 8-2：识别自己写的数字图片（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model import matplotlib.pyplot as plt from PIL import Image import numpy as np\\n\\n# 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# 获取一张照片，并把它的 shape 变成二维（784->28×28）,用灰度图显示 plt.imshow(x_train[18],cmap=\\'gray\\') # 不显示坐标\\n\\n273\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com plt.axis(\\'off\\') plt.show() 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 2）\\n\\n# 载入我自己写的数字图片 img=Image.open(\\'6.jpg\\') # 显示图片 plt.imshow(img) # 不显示坐标 plt.axis(\\'off\\') plt.show() 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 3）\\n\\n# 把图片大小变成 28×28，并且把它从 3D 的彩色图变为 1D 的灰度图 image = np.array(img.resize((28,28)).convert(\\'L\\')) # 显示图片,用灰度图显示 plt.imshow(image,cmap=\\'gray\\') # 不显示坐标 plt.axis(\\'off\\') plt.show()\\n\\n274\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 4）\\n\\n# 观察发现我自己写的数字是白底黑字，MNIST 数据集的图片是黑底白字 # 所以我们需要先把图片从白底黑字变成黑底白字，就是 255-image # MNIST 数据集的数值都是 0-1 之间的，所以我们还需要/255.0 对数值进行归一化 image = (255-image)/255.0 # 显示图片，用灰度图显示 plt.imshow(image,cmap=\\'gray\\') # 不显示坐标 plt.axis(\\'off\\') plt.show() 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 5）\\n\\n# 把数据处理变成 4 维数据 image = image.reshape((1,28,28,1)) # 载入训练好的模型 model = load_model(\\'mnist.h5\\') # predict_classes 对数据进行预测并得到它的类别 prediction = model.predict_classes(image) print(prediction) 结果输出为：\\n\\n275\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com [6]\\n\\n8.12 CIFAR-10 数据集分类\\n\\nCIFAR-10 数据集是深度学习领域比较常用的一个图片数据集，很多模型都会使用 CIFAR-\\n\\n10 数据集来检验模型的效果。CIFAR-10 数据集一共有 10 个分类，每个分类的图片都是 32×\\n\\n32 的彩色图片，每个分类都有 6000 张图片，一共个 60000 张图片。其中 50000 张图片是训\\n\\n练集，10000 张图片是测试集。如图 8.38 所示。\\n\\n图 8.38 CIFAR-10\\n\\n另外还有一个数据集叫 CIFAR-100，顾名思义就是有 100 个种类，每个种类有 600 张图\\n\\n片，一共 60000 张。其中 50000 张为训练集，10000 张为测试集。CIFAR-10 数据集比较\\n\\n用得更多一些，CIFAR-10 数据集分类代码如 8-3 所示。\\n\\n代码 8-3：CIFAR-10 数据集分类（片段 1）\\n\\nimport numpy as np\\n\\n276\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data()\\n\\n# 显示 1 张图片 # 第 3 张图片 n = 3 # 一共 10 个种类 target_name = [\\'airplane\\',\\'automobile\\',\\'bird\\',\\'cat\\',\\'deer\\',\\'dog\\',\\'frog\\',\\'horse\\',\\'ship\\',\\'truck\\'] # 显示图片 plt.imshow(x_train[n]) plt.axis(\\'off\\') # 根据标签获得种类名称 plt.title(target_name[y_train[n][0]]) plt.show() 结果输出为：\\n\\n代码 8-3：CIFAR-10 数据集分类（片段 2）\\n\\n# 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 转 one hot 格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10)\\n\\n277\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 定义卷积网络 model = Sequential() model.add(Convolution2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, pad ding=\\'same\\', activation = \\'relu\\')) model.add(Convolution2D(filters=32, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.2)) model.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.3)) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.4)) model.add(Flatten()) model.add(Dense(10,activation = \\'softmax\\'))\\n\\n# 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\']) # 训练模型 model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuf fle=True) 结果输出为： Train on 50000 samples, validate on 10000 samples Epoch 1/100 50000/50000 [==============================] - 9s 181us/sample - los s: 1.9268 - acc: 0.2873 - val_loss: 1.6186 - val_acc: 0.4077 Epoch 2/100 50000/50000 [==============================] - 6s 127us/sample - los s: 1.5641 - acc: 0.4284 - val_loss: 1.4547 - val_acc: 0.4748 Epoch 3/100 50000/50000 [==============================] - 6s 126us/sample - los s: 1.4103 - acc: 0.4897 - val_loss: 1.2902 - val_acc: 0.5436 …… Epoch 98/100\\n\\n278\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2807 - acc: 0.8987 - val_loss: 0.5496 - val_acc: 0.8293 Epoch 99/100 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2797 - acc: 0.8995 - val_loss: 0.5561 - val_acc: 0.8303 Epoch 100/100 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2822 - acc: 0.8979 - val_loss: 0.5498 - val_acc: 0.8278\\n\\n训练 100 个周期，最后得到了 83%左右的测试集准确率。\\n\\n卷积神经网络是如今深度学习中最常用的算法之一，而另一种非常常用的算法——序列模\\n\\n型将是我们下一章要介绍的内容。\\n\\n8.13 参考文献\\n\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\n\\narXiv:1804.02767, 2018.\\n\\n[2] Nam H, Han B. Learning multi-domain convolutional neural networks for visual\\n\\ntracking[C]//Proceedings of the IEEE conference on computer vision and pattern\\n\\nrecognition. 2016: 4293-4302.\\n\\n[3] Badrinarayanan V, Kendall A, Cipolla R. Segnet: A deep convolutional encoder-\\n\\ndecoder architecture for image segmentation[J]. IEEE transactions on pattern analysis\\n\\nand machine intelligence, 2017, 39(12): 2481-2495.\\n\\n[4] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\n\\ninternational conference on computer vision. 2017: 2961-2969.\\n\\n279\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 9 章-序列模型\\n\\n1986 年 Rumelhart 等人提出循环神经网络（Recurrent Neural Network），简称\\n\\nRNN。RNN 跟我们之前学习过的神经网络都不太一样，它是一种序列模型。比如卷积网络\\n\\n是专门用来处理网格化数据（例如图像数据）的神经网络，RNN 是专门用来处理序列数据的\\n\\n神经网络。所谓的序列数据指的是跟序列相关的数据，比如一段语音，一首歌曲，一段文\\n\\n字，一段录像等。\\n\\n9.1 序列模型应用\\n\\n我们生活中的很多数据都是序列数据，因此序列模型可以应用于我们生活中的很多方\\n\\n面，例如：\\n\\n语音识别：把语音转换成为文字，如图 9.1 所示。\\n\\n图 9.1 语音识别\\n\\n文本分类：把文章，邮件或用户评论等文本数据做分类，如图 9.2 所示。\\n\\n280\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.2 文本分类\\n\\n机器翻译：如把中文翻译成英文，如图 9.3 所示。\\n\\n图 9.3 机器翻译\\n\\n视频识别：通过一段视频分析视频中发生的事件，如图 9.4 所示。\\n\\n图 9.4 视频识别\\n\\n分词标注：给一段文字做分词标注，标注每个字对应的标号。假如使用 4-tag(BMES)标注\\n\\n标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S 表示单字词。可\\n\\n以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n281\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.2 循环神经网络 RNN\\n\\n9.2.1 循环神经网络介绍\\n\\n循环神经网络 RNN 的基本结构是 BP 网络的结构，也是有输入层，隐藏层和输出层。只\\n\\n不过在 RNN 中隐藏层的输出不仅可以传到输出层，并且还可以传给下一个时刻的隐藏层，如\\n\\n图 9.5 所示。\\n\\n图 9.5 RNN 结构\\n\\n图 9.5 中 RNN 的结构可以展开为右边的结构，其中 x 为输入信号，𝑥ˆ(cid:127)\"为 t-1 时刻的输\\n\\n入信号，𝑥ˆ为 t 时刻的输入信号，𝑥ˆ(cid:151)\"为 t+1 时刻的输入信号。ℎˆ(cid:127)\"为 t-1 时刻的隐藏层信号，\\n\\nℎˆ为 t 时刻的隐藏层信号，ℎˆ(cid:151)\"为 t+1 时刻的隐藏层信号。𝑦ˆ(cid:127)\"为 t-1 时刻的输出层信号，𝑦ˆ\\n\\n为 t 时刻的输出层信号，𝑦ˆ(cid:151)\"为 t+1 时刻的输出层信号。W，U，V 为网络的权值矩阵。h 是\\n\\n隐藏(hidden)的首字母。\\n\\n假如图 9.5 是一个训练好的词性分析模型，有一个句子是“我爱你”，那么先把句子做分\\n\\n词得到“我”，“爱”，“你”三个词，然后依次把这三个词输入到网络中。那么𝑥ˆ(cid:127)\"为“我”\\n\\n所表示的信号，𝑥ˆ为“爱”所表示的信号，𝑥ˆ(cid:151)\"为“你”所表示的信号。而𝑦ˆ(cid:127)\"输出结果是主\\n\\n282\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n语，𝑦ˆ输出结果是谓语，𝑦ˆ(cid:151)\"输出结果是宾语，分别得到“我”，“爱”，“你”这三个词的\\n\\n词性。\\n\\n从结构上可以观察到 RNN 最大的特点是之前序列输入的信息会对模型之后的输出结果造\\n\\n成影响。\\n\\n9.2.2 Elman network 和 Jordan network\\n\\n循环神经网络 RNN 有两种常见的模型，一种是 Elman network 另一种是 Jordan\\n\\nnetwork。Elman network 和 Jordan network 也被称为\\n\\nSimple Recurrent Networks (SRN)或 SimpleRNN，即简单的循环神经网络。\\n\\n这两种模型的网络结构是一样的，都如图 9.5，只不过它们的计算公式有一点不同。\\n\\nElman network 的公式为：\\n\\nℎˆ = 𝜎(cid:150)(𝑊𝑥ˆ + 𝑈ℎˆ(cid:127)\" + 𝑏(cid:150))\\n\\n𝑦ˆ = 𝜎—(cid:142)𝑉ℎˆ + 𝑏—(cid:143)\\n\\nJordan network 的公式为：\\n\\nℎˆ = 𝜎(cid:150)(𝑊𝑥ˆ + 𝑈𝑦ˆ(cid:127)\" + 𝑏(cid:150))\\n\\n𝑦ˆ = 𝜎—(cid:142)𝑉ℎˆ + 𝑏—(cid:143)\\n\\n其中𝑥ˆ为 t 时刻的输入信号，ℎˆ为 t 时刻隐藏层的输出信号，𝑦ˆ为 t 时刻输出层的输出信\\n\\n号。W，U，V 对应图 9.5 中的权值矩阵，b 为偏置值。𝜎(cid:150)和𝜎—为激活函数，激活函数可以自\\n\\n行选择。\\n\\n从上面 Elman network 和 Jordan network 的公式对比中可以看出，Elman network\\n\\n的隐层ℎˆ接收的是上时刻的隐层ℎˆ(cid:127)\"的信号；而 Jordan network 的隐层ℎˆ接收的是上时刻的\\n\\n输出层𝑦ˆ(cid:127)\"的信号。一般 Elman network 的形式会更常用一些。\\n\\n283\\n\\n(9.1)\\n\\n(9.2)\\n\\n(9.3)\\n\\n(9.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.3 RNN 的不同架构\\n\\n为了处理不同输入输出组合的各类任务，RNN 可以分为以下几种不同的架构。\\n\\n9.3.1 一对一架构\\n\\n一对一架构如图 9.6 所示。\\n\\n图 9.6 RNN 一对一架构\\n\\n其实就是普通的神经网络，输入序列长度为 1，输出序列长度也是 1。注意这里的𝑥\"不是\\n\\n一个数值的意思，而是第一个序列输入的意思，𝑥\"可以是多个数值。比如𝑥\"输入 MNIST 数据\\n\\n集图片的数据，一张图片有 784 个像素，那么这里的𝑥\"就有 784 个值。把𝑥\"的数据输入，然\\n\\n后𝑦\"得到图片数据的预测结果。\\n\\n9.3.2 多对一架构\\n\\n多对一架构如图 9.7 所示。\\n\\n284\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.7 RNN 多对一架构\\n\\n模型有多次输入，我们只关心序列输出的最后一个值。比如可以用于情感分类，给模型\\n\\n输入一个句子或一篇文章，一个句子或一篇文章包含很多个词，每个词看成是一个输入信\\n\\n号，那么一个序列被分为多次输入。最后模型的预测结果可以是一个句子或一篇文章的情感\\n\\n分类，比如说是正面的情感还是负面的情感，两个类别，那么模型的最后一个序列的输出可\\n\\n以看成是预测结果。同样的道理，如果做文本分类也是可以用多对一架构。\\n\\n这里要注意的是，多对一架构并不是说模型只有最后一个序列才有输出值。其实每次给\\n\\n模型输入一个词的信号，模型都会输出一个结果。只不过如果我们需要分析一个句子或者一\\n\\n篇文章的情感，那么我们需要把整个句子或整篇文章的词的数据都输入到模型进行计算之\\n\\n后，再获得模型最终的一个输出结果，模型最终的这个输出结果会更准确。而前面得到的模\\n\\n型输出结果可能就没这么准确。\\n\\n9.3.3 多对多架构\\n\\n多对多架构如图 9.8 所示。\\n\\n285\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.8 RNN 多对多架构\\n\\n序列有多次输入和多次输出。可以应用在 Tagging（标注），比如说词性标注，标注句\\n\\n子中的每个词分别是什么词性。输入一个信号，然后就输出这个信号的预测结果。\\n\\n9.3.4 一对多架构\\n\\n一对多架构如图 9.9 所示。\\n\\n图 9.9 RNN 一对多架构\\n\\n一对多模型是只有一个输入信号，就可以得到很多个输出结果。第一个序列的输出结果\\n\\n会作为输入传给第二个序列，第二个序列的输出会作为输入传给第三个序列，以此类推。比\\n\\n如可以应用于音乐生成和文章生存。给出第一个音符或字，就可以生成一段旋律或者一句\\n\\n话。\\n\\n286\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.3.5 Seq2Seq 架构\\n\\nSeq2Seq 的全称是 Sequence to Sequence，也就是序列到序列模型。seq2seq 也算\\n\\n是多对多架构，如图 9.10 所示。\\n\\n图 9.10 RNN 的 seq2seq 架构\\n\\nseq2seq 由两部分组成，左边部分为编码器（encoder），右边部分为解码器\\n\\n（decoder）。Encoder 的作用是负责将输入序列压缩成指定长度的向量，相当于是做特征\\n\\n提取。然后把这个向量传给 decoder 进行计算得到多个序列输出。\\n\\n经典的多对多 RNN 架构的输入和输出是等长的，也就是有 10 个输入就必须有 10 个输\\n\\n出结果，它的应用场景也比较有限。而 seq2seq 模型的输入和输出可以是不等长的，它实现\\n\\n了一个序列到另一个序列的转换。比如可以用来做机器翻译，encoder 输入一段中文，\\n\\ndecoder 可以输出一段英文，中文句子的词汇数跟英文句子的词汇数不一定要相同。比如还\\n\\n可以用来做聊天机器人，encoder 输入一句话，decoder 回复另一句话，这两句话的长度也\\n\\n不一定相同。\\n\\n287\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.4 传统 RNN 的缺点\\n\\n我们知道 RNN 可以根据历史信息来进行预测，假如我们训练了一个可以进行文本填空\\n\\n的 RNN 模型，下面要进行文本填空：\\n\\n题目 1:有一朵云飘在（）。\\n\\n对于题目 1 来说正确的答案应该是“天上”，或者“空中“，或者”天空中“等。经过\\n\\n大量训练之后的 RNN 可以根据前面文本的信息填出正确的答案。\\n\\n题目 2:我从小生长在美国，父亲是英国人，母亲是美国人。我最喜欢喝牛奶，吃牛肉，\\n\\n长大想当科学家。我的兴趣爱好是看电影，看书，踢足球还有周末跟爷爷去钓鱼。我可以说\\n\\n一口流利的（）。\\n\\n对于题目 2 来说因为是从小生长在美国，所以应该是可以说一口流利的“英语“。但是\\n\\n传统的 RNN 不一定能预测出正确的结果，原因是句子的长度太长了。\\n\\n为什么句子的长度太长会对 RNN 的预测产生影响呢？这要考虑到 RNN 的基本模型结\\n\\n构，传统的 RNN 基本模型结构是 BP 网络。我们在学习 BP 网络的时候有特别讨论过关于梯\\n\\n度消失的问题。就是模型计算得到的误差信号从输出层不断向前传播，以此来调整前面层的\\n\\n权值，使得模型的性能越来越好。但是由于误差信号在每次传递的时候都需要乘以激活函数\\n\\n的导数，当激活函数的导数取值范围是 0-1 之间时，会使得误差信号越传越小，最终趋近于\\n\\n0。\\n\\n这个梯度消失的问题在 RNN 中同样存在，RNN 的序列结构展开之后也可以看成是有很\\n\\n多的“层”，在计算误差信号的时候同样会出现梯度消失的问题，使得网络输出的学习信号\\n\\n只能影响到它前面的几层，对它前面的几层的权值进行调节。所以反过来考虑，一个信号的\\n\\n输入，只能影响到它后面的几个序列的输出，并且影响力会越来越弱，如图 9.11 所示。\\n\\n288\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.11 RNN 的梯度消失问题[1]\\n\\n9.5 长短时记忆网络 LSTM\\n\\nLSTM(Long Short Term Memory)是 Hochreater 和 Schmidhuber 在 1997 年提出的\\n\\n一种网络结构，尽管该模型在序列建模上的特性非常突出，但由于当时正是神经网络的下坡\\n\\n期，没有能够引起学术界足够的重视。随着深度学习逐渐发展，后来 LSTM 的应用也逐渐增\\n\\n多。\\n\\nLSTM 区别于 SimpleRNN 的地方，主要就在于它在算法中加入了一个判断信息有用与\\n\\n否的“处理器”，这个处理器作用的结构被称为记忆块（Memory Block），如图 9.12 所\\n\\n示。\\n\\n289\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.12 记忆块（memory block）[1]\\n\\n图 9.12 中最下面 4 个神经元是输入神经元，最上面 5 个神经元是输出神经元，\\n\\nmemory block 在隐藏层的位置。传统的 BP 网络隐藏层是普通的神经元，不过在 LSTM 里\\n\\n面是结构比较复杂的 memory block。memory block 内部具体结构如图 9.13 所示。\\n\\n290\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.13 memory block 结构[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈vℎˆ(cid:127)\" + 𝑏v(cid:143)\\n\\n𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(ℎˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)ℎˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑏(cid:211))\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑏(cid:211))\\n\\nmemory block 结构主要包含了三个门：遗忘门（Forget Gate）、输入门（Input\\n\\nGate）、输出门（Output Gate）与一个记忆单元（Cell）。信号从下面传入，上面传出。\\n\\n首先我们先了解一下公式中符号的含义。\\n\\n𝑓ˆ：遗忘门信号\\n\\n291\\n\\n(9.5)\\n\\n(9.6)\\n\\n(9.7)\\n\\n(9.8)\\n\\n(9.9)\\n\\n(9.10)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑖ˆ：输入门信号\\n\\n𝑜ˆ：输出门信号\\n\\n𝑥ˆ：第 t 个序列的输入\\n\\nℎˆ(cid:127)\"：第 t-1 个序列的 memory block 输出\\n\\nℎˆ：第 t 个序列的 memory block 输出，也称为 Hidden State。\\n\\n𝑐̃ˆ：cell 输入信号\\n\\n𝑐ˆ：cell 输出信号，也称为 Cell State。\\n\\n𝑐ˆ(cid:127)\"：第 t-1 个序列的 cell 信号\\n\\n𝜎(cid:209)：sigmoid 函数\\n\\n𝜎(cid:211)：tanh 函数\\n\\n𝜎(cid:150)：tanh 函数或线性函数\\n\\n𝑊, 𝑈, 𝑏：𝑊和𝑈是权值矩阵，𝑏是偏置\\n\\n观察图 9.13，信号从 blcok 底部传入，传入的信号为第 t 个序列的输入𝑥ˆ，以及第 t-1\\n\\n个序列的输出ℎˆ(cid:127)\"，也就是上一个时间 block 的输出信号会传给当前的 block 做计算。𝑥ˆ和\\n\\nℎˆ(cid:127)\"乘以对应的权值矩阵加上偏置值经过激活函数得到𝑐̃ˆ的信号，计算公式为 9.10，如图\\n\\n9.14 所示。\\n\\n292\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.14 𝑐̃ˆ的信号计算[1]\\n\\n𝑐̃ˆ信号继续传会碰到 Input Gate 输入门，输入门的计算公式为 9.6。输入门的传入信号\\n\\n也是𝑥ˆ和ℎˆ(cid:127)\"，激活函数为 sigmoid 函数。我们要注意 2 个地方：\\n\\n1.block 中一共有 3 个门，并且这 3 个门的输入信号都是𝑥ˆ和ℎˆ(cid:127)\"，它们的计算公式都是\\n\\n差不多的，不过他们的权值矩阵是不同的值，不同的门有不同的权值。\\n\\n2.3 个门的激活函数都是 sigmoid 函数，所以 3 个门的输出值都是 0-1 之间，体现了门\\n\\n的作用。门的作用就是控制信号的开关。\\n\\n𝑐̃ˆ信号和输入门信号𝑖ˆ会进行对位相乘，然后再进行传递。𝑖ˆ的作用在这里就体现出来\\n\\n了，𝑖ˆ的值等于 1 表示𝑐̃ˆ信号会 100%传递；𝑖ˆ的值等于 0 表示𝑐̃ˆ信号会完全消失；𝑖ˆ的值等\\n\\n于 0.6 表示𝑐̃ˆ信号会保留 60%的大小进行传递。如图 9.15 所示。\\n\\n图 9.15 𝑖ˆ的信号计算[1]\\n\\n𝑐̃ˆ和𝑖ˆ对位相乘后继续传递到达 Cell 的位置。Cell 的位置有一个 Forget Gate 遗忘门，\\n\\n遗忘门的计算公式为 9.5，跟输入门的计算类似，最后得到 0-1 之间的结果。当前的𝑐ˆ信号计\\n\\n算公式为 9.8，表示𝑐̃ˆ和𝑖ˆ对位相乘后的信号再加上前一个序列的 Cell 信号𝑐ˆ(cid:127)\"和𝑓ˆ对位相乘\\n\\n的信号。\\n\\n其实就相当于是在 block 内部可以保存一个 Cell 信号为𝑐ˆ，这个信号会不断“遗忘”，\\n\\n所以需要乘以遗忘门信号𝑓ˆ。具体需要全部遗忘，还是不遗忘，还是遗忘一部分，是由遗忘\\n\\n293\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n门信号𝑓ˆ来控制的。当前的 Cell 信号就等于之前的 Cell 信号进行一些遗忘𝑐ˆ(cid:127)\" ∘ 𝑓ˆ再加上当\\n\\n前传入的信号𝑐̃ˆ ∘ 𝑖ˆ。如图 9.16 所示。\\n\\n图 9.16 𝑐ˆ的信号计算[1]\\n\\n𝑐ˆ信号继续传递会碰到 Output Gate 输出门，输出门的计算公式为 9.7，跟输入门和遗\\n\\n忘门类似。整个 block 最后的输出为ℎˆ，公式为 9.9。就是𝑐ˆ信号加上 tanh 激活函数再跟输\\n\\n出门信号𝑜ˆ对位相乘得到 block 的输出ℎˆ，如图 9.17 所示。\\n\\n图 9.16 ℎˆ的信号计算[1]\\n\\nmemory blocks 输出的ℎˆ信号会再乘上输出层的权值矩阵加上偏置值再经过激活函数最\\n\\n后得到 LSTM 网络的输出结果。\\n\\n294\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.6 Peephole LSTM 和 FC-LSTM\\n\\n9.6.1 Peephole LSTM 介绍\\n\\nPeephole LSTM 跟 LSTM 差不多，结构如图 9.17 所示。\\n\\n图 9.17 Peephole LSTM 结构图[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈v𝑐ˆ(cid:127)\" + 𝑏v(cid:143)\\n\\n𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(𝑐ˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)𝑐ˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\n295\\n\\n(9.11)\\n\\n(9.12)\\n\\n(9.13)\\n\\n(9.14)\\n\\n(9.15)\\n\\n(9.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n大家可以自己先观察一下 Peephole LSTM 跟 LSTM 的结构和公式哪里不同。\\n\\n不仔细观察可能不容易看出，它们不同之处在与把所有的ℎˆ(cid:127)\"都改成了𝑐ˆ(cid:127)\"，也就是说当\\n\\n前序列的𝑐ˆ信号传传给下一个序列的计算，而不是ℎˆ信号。\\n\\n9.6.2 FC-LSTM 介绍\\n\\nLSTM 还有一个结构为 FC-LSTM(Fully-Connected LSTM)，结构如图 9.18 所示。\\n\\n图 9.18 FC-LSTM 结构[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈vℎˆ(cid:127)\" + 𝑉v𝑐ˆ(cid:127)\" + 𝑏v(cid:143)\\n\\n𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(ℎˆ(cid:127)\" + 𝑉(𝑐ˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)ℎˆ(cid:127)\" + 𝑉(cid:210)𝑐ˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑉(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\n296\\n\\n(9.17)\\n\\n(9.18)\\n\\n(9.19)\\n\\n(9.20)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑉(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\n观察 FC-LSTM 的结构和公式，我们可以很容易的知道，FC-LSTM 的𝑐ˆ信号和ℎˆ信号都\\n\\n可以传给下一个序列进行计算。\\n\\n总结一下，在 LSTM 中存在 3 个门，输入门控制信号的输入，遗忘门控制 Cell 信号的遗\\n\\n忘，输出门控制信号的输出。LSTM 的隐藏层中有大量的 block，数量我们可以自己设置。\\n\\n经过随时间反向传播(BPTT)算法(跟 BP 算法类似)训练后 LSTM 中的 block 就可以自动判断\\n\\n哪些信号应该让它输入，哪些信号应该保存或遗忘，哪些信号应该让它输出。它的输入门会\\n\\n控制有用的信号进行输入，过滤掉一些无用的信号；它的遗忘门会保留一些重要的信号，忘\\n\\n记一些不太有用的信号；它的输出门会控制输出一些有用的信号，如图 9.19 所示。\\n\\n图 9.19 LSTM 对信号的控制[1]\\n\\n297\\n\\n(9.21)\\n\\n(9.22)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.7 其他 RNN 模型\\n\\n9.7.1 门控循环单元 GRU\\n\\nGRU(Gated Recurrent Unit)这个结构是 2014 年才出现的，效果跟 LSTM 差不多，但\\n\\n是用到的参数更少，所以计算速度会更快一些。GRU 将遗忘门和输入门合成了一个单一的更\\n\\n新门。GRU 的 block 结构简图 9.20 所示。\\n\\n图 9.20 GRU 结构\\n\\n𝑧ˆ = 𝜎(cid:209)(𝑊„𝑥ˆ + 𝑈„ℎˆ(cid:127)\" + 𝑏„)\\n\\n𝑟ˆ = 𝜎(cid:209)(𝑊(cid:156)𝑥ˆ + 𝑈(cid:156)ℎˆ(cid:127)\" + 𝑏(cid:156))\\n\\nℎ(cid:213)\\n\\nˆ = 𝑡𝑎𝑛ℎ(𝑊(cid:150)𝑥ˆ + 𝑈(cid:150)(𝑟ˆ ∘ ℎˆ(cid:127)\"))\\n\\nℎˆ = (1 − 𝑧ˆ) ∘ ℎˆ(cid:127)\" + 𝑧ˆ ∘ ℎ(cid:213)\\n\\nˆ\\n\\n𝑧ˆ是更新门(update gate)，决定ℎˆ的更新情况\\n\\n𝑟ˆ是重置门(reset gate)，决定是否要放弃ℎˆ(cid:127)\"\\n\\nℎ(cid:213) ˆ是候选输出，接收[𝑥ˆ, ℎˆ(cid:127)\"]\\n\\n298\\n\\n(9.23)\\n\\n(9.24)\\n\\n(9.25)\\n\\n(9.26)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nℎˆ是当前输出，接收[ℎˆ(cid:127)\", ℎ(cid:213)\\n\\nˆ]\\n\\n9.7.2 双向 RNN（Bidirectional RNN）\\n\\n双向 RNN(Bidirectional RNN)结构如图 9.21 所示。\\n\\n图 9.21 双向 RNN\\n\\nℎˆ(cid:214)(cid:214)(cid:214)⃗ = 𝑓(cid:142)𝑊(cid:214)(cid:214)(cid:214)⃗𝑥ˆ + 𝑉(cid:214)⃗ℎˆ(cid:127)\"\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ + 𝑏(cid:214)⃗(cid:143)\\n\\nℎˆ⃖(cid:214)(cid:214)(cid:214) = 𝑓(cid:142)𝑊⃖(cid:214)(cid:214)(cid:214)𝑥ˆ + 𝑉⃖(cid:214)ℎˆ(cid:151)\"\\n\\n⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏⃖(cid:214)(cid:143)\\n\\n𝑦ˆ = 𝑔(cid:142)𝑈(cid:146)ℎˆ(cid:214)(cid:214)(cid:214)⃗; ℎˆ⃖(cid:214)(cid:214)(cid:214)(cid:147) + 𝑐(cid:143)\\n\\n这里的 RNN 可以使用任意一种 RNN 结构 SimpleRNN，LSTM 或 GRU。这里箭头表示\\n\\n从左到右或从右到左传播，对于每个时刻的预测，都需要来自双向的特征向量，拼接\\n\\n（concatenate）后进行结果预测。箭头虽然不同，但参数还是同一套参数。有些模型中也\\n\\n可以使用两套不同的参数。𝑓, 𝑔表示激活函数，(cid:146)ℎˆ\\n\\n(cid:214)(cid:214)(cid:214)⃗; ℎˆ\\n\\n⃖(cid:214)(cid:214)(cid:214)(cid:147)表示数据拼接（concatenate）。\\n\\n双向的 RNN 是同时考虑“过去”和“未来”的信息。图 9.21 是一个序列长度为 4 的双\\n\\n向 RNN 结构。\\n\\n299\\n\\n(9.27)\\n\\n(9.28)\\n\\n(9.29)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n300\\n\\n比如输入𝑥\"沿着实线箭头传输到隐层得到ℎ\"，然后还需要再利用𝑥ˆ计算得到ℎˆ\\n\\nR ，利用𝑥$和\\n\\nR 计算得到ℎ$ ℎˆ\\n\\nR ，利用𝑥#和ℎ$\\n\\nR 计算得到ℎ#\\n\\nR ，利用𝑥\"和ℎ#\\n\\nR 计算得到ℎ\"\\n\\nR ，再把ℎ\"和ℎ\"\\n\\nR 进行数据拼接\\n\\n（concatenate），再计算得到输出结果𝑦\"。以此类推同时利用前向传递和反向传递的数据\\n\\n进行结果的预测。\\n\\n双向 RNN 就像是我们做阅读理解的时候从头向后读一遍文章，然后又从后往前读一遍文\\n\\n章，然后再做题。有可能从后往前再读一遍文章的时候会有新的不一样的理解，最后模型可\\n\\n能会得到更好的结果。\\n\\n9.7.3 Stacked Bidirectional RNN\\n\\n堆叠的双向 RNN 结构如图 9.22 所示。\\n\\n图 9.22 Stacked Bidirectional RNNs\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ ((cid:132)) ℎˆ ⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) ((cid:132)) ℎˆ\\n\\n(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ + 𝑏(cid:132)(cid:214)(cid:214)(cid:214)⃗(cid:218)\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ℎˆ\\n\\n(cid:132)(cid:127)\" + 𝑉(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)⃗ℎˆ(cid:127)\"\\n\\n= 𝑓 (cid:217)𝑊(cid:132)\\n\\n(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:218)\\n\\n(cid:132)(cid:127)\" + 𝑉(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)ℎˆ(cid:151)\" ⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) (cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ ((cid:132)) ((cid:132)) 𝑦ˆ = 𝑔 l𝑈 (cid:219)ℎˆ ; ℎˆ\\n\\n= 𝑓 (cid:217)𝑊(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)ℎˆ\\n\\n(cid:220) + 𝑐m\\n\\n注意这里的堆叠 RNN 结构并不是只有双向 RNN 才可以堆叠，其实任意的 RNN 都可以\\n\\n堆叠，比如 SimpleRNN，LSTM，GRU 这些循环神经网络也可以进行堆叠。堆叠指的是在\\n\\nRNN 的结构中叠加多层，类似于 BP 神经网络中可以叠加多层，增加网络的非线性。图 9.22\\n\\n中是一个堆叠了 3 个隐藏层的 RNN 网络。\\n\\n9.8 LSTM 网络应用于 MNIST 数据集分类\\n\\nLSTM 网络是序列模型，一般是比较适合处理序列问题。这里我们把它用于手写数字图\\n\\n片的分类，其实是相当于把图片看成序列。一张 MNIST 数据集的图片是 28*28 的大小，我\\n\\n们可以把每一行看成是一个序列输入，那么一张图片就是 28 行，序列长度为 28；每一行有\\n\\n28 个数据，每个序列输入 28 个值，具体实现如代码 9-1 所示。\\n\\n代码 9-1：LSTM 网络应用于 MNIST 数据集分类\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.layers import LSTM from tensorflow.keras.optimizers import Adam\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28）\\n\\n301\\n\\n(9.30)\\n\\n(9.31)\\n\\n(9.32)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 数据大小-一行有 28 个像素 input_size = 28 # 序列长度-一共有 28 行 time_steps = 28 # 隐藏层 memory block 个数 cell_size = 50\\n\\n# 创建模型 model = Sequential()\\n\\n# 循环神经网络的数据输入必须是 3 维数据 # 数据格式为(数据数量，序列长度，数据大小) # 载入的 mnist 数据的格式刚好符合要求 # 注意这里的 input_shape 设置模型数据输入时不需要设置数据的数量 model.add(LSTM( units = cell_size, input_shape = (time_steps,input_size), ))\\n\\n# 50 个 memory block 输出的 50 个值跟输出层 10 个神经元全连接 model.add(Dense(10,activation=\\'softmax\\'))\\n\\n# 定义优化器 adam = Adam(lr=1e-3)\\n\\n# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\'])\\n\\n# 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 14s 236us/sample - lo ss: 0.5748 - accuracy: 0.8189 - val_loss: 0.2315 - val_accuracy: 0.93 03\\n\\n302\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 2/10 60000/60000 [==============================] - 15s 247us/sample - lo ss: 0.1953 - accuracy: 0.9416 - val_loss: 0.1521 - val_accuracy: 0.95 55 …… Epoch 10/10 60000/60000 [==============================] - 14s 228us/sample - lo ss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0644 - val_accuracy: 0.98 03\\n\\nLSTM 应用于 MNIST 数据识别也可以得到不错的结果，不过当然没有卷积网络得到的结\\n\\n果好。更多序列模型的应用案例我们将在后面的章节中进一步介绍。\\n\\n9.9 参考文献\\n\\n[1] Graves A. Supervised sequence labelling[M]//Supervised sequence labelling with\\n\\nrecurrent neural networks. Springer, Berlin, Heidelberg, 2012: 5-13.\\n\\n303\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 10 章-经典图像识别模型介绍（上）\\n\\n经典的图像识别模型比较多，并且我希望可以把各种模型的技术细节，设计思路尽可能\\n\\n地给大家介绍清楚。所以经典图像识别模型介绍的部分分为上下两个章节，第 10 章和第 11\\n\\n章。这两个章节的内容都属于内功修行，为了保持内容的连贯性，这两个章节的内容都是算\\n\\n法理论的介绍，相关代码实践的内容我放到了第 12 章节。大家可以看完第 10，11 章再看\\n\\n12 章，或者是结合第 12 章的代码来看第 10，11 章，两种方式都可以。\\n\\n10.1 图像数据集 ImageNet\\n\\n10.1.1 ImageNet 介绍\\n\\n在正式介绍深度学习的经典图像识别模型之前，我们先来了解一下全世界最大的带有标\\n\\n签的开源图像数据集 ImageNet。\\n\\nImageNet 项目是从 2007 年由斯坦福教授李飞飞领导发起，ImageNet 项目团队从互\\n\\n联网上下载了近 10 亿张照片，然后使用众包技术（例如亚马逊机械土耳其人平台）来帮助\\n\\n他们为这些图像打标签。在巅峰时期，ImageNet 项目有来自 167 个国家的近 50000 名工\\n\\n作者为其进行数据的清理，分类，标注。\\n\\n直到 2009 年 ImageNet 项目正式交付使用，在 ImageNet 数据库中有 1500 万张左右\\n\\n的照片，包含大约 22000 种类别，免费提供给全世界的研究者使用。ImageNet 的官网地址\\n\\n是：http://www.image-net.org/index。如图 10.1 所示。\\n\\n304\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.1 ImageNet 官网\\n\\n官网的右上角可以看到当前 ImageNet 数据库图片的数量为 14197122 张图片，一共有\\n\\n21841 个种类。\\n\\n10.1.2 李飞飞简介\\n\\n李飞飞是美籍华人，人工智能学术圈最知名的女性科学家之一。\\n\\n1976 年出生于北京，长在四川，16 岁随父母移居美国新泽西州。\\n\\n1999 年毕业于普林斯顿大学。\\n\\n2005 年获得加州理工学院电子工程博士。\\n\\n2009 年加入斯坦福大学担任助理教授。\\n\\n2012 年担任副教授（终生教授），和斯坦福人工智能实验室与视觉实验室主任。\\n\\n2017 年 1 月入职 Google，担任谷歌云首席科学家。\\n\\n2018 年 9 月，离开谷歌返回斯坦福大学担任教授，同时保留谷歌云的 AI/ML 顾问。\\n\\n2020 年 2 月，当选为美国国家工程院院士。\\n\\n305\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.1.3 ImageNet 的深远影响\\n\\n2020 年 2 月李飞飞当选美国国家工程院院士，美国国家工程院(NAE)对于李飞飞的当选\\n\\n给出的理由是“李飞飞为建立大型机器学习和视觉理解知识库作做出了贡献”。这里的“大\\n\\n型机器学习和视觉理解知识库”其实说白了就是 ImageNet 数据集。为什么创建一个数据\\n\\n集，就可以有资格评选美国院士？下面是我个人对于 ImageNet 数据集重要性的理解：\\n\\n一．前瞻性和创新性。ImageNet 项目在 2007 年发起，到 2009 年交付使用。这个巨\\n\\n大的项目需要耗费大量的人力物力财力，但是这个项目交付以后能发挥多大的作用，在当时\\n\\n并不是十分明确。我们从今天的视角来看，大规模深度学习模型的训练（这里的训练指的是\\n\\n重新训练一个新模型，不是指迁移学习（Transfer Learning））必然需要大规模的数据集\\n\\n才能得到很好的结果，这也是目前深度学习技术的一个局限性。但是在当时，深度学习技术\\n\\n才刚刚萌芽，大家并不明确大规模数据集对于机器学习/深度学习技术会有多大的影响。\\n\\n二．ImageNet 对于计算机视觉领域的巨大影响。如果大家之前稍微有关注过计算机视\\n\\n觉的发展就会发现，在 ImageNet 交付使用后，特别是 2012 年以后，计算机视觉领域的技\\n\\n术发展可谓是突飞猛进。图像识别，目标检测，人脸识别等技术的应用效果得到了巨大提\\n\\n升。10 年前人脸识别技术我们可能只听说过，没见过，现在走到哪里都有人脸识别。这一切\\n\\n都主要得益于深度学习技术的发展和 ImageNet 数据集。\\n\\nImageNet 在 2009 年免费发布以后，从 2010 年开始每年都会组织一次计算机视觉的比\\n\\n赛 ILSVRC（ImageNet Large Scale Visual Recognition Challenge），简称 ImageNet\\n\\nChallenge。这个比赛也是近年来计算机视觉领域最受追捧也最具权威的学术竞赛之一，代\\n\\n表了计算机视觉领域的最高水平。比赛的项目有图像分类，目标定位，目标检测，视频目标\\n\\n检测，场景分类。其中最重要也最受关注的就是图像分类的比赛。\\n\\n306\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nImageNet Challenge 的图像分类比赛是从 ImageNet 数据集中选出了 1000 个生活中\\n\\n常见的分类，120 万张图片作为训练集，10 万张图片作为测试集，5 万张图片作为验证集。\\n\\n参加比赛的人主要都是来自全世界的大公司，学校，研究院等。也有一些创业公司会参赛，\\n\\n因为如果能在这个全世界最知名的图像比赛上拿奖的话，那就证明了获奖公司拥有全世界最\\n\\n顶尖的图像技术水平，之后拿投资，做推广都会很容易。\\n\\n从 ImageNet Challenge 比赛中诞生出了很多优秀的深度学习模型，这些模型可以应用\\n\\n于计算机视觉的各种领域，图像识别，目标检测，目标分割，人脸识别等等，极大推动了计\\n\\n算机视觉的发展。\\n\\n如果大家对 ImageNet Challenge 比赛感兴趣，也想参赛的话，那么很遗憾，参加不了\\n\\n了。因为这个比赛是从 2010 年开始举办，到 2017 年结束，现在这个比赛已经没有了。因\\n\\n为这个比赛的初衷就是希望可以通过比赛来推动计算机视觉技术的发展，很显然，这个目的\\n\\n已经完全达到，比赛中各个项目的模型效果均已接近甚至超过人类水平。\\n\\n三．ImageNet 对于其他技术领域的影响。ImageNet 最直接的影响肯定是计算机视觉\\n\\n领域，不过除了计算机视觉，ImageNet 也间接推动了其他技术领域的发展。\\n\\n深度学习的主要应用领域是图像，文本和语音等，每个技术领域都有不同的特点，不过\\n\\n也都有一些相通的地方。比如不管在哪个领域使用深度学习都需要涉及到激活函数，代价函\\n\\n数，网络结构设计等这些方面的内容。ImageNet 的发布以及 ImageNet Challenge 比赛促\\n\\n进了深度学习技术的全面发展，让神经网络技术再一次流行起来，使得我们对神经网络/深度\\n\\n学习的技术有了更深刻的理解。所以当我们在其他领域使用深度学习的时候，ImageNet 也\\n\\n起到了潜移默化的作用。\\n\\n307\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.1.4 ImageNet Challenge 历年优秀作品\\n\\nImageNet Challenge 从 2010 年开始举办到 2017 年结束，总共举办了 8 次。在这 8\\n\\n年的时间里诞生出了很多非常经典而且优秀的模型，让神经网络变得越来越流行，并出现了\\n\\n多种优秀变体，可谓百花齐放。下面我们简单来回顾一下 ImageNet Challenge 比赛的历\\n\\n史，图 10.2 为历年比赛结果（数据来源于 http://image-net.org/challenges/LSVRC/）。\\n\\n图 10.2 ImageNet Challenge 历年比赛结果\\n\\n图 10.2 中的百分比为 ImageNet Challenge 图像分类比赛中的错误率，注意这里的错误\\n\\n率为 Top5 错误率。一般在对 ImageNet 数据进行建模分类的时候，模型都会给出两个错误\\n\\n率结果，一个是 Top1 错误率，一个是 Top5 错误率。Top1 错误率表示模型在预测图像分类\\n\\n的时候只能给出一个最可能的预测结果，预测结果跟真实标签相同则表示预测正确；Top5\\n\\n错误率表示模型在预测图像分类的时候可以给出 5 个最可能的预测结果，这 5 个最可能的预\\n\\n测结果只要有其中一个跟真实标签相同则表示预测正确。由于 ImageNet Challenge 图像分\\n\\n308\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n类比赛有 1000 个分类，在做预测的时候有一定的错误容忍性，所以经常使用 Top5 错误率\\n\\n作为主要指标判断模型好坏。\\n\\n这里先对历年比赛结果做一个简单的介绍，后面我们还会再具体分析其中一些比较经典\\n\\n和优秀的模型。如果大家仔细看的话会发现，有些年份我列出了冠亚军，有些年份我只列出\\n\\n了冠军。这是因为有些模型虽然在某些年份的比赛中是亚军，但是它的名气，创新程度不亚\\n\\n于冠军，所以我也列出来了。\\n\\n2010 年和 2011 年的冠军使用的都是 SVM 算法，我们知道 SVM 算法是机器学习领域\\n\\n中的经典算法，在深度学习崛起之前，SVM 算法在计算机视觉中有着很多的应用。所以\\n\\nImageNet Challenge 比赛的前两届大家用的还是老的思路，使用 SVM 来进行建模。从结\\n\\n果中我们也可以看出来，使用 SVM 来进行大规模的图片分类，得到的效果明显不如深度学\\n\\n习。\\n\\n2012 年对深度学习来说也是一个重要的年份，因为这是深度学习在 ImageNet\\n\\nChallenge 图像分类的比赛上首次获得冠军。创造出这个深度学习模型的冠军团队来自多伦\\n\\n多大学，主要作者是 Alex Krizhevsky，所以这个模型被命名为 AlexNet。团队成员中还有\\n\\nGeoffrey Hinton，我们在本书最开始介绍深度学习领域的名人时有介绍过他，被称为“深\\n\\n度学习教父”的人。Alex Krizhevsky 是 Geoffrey Hinton 的学生，所以这个工作应该是在\\n\\nHinton 大牛的带领下主要由学生完成的。AlexNet 在当时大获成功，相比 SVM，图像识别\\n\\n的错误率有了大幅度的下降。2012 年比赛的亚军使用的算法还是传统机器学习算法，错误率\\n\\n为 26.17%，而 AlexNet 的错误率已经下降到了 16.42%，拉开了巨大差距。从 2012 年以\\n\\n后，深度学习逐渐崛起，在后来的比赛中，所有人都开始使用深度学习来进行建模。\\n\\n2013 年的冠军来自 Clarifai 公司，他们用的也是深度学习模型，不过他们获得冠军的网\\n\\n络模型不太有名，网上的资料也不多，后面就不多做介绍了。\\n\\n309\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n2014 年的冠军是来自谷歌的团队完成的，所以给模型命名为 GoogleNet。2014 年的亚\\n\\n军模型也很有名，是来自牛津大学的研究组 VGG (Visual Geometry Group) ，所以给模型\\n\\n起名为 VGGNet。这两个模型都是非常有名和经典的模型，所以我在图中都列出来了。\\n\\n2015 年的冠军是来自微软亚洲研究院(MSRA)，他们给模型命名为残差网络（Residual\\n\\nNetwork），所以模型简称为 ResNet。这个网络的层数多达 152 层，网络结构设计非常具\\n\\n有创新性。\\n\\n2016 年的冠军由中国团队获得，是公安部第三研究所的 Trimps-Soushen 团队，他们用\\n\\n的也是深度学习模型，不过他们获得冠军的网络模型不太有名，网上的资料也不多，后面就\\n\\n不多做介绍了。2016 年的亚军是来自加州大学圣地亚哥分校(UCSD)和 Facebook AI\\n\\nResearch(FAIR)的团队，他们的模型是在 ResNet 的基础上进行改进后得到的，所以模型命\\n\\n名为 ResNeXt。\\n\\n2017 年的冠军是来自 Momenta 公司的团队，他们提出了 Squeeze-and-Excitation\\n\\nNetworks（简称 SENet）。\\n\\n8 年来 ImageNet Challenge 比赛不断推动着计算机视觉技术和深度学习的发展。人类\\n\\n在 ImageNet Challenge 图像识别比赛上的表现大约是 5.1%的错误率[1]，近年的比赛结果\\n\\n已经比人类的错误率要低了许多。2017 年是 ImageNet Challenge 的最后一年，也是一个\\n\\n时代的终结。2017 年以后，ImageNet 将与全世界最大的数据科学社区 Kaggle 结合，在\\n\\nKaggle 社区里继续举办比赛。ImageNet Challenge 虽然没有了，不过 ImageNet 的影响\\n\\n将继续延续。\\n\\n310\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.2 AlexNet\\n\\nAlexNet 是在 ImageNet Challenge 图像识别比赛上第一个获得冠军的深度学习模型，\\n\\n由自多伦多大学团队完成，主要作者是 Alex Krizhevsky，“深度学习教父” Geoffrey\\n\\nHinton 也在团队中。AlexNet 对后来的深度学习模型设计和模型训练都有着重要的启发和指\\n\\n导作用。最早提出 AlexNet 的论文是《ImageNet Classification with Deep\\n\\nConvolutional Neural Networks》[2]。\\n\\n这里我想稍微多说几句，由于 ImageNet Challenge 是一个比赛，比赛中有很多 Trick\\n\\n可以帮助模型得到更好的结果，比如在 AlexNet 中在当时比较创新的使用了 ReLU 激活函\\n\\n数，和使用 Dropout 来防止过拟合，然后把每张图片切分为多张进行训练和预测，改变图片\\n\\n的颜色以生成更多的数据集等。比赛中的很多 Trick 内容比较分散，并且效果不稳定，有时\\n\\n候可以让结果更好，有时候会让结果更差。所以关于模型的介绍我们主要是介绍模型的结构\\n\\n设计，关于模型在比赛中所使用的 Trick 大家有兴趣可以再另外自行研究。\\n\\n图 10.3 为《ImageNet Classification with Deep Convolutional Neural Networks》\\n\\n论文中的网络结构图。\\n\\n图 10.3 AlexNet 网络结构[2]\\n\\n311\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Stride 表示步长；Max pooling 表示最大池化；Dense 表示全连接层。输入图片\\n\\n大小为 224×224，实际上作者在构建模型的时候使用的图片大小为 227×227，主要是为了\\n\\n后续计算方便。\\n\\n大家初看这个图可能会觉得这个结构看起来有点复杂，可能暗藏玄机，这个模型的输入\\n\\n是 227×227 的图片（作者把 ImageNet Challenge 比赛的图片都处理成 227×227 的固定\\n\\n大小再传入模型进行训练），后来怎么就变成了上下两个部分，这样设计有什么精妙之处\\n\\n吗？\\n\\n在当时看来，其实没有什么精妙，只是因为当时算力有限，也没有什么好用的深度学习\\n\\n开源框架。他们手上只有两个 GTX580 的 3GB 内存的 GPU，为了加快模型的训练速度，所\\n\\n以他们把模型分为两个部分。一个 GPU 训练上面的部分，一个 GPU 训练下面的部分，所以\\n\\n网络结构就变成了上下两个部分。我猜测如果尽量不改变模型的设计思路，放在今天的软硬\\n\\n件条件下，AlexNet 应该会被设计成图 10.4 所示的结构。\\n\\n图 10.4 AlexNet 网络结构\\n\\n312\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 s 表示 stride，代表步长，s1 代表卷积或池化的步长为 1，s2 代表卷积或池化的\\n\\n步长为 2，以此类推；fc 表示 fully connected，代表全连接；pool 表示 max pooling，代\\n\\n表最大池化；conv 表示 convolution，代表卷积；output 表示输出。\\n\\n其实我猜测的图 10.4 结构和论文中图 10.3 结构还是有一点点小区别的，论文中的结构\\n\\n分为上下两个部分以后，注意看图 10.3 中的卷积的计算，在某些层会分为上下两个部分独立\\n\\n计算，在某些层上下两个部分会一起计算。不过总的来说模型的效果差别不是很大（其实我\\n\\n画的图 10.4 的 AlexNet 结构会比原始的 AlexNet 结构效果差一点点，不过这里我们忽略不\\n\\n计）。我们就以图 10.4 来看一下 AlexNet 的网络设计。\\n\\n把图画好其实就可以节省很多文字讲解了，图中已经把所有的卷积池化计算的窗口大\\n\\n小，步长，以及卷积池化计算以后得到的特征图大小和数量都表示出来了，下面我再简单说\\n\\n明一下即可。\\n\\n图中卷积和池化的 padding 方式我没有标出来，有些层使用的是 valid padding，有些\\n\\n层使用的是 same padding，不同的 padding 方式对模型结果一般不会有很大影响，所以图\\n\\n中我就省略了。另外其实通过图中的已知的信息我们可以自己判断出 padding 的方式。\\n\\nAlexNet 是一个 8 层的网络（卷积层和全连接层中有需要训练的权值，所以这里计算网\\n\\n络层数的时候只计算卷积层和全连接层），除了最后输出层用的是 softmax 函数以外，其他\\n\\n层用的都是 ReLU 激活函数。\\n\\nAlexNet 是专门为 ImageNet 级别的数据集设计的，一共有 6000 多万个需要训练的参\\n\\n数，参数的数量巨大。\\n\\n第 1 层计算。网络的输入是 227×227 的“臭臭”照片。经过 11×11 步长为 4 的卷积\\n\\n计算后，得到 96 个 55×55 的特征图。然后再进行 3×3 步长为 2 的最大池化计算，得到\\n\\n96 个 27×27 的特征图。\\n\\n313\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 层计算。使用 5×5，步长为 1 的卷积对 96 个 27×27 的特征图进行特征提取，得\\n\\n到了 256 个 27×27 的特征图。然后再用 3×3 步长为 2 的最大池化计算，得到 256 个 13×\\n\\n13 的特征图。\\n\\n第 3 层计算。使用 3×3，步长为 1 的卷积对 256 个 13×13 的特征图进行特征提取，得\\n\\n到了 384 个 13×13 的特征图。\\n\\n第 4 层计算。使用 3×3，步长为 1 的卷积对 384 个 13×13 的特征图进行特征提取，得\\n\\n到了 384 个 13×13 的特征图。\\n\\n第 5 层计算。使用 3×3，步长为 1 的卷积对 384 个 13×13 的特征图进行特征提取，得\\n\\n到了 256 个 13×13 的特征图。然后再用 3×3 步长为 2 的最大池化计算，得到 256 个 6×6\\n\\n的特征图。\\n\\n第 6 层计算。把 pool3 的 256 个 6×6 的特征图数据跟 fc1 中的 4096 个神经元进行全\\n\\n连接计算。\\n\\n第 7 层计算。把 fc2 的 4096 个神经元跟 fc1 中的 4096 个神经元进行全连接计算。\\n\\n第 8 层计算。把 output 的 1000（ImageNet Challenge 比赛有 1000 个分类）个神经\\n\\n元跟 fc2 中的 4096 个神经元进行全连接计算。最后再经过 softmax 计算得到类别的概率值\\n\\n进行输出。\\n\\n可能大家会有一些疑问，什么 AlexNet 要设计成 8 层的网络？为什么有些卷积后面加上\\n\\n了池化，有些卷积后面没有池化？为什么有些卷积生成的特征图数量是 256，有些是 384？\\n\\n为什么是 384 而不是其他的数字？为什么有 3 个全连接层，为什么是 4096 个神经元？\\n\\n其实这些为什么都很难给出合理的解释，因为直至今天深度学习的可解释性依旧是一个\\n\\n重要科研难题。我觉得 AlexNet 的网络结构是在 Alex 团队有限的时间，有限的实验次数下\\n\\n314\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n得到的最好的模型结构了。如果给他们更好的设备，更多的时间，做更多的实验，他们肯定\\n\\n会得到更优秀的模型，得到更好的结果。\\n\\n我们在 2012 年的时候知道 AlexNet 是一个正确的方向，它开拓了一个新的并且更好的\\n\\n思路，我们只要沿着这个方向继续往前走，肯定有更多的收获等着我们。\\n\\n10.3 VGGNet\\n\\nVGGNet 是 2014 年 ImageNet Challenge 图像识别比赛的亚军。参赛团队是来自牛津\\n\\n大学的研究组 VGG (Visual Geometry Group) 。VGGNet 的很多设计思想都受到 AlexNet\\n\\n的影响，所以跟 AlexNet 也有一点点相似的地方。VGGNet 不仅在图像识别方向有着广泛应\\n\\n用，很多目标检测，目标分割，人脸识别等方面的应用也会使用 VGGNet 作为基础模型。\\n\\nVGGNet 在 2014，2015 年左右的流行程度甚至超过了 2014 年 ImageNet Challenge\\n\\n图像识别比赛的冠军 GoogleNet，是当时用得最多的深度学习模型。VGGNet 被广泛使用\\n\\n也是有一定原因的，VGGNet 的网络结构比较简单，也容易搭建，并且 VGGNet 的单模型结\\n\\n果与 GoogleNet 相当。ImageNet Challenge 是一个比赛，在比赛中我们经常会使用模型\\n\\n融合（Ensemble Model）策略，把多个模型组合在一起，这样有可能会得到更好的结果。\\n\\n2014 年，在 ImageNet Challenge 比赛中，多个 GoogleNet 融合后的结果比多个\\n\\nVGGNet 融合后的结果要更好，所以 GoogleNet 得到了冠军。最早提出 VGGNet 的论文是\\n\\n《Very Deep Convolutional Networks for Large-Scale Image Recognition》[3]。\\n\\n其实，VGGNet 有多个版本，如图 10.5 所示。\\n\\n315\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.5 VGGNet 的多个版本[3]\\n\\n从图中 ConvNet Configuration 表示网络结构；weight layers 表示网络层数；input\\n\\n表示输入；conv 表示卷积；maxpool 表示最大池化；FC 表示全连接层。\\n\\n我们可以看出 VGGNet 有 6 个不同的版本，他们的主要区别是网络层数和网络结构的区\\n\\n别。图中的 conv3 表示 3×3 的卷积，conv1 表示 1×1 的卷积；conv3-128 表示 3×3 的\\n\\n卷积计算后生成 128 个特征图；LRN(Local Response Normalization)是局部响应归一\\n\\n化，一种在 AlexNet 中使用的数据归一化计算，不过 VGGNet 的作者认为 LRN 并没有什么\\n\\n用，所以在 VGGNet 中并没有使用。\\n\\n其中使用得比较多的有 B，因为它有 13 层，我们称之为 VGG13。使用得比较多的还有\\n\\nD，因为它有 16 层，我们称之为 VGG16。使用得比较多的还有 E，因为它有 19 层，我们称\\n\\n之为 VGG19。在 ImageNet Challenge 图像识别比赛中效果最好的是 VGG19，其次到\\n\\nVGG16，最后是 VGG13。\\n\\n316\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n每个版本的模型网络结构不同，所以参数的数量也有所不同。参数数量最少的是 A，有 1\\n\\n亿 3 千多万个参数。最多的是 E，有 1 亿 4 千多万个参数。别看网络中有很多的卷积层，其\\n\\n实网络中大部分的参数都是在全连接层中。比如在 VGG16 中，卷积层的参数数量占所有参\\n\\n数的 13%，而全连接层的参数数量占到了 87%。\\n\\n在很多应用中 VGG16 似乎用得更多一些，下面我们来看一下 VGG16 的网络结构图\\n\\n10.6 所示。\\n\\n图 10.6 VGG16 网络结构\\n\\n图中 fc 表示 fully connected，代表全连接；pool 表示 max pooling，代表最大池化；\\n\\nconv 表示 convolution，代表卷积；output 表示输出。\\n\\nVGG16 的所有卷积都是 3×3，步长为 1，same padding；所有池化都是 2×2，步长\\n\\n为 2，same padding；输出层函数为 softmax，除了输出层以外，其他层激活函数都是\\n\\nReLU 函数。\\n\\nVGG16 受 AlexNet 的影响和启发，图片的输入为 224×224 的大小，卷积层后面也使\\n\\n用了 3 个全连接层，并且全连接层也是使用 4096 个神经元。\\n\\n317\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nVGG16 是一个 16 层的网络，它的结构比较简单易懂，叠加了很多个卷积池化层。2×\\n\\n2，步长为 2 的池化特会使得特征图的长宽减少为原来 1/2，池化后的下一个卷积会使得特征\\n\\n图的数量会变成原来的 2 倍。\\n\\nVGG16 的输入是 224×224 大小的图片。\\n\\nblock1 为第 1，2 层，其中包含了 2 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n224×224，池化后特征图大小变成了 112×112，特征图的数量为 64。\\n\\nblock2 为第 3，4 层，其中包含了 2 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n112×112，池化后特征图大小变成了 56×56，特征图的数量为 128。\\n\\nblock3 为第 5，6，7 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n56×56，池化后特征图大小变成了 28×28，特征图的数量为 256。\\n\\nblock4 为第 8，9，10 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生变\\n\\n化 28×28，池化后特征图大小变成了 14×14，特征图的数量为 512。\\n\\nblock5 为第 11，12，13 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生\\n\\n变化 14×14，池化后特征图大小变成了 7×7，特征图的数量为 512。大家可能会稍微有点\\n\\n疑惑，block5 中的特征图的数量按照规律不应该会变成 1024 吗，但是这里还是 512。这里\\n\\n的原因我猜测是作者他们肯定也尝试过 1024，但是最后的效果估计跟 512 的效果差不多。\\n\\n并且改成 1024 后会增加很多计算量和需要训练的权值，所以最后的版本中就没有使用\\n\\n1024。\\n\\n第 14 层计算。把 pool5 的 512 个 7×7 的特征图数据跟 fc1 中的 4096 个神经元进行全\\n\\n连接计算。\\n\\n第 15 层计算。把 fc2 的 4096 个神经元跟 fc1 中的 4096 个神经元进行全连接计算。\\n\\n318\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 16 层计算。把 output 的 1000（ImageNet Challenge 比赛有 1000 个分类）个神\\n\\n经元跟 fc2 中的 4096 个神经元进行全连接计算。最后再经过 softmax 计算得到类别的概率\\n\\n值进行输出。\\n\\nVGGNet 网络结构本身并没有太多创新的内容，它可以看成是对 AlexNet 网络的改进优\\n\\n化版本。\\n\\n10.4 GoogleNet\\n\\nGoogleNet 是 2014 年 ImageNet Challenge 图像识别比赛的冠军。从它的名字我们就\\n\\n可以看出是来自谷歌的团队完成的。前面我们有介绍，GoogleNet 之所以获得冠军，是因为\\n\\n它进行模型融合以后得到的效果要比 VGGNet 模型融合之后的效果要好。不过单模型比拼，\\n\\n它与 VGGNet 的效果相当。\\n\\n虽然 GoogleNet 的模型的效果跟 VGGNet 相差不大，不过它比 VGGNet 更具有创新\\n\\n性。GoogleNet 有一些更具创新性的设计，为后来的模型设计提供了很多新的思路。最早提\\n\\n出 GoogleNet 的论文是《Going Deeper with Convolutions》[4]。\\n\\n10.4.1 1×1 卷积介绍\\n\\n在介绍 GoogleNet 结构之前，我们必须先来介绍一下什么是 1×1 卷积。1×1 卷积在\\n\\nGoogleNet 中有着大量应用，是一个非常重要的设计。它的主要作用主要有两个，一是增加\\n\\n网络非线性，二是减少计算量和需要训练的权值。\\n\\n319\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n所谓 1×1 卷积其实很简单，就是卷积核的大小是 1×1，其他方面跟之前我们学习的卷\\n\\n积没有区别。图 10.7 为 1×1 卷积示意图。\\n\\n图 10.7 1×1 卷积\\n\\n使用 1×1 卷积对 6×6 图像进行特征提取，然后得到 6×6 的特征图。我们可以这么理\\n\\n解，只考虑对 1 张图像进行卷积计算时，3×3，5×5 这样的大卷积核可以对大范围区域的\\n\\n特征进行提取然后得到 1 个特征值。1×1 的卷积只对图上的 1 个值进行特征提取然后得到 1\\n\\n个特征值。那么下面我们具体来看一下 1×1 卷积如何应用于实际的网络搭建。我们先考虑\\n\\n一个没有 1×1 卷积的卷积层计算，如图 10.8 所示。\\n\\n图 10.8 没有加入 1×1 卷积的卷积计算\\n\\n图中 conv 表示卷积。\\n\\n从图中可知 192 个 28×28 的特征图经过 5×5，步长为 1 的卷积进行特征提取，得到 32\\n\\n个 28×28 的特征图。这里我们主要考虑一下图中的权值数量和计算量。关于卷积的权值数\\n\\n量和计算量的计算我们在第 8 章中已有详细介绍，下面我们就不再详细说明了：\\n\\n320\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n权值数量的计算为：5×5×192×32+32 个偏置值=153632。\\n\\n计算量为（这里我们只计算乘法的计算量）：5×5×28×28×192×32≈120M，M 为\\n\\nmillion 百万。\\n\\n我们对正常卷积计算的权值数量和计算量有了大致的了解，下面我们再来看一下加入 1×\\n\\n1 卷积后的计算，如图 10.9 所示。\\n\\n图 10.9 加入了 1×1 卷积的卷积计算\\n\\n图中 conv 表示卷积。\\n\\n从图中可知 192 个 28×28 的特征图经过两次卷积，最后得到 32 个 28×28 的特征图，\\n\\n最左边和最右边的特征图跟图 10.8 中的左右两边的特征图是完全一样的，只是图 10.9 中间\\n\\n多了一次 1×1 的卷积。\\n\\n从表面上看，我们就可以看出 1×1 卷积的第一个作用了，增加网络的非线性。因为网络\\n\\n的层数多了一层，层数越多，网络的非线性就越强。\\n\\n下面我们再来计算一下加入 1×1 卷积后网络的权值数量和计算量。\\n\\n权值数量的计算为：第一个卷积层：1×1×192×16+16 个偏置值=3088。第二个卷积\\n\\n层：5×5×16×32+32 个偏置值=12832。两个卷积层权值数量相加\\n\\n3088+12832=15920，约为图 10.9 中没有 1×1 卷积的 1/10。\\n\\n321\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n计算量为（这里我们只计算乘法的计算量）：第一个卷积层：1×1×28×28×192×\\n\\n16≈2.4M，M 为 million 百万。第二个卷积层：5×5×28×28×16×32≈10M。两个卷积层\\n\\n计算量相加 2.4M+10M=12.4M，约为图 10.9 中没有 1×1 卷积的 1/10。\\n\\n这就是 1×1 卷积的第二个作用，减少计算量和需要训练的权值。初看这个结果大家可能\\n\\n会有点难接受。前后两端都没有发生变化，看起来明明是多了一个卷积层，感觉上应该会有\\n\\n更多的权值和更多的计算量才对。\\n\\n其实大家只要仔细再看一下就能发现其中的原因。其中一个原因是 1×1 卷积本身的计算\\n\\n量和权值数量就很少，另一个重要原因是“16”。1×1 卷积计算后生成了 16 个 28×28 的特\\n\\n征图，比最后输出的 32 个 28×28 特征图的特征数量更少，相当于 1×1 卷积对原来的特征\\n\\n图进行了特征压缩。特征数量越少，计算量和权值数量自然就越少了。\\n\\n如果上面计算中我们把 16 改成 160，1×1 卷积后产生 160 个 28×28 的特征图，那么使\\n\\n用了 1×1 卷积的计算，它的权值数量和计算量都跟不使用 1×1 卷积差不多。\\n\\n所以并不是说用了 1×1 卷积，就一定可以减少权值数量和计算量，也要看 1×1 卷积后生\\n\\n成了多少张特征图。不过通常来说，我们不会让 1×1 卷积生成太多的特征图，所以一般来说\\n\\n加入 1×1 卷积后是可以减少网络权值数量和计算量的。\\n\\n10.4.2 Inception 结构\\n\\n在 GoogleNet 最特别的设计就是 Inception 结构，所以 GoogleNet 在后来的版本中改\\n\\n了名字，模型的名字改成了 Inception，而 GoogleNet 就是 Inception-v1。Inception 结构\\n\\n如图 10.10 所示。\\n\\n322\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.10 Inception 结构[4]\\n\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\n\\npooling 表示最大池化，previous layer 表示前一层。\\n\\n图 10.10 中左边的结构是 Inception 原始的版本，右边的结构是 Inception 后来优化的\\n\\n版本了。前面我们已经介绍过 1×1 卷积的作用，所以在（b）中我们看到 1×1 卷积应该知道\\n\\n它的用意了，增加网络的层数以增加非线性，同时减少网络的权值数量和计算量。\\n\\n不过 Inception 最特别的设计不是在于 1×1 卷积，而是在于同时使用多种不同尺度的卷\\n\\n积核。我们可以看到 Inception 结构中使用了 1×1 卷积，3×3 卷积，5×5 卷积和一个最大\\n\\n池化。卷积的作用我们应该很清楚了，用来做特征提取。不同的卷积核的数值可以提取不同\\n\\n的特征，那么不同大小的卷积核当然也是可以从不同的尺度来提取特征的。从一个小区域提\\n\\n取出来的特征跟从一个大区域提取出来的特征当然是不一样的。所以 Inception 具有创新的\\n\\n设计在于使用了多种不同尺度的卷积核来提取不同尺度的特征。\\n\\n下面我们举一个具体的例子来说明 Inception 结构的计算，如图 10.11 所示。\\n\\n323\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.11 Inception module\\n\\n图中 conv 表示卷积，pool 表示池化。\\n\\nInception module 是从 GoogleNet 结构中拿出来的一个具体计算的例子。输入是 192\\n\\n个 28×28 的特征图，Inception module 会对这些特征图进行不同的特征提取计算。假如我\\n\\n们把 Inception 看成是有 4 个通道的特征提取计算：\\n\\n第 1 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 64 个 28×\\n\\n28 的特征图。\\n\\n324\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 96 个 28×\\n\\n28 的特征图。然后再做 3×3，步长为 1，same padding 卷积，生成 128 个 28×28 的特征\\n\\n图。\\n\\n第 3 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 16 个 28×\\n\\n28 的特征图。然后再做 5×5，步长为 1，same padding 卷积，生成 32 个 28×28 的特征\\n\\n图。\\n\\n第 4 个通道就是对输入特征做 3×3，步长为 1，same padding 的最大池化，生成 192\\n\\n个 28×28 的特征图。然后再做 1×1，步长为 1，same padding 卷积，生成 32 个 28×28\\n\\n的特征图。\\n\\n最后再把这 4 个通道分别得到的特征图组合起来，得到 64+128+32+32=256 个 28×\\n\\n28 的特征图。\\n\\n在 GoogleNet 中叠加了很多个 Inception 结构，使得网络的层数变得非常多，并且网络\\n\\n特征提取的能力特别强。\\n\\n10.4.3 GoogleNet 网络结构\\n\\n这一小节我们来具体看一下 GoogleNet 的网络结构，如图 10.12 所示。\\n\\n325\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n326\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.12 GoogleNet 网络结构[4]\\n\\n图中的 conv 表示卷积；MaxPool 表示最大池化；LocalRespNorm 表示局部响应归一\\n\\n化；DepthConcat 表示数据拼接；FC 表示全连接层；AveragePool 表示平均池化。\\n\\n我们就先从整体上来了解一下 GoogleNet，它是一个 22 层的网络，网络的输入跟\\n\\nVGGNet 一样也是 224×224。除了最后一层用的是 softmax 函数外，其它层的激活函数都\\n\\n是 ReLU 函数。我们可以看到 GoogleNet 的主要结构组成是 Inception module，一共叠加\\n\\n了 9 个 Inception。GoogleNet 网络的一些具体细节如图 10.13 所示。\\n\\n图 10.13 GoogleNet 结构细节[4]\\n\\n图中的 type 表示层的类型；patch size/stride 表示窗口大小/步长；output size 表示输\\n\\n出大小；depth 表示深度；params 表示参数数量；ops 表示计算量；convolution 表示卷\\n\\n积；max pool 表示最大池化；avg pool 表示平均池化；linear 表示全连接层。\\n\\n别看 GoogleNet 有 22 层之多，它的权值参数数量只有 600 多万，仅约为 AlexNet 的\\n\\n1/10，VGGNet 的 1/20。\\n\\n327\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nGoogleNet 的输入是 224×224×3 的彩色图片，从图中我们可以看到第一个卷积是 7×7\\n\\n步长为 2，卷积后得到 64 个 112×112 的特征图。卷积后进行了一次 3×3 步长为 2 的最大\\n\\n池化，得到 64 个 56×56 的特征图。\\n\\n接下来再进行一次 1×1 步长为 1 的卷积得到 64 个 56×56 的特征图，卷积后再进行 3×\\n\\n3 步长为 1 的卷积，得到 192 个 56×56 的特征图。这里我们要注意，图中第 3 行的卷积，\\n\\ndepth 为 2，说明这里是有 2 层卷积。图中的 reduce 其实是表示 1×1 卷积的意思，#3×3\\n\\nreduce 表示 3×3 卷积之前的 1×1 卷积。#5×5 reduce 表示 5×5 卷积之前的 1×1 卷积。\\n\\n卷积后再进行一次 3×3 步长为 2 的最大池化，得到 192 个 28×28 的特征图。\\n\\n下面我们看到了第一个 Inception 模块 inception(3a)，每个 inception 模块都有两层卷\\n\\n积，所有 depth 为 2。\\n\\n图中的信息还是很完整的，所以我们只要仔细看一下图中信息我们就可以知道\\n\\nGoogleNet 的网络结构了。中间部分的计算这里就省略不讲了，大家可以自己看。\\n\\n我们可以想一下，在之前的网络中卷积池化计算后得到很多特征图，最后我们还需要做\\n\\n全连接得到最后的分类结果。那么卷积池化计算后得到的特征图是一个 4 维的数据，所以我\\n\\n们还需要做一个“Flatten”，把 4 维数据变成 2 维，因为全连接必须是 2 维数据，AlexNet\\n\\n和 VGGNet 中都是这么做的。\\n\\nGoogleNet 的平均池化 avg pool 设计。我们看一下图中倒数第 4 行“avg pool”，\\n\\n这是平均池化，这个“avg pool”放在 inception(5b)后面，我们之前在介绍池化操作的时\\n\\n候有介绍过平均池化，不过在实际网络搭建中还没有介绍过。这里使用的“avg pool”，它\\n\\n的作用跟“Flatten”的作用其实类似，主要目的是把 4 维的特征图数据变成 2 维的数据，再\\n\\n跟后面的 1000 个分类神经元进行全连接。\\n\\n328\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\ninception(5b)的输出是 1024 个 7×7 的特征图，“avg pool”窗口大小为 7×7，所以\\n\\n也就是每个特征图求平均得到 1 个特征值，那么 1024 个特征图就可以提取出 1024 个特征\\n\\n值，最后再跟 1000 个神经元进行全连接。GoogleNet 的论文中有提到，把“Flatten”后连\\n\\n接 1024 个神经元改成“avg pool”得到 1024 个特征值，ImageNet Challenge 图像识别\\n\\n比赛 Top1 准确率提高了 0.6%[4]。另外使用“avg pool”还可以减少模型的权值数量，因为\\n\\n全连接层会产生大量权值，而池化计算是没有权值的。\\n\\nGoogleNet 的辅助分类器 auxiliary classifiers 设计。最后我还想再给大家介绍一下在\\n\\n图 10.13 中，GoogleNet 的网络有 3 个输出，中间部分的两个输出是 GoogleNet 设计的两\\n\\n个辅助分类器。作者引入的两个辅助分类器也会经过 softmax 函数后输出预测结果，预测结\\n\\n果跟真实标签做对比得到辅助损失 aux_loss，该模型总损失等于真实损失和辅助损失的加权\\n\\n和，论文中每个辅助损失使用的权重值是 0.3，总的 loss 公式如下：\\n\\n𝑡𝑜𝑡𝑎𝑙(cid:132)(cid:210)(cid:222)(cid:222) = 𝑟𝑒𝑎𝑙(cid:132)(cid:210)(cid:222)(cid:222) + 0.3 × 𝑎𝑢𝑥(cid:132)(cid:210)(cid:222)(cid:222)– + 0.3 × 𝑎𝑢𝑥(cid:132)(cid:210)(cid:222)(cid:222)(cid:157)\\n\\n这两个辅助分类器的作用是增加反向传播的梯度信号[4]，也就是说即使整个网络都是用了\\n\\nReLU 激活函数，但是网络的层的比较多（22 层），梯度信号在反向传递的过程中，还是会\\n\\n损失掉一些有用的信号。 所以作者在中间层加入两个辅助分类器，帮助中间层那部分的权值\\n\\n和靠近输入层那部分的权值更好的训练。\\n\\n辅助分类器只在模型训练阶段起作用，模型预测结果辅助分类器是不使用的。\\n\\n329\\n\\n(10.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.5 Batch Normalization\\n\\n在介绍后面新的一些网络模型之前，这小节我们先介绍一下 Batch Normalization，因为\\n\\n近几年很多网络中都使用了 Batch Normalization 技术。\\n\\nBatch Normalization 中文一般称为批量标准化/批量规范化/批量归一化等，本书中我\\n\\n们就称为批量标准化好了。Batch Normalization 英文的简称一般为 BatchNorm 或 BN，本\\n\\n书中我们就称为 BN 好了。BN 是 Google 研究员 Sergey Ioffe 和 Christian Szegedy 在\\n\\n2015 年提出的一种标准化策略。BN 提出以后，很多网络都使用了 BN 的技术。这里特别说\\n\\n明一下很多网络模型用了 BN 以后效果有所提升，但并不是所有模型用了 BN 就会更好，所\\n\\n以我们可以把它看成是一个很可能有效的网络优化策略。下面对 BN 的介绍主要是参考 BN\\n\\n的原始论文《Batch Normalization: Accelerating Deep Network Training by Reducing\\n\\nInternal Covariate Shift》[5]。我觉得 BN 虽然有效，但并不是一个很好理解的技术，如果\\n\\n大家看了以后不是特别理解的话也不用钻牛角钻尖，先接受它的作用，至于它的原理有时间\\n\\n再慢慢品。\\n\\n10.5.1 Batch Normalization 提出背景\\n\\nBN 的提出主要由于网络的内部协变量偏移（Internal Covariate Shift），简称 ICS。\\n\\nBN 作者在论文中给出了 ICS 一个比较规范的定义：在深度学习网络的训练过程中网络内部\\n\\n结点的分布变化称为内部协变量偏移[5]。其实说白了就是深度学习的深层网络之间的关系很\\n\\n复杂，每一层数据的微小变化都会随着网络一层一层的传递而被逐渐放大（类似于蝴蝶效\\n\\n应）。底层网络（假设靠近输入层的网络我们称为底层网络）输入的微小变化，就会引起高\\n\\n330\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n层网络（假设靠近输出层的网络我们称为高层网络）输入分布的剧烈变化，高层网络需要不\\n\\n断去重新适应底层网络的参数更新。这就使得网络训练起来比较困难，也比较慢。\\n\\n10.5.2 数据标准化（Normalization）\\n\\n在机器学习领域中，数据标准化是一种很常用的数据处理策略。通常就是对输入数据的\\n\\n每个维度的特征进行标准化。具体做法就是所有数据每个维度的特征减去该维度的平均值再\\n\\n除以该维度的标准差。\\n\\n𝑥˝@ =\\n\\n𝑥@ − 𝜇 √𝜎# + 𝜖\\n\\n𝑥@为某个特征维度的第 n 个值，𝜇为该维度的平均值，𝜎为该维度的标准差，𝜖为一个接近\\n\\n于 0 的常数防止分母为 0。如图 10.14 所示。\\n\\n图 10.14 数据标准化\\n\\n图中 a 有 5 个数据，每个数据有 4 个特征，每个特征的大小不一，经过标准化处理以后\\n\\n得到 b，b 中的数据都是在 0 附近的一些值，数值大小差不多。经过标准化以后的数据 b 每\\n\\n个特征的均值都是 0，方差为 1。标准化以后的数据可以消除特征尺度（有些特征数值比较\\n\\n大，有些特征数值比较小）对于模型训练的影响。并且 a 中特征之间的相关系数和 b 中特征\\n\\n之间的相关系数是一样的。特征之间的相关系数不会因为标准化而改变。\\n\\n331\\n\\n(10.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.5.3 Batch Normalization 模型训练阶段\\n\\n我们了解深度学习模型存在的 ICS 问题后，BN 作者提出了对神经网络每一层数据进行标\\n\\n准化处理的策略。普通的数据标准化只是对输入的样本数据进行标准化处理，然后再放入模\\n\\n型进行训练。而 BN 是对网络每一层的输入特征进行标准化处理，使得每一层的每个输入特\\n\\n征都是均值为 0，方差为 1 的分布。每一层标准化的公式都如同公式 10.2。\\n\\n在计算网络每一层的每个信号的均值和标准差的时候，我们并不是一次性把所有数据都\\n\\n传入模型进行计算。因为计算机内存大小有限，所以我们训练模型的时候通常都是对数据进\\n\\n行分批次 mini-batch 的训练。所以这里每层信号计算的均值和标准差都是针对一个批次\\n\\nmini-batch 来说的，所以这个算法的名字是 Batch Normalization。\\n\\n不过我们对每一层的输入信号做标准化处理可能会改变该层数据的表达。因为标准化处\\n\\n理会把一组数据变成另一组数据，每一组数据所包含的信息都是不同的，所以不能做完标准\\n\\n化处理就完事了。因此作者还对标准化后的数据进行了线性变换的处理：\\n\\n𝑦((cid:131)) = 𝛾((cid:131))𝑥˝((cid:131)) + 𝛽((cid:131))\\n\\n𝑥˝((cid:131))表示网络某一层第 k 维度进行标准化后的数值，𝑦((cid:131))表示𝑥˝((cid:131))线性变换后的结果，𝛾((cid:131))\\n\\n和𝛽((cid:131))表示网络某一层第 k 维度的两个参数。使用𝛾((cid:131))和𝛽((cid:131))这两个参数可以对数据进行线性\\n\\n变换。每一层网络的每一个维度都会有不同的𝛾和𝛽，𝛾和𝛽的具体数值是由网络训练得到的，\\n\\n不是人为设置的。\\n\\n比如网络某一层某个特征 x，该特征的 mini-batch 计算得到的平均值是𝜇，标准差是𝜎。\\n\\nx 进行标准化后得到𝑥˝，𝑥˝经过线性变换后得到 y。那么有一个比较特别的结果，当𝛾 = 𝜎，并\\n\\n且𝛽 = 𝜇时线性变换后的结果 y 刚好等于标准化之前的特征 x。也就是作者设计的线性变换的\\n\\n计算实际上是可以恢复原始数据的表达的，不过一般不会这么巧，毕竟𝛾和𝛽是通过模型训练\\n\\n332\\n\\n(10.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n得到的。不管怎么说，𝛾和𝛽还是可以一定程度上起到恢复数据表达能力的作用。每层数据标\\n\\n准化和线性变换的计算流程如图 10.15 所示。\\n\\n图 10.15 BN 计算流程[5]\\n\\n图中内容就是我们前面讲的流程，先对数据进行标准化，然后再做线性变换。\\n\\n10.5.4 Batch Normalization 模型预测阶段\\n\\n模型训练阶段我们已经介绍完了，主要就是对每一层数据进行标准化处理和线性变换后\\n\\n再传入下一层，模型训练好之后我们就把每一层每个维度的𝛾和𝛽训练好了。那么在模型预测\\n\\n阶段我们也要对每一层的特征进行标准化处理，不过在测试阶段我们可能只传入一个数据进\\n\\n行预测，只有一个数据的话计算均值和标准差就没有意义了。所以在模型测试阶段使用的均\\n\\n值和标准差的数据其实是使用训练集数据计算得到的。\\n\\n在模型训练阶段，我们会分批次训练模型，每一个批次在网络的每一层的每个特征都可\\n\\n以计算出该批次的特征均值𝜇和特征方差𝜎#。我们在训练阶段把所有批次的特征均值和特征\\n\\n方差都保存下来，然后计算出所有特征均值的均值𝐸[𝜇]和所有特征方差的均值𝐸[𝜎#]，再把\\n\\n𝐸[𝜇]和𝐸[𝜎#]应用到预测阶段的标准化计算中。\\n\\n333\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n每一层的特性𝑥先减去用训练集数据计算得到的均值𝐸[𝜇]，再除以用训练集数据计算得到\\n\\n的标准差g𝐸[𝜎#] + 𝜖，再做线性变换乘以𝛾加上𝛽，公式如下：\\n\\n𝑦 =\\n\\n𝑥 − E[𝜇]\\n\\ng𝐸[𝜎2] + 𝜖\\n\\n𝛾 + 𝛽\\n\\n10.5.5 Batch Normalization 作用分析\\n\\n在 BN 的原始论文中作者总结了 BN 的很多作用，不过我觉得 BN 的主要作用可以简化的\\n\\n总结为：\\n\\n1.加快模型训练速度。这个作用不需要多说，加快模型训练速度可以节约很多模型训练\\n\\n的时间。\\n\\n2.具有一定正则化作用。使用了 BN 可以减少 Dropout 的使用，甚至不用 Dropout，并\\n\\n且可以减少 L2 正则化的使用。\\n\\n3.有机会使得模型效果更好。这个效果不是绝对的，不过很多模型使用了 BN 之后效果确\\n\\n实变得更好了，所以 BN 值得一试。\\n\\n在《Batch Normalization: Accelerating Deep Network Training by Reducing\\n\\nInternal Covariate Shift》论文中，还使用了 ImageNet 数据集对 BN 的效果做了一些实验\\n\\n分析，如图 10.16 所示。\\n\\n334\\n\\n(10.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.16 BN 实验分析[5]\\n\\n图中的准确率是使用 ImageNet 验证集计算得到的，由于这里计算的是 Top1 准确率，\\n\\n所以这些模型都没有到 80%。\\n\\nInception 就是 GoogleNet，学习率为 0.0015。这个模型差不多是当时最好的图像识别\\n\\n模型了。\\n\\nBN-Baseline 为加上了 BN 的 Inception，其它训练参数一致。我们可以看到，加上 BN\\n\\n后模型训练速度快了很多。\\n\\nBN-x5 跟 BN-Baseline 结构一样，只不过学习率是 Inception 的 5 倍，为 0.0075。我\\n\\n们可以看到，学习率变大以后，模型训练得更快了。（如果没有使用 BN 的话，学习率不能\\n\\n设置得太大，会使得模型调整太剧烈，导致模型无法训练或者训练的效果不好）\\n\\nBN-x30，跟 BN-Baseline 结构一样，只不过学习率是 Inception 的 30 倍。我们可以看\\n\\n到更大的学习率不能使得模型更快，虽然加上 BN 以后学习率可以设置得大一些，但是也不\\n\\n能太大。\\n\\nBN-x5-Sigmoid 跟 BN-x5 类似，只不过激活函数用的是 Sigmoid 函数（其它模型都是\\n\\n用 ReLU 函数）。不用 BN 的话 Sigmoid 在 GoogleNet 中是无法使用的，由于梯度消失会\\n\\n335\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n使得模型无法训练。用了 BN 以后连 Sigmoid 函数也 work 起来了，虽然最后的模型效果还\\n\\n是不太理想。\\n\\nSteps to match Inception 表示这几个模型达到同一准确率的位置。\\n\\n几个模型的训练结果如图 10.17 所示。\\n\\n图 10.17 几个模型训练结果[5]\\n\\n图中的 Model 表示模型；Mac accuracy 表示最大准确率。\\n\\n从模型训练结果可以看出加上了 BN 的模型训练速度都比较快。训练结果最好的是 BN-\\n\\nx30，最差的是 BN-x5-Sigmoid，说明给模型加上 BN 以后有可能会得到更好的结果。\\n\\nBN 的作者融合了 6 个 BN-x30 模型，在 ImageNet 的验证集得到了 4.9%的 Top5 错误\\n\\n率，在测试集得到了 4.82%的 Top5 错误率，在当时应该是 ImageNet 数据集最好的结果\\n\\n了。\\n\\n10.6 ResNet\\n\\nResNet 是 2015 年 ImageNet Challenge 图像识别比赛的冠军，由微软亚洲研究院\\n\\n(MSRA)的研究团队完成，团队的负责人为何恺明。ResNet 的论文获得了 2016 年\\n\\nCVPR(IEEE Conference on Computer Vision and Pattern Recognition)的最佳论文，并\\n\\n336\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n且是 2019 年机器学习领域被引用次数最多的论文，达到了 18000 多次。下面对 ResNet 的\\n\\n思路进行介绍，主要是参考论文《Deep Residual Learning for Image Recognition》[6]。\\n\\n10.6.1 ResNet 背景介绍\\n\\n在介绍 ResNet 网络之前我们先介绍一下何恺明，因为他是目前计算机视觉领域最知名\\n\\n最活跃的专家之一，其代表作 ResNet 更是一鸣惊人。\\n\\n何恺明在广州长大，从小就是好学生，2003 年保送清华大学。即便如此他还是参加了广\\n\\n东省高考，得到了 900 分满分的成绩。\\n\\n2007 年何恺明进入微软亚洲研究院(MSRA)的视觉计算组实习，实习导师是孙剑（现旷\\n\\n视科技首席科学家），当时视觉计算组的负责人是汤晓鸥（商汤科技创始人）。\\n\\n2011 年香港中文大学博士毕业后正式加入 MSRA 。\\n\\n2016 年 8 月，何恺明离开微软亚洲研究院，加入 Facebook AI 研究院（FAIR）。\\n\\n2020 年 1 月 11 日，荣登 AI 全球最具影响力学者榜单。\\n\\n观察 ImageNet Challenge 前几届的优秀模型，我们不难发现一个现象，似乎模型的层\\n\\n数越多，效果就越好。AlexNet 有 8 层，VGG19 有 19 层，GoogleNet 有 22 层。于是\\n\\nResNet 团队就做了一个实验，他们模仿 VGGNet 的模型，分别设计了 20，32，44，56 层\\n\\n的网络，并使用 CIFAR-10 数据集进行测试，测试结果如图 10.18 所示。\\n\\n337\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.18 不同深度的网络结果对比\\n\\n图中的 iter 表示迭代次数，error 表示误差。\\n\\n《Deep Residual Learning for Image Recognition》论文中把模仿 VGGNet 做出来的\\n\\n一些模型称为“plain network”。实验结果表明，20 层的网络误差最低，56 层的网络误差\\n\\n最高，并且层数越多误差越大，实验结果刚好是跟我们前面的猜想是相反的。\\n\\n网络层数不是太多的时候，模型的正确率确实会随着网络的层数增加而提升，不过随着\\n\\n网络层数的增加，正确率也会达到饱和，这个时候如果再继续增加网络层数，那么正确率就\\n\\n会下降。ResNet 论文中把这种现象称为退化问题（Degradation Problem），并且\\n\\nResNet 作者认为退化问题不是由过拟合引起的。\\n\\n10.6.2 残差块（Residual Block）介绍\\n\\nResNet 之所以叫残差网络（Residual Network），是因为 ResNet 是由很多残差块\\n\\n（Residual Block）组成。而残差块的使用，可以解决前面说到的退化问题。残差块如图\\n\\n10.19 所示。\\n\\n338\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.19 残差块（Residual Block）[6]\\n\\n图中的 weight layer 是 3×3 的卷积层，F(x)表示经过两个卷积层计算后得到的结果，\\n\\nidentity 表示“恒等映射”也称为“shortcut connections”，说白了就是把 x 的值不做任\\n\\n何处理直接传过去。最后计算 F(x)+x，这里的 F(x)跟 x 是 shape 相同的信号，所以可以进行\\n\\nelement-wise addition，也就是对应位置进行相加。\\n\\n图 10.20 也是相同的残差块，加上了 BN 层。\\n\\n图 10.20 加上 BN 层的残差块\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化。\\n\\n残差块可以有多种设计方式，比如改变残差块中卷积层的数量，或者残差块中卷积窗口\\n\\n的大小，或者卷积计算后先 ReLU 后 BN，就像是搭积木一样，我们可以随意设置。ResNet\\n\\n研究团队经过很多的测试最终定下了两种他们觉得最好的残差块的结构，如图 10.21 所示。\\n\\n图 10.21 两种残差块结构[6]\\n\\n339\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 1×1，3×3 表示卷积窗口大小，64 和 256 表示特征图数量，注意这里的图片是\\n\\n作者给出的示意图，真正搭建模型的时候特征图数量不一定是图中的 64 和 256。图中左边\\n\\n的残差结构有 2 个卷积层前面我们已经见过，右边的残差结构有 3 个卷积层，加上 BN 层后\\n\\n如图 10.22 所示。\\n\\n图 10.22 3 层残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化。\\n\\nResNet 也有很多个版本，比如 ResNet18，ResNet34，ResNet50，ResNet101，\\n\\nResNet152 等，不同的数字表示不同的网络层数，18 就是 18 层，152 就是 152 层。作者\\n\\n在搭建不同版本的 ResNet 的时候使用了不同的残差结构，ResNet18 和 ResNet34 用的是\\n\\n2 层卷积的残差结构，ResNet50，ResNet101，ResNet152 用的是 3 层卷积的残差结构。\\n\\n残差结构的主要作用是传递信号，把深度学习浅层的网络信号直接传给深层的网络。深\\n\\n度学习中不同的层所包含的信息是不同的，一般我们认为深层的网络所包含的特征可能对最\\n\\n后模型预测更有帮助，但是并不是说浅层的网络所包含的信息就没用，深层网络的特征就是\\n\\n从浅层网络不断提取而得到的。现在我们给网络提供一个“捷径”也就是“shortcut\\n\\nconnections”，它可以直接将浅层信号传递给深层网络，跟深层网络的信号结合，来帮助\\n\\n网络得到更好的效果。\\n\\n10.6.3 ResNet 网络结构\\n\\n图 10.23 中有 3 个网络结构，左边为 VGG19，中间为模仿 VGGNet 设计的 34 层 plain\\n\\nnetwork，右边为 ResNet34。\\n\\n340\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n341\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.23 ResNet 网络结构[6]\\n\\n图中的 conv 表示卷积；pool 表示池化；fc 表示全连接层；avg pool 表示平均池化；\\n\\noutput size 表示输出大小；image 表示图片。\\n\\nVGG19 和 plain network 大家自己看看就行，仔细看看就能看懂。plain network 中有\\n\\n个地方要注意，plain network 没有使用 pooling 层（池化层不一定要使用）。在网络中有\\n\\n几个位置我们可以看到“7×7conv，64，/2”，“3×3conv，128，/2”，“3×3conv，\\n\\n256，/2”，“3×3conv，512，/2”。这里的 7×7 和 3×3 表示卷积窗口大小；\\n\\n65/128/256/512 表示卷积后生成多少特征图；/2 表示卷积的步长为 2，卷积后特征图的长\\n\\n宽都会变为原来的 1/2。最后的 avg pool 为平均池化，是模仿 GoogleNet 的设计。\\n\\n我们重点来看看 ResNet34，ResNet34 是从 34 层的 plain network 改进得来的，结构\\n\\n上跟 34 层的 plain network 非常相似。主要区别是 ResNet34 增加了“shortcut\\n\\nconnections”，由 16 个 2 层的残差结构堆叠而成。不过我们发现“shortcut\\n\\nconnections”分为实线和虚线，实线表示残差结构的输入 x 与残差结构中卷积计算结果\\n\\nF(x)的 shape 是一样的，可以直接进行对位相加，具体例子如图 10.24 所示。\\n\\n图 10.24 实线“shortcut connections”例子\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化，batch 表示批次。\\n\\n虚线“shortcut connections”表示无法直接进行对位相加的接连。我们可以发现虚线\\n\\n部分的残差块输入 x 和残差结构中卷积计算结果 F(x)的 shape 是不一致的，输入 x 的特征图\\n\\n342\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n数量是 F(x)特征图数量的 1/2，并且输入 x 的特征图长宽是 F(x)特征图长宽的 2 倍。虚线\\n\\n“shortcut connections”在 ResNet 论文中给出了 A，B 两种连接方式。\\n\\nA．zero-padding。先做步长为 2 的恒等映射，新增的特征图用 0 填充。ResNet 一般\\n\\n不用这种方式，论文中没有写明白具体的操作，网上的资料也比较少，所以下面 zero-\\n\\npadding 的操作主要来自我的推测，如图 10.25 表示 1 张特征图进行步长为 2 的 Identity\\n\\nmapping：\\n\\n图 10.25 步长为 2 的恒等映射\\n\\n图中的 Identity 表示恒等映射，Stride 表示步长。\\n\\n图 10.26 表示多张特征图步长为 2 的恒等映射，特征图变成原来的 2 倍，新增的特征图\\n\\n用 0 填充：\\n\\n343\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.26 Identity mapping+zero-padding\\n\\n图中的 Identity 表示恒等映射。\\n\\n图 10.27 表示 zero-padding 的“shortcut connections”在 ResNet 中使用的具体例\\n\\n子：\\n\\n图 10.27 zero-padding\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；batch 表示批次；Identity\\n\\nmapping 表示恒等映射。\\n\\nZero-padding 的好处是计算简单并且不需要给网络增加额外的权值，同时也可以得到较\\n\\n好的效果。\\n\\nB．projection shortcut。ResNet 作者把第二种方式称为“projection shortcut”，\\n\\n具体做法是用步长为 2，大小为 1×1 的卷积来对残差块的输入信号 x 进行特征提取，使 x 信\\n\\n号和 F(x)信号的 shape 一致。ResNet 通常都是使用 projection shortcut 的方法，如图\\n\\n10.28：\\n\\n344\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.28 步长为 2，1×1 卷积\\n\\n图中的 conv 表示卷积。\\n\\n图 10.29 表示 projection shortcut 的“shortcut connections”在 ResNet 中使用的具\\n\\n体例子：\\n\\n图 10.29 projection shortcut\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；batch 表示批次。\\n\\n相比于 zero-padding，使用 projection shortcut 可以让模型获得更好的效果。另外作\\n\\n者还提出了另外一种 shortcut 连接方案“all shortcuts are projections”。\\n\\nC．all shortcuts are projections。顾名思义，也就是 ResNet 中所有的 shortcuts，\\n\\n不管是没有特征图数量增加的实线 shortcut，还是有特征图数量增加的虚线 shortcut，都使\\n\\n用带 1×1 卷积的 projection shortcut 来进行连接。\\n\\nResNet 作者使用 imagenet 数据集对 A，B，C 三种 shortcut 方式进行了评估，结果如\\n\\n图 10.30 所示。\\n\\n图 10.30 三种 shortcut 方式评估[6]\\n\\n345\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 model 表示模型；top-1 err.表示 top1 错误率；top-5 err.表示 top5 错误率。\\n\\n图中的 ABC 分别表示前面我们提到的三种 shortcut 方式，ResNet-50，ResNet-101，\\n\\nResNet-152 用的是 B(projection shortcut)的方式。我们从实验结果可以看出，C 方案比 B\\n\\n方案稍微好一点点，B 方案比 A 方案稍微好一点点。C 方案需要给网络增加较多的计算量和\\n\\n权值参数，B 方案需要给网络增加一点计算量和权值参数，C 方法不需要额外的权值参数。\\n\\nResNet 作者基于综合情况考虑，最终选择在模型中使用了 B 方案。所以我们现在看到的\\n\\nResNet 模型一般都是使用 B(projection shortcut)的方式，一般的残差块都是 identity\\n\\nmapping 恒等映射，只有特征图数量改变的时候使用 projection shortcut。\\n\\nResNet 团队最终在 2015 年 ImageNet Challenge 图像识别比赛中，融合了 6 个不同\\n\\n深度的 ResNet 模型，得到了 3.57%的 top5 测试集错误率，获得了当年比赛的冠军。图\\n\\n10.31 为不同模型的测试结果。\\n\\n图 10.31 不同模型的测试结果[6]\\n\\n图中的 method 表示模型，top-5 err. (test)表示测试集 top5 错误率。\\n\\n10.6.4 ResNet-V2\\n\\n2016 年，何恺明所在的 ResNet 团队又发表了一篇关于 ResNet 的论文《Identity\\n\\nMappings in Deep Residual Networks》。在这篇论文中，他们提出了一种关于 ResNet\\n\\n的结构优化，并表示新的 ResNet 结构可以让 ResNet 获得更好的效果。我们一般把\\n\\n346\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n《Identity Mappings in Deep Residual Networks》[7]这篇论文中提到的 ResNet 结构称\\n\\n为 ResNet-V2，如图 10.32 所示。\\n\\n图 10.32 残差结构优化[7]\\n\\n图中的 Iterations 表示迭代次数；Test Error 表示测试集错误率。\\n\\n(a)original 表示原始的 ResNet 的残差结构，(b)proposed 表示新的 ResNet 的残差结\\n\\n构。主要差别就是(a)结构先卷积后进行 BN 和激活函数计算，最后执行 addition 后再进行\\n\\nReLU 计算；(b)结构先进行 BN 和激活函数计算后卷积，把 addition 后的 ReLU 计算放到了\\n\\n残差结构内部。作者使用这两种不同的结构在 CIFAR-10 数据集上做测试，模型用的是 1001\\n\\n层的 ResNet 模型。从图中结果我们可以看出，(b)proposed 的测试集错误率明显更低一\\n\\n些，达到了 4.92%的错误率，(a)original 的测试集错误率是 7.61%。\\n\\n其实 ResNet 团队对 ResNet 的残差结构做了很多不同的尝试，如图 10.33 所示。\\n\\n347\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.33 shortcut 结构的不同尝试[7]\\n\\n图中(a),(b),(c),(d),(e),(f)都是作者对残差结构的 shortcut 部分进行的不同尝试，这里我\\n\\n们就不具体介绍了，因为作者对不同 shortcut 结构的尝试结果如图 10.34 所示。\\n\\n图 10.34 不同 shortcut 结构的测试结果[7]\\n\\n作者用不同 shortcut 结构的 ResNet-110 在 CIFAR-10 数据集上做测试，发现最原始的\\n\\n(a)original 结构是最好的，也就是 identity mapping 恒等映射是最好的。\\n\\n然后作者又对残差结构的残差单元进行了不同的尝试，如图 10.35 所示。\\n\\n348\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.35 不同残差单元测试结果[7]\\n\\n最好的结果是(e)full pre-activation，其次到(a)original。(a)original 的残差结构是应用\\n\\n在最原始的 ResNet 中的残差结构；(e)full pre-activation 的残差结构就是我们前面介绍的\\n\\nResNet-V2 中的残差结构。\\n\\n从 ResNet 的设计和发展过程中我们可以知道，深度学习是一门非常注重实验的学科，\\n\\n我们需要有创新的好想法，同时也需要大量的实验来支撑和证明我们的想法。有些时候我们\\n\\n无法从理论上推断哪种模型设计或优化方法是最好的，这个时候我们可能就需要做大量的实\\n\\n验来不断尝试，找到最好的结果。如今 ResNet 已经得到广泛的应用和肯定，对深度学习和\\n\\n计算机视觉做出了重要贡献。\\n\\n经典图像识别模型介绍下一章继续。\\n\\n10.7 参考文献\\n\\n[1] Russakovsky O , Deng J , Su H , et al. ImageNet Large Scale Visual Recognition\\n\\nChallenge[J]. International Journal of Computer Vision, 2015, 115(3):211-252.\\n\\n349\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[2] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\n\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n\\n[3]Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for\\n\\nLarge-Scale Image Recognition[J].\\n\\n[4]Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n\\n[5] Ioffe S , Szegedy C . Batch Normalization: Accelerating Deep Network Training by\\n\\nReducing Internal Covariate Shift[J]. 2015.\\n\\n[6] He K , Zhang X , Ren S , et al. Deep Residual Learning for Image Recognition[C]//\\n\\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE\\n\\nComputer Society, 2016.\\n\\n[7] He K , Zhang X , Ren S , et al. Identity Mappings in Deep Residual Networks[J].\\n\\n2016.\\n\\n350\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 11 章-经典图像识别模型介绍（下）\\n\\n这一章节我们继续介绍经典图像识别模型。\\n\\n11.1 Inception 模型系列\\n\\nInception 的前身就是前面我们介绍过的 GoogleNet，GoogleNet 中提出了一个多种尺\\n\\n度同时进行特征提取的结构称为 Inception，所以 GoogleNet 后来改名变成了 Inception-\\n\\nv1。Google 的团队后来在 Inception-v1 的基础上做了更多的研究和优化，提出了\\n\\nInception-v2，Inception-v3，Inception-v4，Inception-ResNet-v1，Inception-\\n\\nResNet-v2 多个优化版本。\\n\\n11.1.1 Inception-v2/v3 优化策略\\n\\nInception-v2 和 Inception-v3 都出自同一篇论文《Rethinking the inception\\n\\narchitecture for computer vision》[1]。该论文提出了多种基于 Inception-v1 的模型优化\\n\\n方法，Inception-v2 用了其中的一部分模型优化方法，Inception-v3 用了论文中提到的所有\\n\\n优化方法。相当于 Inception-v2 只是一个过渡版本，Inception-v3 一般用得更多。下面我\\n\\n们主要针对论文中所涉及的一些比较重要的优化方法进行讲解，具体是用在 Inception-v2 还\\n\\n是 Inception-v3 就不做详细区分了，可以都看成是 Inception-v3 的内容。顺便说一下之前\\n\\n我们学过的标签平滑（Label Smoothing）就是出自 Inception-v3 的论文。\\n\\nInception-v3 最大的优化是模型结构上的优化，在 Inception-v3 中作者对 Inception 结\\n\\n构中的卷积进行了分解。分解后的好处是增加了网络的层数，也就是增加了网络的特征提取\\n\\n351\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n能力。同时作者还对 Inception 结构进行了一些调整，设计了不同的 Inception，用在模型\\n\\n的不同位置。\\n\\n我们先回忆一下最原始的 Inception 结构，如图 11.1 所示。\\n\\n图 11.1 原始 Inception 结构[1]\\n\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\n\\npooling 表示最大池化，previous layer 表示前一层。\\n\\nInception-v3 中提出了一个新思路，可以使用两个 3×3 卷积来替代原始 Inception 结构\\n\\n中的 5×5 卷积，如图 11.2 所示。\\n\\n图 11.2 分解 5×5 卷积\\n\\n将 5×5 卷积分解为两层的 3×3 卷积，对于最后得到的特征来说，感受野的大小是相同\\n\\n的，都是 5×5 的区域。相当于 5×5 卷积对 5×5 区域进行特征提取，得到一个特征值；两层\\n\\n352\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的 3×3 卷积对 5×5 区域进行特征提取，也是得到一个特征值。这两种特征提取的方式类\\n\\n似，不过最后得到的特征值可能是不同的，右边的两层 3×3 卷积做了两次卷积得到的特征值\\n\\n或许会更好一些。\\n\\n沿着这个卷积分解的思路继续思考，作者又提出了一种新的卷积分解，把 3×3 卷积分解\\n\\n为 1×3 卷积和 3×1 卷积，如图 11.3 所示。\\n\\n图 11.3 分解 3×3 卷积\\n\\n把 3×3 卷积分解为 1×3 卷积和 3×1 卷积，道理跟将 5×5 卷积分解为两层的 3×3 卷积\\n\\n差不多，对于最后的特征来说，感受野的大小是一样的，并且分解后可以让网络层数变得更\\n\\n多，增加网络的非线性。理论上 n×n 的卷积都可以分解为 1×n 卷积和 n×1 卷积。\\n\\n作者还分析了减小特征图大小时的操作，如图 11.4 所示。\\n\\n图 11.4 减小特征图大小的操作[2]\\n\\n353\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图片 Pooling 表示池化。\\n\\n作者认为直接使用窗口大小 2×2，步长为 2 的池化来压缩特征图的大小效果不太好。因\\n\\n为特征图的数量不变，但是特征图的长宽变成为原来的 1/2，相当于特征值的数量被压缩为\\n\\n原来的 1/4 了，特征值的数量一下减少太多不利于模型的训练，所以左边的结构不太理想。\\n\\n右边的结构先用 Inception 来增加特征图数量然后再进行池化减小特征图大小，对于特征的\\n\\n提取来说没什么问题，就是计算量太大。\\n\\n所以设计了新的 Inception 结构，在减小特征图大小的同时可以增加特征图的数量，如\\n\\n图 11.5 所示。\\n\\n图 11.5 用于减小特征图大小并增加特征图数量[2]\\n\\n图中 Filter Concat 表示滤波器拼接；stride 表示步长；concat 表示拼接；conv 表示卷\\n\\n积；pool 表示池化。\\n\\n除此之外作者还根据实验分析和建模经验，设计了一些新的 Inception 结构，如图 11.6\\n\\n所示。\\n\\n354\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.6 一些新的 Inception 结构[2]\\n\\n图中 Filter Concat 表示滤波器拼接；Pool 表示池化。\\n\\n这些不同的 Inception 结构就像搭积木一样堆叠起来，组成了 Inception-v3 的模型。\\n\\n11.1.2 Inception-v2/v3 模型结构\\n\\nInception-v2/v3 模型的结构非常庞大，Inception-v2/v3 论文中给出的模型结构描述也\\n\\n不是特别清晰，结构如图 11.7 所示。\\n\\n355\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.7 Inception-v2/v3 模型结构[2]\\n\\n图中 architecture 表示结构；Filter Concat 表示滤波器拼接；Pool 表示池化；type 表\\n\\n示层的类型；patch size/stride or remarks 表示窗口大小/步长；input size 表示输入大\\n\\n小；conv 表示卷积；pool 表示池化；linear 表示全连接层。\\n\\n图中 Inception-v2/v3 的结构大家应该能大致看懂，但是好像又看不太懂。那么要如何\\n\\n把 Inception-v2/v3 结构在书里表示清楚，让大家能看懂，我想了很久。其实要把\\n\\nInception-v2/v3 结构图画出来不难，难的是怎么在书里画出来，书这个信息载体对长图片\\n\\n的支持不太友好。最后我想到了一个比较清晰简洁，在书里看起来也相对比较友好的画结构\\n\\n图的方法——“方块构图法”（我瞎起的名字）。我画的这个结构跟论文中描述的结构细节\\n\\n上有些许不同，我是参考 tensorflow.keras.applications.inception_v3 中的结构画的，\\n\\nInception-v2/v3 结构图如图 11.8 所示。\\n\\n356\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n357\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n358\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.8 Inception-v2/v3 结构图\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；AvgPool 表示平均池化；Concat 表\\n\\n示拼接；FC 表示全连接层；V 表示 Valid Padding。\\n\\n相信这个结构图大家应该是很容易看懂的，我只需要稍微提几个注意事项：\\n\\n1. 图中卷积和池化默认的步长是 1 所以没有写出来。如果有“/2”表示步长为 2。\\n\\n2. 图中卷积和池化默认都是 same padding 所以没有写出来。如果有“V”表示 valid\\n\\npadding。\\n\\n3. 每个卷积层后面有 BN 和 ReLU，图中省略了。\\n\\n359\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4. Inception-ABCD 表示论文中提到的几种不同类似的 Inception 模型，不过并不是跟\\n\\n论文中完全一致。\\n\\n最后我们来看一下 Inception-v3 在 ImageNet 数据集中的测试结果，图 11.9 为\\n\\nInception-v3 单模型测试结果。\\n\\n图 11.9 Inception-v3 单模型测试结果[2]\\n\\n图中 Network 表示网络；Crops Evaluated 表示模型评估时裁剪出多少张图片进行预\\n\\n测；Top-5 Error 表示 Top5 错误率；Top-1 Error 表示 Top1 错误率。\\n\\n图 11.10 为 Inception-v3 模型融合后的测试结果。\\n\\n图 11.10 Inception-v3 模型融合后测试结果[2]\\n\\n图中 Network 表示网络；Models Evaluated 表示评估时集成了几个模型；Crops\\n\\nEvaluated 表示模型评估时裁剪出多少张图片进行预测；Top-5 Error 表示 Top5 错误率；\\n\\nTop-1 Error 表示 Top1 错误率。\\n\\n360\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nInception-v3 模型融合后的 Top5 错误率为 3.58%，这个结果跟 2015 年 ImageNet\\n\\nChallenge 图像识别比赛的冠军 ResNet 已经非常接近，ResNet 的 Top5 错误率为\\n\\n3.57%。\\n\\n11.1.3 Inception-v4 和 Inception-ResNet 介绍\\n\\nInception-v3 结构的复杂程度以后够复杂了，但是它还有几个升级版本，就是\\n\\nInception-v4，Inception-ResNet-v1 和 Inception-ResNet-v2。这几个升级版本都出自同\\n\\n一篇论文《Inception-v4, Inception-ResNet and\\n\\nthe Impact of Residual Connections on Learning》[3]。\\n\\n这几个升级版的 Inception 模型基本设计思路都是遵循 Inception-v3 的设计思路，只不\\n\\n过比 Inception-v3 再稍微更复杂一些。Inception-v4 的作者不认同非常深层的网络一定要\\n\\n使用残差单元才行，所以他们设计了没有使用残差单元的深度网络 Inception-v4，我大概数\\n\\n了一下论文中的 Inception-v4 结构，应该是有 76 层。不过 Inception-v4 的作者认同加上\\n\\n残差单元以后，模型可以训练得更加快一些。\\n\\nInception-ResNet-v1 和 Inception-ResNet-v2 顾名思义就是 Inception 的设计加上\\n\\nResNet 的残差结构设计得到的模型。\\n\\n由于 Inception-v4，Inception-ResNet-v1 和 Inception-ResNet-v2 的结构设计跟\\n\\nInception-v3 差别不大，并且使用一次“方块构图法”消耗的体力太多，所以这几个模型的\\n\\n具体网络结构就不给大家展示了。下面使用论文中的一些图给大家展示一下 Inception-v4 和\\n\\nInception-ResNet-v2 的结构，大家大致看一下即可，图 11.11 为 Inception-v4 的结构图.\\n\\n361\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.11 Inception-v4 结构图[3]\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；Output 表示输出；Input 表示输入；\\n\\nFilter concat 表示滤波器拼接；Avg Pooling 和 Average Pooling 表示平均池化；stride 表\\n\\n示步长。\\n\\nInception-v4 延续了 Inception-v3 的设计并进行了一些优化，主要也是使用多个不同的\\n\\nInception 结构堆叠得到深层的网络模型。\\n\\n362\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.12 为 Inception-ResNet-v2 结构图。\\n\\n图 11.12 Inception-ResNet-v2 结构[3]\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；Output 表示输出；Input 表示输入；\\n\\nFilter concat 表示滤波器拼接； Average Pooling 表示平均池化；stride 表示步长。\\n\\nInception-ResNet-v2 的结构特殊之处就是把 Inception 和残差单元的设计结合到了一\\n\\n起变成了 Inception-resnet 模块。\\n\\n363\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.13 为 4 个 Inception 模型在 ImageNet 数据集中，单模型 Top5 错误率的测试结\\n\\n果。\\n\\n图 11.13 4 种 Inception 模型在 ImageNet 数据集测试结果[3]\\n\\n图中的 Epoch 表示训练周期；Error 表示误差。\\n\\n从图中我们可以看到 Inception-v3 和 Inception-ResNet-v1 效果是差不多的，可能\\n\\nInception-ResNet-v1 稍微好一点点。Inception-v4 和 Inception-ResNet-v2 效果是差不\\n\\n多的，可能 Inception-ResNet-v2 稍微好一点点。\\n\\n图 11.14 为几个模型在 ImageNet 数据集中单模型测试结果。\\n\\n图 11.14 几个不同模型的单模型测试结果[3]\\n\\n图中的 Network 表示网络；Crops 表示从一张图片中裁剪出多少张图片；Top-1 Error\\n\\n表示 Top1 错误率；Top-5 Error 表示 Top5 错误率。\\n\\n364\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nCrops 中的 dense 表示直接对一张测试图片进行预测，得到一个预测结果。Crops 中的\\n\\n144 表示从一张测试图片中按照一定的规则裁剪出 144 个子区域，然后对这 144 个区域分别\\n\\n进行预测得到 144 个预测结果，最后再对这 144 个预测结果求平均得到最终的一个预测结果\\n\\n[4]。\\n\\n图 11.15 为模型融合的测试结果。\\n\\n图 11.15 模型融合的测试结果[3]\\n\\n图中的 Network 表示网络；Models 表示集成的模型数量；Top-1 Error 表示 Top1 错\\n\\n误率；Top-5 Error 表示 Top5 错误率。\\n\\n使用 1 个 Inception-v4 和 3 个 Inception-ResNet-v2 模型进行融合，在 ImageNet 的\\n\\n验证集中得到了 3.1%的 Top5 错误率，在 ImageNet 的测试集中得到了 3.08%的 Top5 错\\n\\n误率，这个结果已经比 ResNet 的模型融合后的结果更好了。\\n\\n11.2 ResNeXt\\n\\nResNeXt 获得了 2016 年 ImageNet Challenge 图像识别比赛的亚军。是由来自加州大\\n\\n学圣地亚哥分校(UCSD)和 Facebook AI Research(FAIR)的团队完成。名字中的“Res”表\\n\\n示“ResNet”，名字中的“NeXt”表示“next dimension”，在 ResNeXt 的论文中\\n\\n“next dimension”被称为“cardinality dimension”。作者提出把 cardinality 作为深度\\n\\n学习网络中的一个新参数，就像是网络的深度（网络的层数），宽度（特征图数量）一样。\\n\\n365\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n最早提出 ResNeXt 的论文是《Aggregated Residual Transformations for Deep Neural\\n\\nNetworks》[5]。在介绍 ResNeXt 之前，我们先来了解一下 ResNeXt 网络中的核心内容，分\\n\\n组卷积(Group Convolution)。\\n\\n11.2.1 分组卷积（Group Convolution）介绍\\n\\n分组卷积是一种特殊的卷积，最早应该是用在 AlexNet 网络中，AlexNet 的原始结构分\\n\\n为上下两部分，我们可以看成是上下两个通道或者是上下两个分组，如图 11.16 所示。\\n\\n图 11.16 AlexNet 结构[6]\\n\\n图中的 Stride 表示步长；Max Pooling 表示最大池化；dense 表示全连接层。\\n\\nAlexNet 使用分组卷积主要是当时软硬件条件比较受限，AlexNet 团队想用两个 GPU 来\\n\\n加速模型模型，一个 GPU 运行上面分组的卷积计算，一个 GPU 运行下面分组的卷积计算。\\n\\n所以在 AlexNet 中使用这样的分组卷积设计并不是他们的本意，更多的是巧合。不过有实验\\n\\n证明当初 AlexNet 里面使用分组卷积是正确的设计，使用了分组卷积以后不仅计算量和权值\\n\\n数量减少了，并且模型准确率也提升了一些[5]，实验结果如图 11.17 所示。\\n\\n366\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.17 不同分组 AlexNet 的结果[7]\\n\\n图中的 Model Parameters 表示模型参数数量；Top-5 Val. Error 表示 Top5 验证集错\\n\\n误率；groups 表示分组数。\\n\\n图中横坐标表示模型的参数数量，纵坐标表示模型错误率，原始的 AlexNet 为图中的“2\\n\\ngroups”表示将卷积分为 2 组，“no groups”表示不分组，”4 groups”表示将卷积分\\n\\n为 4 组。从图中我们可以看到分组越多模型的参数越少，模型的准确率上下会有浮动，不过\\n\\n变化不是很大。这 3 个实验结果里将卷积分为 2 组是最好的选择。\\n\\n下面我们正式介绍分组卷积，简单来说分组卷积就是将特征图分为不同的组，再对每组\\n\\n特征图分别进行卷积。这里的分组一般都是分为 n 个等份，理论上其实不是等份也可以，不\\n\\n过一般为了实现方便都是分为等份。分组卷积的好处主要是可以减少模型的计算量和训练参\\n\\n数，同时对模型准确率影响不大，甚至有可能会提高模型准确率。下面我们通过几个图来详\\n\\n细了解一下，图 11.18 为普通卷积：.\\n\\n图 11.18 普通卷积\\n\\n367\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Conv 表示卷积。\\n\\n这里特征图的大小和卷积和的大小都不是重点内容，所以图中没有标出，我们只要能看\\n\\n出 6 个特征图卷积后得到 12 个特征图就可以了。不过为了让大家理解分组卷积的计算量和\\n\\n权值数量这里我们举例计算一下，假设特征图大小是 28×28，卷积核大小为 5×5，Same\\n\\nPadding。卷积层权值数量为 5×5×6×12+12=1812，乘法计算量为 5×5×28×28×6×\\n\\n12=1411200。\\n\\n下面我们看一下分组卷积，分组卷积一般都是把特征图分为 n 个等份，然后再对 n 个等\\n\\n份的特征图分别卷积，这里的 n 可以人为设置，如图 11.19 所示。\\n\\n图 11.19 分组卷积\\n\\n图中的 Conv 表示卷积。\\n\\n为了跟普通卷积对比，所以这里分组卷积的例子输入也是 6 个特征图，输出也是 12 个特\\n\\n征图。这里我们可以看到把 6 个特征图分为了 3 组，每组 2 个特征图，每组分别进行卷积，\\n\\n卷积后得到 4 个特征图。最后再把 3 个组共 12 个特征图组合起来。假设特征图大小是 28×\\n\\n28，卷积核大小为 5×5，Same Padding。这里卷积层权值数量为 5×5×2×4×\\n\\n3+12=612，乘法计算量为 5×5×28×28×2×4×3=470400。权值数量和计算量都约为普通\\n\\n卷积的 1/3。\\n\\n368\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n11.2.2 ResNeXt中的分组卷积\\n\\n这一小节我们主要学习 ResNeXt 的核心内容，分组卷积在 ResNeXt 中的使用。\\n\\nResNeXt 中提出的一个模型调节的新维度“cardinality”其实就是分组卷积中的分组数量，\\n\\n比如 cardinality 为 2 表示把卷积分为 2 组，cardinality 为 32 表示把卷积分为 32 组。\\n\\n作者将分组卷积应用到 ResNet 的残差结构中，如图 11.20 所示。\\n\\n图 11.20 残差结构中使用分组卷积[5]\\n\\n图中的 in 表示输入；out 表示输出；d 表示 dimension，代表维度；total 32 paths 表\\n\\n示总共 32 个通道。\\n\\n图中左边为 ResNet 的残差结构，右边是 cardinality 为 32 的新残差结构。每个格子中\\n\\n的 3 个数字分别表示（输入通道数，卷积核大小，输出通道数）。原始的 ResNet 的残差结\\n\\n构就不用多说了，ResNeXt 中的残差结构也很容易理解，第 1 层卷积输入是 256 个特征\\n\\n图，输出是 4×32=128 个特征图。然后对这 128 个特征图进行分组，分为 32 组，每组 4 个\\n\\n特征图，在第 2 层卷积进行分组卷积计算。第 2 层卷积计算后，每组卷积都是产生 4 个特征\\n\\n图。第 3 层卷积是对 4 个特征图进行卷积产生 256 个特征图。然后再对 32 个分组产生的 32\\n\\n组每组 256 个特征图进行 element-wise addition 按位相加，最后再加上 shortcut 恒等映\\n\\n射传过来的信号，得到残差结构的输出。\\n\\n369\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这里大家可能会有个小疑问，为什么左边原始的残差结构第 1 层卷积输入 256 个特征\\n\\n图，产生 64 个特征图。而右边的分组卷积残差结构第 1 层卷积输入 256 个特征图，产生 4×\\n\\n32=128 个特征图。看起来两个残差结构中间部分产生的特征图数量不一致。其实作者之所\\n\\n以这么设计分组卷积特征图的数量主要是为了使得两个残差结构的训练参数的数量大致相\\n\\n同。\\n\\n我们来计算一下图 11.20 中左边的残差结构训练参数的数量为（为了计算方便忽略偏置\\n\\n值）：256×64+3×3×64×64+64×256≈70000。右边的分组卷积残差结构参数数量为（为\\n\\n了计算方便忽略偏置值）：C×(256×d+3×3×d×d+d×256)\\t≈70000，其中 C=32 表示\\n\\ncardinality 为 32，d=4 表示每个分组有 4 个特征图。右边的残差结构我们也可以表示为 32\\n\\n×4d，意思是 32 个分组每组 4 个特征图；如果是 8×16d 表示 8 个分组，每组 16 个特张\\n\\n图；如果是 1×64d 表示 1 个分组（也就是不分组），每组 64 个特张图。在作者的设计下，\\n\\n新的分组卷积残差结构权值数量和计算量跟原始的残差结构差不多，不过最后模型效果可以\\n\\n变得更好。\\n\\n其实在 ResNeXt 的论文中，作者给出了 3 种形式的分组卷积残差结构，这 3 种形式的分\\n\\n组卷积残差结构输入信号和输出信号都是一样的，只是中间部分略有不同，如图 11.21 所\\n\\n示。\\n\\n图 11.21 3 种形式的分组卷积残差结构[5]\\n\\n370\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 in 表示输入；out 表示输出；d 表示 dimension，代表维度；total 32 paths 表\\n\\n示总共 32 个通道；group 表示分组数；equivalent 表示相等的；concatenate 表示拼接。\\n\\n前面我们已经仔细分析了(a)结构，实际上(b)结构和(c)结构跟(a)结构也是非常类似的。\\n\\n(b)结构是在第 2 层卷积输出的位置对 32 组每组 4 个特征图进行 concatenate，得到了 128\\n\\n个特征图。然后再传给第 3 层卷积进行计算，最后输出 256 个特征图。(c)结构作者在这里用\\n\\n简化的方式表示分组卷积的计算，注意看(c)结构中有些数字是加粗的，加粗的数字表示跟分\\n\\n组卷积相关。也就是(c)结构的第 2 层卷积跟(a)，(b)结构都不一样，(c)的第 2 层卷积分为 32\\n\\n组，每组输入 4 个特征图，输出 128 个特征图。然后再对这 32 组每组 128 个特征图进行\\n\\nelement-wise addition 按位相加，之后传给第 3 层卷积。第 3 层卷积就是输入 128 个特征\\n\\n图，输出 256 个特征图。\\n\\n这 3 种形式的残差结构作者都进行了实验，发现最后得到的结果基本上都差不多，最终\\n\\n选择了(c)结构。作者认为(c)结构更简单速度也更快。\\n\\n11.2.3 ResNeXt的网络结构\\n\\n了解了 ResNeXt 中使用的残差结构以后，下面我们来看一下 ResNeXt 的网络结构，如\\n\\n图 11.22 所示。\\n\\n371\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.22 ResNeXt 网络结构[5]\\n\\n图中的 stage 表示阶段；conv 表示卷积；output 表示输出；stride 表示步长；d 表示\\n\\ndimension，代表维度；max pool 表示最大池化；C 表示 cardinality，代表分组数；\\n\\nglobal average pool 表示全局平均池化；fc 表示全连接；params 表示参数数量；FLOPs\\n\\n表示计算量。\\n\\n图中有两个网络的结构，一个是 ResNet-50，一个是 ResNeXt-50(32×4d)。ResNeXt-\\n\\n50(32×4d)是在 ResNet-50 网络结构的基础上对残差结构进行了一些修改得到的，所以这两\\n\\n个模型的结构框架基本是一致的。这个结构图还是很容易看懂的，基本上要讲解的地方不\\n\\n多。ResNeXt-50(32×4d)的残差结构是加上了分组卷积的，(32×4d)表示图中的 conv2 中\\n\\n使用的分组卷积是 32 个分组每组 4 个特征图。ResNeXt 的结构一般只需要标明第一个分组\\n\\n卷积残差模块的信息，因为后面 conv3，conv4，conv5 中的分组卷积信息都可以由第一个\\n\\n372\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n分组卷积得到。按照 ResNeXt 的设计思路，所有的分组卷积 cardinality 都是一样的，比如\\n\\n图中的 32。conv2 特征图大小是 56×56，每组 4 个特征图；conv3 特征图大小是 28×28，\\n\\n每组 8 个特征图；conv4 特征图大小是 14×14，每组 16 个特征图；conv5 特征图大小是 7\\n\\n×7，每组 32 个特征图。\\n\\n图中我们还可以看出 ResNet-50 和 ResNeXt-50(32×4d)的权值参数数量和浮点计算量\\n\\n都是差不多的。而 ResNet-101 和 ResNeXt-101(32×4d) 的权值参数数量和浮点计算量也\\n\\n都是差不多的。这 4 个模型在 ImageNet 数据集中的测试结果如图 11.23 所示。\\n\\n图 11.23 4 个模型准确率对比[5]\\n\\n图中的 epochs 表示周期；top-1 error 表示 top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n图中可以看出 ResNeXt-50(32×4d)比 ResNet-50 要更好，ResNeXt-101(32×4d)比\\n\\nResNet-101 要更好。\\n\\n作者也尝试了一些不同分组的残差模块，测试结果如图 11.24 所示。\\n\\n373\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.24 不同分组的残差网络测试结果[5]\\n\\n图中 setting 表示结构设置；top-1 error 表示 top1 错误率。\\n\\n图中的 setting 表示模型第一个分组卷积残差模块的分组数和特征图数量，结果看来 32\\n\\n×4d 是一个比较好的选择。\\n\\n图 11.25 为 ResNeXt 使用不同大小的图片跟不同模型在 ImageNet 验证集的单模型对\\n\\n比结果：\\n\\n图 11.25 不同模型测试结果\\n\\n图中 top-1 err 表示 top1 错误率；top-5 err 表示 top5 错误率。\\n\\n374\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nResNet 和 ResNeXt 使用的是 224×224 和 320×320 的分辨率图片，Inception 相关的\\n\\n模型用的是 299×299 的分辨率图片。结果可以看出使用分辨率比较高的图片准确率也会高\\n\\n一些，ResNeXt-101 是上面几个模型中最好的。\\n\\nResNeXt 模型融合后在 ImageNet 测试集得到了 3.03%的 Top5 错误率，比 Inception-\\n\\nv4/Inception-ResNet-v2 的 3.08%结果要更好。\\n\\n11.3 SENet\\n\\nSENet 是 ImageNet Challenge 图像识别比赛 2017 年的冠军，是来自 Momenta 公司\\n\\n的团队完成。他们提出了 Squeeze-and-Excitation Networks（简称 SENet）。SENet 不\\n\\n是独立的模型设计，只对模型的一种优化。一般 SENet 都会结合其它模型一起使用，比如\\n\\nSENet 用于 ResNet-50 中我们就把这个模型称为 SE-ResNet-50，比如 SENet 用于\\n\\nInception-ResNet-v2 中我们就把这个模型称为 SE- Inception-ResNet-v2。最早提出\\n\\nSENet 的论文是《Squeeze-and-Excitation Networks》[8]。\\n\\n11.3.1 SENet 介绍\\n\\n我们之前介绍了很多模型，Inception 系列的模型使用不同尺度的卷积大小来提取不同的\\n\\n特征，ResNet 给模型增加了捷径更有利于信号传递，ResNeXt 使用了分组卷积把特征提取\\n\\n进行分组处理。SENet 的模型优化思路很有意思，主要是针对特征的 channel 进行优化。\\n\\n我们可以想象在进行图像识别的时候，卷积计算后生成了很多特征图，不同的滤波器会\\n\\n得到不同的特征图，不同的特征图代表从图像中提取的不同的特征。我们得到了这么多的特\\n\\n375\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n征图，按理来说某些特征图的应该更重要，某些特征图应该没这么重要，并不是所有特征图\\n\\n都一样的重要。所以 SENet 的核心思想就是给特征图增加注意力和门控机制，增强重要的特\\n\\n征图的信息，减弱不重要的特征图的信息。\\n\\n那么如何做到增强重要的信息，减弱不重要的信息，我们看一下 SENet 的名字\\n\\nSqueeze-and-Excitation Networks。其中的“Squeeze”中文意思是“挤压”，在模型中\\n\\n的实际操作其实是压缩特征图的特征，作者使用的压缩特征图的特征的方式是 avg pooling\\n\\n平均池化。这个大家应该很熟悉了，求一个特征图所有值的平均值，把 avg pooling 计算后\\n\\n的结果作为这个特征图压缩后的特征。比如一共有 64 个特征图，“Squeeze”计算后我们\\n\\n就会得到 64 个值，代表 64 个特征图压缩后的特征。\\n\\n“Excitation”中文意思是“激发”，在模型中的实际操作是调节特征图信号强弱，作者\\n\\n使用的方式是给“Squeeze”计算后的结果加上两个全连接层，最终输出每个特征图对应的\\n\\n激活值，激活值可以改变特征图信号的强弱。每个特征图乘以它所对应的激活值，得到特征\\n\\n图的输出，然后再传给下一层。\\n\\n文字描述很难具体描述清楚，我们还是看图吧，我们先复习一下普通的 ResNet 中的残\\n\\n差结构如图 11.26 所示。\\n\\n376\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.26 普通残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；Identity mapping 表示恒等映\\n\\n射；batch 表示批次。\\n\\n普通的残差结构我们就不需要多说了，下面我们看一下加上了 Squeeze-and-Excitation\\n\\n模块后的残差结构如图 11.27 所示。\\n\\n377\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.27 SE-残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；Identity mapping 表示恒等映\\n\\n射；batch 表示批次；AvgPool 表示平均池化。\\n\\n加上 Squeeze-and-Excitation 模块后的残差结构主要变化是在原来的残差结构最后一个\\n\\n卷积层后面进行 Squeeze-and-Excitation 的操作。Squeeze 就是先做平均池化，得到每一\\n\\n378\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n个特征图的压缩特征。图中特征图大小为 56×56，所以池化的窗口大小也是 56×56。池化\\n\\n过后就是 Excitation 操作，前面我们有提到 Excitation 操作有两个全连接层，这是 SENet\\n\\n原始论文中的做法，实际我们在写程序的时候也可以用两个窗口大小 1×1 的卷积层的替代，\\n\\n效果跟全连接是一样的。Excitation 操作部分最后的激活函数是 Sigmoid 函数，作者在这里\\n\\n使用 Sigmoid 函数主要是利用 Sigmoid 函数输出范围是 0-1 这个特性，让 Excitation 的输\\n\\n出激活值可以起到一个门控的作用。Excitation 的输出的激活值会乘以原始残差结构最后一\\n\\n个卷积层的输出结果，对特征图的数值大小进行控制。如果是重要的特征图，会保持比较大\\n\\n的数值；如果是不重要的特征图，特征图的数值就会变小。\\n\\nSENet 的论文《Squeeze-and-Excitation Networks》中也有一些图一并给大家看看好\\n\\n了，如图 11.28 所示。\\n\\n图 11.28 Squeeze-and-Excitation block[8]\\n\\n各种符号什么意思我就不解释了，跟我前面介绍的内容差不多，大家随意看看就可以。\\n\\n图 11.29 和图 11.30 为 SE-Inception 模块和 SE-ResNet 模块。\\n\\n379\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.29 SE-Inception 模块[8]\\n\\n图中的 Global pooling 表示全局池化；W 表示图片宽度；H 表示图片高度；C 表示图片\\n\\n通道数；FC 表示全连接层；r 表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n\\n就是一个超参数，不用细究，一般取值为 16。\\n\\n图 11.30 SE-ResNet 模块[8]\\n\\n图中的 Global pooling 表示全局池化；W 表示图片宽度；H 表示图片高度；C 表示图片\\n\\n通道数；FC 表示全连接层；r 表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n\\n就是一个超参数，不用细究，一般取值为 16。\\n\\nResNet-50，SE-ResNet-50，SE-ResNeXt-50(32×4d)模型结构如图 11.31 所示。\\n\\n380\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.31 3 种 ResNet 模型对比[8]\\n\\n图中的 Output size 表示输出大小；conv 表示卷积；max pool 表示最大池化；stride\\n\\n表示步长；fc 表示全连接层；global average pool 表示全局平均池化；C 表示分组数。\\n\\n图中𝑓𝑐表示 fully connected 全连接层，𝑓𝑐后面的两个数字表示 SE 模块中两个全连接层\\n\\n的输出维度。\\n\\n11.3.2 SENet 结果分析\\n\\n基础模型增加 SE 模块后会使得整体模型的参数增加 10%左右，计算量增加不多，一般\\n\\n来说模型的效果也会有所提升。作者使用多个模型在 ImageNet 数据集上进行了测试，图\\n\\n11.32 为多个模型在 ImageNet 验证集测试结果。\\n\\n图 11.32 多个模型测试结果[8]\\n\\n381\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中 original 表示模型原始论文中的结果；re-implementation 表示 SENet 作者重新训\\n\\n练模型的结果；SENet 表示给这些模型加上 SE 模块后的结果；top-1 err.表示 top1 错误\\n\\n率；top-5 err.表示 top5 错误率；GFLOPs 表示计算量。\\n\\n图中结果可以看出，图中测试的所有模型只要加上 SE 模块，错误率都能降低，并且模型\\n\\n浮点计算量没有太大变化。图 11.33 和图 11.34 也能看出加上 SE 模块后模型效果可以变得\\n\\n更好：\\n\\n图 11.33 加上 SE 模块后的模型结果对比 1[8]\\n\\n图中的 epochs 表示周期；Top-1 error 表示 Top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n图 11.34 加上 SE 模块后的模型结果对比 2[8]\\n\\n图中的 epochs 表示周期；Top-1 error 表示 Top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n382\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nSENet 论文的最后，作者还给了一组很有意思的图。作者用 ImageNet 数据集训练了一\\n\\n个 SE-ResNet-50，然后选出 4 个种类(goldfish,pug,plane,cliff)的图片，统计这 4 个种类在\\n\\nSE-ResNet-50 模型的每个 SE 模块的特征图的激活情况，如图 11.35 所示。\\n\\n图 11.35 不同 SE 模块的激活情况[8]\\n\\n图中的 all 表示所有 1000 个种类的平均值；goldfish 表示金鱼；pug 表示哈巴狗；\\n\\nplane 表示飞机；cliff 表示悬崖；channel index 表示通道；activation 表示激活值。\\n\\n作者观察实验结果得到 3 个结论：\\n\\n第一，不同种类的物体在浅层激活分布情况是类似的，如图中的 SE_2_3 和 SE_3_4。也\\n\\n就是不管是识别哪种物体，浅层的卷积层中，重要的特征图总是比较固定的那些。\\n\\n第二，在更深层一些的位置，不同种类在不同的特征图激活分布不同，因为不同类别对\\n\\n特征有不同的偏好，如图中的 SE_4_6 和 SE_5_1。低层特征通常更普遍，识别不同种类物体\\n\\n383\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n可以使用类似的滤波器，而高层特征通常包含更多细节，识别不同种类物体需要使用不同的\\n\\n滤波器。\\n\\n第三，在模型的最后阶段，SE_5_2 呈现出饱和状态，其中大部分激活值都接近于 1，也\\n\\n有一些接近于 0。对于激活值为 1 的特征图，相当于 SE 模块不存在。在网络的最后一个 SE\\n\\n模块 SE_5_3，不同种类有着类似的分布，只是尺度不同。也就是说 SE_5_2 和 SE_5_3 相对\\n\\n来说没有前面的一些 SE 模块重要，作者通过实验发现删除最后一个阶段的 SE 模块，总体参\\n\\n数可以显著减少，性能只有一点损失(<0.1%的 Top1 错误率)。\\n\\n下一章节我们将介绍经典图像识别模型的代码实现，以及如何使用这些模型进行图像识\\n\\n别。\\n\\n11.4 参考文献\\n\\n[1] Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n\\n[2] C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna. Rethinking the inception\\n\\narchitecture for computer vision. arXiv preprint arXiv:1512.00567, 2015.\\n\\n[3] Szegedy C , Ioffe S , Vanhoucke V . Inception-v4, Inception-ResNet and the\\n\\nImpact of Residual Connections on Learning[J]. 2016.\\n\\n[4] Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for\\n\\nLarge-Scale Image Recognition[J].\\n\\n[5] Xie S , Girshick R , Dollár, Piotr, et al. Aggregated Residual Transformations for\\n\\nDeep Neural Networks[J]. 2016.\\n\\n384\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[6] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\n\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n\\n[7] Ioannou Y , Robertson D , Cipolla R , et al. Deep Roots: Improving CNN Efficiency\\n\\nwith Hierarchical Filter Groups[J]. 2016.\\n\\n[8] Hu J , Shen L , Albanie S , et al. Squeeze-and-Excitation Networks[J]. IEEE\\n\\nTransactions on Pattern Analysis and Machine Intelligence, 2017.\\n\\n385\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 12 章-图像识别项目实战\\n\\n本章节内容主要是针对第 10，11 章节经典图像识别模型的程序实现，理论部分就不再重\\n\\n复了，直接上代码。注意代码实现不一定跟原始中的描述完全一致，基本框架以及核心实现\\n\\n跟论文是一致的。我们将结合图像识别项目实战内容给大家讲解模型搭建，由于图像识别技\\n\\n术在各个行业的应用基本上差别不大，不管你是做医疗图像分类，农产品图像分类，工业部\\n\\n件图像分类，天气云图图像分类，生活用品图像分类等，只要是图像分类，所用到的技术和\\n\\n流程都是差不多的。所以为了方便，本章节我们主要使用一个数据集给大家讲解，如果大家\\n\\n有其他图像数据集或自己收集了一些图像数据集也可以用本章内容进行图像分类。\\n\\n特别要说明一下，本章的重点在于 Tensorflow 中不同模型的搭建方法，以及图像识别模\\n\\n型的训练流程，因为数据量比较小，我也没有进行调参，所以最后模型的准确率不需要太在\\n\\n意。因为正常图像识别模型训练都不会从头训练（英文是 train from scratch），一般我们\\n\\n都在预训练模型的基础上做进一步的训练。由于我们使用的数据集太小，并不是 ImageNet\\n\\n级别的大数据集，所以从头训练（train from scratch）很难发挥模型的真正水平。本章\\n\\n12.11 小节将会介绍使用预训练模型来进行迁移学习的方法。\\n\\n12.1 图像数据准备\\n\\n12.1.1 数据集介绍\\n\\n在建模之前我们肯定需要先把数据给准备好，图像数据集有很多，大家可以自行收集，\\n\\n我们这里使用的数据集是来自 Visual Geometry Group 的 17 Category Flower Dataset 数\\n\\n386\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n据集，也就是 17 种花的数据集。具体是哪 17 种这个我们可以不用管，反正就是 17 个类\\n\\n别。每个类别的花有 80 张图片，一共是 1360 张图片。单击网址\\n\\nhttp://www.robots.ox.ac.uk/~vgg/data/flowers/17/。出现如图 12.1 所示的界面。\\n\\n图 12.1 17 Category Flower Dataset\\n\\n我们单击“1.Dataset images”就可以下载数据集了，下载后得到一个名为\\n\\n“17flowers.tgz”的压缩包，解压后得到一个名为“17flowers”的文件夹，打开文件夹里\\n\\n面是一个名为“jpg”的文件夹，再打开“jpg”文件夹，我们会看到 1362 个文件，其中有\\n\\n1360 张图片。我们需要把不是图片的那两个文件给删除，只留下图片文件，如图 12.2 所\\n\\n示。\\n\\n12.2 17 种花的图片\\n\\n观察图片名称我们可以发现是都是由编号构成，前 1-80 号为第一种花，81 到 160 号为\\n\\n第二种花以此类推，1360 张图片一共 17 种花。\\n\\n387\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.1.2 数据集准备\\n\\n我们在做图像分类任务的时候，通常需要把数据先整理好，数据整理的格式通常都是每\\n\\n一个类别一个文件夹，文件夹的名称就是类别名称，如图 12.3 所示。\\n\\n图 12.3 数据集准备\\n\\n如图我想做一个 5 分类的图像识别模型，这 5 个分类分别\\n\\n是”animal”,”flower”,”guitar”,”house”,”plane”,那么我需要在一个新的路径下\\n\\n新建 5 个文件夹，这 5 个文件夹的名称修改\\n\\n为”animal”,”flower”,”guitar”,”house”,”plane”。然后把对应类别的图片存放到\\n\\n对应的文件夹下面。如图 12.4 所示。\\n\\n图 12.4 存放数据\\n\\n这是图像分类任务的基本操作，正常情况下大家都会这么整理数据。不过 Visual\\n\\nGeometry Group 的 17 Category Flower Dataset 数据集所有的图片都是在一个文件夹下\\n\\n面的，所以这里我们还需要写一个程序来帮助我们整理一下图片，我写的这个程序是放在与\\n\\n“17flowers”文件夹相同目录下运行的，如果在其他路径运行，要注意程序中路径的设置，\\n\\n如代码 12-1 所示。\\n\\n代码 12-1：17Flower 数据整理\\n\\nimport os import shutil\\n\\n388\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 新建文件夹用于存放整理后的图片 os.mkdir(\\'new_17_flowers\\') for i in range(17): # 17 个种类新建 17 个文件夹 0-16 os.mkdir(\\'new_17_flowers\\'+\\'/\\'+str(i))\\n\\n# 循环所有花的图片 for i,path in enumerate(os.listdir(\\'17flowers/jpg/\\')): # 定义花的图片完整路径 image_path = \\'17flowers/jpg/\\' + path # 复制到对应类别，每个类别 80 张图片 shutil.copyfile(image_path, \\'new_17_flowers\\'+\\'/\\'+str(i//80)+\\'/\\'+path)\\n\\n运行完程序后就会产生一个新的文件夹“new_17_flowers”，这个文件夹里面有 17 个\\n\\n子文件夹，名字为 flower0- flower16，表示 17 种花的编号。flower0- flower16 文件夹里\\n\\n面都各自存放了 80 张图片。\\n\\n12.1.3 切分数据集程序\\n\\n数据集按照格式准备好以后，我们还需要切分训练集和测试集。因为我经常需要做数据\\n\\n切分的工作，所以就自己写了一个程序专门用于打乱数据并切分训练集和测试集。大家如果\\n\\n之后需要做类似的操作，可以参考或直接使用代码 12-2。该程序是放在与\\n\\n“new_17_flowers”文件夹相同的路径下的，如果大家在其他路径运行，需要注意程序中路\\n\\n径的设置。\\n\\n代码 12-2：切分数据集\\n\\nimport os import random import shutil import numpy as np # 数据集路径 DATASET_DIR = \"new_17_flowers\" # 数据切分后存放路径 NEW_DIR = \"data\" # 测试集占比 num_test = 0.2\\n\\n389\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 打乱所有种类数据，并分割训练集和测试集 def shuffle_all_files(dataset_dir, new_dir, num_test): # 先删除已有 new_dir 文件夹 if not os.path.exists(new_dir): pass else: # 递归删除文件夹 shutil.rmtree(new_dir) # 重新创建 new_dir 文件夹 os.makedirs(new_dir) # 在 new_dir 文件夹目录下创建 train 文件夹 train_dir = os.path.join(new_dir, \\'train\\') os.makedirs(train_dir) # 在 new_dir 文件夹目录下创建 test 文件夹 test_dir = os.path.join(new_dir, \\'test\\') os.makedirs(test_dir) # 原始数据类别列表 directories = [] # 新训练集类别列表 train_directories = [] # 新测试集类别列表 test_directories = [] # 类别名称列表 class_names = [] # 循环所有类别 for filename in os.listdir(dataset_dir): # 原始数据类别路径 path = os.path.join(dataset_dir, filename) # 新训练集类别路径 train_path = os.path.join(train_dir, filename) # 新测试集类别路径 test_path = os.path.join(test_dir, filename) # 判断该路径是否为文件夹 if os.path.isdir(path): # 加入原始数据类别列表 directories.append(path) # 加入新训练集类别列表 train_directories.append(train_path) # 新建类别文件夹 os.makedirs(train_path) # 加入新测试集类别列表 test_directories.append(test_path) # 新建类别文件夹\\n\\n390\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com os.makedirs(test_path) # 加入类别名称列表 class_names.append(filename) print(\\'类别列表：\\',class_names)\\n\\n# 循环每个分类的文件夹 for i in range(len(directories)): # 保存原始图片路径 photo_filenames = [] # 保存新训练集图片路径 train_photo_filenames = [] # 保存新测试集图片路径 test_photo_filenames = [] # 得到所有图片的路径 for filename in os.listdir(directories[i]): # 原始图片路径 path = os.path.join(directories[i], filename) # 训练图片路径 train_path = os.path.join(train_directories[i], filename) # 测试集图片路径 test_path = os.path.join(test_directories[i], filename) # 保存图片路径 photo_filenames.append(path) train_photo_filenames.append(train_path) test_photo_filenames.append(test_path) # list 转 array photo_filenames = np.array(photo_filenames) train_photo_filenames = np.array(train_photo_filenames) test_photo_filenames = np.array(test_photo_filenames) # 打乱索引 index = [i for i in range(len(photo_filenames))] random.shuffle(index) # 对 3 个 list 进行相同的打乱，保证在 3 个 list 中索引一致 photo_filenames = photo_filenames[index] train_photo_filenames = train_photo_filenames[index] test_photo_filenames = test_photo_filenames[index] # 计算测试集数据个数 test_sample_index = int((1-num_test) * float(len(photo_filenames))) # 复制测试集图片 for j in range(test_sample_index, len(photo_filenames)): # 复制图片 shutil.copyfile(photo_filenames[j], test_photo_filenames[j]) # 复制训练集图片 for j in range(0, test_sample_index):\\n\\n391\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 复制图片 shutil.copyfile(photo_filenames[j], train_photo_filenames[j])\\n\\n# 打乱并切分数据集 shuffle_all_files(DATASET_DIR, NEW_DIR, num_test) 运行结果如下： 类别列表： [\\'flower0\\', \\'flower1\\', \\'flower10\\', \\'flower11\\', \\'flower12\\', \\'flower13 \\', \\'flower14\\', \\'flower15\\', \\'flower16\\', \\'flower2\\', \\'flower3\\', \\'flower4\\', \\'flowe\\n\\nr5\\', \\'flower6\\', \\'flower7\\', \\'flower8\\', \\'flower9\\']\\n\\n这个程序运行后会生成一个新的文件夹“data“，”data“文件夹中有两个子文件夹”\\n\\ntrain“和”test“。”train“表示训练集数据，占数据集的 80%，”test“表示测试集数\\n\\n据，占数据集的 20%。”train“和”test“文件夹下的子文件夹都是 flower0- flower16，\\n\\n就是 17 种花的类别。“train”的子文件夹下，每个类别有 64 张图片，“test”的子文件夹\\n\\n下，每个类别有 16 张图片。\\n\\n12.2 AlexNet 图像识别\\n\\n这一小节我们要学习如何搭建 AlexNet 模型并从头进行模型训练，如代码 12-3 所示。\\n\\n代码 12-3：AlexNet 图像识别（片段 1）\\n\\nimport numpy as np from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt from tensorflow.keras.callbacks import LearningRateScheduler # 类别数 num_classes = 17\\n\\n392\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 批次大小 batch_size = 32 # 周期数 epochs = 100 # 图片大小 image_size = 224\\n\\n# 训练集数据进行数据增强 train_datagen = ImageDataGenerator( rotation_range = 20, # 随机旋转度数 width_shift_range = 0.1, # 随机水平平移 height_shift_range = 0.1,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 10, # 随机错切变换 zoom_range = 0.1, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range=(0.7, 1.3), # 亮度变化 fill_mode = \\'nearest\\', # 填充方式 ) # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator( rescale = 1/255, # 数据归一化 )\\n\\n# 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从\\'data/train\\'获得训练集数据 # 获得数据后会把图片 resize 为 image_size×image_size 的大小 # generator 每次会产生 batch_size 个数据 train_generator = train_datagen.flow_from_directory( \\'data/train\\', target_size=(image_size,image_size), batch_size=batch_size, )\\n\\n# 测试集数据生成器 test_generator = test_datagen.flow_from_directory( \\'data/test\\', target_size=(image_size,image_size), batch_size=batch_size, ) # 字典的键为 17 个文件夹的名字，值为对应的分类编号 print(train_generator.class_indices) 运行结果如下： {\\'flower0\\': 0,\\n\\n393\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com \\'flower1\\': 1, \\'flower10\\': 2, \\'flower11\\': 3, \\'flower12\\': 4, \\'flower13\\': 5, \\'flower14\\': 6, \\'flower15\\': 7, \\'flower16\\': 8, \\'flower2\\': 9, \\'flower3\\': 10, \\'flower4\\': 11, \\'flower5\\': 12, \\'flower6\\': 13, \\'flower7\\': 14, \\'flower8\\': 15, \\'flower9\\': 16}\\n\\n代码 12-3：AlexNet 图像识别（片段 2）\\n\\n# AlexNet model = Sequential() # 卷积层 model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\\'valid\\',input_shape =(image_size,image_size,3),activation=\\'relu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'valid\\')) model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'valid\\')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\\'valid\\')) # 全连接层 model.add(Flatten()) model.add(Dense(4096, activation=\\'relu\\')) model.add(Dropout(0.5)) model.add(Dense(4096, activation=\\'relu\\')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation=\\'softmax\\')) # 模型概要 model.summary()\\n\\n394\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 模型概要输出省略。。。\\n\\n# 学习率调节函数，逐渐减小学习率 def adjust_learning_rate(epoch): # 前 30 周期 if epoch<=30: lr = 1e-4 # 前 30 到 70 周期 elif epoch>30 and epoch<=70: lr = 1e-5 # 70 到 100 周期 else: lr = 1e-6 return lr\\n\\n# 定义优化器 adam = Adam(lr=1e-4)\\n\\n# 定义学习率衰减策略 callbacks = [] callbacks.append(LearningRateScheduler(adjust_learning_rate))\\n\\n# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\'])\\n\\n# Tensorflow2.1 版本之前可以使用 fit_generator 训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc hs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\\n\\n# Tensorflow2.1 版本(包括 2.1)之后可以直接使用 fit 训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callba cks=callbacks) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 14s 418ms/step - loss: 2.77 50 - accuracy: 0.0800 - val_loss: 2.4774 - val_accuracy: 0.1250 Epoch 2/100 34/34 [==============================] - 13s 395ms/step - loss: 2.46 28 - accuracy: 0.1296 - val_loss: 2.2861 - val_accuracy: 0.1949\\n\\n……\\n\\nEpoch 99/100\\n\\n395\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 34/34 [==============================] - 13s 390ms/step - loss: 0.08 79 - accuracy: 0.9743 - val_loss: 0.7067 - val_accuracy: 0.8346 Epoch 100/100 34/34 [==============================] - 13s 390ms/step - loss: 0.10 61 - accuracy: 0.9660 - val_loss: 0.7062 - val_accuracy: 0.8346\\n\\n代码 12-3：AlexNet 图像识别（片段 3）\\n\\n# 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history[\\'accuracy\\'],c=\\'b\\',label=\\'train_accuracy\\') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'val_accuracy\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() 运行结果如下：\\n\\n12.3 VGGNet 图像识别\\n\\n这一小节我们要学习如何搭建 VGGNet 模型并从头进行模型训练，由于我们使用的都是\\n\\n同一个数据集案例，所以关于模块导入，参数设定，数据集预处理，模型训练，训练后画图\\n\\n396\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的程序基本都是一样的。主要就是模型搭建部分不同，所以为了节约用纸，我们仅在书中展\\n\\n示模型搭建部分的代码，完整的代码可见于本书相关代码。模型代码如代码 12-4 所示。\\n\\n代码 12-4：VGGNet 图像识别\\n\\n…… …… …… # VGG16 model = Sequential() # 卷积层 model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\',input_shape=(image_size,image_size,3))) model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'same\\')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'same\\')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'same\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'same\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'r elu\\')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding=\\'same\\'))\\n\\n397\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 全连接层 model.add(Flatten()) model.add(Dense(4096,activation=\\'relu\\')) model.add(Dropout(0.5)) model.add(Dense(4096,activation=\\'relu\\')) model.add(Dropout(0.5)) model.add(Dense(num_classes,activation=\\'softmax\\')) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 15s 447ms/step - loss: 2.83 44 - accuracy: 0.0506 - val_loss: 2.8332 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 400ms/step - loss: 2.82 52 - accuracy: 0.0542 - val_loss: 2.8332 - val_accuracy: 0.0588\\n\\n……\\n\\nEpoch 99/100 34/34 [==============================] - 14s 401ms/step - loss: 0.20 13 - accuracy: 0.9311 - val_loss: 0.7145 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 14s 400ms/step - loss: 0.18 59 - accuracy: 0.9338 - val_loss: 0.7183 - val_accuracy: 0.7868\\n\\n观察 AlexNet 和 VGG16 模型的训练结果我们其实会发现 AlexNet 的结果反而比\\n\\nVGG16 的结果要好一些。AlexNet 测试集的准确率在 83%左右，VGG16 测试集的准确率在\\n\\n398\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n78%左右。由于我们是从新训练模型，并且数据量比较少，VGG16 模型比 AlexNet 结构更\\n\\n复杂，所以更难训练，那么结果差一些也是可以理解的。如果是大量数据的情况下，VGG16\\n\\n得到的结果应该会比 AlexNet 更好。\\n\\n12.4 函数式（functional）模型\\n\\n12.4.1 函数式（functional）模型介绍\\n\\n在 Tenorflow.keras 种有两种模型搭建的方法，一种就是我们之前学习使用的\\n\\nSequential 顺序模型，模型就像汉堡一样，是一层一层叠加起来的。除此之外模型搭建还有\\n\\n另外一种方式称为函数式模型。\\n\\n函数式模型的特点是需要定义模型的输入和输出，并且在模型搭建的过程中也更灵活。\\n\\n下面举个例子，比如我们在构建 GoogleNet 的 Inception 结构时，使用函数式模型的方式\\n\\n就会比较方便，下面程序我们将构建 GoogleNet 中第一个 Inception 的结构，如代码 12-5\\n\\n所示。\\n\\n代码 12-5：函数式编程实现 Inception 结构\\n\\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model\\n\\n# 定义模型输入 inputs = Input(shape=(28,28,192)) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs)\\n\\n399\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 注意函数式模型的特点，Conv2D 后面的(tower_2)表示把 tower_2 信号输入到 Conv2D 中 计算 tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'re lu\\')(tower_2) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs) # 注意函数式模型的特点，Conv2D 后面的(tower_3)表示把 tower_3 信号输入到 Conv2D 中 计算 tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(tower_3) # 注意函数式模型的特点，MaxPool2D 后面的(inputs)表示把 inputs 信号输入到 MaxPool2D 中计算 pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding=\\'same\\')(inputs) # 注意函数式模型的特点，Conv2D 后面的(pooling)表示把 pooling 信号输入到 Conv2D 中计 算 pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'relu\\' )(pooling) # concatenate 合并 4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # 查看模型概要 model.summary() 运行结果如下：\\n\\n400\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n由于我们第一次讲解函数式编程，所以注释里我强调了很多次要注意函数式模型的特\\n\\n点，输入信号要放在函数的后面。\\n\\n12.4.2 使用函数式模型进行 MNIST 图像识别\\n\\n我们再来看一个函数式模型的完整例子，如代码 12-6 所示。\\n\\n代码 12-6：使用函数式模型进行 MNIST 图像识别\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam from tensorflow.keras.models import Model\\n\\n# 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在 tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式 # 这 4 个维度是(数据数量，图片高度，图片宽度，图片通道数) # 所以这里把数据 reshape 变成 4 维数据，黑白图片的通道数是 1，彩色图片通道数是 3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 定义模型输入 inputs = Input(shape=(28,28,1)) x = Conv2D(filters=32,kernel_size=5,strides=1,padding=\\'same\\',activation=\\'relu\\')(inputs) x = MaxPool2D(pool_size=2,strides=2,padding=\\'same\\')(x) x = Conv2D(64,5,strides=1,padding=\\'same\\',activation=\\'relu\\')(x) x = MaxPool2D(pool_size=2,strides=2,padding=\\'same\\')(x) x = Flatten()(x) x = Dense(1024,activation=\\'relu\\')(x) x = Dropout(0.5)(x) x = Dense(10,activation=\\'softmax\\')(x) # 定义模型 model = Model(inputs,x)\\n\\n401\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\']) # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=2,validation_data=(x_test, y_test)) 运行结果如下： Train on 60000 samples, validate on 10000 samples Epoch 1/2 60000/60000 [==============================] - 83s 1ms/sample - los s: 0.3269 - accuracy: 0.9077 - val_loss: 0.0849 - val_accuracy: 0.975 2 Epoch 2/2 60000/60000 [==============================] - 87s 1ms/sample - los s: 0.0893 - accuracy: 0.9730 - val_loss: 0.0528 - val_accuracy: 0.982 5\\n\\n12.5 模型可视化 plot_model\\n\\n12.5.1 使用 plot_model 进行模型可视化\\n\\nTensorflow 里面有一个小工具可以方便的画出模型结构，很好用。就是\\n\\ntensorflow.keras.utils.plot_model。\\n\\n使用 plot_model 前需要做一些准备工作，首先我们先要打开命令提示符安装 3 个\\n\\npython 模块：\\n\\npip install pydot\\n\\npip install pydot_ng\\n\\npip install graphviz\\n\\n安装好 3 个 python 模型后，我们还需要安装一个软件，软件下载网址是：\\n\\nhttps://graphviz.gitlab.io/download/。\\n\\n402\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n里面有 Linux，Windows，Mac 系统相对应的安装方法，因为每个系统安装方式不太一\\n\\n样，大家可以根据提示操作，搞不定的话可以网上搜索一下安装方法，我就不一一展开了。\\n\\n安装方式如图 12.6 所示。\\n\\n图 12.6 安装 Graphviz 软件\\n\\nWindows 用户应该比较多，我就以 Windows 为例简单说明一下，Windows 版本有一\\n\\n个软件下载地址为：\\n\\nhttps://www2.graphviz.org/Packages/stable/windows/10/msbuild/Release/Win32/gr\\n\\naphviz-2.38-win32.msi。下载完成后双击安装就可以，安装的路径我们要记住，默认路径\\n\\n一般是“C:\\\\Program Files(x86)\\\\Graphviz2.38”，可以使用默认路径或者修改为其他路径\\n\\n都可以。安装好之后，我们还需要把 Graphviz 软件主目录下 bin 文件的路径添加到环境变\\n\\n量中，如果是默认路径安装的话就是把“C:\\\\Program Files(x86)\\\\Graphviz2.38\\\\bin”添加\\n\\n到环境变量中。（可能有些同学还不知道怎么添加环境变量，这个内容太基础了，自行通过\\n\\n403\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n搜索引擎解决吧）。安装配置好以后最好重启电脑，到此为止准备工作应该就做好了。如果\\n\\n运行时还出现有其他问题的话可以自行通过搜索引擎解决。\\n\\n前面我们用函数式模型搭建了一个 Inception 结构，这个 Inception 结构如果我们看它\\n\\n的 summary 输出结果，大概可以看出来它的信号传递关系，但是看起来不太直观。\\n\\nsummary 比较适合用来看顺序模型的结构，看函数式模型就不太方便了。下面我们来学习\\n\\nplot_model 的用法，它可以比较直观的绘制出模型的结构，实现代码如代码 12-7 所示。\\n\\n代码 12-7：画出模型结构 plot_model\\n\\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model from tensorflow.keras.utils import plot_model # 定义模型输入 inputs = Input(shape=(28,28,192)) tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs) tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs) tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\\'same\\',activation=\\'re lu\\')(tower_2) tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(inputs) tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding=\\'same\\',activation=\\'rel u\\')(tower_3) pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding=\\'same\\')(inputs) pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding=\\'same\\',activation=\\'relu\\' )(pooling) # concatenate 合并 4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # model 表示要画图的模型 # \\'model.png\\'表示图片存放路径 # show_shapes=True 画出信号的 shape # dpi 设置分辨率，默认是 96 plot_model(model=model, to_file=\\'model.png\\', show_shapes=True, dpi=200) 运行结果如下：\\n\\n404\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n运行程序后，在程序所在目录下会产生一张名为\\'model.png\\'的图片，保存着模型的结构\\n\\n图。这个图我就不需要多解释了，可以清楚地看到信号的传递关系和信号的 shape 变化。\\n\\n代码 12-6 中的模型使用 plot_model 画出来的结构如图 12.7 所示。\\n\\n图 12.7 plot_model 绘制模型结构\\n\\n405\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nplot_model 画出来的图可以很清晰的看到网络各层结构，信号的流动关系，以及信号输\\n\\n入输出的 shape。如果以后大家对模型的结构理解得不够好的话，可以用 plot_model 把模\\n\\n型结构画出来，看着模型结构图来理解模型的结构会容易一些。\\n\\n12.5.2 plot_model 升级版\\n\\n上一小节我们学习了使用 Tensorflow 官方的 plot_model 来绘制网络结构，\\n\\nplot_model 确实对我们理解模型结构有着很好的帮助。但是如果你仔细观察的话你会发现\\n\\n好像 plot_model 画出来的图好像少了些什么重要的内容。对了，这就卷积/池化窗口的大\\n\\n小，卷积/池化的步长，卷积/池化的 padding 方式，Dense 层的激活函数，Dropout 的系\\n\\n数等这些具体参数对于我们理解网络具体结构也是非常重要的，但是 plot_model 没有把这\\n\\n些信息标注出来。\\n\\n为了可以画出更好的模型结构图，我在 Tensorflow 官方的 plot_model 基础上进行的优\\n\\n化，优化后的效果如图 12.8 和图 12.9 所示。\\n\\n406\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.8 plot_model 升级版 1\\n\\n图 12.9 plot_model 升级版 2\\n\\n我对原始 plot_model 的修改主要就是增加了更多的模型细节以及不同模块有不同颜\\n\\n色，简单的模型可能效果不够明显，如果大家在学习复杂模型的时候，显示更多的细节和颜\\n\\n色区分帮助还是很大的。\\n\\n407\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我优化过的 plot_model 已经发布在 PyPi：https://pypi.org/project/plot-model/。源\\n\\n代码在我的 Github 可以看到：https://github.com/Qinbf/plot_model。推荐安装方式是\\n\\n使用 pip 安装，打开命令提示符输入命令：\\n\\npip install plot_model\\n\\n安装好以后通过如下代码导入：\\n\\nfrom plot_model import plot_model\\n\\nplot_model 的使用方式跟 Tensorflow 中的 plot_model 一样，不过增加了两个参数。\\n\\n一个是 style，可以取值 0 和 1，默认值为 0。style=0 表示使用新风格，style=1 表示使用\\n\\n老风格，大家可以自行尝试。还有一个参数是 color，取值为 True 或 False，默认值是\\n\\nTrue。color=True 表示画彩色结构图，color=False 表示画黑白结构图。以后大家需要画模\\n\\n型结构图的时候，推荐大家使用我的 plot_model。\\n\\n12.6 GoogleNet 图像识别\\n\\nGoogleNet 中包含了很多 Inception 模块，所以我们可以定义一个 Inception 函数专门\\n\\n用于实现 Inception 模块。在调用 Inception 函数时根据论文中 GoogleNet 网络结构描述\\n\\n传入不同的参数即可。我们将使用函数式模型来定义 GoogleNet，同样我们只展示建模相关\\n\\n代码，如代码 12-8 所示。\\n\\n代码 12-8：GoogleNet 图像识别\\n\\n…… …… …… # 定义 Inception 结构 def Inception(x,filters):\\n\\n408\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 409 tower_1 = Conv2D(filters=filters[0],kernel_size=1,strides=1,padding=\\'same\\',activation=\\'re lu\\')(x) tower_2 = Conv2D(filters=filters[1],kernel_size=1,strides=1,padding=\\'same\\',activation=\\'re lu\\')(x) tower_2 = Conv2D(filters=filters[2],kernel_size=3,strides=1,padding=\\'same\\',activation=\\'re lu\\')(tower_2) tower_3 = Conv2D(filters=filters[3],kernel_size=1,strides=1,padding=\\'same\\',activation=\\'re lu\\')(x) tower_3 = Conv2D(filters=filters[4],kernel_size=5,strides=1,padding=\\'same\\',activation=\\'re lu\\')(tower_3) pooling = MaxPool2D(pool_size=3,strides=1,padding=\\'same\\')(x) pooling = Conv2D(filters=filters[5],kernel_size=1,strides=1,padding=\\'same\\',activation=\\'rel u\\')(pooling) x = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) return x\\n\\n# 定义 GoogleNet 模型 model_input = Input(shape=(image_size,image_size,3)) x = Conv2D(filters=64,kernel_size=7,strides=2,padding=\\'same\\',activation=\\'relu\\')(model_inp ut) x = MaxPool2D(pool_size=3,strides=2,padding=\\'same\\')(x) x = Conv2D(filters=64,kernel_size=1,strides=1,padding=\\'same\\',activation=\\'relu\\')(x) x = Conv2D(filters=192,kernel_size=3,strides=1,padding=\\'same\\',activation=\\'relu\\')(x) x = MaxPool2D(pool_size=3,strides=2,padding=\\'same\\')(x) x = Inception(x,[64,96,128,16,32,32]) x = Inception(x,[128,128,192,32,96,64]) x = MaxPool2D(pool_size=3,strides=2,padding=\\'same\\')(x) x = Inception(x,[192,96,208,16,48,64]) x = Inception(x,[160,112,224,24,64,64]) x = Inception(x,[128,128,256,24,64,64]) x = Inception(x,[112,144,288,32,64,64]) x = Inception(x,[256,160,320,32,128,128]) x = MaxPool2D(pool_size=3,strides=2,padding=\\'same\\')(x) x = Inception(x,[256,160,320,32,128,128]) x = Inception(x,[384,192,384,48,128,128]) x = AvgPool2D(pool_size=7,strides=7,padding=\\'same\\')(x) x = Flatten()(x) x = Dropout(0.4)(x) x = Dense(num_classes,activation=\\'softmax\\')(x) model = Model(inputs=model_input,outputs=x) …… …… …… 运行结果如下：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 16s 477ms/step - loss: 2.77 64 - accuracy: 0.0699 - val_loss: 2.5863 - val_accuracy: 0.1140 Epoch 2/100 34/34 [==============================] - 13s 392ms/step - loss: 2.46 51 - accuracy: 0.1360 - val_loss: 2.3358 - val_accuracy: 0.1471 …… Epoch 99/100 34/34 [==============================] - 13s 395ms/step - loss: 0.17 23 - accuracy: 0.9366 - val_loss: 0.8696 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 13s 393ms/step - loss: 0.16 41 - accuracy: 0.9430 - val_loss: 0.8596 - val_accuracy: 0.7904\\n\\nGoogleNet 的结构是一个个 Inception 结构叠加得到的，看程序就很容易理解，不过还\\n\\n是建议大家用 plot_model()把模型结构图画出来，对照着模型结构图来看理解起来更容易，\\n\\n绝对能够让你清晰理解 GoogleNet 的具体结构（注意图片太大，dpi 不要调太高）。由于\\n\\nplot_model()画出来的图太长我就不放到书里了，大家可以自行操作。\\n\\n410\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.7 Batch Normalization 使用\\n\\nBN 我们在之前的内容中学习过，是一种很神奇的网络优化技巧，下面我们通过一个\\n\\nCIFAR10 的图像分类来对比一下，使用 BN 和不使用 BN 的模型效果，如代码 12-9 所示。\\n\\n代码 12-9：BN-CIFAR10 图像分类\\n\\nimport numpy as np from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchN ormalization,Activation from tensorflow.keras.optimizers import Adam,RMSprop import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data() # 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 换 one hot 格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10)\\n\\n# 定义卷积网络 model = Sequential() model.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding=\\'s ame\\', activation = \\'relu\\')) model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.2))\\n\\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\')) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.3))\\n\\n411\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 412 model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\' )) model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\', activation = \\'relu\\' )) model.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model.add(Dropout(0.4))\\n\\nmodel.add(Flatten()) model.add(Dense(10,activation = \\'softmax\\'))\\n\\n# 定义使用了 BN 的卷积网络 # 两个模型结构完全一致，区别只在于是否使用 BN model_bn = Sequential() model_bn.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, paddin g=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(Conv2D(filters=32, kernel_size=3, strides=1, padding=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model_bn.add(Dropout(0.2))\\n\\nmodel_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model_bn.add(Dropout(0.3))\\n\\nmodel_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding=\\'same\\')) model_bn.add(BatchNormalization()) model_bn.add(Activation(\\'relu\\')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding=\\'valid\\')) model_bn.add(Dropout(0.4))\\n\\nmodel_bn.add(Flatten()) model_bn.add(Dense(10,activation = \\'softmax\\'))\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 定义优化器 adam = Adam(lr=1e-4)\\n\\n# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\']) # 定义优化器，loss function，训练过程中计算准确率 model_bn.compile(optimizer=adam,loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\']) # 训练模型 history = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_t est), shuffle=True) history_bn = model_bn.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_ test, y_test), shuffle=True)\\n\\nplt.plot(np.arange(100),history.history[\\'val_accuracy\\'],c=\\'b\\',label=\\'without_bn\\') # 画出使用 BN 的模型验证集准确率 plt.plot(np.arange(100),history_bn.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'bn\\') plt.legend() plt.xlabel(\\'epochs\\') plt.ylabel(\\'accuracy\\') plt.show() 运行结果如下：\\n\\n12.8 ResNet 图像识别\\n\\n同样这里我们只展示 ResNet 建模相关代码，如代码 12-10 所示。\\n\\n413\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 12-10：ResNet50 图像识别\\n\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D …… …… …… # 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding=\\'valid\\')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut) else: # identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x)\\n\\nx = Conv2D(filters=filters,kernel_size=3,strides=1,padding=\\'same\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x)\\n\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x)\\n\\nx = Add()([x, shortcut]) x = Activation(\\'relu\\')(x) return x\\n\\n# 堆叠残差单元 def stack(x, filters, blocks, strides): x = block(x, filters, strides=strides) for i in range(blocks-1): x = block(x, filters, conv_shortcut=False) return x\\n\\n# 定义 ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230\\n\\n414\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding=\\'valid\\')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation=\\'softmax\\')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 19s 546ms/step - loss: 3.05 63 - accuracy: 0.1195 - val_loss: 2.8569 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 399ms/step - loss: 2.45 23 - accuracy: 0.2022 - val_loss: 2.9909 - val_accuracy: 0.0588\\n\\n……\\n\\nEpoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.02 24 - accuracy: 0.9954 - val_loss: 1.0080 - val_accuracy: 0.7794 Epoch 100/100 34/34 [==============================] - 14s 404ms/step - loss: 0.02 29 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794\\n\\n415\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这里我使用了一种比较简洁的方式来搭建 ResNet 模型，程序比较简洁，不过理解起来\\n\\n可能需要多花点时间，建议一行一行代码仔细理解。同时可以借助 plot_model()来帮助模型\\n\\n结构的理解。由于 plot_model()画出来的图太长我就不放到书里了，我截取两个局部给大家\\n\\n看看好了，图 12.10 为 identity shortcut 残差单元（左）和 projection shortcut 残差单元\\n\\n（右）。\\n\\n416\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.10 identity（左），projection（右）\\n\\n417\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.9 ResNeXt图像识别\\n\\n同样这里我们只展示 ResNeXt 建模相关代码，如代码 12-11 所示。\\n\\n代码 12-11：ResNeXt50(32×4d)图像识别\\n\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D,Lambda …… …… …… # 定义分组卷积 # g_channels 每组的通道数 # groups 多少组 def grouped_convolution_block(init_x, strides, groups, g_channels): group_list = [] # 分组进行卷积 for c in range(groups): # 分组取出数据 x = Lambda(lambda x: x[:, :, :, c*g_channels:(c+1)*g_channels])(init_x) # 分组进行卷积 x = Conv2D(filters=g_channels,kernel_size=3,strides=strides,padding=\\'same\\',use_bia s=False)(x) # 存入 list group_list.append(x) # 合并 list 中的数据 group_merge = concatenate(group_list, axis=3) x = BatchNormalization(epsilon=1.001e-5)(group_merge) x = Activation(\\'relu\\')(x) return x\\n\\n# 定义残差单元 def block(x, filters, strides=1, groups=32, conv_shortcut=True): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*2,kernel_size=1,strides=strides,padding=\\'same\\')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\\n\\n418\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com else: # identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=1,padding=\\'same\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x) # 计算每组的通道数 g_channels = int(filters / groups) # 进行分组卷积 x = grouped_convolution_block(x, strides, groups, g_channels)\\n\\nx = Conv2D(filters=filters*2,kernel_size=1,strides=1,padding=\\'same\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Add()([x, shortcut]) x = Activation(\\'relu\\')(x) return x\\n\\n# 堆叠残差单元 def stack(x, filters, blocks, strides, groups=32): x = block(x, filters, strides=strides, groups=groups) for i in range(blocks): x = block(x, filters, groups=groups, conv_shortcut=False) return x\\n\\n# 定义 ResNeXt50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding=\\'valid\\')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=128, blocks=2, strides=1) x = stack(x, filters=256, blocks=3, strides=2) x = stack(x, filters=512, blocks=5, strides=2) x = stack(x, filters=1024, blocks=2, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation=\\'softmax\\')(x)\\n\\n419\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义模型 model = Model(inputs=inputs,outputs=x)\\n\\n# 电脑配置不好的话不要运行 summary 或者 plot_model # model.summary() …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 37s 1s/step - loss: 2.8832 - accuracy: 0.0901 - val_loss: 2.9076 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 17s 490ms/step - loss: 2.48 76 - accuracy: 0.1838 - val_loss: 3.1728 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 17s 495ms/step - loss: 0.03 28 - accuracy: 0.9982 - val_loss: 0.9105 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 17s 495ms/step - loss: 0.02 48 - accuracy: 0.9991 - val_loss: 0.9058 - val_accuracy: 0.8088\\n\\nResNeXt50 的模型程序跟 ResNet50 差不多，使用一个函数\\n\\ngrouped_convolution_block 完成分组卷积的操作。建议大家使用 plot_model 看一下模型\\n\\n结构（建议 dpi 使用 96 或更低的值），groups=32 画出来的图太大了，下面给大家看一下\\n\\ngroups=4 画出来的图的残差结构，如图 12.11 所示。\\n\\n420\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.11 groups=4 的 ResNeXt 残差单元\\n\\n421\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.10 SENet 图像识别\\n\\n同样这里我们只展示 SE-ResNet50 建模相关代码，如代码 12-12 所示。\\n\\n代码 12-12：SE-ResNet50 图像识别\\n\\nfrom tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,BatchNormalization,Activation,Add,ZeroPadding2D,Multiply …… …… …… # SE 模块 def ChannelSE(input_tensor, reduction=16): # 获得信号通道数 channels = input_tensor.shape[-1] # SE 模块 x = GlobalAvgPool2D()(input_tensor) # 把 2 维数据再变成 4 维(?,1,1,?) x = x[:, None, None, :] # 卷积替代全连接层 x = Conv2D(filters=channels//reduction,kernel_size=1,strides=1)(x) x = Activation(\\'relu\\')(x) x = Conv2D(filters=channels,kernel_size=1,strides=1)(x) x = Activation(\\'sigmoid\\')(x) x = Multiply()([input_tensor, x]) return x\\n\\n# 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True, reduction=16): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding=\\'valid\\')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut) else: # identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x)\\n\\n422\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nx = Conv2D(filters=filters,kernel_size=3,strides=1,padding=\\'same\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x)\\n\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x)\\n\\n# SE 模块 x = ChannelSE(x, reduction=reduction)\\n\\nx = Add()([x, shortcut]) x = Activation(\\'relu\\')(x) return x\\n\\n# 堆叠残差单元 def stack(x, filters, blocks, strides): x = block(x, filters, strides=strides) for i in range(blocks-1): x = block(x, filters, conv_shortcut=False) return x\\n\\n# 定义 SE-ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding=\\'valid\\')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation(\\'relu\\')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding=\\'valid\\')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation=\\'softmax\\')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) ……\\n\\n423\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 27s 786ms/step - loss: 2.48 03 - accuracy: 0.2114 - val_loss: 2.8556 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 401ms/step - loss: 1.82 87 - accuracy: 0.4017 - val_loss: 2.9926 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.00 44 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 14s 407ms/step - loss: 0.00 43 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.8088\\n\\nSE-ResNet50 用 plot_model 画出来的图会很大，大家可以自己运行，下面我就给大家\\n\\n看一下 SE-ResNet50 其中一个残差单元的图，如图 12.12 所示。\\n\\n424\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n425\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.12 SE-ResNet50 残差单元\\n\\n12.11 使用预训练模型进行迁移学习\\n\\n12.11.1 使用训练好的模型进行图像识别\\n\\n本章前面的内容中，我们主要是学习了模型搭建方法，这一小节我们将学习使用迁移学\\n\\n习的方式来训练图像识别模型。图像识别的迁移学习简单的来说就是使用一个已经经过预训\\n\\n练的模型，在这个预训练的模型基础上稍作修改，然后训练自己的数据集，也称为微调\\n\\n（Finetune）。这里的预训练模型通常都是使用 ImageNet 比赛数据集训练出来的模型。\\n\\nTensorflow 中有很多官方提供的使用 ImageNet 数据集训练好的预训练模型，我们可以直\\n\\n接下载使用，如图 12.13 所示。\\n\\n图 12.13 可用预训练模型\\n\\n下面我们先看一下如何使用预训练模型来进行图像识别，第一次载入模型需要从网上下\\n\\n载模型，下载的模型会存放在你的用户目录下.keras 隐藏文件夹下的 models 文件夹中（比\\n\\n如 C:\\\\User\\\\qin\\\\.keras\\\\models）。我自己准备了一些图片存放在“test”文件夹中用于测\\n\\n试，如代码 12-13 所示。\\n\\n代码 12-13：使用训练好的 ResNet50 进行图像识别\\n\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\n\\n426\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # imagenet 数据处理工具 from tensorflow.keras.applications.imagenet_utils import decode_predictions,preprocess_in put from tensorflow.keras.preprocessing.image import img_to_array,load_img import matplotlib.pyplot as plt import os import numpy as np # 图片大小 image_size = 224 # 存放测试图片的文件夹 image_dir = \\'test\\' # 载入使用 imagenet 训练好的预训练模型 # include_top=True 表示模型包含全连接层 # include_top=False 表示模型不包含全连接层 # 下载的程序会存放在你的用户目录下.keras 隐藏文件夹下的 models 文件夹中 resnet50 = ResNet50(weights=\\'imagenet\\',include_top=True, input_shape=(image_size,ima ge_size,3))\\n\\n# 循环目录下的图片并进行显示预测 for file in os.listdir(image_dir): # 测试图片完整路径 file_dir = os.path.join(image_dir,file) # 读入图片，并 resize 为 224*224 大小 img = load_img(file_dir, target_size=(224, 224)) # 显示图片 plt.imshow(img) plt.axis(\\'off\\') plt.show() # 将图片转化为 array x = img_to_array(img) # 增加 1 个维度变成 4 维数据 # (224, 224, 3)->(1, 224, 224, 3) x = np.expand_dims(x, axis=0) # 把像素数值归一化为(-1,1)之间，并让 RGB 通道减去对应均值 x = preprocess_input(x) # preds.shap->(1, 1000),1000 个概率值 preds = resnet50.predict(x) # decode_predictions 用于预测结果解码 # 将测试结果解码为如下形式： # [(编码 1, 英文名称 1, 概率 1),(编码 2, 英文名称 2, 概率 2)...] # top=1 表示概率最大的 1 个结果，top=3 表示概率最大的 3 个结果 predicted_classes = decode_predictions(preds, top=1) imagenet_id, name, confidence = predicted_classes[0][0]\\n\\n427\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 打印结果 print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100)) 运行结果如下：\\n\\nThis is a sandbar with 44.15% confidence!\\n\\nThis is a soup_bowl with 61.99% confidence!\\n\\nThis is a tabby named chouchou with 90.97% confidence!\\n\\n12.11.2 使用训练好的模型进行迁移学习\\n\\n现在我们要使用预训练的模型来训练自己的数据集了，为了方便，我还是使用 17flowers\\n\\n的数据集，如果大家有其他数据集的话也可以使用。使用 VGG16 完成迁移学习的代码如代\\n\\n码 12-14 所示。\\n\\n代码 12-14：使用 VGG16 完成迁移学习\\n\\nfrom tensorflow.keras.applications.vgg16 import VGG16 from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dropout,Flatten,Dense\\n\\n428\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.optimizers import SGD from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load _img import json import matplotlib.pyplot as plt import numpy as np # 类别数 num_classes = 17 # 批次大小 batch_size = 32 # 周期数 epochs = 40 # 图片大小 image_size = 224 # 训练集数据进行数据增强 train_datagen = ImageDataGenerator( rotation_range = 20, # 随机旋转度数 width_shift_range = 0.1, # 随机水平平移 height_shift_range = 0.1,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 10, # 随机错切变换 zoom_range = 0.1, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range=(0.7, 1.3), # 亮度变化 fill_mode = \\'nearest\\', # 填充方式 ) # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator( rescale = 1/255, # 数据归一化 ) # 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从\\'data/train\\'获得训练集数据 # 获得数据后会把图片 resize 为 image_size×image_size 的大小 # generator 每次会产生 batch_size 个数据 train_generator = train_datagen.flow_from_directory( \\'data/train\\', target_size=(image_size,image_size), batch_size=batch_size, )\\n\\n# 测试集数据生成器 test_generator = test_datagen.flow_from_directory( \\'data/test\\', target_size=(image_size,image_size),\\n\\n429\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com batch_size=batch_size,\\n\\n)\\n\\n# 字典的键为 17 个文件夹的名字，值为对应的分类编号 label = train_generator.class_indices # 把字典的键值对反过来 # 分类编号为键，分类名称为值 label = dict(zip(label.values(),label.keys())) # 保存到 json 文件中 file = open(\\'label_flower.json\\',\\'w\\',encoding=\\'utf-8\\') json.dump(label, file) # 载入使用 imagenet 训练好的预训练模型 # include_top=True 表示模型包含全连接层 # include_top=False 表示模型不包含全连接层 vgg16 = VGG16(weights=\\'imagenet\\',include_top=False, input_shape=(image_size,image_s ize,3))\\n\\n# 搭建全连接层，连接在 VGG16 模型后面 # 我们主要是利用 VGG16 卷积网络已经训练好的特征提取能力来提取特征 # 然后搭建新的全连接层来进行新图片类型的分类 top_model = Sequential() top_model.add(Flatten(input_shape=vgg16.output_shape[1:])) top_model.add(Dense(256,activation=\\'relu\\')) top_model.add(Dropout(0.5)) top_model.add(Dense(num_classes,activation=\\'softmax\\'))\\n\\nmodel = Sequential() model.add(vgg16) model.add(top_model)\\n\\n# 定义优化器，代价函数，训练过程中计算准确率，设置一个较小的学习率 model.compile(optimizer=SGD(lr=1e- 3,momentum=0.9),loss=\\'categorical_crossentropy\\',metrics=[\\'accuracy\\'])\\n\\n# Tensorflow2.1 版本之前可以使用 fit_generator 训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc hs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\\n\\n# Tensorflow2.1 版本(包括 2.1)之后可以直接使用 fit 训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/40\\n\\n430\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 34/34 [==============================] - 15s 440ms/step - loss: 2.83 96 - accuracy: 0.1131 - val_loss: 2.2644 - val_accuracy: 0.2904 Epoch 2/40 34/34 [==============================] - 14s 406ms/step - loss: 1.97 65 - accuracy: 0.3713 - val_loss: 1.3263 - val_accuracy: 0.6029\\n\\n……\\n\\nEpoch 39/40 34/34 [==============================] - 14s 402ms/step - loss: 0.00 62 - accuracy: 0.9991 - val_loss: 0.1977 - val_accuracy: 0.9632 Epoch 40/40 34/34 [==============================] - 14s 399ms/step - loss: 0.01 21 - accuracy: 0.9945 - val_loss: 0.1575 - val_accuracy: 0.9706 # 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history[\\'accuracy\\'],c=\\'b\\',label=\\'train_accuracy\\') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history[\\'val_accuracy\\'],c=\\'y\\',label=\\'val_accuracy\\') # 图例 plt.legend() # x 坐标描述 plt.xlabel(\\'epochs\\') # y 坐标描述 plt.ylabel(\\'accuracy\\') # 显示图像 plt.show() # 模型保存 model.save(\\'vgg16.h5\\') 运行结果如下：\\n\\n431\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从结果我们可以看到是用了预训练的 VGG16 模型来训练 17flowers 数据集，模型的收\\n\\n敛速度非常快，只训练几个周期就得到了很好的结果。并且训练 40 个周期以后，模型的验\\n\\n证集达到了 97%非常高的准确率。\\n\\n12.11.3 载入训练好的模型进行预测\\n\\n上一小节我们训练好了一个 97%准确率的 17 种花的识别模型并保存为“vgg16.h5“模\\n\\n型文件，这个小节我们要重新载入这个训练好的模型，使用它对其他图片进行预测。模型分\\n\\n类编号跟分类名称的对应关系在上小节的程序里面也已经保存在“label_flower.json”文件\\n\\n中，可以直接载入。我准备了几张测试图片存放在“flowers_test”文件夹中，测试图片的\\n\\n文件名就是该图片的分类名称，如代码 12-15 所示。\\n\\n代码 12-15：载入训练好的模型进行预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.image import img_to_array,load_img import json import os import matplotlib.pyplot as plt import numpy as np # 测试图片存放位置 image_dir = \\'flowers_test\\' # 载入标签 json 文件 file = open(\\'label_flower.json\\',\\'r\\',encoding=\\'utf-8\\') label = json.load(file) # 键为分类编号，值为分类名称 print(label) 运行结果如下： {\\'0\\': \\'flower0\\', \\'1\\': \\'flower1\\', \\'2\\': \\'flower10\\', \\'3\\': \\'flower11\\', \\'4 \\': \\'flower12\\', \\'5\\': \\'flower13\\', \\'6\\': \\'flower14\\', \\'7\\': \\'flower15\\', \\'8 \\': \\'flower16\\', \\'9\\': \\'flower2\\', \\'10\\': \\'flower3\\', \\'11\\': \\'flower4\\', \\'12 \\': \\'flower5\\', \\'13\\': \\'flower6\\', \\'14\\': \\'flower7\\', \\'15\\': \\'flower8\\', \\'16 \\': \\'flower9\\'}\\n\\n代码 12-15：载入训练好的模型进行预测（片段 2）\\n\\n# 载入训练好的模型\\n\\n432\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model = load_model(\\'VGG16.h5\\')\\n\\n# 预测函数 def model_predict(file_dir): # 读入图片，并 resize 为 224*224 大小 img = load_img(file_dir, target_size=(224, 224)) # 显示图片 plt.imshow(img) plt.axis(\\'off\\') plt.show() # 将图片转化为 array x = img_to_array(img) # 增加 1 个维度变成 4 维数据 # (224, 224, 3)->(1, 224, 224, 3) x = np.expand_dims(x, axis=0) # 模型预测结果 # predict_classes 直接返回预测分类结果，比如:[2] preds = model.predict_classes(x) # label 字典中的键为字符串，所以这里需要把 preds[0]转为 str # 根据分类编号查询 label 中对应的分类名称 preds = label[str(preds[0])] return preds\\n\\n# 循环测试文件夹 for file in os.listdir(image_dir): # 测试图片完整路径 file_dir = os.path.join(image_dir,file) # 打印文件路径 print(file_dir) # 传入文件路径进行预测 preds = model_predict(file_dir) print(\\'predict:\\',preds) print(\\'-\\'*20) 运行结果如下： flowers_test\\\\flower0.jpg\\n\\npredict: flower0\\n\\n433\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com -------------------- flowers_test\\\\flower10.jpg\\n\\npredict: flower10 -------------------- flowers_test\\\\flower5.jpg\\n\\npredict: flower5 --------------------\\n\\n434\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 13 章-验证码识别项目实战\\n\\n本章属于内外兼修的章节，既有多任务学习和 CTC 算法介绍，又有大量 Tensorflow 应\\n\\n用技巧，如 tf.data 的使用，如何自定义数据生成器，如何自定义 Callbacks，多种\\n\\nCallbacks 用法，多任务模型的定义和训练。\\n\\n本章模型训练所需时间较长，如果情况允许的情况下，建议大家使用 GPU 来训练模型，\\n\\n提高效率。如果使用 CPU 训练本章模型，每个模型大约需要 2 天时间。\\n\\n13.1 多任务学习介绍\\n\\n多任务学习（Multi-task Learning）是深度学习中很常用的一种模型训练策略，意思\\n\\n其实也很简单，就是同时训练多个任务，给大家举两个例子大家就明白了。比如目标检测项\\n\\n目中，我们既要知道目标所在的位置（也就是预测框坐标值），也要知道预测框内是什么物\\n\\n体。预测框的坐标值是连续型数据，所以是一个回归任务；预测框的物体是一个具体的类\\n\\n别，所以是一个分类任务。如图 13.1 所示。\\n\\n图 13.1 目标检测任务\\n\\n图中的 task1 和 task2 可以共享卷积层。task1 就是目标检测的回归任务，用来预测目标\\n\\n框的位置，我们只要知道目标框左上角的(x1,y1)坐标和右下角的(x2,y2)坐标就可以把目标框\\n\\n435\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n给画出来，所以 task1 中需要 4 个神经元来预测 4 个回归值。task2 的作用是判断目标框内\\n\\n是什么物体，假设我们这个目标检测任务一共有 5 个分类，那么就需要 5 个神经元来预测 5\\n\\n个分类结果。\\n\\n再给大家举一个例子，比如我们在做人脸识别的时候，我们不仅可以识别人脸所在的位\\n\\n置，还可以识别人的年龄，表情，性别等特征。使用多任务学习的方式，我们可以让模型同\\n\\n时训练多个任务，模型训练好以后，输入一张图片，模型就可以输出人脸的位置，以及人的\\n\\n年龄，表情，性别，如图 13.2 所示。\\n\\n图 13.2 人脸识别任务\\n\\n如图所示，task1 任务是识别人脸所在位置，属于回归任务；task2 任务是识别人的年\\n\\n龄，也是回归任务；task3 任务是识别人的表情，人的表情可以人为的标注几个类别，属于\\n\\n分类任务；task4 任务是识别人的性别，当然也是分类任务。所以我们可以看到使用多任务\\n\\n学习模型可以同时训练多个任务，在模型预测阶段也可以同时对多个任务进行预测。\\n\\n我前面提到的多任务人脸识别的例子中，不同的任务其实也可以共享卷积层。因为卷积\\n\\n层的作用主要是特征提取，先提取图像的特征，然后再使用这些特征来预测人的年龄，表\\n\\n情，性别。用于特征提取的卷积层可以共享，不过不同的任务还需要有自己的 task layer，\\n\\n专门用于训练特定任务。\\n\\n436\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n13.2 验证码数据集生成\\n\\n验证码想必大家都很熟悉了，下面我们就来介绍一下我们本章要使用的验证码数据集。\\n\\n有一个 python 模块是专门用来生成验证码图片的，打开命令提示符输入命令：\\n\\npip install captcha\\n\\n验证码图片生成的代码如代码 13-1 所示。\\n\\n代码 13-1：验证码生成\\n\\n# 安装验证码生成库:pip install captcha from captcha.image import ImageCaptcha import random import string\\n\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits+string.ascii_letters\\n\\n# 随机产生验证码，长度为 4 def random_captcha_text(char_set=characters, captcha_size=4): # 验证码列表 captcha_text = [] for i in range(captcha_size): # 随机选择 c = random.choice(char_set) # 加入验证码列表 captcha_text.append(c) return captcha_text\\n\\n# 生成字符对应的验证码 def gen_captcha_text_and_image(): # 验证码图片宽高可以设置，默认 width=160, height=60 image = ImageCaptcha(width=160, height=60) # 获得随机生成的验证码 captcha_text = random_captcha_text() # 把验证码列表转为字符串 captcha_text = \\'\\'.join(captcha_text) # 保存验证码图片 image.write(captcha_text, \\'captcha/\\' + captcha_text + \\'.jpg\\')\\n\\n437\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 产生 1000 次随机验证码 # 真正的数量可能会少于 1000 # 因为重名的图片会被覆盖掉 num = 1000 for i in range(num): gen_captcha_text_and_image()\\n\\nprint(\"生成完毕\")\\n\\n程序运行后会在‘captcha’文件夹下产生差不多 1000 张验证码的图片，虽然生成验证\\n\\n码的程序运行了 1000 次，不过有可能会产生两张重名的图片，第二张图片会把第一张图片\\n\\n给覆盖掉，所以实际图片可能不到 1000 张。运行程序后得到的验证码图片如图 13.3 所示。\\n\\n图 13.3 验证码图片\\n\\n13.3 tf.data 介绍\\n\\ntf.data 是一个很好用的数据读取管道搭建的 API，具有高性能并且简洁易用的特点。我\\n\\n们可以使用 tf.data 来定义数据从哪里获取，获取以后如何对数据进行处理，处理以后还可以\\n\\n打乱数据，给数据进行分批次等，总而言之 tf.data 的作用就是用来获取并处理数据的。\\n\\n438\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\ntf.data 最常用的用法就是使用 tf.data.Dataset.from_tensor_slices 来获取数据，例如：\\n\\ndataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n\\n(x_train, y_train)是训练集数据和对应标签。\\n\\ntf.data.Dataset 支持一类特殊的操作：Transformation。一个 Dataset 通过\\n\\nTransformation 可以变成一个新的 Dataset。通常我们就是使用 Transformation 来对数据\\n\\n进行处理的。例如：\\n\\n1.使用 shuffle 来打乱数据：\\n\\ndataset_train = dataset_train.shuffle(buffer_size=1000)\\n\\n2.使用 map 进行数据处理。map 可以接收一个自定义数据处理函数，Dataset 中的数\\n\\n据会传入 map 中的函数进行处理，并返回处理后的数据作为新的 Dataset：\\n\\ndataset_train = dataset_train.map(image_function)\\n\\n3.使用 repeat 来重复数据。repeat 可以将数据序列重复 n 次，其实也就是重复 n 个周\\n\\n期 epoch。一般我认为就只重复 1 个周期比较好，因为模型训练的时候(model.fit)还会再设\\n\\n置模型训练周期：\\n\\ndataset_train = dataset_train.repeat(1)\\n\\n4.使用 batch 来设置数据产生的批次大小：\\n\\ndataset_train = dataset_train.batch(batch_size)\\n\\n这几个 Transformation 是用得比较多的，还有其他的一些 Transformation 这里我们就\\n\\n不一一列出了。\\n\\n定义好 Dataset 以后我们可以使用：\\n\\nx,y = next(iter(dataset_test))\\n\\n来获得一个批次的数据和标签，查看数据的情况。\\n\\n也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次数据：\\n\\nfor x,y in dataset_test: pass\\n\\n模型训练阶段可以把 Dataset 传入 model.fit 中进行训练：\\n\\n439\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nmodel.fit(x=dataset_train)\\n\\n除非是在本书相关的实际应用中用到，否则我就不展开介绍 Tensorflow 的一些细节上的\\n\\n使用了，如果不结合实际应用很多内容感觉说不明白。更多 tf.data 的使用方法可以参考\\n\\nTensorflow 官方指南（https://tensorflow.google.cn/guide/data）。\\n\\n13.4 使用 tf.data 完成多任务学习-验证码识\\n\\n别\\n\\n13.4.1 使用 tf.data 完成多任务学习模型训练\\n\\n本小节我们将介绍使用多任务学习的方法来进行验证码识别，比如我们要识别的验证码\\n\\n有 4 个字符，我们可以给模型定义 4 个任务，每个任务负责识别 1 个字符。第一个任务识别\\n\\n第一个字符，第二个任务识别第二个字符，第三个任务识别第三个字符，第四个任务识别第\\n\\n四个字符。模型框架如图 13.4 所示。\\n\\n13.4 验证码识别模型框架\\n\\n440\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 4 个输出表示 4 个任务，每个输出都是 62 分类是由于我们使用的验证码的字符是\\n\\n数字加上大小写英文字母所以一共 62 种字符。\\n\\n代码 13-2：tf.data-多任务学习-验证码识别（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input from tensorflow.keras.optimizers import SGD from tensorflow.keras.models import Model from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau import string import numpy as np import os from plot_model import plot_model\\n\\n# 字符包含所有数字和所有小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 62 num_classes = len(characters) # 批次大小 batch_size = 64 # 周期数 epochs=100 # 训练集数据，大约 50000 张图片 # 事先用 captcha 模块生成，长度都是 4 train_dir = \"./captcha/train/\" # 测试集数据，大约 10000 张图片 # 事先用 captcha 模块生成，长度都是 4 test_dir = \"./captcha/test/\" # 图片宽度 width=160 # 图片高度 height=60\\n\\n# 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir): # 存放图片路径 photo_filenames = []\\n\\n441\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 存放图片标签 y = [] for filename in os.listdir(dataset_dir): # 获取文件完整路径 path = os.path.join(dataset_dir, filename) # 保存图片路径 photo_filenames.append(path) # 取文件名前 4 位，也就是验证码的标签 captcha_text = filename[0:4] # 定义一个空 label label = np.zeros((4, num_classes), dtype=np.uint8) # 标签转独热编码 for i, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 # characters.find(ch)得到 ch 在 characters 中的位置，可以理解为 ch 的编号 label[i, characters.find(ch)] = 1 # 保存独热编码的标签 y.append(label) # 返回图片路径和标签\\n\\nreturn np.array(photo_filenames),np.array(y)\\n\\n# 获取训练集图片路径和标签 x_train,y_train = get_filenames_and_classes(train_dir)\\n\\n# 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)\\n\\n# 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label): # 根据图片路径读取图片内容 image = tf.io.read_file(filenames) # 将图像解码为 jpeg 格式的 3 维数据 image = tf.image.decode_jpeg(image, channels=3) # 归一化 image = tf.cast(image, tf.float32) / 255.0 # 返回图片数据和标签 return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label): # transpose 改变数据的维度，比如原来的数据 shape 是(64,4,62) # 这里的 64 是批次大小，验证码长度为 4 有 4 个标签，62 是 62 个不同的字符\\n\\n442\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # tf.transpose(label,[1,0,2])计算后得到的 shape 为(4,64,62) # 原来的第 1 个维度变成了第 0 维度，原来的第 0 维度变成了 1 维度，第 2 维不变 # (64,4,62)->(4,64,62) label = tf.transpose(label,[1,0,2]) # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义 4 个任务，所以这里返 回 4 个标签 # 每个标签的 shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签 return image, (label[0],label[1],label[2],label[3])\\n\\n# 创建 dataset 对象，传入训练集图片路径和标签 dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_train = dataset_train.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_train = dataset_train.map(image_function) # 数据重复生成 1 个周期 dataset_train = dataset_train.repeat(1) # 定义批次大小 dataset_train = dataset_train.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_train = dataset_train.map(label_function)\\n\\n# 创建 dataset 对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成 1 个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_test = dataset_test.map(label_function)\\n\\n# 生成一个批次的数据和标签\\n\\n443\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 可以用于查看数据和标签的情况 x,y = next(iter(dataset_test)) print(x.shape) print(np.array(y).shape) 结果输出为： (64, 60, 160, 3) (4, 64, 62)\\n\\n代码 13-2：tf.data-多任务学习-验证码识别（片段 2）\\n\\n# 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次 # for x,y in dataset_test: # pass # 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights=\\'imagenet\\', include_top=False, input_shape=(height,width,3) ) # 设置输入 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的 4 个字符看成是 4 个不同的任务 # 每个任务负责识别 1 个字符 # 任务 1 识别第 1 个字符，任务 2 识别第 2 个字符，任务 3 识别第 3 个字符，任务 4 识别第 4 个字符 x0 = Dense(num_classes, activation=\\'softmax\\', name=\\'out0\\')(x) x1 = Dense(num_classes, activation=\\'softmax\\', name=\\'out1\\')(x) x2 = Dense(num_classes, activation=\\'softmax\\', name=\\'out2\\')(x) x3 = Dense(num_classes, activation=\\'softmax\\', name=\\'out3\\')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)\\n\\n# 4 个任务我们可以定义 4 个 loss # loss_weights 可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样 model.compile(loss={\\'out0\\':\\'categorical_crossentropy\\', \\'out1\\':\\'categorical_crossentropy\\', \\'out2\\':\\'categorical_crossentropy\\', \\'out3\\':\\'categorical_crossentropy\\'}, loss_weights={\\'out0\\':1,\\n\\n444\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com \\'out1\\':1, \\'out2\\':1, \\'out3\\':1}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=[\\'acc\\'])\\n\\n# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor=\\'val_loss\\', patience=6, verbose=1), CSVLogger(\\'Captcha_tfdata.csv\\'), ModelCheckpoint(\\'Best_Captcha_tfdata.h5\\', monitor=\\'val_loss\\', save_best_only=Tr ue), ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.1, patience=3, verbose=1)]\\n\\n# 训练模型 # 把之前定义的 dataset_train 和 dataset_test 传入进行训练 model.fit(x=dataset_train, epochs=epochs, validation_data=dataset_test, callbacks=callbacks) 结果输出为： Train for 781 steps, validate for 156 steps Epoch 1/100 781/781 [==============================] - 96s 123ms/step - loss: 7. 1427 - out0_loss: 1.3058 - out1_loss: 2.1121 - out2_loss: 2.0675 - ou t3_loss: 1.6573 - out0_acc: 0.6824 - out1_acc: 0.4488 - out2_acc: 0.4 548 - out3_acc: 0.5494 - val_loss: 16.5515 - val_out0_loss: 9.0025 - val_out1_loss: 3.4140 - val_out2_loss: 2.1353 - val_out3_loss: 1.999 7 - val_out0_acc: 0.0323 - val_out1_acc: 0.2611 - val_out2_acc: 0.472 8 - val_out3_acc: 0.4884 …… Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999019 782991e-06. 781/781 [==============================] - 88s 113ms/step - loss: 0. 0088 - out0_loss: 0.0028 - out1_loss: 0.0020 - out2_loss: 0.0018 - ou t3_loss: 0.0021 - out0_acc: 1.0000 - out1_acc: 0.9999 - out2_acc: 1.0 000 - out3_acc: 1.0000 - val_loss: 0.6167 - val_out0_loss: 0.2020 - v al_out1_loss: 0.1470 - val_out2_loss: 0.1508 - val_out3_loss: 0.1168\\n\\n445\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 446 - val_out0_acc: 0.9550 - val_out1_acc: 0.9644 - val_out2_acc: 0.9647 - val_out3_acc: 0.9708 Epoch 00023: early stopping\\n\\n模型的初始学习率为 0.01，随着模型训练学习率会逐渐降低，最后模型训练了 23 周期\\n\\n就提前停止了。我们可以看到训练集的 4 个任务准确率基本上都已经是 1 了，测试集的 4 个\\n\\n任务准确率大约为 0.96 左右，有一定的过拟合现象也是正常的。\\n\\n别看 0.96 的准确率好像挺高的，验证码识别可是要 4 个验证码都识别正确，最后的结果\\n\\n才算正确。所以真正的识别正确率大约是 4 个任务的正确率相乘约等于 0.86，结果也还可\\n\\n以，不过这么看好像就不算非常高了。\\n\\n13.4.2 使用 tf.data 完成多任务学习模型预测\\n\\n下面我们再来看一下载入训练好的模型进行准确率计算和验证码结果预测的程序，如代\\n\\n码 13-3 所示。。\\n\\n代码 13-3：tf.data-多任务学习-验证码识别-模型预测（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model import matplotlib.pyplot as plt import os import numpy as np import string\\n\\n# 载入之前训练好的模型 model = load_model(\\'Best_Captcha_tfdata.h5\\')\\n\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集数据，大约 10000 张图片 # 事先用 captcha 模块生成，长度都是 4 test_dir = \"./captcha/test/\"\\n\\n# 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir): # 存放图片路径 photo_filenames = [] # 存放图片标签 y = [] for filename in os.listdir(dataset_dir): # 获取文件完整路径 path = os.path.join(dataset_dir, filename) # 保存图片路径 photo_filenames.append(path) # 取文件名前 4 位，也就是验证码的标签 captcha_text = filename[0:4] # 定义一个空 label label = np.zeros((4, num_classes), dtype=np.uint8) # 标签转独热编码 for i, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 # characters.find(ch)得到 ch 在 characters 中的位置，可以理解为 ch 的编号 label[i, characters.find(ch)] = 1 # 保存独热编码的标签 y.append(label) # 返回图片路径和标签 return np.array(photo_filenames),np.array(y)\\n\\n# 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)\\n\\n# 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label): # 根据图片路径读取图片内容 image = tf.io.read_file(filenames) # 将图像解码为 jpeg 格式的 3 维数据 image = tf.image.decode_jpeg(image, channels=3) # 归一化 image = tf.cast(image, tf.float32) / 255.0 # 返回图片数据和标签\\n\\n447\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label): # transpose 改变数据的维度，比如原来的数据 shape 是(64,4,62) # 这里的 64 是批次大小，验证码长度为 4 有 4 个标签，62 是 62 个不同的字符 # tf.transpose(label,[1,0,2])计算后得到的 shape 为(4,64,62) # 原来的第 1 个维度变成了第 0 维度，原来的第 0 维度变成了 1 维度，第 2 维不变 # (64,4,62)->(4,64,62) label = tf.transpose(label,[1,0,2]) # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义 4 个任务，所以这里返 回 4 个标签 # 每个标签的 shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签 return image, (label[0],label[1],label[2],label[3])\\n\\n# 创建 dataset 对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成 1 个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_test = dataset_test.map(label_function)\\n\\n# 用于统计准确率 acc_sum = 0 # 统计批次数量 n = 0 for x,y in dataset_test: # 计算批次数量 n+=1 # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1)\\n\\n448\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 获得标签数据 label = np.argmax(y, axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean() # 计算测试集准确率 print(acc_sum / n) 结果输出为： 0.8631052107614607\\n\\n代码 13-3：tf.data-多任务学习-验证码识别-模型预测（片段 2）\\n\\n# 把标签编号变成字符串 # 如[2,34,22,45]->\\'2ymJ\\' def labels_to_text(labels): ret = [] for l in labels: ret.append(characters[l]) return \"\".join(ret)\\n\\n# 把一个批次的标签编号都变成字符串 def decode_batch(labels): ret = [] for label in labels: ret.append(labels_to_text(label))\\n\\nreturn np.array(ret)\\n\\n# 获得一个批次数据 x,y = next(iter(dataset_test)) # 预测结果 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1) # shape 转换 # (4,64)->(64,4) pred = pred.T # 获得标签数据 label = np.argmax(y, axis=-1) # (4,64)->(64,4) label = label.T # 根据编号获得对应验证码 pred = decode_batch(pred) # 根据编号获得对应验证码 label = decode_batch(label)\\n\\n449\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 获取前 3 张图片数据 for i,image in enumerate(x[:3]): # 显示图片 plt.imshow(image) # 设置标题 plt.title(\\'real:%s\\\\npred:%s\\'%(label[i],pred[i])) plt.show() 结果输出为：\\n\\n我们可以看到，要把 4 个验证码都预测正确其实还是挺难的，因为我这里做的验证码识\\n\\n别是需要区分大小写的，比如第一张图片中的第 3 个字符正确标签是小 x，模型预测结果是\\n\\n450\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n大 X，这确实很容易判断错误。还有 0 小 o 大 O 等这些都比较容易混淆，所以能得到 86%\\n\\n的准确率也还算不错了。\\n\\n13.5 使用自定义数据生成器完成验证码识别\\n\\n13.5.1 使用自定义数据生成器完成模型训练\\n\\n我们之前有用过 Tensorflow.keras 自带的一个专门用来处理图片数据的生成器\\n\\nImageDataGenerator，它可以从电脑硬盘读取数据，然后进行数据增强处理，再生成一个\\n\\n一个批次的数据，在 model.fit 中进行模型训练。\\n\\n我们现在要做的验证码识别项目使用的数据集是一个 python 模块自动生成的，所以在\\n\\n训练模型的时候我们可以一边生成数据集一边训练模型，那么我们可以自定义一个生成器来\\n\\n完成这个数据生成的工作。本小节我们也将使用多任务学习的方式来完成验证码识别的模型\\n\\n训练，不过我们这次不是用 tf.data 来获取和处理数据，我们将通过自定义数据生成器来完成\\n\\n数据的产生和处理，如代码 13-4 所示。。\\n\\n代码 13-4：自定义数据生成器-验证码识别（片段 1）\\n\\nfrom tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model\\n\\n451\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60\\n\\n# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度 self.n_len = n_len # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度\\n\\n452\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.num_classes = len(characters) # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []\\n\\n# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # n_len 是多任务学习的任务数量，这里是 4 个任务，batch 批次大小，num_classes 分 类数量 y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8) # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 captcha_text = \\'\\'.join([random.choice(self.characters) for j in range(self.n_len)]) self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3]]\\n\\n# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 显示图片 plt.imshow(x[0])\\n\\n453\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n代码 13-4：自定义数据生成器-验证码识别（片段 2）\\n\\n# 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights=\\'imagenet\\', include_top=False, input_shape=(height,width,3) ) # 设置输入 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的 4 个字符看成是 4 个不同的任务 # 每个任务负责识别 1 个字符 # 任务 1 识别第 1 个字符，任务 2 识别第 2 个字符，任务 3 识别第 3 个字符，任务 4 识别第 4 个字符 x0 = Dense(num_classes, activation=\\'softmax\\', name=\\'out0\\')(x) x1 = Dense(num_classes, activation=\\'softmax\\', name=\\'out1\\')(x) x2 = Dense(num_classes, activation=\\'softmax\\', name=\\'out2\\')(x) x3 = Dense(num_classes, activation=\\'softmax\\', name=\\'out3\\')(x) # 定义模型\\n\\n454\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)\\n\\n# 4 个任务我们可以定义 4 个 loss # loss_weights 可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样 model.compile(loss={\\'out0\\':\\'categorical_crossentropy\\', \\'out1\\':\\'categorical_crossentropy\\', \\'out2\\':\\'categorical_crossentropy\\', \\'out3\\':\\'categorical_crossentropy\\'}, loss_weights={\\'out0\\':1, \\'out1\\':1, \\'out2\\':1, \\'out3\\':1}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=[\\'acc\\'])\\n\\n# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor=\\'val_loss\\', patience=6, verbose=1), CSVLogger(\\'Captcha.csv\\'), ModelCheckpoint(\\'Best_Captcha.h5\\', monitor=\\'val_loss\\', save_best_only=True), ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.1, patience=3, verbose=1)] # 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_st eps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 164s 164ms/step - loss: 10.0266 - out0_loss: 2.3069 - out1_loss: 2.7054 - out2_loss: 2.6668 - out3_loss: 2.3474 - out0_acc: 0.3711 - out1_acc: 0.3144 - out2_acc: 0.3197 - out3_acc: 0.3896 - val_loss: 3.8732 - val_out0_loss: 1.1623 - val_out1_loss: 0.9057 - val_out2_loss: 0.9186 - val_out3_loss: 0.8 866 - val_out0_acc: 0.6719 - val_out1_acc: 0.7352 - val_out2_acc: 0.7 278 - val_out3_acc: 0.7531\\n\\n455\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com …… Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-07. 1000/1000 [==============================] - 160s 160ms/step - loss: 0.1092 - out0_loss: 0.0254 - out1_loss: 0.0295 - out2_loss: 0.0283 - out3_loss: 0.0260 - out0_acc: 0.9901 - out1_acc: 0.9880 - out2_acc: 0.9885 - out3_acc: 0.9902 - val_loss: 0.1104 - val_out0_loss: 0.0260 - val_out1_loss: 0.0304 - val_out2_loss: 0.0273 - val_out3_loss: 0.02 67 - val_out0_acc: 0.9902 - val_out1_acc: 0.9877 - val_out2_acc: 0.99 00 - val_out3_acc: 0.9881 Epoch 00050: early stopping\\n\\n由于使用自定义数据生成器可以生产出无数张图片，所以相当于模型的训练数据比之前\\n\\n用 tf.data 从硬盘中读取数据要多了很多。最终我们也可以看到更多的训练数据得到的结果也\\n\\n会更好。\\n\\n13.5.2 使用自定义数据生成器完成模型预测\\n\\n下面我们来看一下关于模型预测部分的程序，如代码 13-5 所示。\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 批次大小 batch_size = 64 # 载入训练好的模型 model = load_model(\\'Best_Captcha.h5\\')\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的，\\n\\n456\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度 self.n_len = n_len # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = len(characters) # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []\\n\\n# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # n_len 是多任务学习的任务数量，这里是 4 个任务，batch 批次大小，num_classes 分 类数量 y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8) # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 captcha_text = \\'\\'.join([random.choice(self.characters) for j in range(self.n_len)]) self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符)\\n\\n457\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3]]\\n\\n# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试模型，随机生成验证码 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred,axis=-1)[:,0] # 根据编号获得对应验证码 pred = \\'\\'.join([characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(\\'real:%s\\\\npred:%s\\'%(data.captcha_list[0],pred)) plt.show() 结果输出为：\\n\\n458\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 2）\\n\\n# 自定义验证码生成和预测 # 生成自定义验证码 captcha_text = \\'0oO0\\' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成 4 维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred,axis=-1)[:,0] # 根据编号获得对应验证码 pred = \\'\\'.join([characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(\\'real:%s\\\\npred:%s\\'%(captcha_text,pred)) plt.show() 结果输出为：\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 3）\\n\\n459\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 计算准确率，区分大小写 def accuracy(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1) # 获得标签数据 label = np.argmax(y, axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean() # 返回平均准确率 return acc_sum / test_steps # 计算准确率，区分大小写 print(accuracy()) 结果输出为： 0.956875\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 4）\\n\\n# 计算准确率，忽略大小写 def accuracy2(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred,axis=-1).T # 保存预测值 pred_list = [] # 把验证码预测值转小写后保存 for c in pred: # 根据编号获得对应验证码 temp_c = \\'\\'.join([characters[x] for x in c]) # 字母都转小写后保存 pred_list.append(temp_c.lower()) # 获得标签数据 label = np.argmax(y, axis=-1).T # 保存标签 label_list = []\\n\\n460\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # # 把验证码标签值转小写后保存 for c in label: # 根据编号获得对应验证码 temp_c = \\'\\'.join([characters[x] for x in c]) # 字母都转小写后保存 label_list.append(temp_c.lower()) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (np.array(pred_list) == np.array(label_list)).mean() # 返回平均准确率 return acc_sum / test_steps # 计算准确率，忽略大小写 print(accuracy2()) 结果输出为： 0.98546875\\n\\n我们从测试结果可以看到使用自定义数据生成器产生更多的训练数据以后，模型的准确\\n\\n率提高到了 95.69%（区分大小写）非常高的准确率，如果不区分大小写准确率可以进一步\\n\\n提高到 98.55%。\\n\\n在自定义验证码程序段中，我生成了一个“0oO0”验证码，就问大家能不能分辨出哪个\\n\\n是 0，哪个是 o，哪个是 O，反正我肯定是分不出来，但是这个模型还能识别正确（当然这\\n\\n个难度还是很大的，不能保证它每一次都能识别正确）。我觉得我们训练的这个模型在这种\\n\\n类型的验证码识别准确率上应该是超过了人类。\\n\\n13.6 挑战变长验证码识别\\n\\n13.6.1 挑战变长验证码识别模型训练\\n\\n前面我们生成的验证码是固定 4 位长度的，下面我们将增加难度，挑战不固定长度的验\\n\\n证码识别，验证码长度我设置为 3-6 位的随机 4 种长度。程序大体框架跟“代码 13-4：自\\n\\n461\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n定义数据生成器-验证码识别”差不多，主要是自定义数据生成器的部分做了一些修改，让数\\n\\n据生成器会产生随机长度的验证码。\\n\\n不过为了保证标签对齐，所以我们还是需要固定标签的数量和多任务学习任务的数量。\\n\\n因为验证码最长是 6，所以我们把标签的长度和多任务学习任务数量固定为 6，标签不足长\\n\\n度 6 的情况我们会把标签填充到 6。模型的类别数会增加一个空白类别，用于填充。\\n\\n另外我还给模型增加了一个新的任务，用于预测验证码的长度，这个任务其实可有可\\n\\n无，不过用作演示还是加上给大家看看效果，模型结构如图 13.5 所示。\\n\\n图 13.5 变长验证码识别\\n\\n图中有一共有 7 个输出，其中 6 个输出表示验证码识别的 6 个任务，每个任务有 63 个\\n\\n类别（62 个字符加一个空白符）。还有一个输出表示验证码的长度，有 4 个类别，分别表示\\n\\n3，4，5，6，一共 4 种验证码的长度。\\n\\n462\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n挑战变长验证码识别的代码如代码 13-6 所示。\\n\\n代码 13-6：挑战变长验证码识别（片段 1）\\n\\nfrom tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # 最长验证码 max_len = 6\\n\\n# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。\\n\\n463\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []\\n\\n# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # 6 个验证码识别任务，batch 批次大小，num_classes 分类数量 y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32) # 数据清 0 self.captcha_list = [] # 初始化数据用于保存判断验证码长度的标签，一共 4 种情况 len_captcha = np.zeros((self.batch_size, 4), dtype=np.int) # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 设置标签，独热编码 one-hot 格式，一共 4 种情况 len_captcha[i, self.n_len-3] = 1 # 转字符串 captcha_text = \\'\\'.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码\\n\\n464\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 如果验证码长度不是 6，则需要设置空白字符的标签为 1 # 空白字符在-1 位置 for k in range(len(captcha_text),max_len): # 空白字符 y[k, i, -1] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]\\n\\n# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n465\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-6：挑战变长验证码识别（片段 2）\\n\\n# 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights=\\'imagenet\\', include_top=False, input_shape=(height,width,3) )\\n\\n# 设置输入图片 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 每个任务负责识别 1 个字符 x0 = Dense(num_classes, activation=\\'softmax\\', name=\\'out0\\')(x) x1 = Dense(num_classes, activation=\\'softmax\\', name=\\'out1\\')(x) x2 = Dense(num_classes, activation=\\'softmax\\', name=\\'out2\\')(x) x3 = Dense(num_classes, activation=\\'softmax\\', name=\\'out3\\')(x) x4 = Dense(num_classes, activation=\\'softmax\\', name=\\'out4\\')(x) x5 = Dense(num_classes, activation=\\'softmax\\', name=\\'out5\\')(x) # 预测验证码长度 3-6，4 种情况所以定义 4 个分类 num_x = Dense(4, activation=\\'softmax\\', name=\\'out_num\\')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3,x4,x5,num_x]) # 画图 plot_model(model,style=0,dpi=200)\\n\\n# loss_weights 可以用来设置不同任务的权重，验证码识别的 6 个任务权重都一样 # 相对而言 out_num 更重要一些，因为如果验证码的长度判断错误，那么识别结果一定是错 的 # 所以可以给 out_num 更大一点的权重 model.compile(loss={\\'out0\\':\\'categorical_crossentropy\\', \\'out1\\':\\'categorical_crossentropy\\', \\'out2\\':\\'categorical_crossentropy\\',\\n\\n466\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com \\'out3\\':\\'categorical_crossentropy\\', \\'out4\\':\\'categorical_crossentropy\\', \\'out5\\':\\'categorical_crossentropy\\', \\'out_num\\':\\'categorical_crossentropy\\'}, loss_weights={\\'out0\\':1, \\'out1\\':1, \\'out2\\':1, \\'out3\\':1, \\'out4\\':1, \\'out5\\':1, \\'out_num\\':2}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=[\\'acc\\'])\\n\\n# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor=\\'val_loss\\', patience=6, verbose=1), CSVLogger(\\'Captcha2.csv\\'), ModelCheckpoint(\\'Best_Captcha2.h5\\', monitor=\\'val_loss\\', save_best_only=True), ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.1, patience=3, verbose=1)]\\n\\n# 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_ steps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 184s 184ms/step - loss: 14.0520 - out0_loss: 2.2189 - out1_loss: 2.6810 - out2_loss: 2.9503 - out3_loss: 2.5608 - out4_loss: 1.8766 - out5_loss: 1.0524 - out_num _loss: 0.3560 - out0_acc: 0.4063 - out1_acc: 0.3020 - out2_acc: 0.244 7 - out3_acc: 0.3636 - out4_acc: 0.5493 - out5_acc: 0.7673 - out_num_ acc: 0.8614 - val_loss: 13.9098 - val_out0_loss: 2.5258 - val_out1_lo ss: 1.9578 - val_out2_loss: 2.3671 - val_out3_loss: 2.5046 - val_out4 _loss: 1.6575 - val_out5_loss: 0.9196 - val_out_num_loss: 0.9887 - va l_out0_acc: 0.4391 - val_out1_acc: 0.5095 - val_out2_acc: 0.4242 - va\\n\\n467\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 468 l_out3_acc: 0.4322 - val_out4_acc: 0.6039 - val_out5_acc: 0.7880 - va l_out_num_acc: 0.8316 …… Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-08. 1000/1000 [==============================] - 178s 178ms/step - loss: 0.2524 - out0_loss: 0.0436 - out1_loss: 0.0534 - out2_loss: 0.0558 - out3_loss: 0.0457 - out4_loss: 0.0341 - out5_loss: 0.0173 - out_num_ loss: 0.0013 - out0_acc: 0.9825 - out1_acc: 0.9796 - out2_acc: 0.9800 - out3_acc: 0.9823 - out4_acc: 0.9870 - out5_acc: 0.9930 - out_num_a cc: 0.9997 - val_loss: 0.2374 - val_out0_loss: 0.0452 - val_out1_los s: 0.0515 - val_out2_loss: 0.0498 - val_out3_loss: 0.0404 - val_out4_ loss: 0.0307 - val_out5_loss: 0.0174 - val_out_num_loss: 0.0012 - val _out0_acc: 0.9823 - val_out1_acc: 0.9786 - val_out2_acc: 0.9792 - val _out3_acc: 0.9841 - val_out4_acc: 0.9886 - val_out5_acc: 0.9931 - val _out_num_acc: 0.9997 Epoch 00036: early stopping\\n\\n从模型最后的结果看来预测验证码长度的任务准确率几乎达到了 1，也就是说模型预测验\\n\\n证码的长度是非常准了。6 个验证码预测任务中准确率最高的是 out5，也就是最后 1 位验证\\n\\n码的预测。out5 准确率明显高于其他任务是因为验证码的长度是 3-6，也就是说只要验证码\\n\\n的长度判断正确，那么有 75%的可能性最后 1 位验证码它就是空白符，所以准确率比较高。\\n\\n相对而言 out0-out2 的准确率就会偏低一些了，因为不可能会有空白符。\\n\\n13.6.2 挑战变长验证码识别模型预测\\n\\n实现变长验证码识别-模型预测的代码如代码 13-7 所示。\\n\\n代码 13-7：变长验证码识别-模型预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入训练好的模型 model = load_model(\\'Best_Captcha2.h5\\') # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 预测阶段使用的字符多一个空白符在最后 pred_characters = characters + \\' \\' # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 最长验证码 max_len = 6\\n\\n# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []\\n\\n# 获得 index 位置的批次数据\\n\\n469\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # 6 个验证码识别任务，batch 批次大小，num_classes 分类数量 y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32) # 数据清 0 self.captcha_list = [] # 初始化数据用于保存判断验证码长度的标签，一共 4 种情况 len_captcha = np.zeros((self.batch_size, 4), dtype=np.int) # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 设置标签，独热编码 one-hot 格式，一共 4 种情况 len_captcha[i, self.n_len-3] = 1 # 转字符串 captcha_text = \\'\\'.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码 self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 如果验证码长度不是 6，则需要设置空白字符的标签为 1 # 空白字符在-1 位置 for k in range(len(captcha_text),max_len): # 空白字符 y[k, i, -1] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]\\n\\n# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试模型 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据\\n\\n470\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com x, y = data[0] # 预测结果 pred = model.predict(x) # 0 表示长度 3，1 表示长度 4，2 表示长度 5，3 表示长度 6 captcha_len = np.argmax(pred[6],axis=-1)[0]+3 # 打印验证码长度 print(\\'验证码长度：\\',captcha_len) # 获得对应编号 captcha = np.argmax(pred[:6],axis=-1)[:,0] # 根据编号获得对应验证码 # 注意这里需要使用 pred_characters，包含空白符 pred = \\'\\'.join([pred_characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(\\'real:%s\\\\npred:%s\\'%(data.captcha_list[0],pred)) plt.show() 结果输出为： 验证码长度： 6\\n\\n验证码长度： 5\\n\\n代码 13-7：变长验证码识别-模型预测（片段 2）\\n\\n# 自定义验证码生成和预测 # 生成自定义验证码\\n\\n471\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com captcha_text = \\'oOxXvV\\' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成 4 维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred[:6],axis=-1)[:,0] # 根据编号获得对应验证码 pred = \\'\\'.join([pred_characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(\\'real:%s\\\\npred:%s\\'%(captcha_text,pred)) plt.show() 结果输出为：\\n\\n代码 13-7：变长验证码识别-模型预测（片段 3）\\n\\n# 计算准确率，区分大小写 def accuracy(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred[:6], axis=-1) # 获得标签数据 label = np.argmax(y[:6], axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean()\\n\\n472\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 返回平均准确率 return acc_sum / test_steps # 打印区分大小写准确率 print(accuracy()) 结果输出为： 0.913125\\n\\n代码 13-7：变长验证码识别-模型预测（片段 4）\\n\\n# 计算准确率，忽略大小写 def accuracy2(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred[:6],axis=-1).T # 保存预测值 pred_list = [] # 把验证码预测值转小写后保存 for c in pred: # 根据编号获得对应验证码 temp_c = \\'\\'.join([pred_characters[x] for x in c]) # 字母都转小写后保存 pred_list.append(temp_c.lower()) # 获得标签数据 label = np.argmax(y[:6], axis=-1).T # 保存标签 label_list = [] # # 把验证码标签值转小写后保存 for c in label: # 根据编号获得对应验证码 temp_c = \\'\\'.join([pred_characters[x] for x in c]) # 字母都转小写后保存 label_list.append(temp_c.lower()) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (np.array(pred_list) == np.array(label_list)).mean() # 返回平均准确率 return acc_sum / test_steps # 打印忽略大小写准确率 print(accuracy2()) 结果输出为：\\n\\n473\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 0.963125\\n\\n程序运行结果我们可以看到，这个模型可以自动判断验证码的长度，并做出正确识别。\\n\\n就连“oOxXvV”这种几乎不可能识别正确的验证码图片它也能识别正确。不过由于变长验\\n\\n证码难度更大，并且验证码的位数有可能比原来的 4 位更多，所以验证码的综合准确率相比\\n\\n之前有所下降。\\n\\n13.7 CTC 算法\\n\\n13.7.1 CTC 算法介绍\\n\\nCTC(Connectionist Temporal Classification)是用来解决输入序列和输出序列难以一\\n\\n一对应的问题，主要用于语音识别和 OCR(Optical Character Recognition)领域。语音识\\n\\n别如图 13.6 所示。\\n\\n图 13.6 语音识别\\n\\n比如在语音识别任务中，我们需要将一大段语音跟一段文本对应。最容易想到的方式就\\n\\n是把一大段语音切分为语音片段，然后每个语音片段对应一个字或一个词。但是每个人说话\\n\\n474\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的语速不同，这个切分的规则很难定义。如果每一段语音都通过人为手动切分，虽然方法可\\n\\n行，但是工作量非常大。\\n\\n同样的在 OCR 领域也会遇到同样的对齐困难，如图 13.7 所示。\\n\\n图 13.7 数据对齐困难\\n\\nCTC 就是用来解决输入数据和输出数据的对齐问题，我们可以通过下面的例子来理解。\\n\\n不管是语音识别或是 OCR 还是其他类似任务，假设我们先以一定的方法（比如卷积）对输\\n\\n入数据进行特征提取，然后得到 6 个数据特征，如图 13.8 中的𝑥\"-𝑥(cid:226)。\\n\\n图 13.8 数据对齐\\n\\n6 个特征𝑥\"-𝑥(cid:226)分别预测出对应的 6 个字符，然后我们可以将相邻并重复的字符删除，得\\n\\n到最后的结果。这个对齐方式有两个问题，第一个问题是在语音识别，有些音频片段可能是\\n\\n无声的，这个时候应该是没有字符输出的。第二个问题是有些单词本身就存在重复单词，比\\n\\n如“hello”，如果去重的话就会变成“helo”。\\n\\n为了解决这两个问题，CTC 引入了一个空白占位符，用来表示空白输出，这里我们用𝜖来\\n\\n表示，加入空白符以后输入和输出就可以合理的对应上了，如图 13.9 所示。\\n\\n475\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 13.9 引入空白符\\n\\n在这个对齐方式中，如果标签文本存在重复字符，对齐过程中会在两个重复字符当中插\\n\\n入空白符隔开，这样“hello”就不会变成“helo”了。\\n\\n假设标签文本为“cat”，图 13.10 中左边的部分都是正确的结果，右边的部分都是错误\\n\\n的结果。\\n\\n图 13.10 正确对齐和错误对齐\\n\\n476\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n13.7.2 贪心算法（ Greedy Search）和集束 搜索算法（ Beam\\n\\nSearch）\\n\\n下面我们进一步考虑更多的细节，比如我们把一段“hello”的语音进行特征提取，然后\\n\\n再把提取后的特征传入 RNN 网络中，每传入 1 个特征 RNN 网络就会输出一组结果，如图\\n\\n13.11。\\n\\n图 13.11 CTC 算法\\n\\n图中 RNN 的每次输出都有 5 种可能的结果，这 5 种可能的结果有不同的概率值（图中\\n\\n不同的背景颜色深度表示不同的概率值，颜色越深表示概率越大）。对于一组输入输出(X,Y)\\n\\n来说，CTC 的目标是最大化条件概率，公式为 13.1。\\n\\n𝑇\\n\\n𝑝(𝑌|𝑋) = ? ª 𝑝𝑡(𝑎𝑡|𝑋) 𝐴∈𝐴𝑋,𝑌\\n\\n𝑡=1\\n\\n477\\n\\n(13.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑝ˆ(𝑎ˆ|𝑋)表示 RNN 每个时间序列的输出概率分布，t 表示 RNN 里第 t 个序列，\\n\\n~ ˆA\"\\n\\n∏ 𝑝ˆ(𝑎ˆ|𝑋)\\n\\n表示一条路径所有字符概率相乘，∑\\n\\n(cid:231)∈(cid:231)Ł,Ø\\n\\n~ ˆA\"\\n\\n∏ 𝑝ˆ(𝑎ˆ|𝑋)\\n\\n表示多条路径概率相\\n\\n加。\\n\\n其实有多条路径可以得到“hello”的结果，比如序列长度为 10，“heeϵlϵloϵϵ”,\\n\\n“hϵϵeeϵlϵlo”, “ϵϵhheϵlϵlo”, “hϵeeϵlϵloϵ”等结果其实都是表示“hello”。所以\\n\\n“hello”的概率应该是所有有效的“hello”路径概率的总和。\\n\\nP(“hello”)=P(“heeϵlϵloϵϵ”)+P(“hϵϵeeϵlϵlo”)+P(“ϵϵhheϵlϵlo”)+P(“hϵeeϵlϵl\\n\\noϵ”)+……\\n\\n可以想象对于一个输出，可以得到这个输出的路径肯定是非常多的。在实际应用中我们\\n\\n不会将所有路径的概率都计算出来，主要是计算量太大了，所以我们需要采用动态规划的思\\n\\n想来计算。CTC 主要采用两种动态规划的算法，贪心算法（Greedy Search）和集束搜索算\\n\\n法（Beam Search）。\\n\\n下面我们举两个简单的例子来说明，贪心算法就是在序列输出的每一个阶段都选取概率\\n\\n最大的一个输出值，比如我们有一个序列有 3 种输出“a”，“b”，“-”。“-”表示空白\\n\\n符，贪心算法输出的结果如下图 13.12 所示。\\n\\n图 13.12 贪心算法（Greedy Search）\\n\\n478\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nt0 阶段概率最大的是“-”为 0.8，t1 阶段概率最大的是“-”为 0.6，所以贪心算法的输\\n\\n出结果为“--”，概率为 0.8×0.6=0.48。一般来说贪心算法计算量小，效果也不错。但有时\\n\\n候贪心算法得到的结果不一定是最好的。如图 13.13 所示。\\n\\n图 13.13 贪心算法失效\\n\\n比如我们计算一下“a”的输出概率：\\n\\nP(“a”）=P(“aa”)+P(“a-”)+P(“-a”)= 0.2×0.4+0.2×0.6+0.8×\\n\\n0.4=0.52>0.48。所以贪心算法得到的结果不一定是最好的，我们可以使用 beam search。\\n\\nbeam search 跟贪心算法不同的地方在于 beam search 会计算当前最好的 N 个结果，\\n\\nN 可以人为设定。还是使用上面的例子，当 N 等于 2 时，可以得到图 13.14 所示。\\n\\n图 13.14 beam search\\n\\n479\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们来分析一下，t0 时“a”的概率为 0.2，空白符“-”的概率为 0.8，所以 t0 我们选\\n\\n出最好的两个结果就是“a”和“-”。t1 时我们得到的组合有“aa”，“ab”，“a”，\\n\\n“b”，“”，我们一个一个来分析。\\n\\nt1 时输出“aa”是不可能的，因为如果真的要输出“aa”，必须至少要有一个空白符在\\n\\n两个“a”中间，如“a-a”->“aa”。\\n\\nt1 时输出“ab”也不可能，因为 t1 时“b”的概率为 0。\\n\\nt1 时输出“b”也不可能，因为 t1 时“b”的概率为 0。\\n\\nt1 时输出“a”可以。t0 输出“a”，t1 输出“a”或“-”，最后的结果都是“a”；t0\\n\\n输出“-”，t1 输出“a”，也可以得到“a”。总概率前面我们计算过为 0.52。\\n\\nt1 时输出空白“”可以。t0 输出“-”，t1 也输出“-”，最后得到“”。概率为 0.48。\\n\\n如果有更长的序列，我们将沿着这个结果继续往下分析，并且每个序列只保存概率最大\\n\\n的两个输出。\\n\\n13.7.3 CTC 存在的问题\\n\\n最后总结一下 CTC 的几个问题：\\n\\n1.条件独立性。CTC 做了一个假设就是不同时间序列的输出之间是独立的。这个假设对\\n\\n于很多序列问题来说并不成立，输出序列之间往往存在联系。\\n\\n2.单调对齐。CTC 只允许单调对齐，这在语音识别，OCR 等领域中可能是有效的。但是\\n\\n在机器翻译中，比如有些中文句子后面的词可能对应于英文句子中前面的词，这个 CTC 无法\\n\\n做到。\\n\\n480\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n3.多对一映射。CTC 的输入和输出是多对一的关系。这意味着输出长度不能超过输入长\\n\\n度，这在语音识别，OCR 等领域问题不大，但是对于某些输出长度大于输入长度的应用 CTC\\n\\n就无法处理了。\\n\\n13.8 CTC 算法-验证码识别\\n\\n13.8.1 使用 CTC 算法训练验证码模型\\n\\n下面我们要学习的 CTC 算法-验证码识别程序要注意的点挺多的，我在程序注释中都已经\\n\\n详细的写清楚了。这里再稍微提一下，由于 Tensorflow.keras 中没有实现 CTC 算法的相关\\n\\n功能，所以 CTC 算法相关计算需要调用 Tensorflow 中的程序实现，如代码 13-8 所示。\\n\\n代码 13-8：CTC 算法-验证码识别（片段 1）\\n\\nfrom tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from tensorflow.keras import backend as K from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数\\n\\n481\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # RNN 的 cell 数量 RNN_cell = 128 # 最长验证码 max_len = 6 # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence # 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=max_len, width=160, height=60, input_len=10, label_len=max_len): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 输入长度 10，注意这里输入长度指的是 RNN 模型输出的序列长度，具体要看下面模 型搭建部分 # RNN 模型输出序列长度为 10 表示模型最多可以输入 10 个字符(包含空白符在内) self.input_len = input_len # 标签长度 self.label_len = label_len\\n\\n482\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []\\n\\n# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 y = np.zeros((self.batch_size, self.label_len), dtype=np.int8) # 输入长度 input_len = np.ones(self.batch_size)*self.input_len # 标签长度 label_len = np.ones(self.batch_size)*self.label_len # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 转字符串 captcha_text = \\'\\'.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码 self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 for j, ch in enumerate(captcha_text): # 设置标签，这里不需要独热编码 y[i, j] = self.characters.find(ch) # 如果验证码长度不是 6，则需要设置空白字符 for k in range(len(captcha_text),self.label_len): # 空白字符编号为 num_classes-1 y[i, k] = num_classes-1 # 返回一个批次的数据和标签 # 注意这里的标签 np.ones(self.batch_size)是没有意义的，只是由于返回的数据必须要 有标签 return [x, y, input_len, label_len], np.ones(self.batch_size)\\n\\n# 返回批次数量 def __len__(self): return self.steps\\n\\n483\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 [x, y, _, _], _ = data[0] # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n代码 13-8：CTC 算法-验证码识别（片段 2）\\n\\n# Keras 调用 Tensorflow 中的 ctc_batch_cost # x 是模型输出，shape-(?,10,63) # labels 是验证码的标签，shape-(?,max_len) # input_len 是 x 的长度，shape-(?,1)，x 的长度为 10 # label_len 是 labels 的的长度，shape-(?,1)，labels 的长度为 max_len def ctc_lambda_func(args): x, labels, input_len, label_len = args # Tensorflow 中封装的 ctc 计算\\n\\nreturn K.ctc_batch_cost(labels, x, input_len, label_len)\\n\\n484\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入预训练的 resnet50 模型，不包含全连接层 resnet50 = ResNet50(weights=\\'imagenet\\', include_top=False, input_shape=(height,width,3) ) # 设置输入 image_input = Input((height,width,3), name=\\'image_input\\') # 使用 resnet50 进行特征提取 x = resnet50(image_input) # resnet50 计算后得到的数据 shape 为(?,2,5,2048) # 10 个输入最多对应 10 个输出，验证码最长为 6，理论上只要不出现 6 个字符都相同的极 端情况，长度是够用的。 # 比如极端情况\\'aaaaaa\\'，\\'-\\'表示空白符，模型输出\\'a-a-a-a-a-a\\'至少需要 11 的长度。 # 不过长度不够可能会影响对连续重复字符的判断效果，比如\\'aaaa\\'可能会被识别为\\'aaa\\' # 如果要增加输入长度，可以通过增大输入图片的大小或修改网络结构的方式实现 # 这里 Reshape 的作用是将卷积输出的 4 维数据转化为 RNN 输入所要求的 3 维数据， 2*5=10 表示序列长度 x = Reshape((10,2048))(x) # Bidirectional 为双向 RNN，可以把 RNN/LSTM/GRU 传入 Bidirectional 中 # GRU 中的 return_sequences=True 表示返回所有序列的结果 # 比如在本程序中 return_sequences=True 返回的结果 shape 为(?,10,256) # GRU 中的 return_sequences=False 表示只返回序列 last output 的结果 # 比如在本程序中 return_sequences=False 返回的结果 shape 为(?,256) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation=\\'softmax\\')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name=\\'max_len\\') # 输入长度 input_len = Input(shape=(1), name=\\'input_len\\') # 标签长度 label_len = Input(shape=(1), name=\\'label_len\\') # Lambda 的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name=\\'ctc\\')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out) # 画图 plot_model(ctc_model,style=0,show_layer_names=True) 结果输出为：\\n\\n485\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-8：CTC 算法-验证码识别（片段 3）\\n\\nfrom tensorflow.keras.callbacks import Callback\\n\\n# 编号转成字符串 def labels_to_text(labels): ret = [] for l in labels: # -1 是空白符 if l == -1: ret.append(\\'\\') else: ret.append(characters[l]) return \"\".join(ret)\\n\\n# 把一个批次的编号转为字符串 def decode_batch(labels): ret = [] for label in labels: ret.append(labels_to_text(label)) return np.array(ret)\\n\\n# 自定义 Callback\\n\\n486\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com class Evaluate(Callback): def __init__(self): pass # 自定义准确率计算 def accuracy(self, model, batch_size=batch_size, steps=test_steps): # 准确率统计 batch_acc = 0 # 产生测试数据 valid_data = CaptchaSequence(characters, batch_size, steps) for [X_test, y_test, _, _], _ in valid_data: # 特别要注意，空白字符的编号为-1 # 这里可以先将我们自定义的空白符标签变成-1 for i,label in enumerate(y_test): for j,l in enumerate(label): if l == num_classes-1: y_test[i,j] = -1 # 将一个批次的标签数据转为字符串形式 y_test = decode_batch(y_test) # 得到预测结果 y_pred = model.predict(X_test) # shape[0]为 batch_size，shape[1]为 max_len shape = y_pred.shape # ctc_decode 默认使用贪心算法计算出 ctc 的预测结果 # get_value 获得 ctc_decode 的数值返回 numpy array 格式的数据 out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[ 0][0]) # 将一个批次的预测数据转为字符串形式 out = decode_batch(out) # 对比一个批次的标签和预测数据，计算准确率 batch_acc += (y_test == out).mean() # 返回准确率 return batch_acc / steps\\n\\n# 顾名思义，在一个训练周期的末尾会自动调用这个方法 # 这里的 epoch 是当前训练的周期数 # logs 是一个字典用来记录一些模型训练的信息 def on_epoch_end(self, epoch, logs): # 计算准确率 acc = self.accuracy(model) # 记录 val_acc logs[\\'val_acc\\'] = acc # 打印 print(f\\'\\\\nacc: {acc*100:.4f}\\')\\n\\n487\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 除了 on_epoch_end 以外，自定义 Callback 还可以定义很多方法，比如： # def on_epoch_begin(self, epoch, logs=None): # def on_batch_begin(self, batch, logs=None): # def on_batch_end(self, batch, logs=None): # 等等，有兴趣的同学可以看 tensorflow 源码进一步研究。\\n\\n# loss 的计算是在 K.ctc_batch_cost 中实现的，所以这里定义了一个假的 loss，没什么意 义，也没有作用，但是必须要定义 ctc_model.compile(loss={\\'ctc\\': lambda y_true, y_pred: y_pred}, optimizer=SGD(lr=1e- 2,momentum=0.9))\\n\\n# 监控指标统一使用 val_acc # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_acc 没有上升就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_acc 最高的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_acc 没有上升当前学习率乘以 0.1 callbacks = [Evaluate(), EarlyStopping(monitor=\\'val_acc\\', patience=6, verbose=1), CSVLogger(\\'Captcha_ctc.csv\\'), ModelCheckpoint(\\'Best_Captcha_ctc.h5\\', monitor=\\'val_acc\\', save_best_only=True), ReduceLROnPlateau(monitor=\\'val_acc\\', factor=0.1, patience=3, verbose=1) ]\\n\\n# 训练模型 ctc_model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test _steps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 999/1000 [============================>.] - ETA: 0s - loss: 5.8164 acc: 33.6562 1000/1000 [==============================] - 313s 313ms/step - loss: 5.8136 - val_loss: 4.2324 Epoch 2/100 999/1000 [============================>.] - ETA: 0s - loss: 1.7650 acc: 62.4844 …… Epoch 36/100 999/1000 [============================>.] - ETA: 0s - loss: 0.3042 acc: 89.7344\\n\\n488\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-08. 1000/1000 [==============================] - 306s 306ms/step - loss: 0.3042 - val_loss: 0.2984 Epoch 00036: early stopping\\n\\n13.8.2 使用 CTC 算法训练验证码模型-模型预测\\n\\n关于模型测试阶段，我们需要注意的是使用 load_weights 的方式载入模型权值，而不\\n\\n能直接用 load_model 载入模型。因为 keras 中没有封装 ctc 的 loss，ctc 的 loss 是在 tens\\n\\norflow 中定义的，属于 keras 外部自定义 loss。模型 save 的时候如果包含了自定义 loss，\\n\\n那么在 load_model 的时候也需要声明自定义 loss。在这个应用中还是重新搭建一遍模型并\\n\\n使用 load_weights 载入模型权值比较简单，如代码 13-9 所示。\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 1）\\n\\nfrom tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model from tensorflow.keras import backend as K from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import string # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 图片宽度 width=160 # 图片高度 height=60 # RNN 的 cell 数量 RNN_cell = 128 # 最长验证码 max_len = 6 # Keras 调用 Tensorflow 中的 ctc_batch_cost # x 是模型输出，shape-(?,10,63)\\n\\n489\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # labels 是验证码的标签，shape-(?,max_len) # input_len 是 x 的长度，shape-(?,1)，x 的长度为 10 # label_len 是 labels 的的长度，shape-(?,1)，labels 的长度为 max_len def ctc_lambda_func(args): x, labels, input_len, label_len = args # Tensorflow 中封装的 ctc 计算 return K.ctc_batch_cost(labels, x, input_len, label_len) # 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights=\\'imagenet\\', include_top=False, input_shape=(height,width,3) ) # 设置输入 image_input = Input((height,width,3), name=\\'image_input\\') # 使用 resnet50 进行特征提取 x = resnet50(image_input) # 搭建 RNN 网络 x = Reshape((10,2048))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation=\\'softmax\\')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name=\\'max_len\\') # 输入长度 input_len = Input(shape=(1), name=\\'input_len\\') # 标签长度 label_len = Input(shape=(1), name=\\'label_len\\') # Lambda 的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name=\\'ctc\\')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out)\\n\\n# 注意这里是 load_weights，载入权值，这里不能直接用 load_model 载入模型 # 因为 keras 中没有封装 ctc 的 loss，ctc 的 loss 是在 tensorflow 中定义的，属于 keras 外部 自定义 loss # 模型 save 的时候如果包含了自定义 loss，那么在 load_model 的时候也需要声明自定义 loss。 # 在这个应用中还是重新搭建一遍模型并使用 load_weights 载入模型权值比较简单 model.load_weights(\\'Best_Captcha_ctc.h5\\')\\n\\n# 用于预测的字符集多一个空白符 pre_characters = characters + \\'-\\'\\n\\n490\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 使用贪心算法预测结果 def greedy(captcha_text): # 自定义产生一个验证码 captcha_text = captcha_text # 产生验证码并归一化 image = ImageCaptcha(width=160, height=60) x = np.array(image.generate_image(captcha_text)) / 255.0 # 变成 4 维数据 X_test = np.expand_dims(x, axis=0) # 用模型进行预测 y_pred = model.predict(X_test) # 查看 y_pred 的 shape print(\"y_pred shape:\",y_pred.shape) # 获得每个序列最大概率的输出所在位置，其实也就是字符编号 argmax = np.argmax(y_pred[0], axis=-1) print(\\'id\\',\\'\\\\t\\',\\'characters\\') for x in argmax: # 打印字符编号和对应的字符 print(x,\\'\\\\t\\',pre_characters[x]) # 使用贪心算法计算预测结果 out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred. shape[1], greedy=True)[0][0]) # 把预测结果转化为字符串 out = \\'\\'.join([characters[x] for x in out[0]]) # 显示图片 plt.imshow(X_test[0]) # 设置 title plt.title(\\'pred:\\' + out + \\'\\\\ntrue: \\' + captcha_text) # show plt.show() # 生产特定验证码并进行识别 greedy(\\'a0b1C3\\') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 0 0 b 11 1 1 C 38 3 3 - 62 - 62 - 62\\n\\n491\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 62\\n\\n\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 2）\\n\\n# 生产特定验证码并进行识别 # 模型训练阶段我们使用的验证码都是 3-6 位的 # 预测阶段使用 2 位长度的验证码也可以识别正确 greedy(\\'aa\\') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 - 62 a 10 a 10 - 62 - 62 - 62 - 62 - 62 - 62\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 3）\\n\\n# 生产特定验证码并进行识别\\n\\n492\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 模型训练阶段我们使用的验证码都是 3-6 位的 # 预测阶段使用 7 位长度的验证码也可以识别正确 # 不过由于我们的模型输入输出长度最多为 10，并且模型训练阶段，验证码最多为 6 位 # 所以如果验证码长度超过 6 的话识别的效果可能不太理想 greedy(\\'abcdefg\\') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 b 11 c 12 d 13 e 14 f 15 g 16 - 62 - 62 - 62\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 4）\\n\\n# 使用 beam search 预测结果 def beam_search(captcha_text): # 自定义产生一个验证码 captcha_text = captcha_text # 产生验证码并归一化 image = ImageCaptcha(width=160, height=60) x = np.array(image.generate_image(captcha_text)) / 255.0 # 变成 4 维数据 X_test = np.expand_dims(x, axis=0) # 用模型进行预测 y_pred = model.predict(X_test) # 最好的 3 个结果 top_paths = 3\\n\\n493\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 保存最好的 3 个结果 outs = [] for i in range(top_paths): labels = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_ pred.shape[1], greedy=False,top_paths=top_paths)[0][i])[0] outs.append(labels) # 最好的 3 个结果分别显示出来 for out in outs: # 转字符串 out = \\'\\'.join([characters[x] for x in out]) # 显示图片 plt.imshow(X_test[0]) # 设置 title plt.title(\\'pred:\\' + out + \\'\\\\ntrue: \\' + captcha_text) # show plt.show()\\n\\n# 生产特定验证码并进行识别 beam_search(\\'AbCd70\\') 结果输出为：\\n\\n494\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从 CTC 算法模型测试结果可以看出，就算训练阶段验证码长度是 3-6 位，模型也能预测\\n\\n少于 3 位或多于 6 位的验证码结果。在使用 beam search 算法后，模型可以给出概率最大\\n\\n的几个输出结果。\\n\\n495\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 14 章-自然语言处理 NLP 发展历程\\n\\n（上）\\n\\n本章主要给大家介绍 NLP(Natural Language Processing)技术的发展历程，不过必须先\\n\\n要说清楚的是 NLP 技术是 AI 技术领域的一个大方向，所以真的要把 NLP 发展历程介绍清楚\\n\\n那至少要写一两本书。所以本章介绍的内容主要是近年来 NLP 与深度学习结合的最重要和最\\n\\n新的一些成果。由于内容比较多，所以分上下两个部分给大家介绍。\\n\\n14.1 NLP 应用介绍\\n\\n在介绍 NLP 的具体技术之前，我们先来了解一下 NLP 的一些实际应用。NLP 的任务基\\n\\n本上都可以使用序列模型来完成，如果大家对前面的序列模型忘记了可以先回头看一下。\\n\\nNLP 应用中大部分的任务都可以使用 seq2seq 架构来完成，seq2seq 计算细节我们在后面\\n\\n再详细介绍。\\n\\n14.1.1 文本分类/情感分类\\n\\n如图 14.1：\\n\\n图 14.1 文本分类\\n\\n496\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n文本分类就是把一段文本划分到不同的类别；情感分类就是对一段文本中所包含的情感\\n\\n进行分类。其实文本分类或文章句子的情感分类本质上都是一样，都是属于分类任务，套用\\n\\n序列模型里面我们讲过的框架，属于多对一框架。输入一篇文章或句子可以看出是一个序\\n\\n列，整个序列输入结束后我们只需要获得序列最后一个输出即可。对最后一个序列的输出信\\n\\n号进行分类，得到分类结果。\\n\\n14.1.2 分词标注\\n\\n这个应用在序列模型的章节中也有介绍过，可以使用多对多架构完成，序列的每个输入都\\n\\n会得到一个对应的输出结果。给一段文字做分词标注，标注每个字对应的标号。假如使用 4-\\n\\ntag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S\\n\\n表示单字词。可以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n14.1.3 机器翻译\\n\\n如图 14.2：\\n\\n图 14.2 机器翻译\\n\\n机器翻译是典型的 seq2seq 应用，比如输入一段中文，中文句子就是一段序列。输出得\\n\\n到一段英文，英文句子也是一段序列。类似这种问题都可以使用 seq2seq 架构来完成。\\n\\n497\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.1.4 聊天机器人\\n\\n如图 14.3：\\n\\n图 14.3 聊天机器人\\n\\n聊天机器人也是典型的 seq2seq 应用，输入一个句子输出一个句子。不过目前的技术发\\n\\n展还不够成熟，纯娱乐性质的聊天机器人用处不大，因为你稍微跟它多聊几句可能就会发现\\n\\n它是个智障。你只能跟它聊今天星期几，明天什么天气之类的话题，无法实现复杂对话。\\n\\n不过聊天机器人在某些特定领域，如机器人客服领域，还是发挥了很大的作用。很多电\\n\\n商，银行都已经上线了机器人客服的应用，因为在特定领域，大家的聊天内容相对固定，所\\n\\n以比较容易判断用户的意图，然后给出相应的回复。\\n\\n不过大家要注意像机器人客服这样的应用并不是一个模型就可以搞定所有的事情，虽然\\n\\n模型也会用，不过很多用户意图的判断和对话的回复还是通过规则来实现的。比如匹配句子\\n\\n是否出现了某个词，假设出现“发货”这个词，那说明用户可能想咨询发货相关的问题；假\\n\\n如出现“信用卡”，那用户可能是要咨询信用卡相关业务。并且机器人的回复也不是自动生\\n\\n成的回复，机器人回复的内容基本上也是事先人工设置好的内容。\\n\\n498\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.1.5 自动摘要\\n\\n自动摘要很容易理解，就是阅读文章后产生出文章的标题，也是属于 seq2seq 架构。这\\n\\n要求模型具备极强的核心内容提取概括能力，听起来就很难。所以目前自动摘要技术做得也\\n\\n不算非常好，有些时候效果不错，有些时候效果很差。\\n\\n14.1.6 文章生成\\n\\n可以给模型输入一段话或者是一大段文章，然后让模型自动生成接下来的内容，生成的\\n\\n文章长度可以人为控制，这也是 seq2seq 模型。这个应用听起来就是即神奇有趣又不靠谱。\\n\\n下面我们可以看一下实际模型得到的效果，使用金庸小说训练后的模型，给它输入一段文字\\n\\n让它进行后续文章的生成（结果来自：\\n\\nhttps://github.com/bojone/bert4keras/blob/master/examples/task_language_model.\\n\\npy）。\\n\\n输入：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。\\n\\n输出：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。这时见他手中所握，竟是\\n\\n一柄特制的短剑，心中大喜，叫道：：原来是金蛇郎君的剑！原来你便是金蛇郎君的弟子，\\n\\n这一下可要叫我失望了。那人哈哈一笑，说道：好啊！好啊，好啊！我的金蛇剑是我的，不\\n\\n过我是你的。这人道：我姓杨名过，名字叫过。你是我儿子，是我女儿，是不是？你这么大\\n\\n的年纪，怎地自称金刀驸马？我这就给你取个名字，叫作过儿。\\n\\n输入：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n\\n外，但听她呼吸调匀，正自香梦沉酣。\\n\\n499\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n输出：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n\\n外，但听她呼吸调匀，正自香梦沉酣。次日清晨，张无忌便和赵敏去买了一匹高头大马，自\\n\\n己骑了随伴。那马甚有神骏，三十六斤重的身躯之中，竟无一头白马。他心中怦怦乱跳，暗\\n\\n想：若能将赵敏引出迷城，我决不致再和她相会，但若和赵姑娘相遇，我一生一世决计再难\\n\\n相见。何况我是她的私生女儿，这般亲热，岂不是好？我如何能和她相见？今后我要教训教\\n\\n训她才好？我教教她，教训她，要她心里快快活活的。他心如刀割，当即回到客店，将张无\\n\\n忌的所在说了。\\n\\n这是什么玩意儿？目前看来除了搞笑以外，没有其他作用。\\n\\n另外诗歌生成也是类似的，我们可以给模型传入诗歌的标题，模型就可以产生一首诗出\\n\\n来。\\n\\n14.1.7 图片描述\\n\\n图片描述是计算机视觉与 NLP 相结合的一个技术，首先使用一个预训练的 CNN 模型对\\n\\n图片数据进行特征提取，然后把 CNN 模型提取的图像特征传给 RNN 网络进行文字生成，如\\n\\n图 14.4：\\n\\n500\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.4 图片描述模型\\n\\n有些图片得到的效果挺好的，如图 14.5：\\n\\n图 14.5 图片描述 1\\n\\n臭臭躺在床上，不过光看背景也不太看得出是床，所以描述是 laying on a couch 也是\\n\\n合理的。\\n\\n501\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n有些图片描述的效果就比较奇怪了，如图 14.6：\\n\\n图 14.6 图片描述 2\\n\\n一个女人站在人行道上，穿着粉红色的雨伞……很显然该模型不具备生活的常识，生活的\\n\\n常识就是人是不会穿雨伞的，它只是把它识别到的物体给拼凑到一起了。\\n\\n图片描述在某些特定场景下可以得到不错的效果，不过整体而言效果还是差强人意的。\\n\\nNLP 的应用还有很多，这里我们就不举太多例子了，大家有兴趣可以再自行研究。\\n\\n14.2 从传统语言模型到神经语言模型\\n\\n传统的自然语言处理也叫统计自然语言处理，听名字我们就知道传统的自然语言处理技\\n\\n术主要是使用数学和统计学。这跟神经网络/深度学习在自然语言处理中的技术截然不同，神\\n\\n经网络/深度学习主要使用的是数学和玄学（开玩笑）。由于技术上的巨大差异，下面关于统\\n\\n计自然语言处理的部分我们只做简单介绍，重点还是介绍神经网络/深度学习在自然语言处理\\n\\n方面的应用。\\n\\n502\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.1 规则模型[1]\\n\\n在上世纪 60 年代左右，学术界对人工智能和自然语言处理的普遍理解是：要让机器完成\\n\\n翻译或语言识别等只有人类才能做的事情，就必须先让计算机理解自然语言，而做到这一点\\n\\n就必须让计算机拥有类似我们人类这样的智能。（真正做到这点确实很难，直到今天计算机\\n\\n也没能做到这一步，所以现在几乎所有科学家都不再坚持这一点）。\\n\\n那么要如何让计算机理解自然语言呢，当时科学家得出的结论是分析语句和获取语义。\\n\\n我们在学校学习外语的时候都要学习语法规则（Grammar Rules），词性（Part of\\n\\nSpeech）和构词法（Morphologie）等，这些内容对于我们学习外语有一定的帮助，并且\\n\\n比较容易用计算机的算法描述。大家以为这会是一条正确的道路。\\n\\n在上世纪 80 年代以前，自然语言处理工作中的文法规则都是人工写的，直到 2000 年\\n\\n后，很多公司还是靠人工来总结文法规则。通过人工设计的规则来分析句子虽然可能会有些\\n\\n效果，但是总体而言不太靠谱。比如有下面 3 个问题：\\n\\n问题 1：我们人类的语言博大精深，几乎有无数种不同的句子，如果真的能有一套规则能\\n\\n描述好每一个句子，那这套规则得有多少条，几亿条还是几百亿条还是更多？这么复杂的一\\n\\n套规则即使真的存在，我们人类可能无法把它写出来。\\n\\n问题 2：我们人类设计的文法规则通常是上下文无关文法（Context Independent\\n\\nGrammar），而实际句子的文法其实应该是跟上下文相关的，属于上下文相关文法\\n\\n（Context Dependent Grammar）。两者的设计难度和计算量都无法相提并论。\\n\\n问题 3：我们人类的语言有些是需要常识来进行判断的。比如“吃饭前我想方便一下”，\\n\\n“你方便的时候我想请你吃饭”，“你方不方便你去方便的时候问你吃饭的事”，这里的\\n\\n“方便”我们都能理解什么意思，但是要跟老外解释清楚就不容易了，更别说计算机。\\n\\n503\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.2 统计语言模型[1]\\n\\n在上世纪 80 年代末，随着计算能力的提升和数据量的不断增加，过去看似不可能通过统\\n\\n计模型完成的任务，渐渐都变得可能了。到了上世纪 90 年代末期，大家发现通过统计得到\\n\\n的句法规则甚至比语言学家总结的更有说服力。2005 年以后，Google 基于统计方法的翻译\\n\\n系统全面超过基于规则的 SysTran 翻译系统，宣告规则方法学派的全面溃败。\\n\\n统计语言模型简单来说就是通过统计得到的语言模型。规则模型的主要思想是通过人工\\n\\n设定的规则来描述语言，而统计语言模型是通过统计学找到语言的规律。比如一个句子：\\n\\n“我爱北京天安门，天安门上太阳升”。\\n\\n意思清晰句子通顺。如果我们调整一些词的位置，得到：\\n\\n“我爱天安门北京，太阳升上天安门”\\n\\n虽然句子有些不够通顺，但是意思我们还是可以看懂的，假设我们再调整一下句子，得\\n\\n到：\\n\\n“爱北京天安我门，升门天安上太阳”\\n\\n这句话就基本看不懂什么意思了，为什么会这样？规则方法学派的科学家认为一个句子\\n\\n是否能理解，要看句子是否合乎语法，句子中的语义是否清晰。他们的想法有一定的道理，\\n\\n但是在规则方法学这条路上的困难要远大于方法，所以这条路是走不通的。\\n\\n著名的语音识别和自然语言处理的专家弗莱德里克·贾里尼克（Frederick Jelinek）提出\\n\\n了一个新的思路，可以使用简单的统计模型来分析描述一个句子。其实方法很简单，一个句\\n\\n子是否合理，我们不需要分析它的语法语义，只需要分析这句话出现的概率。比如上面我们\\n\\n列举的三个天安门的句子，第一个句子出现概率可能是10(cid:127)\"<，第二个句子出现的概率可能是\\n\\n504\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10(cid:127)$<，第三个句子出现的概率可能是10(cid:127)\"<<。第一个句子出现概率最大，所以最合理，第三\\n\\n个句子概率最小所以最不合理。\\n\\n比如用 S 表示一个句子，一个句子由若干个顺序排列的词𝑤\",\\t𝑤#,\\t𝑤$,…,\\t𝑤@组成。所以一\\n\\n个句子出现的概率就等于这个句子每一个词出现的条件概率相乘：\\n\\n𝑃(𝑆) = 𝑃(𝑤\", 𝑤#, … , 𝑤@) = 𝑃(𝑤\") ∙ 𝑃(𝑤#|𝑤\") ∙ 𝑃(𝑤$|𝑤\", 𝑤#) ∙∙∙ 𝑃(𝑤@|𝑤\", 𝑤#, … , 𝑤@(cid:127)\")\\n\\n其中𝑃(𝑤\")表示第一个词出现的概率，𝑃(𝑤#|𝑤\")是在已知第一个词的前提下，第二个词出\\n\\n现的概率；以此类推，词𝑤@的出现概率取决于它前面所有的词。\\n\\n每个词出现的条件概率怎么统计？通常在训练 NLP 模型的时候我们都会准备一个语料库\\n\\n（Corpus），语料库其实就是一个数据集，这个数据集就是大量的文本数据。我们可以在这\\n\\n个数据集中统计每个词𝑃(𝑤ˆ)出现的概率，以及前后相邻的两个词𝑃(𝑤ˆ|𝑤ˆ(cid:127)\")出现概率，前后\\n\\n相邻的三个词，四个词，N 个词的概率。\\n\\n不过这个模型存在一个问题，就是计算量的问题。𝑃(𝑤\")很容易统计出来，𝑃(𝑤#|𝑤\")难度\\n\\n也不是很大，𝑃(𝑤$|𝑤\", 𝑤#)难度就已经非常大了。并且这个计算量是指数级增长的，如果句子\\n\\n比较长，𝑃(𝑤@|𝑤\", 𝑤#, … , 𝑤@(cid:127)\")可能是无法计算出来的。\\n\\n好在这个问题存在可以简化的方式。20 世纪初，俄国数学家马尔可夫（Andrey\\n\\nMarkov）提出每当遇到类似这种情况时，就假设任意一个词𝑤ˆ出现的概率只与它前面的词\\n\\n𝑤ˆ(cid:127)\"相关，这样问题就变得简单了。这种假设在数学上称为马尔可夫假设。于是公式 14.1 就\\n\\n可以简化为：\\n\\n𝑃(𝑆) = 𝑃(𝑤\", 𝑤#, … , 𝑤@) = 𝑃(𝑤\") ∙ 𝑃(𝑤#|𝑤\") ∙ 𝑃(𝑤$|𝑤#) ∙∙∙ 𝑃(𝑤@|\\t𝑤@(cid:127)\")\\n\\n公式 14.2 对应的统计语言模型是二元模型（Bigram Model）。一个词的出现概率只与\\n\\n它前面一个词相关叫二元模型，一个词的出现概率与它前面两个词相关叫三元模型，一个词\\n\\n505\\n\\n(14.1)\\n\\n(14.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的出现概率与它前面三个词相关叫四元模型。以此类推，一个词的出现概率由前面 N-1 个词\\n\\n决定，称为 N 元模型（N-Gram Model）。\\n\\n可以想象 N 元模型中 N 的值越大就越接近句子真实的概率，当然 N 的值越大计算量也\\n\\n会越大。当 N 从 1 到 2，再从 2 到 3，模型的效果上升显著，而当模型从 3 到 4 时，效果的\\n\\n提升就不是很明显了。所以一般三元或四元模型用得比较多，很少人会使用四元以上模型。\\n\\n举例来说一下基于 N-Gram 模型的应用，比如在进行文本分类应用的时候。我们可以根\\n\\n据每个类别的语料库训练各自的语言模型，比如情绪二分类，正面情绪有一个语料库，可以\\n\\n训练一个语言模型；负面情绪有一个语料库，可以训练一个语言模型。当新来一个文本的时\\n\\n候，只要根据各自的语言模型，计算每个语言模型下这篇文本发生的概率。文本在哪个模型\\n\\n的概率大，这篇文本就属于哪个类别。\\n\\n比如在做语音识别的时候，我们识别出了一个句子的发音“woaibeijingtiananmen”，\\n\\n正确的识别结果是“我爱北京天安门”。但其实这个句子的发音可以对应非常多的文本，比\\n\\n如“我碍北京添安们”，“我爱北精天氨门”。通过 N-Gram 模型我们可以计算出“我爱北\\n\\n京天安门”这句话出现概率是最大的。\\n\\n统计语言模型可以很好地解决很多问题，但是该模型也存在很多问题：\\n\\n问题 1：很多时候，在计算条件概率时，𝑃(𝑤ˆ|𝑤ˆ(cid:127)\")会得到 0 值。也就是新文本中两个相\\n\\n邻词𝑤ˆ(cid:127)\"𝑤ˆ在语料库中没有出现过。所以统计语言模型中需要设计各种平滑方法来处理这种\\n\\n情况。\\n\\n问题 2：统计语言模型无法把 n 取得很大，最多就是 3-gram 或 4-gram。所以统计语言\\n\\n模型无法建模语言中上下文较长的依赖关系。\\n\\n问题 3：统计语言模型无法表征词语之间的相似性。\\n\\n506\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.3 词向量（word embedding）\\n\\n在介绍神经网络语言模型 NNLM（Neural Net Language Model）之前，我们先聊\\n\\n一下 NNLM 中的核心思想-词向量（Word Embedding），word embedding 也可以翻译\\n\\n为词嵌入，本书把它称之为词向量。\\n\\n我们在处理图像时，图像数据就是一个密集的矩阵，矩阵中的每个数值对应着图片中的\\n\\n每个像素点，我们所需的全部信息都储存在原始数据中。如图 14.7：\\n\\n图 14.7 图像数据\\n\\n所以我们把这个图像数据对应的矩阵分析好就行了。如果是分析文本数据，我们通常会\\n\\n给每个词进行编号，比如“猫”的编号是 343，“狗”的编号是 452。每个词的编号大小一\\n\\n般是跟该词在语料库中出现的频率相关（也有可能是其他编号方式或人为设置的编号），出\\n\\n现的频率越高，编号就越小。从词的编号我们无法知道这个词所包含的含义，也无法知道词\\n\\n与词之间的相关性。\\n\\n接下来我们可能还会对编号进行 one-hot 独热编码处理。假设语料库中一共有 10000 个\\n\\n词，经过独热编码处理后，每个词的数据长度都为 10000，其中只有一个 1，其余的位置都\\n\\n是 0，如：\\n\\n杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0]\\n\\n上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0]\\n\\n507\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0]\\n\\n北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0]\\n\\n注意，虽然独热编码处理后，每个词变成了一个向量，但是这种独热编码类型的向量可\\n\\n不是前面我们说的词向量（Word Embedding）。独热编码的向量虽然在某些简单场景下也\\n\\n可以得到不错的效果，但是复杂一些的场景就无法得到好的效果了。我们把一个词看成是 1\\n\\n行 10000 列的数据，把一个句子看成是一个矩阵，那么这个矩阵将会是一个非常稀疏的矩\\n\\n阵，大部分的值都是 0，这个稀疏的矩阵也没有多少可以分析的价值。\\n\\n所以传统的方式不管是将词变成编号还是将词再转成独热编码，都无法对词包含的信息\\n\\n进行一个很好的描述。那么如何才能比较好的去描述一个词呢？用一个向量来描述一个词，\\n\\n或许是一个不错的方法，这就是我们所说的词向量。\\n\\n为什么用一个向量来描述一个词会是一个有效的方法？通常词向量的长度都是人为设置\\n\\n的，比如我们设置词向量的长度为 128，也就是说每个词都会使用一个 128 维的向量来表\\n\\n示，这个向量的每一个维度都具有抽象的含义（具体的含义我们是无法知道的）。我举一个\\n\\n不是很恰当的例子，假设词向量的某一个维度 d 表示该词跟我们日常生活的相关性，相关越\\n\\n大，d 的数值就越大。比如“猫”这个词在我们日常生活中经常出现，那么“猫”这个词的\\n\\n词向量中维度 d 的数值就会比较大；而“引力红移”（广义相对论预言的一种电磁辐射波长\\n\\n变长，频率降低的效应）这个词在我们日常生活中几乎不会出现，所以“引力红移”这个词\\n\\n的词向量中维度 d 的数值就会比较小。如果每一个词都有 128 个维度可以用来描述它，那么\\n\\n理论上就可以把这个词包含的信息描述得比较好。最后再强调一下，词向量中每个维度的含\\n\\n义是抽象的，无法知道它们的具体含义。\\n\\n词向量的思想从 NNLM 中提出，并一直沿用至今，是深度学习在 NLP 领域中使用的既\\n\\n是基础又是核心的思想。\\n\\n508\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.4 神经语言模型\\n\\n2003 年 Bengio 在他的经典论文《A Neural Probabilistic Language Model》[2]中首\\n\\n次将神经网络融入到语言模型中，并经过训练得到神经网络语言模型 NNLM（Neural Net\\n\\nLanguage Model）。NNLM 的模型结构可以看下图 14.8：\\n\\n图 14.8 神经语言模型 NNLM[2]\\n\\n图中 output 表示输出；Matrix 表示矩阵；Table look-up in C 表示在矩阵 C 中查询；\\n\\nshared parameters across words 表示参数共享。\\n\\n下面我们说一下 NNLM 的训练过程，其实很简单，就是传入前面几个词，然后再预测下\\n\\n一个词是什么。具体流程是我们会分析语料库并构建一个字典 V，所有的词都在这个字典\\n\\n中，并且每个词在字典中有唯一编号。NNLM 每次训练时从语料库中选取一段长度为 n 的文\\n\\n本（𝑤ˆ(cid:127)@(cid:151)\",…,\\t𝑤ˆ(cid:127)#,𝑤ˆ(cid:127)\",𝑤ˆ）。比如 t=10，n=5，那么文本就是（𝑤(cid:226),𝑤(cid:236),𝑤(cid:201),𝑤(cid:237),𝑤\"<）。n 可\\n\\n以人为设置，这里的 n 有点像 n-gram 模型中的 n 的意思，分析连续的 n 个词。\\n\\n509\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n接下来我们把长度为 n 的文本序列用它们所对应的编号来替代，例如：\\n\\n（𝑤(cid:226),𝑤(cid:236),𝑤(cid:201),𝑤(cid:237),𝑤\"<）就变成了类似（26,42,267,6582,64）这样的编号。\\n\\n然后再将编号变为 one-hot 独热编码格式。假设字典 V 中一共有 10000 个词，本文序\\n\\n列长度为 5，经过独热编码的处理后文本数据就变成了 5 行 10000 列的矩阵，类似下面这\\n\\n样：\\n\\n[[0,…,0,…,1,…,0,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,1,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,0,…,0,…,1,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,0,…,0,…,0,…,0,…,0,…0,…,0,…1,…0]\\n\\n[0,…,0,…,0,…,0,…,1,…,0,…,0,…,0,…0,…,0,…1,…0]]\\n\\n然后把最后一个词的独热编码作为模型预测的标签值，其他词的独热编码作为输入传给\\n\\n模型。图 14.8 中的 C 称为词特征层，该层有一个权值矩阵 Matrix C 可以理解为所有词的词\\n\\n向量矩阵（Matrix C 在训练开始的时候都是随机值，没有任何意义，经过模型训练以后才能\\n\\n得到有意义的词向量）。比如词向量的长度为 128，那么 Matrix C 可能就是一个 10000 行\\n\\n128 列的权值矩阵，矩阵中的一行表示一个词的词向量。\\n\\n每个词的独热编码与 Matrix C 相乘，得到该词对应的词向量的值，如图 14.9：\\n\\n510\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.9 得到每个词的词向量\\n\\n图 14.8 中的𝐶(𝑤ˆ(cid:127)@(cid:151)\")表示𝑤ˆ(cid:127)@(cid:151)\"的词向量，𝐶(𝑤ˆ(cid:127)#)表示𝑤ˆ(cid:127)#的词向量，𝐶(𝑤ˆ(cid:127)\")表示\\n\\n𝑤ˆ(cid:127)\"的词向量。得到输入的每个词的词向量以后，对这些词向量进行拼接\\n\\n（concatenation），比如对 4 个长度为 128 维的词向量进行拼接，得到 512 维的数据。公\\n\\n式 14.3 表示多个词向量进行拼接得到 x：\\n\\n𝑥 = (𝐶(𝑤ˆ(cid:127)\"), 𝐶(𝑤ˆ(cid:127)#), … , 𝐶(𝑤ˆ(cid:127)@(cid:151)\"), )\\n\\n模型最终的输出值 y 的计算公式为：\\n\\n𝑦 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑏 + 𝑊𝑥 + 𝑈𝑡𝑎𝑛ℎ(𝑑 + 𝐻𝑥))\\n\\n可以对照着图 14.8 来看，x 为多个词向量拼接后的信号，H 为 x 到隐藏层之间的权值矩\\n\\n阵，d 为隐藏层的偏置值，tanh 为隐藏层的激活函数，U 为隐藏层到输出层之间的权值矩\\n\\n阵。b+Wx 为图 14.8 中的虚线部分，b 是偏置值，W 是权值矩阵，虚线就是表示可有可\\n\\n无，如果设置了 b 和 W 不为 0，则计算 b+Wx，相当于 x 可以传给输出层。如果设置\\n\\nb=W=0，相当于不把 x 直接传给输出层。模型输出神经元的数量等于字典中的词汇数量，\\n\\n最后 softmax 得到每个词的预测概率值。\\n\\nNNLM 模型就是在训练一个传入前面几个词，然后预测下一个词的模型。这个模型训练\\n\\n好之后，就得到了我们想要的词向量，词向量就保存在前面提到的 Matrix C 中。Matrix C\\n\\n中的每一行就对应了一个词的词向量，Matrix C 的列数表示词向量的长度，可以人为设置。\\n\\nNNLM 能够对句子中更长的依赖关系进行建模，并且得到了每个词的数值表示，然后可\\n\\n以使用词向量来计算词与词之间的相似性，这些都是传统统计模型无法做到的。将词表征为\\n\\n一个向量形式，这个思想直接启发了后来的 word2vec 的工作。\\n\\n511\\n\\n(14.3)\\n\\n(14.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.3 word2vec\\n\\n14.3.1 word2vec 介绍\\n\\n词向量的思想最早源于 2003 年 Bengio 的论文，但是真正发扬光大是在 10 年后的\\n\\n2013 年。2013 年托马斯·米科洛夫（Tomas Mikolov）在 Google 带领的研究团队创造了\\n\\n一套 word embedding 训练的方法，称之为 word2vec。最早提出 word2vec 的论文是\\n\\n《Efficient estimation of word representations in vector space》[3]。\\n\\nword2vec 就是 word to vector 的缩写，中文意思就是将词转化为向量。词向量的思想\\n\\n2003 年就已经提出，之所以没有得到大规模的应用，一方面是传统统计语言模型在 NLP 领\\n\\n域已经大规模应用，并且效果也还不错，想要撼动它的地位不容易；另一方面是词向量的思\\n\\n想虽然看起来很美好，但是实际用起来效果也不算很突出。其实词向量的思想是一个正确的\\n\\n方向，为什么实际应用效果不够突出，主要是词向量的训练方法不够好。而 word2vec 正是\\n\\n一种更好的词向量训练方法。\\n\\n14.3.2 word2vec 模型训练[4]\\n\\nword2vec 的模型训练有两种方式，分别是连续词袋模型 CBOW（Continuous Bag-\\n\\nof-Words）和 Skip-Gram 模型。这两个模型都很简单，CBOW 模型是给神经网络传入上\\n\\n下文词汇，然后预测目标词汇。比如我们有一个用于训练的句子是“我爱北京天安门“，可\\n\\n以给模型传入“爱”和“天安门“，然后用”北京“作为要预测的目标词汇。而最简单的\\n\\nCBOW 模型就是传入前一个词然后再预测后一个词，如图 14.10：\\n\\n512\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.10 简单 CBOW 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n这是一个带有一个隐藏层的简单神经网络。数据预处理的部分跟 NNLM 一样，先准备一\\n\\n个语料库，然后利用语料库构建一个字典，每个词都有一个编号，再把编号变成独热编码。\\n\\n训练模型的时候就把语料库中的句子相邻的两个词作为一组。比如把“我爱北京天安门”变\\n\\n成“我，爱”，“爱，北京”，“北京，天安门”，然后传给模型，前一个词作为输入，后\\n\\n一个词作为标签。图中的输入为词的独热编码，W 为保存词向量的矩阵，字典中一共有 V 个\\n\\n词，人为设置的词向量长度为 N，所以词向量矩阵 W 是 V 行 N 列。词向量的长度其实是通\\n\\n过神经网络隐藏层的神经元个数来设置的，隐藏层的神经元个数等于词向量的长度。隐藏层\\n\\n到输出层之间的权值矩阵 W’是 N 行 V 列，最后得到 V 个词的概率分布。\\n\\n这个简单的 CBOW 模型训练好以后，每个词的词向量组成的矩阵就是输入层到输出层之\\n\\n间的权值矩阵 W，W 中的每一行就是一个词的词向量。那么更复杂一些的 CBOW 模型如图\\n\\n14.11：\\n\\n513\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.11 标准 CBOW 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n标准 CBOW 模型跟前面的简单 CBOW 模型类似，只不过是使用上下文的词汇来预测目\\n\\n标词汇。具体是使用前后一个词还是前后两个词或是前后三个词可以人为设定。输入的每个\\n\\n词都共用一个权值矩阵 W，而模型训练好以后，输入层到隐藏层之间的权值矩阵 W 就是词\\n\\n向量矩阵。\\n\\nSkip-Gram 模型跟 CBOW 模型相反，给模型传入一个词汇，然后预测上下文的词汇。\\n\\n比如给模型传入”北京“，然后把”爱“和”天安门“作为要预测的词汇。如图 14.12：\\n\\n514\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.12 Skip-Gram 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n传入一个词汇以后要预测多少个上下文词汇，都是可以人为设置的。模型训练好以后输\\n\\n入层到隐藏层之间的权值矩阵 W 就是词向量矩阵。\\n\\nCBOW 和 Skip-Gram 这两种方式都可以用于训练词向量。\\n\\n14.3.3 word2vec 训练 trick 和可视化效果\\n\\nword2vec 训练过程中有两个 trick，主要是用于加速模型训练。分别是层次 softmax\\n\\n（Hierarchical Softmax）和 负采样（Negative Sampling）。这两个 trick 并不是\\n\\n515\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nword2vec 的精髓，只是训练技巧，所以这里我们只做个简单介绍，大家有兴趣可以再自行\\n\\n研究。\\n\\nhierarchical softmax 最早源于 2005 年 Bengio 的论文《Hierarchical Probabilistic\\n\\nNeural Network Language Model》[5]。训练 word2vec 词向量的时候，模型的输出是一\\n\\n个多分类，并且由于字典中词汇数量巨大，导致分类数量巨大。hierarchical softmax 的本\\n\\n质是把 N 分类问题变成了 log(N)次二分类问题，可以加快模型训练速度。不过随着计算能力\\n\\n的提升，以及 GPU 加速和 TPU 加速的应用，现在 hierarchical softmax 已经用得不多了。\\n\\nnegative sampling 源自 2013 年 Mikolov 自己的论文《Distributed Representations\\n\\nof Words and Phrases and their Compositionality 》[6]。假设训练 word2vec 词向量\\n\\n时，词典的大小为 30000，那么最后 softmax 分类就会有 30000 个结果。如果我们用的是\\n\\nCBOW 模型，传入上下文词汇，预测目标词汇。我们把标签词汇看成是正样本，其他词汇看\\n\\n成是负样本。那么在模型训练时，模型输出会最大化正样本（也就是标签词汇）的概率，同\\n\\n时最小化负样本（除标签词汇以外的词汇）的概率，而正样本只有 1 个，负样本有 29999\\n\\n个，负样本的数量巨大，所以计算量比较大。负采样的做法是，每次训练时在所有负样本中\\n\\n选取部分（论文作者的建议是小数据集 5-20 个，大数据集 2-5 个）进行训练，由于只选取\\n\\n了少量的负样本进行训练，所以在进行模型计算和权值更新时，计算量减少了很多。\\n\\nword2vec 训练得到的词向量通常都比较长，词向量的效果怎么样，我们可以通过可视化\\n\\n的方式来查看。比如如图 14.13：\\n\\n516\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.13 word2vec 可视化 1\\n\\n这是对 word2vec 训练得到的词向量进行了降维可视化的结果。图中我们可以看到从男\\n\\n人到女人的向量与从国王到皇后的向量是差不多的，也就是从男人变成女人的这个过程与从\\n\\n国王变成女王的过程差不多，似乎有些道理。\\n\\n图 14.14 中也是词向量可视化的结果：\\n\\n图 14.14 word2vec 可视化 2\\n\\n图中国王的词向量减去男人的词向量再加上女人的词向量得到的结果约等于皇后的词向\\n\\n量。\\n\\n从这些可视化的结果我们可以看出，word2vec 训练出来的词向量确实包含了词语的信\\n\\n息，可以对词语进行比较好的描述。由于 word2vec 在实际应用中取得了比较好的效果，基\\n\\n517\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n于 word2vec，后来又出现了 phrase2vec（把词组/短语变成向量表示）, sentence2vec\\n\\n（把句子变成向量表示）和 doc2vec（把文章段落变成向量表示），NLP 技术的发展一下子\\n\\n变成了 embedding 的世界。\\n\\n14.4 CNN 在 NLP 领域的使用\\n\\n说到 CNN 大家可能会立马想到计算机视觉。确实，CNN 广泛应用于计算机视觉领域，\\n\\n并取得了非常好的效果。不过 CNN 不仅可以用于计算机视觉，在 NLP 领域同样可以使用，\\n\\n并且效果也很好。下面我们通过一个文本分类的例子来学习 NLP 领域如何使用 CNN 网络，\\n\\n这个例子主要参考 2015 年的一篇论文《A Sensitivity Analysis of (and Practitioners’\\n\\nGuide to) Convolutional Neural Networks for Sentence Classification》[7]。\\n\\n这篇论文是在 word2vec 之后发表的，所以用到了词向量的思想。数据处理以及模型计\\n\\n算的流程如图 14.15：\\n\\n518\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.15 使用 CNN 进行文本分类[7]\\n\\n图中“I like this movie very much!”表示一个英文的句子，中文意思是“我非常喜欢\\n\\n这个电影”；d 表示词向量长度；Sentence matrix 表示把句子看成是一个矩阵；\\n\\nconvolution 表示卷积；activation function 表示激活函数；3 region sizes(2,3,4)表示卷积\\n\\n窗口的大小为(2,3,4)；2 filters for each region size 表示每个尺度的卷积有 2 个滤波器；\\n\\ntotally 6 filters 表示总共 6 个滤波器；2 feature maps for each region size 表示每个尺度\\n\\n的卷积有 2 张特征图；max-pooling 表示最大池化；6 univariate vectors concatenated\\n\\ntogether to form a single feature vector 表示池化后的 6 张特征图组合起来得到一个新的\\n\\n519\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n特征向量。softmax function regularization in this layer 表示使用 softmax 激活函数；2\\n\\nclasses 表示 2 分类。\\n\\n我们可以对照着图来看下面具体模型计算和训练步骤：\\n\\n1.首先对要分类的句子进行分词，然后获得每个词的词向量。这里关于词向量如何获取和\\n\\n训练要说明一下。有三种方式，一：载入预训练的词向量。预训练的词向量就是收集大量语\\n\\n料库，使用 word2vec 的方法训练出每个词的词向量，然后直接载入现在的模型中。词向量\\n\\n载入后数值是固定的，只做计算，不参与训练。二：与方式一相同，载入预训练的词向量，\\n\\n不过方式二中词向量会跟模型一起在新数据集中进行微调 finetune。三：随机初始化新的词\\n\\n向量，在新数据集中进行训练。通常来说使用方法二训练效果会稍微更好一些，如果训练数\\n\\n据集比较大的话，用方法三随机初始化新的词向量进行训练也可以。\\n\\n2.把一个句子的信息看成一个矩阵，矩阵的行是每个词汇，列是每个词汇的词向量，所以\\n\\n行数等于词汇数，列数等于词向量长度，然后对这个矩阵进行卷积。这里的卷积计算跟图像\\n\\n中卷积的计算是一样的，我们可以设置卷积核大小和步长。不过要注意的是卷积核的大小通\\n\\n常指的是卷积窗口的行数，比如可以设置为 2,3,4 等；卷积窗口的列数等于词向量的长度，\\n\\n也就是等于矩阵的列数（图中的 d=5 就是词向量的长度为 5，主要是为了画图方便，实际应\\n\\n用中词向量的长度可能是 128，256，300 等这些值）。卷积步长一般设置为 1。我们可以像\\n\\nInception 结构一样，设置多个不同尺度的卷积来提取不同尺度的信息。比如使用一些 2 行\\n\\n的卷积，使用一些 3 行的卷积，使用一些 4 行的卷积。这就有点像是 2 行的卷积是对相邻的\\n\\n2 个词进行特征提取，3 行卷积对相邻的 3 个词进行特征提取，4 行卷积对相邻 4 个词进行\\n\\n特征提取。\\n\\n3.卷积计算后会得到一些特征图，接下来我们可以对这些特征图进行池化，这里的池化用\\n\\n的是最大池化，池化窗口大小等于特征图的大小，也就是提取每个特征图的最大值。\\n\\n520\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.把池化后的数据进行拼接（concatenate）。\\n\\n5.池化数据拼接后与最后的输出层进行全连接，得到分类结果。输出层神经元个数等于分\\n\\n类类别数。\\n\\n14.5 RNN 在 NLP 领域的使用\\n\\nRNN 是专门用来处理序列问题的，所以 RNN 在 NLP 领域的应用很容易理解。这里的\\n\\nRNN 指的是所有的 RNN 类似的模型，包括 SimpleRNN，LSTM，GRU，Bidirectional\\n\\nRNN 和多层 RNN 等，下面我们举两个例子来说明。\\n\\n14.5.1 使用 RNN 进行文本分类\\n\\n数据的预处理跟 CNN 在 NLP 领域应用一样。先对句子进行分词，分词后获得每个词的\\n\\n词向量（前面我们说过了有 3 种方式获取并训练词向量）。然后再把每个词的词向量按照序\\n\\n列的顺序传入 RNN 模型即可，如图 14.16：\\n\\n图 14.16 RNN 应用于文本分类\\n\\n521\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中𝑥<,\\t𝑥\",\\t𝑥#分别为三个词的词向量，ℎ<,\\tℎ\",\\tℎ#分别表示 RNN 隐藏状态 Hidden State\\n\\n（比如 LSTM 的 memory block 输出），RNN 的 Hidden State 加上一个用于分类的全连\\n\\n接层，得到 RNN 的预测结果 y。𝑦<,\\t𝑦\",\\t𝑦#分别为 RNN 的 3 个序列的输出。由于我们的任务\\n\\n是文本分类，所以我们通常只需要关心序列的最后一个输出即可，用序列最后一个输出与真\\n\\n实标签进行对比得到 loss 训练模型。\\n\\n14.5.2 使用 RNN 进行中文分词标注\\n\\n我们先简单介绍一下中文分词，在中文分词的任务中，句子中的每个字都会被打上标签。\\n\\n假如使用 4-tag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结\\n\\n束位置，S 表示单字词。可以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n在这里我们需要把每个字都变成向量，也就是把每个字都看成是一个“词”。同样的我\\n\\n们也是有 3 种方式获取并训练词向量，跟前面我们提到的一样。然后再把每个字的词向量按\\n\\n照序列的顺序传入 RNN 模型即可，如图 14.17：\\n\\n图 14.17 RNN 应用于中文分词标注\\n\\n522\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中𝑥<-\\t𝑥(cid:236)分别为句子每个字的词向量，𝑦<-\\t𝑦(cid:236)分别为 RNN 的 8 个序列的输出。由于我\\n\\n们的任务是中文分词标注，所以 RNN 模型的每个输出我们都需要得到。把 RNN 模型的每个\\n\\n输出跟真实标签进行对比得到 loss 训练模型。\\n\\n14.6 Seq2Seq 模型在 NLP 领域的使用\\n\\nSeq2Seq 模型本质上其实也是 RNN，只不过它稍微特殊一些，它是由两个 RNN 组成。\\n\\n一个 RNN 是编码器 Encoder，另一个 RNN 是解码器 Decoder。Seq2Seq 可以完成很多\\n\\nNLP 的应用，比如机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。下面我们将\\n\\n使用机器翻译的例子给大家讲解 Seq2Seq 的工作流程，参考 Google 在 2014 年的论文\\n\\n《Sequence to Sequence Learning with Neural Networks》[8]，这篇论文也是比较早期\\n\\n的一篇 Seq2Seq 的论文，应用于机器翻译，并取得了不错的效果。\\n\\nSeq2Seq 应用于机器翻译如图 14.18：\\n\\n图 14.18 Seq2Seq 应用于机器翻译\\n\\n523\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n524\\n\\n左边部分为编码器 Encoder，输入一个句子每个字的词向量进行计算，𝑥<-\\t𝑥$表示\\n\\nEncoder 序列 4 个输入的词向量值。Encoder 的作用是将整个序列的信息压缩成一个向量表\\n\\n示，所以 Encoder 不需要进行预测。\\n\\n经过 Encoder 计算后会得到 C，C 称为上下文向量（Context Vector），用来表示整个\\n\\n序列的信息。C 的实际内容是 Encoder 最后一个序列的状态，也就是 Hidden State，这里\\n\\n我们称为 State 好了。\\n\\n图中右边部分为解码器 Decoder。得到 C 以后，我们可以用 C 给 Decoder 的 State 进\\n\\n行初始化（Encoder 和 Decoder 使用的 RNN 结构一致，所以 Encoder 最后一个序列的\\n\\nState 可以传给 Decoder 的 State 进行初始化），然后给 Decoder 传入句子起始符\\n\\n“<start>”的词向量，起始符可以自己定义，起始符的词向量跟其他词的词向量一样会跟着\\n\\n模型参数一起训练。传入起始符词向量后计算得到𝑦<\\n\\nR ，然后再把𝑦<\\n\\nR 的词向量作为下一个序列\\n\\n的输入进行计算得到𝑦\"\\n\\nR ，然后再把𝑦\"\\n\\nR 的词向量作为下一个序列的输入进行计算得到𝑦#\\n\\nR 。𝑦#\\n\\nR 是\\n\\n“<end>”符号，表示 Decoder 输出结束。“<end>”符号是句子结束符，可以自定义。\\n\\n以上是 Seq2Seq 的计算过程，训练过程只要将真实标签跟 Decoder 序列输出进行对比\\n\\n得到 loss 更新网络权值即可。\\n\\n这里再重复强调一下，Encoder 和 Decoder 的基本架构可以使用 SimpleRNN，\\n\\nLSTM，GRU，双向 RNN 和多层 RNN 等。在实际应用中，Seq2Seq 模型可能会更多地使\\n\\n用多层 RNN 或多层双向 RNN，提升模型拟合能力。如图 14.19 是一个三层的 Seq2Seq 模\\n\\n型：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.19 多层 Seq2Seq 模型\\n\\n由此我们可以看到使用 Seq2Seq 模型就可以使得输入序列的长度和输出序列的长度不再\\n\\n受到限制，可以输入任意长度的序列得到任意长度的输出序列。Seq2Seq 的变化形式很多，\\n\\n所以大家也有可能会见到跟上面介绍略有不同的 Seq2Seq 模型。我们主要理解 Seq2Seq 的\\n\\n设计思路，细节上的实现可以有多种形式。\\n\\n14.7 Attention 机制\\n\\n14.7.1 Attention 思想的介绍\\n\\nAttention 也就是注意力机制，主要是一种思想，就是我们在做某些应用的时候可以把注\\n\\n意力放在某些重要的信息上，同时忽视一些没这么重要的信息。其实之前我们介绍的 SENet\\n\\n525\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的核心技术就是一种 Attention 的思想，把注意力集中在某些比较重要的特征图通道上。\\n\\nAttention 的这种思想在自然语言处理，图像，语音等领域都可以使用，不过一般在自然语\\n\\n言处理领域用得更多。\\n\\n下面我们还是通过机器翻译的例子来给大家讲解一下 Seq2Seq 模型如何与 Attention 进\\n\\n行结合。我们在做机器翻译时，使用 Seq2Seq 模型的 Encoder 把整个句子压缩成一个上下\\n\\n文向量 C，然后把 C 传给 Decoder 得到翻译结果。这样做其实有个缺点，翻译时，翻译的\\n\\n结果过分依赖于上下文向量 C，C 是通过一整个句子压缩得来的，那么在压缩的过程中不可\\n\\n避免会造成信息的丢失，翻译的结果也不会特别准确。如何可以改进这种情况呢，可以考虑\\n\\n使用 Attention 机制，如图 14.20：\\n\\n图 14.20 Seq2Seq with Attention\\n\\n526\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n还是熟悉的例子，这个图不是一个真实的 Attention 模型，主要是先让大家了解一下\\n\\nAttention 的思想。这里主要有两点我们需要注意：\\n\\n1.在带有 Attention 的 Seq2Seq 模型中，上下文向量 C 的并不是 Encoder 最后一个序\\n\\n列的 State，而是通过 Encoder 所有序列的 State 计算得到。\\n\\n2.Decoder 中每个序列的计算都需要用到不同的上下文向量 C。\\n\\n当我们得到 Encoder 所有序列的 State 后，Decoder 在进行计算时，可以重点关注对当\\n\\n前输出重要的 Encoder State，而忽视不重要的 Encoder State。比如翻译的第一个英文单\\n\\n词“deep”，主要是通过“深”，“度”这两个输入得到的，在计算时应该重点关注“深”\\n\\n和“度”所对应的 State；第二个英文单词“learning”，主要是通过“学”，“习”这两个\\n\\n输入得到的，在计算时应该重点关注“学”和“习”所对应的 State。如图 14.21：\\n\\n图 14.21 不同序列有不同的 attention\\n\\n那么如何可以得知 Encoder 中所有的 State，与当前 Decoder 序列相关性的强弱呢？想\\n\\n要得到这个问题的答案，必须建立起 Encoder 中 State 与 Decoder 序列中的 State 的关\\n\\n系，这也是 Attention 模型的关键。图 14.20 中的模型显然没有做到这一点。后面我们将介\\n\\n527\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n绍几个实际的 Attention 模型，由于 Attention 的各种变化形式很多，这里主要给大家介绍\\n\\n2 种比较常见的 Attention，Bahdanau Attention 和 Luong Attention。\\n\\n14.7.2 Bahdanau Attention 介绍\\n\\n最早提出 Bahdanau Attention 的论文是 2014 年的一篇论文《Neural machine\\n\\ntranslation by jointly learning to align and translate》[9]，论文的第一作者为 Dzmitry\\n\\nBahdanau，所以论文中所使用的 Attention 也称为 Bahdanau Attention。对于\\n\\nBahdanau Attention 的计算流程，我们还是看图片更容易理解，如图 14.22：\\n\\n528\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n529\\n\\n图 14.22 Bahdanau Attention\\n\\n这个图画完，我的第一感觉是像极了 PCB 电路板设计，这些方块就像是贴片元器件的焊\\n\\n盘，连线就像是电路走线。我在大学做了 3 年 PCB 电路设计，看来对我的绘图风格产生了深\\n\\n远的影响……\\n\\n言归正传，Bahdanau Attention 的计算流程图基本上跟上一小节 Seq2Seq with\\n\\nAttention 的图差不多。Encoder 没什么好说的，获得所有序列的 State。Decoder 有些小\\n\\n细节我们要注意，使用 Encoder 最后一个序列的 State 作为 Decoder 的初始化 State，传入\\n\\n起始信号<start>，起始信号可以人为设定，计算得到 Decoder 的 State 信号ℎ<\\n\\nR ，并预测出\\n\\n翻译结果𝑦<\\n\\nR ，𝑦<\\n\\nR 假设我们得到“deep”。在进行下一次预测的时候，我们就要开始计算上下\\n\\n文向量𝐶\"了，注意看𝐶\"的信号是通过 Encoder 所有的 State 和 Decoder 中上一个序列的\\n\\nState 信号ℎ<\\n\\nR 共同计算得到的，具体怎么计算等下再说。计算得到𝐶\"后，𝐶\"与上一个序列的预\\n\\n测结果“deep”对应的词向量进行拼接（concatenate），然后传入 RNN 中进行计算得到\\n\\nState 信号ℎ\"\\n\\nR ，并预测出翻译结果𝑦\"\\n\\nR 。后面的计算以此类推，直到得到句子结束符<end>。\\n\\n下面我们来说一下 Bahdanau Attention 的上下文向量 C 具体怎么算。首先我们要知道\\n\\nC 是通过 Encoder 中所有的 State 计算出来的，我们会根据 Attention，给 Encoder 中的\\n\\nState 分配不同的权重。因此有公式：\\n\\n~ 𝑐( = ? 𝛼((cid:129)ℎ(cid:129) (cid:129)A\"\\n\\n(14.5)\\n\\n公式中𝑐(表示 Decoder 中第 i 序列的上下文向量 C，𝛼((cid:129)表示 Decoder 中第 i 序列对\\n\\nEncoder 中第 j 序列的 Attention 权重，ℎ(cid:129)表示 Encoder 中第 j 序列的 State，T 表示\\n\\nEncoder 一共有 T 个序列。举个具体例子大家可能更好理解，比如“深”，“度”，\\n\\n“学”，“习”分别传入 Encoder 中得到的 State 是ℎ<, ℎ\", ℎ#, ℎ$。Decoder 在翻译\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n530\\n\\n“learning”的时候，假设对ℎ<, ℎ\", ℎ#, ℎ$的权重是 0.05，0.05，0.6，0.3（注意这里权重的\\n\\n和为 1，“learning”对“学”和“习”的权重相对较大），那么在翻译“learning”的时\\n\\n候上下文向量𝐶(cid:132)⁄(cid:240)(cid:156)@(@(cid:209) = 0.05ℎ< + 0.05ℎ\" + 0.6ℎ# + 0.3ℎ$。\\n\\n接下来再说一下 Attention 权重𝛼具体怎么得到，计算𝛼的公式为：\\n\\n𝛼( = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄))\\n\\n(14.6)\\n\\n这里的𝛼计算有点像是一个神经网络的计算。𝛼(为 Decoder 中第 i 个序列的 Attention\\n\\n权重，𝐻æ\\n\\n((cid:127)\"为 Decoder 中第 i-1 序列的 Hidden State，𝐻⁄为 Encoder 中所有序列的\\n\\nHidden State。𝑊æ和𝑊⁄分别为𝐻æ\\n\\n((cid:127)\"和𝐻⁄对应的权值矩阵会跟着模型一起训练，tanh 为神经\\n\\n网络第一层的激活函数。𝑊(cid:240)为第二层的权值矩阵会跟着模型一起训练，softmax 为第二层的\\n\\n激活函数。\\n\\n我们通过图片的方式来仔细理解一下这里的计算，为了画图方便，假设 Encoder 和\\n\\nDecoder 输出的 Hidden State 都是 4 个值，Encoder 的序列长度为 2。我们将计算过程分\\n\\n为几步来讲解，第一步𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\"和𝑊⁄ ∙ 𝐻⁄的计算如图 14.23：\\n\\n图 14.23 Attention 权值计算第一步\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第二步计算𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄)，如图 14.24：\\n\\n图 14.24 Attention 权值计算第二步\\n\\n第三步计算𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄)，如图 14.25：\\n\\n图 14.25 Attention 权值计算第三步\\n\\n第四步计算𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄))，如图 14.26：\\n\\n图 14.26 Attention 权值计算第四步\\n\\n由于在这个例子中，Encoder 的序列长度为 2，所以这里会计算得到两个权重的值，那\\n\\n么最后的上下文向量𝐶(计算如图 14.27：\\n\\n531\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.27 上下文向量 C 计算\\n\\nBahdanau Attention 的论文中还给了一些可视化结果，英文翻译成法文时，英文单词和\\n\\n法文单词之间的 Attention 权重如图 14.28：\\n\\n图 14.28 英文单词和法文单词之间的 Attention 权重[9]\\n\\n14.7.3 Luong Attention 介绍\\n\\n最早提出 Luong Attention 的论文是 2015 年的一篇论文《Effective Approaches to\\n\\nAttention-based Neural Machine Translation》[10]，论文的第一作者为 Minh-Thang\\n\\n532\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nLuong ，所以论文使用的 Attention 也称为 Luong Attention。Luong Attention 基本思\\n\\n想跟 Bahdanau Attention 差不多，不过总的来说要比 Bahdanau Attention 更复杂一些，\\n\\n同时也考虑得更加全面。Luong Attention 的计算流程图如图 14.29：\\n\\n图 14.29 Luong Attention\\n\\n我们来看看 Luong Attention 的计算，Encoder 也是计算得到所有序列的 State。\\n\\nDecoder 部分的 RNN 也是用 Encoder 最后输出的 State 信号ℎ$进行 State 初始化，然后传\\n\\n533\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n534\\n\\n入<start>句子起始符，得到 State 信号ℎ<\\n\\nR 。接下来计算上下文向量𝐶<，𝐶<是使用 Encoder\\n\\n所有序列的 State 和 Decoder 的 State 信号ℎ<\\n\\nR 一起计算出来的，具体的怎么算等下再说。得\\n\\n到𝐶<后与ℎ<\\n\\nR 进行拼接（concatenate），ℎ<\\n\\nR(cid:242)的计算公式为：\\n\\n′(cid:243) = 𝑡𝑎𝑛ℎ\\t(𝑊(cid:211)[𝐶<; ℎ0 ℎ0\\n\\n′ ])\\n\\n(14.7)\\n\\n其中[𝐶<; ℎ<\\n\\nR ]表示𝐶<与ℎ<\\n\\nR 进行拼接（concatenate），𝑊(cid:211)为权值矩阵会跟着模型一起训\\n\\n练，tanh 为激活函数。最后输出𝑦<\\n\\nR 的计算公式为：\\n\\n′(cid:243) ) ′ = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑊(cid:222)ℎ0 𝑦0\\n\\n(14.8)\\n\\n其中𝑊(cid:222)为权值矩阵会跟着模型一起训练，softmax 为激活函数。假如预测得到结果\\n\\n“deep”，在进行下一个序列的计算时会把“deep”对应的词向量和ℎ<\\n\\nR(cid:242)一起作为输入传入\\n\\nRNN 中。后面的计算以此类推，直到得到句子结束符<end>。\\n\\n下面我们来看一下 Luong Attention 的上下文向量 C 怎么计算，C 的计算公式跟\\n\\nBahdanau Attention 一样为公式 14.5，不过 Luong Attention 中 Attention 权重𝛼的计算\\n\\n方式不同。Luong Attention 论文中给出了三种计算 Attention 权重𝛼的方法：\\n\\n第一种称为“dot”，也就是 dot product 点乘的意思，公式为 14.9：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎˆ\\n\\n⊺ℎı\\n\\n(cid:222))\\n\\n(14.9)\\n\\nLuong Attention 论文中把 Encoder 中的 State 称为“source state“，所以ℎı\\n\\n(cid:222)表示所\\n\\n有 Encoder 的 State。Decoder 中的 State 称为”target state“，所以ℎˆ为 Decoder 中的\\n\\nState，ℎˆ\\n\\n⊺表示ℎˆ转置的意思。举个例子吧，假设 Decoder 和 Encoder 的 State 都是输出 4\\n\\n个值，Encoder 总共有 2 个序列，如图 14.30：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.30 dot\\n\\n使用“dot”方式计算 Attention 权重𝛼是最简单的了，并且计算过程中没有额外的权重\\n\\n需要训练。\\n\\n第二种方式称为“general”，公式为：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎˆ\\n\\n⊺𝑊(cid:240)ℎı\\n\\n(cid:222))\\n\\n“general”方式跟“dot”方式其实差不多，只是在计算 dot product 时加入一个可以\\n\\n训练的权值矩阵。\\n\\n第三种方式称为“concat”，公式为：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑣(cid:240)\\n\\n⊺𝑡𝑎𝑛ℎ(𝑊(cid:240)[ℎˆ; ℎı\\n\\n(cid:222)]))\\n\\n第三种方式其实跟 Bahdanau Attention 计算 Attention 权重𝛼的公式是一样的。\\n\\n最后我们再简单说一下 Luong Attention 论文中提到的“Global attentional model”\\n\\n和“Local attention model”。作者对 Attention 的细节做了更多的考虑，“Global\\n\\nattentional model”指的是在计算 Attention 权重𝛼时，考虑 Encoder 中所有序列的\\n\\nState，如图 14.31：\\n\\n535\\n\\n(14.10)\\n\\n(14.11)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.31 Global attentional model[10]\\n\\n图中的 Attention Layer 表示注意力层；Context vector 表示上下文向量；Global align\\n\\nweights 表示全局权重。\\n\\n“Local attention model“指的是在计算 Attention 权重𝛼时，只考虑 Encoder 中部分\\n\\n序列的 State，如图 14.32：\\n\\n图 14.32 Local attention model[10]\\n\\n536\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Attention Layer 表示注意力层；Context vector 表示上下文向量；Local\\n\\nweights 表示局部权重；Aligned position 表示对齐位置。\\n\\n我觉得这一部分已经不是 Attention 最核心的内容了，所以就不展开介绍了，大家有兴\\n\\n趣可以自行阅读论文中的说明。\\n\\n14.7.4 谷歌机器翻译系统 GNMT 介绍\\n\\n2006 年是谷歌翻译推出的年份，10 年后的 2016 年谷歌发布了基于深度学习机器翻译系\\n\\n统 GNMT(Google\\'s Neural Machine Translation )。谷歌称 GNMT 与之前采用的基于短语\\n\\n的机器翻译算法(PBMT)相比，翻译误差降低了 55%-85%，并且多种语言互译已经接近人类\\n\\n水平，比如英法互译，英语西班牙语互译，我们最关心的中英互译跟人类还是有些差距，不\\n\\n过也已经提高了很多。而 GNMT 所使用的模型正是 Seq2Seq with Attention，最早提出\\n\\nGNMT 的论文是《Google\\'s Neural Machine Translation System: Bridging the Gap\\n\\nbetween Human and Machine Translation》[11]。\\n\\n下面我们简单介绍一下 GNMT 的内容，GNMT 中使用的是 8 层的 LSTM-Encoder，8\\n\\n层的 LSTM-Decoder，并且 Encoder 的第一层是双向 LSTM，如图 14.33：\\n\\n537\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.33 GNMT 结构[11]\\n\\n图中的 GPU1-GPU8 表示使用多个 GPU 加速训练，Encoder 的第一层如图 14.34：\\n\\n图 14.34 双向 LSTM[11]\\n\\n大家仔细观察一下 GNMT 的结构还会发现，在多层 LSTM 结构中竟然还加上了类似\\n\\nResNet 的残差设计，如图 14.35：\\n\\n图 14.35 残差设计[11]\\n\\n深度学习在计算机视觉，自然语言处理和语音等方面的应用很多地方是相通的，所以可\\n\\n以互相学习和借鉴。\\n\\nGNMT 还有更多的细节内容，如为了加快翻译速度，在模型计算过程中使用低精度计算\\n\\n（模型中部分参数使用 8bit 计算）。\\n\\n538\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n为了减少词汇数量，使用 WordPiece 技术，就是把一些词拆成一片一片，比如\\n\\n“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，“saving”，\\n\\n“saved”，“saves”都是保存的意思，是不是有点重复？使用 WordPiece 拆分后会得到\\n\\n“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很\\n\\n多。\\n\\n其他细节内容大家有兴趣可以再进一步研究。\\n\\n14.7.5 Attention 机制在视觉和语音领域的应用\\n\\nAttention 机制虽然一般是应用在 NLP 领域，不过在计算机视觉和语音领域也有着不少\\n\\n应用。2015 年的一篇论文《Show, Attend and Tell: Neural Image Caption Generation\\n\\nwith Visual Attention》[12]展示了 Attention 机制在图像标题生成应用中效果，如图\\n\\n14.36：\\n\\n图 14.36 Image Caption Generation with Visual Attention[12]\\n\\n539\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图片下面的句子为深度学习网络生成的图片标题，标题中带有下划线的单词所 Attention\\n\\n的区域为图片中白色的部分。比如“dog”所 Attention 的区域就是图片中的狗头，\\n\\n“stop”所 Attention 的区域为图片中的 stop 指示牌，“trees”所 Attention 的区域为除\\n\\n了长颈鹿以外的背景区域。\\n\\n2015 年的一篇论文《Listen, Attend and Spell》[13]展示了 Attention 在语音识别领域\\n\\n的应用效果，如图 14.37：\\n\\n图 14.37 Speech Recognition with Attention[13]\\n\\n图中的 Audio 表示语音；Hypothesis 表示预测结果；Time 表示时间。\\n\\n图中我们可以看到语音识别的结果与原始语音片段之间的关系，语音识别结果的每个词\\n\\n都会 Attention 原始语音片段的某些特定区域。\\n\\nAttention 作为一种思想可以应用于各种领域中，大家在研究一些新的问题时也可以考虑\\n\\n加入 Attention 机制，说不定会得到意想不到的效果。\\n\\n14.8 参考文献\\n\\n540\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[1] 吴军.数学之美[M].北京:人民邮电出版社\\n\\n[2] Kandola E J , Hofmann T , Poggio T , et al. A Neural Probabilistic Language\\n\\nModel[J]. Studies in Fuzziness & Soft Computing, 2006, 194:137-186.\\n\\n[3] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations\\n\\nin vector space[J]. arXiv preprint arXiv:1301.3781, 2013.\\n\\n[4] Rong X. word2vec parameter learning explained[J]. arXiv preprint\\n\\narXiv:1411.2738, 2014.\\n\\n[5] Morin F, Bengio Y. Hierarchical probabilistic neural network language\\n\\nmodel[C]//Aistats. 2005, 5: 246-252.\\n\\n[6] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and\\n\\nphrases and their compositionality[C]//Advances in neural information processing\\n\\nsystems. 2013: 3111-3119.\\n\\n[7] Zhang Y, Wallace B. A sensitivity analysis of (and practitioners\\' guide to)\\n\\nconvolutional neural networks for sentence classification[J]. arXiv preprint\\n\\narXiv:1510.03820, 2015.\\n\\n[8] Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural\\n\\nnetworks[C]//Advances in neural information processing systems. 2014: 3104-3112.\\n\\n[9] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to\\n\\nalign and translate[J]. arXiv preprint arXiv:1409.0473, 2014.\\n\\n[10] Luong M T, Pham H, Manning C D. Effective approaches to attention-based\\n\\nneural machine translation[J]. arXiv preprint arXiv:1508.04025, 2015.\\n\\n541\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[11] Wu Y, Schuster M, Chen Z, et al. Google\\'s neural machine translation system:\\n\\nBridging the gap between human and machine translation[J]. arXiv preprint\\n\\narXiv:1609.08144, 2016.\\n\\n[12] Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation\\n\\nwith visual attention[C]//International conference on machine learning. 2015: 2048-\\n\\n2057.\\n\\n[13] Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint\\n\\narXiv:1508.01211, 2015.\\n\\n542\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 15 章-自然语言处理 NLP 发展历程\\n\\n（下）\\n\\n15.1 NLP 新的开始-Transformer 模型[1]\\n\\nTransformer 可能很多人都知道，就是“变形金刚”嘛，电影我们都看过，下面我们要\\n\\n了解的内容正是 NLP 领域的“变形金刚”-Transformer 模型。为什么说 Transformer 是\\n\\nNLP 新的开始？因为 Transformer 模型的出现给混乱的 NLP 领域发展指引了新的方向。\\n\\nNLP 领域在 2015-2017 年左右这段时间发展有些混乱，因为传统的基于统计的 NLP 模型还\\n\\n有着很多应用，而基于深度学习的 CNN，RNN 等模型也展现出了不错的效果，未来应该往\\n\\n哪个方向发展，大家都说不准。这时谷歌 2017 年的一篇论文给我们指引了新的方向，论文\\n\\n很直接，标题直接告诉了我们答案：《Attention is all you need》[2]。没错，NLP 新的发\\n\\n展方向既不是 CNN 也不是 RNN，而是 Attention。Transformer 模型的重要性不在于它刷\\n\\n新了多少项 NLP 的记录，而在于它提出了一个新的建模方式，为后续的很多“刷榜”模型提\\n\\n供了基础。\\n\\n15.1.1 Transformer 模型结构和输入数据介绍\\n\\n下面我们使用机器翻译的例子来讲解 Transformer。Transformer 的基本框架用的也是\\n\\nSeq2Seq 模型，注意这里的 Seq2Seq， 里面没有用到 RNN，原始的 Transformer 用的是\\n\\n6 层的编码器（Encoder）和 6 层的解码器（Decoder），如图 15.1 所示。\\n\\n543\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.1 Transformer 的 Seq2Seq 结构\\n\\n图中的 6 个 Encoder 是相同的结构，6 个 Decoder 也是相同的结构，但 Encoder 和\\n\\nDecoder 的结构有些不同。每个 Encoder 中有两个结构，每个 Decoder 中有三个结构，如\\n\\n图 15.2 所示。\\n\\n图 15.2 Encoder 和 Decoder 内部结构\\n\\nTransformer 中最核心的结构应该就是 Self-Attention，Self-Attention 具体是什么后\\n\\n面再说。Feed Forward 其实就是两个全连接层，并且不会改变数据维度，这里我们就不多\\n\\n做介绍了。每个 Encoder 和 Decoder 中都有一个 Self-Attention 结构和 Feed Forward 结\\n\\n544\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n构。在 Decoder 中间还有一个 Encoder-Decoder-Attention 层，Encoder 部分最后输出的\\n\\nAttention 信息会传给这个层，告诉 Decoder 要重点关注输入序列的哪些内容。\\n\\nTransformer 的 Encoder 最开始的输入为每个词的编号，经过一个 Embedding 层得到\\n\\n单词的词向量，词向量长度为 512。Embedding 层的权值矩阵会随机初始化然后跟着模型\\n\\n一起训练，为了画图方便，下面图中的词向量长度为 4（我们把它想象成长度为 512 就可以\\n\\n了），如图 15.3 所示。\\n\\n图 15.3 Encoder 词向量输入\\n\\n图中的𝑥\"-\\t𝑥#为序列输入，注意 Transformer 的 Encoder 中没有使用 RNN，所以序列输\\n\\n入不需要每次传入一个值，而是可以一次性传入所有词的词向量。不过一次性传入所有词的\\n\\n词向量会丢失每个词的位置信息，所以除了词向量 Embedding 以外，输入信息中还会加上\\n\\n一个表示每个词位置的信息 Positional Encoding，所以实际的 Encoder 输入是词向量\\n\\nEmbedding 加上位置信息 Positional Encoding，如图 15.4 所示。\\n\\n545\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.4 Encoder 输入\\n\\n图中 INPUT 表示输入；POSITIONAL ENCODING 表示位置信息；EMBEDDING WITH\\n\\nTIME SIGNAL 表示包含时序信息的信号。\\n\\nPositional Encoding 可以通过固定公式计算出来，也可以通过一个神经网络训练出来，\\n\\n并且效果相差不大。论文中使用的是固定公式计算，其实固定公式也有很多种，论文中使用\\n\\n的固定公式为\\n\\n𝑃𝐸((cid:154)(cid:210)(cid:222),#() = 𝑠𝑖 𝑛 (cid:139)\\n\\n𝑝𝑜𝑠\\n\\n10000\\n\\n#( æ(cid:246)(cid:247)łøœ\\n\\n(cid:140)\\t\\t\\t\\t\\t\\t\\t(15.1)\\n\\n𝑃𝐸((cid:154)(cid:210)(cid:222),#((cid:151)\") = 𝑐𝑜𝑠 (cid:139)\\n\\n𝑝𝑜𝑠\\n\\n10000\\n\\n#( æ(cid:246)(cid:247)łøœ\\n\\n(cid:140)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(15.2)\\n\\n公式中 PE 为 Positional Encoding 得到的值，跟词向量长度一样。pos 表示当前词在句\\n\\n子中的位置，𝑑(cid:130)(cid:210)æ⁄(cid:132)为词向量长度 512，𝑃𝐸((cid:154)(cid:210)(cid:222),#()表示偶数维度的计算公式，𝑃𝐸((cid:154)(cid:210)(cid:222),#((cid:151)\")表示\\n\\n奇数维度的计算公式。词向量长度为 512，句子长度为 50，PE 的值如图 15.5 所示。\\n\\n546\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.5 Positional Encoding\\n\\n横坐标为 512 个维度的值，纵坐标为句子的 50 个词，这个图看起来有点玄学的感觉。\\n\\n其实这里的核心在于句子中每个词的 Positional Encoding 不同就可以，所以可以有多种方\\n\\n式计算 Positional Encoding 的数值。\\n\\n词向量 Embedding 和 Positional Encoding 相加以后传入第一个 Encoder 的 Self-\\n\\nAttention，如图 15.6 所示。\\n\\n547\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.6 输入 Encoder\\n\\n15.1.2 Self-Attention 介绍\\n\\nSelf-Attention 是 Transformer 模型中所使用的 Attention，基本思想跟我们之前介绍\\n\\n过的 Attention 差不多。不过 Self-Attention 主要是计算一个句子中一个词与其他词之间的\\n\\nAttention，所以名字中有个“Self”。比如我们看下面这个例子：\\n\\nThe animal didn\\'t cross the street because it was too tired.\\n\\n句子中的“it”指的是“animal”还是“street”，我们很容易判断，不过机器是比较难判\\n\\n断的。使用 Self-Attention 可以让机器把“it”和“animal”联系起来，如图 15.7 所示。\\n\\n图 15.7 Self-Attention\\n\\n下面我们来看一下 Self-Attention 的具体计算：\\n\\n第一步——在 Self-Attention 的计算中会引入 3 个新的向量，分别是 Query，Key，\\n\\nValue。这 3 个向量是 Self-Attention 的输入向量 x 分别乘以 3 个不同的权值矩阵\\n\\nWQ,WK,WV 而得到的。权值矩阵是随机初始化的，维度是（64，512），其中 512 需要与\\n\\n548\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nSelf-Attention 输入向量维度一致，其实 64 和 512 都是人为设置的，理论上都可以修改。\\n\\nQuery，Key，Value 的计算如图 15.8 所示。\\n\\n图 15.8 Self-Attention 计算 1\\n\\n第二步——计算 Self-Attention 的分数值，每个词都会与句子中的所有词计算一个分数\\n\\n值，这个分数值表示该词与句子中所有词之间的关注度。计算方法是该词的 Query 与每个词\\n\\n的 Key 做点乘，比如针对例子中“deep”这个词，计算出该词与句子中所有词的分数，假设\\n\\n计算 q1·k1 得到 112，假设计算 q1·k2 得到 96，如图 15.9 所示。\\n\\n549\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.9 Self-Attention 计算 2\\n\\n第三步——把前面计算的 Score 除以g𝑑(cid:131)，这里的𝑑(cid:131)为 Query，Key，Value 的权值矩\\n\\n阵的行数，论文中为 64。g𝑑(cid:131)就是 8，Score 除以 8 主要是为了模型训练时得到比较稳定的\\n\\n梯度，理论上取其他值也可以。然后再进行 softmax 计算，得到当前的词与其他所有词的相\\n\\n关性大小，如图 15.10 所示。\\n\\n图 15.10 Self-Attention 计算 3\\n\\n第四步——把 Value 的值与 Softmax 的结果进行相乘，然后再相加，比如 z1=v1×\\n\\n0.88+v2×0.12，如图 15.11 所示。\\n\\n550\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.11 Self-Attention 计算 4\\n\\n每个词都可以计算出一个 z 值，z 值相当于是每个词的 Self-Attention 特征。以上就是\\n\\nSelf-Attention 层的主要计算内容了。\\n\\n在实际应用的时候，一般都是以矩阵的形式来进行计算的，输入 Self-Attention 层的数\\n\\n据也是一个矩阵，如图 15.12 所示。\\n\\n551\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.12 矩阵形式的 Self-Attention 计算 1\\n\\n图中的 X 中的行数表示输入词汇数量，2 行表示 2 个词；X 中的列数表示词向量长度，\\n\\n实际应用中为 512。W 中的行数为词向量长度，实际应用中为 512；W 中的列数实际应用中\\n\\n为 64。接下来再进行如前面描述的 Self-Attention 计算，如图 15.13 所示。\\n\\n图 15.13 矩阵形式的 Self-Attention 计算 2\\n\\n15.1.3 Multi-Head Attention 介绍\\n\\n作者为了增强 Self-Attention 的表达效果，使用了“Multi-Head Attention”，中文就\\n\\n是“多头注意力机制”，虽然名字有点奇怪，但是作用很大。这个“多头注意力机制”理解\\n\\n552\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n起来很容易，上一小节我们介绍了 Self-Attention 的计算流程，我们所介绍的 Self-\\n\\nAttention 计算就是一个头（Head）。那我们初始化多个 Query，Key，Value 权值矩阵，\\n\\n进行多次独立地计算，就是“多头注意力机制”了。“多头注意力机制”的主要作用是给模\\n\\n型引入更多的训练参数，可以使得不同的“头”起到不同的 Self-Attention 的表达效果。我\\n\\n觉得有点像在图像识别中，卷积网络使用多个滤波器，提取图像不同的特征。“Multi-Head\\n\\nAttention”计算如图 15.14 所示。\\n\\n图 15.14 Multi-Head Attention 计算 1\\n\\n论文中作者用了 8 个 Attention Head，那么每个词就可以计算得到 8 组 Z 值了，从𝑍< −\\n\\n𝑍(cid:236)，如图 15.15 所示。\\n\\n553\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.15 Multi-Head Attention 计算 2\\n\\n得到 8 组 Z 值以后进行拼接（concatenate），然后还需要再乘以一个权值矩阵𝑊(cid:252)，得\\n\\n到 Self-Attention 层的最终输出 Z，如图 15.16 所示。\\n\\n554\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.16 Multi-Head Attention 计算 3\\n\\n注意 Self-Attention 层的最终输出的行数等于句子的词汇数，比如“Thinking\\n\\nMachines”就 2 个词所以 Z 只有 2 行，Z 的列数等于最开始时的词向量长度 512。\\n\\n总结一下，“Multi-Head Attention”的整个流程如图 15.17 所示。\\n\\n图 15.17 Multi-Head Attention 计算全流程\\n\\n555\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n使用了 Multi-Head Attention”以后，我们可以看到不同的两个 Attention Head 会关\\n\\n注句子中不同的部位，如图 15.18 所示。\\n\\n图 15.18 两个 Attention Head 关注点不同\\n\\n对于“it”这个词，一个头主要关注“tired”这个词，另一个头主要关注“The\\n\\nanimal”。如果是 8 个头的话可能会得到下面结果，如图 15.19 所示。\\n\\n图 15.19 8 个 Attention Head\\n\\n556\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n15.1.4 Layer Normalization 介绍\\n\\n在 Transformer 中，每一个子层（Self-Attention，Feed forward）之后都会加上残差\\n\\n模块和 Layer Normmalization[3]，如图 15.20 所示。\\n\\n图 15.20 残差结构和 Layer Normmalization\\n\\n残差结构应该不需要多说了，跟 ResNet 中差不多，这里的残差结构是一个恒等映射。\\n\\n如图 X+Z 的结果会进行 Layer Normmalization。Layer Normmalization 看名字就知道跟\\n\\nBatch Normmalization 应该是差不多的。Batch Normalization 是计算一个批次中，每个\\n\\n特征维度的平均值和标准差，然后再对每个特征维度进行标准化计算，如图 15.21 所示。\\n\\n557\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.21 Batch Normalization\\n\\nLayer Normmalization 是计算一个数据中，所有特征维度的平均值和标准差，然后再对\\n\\n这个数据进行标准化计算，如图 15.22 所示。\\n\\n图 15.22 Layer Normmalization\\n\\nBatch Normalization 和 Layer Normmalization 都可以起到数据标准化的效果，不同\\n\\n的场景下可能会得到不同的效果。在 Transformer 的模型中使用 Layer Normmalization 效\\n\\n果会更好。\\n\\n558\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n15.1.5 Decoder 结构介绍\\n\\nTransformer 叠加了 6 个相同结构的 Encoder，Encoder 最后的输出结果会传给所有\\n\\nDecoder 中的 Encoder-Decoder Attention 层进行计算，如图 15.23 所示。\\n\\n图 15.23 Encoder-Decoder\\n\\n我们也可以看一下《Attention is all you need》论文中的结构图，不过论文中的结构只\\n\\n画出来一个 Encoder 和一个 Decoder（实际上 Encoder 和 Decoder 都各有 6 个），如图\\n\\n15.24 所示。\\n\\n559\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.24 Transformer 结构[2]\\n\\n图中 Inputs 表示输入；Output 表示输出；Positional Encoding 表示位置信息；\\n\\nOutput Probabilities 表示输出概率；Linear 表示全连接层。\\n\\n我们可以看到在 Decoder 中有两个 Multi-Head Attention，这两个 Multi-Head\\n\\nAttention 跟 Encoder 中的 Multi-Head Attention 差不多，具体一些细节上的不同后面详\\n\\n细说明。\\n\\nDecoder 阶段的最后 Softmax 层计算下一个输出单词的概率。\\n\\n560\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n15.1.6 Decoder 中的 Multi-Head Attention 和模型训练\\n\\n下面我们来仔细分析一下 Decoder 中的 Multi-Head Attention，先说一下第一个\\n\\nMulti-Head Attention。第一个 Multi-Head Attention 采用了 Mask 操作，因为在翻译的\\n\\n时候，我们是先翻译第一个词，然后翻译第二个词，再翻译第三个词。在 Decoder 的时候，\\n\\n需要根据之前的翻译结果来预测当前的最佳输出。\\n\\n这里的 Mask 指的是在模型训练时遮挡住一部分的信息，当前预测结果可以回顾之前的\\n\\n标签信息，但是不能“偷看”之后的标签信息。比如我们有一对训练数据，中文是“我有一\\n\\n只猫”，英文是“I have a cat”。“我有一只猫”的数据会传给 Encoder，“<start> I\\n\\nhave a cat”会传给 Decoder。Decoder 的输出标签为“I have a cat <end>”，如图\\n\\n15.25：\\n\\n图 15.25 Decoder 预测\\n\\nMask 的作用就是我们在预测“have”的时候，我们可以借鉴”<start>”和“I”的信\\n\\n息，但是不能偷看“have”，“a”和“cat”的信息。我们在预测“a”的时候，可以借鉴\\n\\n“<start>”，“I”和“have”的信息，但是不能偷看“a”和“cat”的信息。具体的做法\\n\\n561\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n是，假设这里的英文句子有 5 个单词，我们会得到一个 5×5 的 Mask 矩阵，被 Mask 的部分\\n\\n值为负无穷-inf，没有 Mask 的部分值为 1，如图 15.26 所示。\\n\\n图 15.26 Mask 矩阵\\n\\nSelf-Attention 中 Query 和 Key 的计算跟 Encoder 中的一致，使用矩阵的方式计算，\\n\\n如图 15.27 所示。\\n\\n图 15.27 Decoder-Self-Attention 计算 1\\n\\n得到𝑄𝐾~之后需要进行 softmax 计算得到 Attention Score，在进行 softmax 计算之前\\n\\n需要先使用 Mask 矩阵遮挡住每一个单词之后的信息，如图 15.28 所示。\\n\\n图 15.28 Decoder-Self-Attention 计算 2\\n\\n562\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n得到𝑀𝑎𝑠𝑘\\t𝑄𝐾~以后再对𝑀𝑎𝑠𝑘\\t𝑄𝐾~每一行进行 softmax 计算，计算后每一行的和都为\\n\\n1。之后再与 Value 矩阵相乘，得到 Z，如图 15.29 所示。\\n\\n图 15.29 Decoder-Self-Attention 计算 3\\n\\n矩阵 Z 中第 1 行只包含单词 1 的信息，第 2 行包含单词 1 和单词 2 的信息，以此类推，\\n\\n第 5 行包含所有单词信息。\\n\\n后面的计算跟 Encoder 中的 Multi-Head Attention 类似，Multi-Head Attention 得到\\n\\n多个 Z 矩阵，然后再乘以一个权值矩阵𝑊(cid:252)得到 Mask Self-Attention 的输出。\\n\\nDecoder 中的第二个 Multi-Head Attention 层（也就是 Encoder-Decoder Attention\\n\\n层）中，会使用 Encoder 的最终输出 C 作为 Multi-Head Attention 的输入来计算 Key 和\\n\\nValue 矩阵，而 Query 矩阵则是使用上一个 Multi-Head Attention 的输出进行计算。每个\\n\\nDecoder 的 Encoder-Decoder Attention 层都使用 Encoder 的输出信息 C 来计算 Key 和\\n\\nValue 矩阵，有助于 Decoder 将注意力集中在输入序列中的适当位置。\\n\\n经过 6 个叠加的 Decoder 计算得到最终输出的 Z 矩阵，因为使用了 Mask，所以 Z 矩阵\\n\\n的第 1 行只包含单词 1 的信息，第 2 行包含单词 1 和单词 2 的信息，以此类推。模型最后\\n\\nsoftmax 输出的矩阵每一行会预测一个单词，如图 15.30 所示。\\n\\n563\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.30 softmax 输出\\n\\n因为在训练阶段 Decoder 输入序列的长度是等于标签序列长度的，比如：输入序列为\\n\\n“<start> I have a cat”一共 5 个词，标签序列为“I have a cat <end>”也是 5 个词。所\\n\\n以 Transformer 的训练可以并行计算，在训练阶段 Encoder 的一次前向计算就可以获得\\n\\nEncoder 信息 C，Decoder 的一次前向计算就可以获得序列的预测结果，把预测结果跟标签\\n\\n进行对比，计算 loss，使用反向传播算法就可以更新模型参数了。\\n\\n在模型预测阶段，label 是未知的，Decoder 就无法进行并行计算了，只能像普通的\\n\\nSeq2Seq 模型一样，1 次计算得到 1 个预测结果。然后再运行一遍 Decoder 计算，把第 1\\n\\n次得到的结果传入，得到第 2 个预测结果；再运行一遍 Decoder，传入第 1 次和第 2 次的结\\n\\n果，得到第 3 个预测，一直循环，直到出现结束符。\\n\\n15.2 BERT 模型\\n\\nTransformer 模型是 NLP 发展历程新的起点，而真正做到大放异彩，取得重大突破的是\\n\\nBERT 模型。2018 年底谷歌新论文《BERT: Pre-training of Deep Bidirectional\\n\\nTransformers for Language Understanding》[4]在 11 种不同的 NLP 测试中获得最佳成\\n\\n绩，并且在机器阅读理解顶级水平测试 SQuAD1.1[5]中超过人类水平。\\n\\n564\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们先说一下它的名字，BERT 的全称为 Bidirectional Encoder Representations from\\n\\nTransformers，我怀疑这个名字的全称是 BERT 作者强行拼凑的。大家有没有看过一个\\n\\n1969 年美国的喜剧动画芝麻街（Sesame Street），如图 15.31 所示。\\n\\n15.31 芝麻街（Sesame Street）\\n\\n我也没看过。在 2018 年初 AllenNLP 发布了一个新模型 ELMo，ELMo 是一种比\\n\\nword2vec 更好的训练词向量的模型，在 BERT 发布之前也小火了一把。由于 ELMo 跟\\n\\nTransformer 模型没什么关系，这里我们就不详细介绍了。这里我想说的是 ELMo 是芝麻街\\n\\n这个动画片的人物，图中最左边的。BERT 也是芝麻街的人物，图中从左往右数第三个。所\\n\\n以 BERT 名字的真正来源，应该是来自于芝麻街。\\n\\n15.2.1 BERT 模型介绍\\n\\nBERT 模型在结构上几乎没有创新，因为 BERT 模型的结构就是 Transformer 的\\n\\nEncoder 结构，只是具体参数上有些小改动。BERT 真正创新的地方在于模型的训练方法，\\n\\n具体如何训练后面会详细介绍。\\n\\nBERT 论文中训练了两种 BERT 模型，分别是BERT$%&’（L=12，H=768，A=12，总共\\n\\n参数=110M）和BERT(%)*’（L=24，H=1024，A=16，总共参数=340M）。其中的 L 表示\\n\\n模型层数，L=12 表示有 12 个 Encoder 层；H 表示词向量长度，H=768 表示词向量长度为\\n\\n565\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n768；A 表示 Multi-Head Attention 中有多少个 Head，A=12，表示有 12 个 Head。一般\\n\\n情况下BERT(%)*’模型效果会比BERT$%&’更好一些，BERT 结构如图 15.32 所示。\\n\\n图 15.32 两种 BERT 模型\\n\\n这些超参数其实都是可以人为设置的，论文作者选用了这两组参数来进行建模，其实也\\n\\n可以使用其他参数。\\n\\n接下来说一下 BERT 的输入信号，BERT 输入信号跟 Transformer 有一点不同。\\n\\nTransformer 输入信号的组成为分词向量（Token Embeddings）和位置向量（Position\\n\\nEmbeddings）；BERT 输入信号的组成为分词向量（Token Embeddings），段落向量\\n\\n（Segment Embeddings）和位置向量（Position Embeddings）。\\n\\n关于分词元素（Token），之前的内容一直都没有特别详细的说明这个问题，这里刚好\\n\\n可以说明一下。token 就是分词后的结果，这里的“词”不一定是一个词汇，也有可能是一\\n\\n个字符或其他自定义元素。我们最开始使用的分词方式是，比如英文中使用空格作为分词\\n\\n符，中文中需要一些分词算法，把句子分为一个一个的词汇（word）。在后来的一些研究中\\n\\n发现字符级别（character）的分词方法也能得到同样的效果，有时候效果甚至会更好。比如\\n\\n把“hello world”，分为“h”，“e”，“l”，“l”，“o”，“w”，“o”，“r”，\\n\\n566\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n“l”，“d”，把“我有一只猫”分为“我”，“有”，“一”，“只”，“猫”。而在\\n\\nBERT 中使用的是 WordPiece[6]，WordPiece 技术之前我们有介绍过，就是把一些词拆成一\\n\\n片一片，比如“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，\\n\\n“saving”，“saved”，“saves”都是保存的意思，使用 WordPiece 拆分后会得到\\n\\n“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很\\n\\n多。所以 BERT 中的 token 指的是使用 WordPiece 技术分词后得到的分词元素。BERT 输入\\n\\n信号如图 15.33 所示。\\n\\n图 15.33 BERT 输入信号[4]\\n\\nToken Embeddings 就是每个 token 对应的向量，BERT$%&’中向量长度为 768，\\n\\nBERT(%)*’中向量长度为 1024。\\n\\nSegment Embeddings 举例说明比较容易理解，BERT 可以传入一个句子或者两个句\\n\\n子，假设传入一个句子，句子可以分为 5 个 token，那么 Segment Embeddings 就是[0，\\n\\n0，0，0，0]；假设传入两个句子，第一个句子可以分为 4 个 token，第二个句子可以分为 5\\n\\n个 token，那么 Segment Embeddings 就是[0，0，0，0，1，1，1，1，1]。所以\\n\\nSegment Embeddings 就是标注哪几个 token 是第一个句子，哪几个 token 是第二个句\\n\\n子。\\n\\n567\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nPosition Embeddings 的作用跟 Transformer 模型一样，表示每个 token 的位置信\\n\\n息。不过在 BERT 模型中的 Position Embeddings 使用的是可以训练的参数，不是预先设定\\n\\n好的值。\\n\\n15.2.2 BERT 模型训练\\n\\nBERT 模型的最大创新在于模型训练。作者使用了两个任务来训练，一个任务是掩码语言\\n\\n模型（Masked Language Model），简称 MLM，简单的说就是完形填空；另一个任务是\\n\\n预测下一个句子（Next Sentence Prediction），简称 NSP，就是字面意思预测下一个句\\n\\n子。\\n\\n我们先来说一下 MLM，也就是完形填空。模型训练时会随机 mask 一个句子中 15%的\\n\\ntoken（使用“[MASK]”符号替代掉原来的字符），然后将“[MASK]”位置的输出信号传\\n\\n给 softmax 层预测被遮挡的 token 具体是什么。不过这么做可能会有一个问题，就是所有的\\n\\ntoken 中有 15%被遮挡住了，有可能导致某些 token 模型从来没见过。所以作者还做了如下\\n\\n细节处理，比如有一个句子“my dog is hairy”，我们要遮挡的词是“hairy”， 那么：\\n\\nl 有 80%的概率正常使用“[MASK]”，“my dog is hairy”会变成 my dog is [MASK]”。\\n\\nl 有 10%的概率随机取一个词来替代 mask 的词，“my dog is hairy”可能会变成 my\\n\\ndog is apple”。\\n\\nl 有 10%的概率句子保持不变，“my dog is hairy”可能还是“my dog is hairy”。\\n\\n随机替换发生的概率只有 15%×10%=1.5%，所以基本不会影响模型的语言理解能力。\\n\\nMLM 训练如图 15.34 所示。\\n\\n568\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.34 MLM 训练\\n\\n下面我们再来说一下 NSP，也就是预测下一个句子。其实很简单，就是模型训练时会传\\n\\n入两个句子，模型要做的就是判断这两个句子是不是连续的两个句子。比如输入“[CLS] the\\n\\nman went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] “，中文是\\n\\n“男人去商店买牛奶”，所以 Label=IsNext，这是两个连续的句子。这里的“[CLS]”字符\\n\\n是表示用于预测结果的字符，“[CLS]”位置的输出信号会传给 softmax 判断这两个句子是\\n\\n不是连续的。“[MASK]”字符前面介绍过了，用作随机遮挡一部分 token。“[SEP]”字符\\n\\n用于表示句子结束，我们可以看到前面的句子中有两个“[SEP]”，第一个“[SEP]”表示第\\n\\n一个句子的结束，第二个“[SEP]”表示第二个句子的结束。这些特殊字符的 Token\\n\\nEmbeddings 跟其他的 Token Embeddings 一样都会跟着模型参数一起训练。假设有个句\\n\\n子是“[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flightless birds\\n\\n[SEP]“，中文是”男人去商店，企鹅是不会飞的鸟“，所以 Label=NotNext，显然第二句\\n\\n话并不是第一句话的下一句。NSP 训练如图 15.35 所示。\\n\\n569\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.35 NSP 训练\\n\\nBERT 模型使用了大量没有人工标注，但是又自带标签的数据来进行训练（MLM 和 NSP\\n\\n都可以看成语料本身就已经自带标签）。BERT 论文中使用的训练数据集为 BooksCorpus[7]\\n\\n（800M words）和英文的 Wikipedia（2500M words），总共 33 亿个词。谷歌使用 64\\n\\n块 TPU 训练BERT(%)*’花了 4 天时间，租用这些 TPU 训练一次模型的价格大约是 30 万人民\\n\\n币，所以一般情况下我们就不要想复现模型了，直接使用谷歌发布的预训练模型就可以。\\n\\n15.2.3 BERT 模型应用\\n\\n使用上一小节介绍的方式把 BERT 模型训练好之后，就可以使用 BERT 来完成各种 NLP\\n\\n任务了，BERT 论文中测试的 NLP 任务大部分都是 GLUE(General Language\\n\\nUnderstanding Evaluation)中的任务，GLUE 是一个自然语言任务集合。除了 GLUE 以\\n\\n外，作者也测试了其他一些任务，BERT 论文中涉及的 11 个 NLP 任务如图 15.36 所示\\n\\n570\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n名称\\n\\n全名\\n\\n用途\\n\\n(a)MNLI\\n\\nmulti-genre natural language inference\\n\\n多类型文本蕴含关系识别\\n\\n判断两个句子是蕴含关系、矛盾关系还是中立关系，\\n\\n3分类\\n\\n(a)QQP\\n\\nquora question pairs\\n\\n文本匹配\\n\\n判断两个问题是不是等价，2分类\\n\\n(a)QNLI\\n\\nquestion natural language inference\\n\\n自然语言问题推理\\n\\n判断两个句子（前面句子是一个问题），\\n\\n后一个句子是否包含前一个句子的答案，2分类\\n\\n(a)STS-B\\n\\nthe semantic textual similarity benchmark\\n\\n语义文本相似度数据集\\n\\n判断两个句子相似性，有5个等级，5分类\\n\\n(a)MRPC\\n\\nmicrosoft research paraphrase corpus\\n\\n微软研究院释义语料库\\n\\n判断两个文本对语音信息是否等价，2分类\\n\\n(a)RTE\\n\\nrecognizing textual entailment\\n\\n识别文本蕴含关系\\n\\n类似于MNLI，只不过是2分类\\n\\n(a)SWAG\\n\\nthe situations with adversarial generations dataset 情景对抗生成数据集\\n\\n从四个句子中选择可能是前一句下文的那个，4分类\\n\\n(b)SST-2\\n\\nthe stanford sentiment treebank\\n\\n斯坦福情感分类任务\\n\\n电影评论的情感分类，2分类\\n\\n(b)CoLA\\n\\nthe corpus of linguistic acceptability\\n\\n语言可接受性语料库\\n\\n判断一个句子语法是否正确，2分类\\n\\n(c)SQuAD v1.1\\n\\nthe standFord question answering dataset\\n\\n斯坦福问答数据集\\n\\n传入两个句子，前一个句子是问题，后一个句子是文本段落。\\n\\n判断问题的答案在文本段落的哪个部分。\\n\\n(d)CoNLL-2003\\n\\nthe conference on natural language learning\\n\\n自然语言学习会议\\n\\nNER命名实体识别，判断一个句子中的单词是不是\\n\\n人名，机构名，地名，以及其他所有以名称为标识的实体\\n\\n图 15.36 BERT 测试的 NLP 任务\\n\\nBERT 作者把这 11 个应用分为了(a)，(b)，(c)，(d)四个大类，下面我们逐一来介绍，第\\n\\n一个类别是 Sentence Pair Classification Tasks，两个句子的分类任务，如图 15.37 所示。\\n\\n图 15.37 Sentence Pair Classification Tasks[4]\\n\\n图中的 Class Label 表示类别；Sentence Pair Classification Tasks 表示句子对分类任\\n\\n务。\\n\\n571\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n也就是传入两个句子，得到分类结果。对应的任务有 MNLI，QQP，QNLI，STS-B，\\n\\nMRPC，RTE，SWAG。我们随便举个例子，比如 QQP，就是传入两个句子（这两个句子是\\n\\n两个问题），判断这两个问题是不是等价，属于二分类问题。[CLS]对应的输出加上一个用于\\n\\n分类的全连接层，然后 Finetune 整个模型包括最后的全连接层就可以进行训练了。\\n\\n第二个类别是 Single Sentence Classification，一个句子的分类任务，如图 15.38 所\\n\\n示。\\n\\n图 15.38 Single Sentence Classification[4]\\n\\n图中的 Class Label 表示类别；Single Sentence Classification Tasks 表示单个句子分\\n\\n类任务。\\n\\n比如情感分类，传入一个句子，判断这个句子是正面情感还是负面情感，属于二分类问\\n\\n题。训练跟第一类差不多，[CLS]对应的输出加上一个用于分类的全连接层，然后 Finetune\\n\\n整个模型包括最后的全连接层就可以进行训练了。\\n\\n第三个类别是 Question Answering Tasks，问答任务，如图 15.39 所示。\\n\\n572\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n573\\n\\n图 15.39 Question Answering Tasks[4]\\n\\n图中的 Start 表示句子的起始；End 表示句子的结束；Span 表示句子的跨度；Question\\n\\n表示问题；Paragraph 表示答案所在段落；Question Answering Tasks 表示问答任务。\\n\\n问答任务，传入两个句子，第一个句子是问题，第二个句子是一段文本，问题的答案在\\n\\n第二个句子中，模型要预测的是答案的位置。有一个权值向量 S 和一个权值向量 E 用于预测\\n\\n答案的起始位置和结束位置，每个 Paragraph 中的 token 对应的输出为T\"\\n\\nR − T+\\n\\nR ，假设标签\\n\\n中 i 表示答案的起始，j 表示答案的结束，j≥i。训练阶段最大化 i 作为起始位置的概率𝑃( =\\n\\n⁄-∙.”\\n\\n∑ ⁄ »\\n\\n-∙.»\\n\\n和 j 作为结束位置的概率𝑃(cid:129) = ⁄ ∑ ⁄ »\\n\\n/∙.»\\n\\n-∙.»\\n\\n。然后 Finetune 整个模型包括 S 和 E 就可以进行\\n\\n训练了。预测阶段计算从 m 到 n 的区间分数：𝑆 ∙ 𝑇(cid:130) + 𝐸 ∙ 𝑇@(𝑛 ≥ 𝑚)，计算得到最大的区间\\n\\n分数并且 n≥m 就是预测的答案区间。\\n\\n第四个类别是 Single Sentence Tagging，一个句子的标注任务，如图 15.40 所示。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.40 Single Sentence Tagging[4]\\n\\n图中 Single Sentence 表示单个句子；Single Sentence Tagging Tasks 表示单个句子\\n\\n的标记任务。\\n\\n标注任务，比如我们之前说过的分词标注或者是图中的命名实体识别 NER（Named\\n\\nEntity Recognition）。命名实体识别就是判断一个句子中的单词是不是人名，机构名，地\\n\\n名，以及其他所有以名称为标识的实体。模型训练就是传入一个句子，句子的每个 token 的\\n\\n输出都会经过一个全连接层预测是不是命名实体或者命名实体的类型。然后 Finetune 整个\\n\\n模型包括最后的全连接层就可以进行训练了。\\n\\n很显然 BERT 的应用范围不止于此，并且 BERT 也只是一个新的开端。在 BERT 模型发布\\n\\n以后，很多类似 BERT 的模型不断被推出，不断刷新着 NLP 任务的新纪录，NLP 领域也因此\\n\\n迎来了新一轮的快速发展。\\n\\n15.3 参考文献\\n\\n[1] Alammar, Jay (2018). The Illustrated Transformer [Blog post]. Retrieved\\n\\nfrom https://jalammar.github.io/illustrated-transformer/\\n\\n574\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in\\n\\nneural information processing systems. 2017: 5998-6008.\\n\\n[3] Ba J L, Kiros J R, Hinton G E. Layer Normalization[J]. arXiv preprint\\n\\narXiv:1607.06450, 2016.\\n\\n[4] Devlin J, Chang M W, Lee K, et al. BERT: Pre-training of Deep Bidirectional\\n\\nTransformers for Language Understanding J]. arXiv preprint arXiv:1810.04805, 2018.\\n\\n[5] Rajpurkar P, Zhang J, Lopyrev K, et al. Squad: 100,000+ questions for\\n\\nMachine Comprehension of Text[J]. arXiv preprint arXiv:1606.05250, 2016.\\n\\n[6] Wu Y, Schuster M, Chen Z, et al. Google\\'s neural machine translation system:\\n\\nBridging the gap between human and machine translation[J]. arXiv preprint\\n\\narXiv:1609.08144, 2016.\\n\\n[7] Zhu Y, Kiros R, Zemel R, et al. Aligning Books and Movies: Towards Story-like\\n\\nVisual Explanations by Watching Movies and Reading Books[C]//Proceedings of the\\n\\nIEEE international conference on computer vision. 2015: 19-27.\\n\\n575\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 16 章- NLP 任务项目实战\\n\\n这个章节的内容为 14，15 章节 NLP 内容的项目实战部分。在前两个章节中我们介绍了\\n\\n多种 NLP 的技术，涉及的内容比较多，所以本章会选取部分内容完成相关项目的代码实战。\\n\\n相关理论介绍主要参考 14，15 章的内容，这个章节就不做过多介绍了。\\n\\n16.1 一维卷积英语电影评论情感分类项目\\n\\n16.1.1 项目数据和模型说明\\n\\n在 14 章的内容中我们有介绍过卷积在文本分类中的使用，当时介绍的是二维卷积在文本\\n\\n分类中的应用。本章的第一个程序我们先来一个开胃菜，先做一个简单一点的程序，使用一\\n\\n维卷积对英语文本进行情感分类，二维卷积的程序我们留在后面再做。这里说的简单，并不\\n\\n是二维卷积比一维卷积难，其实二维卷积和一维卷积在文本分类中的使用几乎没什么区别。\\n\\n这里说的简单指的是数据处理上的简单，我们要使用的数据集是 IMDB 电影评论数据集，数\\n\\n据分为正面评论和负面评论。这个数据集直接从 Tensorflow 中获得：\\n\\nfrom tensorflow.keras.datasets import imdb\\n\\n我们不需要进行任何数据处理就可以直接载入数据，数据的训练集有 25000 条评论数\\n\\n据，正面评论 12500 条，负面评论 12500 条。测试集数据也是 25000 条数据，正负样本各\\n\\n576\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n占 50%。并且句子已经做好了分词，而且还把每个词都变成了编号（词出现的频率越高，编\\n\\n号越小）。例如，测试集第 0 行的数据如图 16.1 所示。\\n\\n图 16.1 具体数据展示\\n\\n下面我们再说一下一维卷积在文本分类中的应用，如图 16.2 所示。\\n\\n图 16.2 一维卷积在文本分类中的应用[1]\\n\\n我们可以用一个简单的方式来理解一维卷积和二维卷积的区别，二维卷积它的\\n\\nkernel_size 也是两维的，并且可以沿两个方向进行移动（比如水平方向和竖直方向），二维\\n\\n卷积计算时要求输入数据必须是 4 维的（数据数量，图片高度，图片宽度，通道数\\n\\nchannels）；一维卷积它的 kernel_size 是一维的，并且只能沿一个方向进行移动，一维卷\\n\\n积计算时要求输入数据必须时 3 维的（数据数量，序列长度，通道数 channels）。在文本分\\n\\n类中，使用一维卷积和二维卷积都可以。\\n\\n如果是使用一维卷积相当于是对一个序列进行特征提取，如上图中假设我们使用一维卷\\n\\n积，词汇数相当于是序列长度，每个词的词向量长度相当于是通道数 channels。我们把\\n\\nkernel_size 设置为 3，也就是每次卷积会对图中 3 行数据进行卷积计算（图中的列数其实就\\n\\n577\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n是通道数 channels），步长一般设置为 1 就可以，每次走一步。卷积计算后得到特征图，接\\n\\n下来再进行 max-pooling 计算，最后再进行全连接得到分类结果。\\n\\n16.1.2 一维卷积英语电影评论情感分类程序\\n\\n实现一维卷积英语电影评论情感分类的代码如代码 16-1 所示。\\n\\n代码 16-1：一维卷积英语电影评论情感分类（片段 1）\\n\\nfrom tensorflow.keras.preprocessing import sequence from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout from tensorflow.keras.layers import Embedding from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D from tensorflow.keras.datasets import imdb from plot_model import plot_model # 最大词汇数量 max_words = 10000 # 最长句子设置为 400 # 这里句子长度值的是句子词汇数量，句子有 100 个词则长度为 100 maxlen = 400 # 批次大小 batch_size = 32 # 词向量长度 embedding_dims = 128 # 训练周期 epochs = 3 # 滤波器数量 filters = 64 # 卷积核大小 kernel_size = 3 # 载入 imdb 评论数据集，设置最大词汇数，只保留出现频率最高的前 max_words 个词 # 出现频率越高，编号越小。词的编号从 4 开始，也就是频率最大的词编号为 4。 # 编号 0 表示 padding，1 表示句子的开始(每个句子第一个编号都是 1)，2 表示 OOV，3 表 示预留(所有的数据中都没有 3) # Out-of-vocabulary,简称 OOV,表示不在字典中的词 # 数据的标签为 0 和 1。0 表示负面情感，1 表示正面情感。 (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words) # 查看测试集第 0 个句子 print(x_test[0]) 结果输出为：\\n\\n578\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com [1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 576 0, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 48 8, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 1 4, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 45 1, 202, 14, 6, 717]\\n\\n代码 16-1：一维卷积英语电影评论情感分类（片段 2）\\n\\n# 获得 imdb 数据集的字典，字典的键是英语词汇，值是编号 # 注意这个字典的编词汇编号跟数据集中的词汇编号是不对应的 # 数据集中的编号减三才能得到这个字典的编号，举个例子： # 比如在 x_train 中\\'a\\'的编号为 6，在 word2id 中\\'a\\'的编号为 3 word2id = imdb.get_word_index()\\n\\n# 把字典的键值对反过来：键是编号，值是英语词汇 # 编号数值范围：0-88587 # value+3 把字典中词汇的编号跟 x_train 和 x_test 数据中的编号对应起来 id2word = dict([(value+3, key) for (key, value) in word2id.items()]) # 设置预留字符 id2word[3] = \\'[RESERVE]\\' # 设置 Out-of-vocabulary 字符 id2word[2] = \\'[OOV]\\' # 设置起始字符 id2word[1] = \\'[START]\\' # 设置填充字符 id2word[0] = \\'[PAD]\\'\\n\\n# 在词典中查询得到原始英语句子，如果编号不在字典用则用\\'?\\'替代 decoded_review = \\' \\'.join([id2word.get(i, \\'?\\') for i in x_test[0]]) print(decoded_review) 结果输出为： [START] please give this one a miss br br [OOV] [OOV] and the rest of the cast rendered terrible performances the show is flat flat flat br br i don\\'t know how michael madison could have allowed this one on hi s plate he almost seemed to know this wasn\\'t going to work out and his performance was quite [OOV] so all you madison fans give this a miss\\n\\n代码 16-1：一维卷积英语电影评论情感分类（片段 3）\\n\\n# 序列填充，因为模型结构是固定的而句子的长度是不固定的，所以我们需要把句子变成相 同的长度 # 如果句子长度不足 maxlen，则把句子填充到 maxlen 的长度，如果句子长度超过 maxlen， 则取句子前 maxlen 个词\\n\\n579\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com x_train = sequence.pad_sequences(x_train, maxlen=maxlen) x_test = sequence.pad_sequences(x_test, maxlen=maxlen) # 填充后所有句子都变成了 400 的长度 print(\\'x_train shape:\\', x_train.shape) print(\\'x_test shape:\\', x_test.shape) print(x_test[0]) 结果输出为： x_train shape: (25000, 400) x_test shape: (25000, 400) [ 0 0 0 0 0 0 0 0 0 0 0 0 0 …… 0 0 0 0 0 0 0 0 0 0 1 591 202 14 31 6 717 10 10 2 2 5 4 360 7 4 177 5760 394 354 4 123 9 1035 1035 1035 10 10 13 92 124 89 488 7944 100 28 1668 14 31 23 27 7479 29 220 468 8 124 14 286 1 70 8 157 46 5 27 239 16 179 2 38. 32 25 7944 451 202 14 6 717]\\n\\n代码 16-1：一维卷积英语电影评论情感分类（片段 4）\\n\\n# 构建模型 model = Sequential() # Embedding 是一个权值矩阵，包含所有词汇的词向量，Embedding 的行数等于词汇数，列 数等于词向量长度 # Embedding 的作用是获得每个词对应的词向量，这里的词向量是没有经过预训练的随机 值，会跟随模型一起训练 # max_words 词汇数，embedding_dims 词向量长度 # 模型训练时数据输入为(batch, maxlen) model.add(Embedding(max_words, embedding_dims))\\n\\n# 设置一个一维卷积 model.add(Conv1D(filters, kernel_size, strides=1, padding=\\'same\\', activation=\\'relu\\'))\\n\\n# 卷积计算后得到的数据为(batch, maxlen, filters) # GlobalMaxPooling1D-全局最大池化计算每一张特征图的最大值 # 池化后得到(batch, filters) model.add(GlobalMaxPooling1D()) # 加上 Dropout model.add(Dropout(0.5))\\n\\n580\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 最后 2 分类，设置 2 个神经元 model.add(Dense(2,activation=\\'softmax\\')) # 画图 plot_model(model) 结果输出为：\\n\\n代码 16-1：一维卷积英语电影评论情感分类（片段 5）\\n\\n# sparse_categorical_crossentropy 和 categorical_crossentropy 都是交叉熵代价函数 # categorical_crossentropy 需要把标签变成独热编码 one-hot # sparse_categorical_crossentropy 不需要把标签变成独热编码 one-hot(不是真的不需要， 而且程序中会自动帮你做转换) # 所以这个程序中的标签没有转独热编码 one-hot model.compile(loss=\\'sparse_categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\n581\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 训练模型 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test)) 结果输出为： Train on 25000 samples, validate on 25000 samples Epoch 1/3 25000/25000 [==============================] - 31s 1ms/sample - los s: 0.4680 - accuracy: 0.7660 - val_loss: 0.3246 - val_accuracy: 0.863 5 Epoch 2/3 25000/25000 [==============================] - 31s 1ms/sample - los s: 0.2997 - accuracy: 0.8777 - val_loss: 0.2927 - val_accuracy: 0.876 6 Epoch 3/3 25000/25000 [==============================] - 31s 1ms/sample - los s: 0.2161 - accuracy: 0.9168 - val_loss: 0.2991 - val_accuracy: 0.877 2\\n\\n16.2 二维卷积中文微博情感分类项目\\n\\n上一小节我们使用一维卷积完成了英语情感分类项目，不过大家应该更关心中文的情感\\n\\n分类要怎么做。这一小节我们将从头到尾完整地完成一个中文微博情感分类项目。这里我使\\n\\n用的数据集是从新浪微博收集的 12 万条数据，正负样本各一半。标签中 1 表示正面评论，0\\n\\n表示负面评论。数据来源为\\n\\nhttps://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_sen\\n\\nti_100k/intro.ipynb。如果大家有其他数据的话，也可以使用其他数据。\\n\\n这一次我们使用的数据需要自己做处理，所以我们需要对句子进行分词，分词后再对每\\n\\n个词根据频率来进行编号。这里我们要使用的分词工具是结巴分词，结巴分词是一个很好用\\n\\n的中文分词工具，安装方式为打开命令提示符，然后输入命令：\\n\\n582\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\npip install jieba\\n\\n安装好以后在 python 程序中直接 import jieba 就可以使用了。\\n\\n实现二维卷积中文微博情感分类的代码如代码 16-2 所示。\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 1）\\n\\n# 安装结巴分词 # pip install jieba import jieba import pandas as pd import numpy as np from tensorflow.keras.layers import Dense, Input, Dropout from tensorflow.keras.layers import Conv2D, GlobalMaxPool2D, Embedding, concatenate from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Model,load_model from tensorflow.keras.backend import expand_dims from tensorflow.keras.layers import Lambda import tensorflow.keras.backend as K from sklearn.model_selection import train_test_split import json # 批次大小 batch_size = 128 # 训练周期 epochs = 3 # 词向量长度 embedding_dims = 128 # 滤波器数量 filters = 32 # 这个数据前半部分都是正样本，后半部分都是负样本 data = pd.read_csv(\\'weibo_senti_100k.csv\\') # 查看数据前 5 行 data.head() 结果输出为：\\n\\n583\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 2）\\n\\n# 计算正样本数量 poslen = sum(data[\\'label\\']==1) # 计算负样本数量 neglen = sum(data[\\'label\\']==0) print(\\'正样本数量：\\', poslen) print(\\'负样本数量：\\', neglen) 结果输出为： 正样本数量： 59993 负样本数量： 59995\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 3）\\n\\n# 测试一下结巴分词的使用 print(list(jieba.cut(\\'做父母一定要有刘墉这样的心态，不断地学习，不断地进步\\'))) 结果输出为： [\\'做\\', \\'父母\\', \\'一定\\', \\'要\\', \\'有\\', \\'刘墉\\', \\'这样\\', \\'的\\', \\'心态\\', \\'，\\', \\'不 断\\', \\'地\\', \\'学习\\', \\'，\\', \\'不断\\', \\'地\\', \\'进步\\']\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 4）\\n\\n#定义分词函数，对传入的 x 进行分词 cw = lambda x: list(jieba.cut(x)) # apply 传入一个函数，把 cw 函数应用到 data[\\'review\\']的每一行 # 把分词后的结果保存到 data[\\'words\\']中 data[\\'words\\'] = data[\\'review\\'].apply(cw) # 再查看数据前 5 行 data.head() 结果输出为：\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 5）\\n\\n# 计算一条数据最多有多少个词汇 max_length = max([len(x) for x in data[\\'words\\']])\\n\\n584\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 打印看到结果为 202，最长的句子词汇数不算太多 # 后面就以 202 作为标准，把所有句子的长度都填充到 202 的长度 # 比如最长的句子为 2000，那么说明有些句子太长了，我们可以设置一个小一点的值作为所 有句子的标准长度 # 比如设置 1000，那么超过 1000 的句子只取前面 1000 个词，不足 1000 的句子填充到 1000 的长度 print(max_length) 结果输出为： 202\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 6）\\n\\n# 把 data[\\'words\\']中所有的 list 都变成字符串格式 texts = [\\' \\'.join(x) for x in data[\\'words\\']] # 查看一条评论，现在数据变成了字符串格式，并且词与词之间用空格隔开 # 这是为了满足下面数据处理对格式的要求，下面要使用 Tokenizer 对数据进行处理 print(texts[4]) 结果输出为： \\'梦想 有 多 大 ， 舞台 就 有 多 大 ! [ 鼓掌 ]\\'\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 7）\\n\\n# 实例化 Tokenizer，设置字典中最大词汇数为 30000 # Tokenizer 会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer(num_words=30000) # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts) # 把词转换为编号，编号大于 30000 的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts) # 把序列设定为 max_length 的长度，超过 max_length 的部分舍弃，不到 max_length 则补 0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\') # 获取字典 dict_text = tokenizer.word_index # 在字典中查询词对应编号 print(dict_text[\\'梦想\\']) 结果输出为： 581\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 8）\\n\\n# 把 token_config 保存到 json 文件中，模型预测阶段可以使用\\n\\n585\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com file = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\') # 把 tokenizer 变成 json 数据 token_config = tokenizer.to_json() # 保存 json 数据 json.dump(token_config, file) print(X[4]) 结果输出为： [ 0 0 0 0 …… 0 0 0 0 0 0 581 18 75 77 1 1946 20 18 75 77 19]\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 9）\\n\\n# 定义标签 # 01 为正样本，10 为负样本 positive_labels = [[0, 1] for _ in range(poslen)] negative_labels = [[1, 0] for _ in range(neglen)] # 合并标签 Y = np.array(positive_labels + negative_labels) # 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2) # 定义函数式模型 # 定义模型输入，shape-(batch, 202) sequence_input = Input(shape=(max_length,)) # Embedding 层，30000 表示 30000 个词，每个词对应的向量为 128 维 embedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims) # embedded_sequences 的 shape-(batch, 202, 128) embedded_sequences = embedding_layer(sequence_input) # embedded_sequences 的 shape 变成了(batch, 202, 128, 1) embedded_sequences = K.expand_dims(embedded_sequences, axis=-1)\\n\\n# 卷积核大小为 3,列数必须等于词向量长度 cnn1 = Conv2D(filters=filters, kernel_size=(3,embedding_dims), activation=\\'relu\\')(embedde d_sequences) cnn1 = GlobalMaxPool2D()(cnn1)\\n\\n# 卷积核大小为 4,列数必须等于词向量长度 cnn2 = Conv2D(filters=filters, kernel_size=(4,embedding_dims), activation=\\'relu\\')(embedde d_sequences) cnn2 = GlobalMaxPool2D()(cnn2)\\n\\n# 卷积核大小为 5,列数必须等于词向量长度 cnn3 = Conv2D(filters=filters, kernel_size=(5,embedding_dims), activation=\\'relu\\')(embedde d_sequences)\\n\\n586\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com cnn3 = GlobalMaxPool2D()(cnn3)\\n\\n# 合并 merge = concatenate([cnn1, cnn2, cnn3], axis=-1) # 全连接层 x = Dense(128, activation=\\'relu\\')(merge) # Dropout 层 x = Dropout(0.5)(x) # 输出层 preds = Dense(2, activation=\\'softmax\\')(x) # 定义模型 model = Model(sequence_input, preds) plot_model(model) 结果输出为：\\n\\n587\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-2：二维卷积中文微博情感分类（片段 10）\\n\\n# 定义代价函数，优化器 model.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'acc\\'])\\n\\n# 训练模型 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test)) # 保存模型 model.save(\\'cnn_model.h5\\') 结果输出为： Train on 95990 samples, validate on 23998 samples Epoch 1/3 95990/95990 [==============================] - 30s 318us/sample - lo ss: 0.0765 - acc: 0.9705 - val_loss: 0.0434 - val_acc: 0.9814 Epoch 2/3 95990/95990 [==============================] - 27s 282us/sample - lo ss: 0.0415 - acc: 0.9821 - val_loss: 0.0528 - val_acc: 0.9815 Epoch 3/3 95990/95990 [==============================] - 27s 282us/sample - lo ss: 0.0346 - acc: 0.9832 - val_loss: 0.0720 - val_acc: 0.9793\\n\\n我们可以看到最后得到的准确率有点高，一般准确率太低我们需要分析原因，有时候准\\n\\n确非常高我们也需要想一想是为什么。我们来看一下原始数据，如图 16.3 所示。\\n\\n图 16.3 微博情感分类数据集\\n\\n588\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n可以看到原始数据中有大量表情符号，如[爱你]，[哈哈]，[鼓掌]，[可爱]等，这些表情符\\n\\n号中对应的文字从较大程度上代表了这一句话的情感。所以我们做的这个项目之所以得到这\\n\\n么高的准确率，跟这里的表情符号是有很大关系。大家如果使用其他数据集来做情感分类，\\n\\n应该也会得到不错的结果，但是应该很难得到 98%这么高的准确率。\\n\\n模型训练好以后，我们再来看看如何使用训练好的模型进行预测，如代码 16-3 所示。\\n\\n代码 16-3：中文情感分类模型预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.preprocessing.text import tokenizer_from_json import jieba import numpy as np # 载入 tokenizer json_file = open(\\'token_config.json\\',\\'r\\',encoding=\\'utf-8\\') token_config = json.load(json_file) tokenizer = tokenizer_from_json(token_config) # 载入模型 model = load_model(\\'cnn_model.h5\\') # 情感预测 def predict(text): # 对句子分词 cw = list(jieba.cut(text)) # list 转字符串，元素之间用\\' \\'隔开 texts = \\' \\'.join(cw) # 把词转换为编号，编号大于 30000 的词会被过滤掉 sequences = tokenizer.texts_to_sequences([texts]) # model.input_shape 为(None, 202)，202 为训练模型时的序列长度 # 把序列设定为 202 的长度，超过 202 的部分舍弃，不到 202 则补 0 sequences = pad_sequences(sequences, maxlen=model.input_shape[1], padding=\\'pre\\') # 模型预测 result = np.argmax(model.predict(sequences)) if(result==1): print(\"正面情绪\") else: print(\"负面情绪\")\\n\\npredict(\"今天阳光明媚，手痒想打球了。\")\\n\\n589\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 结果输出为： 正面情绪\\n\\n代码 16-3：中文情感分类模型预测（片段 2）\\n\\npredict(\"一大屋子人，结果清早告停水了，我崩溃到现在[抓狂]\") 结果输出为： 负面情绪\\n\\n16.3 双向 LSTM 中文微博情感分类项目\\n\\n上一小节我们讲解了 CNN 在中文微博情感分类项目中的应用，这一小节我们改用 LSTM\\n\\n来完成，前期数据处理部分都是一样的流程，只有建模部分的程序不同。由于之前是第一次\\n\\n讲解完整流程所以加上了很多说明的步骤，下面这个程序把一些说明的步骤给去掉了，更加\\n\\n精简一些，如代码 16-4 所示。\\n\\n代码 16-4：双向 LSTM 中文微博情感分类（片段 1）\\n\\n# 安装结巴分词 # pip install jieba import jieba import pandas as pd import numpy as np from tensorflow.keras.layers import Dense,Input,Dropout,Embedding,LSTM,Bidirectional from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Model from sklearn.model_selection import train_test_split import json # pip install plot_model from plot_model import plot_model # 批次大小 batch_size = 128 # 训练周期 epochs = 3 # 词向量长度 embedding_dims = 128\\n\\n590\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # cell 数量 lstm_cell = 64\\n\\n########step1-数据预处理######## # 这个数据前半部分都是正样本，后半部分都是负样本 data = pd.read_csv(\\'weibo_senti_100k.csv\\') # 计算正样本数量 poslen = sum(data[\\'label\\']==1) # 计算负样本数量 neglen = sum(data[\\'label\\']==0) #定义分词函数，对传入的 x 进行分词 cw = lambda x: list(jieba.cut(x)) # apply 传入一个函数，把 cw 函数应用到 data[\\'review\\']的每一行 # 把分词后的结果保存到 data[\\'words\\']中 data[\\'words\\'] = data[\\'review\\'].apply(cw) # 计算一条数据最多有多少个词汇 max_length = max([len(x) for x in data[\\'words\\']]) # 把 data[\\'words\\']中所有的 list 都变成字符串格式 texts = [\\' \\'.join(x) for x in data[\\'words\\']] # 实例化 Tokenizer，设置字典中最大词汇数为 30000 # Tokenizer 会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer(num_words=30000) # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts) # 把词转换为编号，编号大于 30000 的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts) # 把序列设定为 max_length 的长度，超过 max_length 的部分舍弃，不到 max_length 则补 0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\')\\n\\n########step2-保存 tokenizer######## # 把 token_config 保存到 json 文件中，模型预测阶段可以使用 file = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\') # 把 tokenizer 变成 json 数据 token_config = tokenizer.to_json() # 保存 json 数据 json.dump(token_config, file)\\n\\n########step3-定义标签切分数据######## # 定义标签 # 01 为正样本，10 为负样本 positive_labels = [[0, 1] for _ in range(poslen)] negative_labels = [[1, 0] for _ in range(neglen)]\\n\\n591\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 合并标签 Y = np.array(positive_labels + negative_labels) # 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)\\n\\n########step4-搭建模型######## # 定义函数式模型 # 定义模型输入，shape-(batch, 202) sequence_input = Input(shape=(max_length,)) # Embedding 层，30000 表示 30000 个词，每个词对应的向量为 128 维 embedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims) # embedded_sequences 的 shape-(batch, 202, 128) embedded_sequences = embedding_layer(sequence_input) # 双向 LSTM x = Bidirectional(LSTM(lstm_cell))(embedded_sequences)\\n\\n# 全连接层 x = Dense(128, activation=\\'relu\\')(x) # Dropout 层 x = Dropout(0.5)(x) # 输出层 preds = Dense(2, activation=\\'softmax\\')(x) # 定义模型 model = Model(sequence_input, preds) # 画图 plot_model(model) 结果输出为：\\n\\n592\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-4：双向 LSTM 中文微博情感分类（片段 2）\\n\\n########step5-模型训练和保存######## # 定义代价函数，优化器 model.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'acc\\'])\\n\\n# 训练模型 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\\n\\n# 保存模型 model.save(\\'lstm_model.h5\\') 结果输出为： Train on 95990 samples, validate on 23998 samples Epoch 1/3\\n\\n593\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 95990/95990 [==============================] - 39s 410us/sample - lo ss: 0.1177 - acc: 0.9642 - val_loss: 0.0710 - val_acc: 0.9821 Epoch 2/3 95990/95990 [==============================] - 36s 370us/sample - lo ss: 0.0602 - acc: 0.9816 - val_loss: 0.0532 - val_acc: 0.9814 Epoch 3/3 95990/95990 [==============================] - 35s 367us/sample - lo ss: 0.0440 - acc: 0.9818 - val_loss: 0.0519 - val_acc: 0.9820\\n\\n双向 LSTM 模型最后得到的结果跟 CNN 差不多，都是 98%左右的准确率。双向 LSTM\\n\\n模型的预测程序跟 16-3 完全一样，把模型载入改成载入 LSTM 模型即可。\\n\\n16.4 堆叠双向 LSTM 中文分词标注项目\\n\\n16.4.1 中文分词标注模型训练\\n\\n中文分词标注在之前的内容中我们有介绍过，常用的是 4-tag(BMES)标注标签，B 表示\\n\\n词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S 表示单字词。分词标注的数\\n\\n据需要对每一个字都进行标注。使用的是微软亚洲研究院开源的数据集\\n\\n（http://sighan.cs.uchicago.edu/bakeoff2005/），我会把数据跟书的代码放在一起给大\\n\\n家下载。实现堆叠双向 LSTM 中文分词标注的代码如代码 16-5 所示。\\n\\n代码 16-5：堆叠双向 LSTM 中文分词标注（片段 1）\\n\\nimport re import numpy as np import pandas as pd from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidir ectional from tensorflow.keras.models import Model\\n\\n594\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from sklearn.model_selection import train_test_split # pip install plot_model from plot_model import plot_model import json # 批次大小 batch_size = 256 # 训练周期 epochs = 30 # 词向量长度 embedding_dims = 128 # cell 数量 lstm_cell = 64 # 最长的句子设置为 128，只保留长度小于 128 的句子，最好不要截断句子 # 大部分的句子都是小于 128 长度的 max_length=128 # 读入数据 # {b:begin, m:middle, e:end, s:single}，分别代表每个状态代表的是该字在词语中的位置， # b 代表该字是词语中的起始字，m 代表是词语中的中间字，e 代表是词语中的结束字，s 则 代表是单字成词 text = open(\\'msr_train.txt\\').read() # 根据换行符切分数据 text = text.split(\\'\\\\n\\') # 得到所有的数据和标签 def get_data(s): # 匹配(.)/(.)格式的数据 s = re.findall(\\'(.)/(.)\\', s) if s: s = np.array(s) # 返回数据和标签，0 为数据，1 为标签 return s[:,0],s[:,1]\\n\\n# 数据 data = [] # 标签 label = [] # 循环每个句子 for s in text: # 分离文字和标签 d = get_data(s) if d: # 0 为数据 data.append(d[0]) # 1 为标签 label.append(d[1])\\n\\n595\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 存入 DataFrame df = pd.DataFrame(index=range(len(data))) df[\\'data\\'] = data df[\\'label\\'] = label # 只保留长度小于 max_length 的句子 df = df[df[\\'data\\'].apply(len) <= max_length]\\n\\n# 把 data 中所有的 list 都变成字符串格式 texts = [\\' \\'.join(x) for x in df[\\'data\\']] # 实例化 Tokenizer，设置字典中最大词汇数为 num_words # Tokenizer 会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer() # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts) # 把词转换为编号，编号大于 num_words 的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts) # 把序列设定为 max_length 的长度，超过 max_length 的部分舍弃，不到 max_length 则补 0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'post\\') # 把 token_config 保存到 json 文件中，模型预测阶段可以使用 file = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\') # 把 tokenizer 变成 json 数据 token_config = tokenizer.to_json() # 保存 json 数据 json.dump(token_config, file) # 计算字典中词的数量，由于有填充的词，所有加 1 # 中文的单字词数量一般比较少，这个数据集只有 5000 多个词 num_words = len(tokenizer.index_word)+1\\n\\n# 相当于是把字符类型的标签变成了数字类型的标签 tag = {\\'o\\':0, \\'s\\':1, \\'b\\':2, \\'m\\':3, \\'e\\':4} Y = [] # 循环原来的标签 for label in df[\\'label\\']: temp = [] # 把 sbme 转变成 1234 temp = temp + [tag[l] for l in label] temp = temp + [0]*(max_length-len(temp)) Y.append(temp) Y = np.array(Y)\\n\\n596\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)\\n\\n# 定义模型 sequence_input = Input(shape=(max_length)) # Embedding 层， # mask_zero=True，计算时忽略 0 值，也就是填充的数据不参与计算 embedding_layer = Embedding(num_words, embedding_dims, mask_zero=True)(sequence _input) # 双向 LSTM，因为我们的任务是分词标签，因此需要 LSTM 每个序列的 Hidden State 输出 值 # return_sequences=True 表示返回所有序列 LSTM 的输出，默认只返回最后一个序列 LSTM 的输出 x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(embedding_layer) # 堆叠多个双向 LSTM x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x) x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x) # TimeDistributed 该包装器可以把一个层应用到输入的每一个时间步上 # 也就是说 LSTM 每个序列输出的 Hidden State 都应该连接一个 Dense 层并预测出 5 个结 果 # 这 5 个结果分别对应：sbmeo。o 为填充值，对应标签 0。 preds = TimeDistributed(Dense(5, activation=\\'softmax\\'))(x) # 定义模型输入输出 model = Model(inputs=sequence_input, outputs=preds) # 画图 plot_model(model) 结果输出为：\\n\\n597\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-5：堆叠双向 LSTM 中文分词标注（片段 2）\\n\\n# 定义代价函数，优化器 # 使用 sparse_categorical_crossentropy，标签不需要转变为独热编码 one-hot model.compile(loss=\\'sparse_categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accurac y\\']) # 训练模型 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test)) # 保存模型 model.save(\\'lstm_tag.h5\\') 结果输出为： Train on 68496 samples, validate on 17124 samples Epoch 1/30 68496/68496 [==============================] - 35s 514us/sample - lo ss: 0.2811 - accuracy: 0.6381 - val_loss: 0.1426 - val_accuracy: 0.85 18\\n\\n……\\n\\n598\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 29/30 68496/68496 [==============================] - 22s 320us/sample - lo ss: 0.0122 - accuracy: 0.9892 - val_loss: 0.0604 - val_accuracy: 0.95 78 Epoch 30/30 68496/68496 [==============================] - 22s 319us/sample - lo ss: 0.0114 - accuracy: 0.9900 - val_loss: 0.0629 - val_accuracy: 0.95 63\\n\\n最后训练得到的准确率在 95%左右。\\n\\n16.4.2 维特比算法（Viterbi Algorithm）\\n\\n这一小节我们要介绍维特比算法（Viterbi Algorithm），因为中文分词标注模型预测阶\\n\\n段需要用到。维特比算法是应用最广泛的动态规划算法之一，主要应用在数字通信，语音识\\n\\n别，机器翻译，分词等领域。\\n\\n就用分词来举例，我们在进行分词的时候，可能会有多种分词结果，把每一种分词结果\\n\\n看成是一条路径，如图 16.4 所示。\\n\\n16.4 多种分词路径\\n\\n599\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 O 表示填充标注，B 代表该字是词语中的起始字，M 代表是词语中的中间字，E\\n\\n代表是词语中的结束字，S 则代表是单字成词。如果我们要遍历所有路径找到概率最大的路\\n\\n径（最优路径），计算量是非常大的。\\n\\n维特比算法就是用来解决的最优路径问题的，我没有想到特别简洁又清晰的表达方式把\\n\\n维特比算法给描述清楚，所以我打算直接用一个实际例子来给大家讲解维特比算法的计算流\\n\\n程。这里我使用的是一个真实的分词例子，例子中所有的数值都是真实计算得到的数值。\\n\\n首先我们先说一下状态转移矩阵，我们把 osbme 看成是 5 种状态，这 5 种状态之间的\\n\\n转移是有一定概率的。比如跟 o 相关的状态转移（o->s，e->o 等）都是不存在的，因为正\\n\\n真分词的时候是不可能出现 o 这个标注的；再比如 s->m，s->e，b->s，b->b，m->s，\\n\\nm->b，e->m，e->e 这些状态也都是不可能存在的，这不符合我们的标注规则。这些不可\\n\\n能出现的状态转移我们可以把它们的值设置为-inf（负无穷）。那么存在的状态转移 s->s，\\n\\ns->b，b->m，b->e，m->m，m->e，e->s，e->b 应该要怎么确定状态转移权重呢？最\\n\\n简单的方式是全都设置为 1，表示这些合理的状态转移概率都相等。更好一些的方法可以使\\n\\n用二元模型，统计语料库里 s->s 的概率，s->b 的概率，一直到 e->b 的概率。还有再更好\\n\\n一些的方法可以使用条件随机场 CRF（Conditional Random Field）。状态转移矩阵的计\\n\\n算不属于维特比算法的内容。这里我们就用一个相对简单的方法——二元模型来进行计算\\n\\n（具体操作在后面程序中），得到的状态转移矩阵如图 16.5 所示。\\n\\n600\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n601\\n\\n图 16.5 状态转移矩阵\\n\\n比如我们要对“深度学习”这 4 个字进行分词，那么我们就要把“深”，“度”，\\n\\n“学”，“习”这 4 个字对应的词向量传入到模型中，模型的输出结果是“o”，“s”，\\n\\n“b”，“m”，“e”这 5 个结果的分类概率（“o”表示用了填充的标注）。如图 16.6 所\\n\\n示。\\n\\n图 16.6 维特比算法 1\\n\\n我们先把这个图看懂，每个字传入模型中，就会得到 5 种标注的预测概率值，图中的 T\\n\\n表示状态转移矩阵。每一时刻，我们都根据上一时刻的情况和当前时刻的情况来计算当前每\\n\\n个状态的最佳路径，这句话可能有点难理解，但这是维特比算法的核心内容。\\n\\n假设“度”的标注是“s”，那么路径可能是 o->s，s->s，b->s，m->s，e->s。每条\\n\\n路径我们都会计算一个分数（score），我们可以认为分数越高这条路径越好。分数的计算如\\n\\nscore(o->s)=𝑃<\\n\\n(cid:210) + 𝑇(cid:210)(cid:222) + 𝑃\"\\n\\n(cid:222)，𝑃<\\n\\n(cid:210)为模型输入“深”得到“o”的概率，我的模型计算得到的\\n\\n值为5.24 × 10(cid:127)(cid:201)；𝑇(cid:210)(cid:222)为转移矩阵中 o->s 的值，为-inf；𝑃\"\\n\\n(cid:222)为模型输入“度”得到“s”的概\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n602\\n\\n率，我的模型计算得到的值为6.39 × 10(cid:127)(cid:176)。所以 score(o->s)=-inf。同样的方式，我们把\\n\\no->s，s->s，b->s，m->s，e->s 所有的分数计算出来，只保留最高的得分\\n\\nscore(e->s)=0.17。\\n\\n“度”的标注还可能是“o”，“b”，“m”，“e”。所以我们还需要分别计算上一时\\n\\n刻的状态到“o”，“b”，“m”，“e”的最佳路径以及路径得分。最后得到的结果如图\\n\\n16.7 所示。\\n\\n图 16.7 维特比算法 2\\n\\n图中的 S 表示路径得分 Score。接下来计算从“度”到“学”这一阶段。比如计算\\n\\nscore(e->s)=使用上一时刻的得分𝑆⁄+状态转移得分𝑇⁄(cid:222)+这一时刻的得分𝑃#\\n\\n(cid:222)。同样根据上一\\n\\n时刻的情况和当前时刻的情况来计算当前每个状态的最佳路径，结果如图 16.8 所示。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 16.8 维特比算法 3\\n\\n最后得到的结果如图 16.9 所示。\\n\\n图 16.9 维特比算法 4\\n\\n603\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n最后阶段得到 5 条最佳路径，o->o->o->o，b->e->s->s，b->e->s->b，\\n\\nb->e->b>m，b->e->b->e。最高得分是 4.67，所以最后我们选择的分词标注为\\n\\nb->e->b->e，所以分词结果为：\\n\\n[\\'深度\\', \\'学习\\']\\n\\n最后总结一下，路径的分数是由模型预测的概率作为分数再加上转移矩阵的分数得到\\n\\n的。也就是说如果每个序列模型预测的结果非常准确，其实状态转移矩阵的分数也就不太重\\n\\n要了，甚至可以忽略状态转移矩阵的分数；如果每个序列模型预测的结果不够准确，那么状\\n\\n态转移矩阵的分数就比较关键了，甚至可以适当增加状态转移矩阵分数的权重。所以在早期\\n\\n的一些 NLP 应用中，模型预测的结果准确率不够高，可能需要使用条件随机场 CRF 来训练\\n\\n出一个好的状态转移矩阵，这样可以使得标注结果更好。而现在如果我们使用 BERT 模型来\\n\\n预测序列结果，由于 BERT 模型预测准确率很高，所以状态转移矩阵就不一定是关键影响因\\n\\n素了。\\n\\n16.4.3 中文分词标注模型预测\\n\\n实现中文分词标注模型预测的代码如代码 16-6 所示。\\n\\n代码 16-6：中文分词标注模型预测（片段 1）\\n\\nimport numpy as np import re from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.text import tokenizer_from_json from tensorflow.keras.preprocessing.sequence import pad_sequences import json # 句子长度，需要跟模型训练时一致 max_length = 128 # 载入 tokenizer json_file = open(\\'token_config.json\\',\\'r\\',encoding=\\'utf-8\\')\\n\\n604\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com token_config = json.load(json_file) tokenizer = tokenizer_from_json(token_config) # 获得字典，键为字，值为编号 word_index = tokenizer.word_index # 载入模型 model = load_model(\\'lstm_tag.h5\\') # 载入数据集做处理主要是为了计算状态转移概率 # 读入数据 text = open(\\'msr_train.txt\\', encoding=\\'gb18030\\').read() # 根据换行符切分数据 text = text.split(\\'\\\\n\\')\\n\\n# 得到所有的数据和标签 def get_data(s): # 匹配(.)/(.)格式的数据 s = re.findall(\\'(.)/(.)\\', s) if s: s = np.array(s) # 返回数据和标签，0 为数据，1 为标签 return s[:,0],s[:,1]\\n\\n# 数据 data = [] # 标签 label = [] # 循环每个句子 for s in text: # 分离文字和标签 d = get_data(s) if d: # 0 为数据 data.append(d[0]) # 1 为标签 label.append(d[1]) # texts 二维数据，一行一个句子 # 比如 ngrams(texts,2,2)，只计算 2-grams # 比如 ngrams(texts,2,4)，计算 2-grams，3-grams，4-grams def ngrams(texts, MIN_N, MAX_N): # 定义空字典记录 ngrams_dict = {} # 循环每一个句子 for tokens in texts: # 计算一个句子 token 数量 n_tokens = len(tokens)\\n\\n605\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 词汇组合统计 for i in range(n_tokens): for j in range(i+MIN_N, min(n_tokens, i+MAX_N)+1): # 词汇组合 list 转字符串 temp = \\'\\'.join(tokens[i:j]) # 字典计数加一 ngrams_dict[temp] = ngrams_dict.get(temp, 0) + 1 # 返回字典 return ngrams_dict # 统计状态转移次数 ngrams_dict = ngrams(label,2,2) print(ngrams_dict) 结果输出为： {\\'sb\\': 600115, \\'be\\': 1039906, \\'es\\': 659674, \\'ss\\': 427204, \\'bm\\': 21514 9, \\'me\\': 215149, \\'mm\\': 211874, \\'eb\\': 594480}\\n\\n代码 16-6：中文分词标注模型预测（片段 2）\\n\\n# 计算状态转移总次数 sum_num = 0 for value in ngrams_dict.values(): sum_num = sum_num + value # 计算状态转移概率 p_sb = ngrams_dict[\\'sb\\']/sum_num p_be = ngrams_dict[\\'be\\']/sum_num p_es = ngrams_dict[\\'es\\']/sum_num p_ss = ngrams_dict[\\'ss\\']/sum_num p_bm = ngrams_dict[\\'bm\\']/sum_num p_me = ngrams_dict[\\'me\\']/sum_num p_mm = ngrams_dict[\\'mm\\']/sum_num p_eb = ngrams_dict[\\'eb\\']/sum_num # p_oo 用于表示不可能的转移，-np.inf 负无穷 p_oo = -np.inf\\n\\n# 使用条件随机场 CRF 来计算转移矩阵有可能效果会更好 # 这里我们用简单的二元模型来定义状态转移矩阵 # oo,os,ob,om,oe, # so,ss,sb,sm,se # bo,bs,bb,bm,be # mo,ms,mb,mm,me # eo,es,eb,em,ee # 其中 sm,se,bs,bb,ms,mb,em,ee 这几个状态转移是不存在的 # o 为填充状态，跟 o 相关的转移也都不需要考虑\\n\\n606\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com transition_params = [[p_oo,p_oo,p_oo,p_oo,p_oo], [p_oo,p_ss,p_sb,p_oo,p_oo], [p_oo,p_oo,p_oo,p_bm,p_be], [p_oo,p_oo,p_oo,p_mm,p_me], [p_oo,p_es,p_eb,p_oo,p_oo]]\\n\\n# 维特比算法 def viterbi_decode(sequence, transition_params): \"\"\" Args: sequence: 一个[seq_len, num_tags]矩阵 transition_params: 一个[num_tags, num_tags]矩阵 Returns: viterbi: 一个[seq_len]序列 \"\"\" # 假设状态转移共有 num_tags 种状态 # 创建一个跟 sequence 相同形状的网格 score = np.zeros_like(sequence) # 创建一个跟 sequence 相同形状的 path，用于记录路径 path = np.zeros_like(sequence, dtype=np.int32) # 起始分数 score[0] = sequence[0] for t in range(1, sequence.shape[0]): # t-1 时刻 score 得分加上 trans 分数，得到下一时刻所有状态转移 [num_tags, num_tags]的得分 T = np.expand_dims(score[t - 1], 1) + transition_params # t 时刻 score = 计算每个状态转移的最大得分 + 下个序列预测得分 score[t] = np.max(T, 0) + sequence[t] # 记录每个状态转移的最大得分所在位置 path[t] = np.argmax(T, 0) # score[-1]为最后得到的 num_tags 种状态得分 # np.argmax(score[-1])找到最高分数所在位置 viterbi = [np.argmax(score[-1])] # 回头确定来的路径，相当于知道最高分以后从后往前走 for p in reversed(path[1:]): viterbi.append(p[viterbi[-1]]) # 反转 viterbi 列表，把 viterbi 变成正向路径 viterbi.reverse() # 计算最大得分，如果需要可以 return # viterbi_score = np.max(score[-1])\\n\\nreturn Viterbi\\n\\n# 小句分词函数 def cut(sentence):\\n\\n607\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 如果句子大于最大长度，只取 max_length 个词 if len(sentence) >= max_length: seq = sentence[:max_length] # 如果不足 max_length，则填充 else: seq = [] for s in sentence: try: # 在字典里查询编号 seq.append(word_index[s]) except: # 如果不在字典里填充 0 seq.append(0) seq = seq + [0]*(max_length-len(sentence)) # 获得预测结果，shape(32,5) preds = model.predict([seq])[0] # 维特比算法 viterbi = viterbi_decode(preds, transition_params) # 只保留跟句子相同长度的分词标注 y = viterbi[:len(sentence)] # 分词 words = [] for i in range(len(sentence)): # 如果标签为 s 或 b，append 到结果的 list 中 if y[i] in [1, 2]: words.append(sentence[i]) else: # 如果标签为 m 或 e，在 list 最后一个元素中追加内容 words[-1] += sentence[i]\\n\\nreturn words\\n\\n# 根据符号断句 cuts = re.compile(u\\'([\\\\da-zA-Z ]+)|[。，、？！\\\\.\\\\?,!()（）]\\') # 先分小句，再对小句分词 def cut_word(s): result = [] # 指针设置为 0 i = 0 # 根据符号断句 for c in cuts.finditer(s): # 对符号前的部分分词 result.extend(cut(s[i:c.start()])) # 加入符号 result.append(s[c.start():c.end()])\\n\\n608\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 移动指针到符号后面 i = c.end() # 对最后的部分进行分词 result.extend(cut(s[i:])) return result\\n\\nprint(cut_word(\\'针对新冠病毒感染，要做好“早发现、早报告、早隔离、早治疗”，及时给予临 床治疗的措施。\\')) 结果输出为： [\\'针对\\', \\'新冠\\', \\'病毒\\', \\'感染\\', \\'，\\', \\'要\\', \\'做好\\', \\'“\\', \\'早\\', \\'发现\\', \\'、\\', \\'早\\', \\'报告\\', \\'、\\', \\'早\\', \\'隔离\\', \\'、\\', \\'早\\', \\'治疗\\', \\'”\\', \\'，\\', \\'及 时\\', \\'给予\\', \\'临床\\', \\'治疗\\', \\'的\\', \\'措施\\', \\'。\\']\\n\\n代码 16-6：中文分词标注模型预测（片段 3）\\n\\nprint(cut_word (\\'广义相对论是描写物质间引力相互作用的理论\\')) 结果输出为： [\\'广义\\', \\'相对论\\', \\'是\\', \\'描写\\', \\'物质\\', \\'间\\', \\'引力\\', \\'相互\\', \\'作用\\', \\'的 \\', \\'理论\\']\\n\\n代码 16-6：中文分词标注模型预测（片段 4）\\n\\nprint(cut_word(\\'阿尔法围棋（AlphaGo）是第一个击败人类职业围棋选手、第一个战胜围棋 世界冠军的人工智能，是谷歌（Google）旗下 DeepMind 公司戴密斯·哈萨比斯领衔的团队开 发。\\')) 结果输出为： [\\'阿尔法围棋\\', \\'（\\', \\'AlphaGo\\', \\'）\\', \\'是\\', \\'第一个\\', \\'击败\\', \\'人类\\', \\'职 业\\', \\'围棋\\', \\'选手\\', \\'、\\', \\'第一个\\', \\'战胜\\', \\'围棋\\', \\'世界\\', \\'冠军\\', \\'的\\', \\'人工\\', \\'智能\\', \\'，\\', \\'是\\', \\'谷歌\\', \\'（\\', \\'Google\\', \\'）\\', \\'旗\\', \\'下\\', \\'De epMind\\', \\'公司\\', \\'戴密斯·哈萨比斯\\', \\'领衔\\', \\'的\\', \\'团队\\', \\'开发\\', \\'。\\']\\n\\n经过测试我们看到模型可以得到较好的分词结果，对公司名，人名等这些命名实体也可\\n\\n以得到很好的识别效果。\\n\\n609\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n16.5 最新的一些激活函数介绍\\n\\nNLP 实战章节突然又讲到激活函数，大家不要觉得奇怪，肯定是因为下面的 NLP 实战内\\n\\n容有涉及到新的激活函数的使用。BERT 中使用的激活函数为 GELU(Gaussian Error Linear\\n\\nUnit)函数[2]，不再是我们熟悉的 ReLU 函数。在近年的深度学习技术发展中又诞生了许多新\\n\\n的激活函数，既然要介绍 GELU 函数，那干脆把一些新的激活函数都一起介绍一下吧。\\n\\n之前我们有介绍过 Sign，Sigmoid，Tanh，Softsign，ReLU 这些激活函数，这些激活\\n\\n函数中表现最好的自然是 ReLU。ReLU 的优点是计算简单，可以避免梯度消失。下面要介绍\\n\\n的这些激活函数大部分都跟 ReLU 有点关系。新的一些激活函数有部分在 Tensorflow 中可\\n\\n以直接调用，有部分在 Tensorflow 中没有，需要自行定义，如何自定义激活函数可以参考\\n\\n后面 BERT 的源代码。\\n\\n16.5.1 Leaky ReLU\\n\\n带泄露修正线性单元 Leaky ReLU[3]算是 ReLU 函数的一个变种，可以简写为 LReLU，\\n\\n公式为：\\n\\n𝐿𝑅𝑒𝐿𝑈(𝑥) = 1\\n\\n𝑥\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼𝑥\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.1)\\n\\nLReLU 的导数公式为：\\n\\n𝐿𝑅𝑒𝐿𝑈R(V) = 1\\n\\n1\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼\\t\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.2)\\n\\n这里的𝛼是一个人为设置的超参数，一般取值范围是 0.1-0.3。𝛼为 0.3 时，Leaky ReLU\\n\\n函数图像如图 16.10 所示。\\n\\n610\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 16.10 Leaky ReLU\\n\\nLeaky ReLU 函数的导数图像如图 16.11 所示。\\n\\n图 16.11 Leaky ReLU 函数导数\\n\\n从图中我们就可以看出 Leaky ReLU 的特点是当 x 取值为负时，函数也有对应的输出，\\n\\n并且 x 取值为负时也存在较小的梯度。可以解决 ReLU 函数中当 x 取值为负时，函数只能输\\n\\n出 0，并且导数也为 0 的问题。其实总的来说 ReLU 和 Leaky ReLU 效果差不多，只不过有\\n\\n些时候使用 Leaky ReLU 可以得到更好的效果。\\n\\n16.5.2 ELU\\n\\n指数线性单元 ELU(Exponential Linear Unit)[4]也是一个跟 ReLU 类似的激活函数，公\\n\\n式为：\\n\\n611\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸𝐿𝑈(𝑥) = 1\\n\\n𝑥\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼(𝑒 V − 1)\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.3)\\n\\nELU 的导数为公式：\\n\\n𝐸𝐿𝑈R(V) = 1\\n\\n1\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼𝑒 V\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.4)\\n\\n这里的𝛼是一个人为设置的超参数，一般取值范围是 0.1-0.3。𝛼为 0.3 时，ELU 函数图像\\n\\n如图 16.12 所示。\\n\\n图 16.12 ELU\\n\\nELU 函数的导数图像如图 16.13 所示。\\n\\n图 16.13 ELU 函数导数\\n\\n从图中我们就可以看出 ELU 跟 Leaky ReLU 挺像的，当 x 取值为负时，函数也有对应的\\n\\n输出，并且 x 取值为负时也存在较小的梯度。只不过 ELU 中有指数计算，x 的值越小，梯度\\n\\n612\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的值也会越接近于 0。一般来说使用 ELU 作为激活函数，模型的效果可能会比使用 ReLU 要\\n\\n稍微好一些。\\n\\n16.5.3 SELU\\n\\n扩展指数线性单元 SELU(Scaled Exponential Linear Unit)[5]看名字就知道应该是跟\\n\\nELU 差不多，SELU 的公式为：\\n\\n𝑆𝐸𝐿𝑈(𝑥) = 𝜆 × 1\\n\\n𝑥\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼(𝑒 V − 1)\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.5)\\n\\nSELU 的导数为公式：\\n\\n𝑆𝐸𝐿𝑈R(V) = 𝜆 × 1\\n\\n1\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥 > 0) 𝛼𝑒 V\\t\\t𝑖𝑓(𝑥 ≤ 0)\\n\\n(16.6)\\n\\n比 ELU 公式中多了一个𝜆，大家可能会想又多了一个参数，调参岂不是更困难。这个大家\\n\\n可以放心，作者用一篇包含 300 多个公式推导的 100 页左右的论文告诉我们：\\n\\n𝛼 ≈ 1.6732632423543772848170429916717 𝜆 ≈ 1.0507009873554804934193349852946\\n\\n具体的推导过程估计没几个人会去看，大家有兴趣的话可以自行研究。总之得到𝛼和𝜆这\\n\\n两个具体的数值以后，神经网络每一层的激活值都会满足均值接近于 0，标准差接近于 1 的\\n\\n正态分布。可以有效的解决梯度消失问题，同时加快模型收敛速度，这跟 Batch\\n\\nNormalization 比较类似。而使用了 SELU 激活函数的网络也被称为自归一化神经网络\\n\\n(Self-Normalizing Neural Networks)，简称 SNN。\\n\\nSNN 模型训练有一个条件，就是必须要对网络的权值进行标准化的权值初始化，比如可\\n\\n以使用 lecun_normal(参考内容来自 http://yann.lecun.com/exdb/publis/pdf/lecun-\\n\\n98b.pdf)初始化网络权值，否则可能会训练失败。另外如果网络中需要使用 Dropout 的话，\\n\\n613\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n最好使用 Alpha Dropout。Alpha Dropout 是一种保持信号均值和方差不变的 Dropout，\\n\\n该层的作用是即使在 Dropout 的时候也保持数据的自规范性。\\n\\nSELU 函数图像如图 16.14 所示。\\n\\n图 16.14 SELU\\n\\nSELU 函数的导数图像如图 16.15 所示。\\n\\n图 16.15 SELU 函数导数\\n\\nSELU 良好的自归一化特性使得它在很多任务中都会比 ReLU 得到更好的效果。\\n\\n16.5.4 GELU\\n\\n高斯误差线性单元 GELU(Gaussian Error Linear Unit)[6]，BERT 模型中使用的激活函\\n\\n数就是 GELU。\\n\\n614\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nGELU 的公式为：\\n\\n𝐺𝐸𝐿𝑈(𝑥) = 𝑥𝑃(𝑋 ≤ 𝑥) = 𝑥Φ(𝑥)\\t\\t\\t\\t\\t\\t\\t\\t(16.7)\\n\\n其中𝑃(𝑋 ≤ 𝑥)表示概率值，Φ(𝑥)指的是 x 的正态分布的累积分布函数：\\n\\nV 𝐺𝐸𝐿𝑈(𝑥) = 𝑥𝑃(𝑋 ≤ 𝑥) = 𝑥 5\\n\\n(cid:127):\\n\\n(6(cid:127)7)(cid:157) #8(cid:157)\\n\\n𝑒(cid:127) √2𝜋𝜎\\n\\n𝑑𝑋\\t\\t\\t\\t\\t\\t\\t(16.8)\\n\\n计算结果可以约等于：\\n\\n𝐺𝐸𝐿𝑈(𝑥) = 0.5𝑥 (cid:139)1 + tanh (cid:138)o\\n\\n2 𝜋\\n\\n(𝑥 + 0.044715𝑥$)(cid:141)(cid:140)\\t\\t\\t(16.9)\\n\\nGELU 的导数为公式：\\n\\n𝐺𝐸𝐿𝑈R(V) = 0.5 tanh(0.0356774𝑥$ + 0.797885𝑥) + (0.0535161𝑥$ + 0.398942𝑥) × 𝑠𝑒𝑐ℎ#(0.0356774𝑥$ + 0.797885𝑥) + 0.5\\t\\t\\t\\t\\t\\t\\t\\t(16.10)\\n\\n概率𝑃(𝑋 ≤ 𝑥)中的 x 表示当前神经元的激活值输入，X 的正态分布的累积分布Φ(𝑥)是随\\n\\n着 x 的变化而变化的。当神经元激活值输入 x 增大，Φ(𝑥)也会增大；当 x 减小，Φ(𝑥)也会减\\n\\n小。如果 x 很小，Φ(𝑥)的值会接近于 0，神经元的输出值会接近于 0，相当于神经元被\\n\\nDropout；如果 x 比较大，Φ(𝑥)的值会接近于 1，相当于神经元会保留。\\n\\nGELU 的函数图像如图 16.16 所示。\\n\\n图 16.16 GELU\\n\\n615\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nGELU 函数的导数图像如图 16.17 所示。\\n\\n图 16.17 GELU 函数导数\\n\\nGELU 激活函数在很多实验中也表现出了比 ReLU 和 ELU 更好的效果。\\n\\n16.5.5 Swish\\n\\nSwish[7]是由谷歌提出的一个激活函数，谷歌也是做了很多实验证明 Swish 比 Relu 要更\\n\\n好，甚至比 LReLU，ELU，SELU，GELU 这些 ReLU 的变形还要好。当然 Swish 真正的效果\\n\\n如何，大家不妨在之后的项目中尝试使用看看，对比一下其他的激活函数就知道了。\\n\\nSwish 的公式为：\\n\\n𝑆𝑤𝑖𝑠ℎ(𝑥) = 𝑥 × 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.11)\\n\\n这里的𝛽是一个人为设置的参数值，也可以通过模型训练得到。\\n\\nSwish 的导数为公式：\\n\\n𝑆𝑤𝑖𝑠ℎR(𝑥) = 𝛽𝑆𝑤𝑖𝑠ℎ(𝑥) + 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥) × (cid:142)1 − 𝛽𝑆𝑤𝑖𝑠ℎ(𝑥)(cid:143)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.12)\\n\\nSwish 的函数图像如图 16.18 所示。\\n\\n616\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 16.18 Swish\\n\\nSwish 函数的导数图像如图 16.19 所示。\\n\\n图 16.19 Swish 函数导数\\n\\n16.6 BERT 模型简单使用\\n\\n16.6.1 安装 tf2-bert 模块并准备预训练模型\\n\\n我参考 Github 上一个做得比较好的 BERT 开源项目 bert4kera(参考内容来自\\n\\nhttps://github.com/bojone/bert4keras)，在它的基础上进行了进一步的精简，只留下跟\\n\\n617\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nBERT 相关的最核心的代码，并把它变成了“全注释代码”，主要是方便大家学习和基本使\\n\\n用。我精简和注释过的项目发布在我的 Github 上：https://github.com/Qinbf/tf2_bert。\\n\\nBERT 模型的完整实现即便是做了很多的精简，整个程序也还是有 1000 多行的代码。所\\n\\n以在这里我们就不讲解 BERT 模型实现的细节了，大家可以到我的 Github 上下载程序来进\\n\\n行学习。下面我们主要讲一下如何使用 BERT 来完成 NLP 相关的一些任务。首先我们需要先\\n\\n安装 tf2_bert 模块，安装方式为打开命令提示符运行命令：\\n\\npip install tf2-bert\\n\\n模块安装好以后我们还需要下载预训练模型，可以通过网址\\n\\n（https://github.com/google-research/bert）下载谷歌官方的预训练模型，谷歌提供的\\n\\n预训练模型大部分都是使用英文语料训练出来的。如果大家要使用中文语料训练的 BERT 模\\n\\n型，推荐大家使用哈工大提供的预训练模型，网址为：\\n\\nhttps://github.com/ymcui/Chinese-BERT-wwm。\\n\\n我在哈工大提供的预训练模型中下载了一个简称为“RoBERTa-wwm-ext, Chinese”的\\n\\n模型，下载地址为：\\n\\nhttp://pan.iflytek.com/#/link/98D11FAAF0F0DBCB094EE19CCDBC98BF，密码为\\n\\nXe1p。下载好以后得到一个名为“chinese_roberta_wwm_ext_L-12_H-768_A-12”的文件\\n\\n夹，文件夹中的文件如图 16.20 所示。\\n\\n图 16.20 模型文件\\n\\n618\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n其中“bert_config.json”是 BERT 模型相关的一些配置文件，“vocab.txt”为 BERT 模\\n\\n型训练时用到的词表，剩下的 3 个为 Tensorflow 的模型文件。“ckpt”为“checkpoint”\\n\\n的缩写，“ckpt”这种模型保存格式在 Tensorflow1.0 中用得比较多，也可以沿用至\\n\\nTensorflow2。\\n\\n16.6.2 使用 BERT 进行文本特征提取\\n\\n准备工作做好以后，下面我们开始进行 BERT 模型的使用，首先我们先用预训练的 BERT\\n\\n模型来进行文本特征提取，如代码 16-7 所示。\\n\\n代码 16-7：使用 BERT 进行文本特征提取（片段 1）\\n\\nfrom tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer import numpy as np # 定义预训练模型路径 model_dir = \\'./chinese_roberta_wwm_ext_L-12_H-768_A-12\\' # BERT 参数 config_path = model_dir+\\'/bert_config.json\\' # 保存模型权值参数的文件 checkpoint_path = model_dir+\\'/bert_model.ckpt\\' # 词表 dict_path = model_dir+\\'/vocab.txt\\' # 建立分词器 tokenizer = Tokenizer(dict_path) # 建立模型，加载权重 model = build_transformer_model(config_path, checkpoint_path) # 句子 0 sentence0 = \\'机器学习\\' # 句子 1 sentence1 = \\'深度学习\\' # 用分词器对句子分词 tokens = tokenizer.tokenize(sentence0) # 分词后自动在句子前加上[CLS]，在句子后加上[SEP] print(tokens) 结果输出为： [\\'[CLS]\\', \\'机\\', \\'器\\', \\'学\\', \\'习\\', \\'[SEP]\\']\\n\\n619\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-7：使用 BERT 进行文本特征提取（片段 2）\\n\\n# 编码测试 token_ids, segment_ids = tokenizer.encode(sentence0) # [CLS]的编号为 101，机为 3322，器为 1690，学为 2110，习为 739，[SEP]为 102 print(\\'token_ids:\\',token_ids) # 因为只有一个句子所以 segment_ids 都是 0 print(\\'segment_ids:\\',segment_ids) 结果输出为： token_ids: [101, 3322, 1690, 2110, 739, 102] segment_ids: [0, 0, 0, 0, 0, 0]\\n\\n代码 16-7：使用 BERT 进行文本特征提取（片段 3）\\n\\n# 编码测试 token_ids, segment_ids = tokenizer.encode(sentence0,sentence1) # 可以看到两个句子分词后的结果为： # [\\'[CLS]\\', \\'机\\', \\'器\\', \\'学\\', \\'习\\', \\'[SEP]\\', \\'深\\', \\'度\\', \\'学\\', \\'习\\', [SEP]] print(\\'token_ids:\\',token_ids) # 0 表示第一个句子的 token，1 表示第二个句子的 token print(\\'segment_ids:\\',segment_ids) 结果输出为： token_ids: [101, 3322, 1690, 2110, 739, 102, 3918, 2428, 2110, 739, 1 02] segment_ids: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\\n\\n代码 16-7：使用 BERT 进行文本特征提取（片段 4）\\n\\n# 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids]) # 得到的结果中 1 表示批次大小，11 表示 11 个 token，768 表示特征向量长度 # 这里就是把句子的 token 转化为了特征向量 print(pre.shape) 结果输出为： (1, 11, 768)\\n\\n620\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n16.6.3 使用 BERT 进行完形填空\\n\\n使用 BERT 进行完形填空其实就是使用 BERT 的掩码语言模型 MLM 来对包\\n\\n含”[MASK]”符号的句子进行预测，把”[MASK]”符号变成合理的词填入到句子中，如代\\n\\n码 16-8 所示。\\n\\n代码 16-8：使用 BERT 进行完形填空（片段 1）\\n\\nfrom tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer import numpy as np # 定义预训练模型路径 model_dir = \\'./chinese_roberta_wwm_ext_L-12_H-768_A-12\\' # BERT 参数 config_path = model_dir+\\'/bert_config.json\\' # 保存模型权值参数的文件 checkpoint_path = model_dir+\\'/bert_model.ckpt\\' # 词表 dict_path = model_dir+\\'/vocab.txt\\' # 建立分词器 tokenizer = Tokenizer(dict_path) # 建立模型，加载权重 # with_mlm=True 表示使用 mlm 的功能，模型结构及最后的输出会发生一些变化，可以用来 预测被 mask 的 token model = build_transformer_model(config_path, checkpoint_path, with_mlm=True) # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode(\\'机器学习是一门交叉学科\\') # 把“学”字和“习”字变成“[MASK]”符号 token_ids[3] = token_ids[4] = tokenizer._token_dict[\\'[MASK]\\'] # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第 3，4 个位置经过模型预测，[MASK]变成了“学习” print(tokenizer.decode(pre[3:5].argmax(axis=1))) 结果输出为： 学习\\n\\n621\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-8：使用 BERT 进行完形填空（片段 2）\\n\\n# 分词并转化为编码 token_ids, segment_ids = tokenizer.encode(\\'机器学习是一门交叉学科\\') # 把“交”字和“叉”字变成“[MASK]”符号 token_ids[8] = token_ids[9] = tokenizer._token_dict[\\'[MASK]\\'] # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第 8，9 个位置经过模型预测，[MASK]变成了“什么”，句子变成了一个疑问句 # 虽然模型没有预测出原始句子的词汇，不过作为完形填空，填入一个“什么”句子也是正确 print(tokenizer.decode(pre[8:10].argmax(axis=1))) 结果输出为： 什么\\n\\n16.7 BERT 电商用户多情绪判断项目\\n\\n16.7.1 项目背景介绍\\n\\n之前我们使用的情感分类数据都是网上可以找到的开源数据，并且相对简单。这一小节\\n\\n我们来点更硬核的内容，给大家介绍一个我之前给某化妆品公司做的电商用户多种情绪判断\\n\\n的项目，项目用到的部分标注好的数据我会跟本书的代码一起开放给大家下载，供大家学习\\n\\n和研究使用。项目背景大概就是化妆品公司希望可以通过分析自己用户的评论数据，挖掘影\\n\\n响产品购买的因素，提供产品建议或策略指导，进而提升效率。了解对方需求后，我对用户\\n\\n评论的分析并不只是针对好评还是差评这一个维度来判断，只判断好评差评维度太单一，无\\n\\n法挖掘出更深层次的内容。因此我把用户评论的分析分为了 7 个不同维度，分别是总体评\\n\\n论，是否为老用户，是否是参与活动购买，产品质量评价，性价比评价，客户物流包装等服\\n\\n务评价，是否考虑在再次购买，如图 16.21：\\n\\n622\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 16.21 用户评论 7 个维度分析\\n\\n每个维度都有 3 个分类，在数据的标注中使用 1，0，-1 来标注。具体情况如图 16.22\\n\\n所示。\\n\\n图 16.22 7 个维度具体标注情况\\n\\n获得用户评论中更多维度的信息以后就可以对用户评论进行更深入的挖掘和更全面的分\\n\\n析。\\n\\n623\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n16.7.2 模型训练\\n\\n实现 BERT 电商用户多情绪判断-模型训练的代码如代码 16-9 所示。\\n\\n代码 16-9：BERT 电商用户多情绪判断-模型训练（片段 1）\\n\\nfrom tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer from tensorflow.keras.utils import to_categorical from tensorflow.keras.layers import Lambda,Dense,Input,Dropout from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ModelCheckpoint import numpy as np import pandas as pd from plot_model import plot_model # 周期数 epochs = 5 # 批次大小 batch_size = 16 # 验证集占比 validation_split = 0.2 # 句子长度 seq_len = 256 # 载入数据 data = pd.read_excel(\\'reviews.xlsx\\') # 查看数据前 5 行 data.head() 结果输出为：\\n\\n代码 16-9：BERT 电商用户多情绪判断-模型训练（片段 2）\\n\\n# 定义预训练模型路径\\n\\n624\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model_dir = \\'./chinese_roberta_wwm_ext_L-12_H-768_A-12\\' # BERT 参数 config_path = model_dir+\\'/bert_config.json\\' # 保存模型权值参数的文件 checkpoint_path = model_dir+\\'/bert_model.ckpt\\' # 词表 dict_path = model_dir+\\'/vocab.txt\\' # 建立分词器 tokenizer = Tokenizer(dict_path) # 建立模型，加载权重 bert_model = build_transformer_model(config_path, checkpoint_path)\\n\\ntoken_ids = [] segment_ids = [] # 循环每个句子 for s in data[\\'评论\\'].astype(str): # 分词并把 token 变成编号 token_id,segment_id = tokenizer.encode(s, first_length=seq_len) token_ids.append(token_id) segment_ids.append(segment_id) token_ids = np.array(token_ids) segment_ids = np.array(segment_ids)\\n\\nlabel = [] # 定义标签 def LabelEncoder(y): # 增加一个维度 y = y[:,np.newaxis] # 原始标签把-1,0,1 变成 0,1,2 y = y+1 y = y.astype(\\'uint8\\') # 转成独热编码 y = to_categorical(y, num_classes=3) return y\\n\\n# 获取 7 个维度的标签，并把每个维度的标签从-1,0,1 变成 0,1,2 label = [(LabelEncoder(np.array(data[columns]))) for columns in data.columns[1:]] label = np.array(label) print(label.shape) 结果输出为： (7, 10000, 3)\\n\\n625\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-9：BERT 电商用户多情绪判断-模型训练（片段 3）\\n\\n# token 输入 token_in = Input(shape=(None,)) # segment 输入 segment_in = Input(shape=(None,)) # 使用 BERT 进行特征提取 x = bert_model([token_in, segment_in]) # 每个序列的第一个字符是句子的分类[CLS],该字符对应的 embedding 可以用作分类任务中 该序列的总表示 # 说白了就是用句子第一个字符的 embedding 来表示整个句子 # 取出每个句子的第一个字符对应的 embedding x = Lambda(lambda x: x[:, 0])(x)\\n\\n# 多任务学习 # 性价比输出层 x0 = Dropout(0.5)(x) preds0 = Dense(3, activation=\\'softmax\\',name=\\'out0\\')(x0) # 产品质量输出层 x1 = Dropout(0.5)(x) preds1 = Dense(3, activation=\\'softmax\\',name=\\'out1\\')(x1) # 参加活动输出层 x2 = Dropout(0.5)(x) preds2 = Dense(3, activation=\\'softmax\\',name=\\'out2\\')(x2) # 客服物流包装输出层 x3 = Dropout(0.5)(x) preds3 = Dense(3, activation=\\'softmax\\',name=\\'out3\\')(x3) # 是否为老顾客输出层 x4 = Dropout(0.5)(x) preds4 = Dense(3, activation=\\'softmax\\',name=\\'out4\\')(x4) # 是否会再买输出层 x5 = Dropout(0.5)(x) preds5 = Dense(3, activation=\\'softmax\\',name=\\'out5\\')(x5) # 总体评论输出层 x6 = Dropout(0.5)(x) preds6 = Dense(3, activation=\\'softmax\\',name=\\'out6\\')(x6) # 定义模型 model = Model([token_in, segment_in], [preds0,preds1,preds2,preds3,preds4,preds5,preds 6]) # 画出模型结构 plot_model(model,dpi=200) 结果输出为：\\n\\n626\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-9：BERT 电商用户多情绪判断-模型训练（片段 4）\\n\\n# 定义模型训练的 loss，loss_weights，optimizer # loss_weights 表示每个任务的权重，可以看情况设置 model.compile(loss={ \\'out0\\': \\'categorical_crossentropy\\', \\'out1\\': \\'categorical_crossentropy\\', \\'out2\\': \\'categorical_crossentropy\\', \\'out3\\': \\'categorical_crossentropy\\', \\'out4\\': \\'categorical_crossentropy\\', \\'out5\\': \\'categorical_crossentropy\\', \\'out6\\': \\'categorical_crossentropy\\'}, loss_weights={ \\'out0\\': 1., \\'out1\\': 1., \\'out2\\': 1., \\'out3\\': 1., \\'out4\\': 1., \\'out5\\': 1, \\'out6\\': 2.}, optimizer=Adam(1e-5), metrics=[\\'accuracy\\'])\\n\\n# 保存 val_loss 最低的模型 callbacks = [ModelCheckpoint(filepath=\\'bert_model/\\'+\\'{epoch:02d}.h5\\', monitor=\\'val_loss\\', verbose=1, save_best_only=True)]\\n\\n# 训练模型 model.fit([token_ids, segment_ids], [label[0],label[1],label[2],label[3],label[4],label[5],label[6]] ,\\n\\n627\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks) 结果输出为： Train on 8000 samples, validate on 2000 samples Epoch 1/5 7984/8000 [============================>.] - ETA: 0s - loss: 3.4144 - out0_loss: 0.2809 - out1_loss: 0.6564 - out2_loss: 0.2141 - out3_los s: 0.4407 - out4_loss: 0.4736 - out5_loss: 0.2666 - out6_loss: 0.5410 - out0_accuracy: 0.9176 - out1_accuracy: 0.7325 - out2_accuracy: 0.9 400 - out3_accuracy: 0.8403 - out4_accuracy: 0.8391 - out5_accuracy: 0.9163 - out6_accuracy: 0.8111 …… Epoch 5/5 7984/8000 [============================>.] - ETA: 0s - loss: 0.9488 - out0_loss: 0.0636 - out1_loss: 0.2589 - out2_loss: 0.0501 - out3_los s: 0.0752 - out4_loss: 0.1288 - out5_loss: 0.0652 - out6_loss: 0.1535 - out0_accuracy: 0.9797 - out1_accuracy: 0.9023 - out2_accuracy: 0.9 862 - out3_accuracy: 0.9757 - out4_accuracy: 0.9543 - out5_accuracy: 0.9770 - out6_accuracy: 0.9461 Epoch 00005: val_loss did not improve from 2.51170 8000/8000 [==============================] - 287s 36ms/sample - los s: 0.9486 - out0_loss: 0.0635 - out1_loss: 0.2588 - out2_loss: 0.0500 - out3_loss: 0.0751 - out4_loss: 0.1293 - out5_loss: 0.0651 - out6_l oss: 0.1534 - out0_accuracy: 0.9797 - out1_accuracy: 0.9022 - out2_ac curacy: 0.9862 - out3_accuracy: 0.9758 - out4_accuracy: 0.9540 - out5 _accuracy: 0.9770 - out6_accuracy: 0.9461 - val_loss: 3.0706 - val_ou t0_loss: 0.1404 - val_out1_loss: 0.5145 - val_out2_loss: 0.2064 - val _out3_loss: 0.1928 - val_out4_loss: 0.3246 - val_out5_loss: 0.2494 - val_out6_loss: 0.7211 - val_out0_accuracy: 0.9580 - val_out1_accurac y: 0.8125 - val_out2_accuracy: 0.9515 - val_out3_accuracy: 0.9450 - v al_out4_accuracy: 0.9015 - val_out5_accuracy: 0.9185 - val_out6_accu racy: 0.8260\\n\\n16.7.3 模型预测\\n\\n实现 BERT 电商用户多情绪判断-模型预测的代码如代码 16-10 所示。\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 1）\\n\\nfrom tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer\\n\\n628\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.models import load_model import numpy as np # 载入模型 model = load_model(\\'bert_model.h5\\') # 词表路径 dict_path = \\'./chinese_roberta_wwm_ext_L-12_H-768_A-12\\'+\\'/vocab.txt\\' # 建立分词器 tokenizer = Tokenizer(dict_path) # 预测函数 def predict(text): # 分词并把 token 变成编号，句子长度需要与模型训练时一致 token_ids, segment_ids = tokenizer.encode(text, first_length=256) # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 模型预测 pre = model.predict([token_ids, segment_ids]) # 去掉一个没用的维度 pre = np.array(pre).reshape((7,3)) # 获得可能性最大的预测结果 pre = np.argmax(pre,axis=1)\\n\\ncomment = \\'\\' if(pre[0]==0): comment += \\'性价比差,\\' elif(pre[0]==1): comment += \\'-,\\' elif(pre[0]==2): comment += \\'性价比好,\\'\\n\\nif(pre[1]==0): comment += \\'质量差,\\' elif(pre[1]==1): comment += \\'-,\\' elif(pre[1]==2): comment += \\'质量好,\\'\\n\\nif(pre[2]==0): comment += \\'希望有活动,\\' elif(pre[2]==1): comment += \\'-,\\' elif(pre[2]==2): comment += \\'参加了活动,\\'\\n\\n629\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nif(pre[3]==0): comment += \\'客服物流包装差,\\' elif(pre[3]==1): comment += \\'-,\\' elif(pre[3]==2): comment += \\'客服物流包装好,\\'\\n\\nif(pre[4]==0): comment += \\'新用户,\\' elif(pre[4]==1): comment += \\'-,\\' elif(pre[4]==2): comment += \\'老用户,\\'\\n\\nif(pre[5]==0): comment += \\'不会再买,\\' elif(pre[5]==1): comment += \\'-,\\' elif(pre[5]==2): comment += \\'会继续购买,\\'\\n\\nif(pre[6]==0): comment += \\'差评\\' elif(pre[6]==1): comment += \\'中评\\' elif(pre[6]==2): comment += \\'好评\\'\\n\\nreturn pre,comment\\n\\npre,comment = predict(\"还没用，不知道怎么样\") print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [1 1 1 1 1 1 1] comment: -,-,-,-,-,-,中评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 2）\\n\\npre,comment = predict(\"质量不错，还会再来，价格优惠\") print(\\'pre:\\',pre)\\n\\n630\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 1 2 2] comment: 性价比好,质量好,-,-,-,会继续购买,好评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 3）\\n\\npre,comment = predict(\"好用不贵物美价廉，用后皮肤水水的非常不错\") print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 1 1 2] comment: 性价比好,质量好,-,-,-,-,好评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 4）\\n\\npre,comment = predict(\\'一直都用这款产品，便宜又补水，特别好用，今后要一直屯下去。\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 2 2 2] comment: 性价比好,质量好,-,-,老用户,会继续购买,好评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 5）\\n\\npre,comment = predict(\\'趁着搞活动又囤了几盒，很划算，天天用也不心疼，补水效果还可以 的\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 2 1 1 1 2] comment: 性价比好,质量好,参加了活动,-,-,-,好评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 6）\\n\\npre,comment = predict(\\'我周六买的，星期一才发货，问客服没有回复，不过速度还是快，星 期二收到的。发货速度有待改进。\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [1 1 1 0 1 1 0] comment: -,-,-,客服物流包装差,-,-,差评\\n\\n631\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 7）\\n\\npre,comment = predict(\\'人生中第一次差评，差评一是给这个产品，用了过敏；二是给这个客 服，说过敏仅支持退货并且运费自理。我的天！那我就不退了吧。只能说自己倒霉咯，过敏 了没人管，退货还得自掏腰包，最惨不过我\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [1 0 1 0 1 1 0] comment: -,质量差,-,客服物流包装差,-,-,差评\\n\\n代码 16-10：BERT 电商用户多情绪判断-模型预测（片段 8）\\n\\npre,comment = predict(\\'自从朋友推荐就一直使用这款面膜，哈哈哈哈，这款面膜一件用了很 久了，每次活动买，比较实惠划算，比较适合我自己。唯一感觉不足的就是乳液太少。发货 也特别快，值得购买。会在买的。\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 2 2 2 2 2] comment: 性价比好,质量好,参加了活动,客服物流包装好,老用户,会继续购买,好评\\n\\n16.8 参考文献\\n\\n[1] Kim Y . Convolutional Neural Networks for Sentence Classification[J]. Eprint Arxiv,\\n\\n2014.\\n\\n[2] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint\\n\\narXiv:1606.08415, 2016.\\n\\n[3] Maas A L, Hannun A Y, Ng A Y. Rectifier nonlinearities improve neural network\\n\\nacoustic models[C]//Proc. icml. 2013, 30(1): 3.\\n\\n[4] Clevert D A, Unterthiner T, Hochreiter S. Fast and accurate deep network learning\\n\\nby exponential linear units (elus)[J]. arXiv preprint arXiv:1511.07289, 2015.\\n\\n632\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[5] Klambauer G, Unterthiner T, Mayr A, et al. Self-normalizing neural\\n\\nnetworks[C]//Advances in neural information processing systems. 2017: 971-980.\\n\\n[6] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint\\n\\narXiv:1606.08415, 2016.\\n\\n[7]Ramachandran P, Zoph B, Le Q V. Searching for activation functions[J]. arXiv\\n\\npreprint arXiv:1710.05941, 2017.\\n\\n第 17 章 音频信号处理\\n\\n深度学习目前应用最广泛的 3 大领域就是计算机视觉，自然语言处理和语音。计算机视\\n\\n觉和自然语言处理的内容在前面我们都已经有所了解，这一章节我们就来介绍一下语音方面\\n\\n的任务。本章出现的新概念比较多，要想把这一章的内容学好，最好把这些新概念的中英文\\n\\n名称都记住，对应的含义都理解清楚。\\n\\n633\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n17.1 深度学习在声音领域的应用介绍\\n\\n1. 音频分类\\n\\n音频分类算是音频领域的一个基本应用，就是判断一段音频数据是属于哪一种分类，比\\n\\n如分类可以是人的说话声，飞机轰鸣声，汽车声音，火车声音，小孩哭声，玻璃破碎声，狗\\n\\n叫声，警报声等等，如图 17.1 所示。\\n\\n图 17.1 语音分类\\n\\n2.音频事件检测\\n\\n音频事件检测（Audio Event Detection）其实跟音频分类有点像，就是实时监测环境中\\n\\n的音频事件，这里的音频事件可以看成是某种声音的分类。比如一对新婚夫妻生了一个小婴\\n\\n儿，父母睡眠质量都比较好并且对婴儿哭声不太敏感，半夜婴儿肚子饿，哭了半天父母才能\\n\\n醒过来。如果要解决这个问题我们可以把婴儿的哭声作为要检测的音频事件，检测到婴儿的\\n\\n哭声后，可以触发一个音量比较大的闹钟铃声唤醒婴儿的父母。如图 17.2 所示。\\n\\n图 17.2 音频事件检测\\n\\n634\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n3. 语音识别\\n\\n语音识别大家应该比较熟悉，就是把语音信息转化为文字信息。在我们的日常生活中语\\n\\n音识别已经得到了较大规模的应用，日常用语的语音识别效果已经可以达到非常高的准确\\n\\n率。\\n\\n4．音乐检索\\n\\n音乐检索就是通过一小段音乐去检索出该音乐出自哪一首歌曲，也就是我们日常所说的\\n\\n听歌识曲。不少音乐类 APP 现在都已经实现了该功能。\\n\\n5. 音乐生成\\n\\nAI 与音乐的结合在这几年变得越来越频繁，在 2019 年中国数字音乐产业发展峰会上，\\n\\n有音乐制作公司在现场演示了 AI 作曲的操作，只需要给 AI 算法随意唱几个音符，它就可以\\n\\n作出一首完整的歌曲。美国网红歌手 Taryn Southern 跟 AI 一起创作了一首歌《Break\\n\\nFree》。AI 技术用于音乐生成目前还处于比较早期的阶段，相信在未来我们可以听到更多更\\n\\n好的 AI 音乐作品。\\n\\n6. 语音合成\\n\\n语音合成包括把文本文字合成人声。近几年有部分广告推销电话已经开始时候语音合成\\n\\n技术，使用机器来给我们打电话。如果不仔细分辨的话，有可能还不知道对方是机器人。当\\n\\n然，目前这个技术还不算特别成熟，机器人的声音相比于普通人的声音来说会显得更僵硬一\\n\\n些，说话方式没有人这么自然。\\n\\n635\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7. 语音克隆\\n\\n语音克隆技术指的是克隆某个人的声音。给算法输入某个人的一个声音片段，算法会学\\n\\n习这个人的方式，然后再把这种说话方法跟其他的人声相结合。比如你想模仿“小团团”魔\\n\\n性的声音，就准备一段“小团团”的语言片段传给算法学习，然后算法就可以把你的说话声\\n\\n音变成“小团团”的声音了。\\n\\n17.2 MFCC 和 Mel Filter Banks\\n\\n这一小节我们来介绍一下自动语言识别(Automatic Speech Recognition，简称 ASR)\\n\\n领域中最常用的两种语音处理方法： 梅尔滤波器组（Mel Filter Banks）和梅尔频率倒谱系\\n\\n数 (Mel-frequency cepstral coefficients，简称 MFCC )。\\n\\n语音数据处理的流程如图 17.3 所示。\\n\\n636\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 17.3 语音数据处理的流程\\n\\n17.2.1 音频数据采集\\n\\n首先我们来大概了解一下语音中的一些基本概念，语音信号在自然界中是属于模拟信号\\n\\n（Analog Signal），模拟信号是指用连续变化的物理量表示的信号。我们需要把模拟信号\\n\\n变成数字信号（Digital Signal）以后才能进行后续的分析和建模，数字信号指的是离散的\\n\\n数值信号。所以一般我们可以使用数字麦克风（可以直接输出数字信号的麦克风），或者模\\n\\n拟麦克风（输出模拟信号的麦克风）加上模数转换芯片（把模拟信号变成数字信号的芯片）\\n\\n得到数字信号。\\n\\n在采集声音数据的时候，可以通过设置采样频率（Sampling frequency）来控制信号\\n\\n采集的快慢，比如采样频率为 8kHz 时，表示每秒可以采集到 8000 个数据。一个数据就是\\n\\n一个数值，数值的大小表示信号的强弱。我们人耳的听力范围一般是 20Hz-20kHz，根据\\n\\nNyquist 采样定理，采样频率至少是信号中的最高频率的两倍，也就是说要采样 20Hz-\\n\\n20kHz 的信号，需要至少 40kHz 以上的采样频率。在 CD 中采用了 44.1kHz 的采样频率，\\n\\n所以 CD 可以保存高质量的音频信号。采样频率也不是越高越好，因为采样频率越高，采集\\n\\n到的数据就越多，音频文件也会变得越大。人耳对低频声音比较敏感，对高频声音不太敏\\n\\n感，并且人说话的声音频率也比较低，所以在普通的录音应用中 8kHz 或 16kHz 的采样频率\\n\\n会用的比较多。\\n\\n除了采样频率以外，量化位数（Quantization Bits）也会影响音频文件的大小，量化位\\n\\n数是对模拟信号进行数字化时的精度。比如 8 位就是用 8bit 来表示音频信号，16 位就是用\\n\\n16bit 来表示音频信号。位数越高，数字化后的音频信号就越可能接近原始信号，但所需的\\n\\n存储空间也越大。通常 8 位和 16 位用得比较多。\\n\\n637\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n17.2.2 分帧加窗\\n\\n我们在分析视频数据的时候会把连续的视频数据拆分为一帧一帧的图像数据来进行分析。处\\n\\n理语音数据的时候也是如此，我们会把一长串语音数据拆分为一帧一帧的数据进行处理。语\\n\\n音数据中的帧指的是一小段语音数据，一般情况下我们会把 20-40ms 的数据看成是一帧。\\n\\n选择 20-40ms 这个长度主要是我们假设在短时尺度上音频信号没有太大的变化，如果帧的\\n\\n长度更短的话，我们没有足够的样本来获取可靠的频谱估计，如果帧更长的话，信号在整个\\n\\n帧中变化太大。比较常用的帧长为 20-25ms，帧移为 10ms，如图 17.4 所示。\\n\\n图 17.4 分帧\\n\\n图中的 Amplitude 表示振幅；Time 表示时间；seconds 表示秒。\\n\\n分帧后一般还会有一个加窗的操作，如常用的窗口有 Rectangular Window，\\n\\nHamming Window 和 Hanning Window 等，如图 17.5 所示。\\n\\n638\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 17.5 各种窗口\\n\\nRectangular Window 其实就是保留分帧后的数据不做处理，Hamming Window 和\\n\\nHanning Window 效果差不多，就是增强每一帧数据中间部分的信号，减弱每一帧数据边缘\\n\\n的信号。一般来说 Hamming Window 和 Hanning Window 用得比较多。\\n\\n17.2.3 傅里叶变换\\n\\n分帧加窗做好以后，下一步就要对每帧数据进行傅里叶变换（Fourier Transform），\\n\\n如图 17.6 所示。\\n\\n639\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 17.6 对每帧数据进行傅里叶变换\\n\\n因为我们使用的数据都是离散的数值信号，对离散的数值信号进行的傅里叶变换也称为\\n\\n离散傅里叶变换（Discrete Fourier Transform，简称 DFT）。在计算机中一般会使用更\\n\\n高效，更快速的离散傅里叶变换，称为快速傅里叶变换（Fast Fourier Transform，简称\\n\\nFFT），FFT 是 DFT 的快速算法。\\n\\n我们这里的具体操作是将信号加上滑动时间窗，并对每个时间窗口内的数据进行 FFT，\\n\\n这种操作有一个专门的名词，称为短时傅里叶变换（short-term Fourier transform，简\\n\\n称 STFT）。\\n\\n下面我们就拿 FFT 来说明一下，傅里叶变换具体是一种什么变换。如果用一句话来说\\n\\n明，傅里叶变换就是将时域（Time Domain）信号转换为频域（Frequency Domain）信\\n\\n号。时域信号就是信号强弱与时间的关系，比如一段语音信号跟时间的关系，如图 17.7 所\\n\\n示。\\n\\n图 17.7 时域信号\\n\\n图中的 Amplitude 表示振幅；Time 表示时间；seconds 表示秒。\\n\\n640\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n任何一段复杂的声音信号我们都可以看成是很多个正余弦波叠加得到的，如图 17.8 所\\n\\n示。\\n\\n图 17.8 时域转频域\\n\\n我们用 FFT 算法把这图 17.8 段语音信号转换为频域信号以后，会得到图 17.9 所示。\\n\\n图 17.9 频域信号\\n\\n图中 Magnitude 表示重要性；Frequency 表示频率。\\n\\n频域信号就是信号强弱与频率的关系，横坐标为频率，纵坐标为重要性，信号频率与强\\n\\n弱的关系图也称为频谱图（Spectrum）。这是一段人说话的语音片段，转换为频域信号后\\n\\n641\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们可以看到在这段语音中低频的信号比较强，比如 250Hz 和 450Hz 左右的信号是最强\\n\\n的，高频的信号很弱。关于 FFT 的具体细节大家有兴趣的话可以再自行研究，这里我们就不\\n\\n展开介绍了。\\n\\n对一段语音数据进行 STFT 以后，得到的结果如图 17.10 所示。\\n\\n图 17.10 STFT\\n\\n图中 FFT 的结果可以看到不同的频率有不同的灰度值，这里的灰度值表示数值大小，颜\\n\\n色越深表示该频率的振幅越大。使用 STFT 计算后得到的二维信号我们称之为声谱图\\n\\n（Spectrogram）。\\n\\n17.2.4 梅尔滤波器组（Mel Filter Banks）\\n\\n梅尔滤波器组是模拟人耳听力特点设计出来的一组滤波器。前面我们有提到过人耳对低\\n\\n频信号比较敏感，对高频信号不太敏感。比如我们很容易区分 500Hz 和 1000Hz 这两个声\\n\\n音信号，但是比较难区分 18000Hz 和 18500Hz 这两个声音信号。梅尔滤波器可以模拟人类\\n\\n对声音频率非线性的感知能力，对信号进行进一步的特征提取。梅尔 m 与赫兹 f 的转换关系\\n\\n如下：\\n\\n642\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑚 = 2595𝑙𝑜𝑔\"<(1 +\\n\\n𝑓 700\\n\\n)\\n\\n𝑓 = 700(10\\n\\n(cid:130) #(cid:176)(cid:237)(cid:176) − 1)\\n\\n梅尔 Mels 与赫兹 Hz 的关系如图 17.11 所示。\\n\\n图 17.11 梅尔（Mels）与赫兹（Hz）的关系\\n\\n下面举例说明一下这些滤波器如何生成。梅尔滤波器组的个数是可以人为设置的，一般\\n\\n设置为 40。假设现在我们设置为 10 个滤波器，10 个滤波器需要 10+2=12 个频率点（这里\\n\\n的 2 表示最小频率点和最大频率点）。比如我们使用的采样频率是 8000Hz，根据 Nyquist\\n\\n采样定理，我们采集到的信号频率上限为 4000Hz，4000Hz 根据公式 17.1 计算约等于\\n\\n2146.06Mels。现在我们从 0-2146.06 均匀划分 12 个点，得到：\\n\\nm(i) = 0，195.10，390.19，585.29，780.39，975.48，1170.58，1365.68，\\n\\n1560.77，1755.87，1950.97，2146.06\\n\\n这 12 个 Mels 转换为 Hz 等于：\\n\\nh(i) = 0，132.30，289.60，476.64，699.02，963.44，1277.83，1651.64，\\n\\n2096.10，2624.56，3252.90，4000\\n\\n643\\n\\n(17.1)\\n\\n(17.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n根据这 12 个 Hz 频率点可以得到 10 个三角滤波器。三角滤波器的特点是三角形区域以\\n\\n外的信号都会被过滤掉，在三角形区域内中间的信号比较强，两边的信号会被减弱。第一个\\n\\n滤波器从第 1 个频率点开始，在第 2 个频率点达到最大值 1，然后在第 3 个频率点降为 0；\\n\\n第二个滤波器从第 2 个频率点开始，在第 3 个频率点达到最大值 1，然后在第 4 个频率点降\\n\\n为 0。以此类推得到 10 个三角滤波器，如图 17.12 所示。\\n\\n图 17.12 10 个梅尔滤波器组\\n\\n图中 Amplitude 表示重要性；Frequency 表示频率。\\n\\n接下来使用梅尔滤波器组对经过 STFT 计算后得到的声谱图 Spectrogram 进行滤波，得\\n\\n到梅尔频谱（Mel Spectrogram），如图 17.13 所示。\\n\\n644\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 17.13 梅尔频谱（Mel Spectrogram）\\n\\n图 17.13 为图 17.7 语音数据对应的梅尔频谱，梅尔滤波器组的个数为 40。到这里通过\\n\\n梅尔滤波器组（Mel Filter Banks）计算得到的梅尔频谱（Mel Spectrogram）就可以用来\\n\\n作为这一段语音的特征数据了。然后再使用 CNN 或者是 RNN 网络就可以对于这段语音的特\\n\\n征数据进行进一步的分析和预测。\\n\\n17.2.5 梅尔频率倒谱系数 MFCC\\n\\n在介绍 MFCC 具体怎么计算之前，我们先介绍一下相关背景。如图 17.14 所示为一段语\\n\\n音的频谱图。\\n\\n图 17.14 频谱图\\n\\n645\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n峰值就表示语音的主要频率成分，我们把这些峰值称为共振峰（Formants）。共振峰携\\n\\n带了声音的辨识属性，用它就可以识别不同的声音。 我们可以把共振峰提取出来，不仅要提\\n\\n取共振峰的位置，还要提取它们的变化过程，得到包络（Spectral Envelope）。包络就是\\n\\n一条将所有共振峰连接起来的平滑曲线，如图 17.15 所示。\\n\\n图 17.15 包络\\n\\n我们可以认为频谱信号是由包络和包络细节（Spectral Details）组成，如图 17.16 所\\n\\n示。\\n\\n图 17.16 频谱信号的组成\\n\\n我们可以认为包络是比较重要的特征，包络细节是不太重要的特征，甚至可能是噪声。\\n\\n现在我们要转换一下思维，如果我们把图中的横坐标 Frequency 看成是时间，把包络和包络\\n\\n646\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n细节看成是波形。那包络的波形属于低频信号，包络细节的波形属于高频信号。那也就是说\\n\\n频谱图中的低频信号是重要特征，高频信号不太重要。\\n\\n所以我们可以对频谱图再做一次 FFT，得到频谱图的倒谱（Cepstrum）。倒谱这个词的\\n\\n英文 Cepstrum 实际上就是频谱图的英文 Spectrum 前四个字母顺序颠倒过来得到的。在倒\\n\\n谱中的频率称为伪频率（Pseudo-Frequency），因为它不是真正的音频信号的频率，它表\\n\\n示的是频谱图中波形的频率。\\n\\n根据我们前面所说，倒谱中的伪频率低频信号是重要特征，所以我们可以只取倒谱中低\\n\\n频信号的特征值，舍弃倒谱中高频信号的特征。具体取多少个倒谱中的低频信号，可以人为\\n\\n设置，对于 ASR 任务一般取前 12-20 个。\\n\\nMFCC 信号的具体计算是对梅尔频谱再做一次离散余弦变换（Discrete Fourier\\n\\nTransform，简称 DCT），DCT 类似于 DFT，DCT 只使用实数。然后取倒谱中前 n 个低频\\n\\n信号，n 可以人为设置。MFCC 可以看成是对梅尔频谱的进一步特征提取，可以得到更适合\\n\\nASR 任务的特征。语音信号是时域连续的，分帧提取的信息只反应了本帧语音的特性，我们\\n\\n还可以计算 MFCC 的差分信号，常用的是一阶差分和二阶差分，差分的简单计算公式如下：\\n\\n𝑑(𝑡) =\\n\\n𝑐ˆ(cid:151)\" − 𝑐ˆ(cid:127)\" 2\\n\\n(17.3)\\n\\n其中 c 为 MFCC 中的倒谱特征，t 为时间，也可以理解为第 t 帧，d 为差分特征。使用原\\n\\n始 MFCC 的值可以计算出一阶差分∆𝑀𝐹𝐶𝐶，然后使用∆𝑀𝐹𝐶𝐶又可以计算出二阶差分\\n\\n∆#𝑀𝐹𝐶𝐶。实际计算时差分计算公式不一定用的是这一个，也可以使用其他的差分计算公\\n\\n式。图 17.7 语音数据的 MFCC，∆𝑀𝐹𝐶𝐶，∆#𝑀𝐹𝐶𝐶结果如图 17.17 所示。\\n\\n647\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 17.17 MFCC 及其一阶差分和二阶差分\\n\\n差分信号可以计算也可以不计算，计算差分信号相当于可以得到多一些特征。得到\\n\\nMFCC 后再使用 CNN 或者是 RNN 网络就可以对于这段语音的特征数据进行进一步的分析\\n\\n和预测。\\n\\n17.3 语音分类项目\\n\\n17.3.1 音频处理库 librosa 介绍\\n\\n语音信号有很多复杂的处理流程，因此使用一个封装好的 python 模块会让事情变得简\\n\\n单很多，下面我们要使用一个专门做音频数据处理的模块 librosa。首先，先进行 librosa 的\\n\\n安装，同样也是打开命令提示符，输入命令：\\n\\n648\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\npip install librosa\\n\\n安装好以后就可以使用 librosa 进行一些音频数据的处理了，我们需要准备一些音频文\\n\\n件，如果你暂时找不到音频文件，那么在下面这个地址可以下载到一些音频文件的 demo：\\n\\nhttp://www.voiptroubleshooter.com/open_speech/american.html。\\n\\nlibrosa 基本操作的代码如代码 17-1 所示。\\n\\n代码 17-1：librosa 基本操作（片段 1）\\n\\nimport matplotlib.pyplot as plt import librosa import librosa.display import sklearn import IPython.display as ipd # 播放音频文件 ipd.Audio(\\'OSR_us_000_0010_8k.wav\\') # 读取一段音频文件 # sr=None 表示不设置采样率，默认会使用音频文件自身的采样率 # duration=3.5 表示读取该文件前 3.5 秒的数据 # 读取文件后返回文件数据 signal 和采样率 sample_rate signal,sample_rate = librosa.load(\\'OSR_us_000_0010_8k.wav\\', sr=None, duration=3.5) print(\\'sample_rate:\\',sample_rate) print(\\'signal:\\',len(signal)) 结果输出为： sample_rate: 8000 signal: 28000\\n\\n代码 17-1：librosa 基本操作（片段 2）\\n\\n# 画出音频数据的波形图 librosa.display.waveplot(signal, sample_rate) plt.show() 结果输出为：\\n\\n649\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 17-1：librosa 基本操作（片段 3）\\n\\n# 提取梅尔频谱特征 # n_fft 为 FFT 窗口长度，hop_length 为帧移，n_mels 为滤波器个数 melspec = librosa.feature.melspectrogram(signal, sample_rate, n_fft=1024, hop_length=51 2, n_mels=40) # 取对数 logmelspec = librosa.power_to_db(melspec) # 画出梅尔频谱特征 Mel Spectrogram # fmax 为最大频率 librosa.display.specshow(logmelspec, sr=sample_rate, fmax=4000, x_axis=\\'time\\', y_axis=\\'h z\\') # 设置 title plt.title(\\'Mel Spectrogram\\') # 显示颜色数值 plt.colorbar() plt.show() 结果输出为：\\n\\n代码 17-1：librosa 基本操作（片段 4）\\n\\n# 计算 mfcc,n_mfcc 为每帧数据 mfcc 特征数量 mfcc = librosa.feature.mfcc(signal,sample_rate,n_mfcc=20) # 数据标准化\\n\\n650\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com mfcc = sklearn.preprocessing.scale(mfcc, axis=1) # 画出 mfcc 频谱图 librosa.display.specshow(mfcc,sr=sample_rate) plt.title(\\'MFCC\\') plt.colorbar() plt.show() 结果输出为：\\n\\n17.3.2 音频分类项目-模型训练\\n\\n这里我们使用的分类数据集为 UrbanSound，数据集地址为\\n\\nhttps://urbansounddataset.weebly.com/。如果大家有其他数据集的话也可以使用其他数\\n\\n据集。UrbanSound 数据集有 10 个种类的声音，分别是 0 冷气机，1 汽车喇叭，2 孩子声\\n\\n音，3 狗叫声，4 电钻声，5 发动机声音，6 枪声，7 手提钻，8 警报声，9 街头音乐声。原\\n\\n始数据一共有 10 个文件夹，每个文件夹里有 800 多个音频文件，每个文件为某种声音类型\\n\\n的音频数据，时长为几秒。由于数据比较大，所以只使用了其中 3 个文件夹，大约 2500 个\\n\\n音频文件。音频文件名中包含标签信息，标签为文件名中的第二个数字，如“7061-6-0-\\n\\n0.wav”标签为 6 枪声，“9031-3-2-0.wav”标签为 3 狗叫声，具体实现代码如代码 17-2\\n\\n所示。\\n\\n代码 17-2：音频分类项目-模型训练（片段 1）\\n\\nimport warnings warnings.filterwarnings(\"ignore\") import glob\\n\\n651\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import os # 需要安装 tqdm，用于查看进度条 # pip install tqdm from tqdm import tqdm # pip install librosa import librosa import numpy as np import sklearn from sklearn.model_selection import train_test_split # pip install plot_model from plot_model import plot_model # 音频文件存放位置 # 在\\'audio/\\'文件夹下还有 fold1，fold2，fold3 这 3 个文件夹 audio_dir = \\'audio/\\' # 批次大小 batch_size = 64 # 训练周期 epochs = 500 # 获取所有 wav 文件 def get_wav_files(audio_dir): # 用于保存音频文件路径 audio_files = [] # 循环文件夹 for sub_file in os.listdir(audio_dir): # 得到文件完整路径 file = os.path.join(audio_dir,sub_file) # 如果是文件夹 if os.path.isdir(file): # 得到 file 文件夹下所有\\'*.wav\\'文件 audio_files += glob.glob(os.path.join(file, \\'*.wav\\')) return audio_files\\n\\n# 获取文件 mfcc 特征和对应标签 def extract_features(audio_files): # 用于保存 mfcc 特征 audio_features = [] # 用于保存标签 audio_labels = [] # 由于特征提取需要时间比较长，可以加上 tqdm 实时查看进度 for audio in tqdm(audio_files): # 读入音频文件 # 由于音频文件原始采样率高低不一，这里我们把采样率固定为 22050 signal,sample_rate = librosa.load(audio,sr=22050)\\n\\n652\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 由于音频长度长短不一，基本上都在 4 秒左右，所以我们把所有音频数据的长度都固 定为 4 秒 # 采样率 22050，时长为 4 秒，所以信号数量为 22050*4=88200 # 小于 88200 填充 if len(signal)<88200: # 给 signal 信号前面填充 0 个数据，后面填充 88200-len(signal)个数据，填充值为 0 signal = np.pad(signal,(0,88200-len(signal)),\\'constant\\',constant_values=(0)) # 大于 88200，只取前面 88200 个数据 else: signal = signal[:88200] # 获取音频 mfcc 特征，然后对数据进行转置 # 原始 mfcc 数据 shape 为(mfcc 特征数，帧数)->(帧数，mfcc 特征数) # 相当于把序列长度的维度放前面，特征数的维度放后面 mfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0]) # 数据标准化 mfcc = sklearn.preprocessing.scale(mfcc, axis=0) # 保存 mfcc 特征 audio_features.append(mfcc.tolist()) # 获取 label # 获取文件名第 2 个数字，第 2 个数字为标签 label = audio.split(\\'/\\')[-1].split(\\'-\\')[1] # 保存标签 audio_labels.append(int(label)) return np.array(audio_features), np.array(audio_labels)\\n\\n# 获取所有 wav 文件 audio_files = get_wav_files(audio_dir) print(\\'文件数量：\\',len(audio_files)) 结果输出为： 文件数量： 2685\\n\\n代码 17-2：音频分类项目-模型训练（片段 2）\\n\\n# 获取文件 mfcc 特征和对应标签 audio_features,audio_labels = extract_features(audio_files) # 切分训练集和测试集 x_train,x_test,y_train,y_test = train_test_split(audio_features,audio_labels)\\n\\nfrom tensorflow.keras.models import Sequential,Model from tensorflow.keras.layers import Conv1D,GlobalMaxPool1D,AlphaDropout,Dense,Input,c oncatenate from tensorflow.keras.optimizers import Adam\\n\\n653\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.activations import selu from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from tensorflow.keras.regularizers import l2 # 定义模型输入 inputs = Input(shape=(x_train.shape[1:])) # 定义 1 维卷积，权值初始化使用 lecun_normal，主要是为了跟 selu 搭配 x0 = Conv1D(filters=256, kernel_size=3, activation=\\'selu\\', kernel_initializer=\\'lecun_normal\\', kernel_regularizer=l2(0.0001))(inputs) x0 =GlobalMaxPool1D()(x0) # 定义 1 维卷积 x1 = Conv1D(filters=256, kernel_size=4, activation=\\'selu\\', kernel_initializer=\\'lecun_normal\\', kernel_regularizer=l2(0.0001))(inputs) x1 =GlobalMaxPool1D()(x1) # 定义 1 维卷积 x2 = Conv1D(filters=256, kernel_size=5, activation=\\'selu\\', kernel_initializer=\\'lecun_normal\\', kernel_regularizer=l2(0.0001))(inputs) x2 =GlobalMaxPool1D()(x2) # 合并特征 x = concatenate([x0,x1,x2],axis=-1) # 可以用 AlphaDropout 保持信号均值和方差不变，AlphaDropout 一般跟 selu 搭配 x = AlphaDropout(0.5)(x) # 10 分类 preds = Dense(10, activation=\\'softmax\\', kernel_initializer=\\'lecun_normal\\')(x) # 定义模型 model = Model(inputs, preds) # 画结构图 plot_model(model, dpi=200) 结果输出为：\\n\\n654\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 17-2：音频分类项目-模型训练（片段 3）\\n\\n# 定义优化器 # 因为标签没有转独热编码，所以 loss 用 sparse_categorical_crossentropy model.compile(optimizer=Adam(0.01), loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# 监控指标统一使用 val_accuracy # 可以使用 EarlyStopping 来让模型停止，连续 40 个周期 val_accuracy 没有下降就结束训练 # ModelCheckpoint 保存所有训练周期中 val_accuracy 最高的模型 # ReduceLROnPlateau 学习率调整策略，连续 20 个周期 val_accuracy 没有提升，当前学习 率乘以 0.1 callbacks = [EarlyStopping(monitor=\\'val_accuracy\\', patience=40, verbose=1), ModelCheckpoint(\\'audio_model/\\'+\\'cnn_{val_accuracy:.4f}.h5\\', monitor=\\'val_accurac y\\', save_best_only=True), ReduceLROnPlateau(monitor=\\'val_accuracy\\', factor=0.1, patience=20, verbose=1)]\\n\\n# 模型训练 history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data =(x_test, y_test), callbacks=callbacks)\\n\\n655\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n模型训练最后得到测试集准确率大概为 90%左右。\\n\\n17.3.3 音频分类项目-模型预测\\n\\n下面我们再看一下模型预测程序，单独准备一些音频测试文件，存放在”audio_test”\\n\\n文件夹下面，具体实现如代码 17-3 所示。\\n\\n代码 17-3：音频分类项目-模型预测（片段 1）\\n\\nimport warnings warnings.filterwarnings(\"ignore\") import librosa from tensorflow.keras.models import load_model import glob import os from tqdm import tqdm import numpy as np import sklearn # 测试文件存放路径 audio_dir = \\'audio_test/\\' # 载入模型 model = load_model(\\'audio_model/cnn_0.8943.h5\\') # 获取文件 mfcc 特征和对应标签 def extract_features(audio_files): # 用于保存 mfcc 特征 audio_features = [] # 用于保存标签 audio_labels = [] # 由于特征提取需要时间比较长，可以加上 tqdm 实时查看进度 for audio in tqdm(audio_files): # 读入音频文件 # 由于音频文件原始采样率高低不一，这里我们把采样率固定为 22050 signal,sample_rate = librosa.load(audio,sr=22050) # 由于音频长度长短不一，基本上都在 4 秒左右，所以我们把所有音频数据的长度都固 定为 4 秒 # 采样率 22050，时长为 4 秒，所以信号数量为 22050*4=88200 # 小于 88200 填充 if len(signal)<88200: # 给 signal 信号前面填充 0 个数据，后面填充 88200-len(signal)个数据，填充值为 0 signal = np.pad(signal,(0,88200-len(signal)),\\'constant\\',constant_values=(0)) # 大于 88200，只取前面 88200 个数据\\n\\n656\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com else: signal = signal[:88200] # 获取音频 mfcc 特征，然后对数据进行转置 # 原始 mfcc 数据 shape 为(mfcc 特征数，帧数)->(帧数，mfcc 特征数) # 相当于把序列长度的维度放前面，特征数的维度放后面 mfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0]) # 数据标准化 mfcc = sklearn.preprocessing.scale(mfcc, axis=0) # 保存 mfcc 特征 audio_features.append(mfcc.tolist()) # 获取 label # 获取文件名第 2 个数字，第 2 个数字为标签 label = audio.split(\\'/\\')[-1].split(\\'-\\')[1] # 保存标签 audio_labels.append(int(label)) return np.array(audio_features), np.array(audio_labels)\\n\\n# 获取所有 wav 文件 audio_files = glob.glob(os.path.join(audio_dir, \\'*.wav\\')) print(\\'文件数量：\\',len(audio_files)) 结果输出为： 文件数量： 10\\n\\n代码 17-3：音频分类项目-模型预测（片段 2）\\n\\n# 获取文件 mfcc 特征和对应标签 audio_features,audio_labels = extract_features(audio_files) # 把测试数据当作一个批次进行预测 preds = model.predict_on_batch(audio_features) # 计算概率最大的类别 preds = np.argmax(preds, axis=1) print(\\'真实标签为：\\',audio_labels) print(\\'预测结果为：\\',preds) 结果输出为： 真实标签为： [3 0 5 1 8 7 9 5 2 1] 预测结果为： [3 0 5 1 8 7 9 5 2 1]\\n\\n657\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 18 章 图像风格转换\\n\\n图像风格转换对应的英文为 Image Style Transfer，意思将两个图像，一张内容图像\\n\\nA，一张风格图像 B 混合在一起，使得输出的图像内容像 A，风格像 B，如图 18.1 所示。\\n\\n图 18.1 图像风格转换[1]\\n\\n18.1 图像风格转换实现原理\\n\\n下面主要以《A Neural Algorithm of Artistic Style》[1]这篇论文的思路给大家介绍一下\\n\\n图像风格转换如何实现。我们在之前学习卷积网络的时候有介绍过，卷积的功能主要是特征\\n\\n提取，那么经过大量训练的卷积网络就可以具备良好的特征提取能力。并且，不同的卷积层\\n\\n658\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n可以提取不同的特征。一般来说，浅层的卷积主要是提取图像边缘轮廓的特征，而深层的卷\\n\\n积则是提取图像更抽象的特征。因此我们可以选用一个经过预训练的图像识别卷积网络来作\\n\\n为特征提取器，比如可以选择 VGG16。\\n\\n图像风格转换的模型训练其实跟其他的深度学习模型训练类似，模型中有一些需要训练\\n\\n的权值，在图像风格变换中模型需要训练的权值是生成图片的像素值。我们一般使用内容图\\n\\n片来初始化生成图片的像素值，之后生成图片的像素值会随着模型的训练不断变化。我们还\\n\\n需要定义一个代价函数，然后使用优化器最小化代价函数的值。所以这里的重点在于这个代\\n\\n价函数如何定义。\\n\\n18.1.1 代价函数的定义\\n\\n我们把代价函数分为内容 content loss 和风格 style loss。Content loss 表示生成出来\\n\\n的新图片与作为内容的图片 A 之间的 loss；style loss 表示生成出来的新图片与作为风格的\\n\\n图片 B 之间的 loss，总的代价函数公式为：\\n\\n𝐿ˆ(cid:210)ˆ(cid:240)(cid:132) = 𝛼𝐿(cid:211)(cid:210)@ˆ⁄@ˆ + 𝛽𝐿(cid:222)ˆ—(cid:132)⁄\\n\\n其中𝐿(cid:211)(cid:210)@ˆ⁄@ˆ表示 content loss，𝐿(cid:222)ˆ—(cid:132)⁄表示 style loss，𝛼表示 content loss 的权重，𝛽表\\n\\n示 style loss 的权重，权重的值可以人为设定。𝐿(cid:211)(cid:210)@ˆ⁄@ˆ和𝐿(cid:222)ˆ—(cid:132)⁄的计算如图 18.2 所示。\\n\\n659\\n\\n(18.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 18.2 loss 计算\\n\\n图中的卷积网络为一个经过预训练的 VGG16 模型，在计算𝐿(cid:222)ˆ—(cid:132)⁄时使用的卷积层为\\n\\nConv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1，𝐿(cid:222)ˆ—(cid:132)⁄的计算公式为：\\n\\n𝐸= = ?(𝐺= − 𝑆=)#\\n\\n𝐿(cid:222)ˆ—(cid:132)⁄ = ? 𝑤(cid:132)𝐸(cid:132)\\n\\n其中 L 表示不同的卷积层，G 为生成图片的特征图计算得到的格拉姆矩阵（Gram\\n\\nMatrix），S 为风格图片的特征图计算得到的格拉姆矩阵。这里计算格拉姆的原因是我们可\\n\\n以使用格拉姆矩阵来表示一副图片的风格，关于格拉姆矩阵的具体计算后面再介绍。总之，\\n\\n我们可以计算出风格图片和生成图片 Conv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1\\n\\n这 5 个卷积层输出的特征图所计算得到的 Gram 矩阵𝑆=和𝐺=，根据𝑆=和𝐺=来计算𝐸=。把所有\\n\\n660\\n\\n(18.2)\\n\\n(18.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸(cid:132)乘以对应权重𝑤(cid:132)，再累加起来得到𝐿(cid:222)ˆ—(cid:132)⁄。权重𝑤(cid:132)可以人为设置，一般设置为 1/5，即所有\\n\\n卷积层的特征权重相等。\\n\\n在计算𝐿(cid:211)(cid:210)@ˆ⁄@ˆ时使用的是 Conv5_2 输出的特征图，也可以取多个卷积层输出，不过效果\\n\\n变化不大，𝐿(cid:211)(cid:210)@ˆ⁄@ˆ的计算公式为：\\n\\n𝐿(cid:211)(cid:210)@ˆ⁄@ˆ = ?(𝐺(cid:132) − 𝐶(cid:132))#\\n\\n其中𝐺(cid:132)为生成图片 Conv5_2 输出的特征图，𝐶(cid:132)为内容图片 Conv5_2 输出的特征图。注\\n\\n意在计算𝐿(cid:211)(cid:210)@ˆ⁄@ˆ的时候这里是直接对比特征图𝐺(cid:132)和特征图𝐶(cid:132)，并没有计算 Gram 矩阵。因为\\n\\n计算 Gram 矩阵可以得到特征图和特征图之间的相关性，对于表示图片的风格是有意义的，\\n\\n跟图片的内容关系不大。\\n\\n当我们使用优化器最小化代价函数的时候，相当于是在对比风格图片和生成图片的图像\\n\\n风格，然后使得图片风格的差异越小越好；然后再对比生成图片和内容图片的内容特征，然\\n\\n后使得图片内容特征的差异越小越好。生成图片的像素值经过不断的变化，就可以得到风格\\n\\n转换后的结果。\\n\\n18.1.2 格拉姆矩阵（Gram Matrix）介绍\\n\\n上一小节我们有提到，在计算图像风格的时候用到了格拉姆矩阵（Gram Matrix），那\\n\\n么这一小节我们主要来介绍一下格拉姆矩阵是如何计算的。\\n\\n我们使用图像经过卷积计算后得到的特征图来计算 Gram 矩阵，然后用 Gram 矩阵表示图像\\n\\n风格。在计算 Gram 矩阵前，我们先把 2 维的特征图变成 1 维的特征向量，如图 18.3 所\\n\\n示。\\n\\n661\\n\\n(18.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 18.3 把 2 维特征图变成 1 维特征向量\\n\\n假设我们现在一共有 5 张特征图，如图所示。特征图的宽为𝑛>，高为𝑛?，所以展开成 1\\n\\n维后，得到的特征图矩阵的列数为𝑛? × 𝑛>，行数为特征图数量 5。\\n\\n接下来的计算如图 18.4 所示。\\n\\n图 18.4 Gram 矩阵计算\\n\\n把前面得到的特征图矩阵乘以该特征图矩阵的转置，得到的结果就是 Gram 矩阵。在上\\n\\n面这个例子中，因为一共有 5 张特征图，所以最后得到的 Gram 矩阵为 5×5 的矩阵。Gram\\n\\n矩阵可以把图像特征之间的联系提取出来，也就是可以得到特征之间的相关性。所以在图像\\n\\n风格转换中，可以使用 Gram 矩阵来表示图像的特征。\\n\\n662\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n18.2 图像风格转换项目实战\\n\\n在运行程序之前，大家可以自己收集一些风格图片和内容图片，然后尝试使用不同的照\\n\\n片看看可以得到什么结果。也可以尝试设置不同的 loss 权重，看看图片的变化情况。实现图\\n\\n像风格装换的代码如代码 18-1 所示。\\n\\n代码 18-1：图像风格转换（片段 1）\\n\\nimport matplotlib.pyplot as plt import tensorflow as tf import numpy as np from PIL import Image # 设置最长的一条边的长度 max_dim = 800 # 内容图片路径 content_path = \\'臭臭.jpeg\\' # 风格图片路径 style_path = \\'starry_night.jpg\\' # 风格权重 style_weight=10 # 内容权重 content_weight=1 # 全变差正则权重 total_variation_weight=1e5 # 训练次数 stpes = 301 # 是否保存训练过程中产生的图片 save_img = True\\n\\n# 载入图片 def load_img(path_to_img): # 读取文件内容 img = tf.io.read_file(path_to_img) # 变成 3 通道图片数据 img = tf.image.decode_image(img, channels=3, dtype=tf.float32) # img = tf.image.convert_image_dtype(img, tf.float32) # 获得图片高度和宽度，并转成 float 类型 shape = tf.cast(tf.shape(img)[:-1], tf.float32)\\n\\n663\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 最长的边的长度 long_dim = max(shape) # 图像缩放，把图片最长的边变成 max_dim scale = max_dim / long_dim new_shape = tf.cast(shape * scale, tf.int32) # resize 图片大小 img = tf.image.resize(img, new_shape) # 增加 1 个维度，变成 4 维数据 img = img[tf.newaxis, :] return img\\n\\n# 用于显示图片 def imshow(image, title=None): # 如图是 4 维度数据 if len(image.shape) > 3: # 去掉 size 为 1 的维度如(1,300,300,3)->(300,300,3) image = tf.squeeze(image) # 显示图片 plt.imshow(image) if title: # 设置图片 title plt.title(title) plt.axis(\\'off\\') plt.show()\\n\\n# 载入内容图片 content_image = load_img(content_path) # 载入风格图片 style_image = load_img(style_path) # 显示内容图片 imshow(content_image, \\'Content Image\\') # 显示风格图片 imshow(style_image, \\'Style Image\\') 结果输出为：\\n\\n664\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 18-1：图像风格转换（片段 2）\\n\\n# 用于计算 content loss # 这里只取了一层的输出进行对比，取多层输出效果变化不大 content_layers = [\\'block5_conv2\\']\\n\\n# 用于计算风格的卷积层 style_layers = [\\'block1_conv1\\', \\'block2_conv1\\', \\'block3_conv1\\', \\'block4_conv1\\', \\'block5_conv1\\']\\n\\n# 计算层数 num_content_layers = len(content_layers) num_style_layers = len(style_layers) # 创建一个新模型，输入与 vgg16 一样，输出为指定层的输出 def vgg_layers(layer_names): # 载入 VGG16 的卷积层部分 vgg = tf.keras.applications.VGG16(include_top=False, weights=\\'imagenet\\') # VGG16 的模型参数不参与训练 vgg.trainable = False # 获取指定层的输出值 outputs = [vgg.get_layer(name).output for name in layer_names] # 定义一个新的模型，输入与 vgg16 一样，输出为指定层的输出 model = tf.keras.Model([vgg.input], outputs) # 返回模型 return model # 获得输出风格层特征的模型 style_extractor = vgg_layers(style_layers) # 图像预处理，主要是减去颜色均值，RGB 转 BGR preprocessed_input = tf.keras.applications.vgg16.preprocess_input(style_image*255) # 风格图片传入 style_extractor，提取风格层的输出 style_outputs = style_extractor(preprocessed_input)\\n\\n665\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# Gram 矩阵的计算 def gram_matrix(input_tensor): # 爱因斯坦求和，bijc 表示 input_tensor 中的 4 个维度，bijd 表示 input_tensor 中的 4 个维 度 # 例如 input_tensor 的 shape 为(1,300,200,32)，那么 b=1,i=300,j=200,c=32,d=32 # ->bcd 表示计算后得到的数据维度为(1,32,32),得到的结果表示特征图与特征图之间的相 关性 result = tf.linalg.einsum(\\'bijc,bijd->bcd\\', input_tensor, input_tensor) # 特征图的 shape input_shape = tf.shape(input_tensor) # 特征图的高度乘以宽度得到特征值数量 num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32) # 除以特征值的数量 return result/(num_locations)\\n\\n# 构建一个返回风格特征和内容特征的模型 class StyleContentModel(tf.keras.models.Model): def __init__(self, style_layers, content_layers): super(StyleContentModel, self).__init__() # 获得输出风格层和内容层特征的模型 self.vgg = vgg_layers(style_layers + content_layers) # 用于计算风格的卷积层 self.style_layers = style_layers # 用于计算 content loss 的卷积层 self.content_layers = content_layers # 风格层的数量 self.num_style_layers = len(style_layers)\\n\\ndef call(self, inputs): # 图像预处理，主要是减去颜色均值，RGB 转 BGR preprocessed_input = tf.keras.applications.vgg16.preprocess_input(inputs*255.0) # 图片传入模型，提取风格层和内容层的输出 outputs = self.vgg(preprocessed_input) # 获得风格特征输出和内容特征输出 style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:]) # 计算风格特征的 Gram 矩阵 style_outputs = [gram_matrix(style_output) for style_output in style_outputs] # 把风格特征的 Gram 矩阵分别存入字典 style_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outp uts)} # 把内容特征存入字典\\n\\n666\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com content_dict = {content_name:value for content_name, value in zip(self.content_layers , content_outputs)} # 返回结果 return {\\'content\\':content_dict, \\'style\\':style_dict}\\n\\n# 构建一个返回风格特征和内容特征的模型 extractor = StyleContentModel(style_layers, content_layers) # 计算得到风格图片的风格特征 style_targets = extractor(style_image)[\\'style\\'] # 计算得到内容图片的内容特征 content_targets = extractor(content_image)[\\'content\\'] # 初始化要训练的图片 image = tf.Variable(content_image) # 定义优化器 opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1) # 把数值范围限制在 0-1 之间 def clip_0_1(image): return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\\n\\n# 定义风格和内容 loss def style_content_loss(outputs): # 模型输出的风格特征 style_outputs = outputs[\\'style\\'] # 模型输出的内容特征 content_outputs = outputs[\\'content\\'] # 计算风格 loss style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) for name in style_outputs.keys()]) style_loss *= style_weight / num_style_layers # 计算内容 loss content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]- content_targets[name])**2) for name in content_outputs.keys()]) content_loss *= content_weight / num_content_layers # 风格加内容 loss loss = style_loss + content_loss return loss\\n\\n# 施加全变差正则，全变差正则化常用于图片去噪，可以使生成的图片更加平滑自然 def total_variation_loss(image): x_deltas = image[:,:,1:,:] - image[:,:,:-1,:] y_deltas = image[:,1:,:,:] - image[:,:-1,:,:]\\n\\n667\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com return tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)\\n\\n# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 @tf.function() # 定义一个训练模型的函数 def train_step(image): # 固定写法，使用 tf.GradientTape()来计算梯度 with tf.GradientTape() as tape: # 传入图片获得风格特征和内容特征 outputs = extractor(image) # 计算风格和内容 loss loss = style_content_loss(outputs) # 再加上全变差正则 loss loss += total_variation_weight*total_variation_loss(image) # 传入 loss 和模型参数，计算权值调整 grad = tape.gradient(loss, image) # 进行权值调整，这里要调整的权值就是 image 图像的像素值 opt.apply_gradients([(grad, image)]) # 把数值范围限制在 0-1 之间\\n\\nimage.assign(clip_0_1(image))\\n\\n# 训练 steps 次 for n in range(stpes): # 训练模型 train_step(image) # 每训练 5 次打印一次图片 if n%5==0: imshow(image.read_value(), \"Train step: {}\".format(n)) # 保存图片 if save_img==True: # 去掉一个维度 s_image = tf.squeeze(image) # 把 array 变成 Image 对象 s_image = Image.fromarray(np.uint8(s_image.numpy()*255)) # 设置保存路径保存图片 s_image.save(\\'temp/\\'+\\'steps_\\'+str(n)+\\'.jpg\\') 结果输出为：\\n\\n668\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n……\\n\\n……\\n\\n18.3 遮挡图像风格转换项目实战\\n\\n我们可以自己制作图片中某些物体的遮挡（Mask），这样可以在做风格转换的时候图片\\n\\n中的某些部分进行了风格转换，某些部分还是保持原有的样子。如图 18.5 和图 18.6 所示。\\n\\n669\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 18.5 遮挡图像风格转换（1）\\n\\n图 18.6 遮挡图像风格转换（2）\\n\\n图中的左上角的图片内容图片，右上角为风格图片，左下角为遮挡图片，遮挡图片从内\\n\\n容图片中获得，需要自己手动制作。遮挡图片中的白色部分会进行图像风格转换，黑色部分\\n\\n保持不变。右下角为风格转换后的效果。\\n\\n遮挡图像风格转换其实就是多了一个 Mask，其他部分跟之前的图像风格转换是一样的，\\n\\n所以下面只给出遮挡部分的代码，这部分代码放在图像风格转换的代码后面即可，如代码\\n\\n18-2 所示。。\\n\\n代码 18-2：遮挡图像风格转换\\n\\n670\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com …… # mask 图片路径 mask_path = \\'mask.jpg\\' # 载入 mask 图片 def load_mask(mask_path, shape): # 读取文件 mask = tf.io.read_file(mask_path) # 变成图片格式 mask = tf.image.decode_image(mask, channels=1) mask = tf.image.convert_image_dtype(mask, tf.float32) # 获得生成图片的宽度和高度 _, width, height, _ = shape # 把 mask 图片 shape 变得跟生成图片一样 mask = tf.image.resize(mask, (width, height)) return mask\\n\\n# 把 mask 应用到生成的图片中 def mask_content(content, generated, mask): # 生成图片的 shape width, height, channels = generated.shape # 把内容图片变成 numpy 格式 content = content.numpy() # 把生成图片变成 numpy 格式 generated = generated.numpy() # mask 图片黑色部分，把内容图片的像素值填充到生成图片中 for i in range(width): for j in range(height): if mask[i, j] == 0.: generated[i, j, :] = content[i, j, :] return generated # 载入 mask 图片 mask = load_mask(mask_path, image.shape) # 3 维降 2 维 s_mask = tf.squeeze(mask) # 4 维降 3 维 s_image = tf.squeeze(image) # 4 维降 3 维 s_content_image = tf.squeeze(content_image) # 把 mask 应用到生成的图片中 img = mask_content(s_content_image,s_image,s_mask) # 显示图片 imshow(img)\\n\\n671\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n18.4 参考文献\\n\\n[1] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv\\n\\npreprint arXiv:1508.06576, 2015.\\n\\n672\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 19 章 生成对抗网络 GANs\\n\\n生成对抗网络（Generative Adversarial Networks，简称 GANs）是近几年深度学习领\\n\\n域一个非常热门的新的研究方向。最早是由“深度学习三巨头”之一 Yoshua Bengio 的学\\n\\n生 Ian Goodfellow 提出，相关论文为《Generative Adversarial Nets》[1]。经过几年时间\\n\\n的发展，生成对抗网络已经从深度学习的一个新方向发展成为一个庞大的分支，是目前深度\\n\\n学习领域最有发展潜力的算法之一。本书的内容主要还是以入门为主，所以本章节主要还是\\n\\n介绍关于生成对抗网络的基础知识和基本应用。\\n\\n19.1 生成对抗网络的应用\\n\\nGANs 的应用非常多，下面列举了部分 GANs 的常见应用。\\n\\n1.图像生成\\n\\n你能猜出图 19.1 中这些人脸的共同点吗？\\n\\n图 19.1 人脸图片[2]\\n\\n673\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这些图片中的人都不是真人，他们都是由 GANs 产生的假图片。GANs 最擅长做的事就\\n\\n是生成假图片，不只可以生成假的人脸，理论上什么类型的图片它都可以生成。\\n\\n2.向量空间运算\\n\\n如图 19.2 所示，我们可以看到戴眼镜的男人减去男人加上女人可以得到戴眼镜的女人。\\n\\n图 19.2 向量空间运算[3]\\n\\n3.图像转换\\n\\n如图 19.4 所示，通过简笔画可以转换为真实的物体图像。\\n\\n图 19.3 图像转换[4]\\n\\n4.图像风格转换\\n\\n如图 19.4，最左边的一张图片可以转换为右边的 4 种不同的图像风格。\\n\\n674\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 19.4 图像风格转换[5]\\n\\n5.文字转图像\\n\\n如图 19.5，给模型传入一段文字，输出的结果为一张图片。\\n\\n图 19.5 文字转图像[6]\\n\\n6.图像渐变\\n\\n如图 19.6，一张图片逐渐变化成另一张图片。\\n\\n675\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n19.6 图像渐变[7]\\n\\n7.超分辨率\\n\\n如图 19.7 所示，提升图像的分辨率。\\n\\n图 19.7 超分辨率[8]\\n\\n19.2 DCGAN 介绍\\n\\n19.2.1 DCGAN 原理\\n\\n下面我们主要以 DCGAN 为例，给大家介绍 DCGAN 的模型设计思路和程序实现，最早\\n\\n提出 DCGAN 的论文是《Unsupervised Representation Learning with Deep\\n\\nConvolutional Generative Adversarial Networks》[3]。\\n\\n生成对抗网络的核心思想是同时训练两个相互协作，同时又相互竞争的深度神经网络，\\n\\n一个称为生成器 （Generator），另一个称为判别器 （Discriminator）。生成器用来生成\\n\\n假图片，而判别器用来判断图片的真假。\\n\\n676\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n比如我们可以把警察看成是判别器，把制造假币的犯罪份子看成是生成器。在一开始的\\n\\n时候警察是不知道如何判断真钱和假币的，犯罪份子也不知道如何制造假币，他们会同时开\\n\\n始学习。一段时间后警察的判断能力提高了，他可以识别出哪些是犯罪份子制作的假币，哪\\n\\n些是真钱了，并把识别的过程告诉犯罪份子。犯罪份子根据警察的反馈改进自己的制作工\\n\\n艺，制作出更逼真的假币给警察识别。警察在识别假币的过程中判别能力不断提升，犯罪份\\n\\n子在制作假币的过程中制假能力不断提升。最终犯罪份子可以制作出警察无法判断真假的假\\n\\n币，这个时候模型训练就成功了。\\n\\n19.2.2 转置卷积（Transposed Convolution）介绍\\n\\n生成器网络中使用到了转置卷积（Transposed Convolution），所以这里我们先来了\\n\\n解一下。普通的卷积操作是一种下采样（Subsampled）操作，会使得图像的分辨率从大变\\n\\n小。而转置卷积是一种上采样（Upsampling）操作，会使得图像的分辨率从小变大。\\n\\n下面举两个例子给大家说明。\\n\\n比如我们使用 3×3 的卷积核对 4×4 的图像进行卷积计算，步长为 1，Valid Padding，\\n\\n卷积计算后可以得到 2×2 的特征图，如图 19.8 所示。\\n\\n图 19.8 普通卷积（1）\\n\\n当我们使用同样的条件：3×3 的卷积核，步长为 1，Valid Padding 对 2×2 的图像进行\\n\\n转置卷积就可以得到 4×4 的特征图，如图 19.9 所示。\\n\\n677\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 19.9 转置卷积（1）\\n\\n比如我们使用 3×3 的卷积核对 5×5 的图像进行卷积计算，步长为 2，Valid Padding，\\n\\n卷积计算后可以得到 2×2 的特征图，如图 19.10 所示。\\n\\n图 19.10 普通卷积（2）\\n\\n当我们使用同样的条件：3×3 的卷积核，步长为 2，Valid Padding 对 2×2 的图像进行\\n\\n转置卷积就可以得到 5×5 的特征图，如图 19.11 所示。\\n\\n图 19.11 转置卷积（2）\\n\\n大家应该能从这里找到些规律了，同样的条件下，对卷积后得到的特征图进行转置卷积\\n\\n可以得到原始图像的大小。不过要注意只是恢复图像的大小，图像的数值不一定会恢复。因\\n\\n为转置卷积的本质还是卷积，转置卷积中的卷积计算跟普通卷积一致，卷积核的具体数值也\\n\\n是需要通过模型训练得到。\\n\\n678\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n19.2.3 DCGAN 模型结构\\n\\n下面我们以 MNIST 数据生成为例来介绍 DCGAN 的模型结构。DCGAN 由两部分模型组\\n\\n成，生成器和判别器，如图 19.12 所示。\\n\\n图 19.12 生成器和判别器\\n\\n判别器的作用是判断一张图片是真还是假，属于二分类问题，所以模型的最后输出只需\\n\\n要 1 个神经元。\\n\\n679\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n而生成器的作用是生成假图片，生成器的输入是一个 100 维的随机数，其实也不一定要\\n\\n是 100 维，其他任意维度也可以。把随机数加上全连接层再 Reshape 就可以变成 4 维图像\\n\\n数据。然后再进行几次转置卷积，使得图像大小不断变大，最后输出 28×28 的图片。\\n\\n我们把 MNIST 数据集中的原始数据看成是真图片，然后把生成器生成的图片看成是假图\\n\\n片。把真图片和假图片都传给判别器进行学习，提升判别器的判断能力，同时利用判别器来\\n\\n提升生成器的造假能力。\\n\\n19.3 手写数字图像生成\\n\\n实现手写数字图像生成的代码如代码 19-1 所示。\\n\\n代码 19-1：手写数字图像生成（片段 1）\\n\\nfrom tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Conv2DTransp ose,Reshape,Conv2D,Dropout,Flatten import tensorflow as tf import matplotlib.pyplot as plt import numpy as np import os # Dataset 中的 buffer buffer_size = 60000 # 批次大小 batch_size = 256 # 训练周期 epochs = 51 # 100 维的随机噪声 noise_dim = 100 # 载入 MNNIST 数据，只需要训练集的图片就可以 (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data() # reshape 为 4 维数据 train_images = train_images.reshape(-1, 28, 28, 1).astype(\\'float32\\') # 将图片归一化到 [0, 1] 区间内 train_images = train_images/ 255.0\\n\\n680\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义 Dataset，用于生成打乱后的批次数据 train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch( batch_size)\\n\\n# 定义生成器 def generator_model(): # 顺序模型 model = tf.keras.Sequential() # 传入噪声数据，然后与 7*7*256 个神经元进行全连接 # 7*7*256 主要是为了后面可以 Reshape 变成(7, 7, 256) model.add(Dense(7*7*256, input_shape=(noise_dim,))) model.add(BatchNormalization()) model.add(LeakyReLU()) # 变成 4 维图像数据(-1,7,7,256) model.add(Reshape((7, 7, 256))) # 转置卷积，图像 shape 变成(-1,7,7,128) model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\\'same\\')) model.add(BatchNormalization()) model.add(LeakyReLU()) # 转置卷积，图像 shape 变成(-1,14,14,64) model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\\'same\\')) model.add(BatchNormalization()) model.add(LeakyReLU()) # 转置卷积，图像 shape 变成(-1,28,28,1) # 激活函数使用 sigmoid，主要是因为我们把 MNIST 数据图片归一化为[0,1]之间了，生成 的假图片要跟真实图片数据匹配 model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\\'same\\', activation=\\'sigmoi d\\')) return model\\n\\n# 定义判别器 def discriminator_model(): # 顺序模型 model = tf.keras.Sequential() # 传入一张图片数据进行卷积，卷积后图像 shape 为(1,14,14,64) model.add(Conv2D(64, (5, 5), strides=(2, 2), padding=\\'same\\', input_shape=[28, 28, 1])) model.add(LeakyReLU()) model.add(Dropout(0.3)) # 卷积后图像 shape 为(1,7,7,128) model.add(Conv2D(128, (5, 5), strides=(2, 2), padding=\\'same\\')) model.add(LeakyReLU()) model.add(Dropout(0.3))\\n\\n681\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model.add(Flatten()) # 最后输出一个值，激活函数为 sigmoid 函数，用于判断图片的真假 model.add(Dense(1, activation=\\'sigmoid\\')) return model\\n\\n# 创建生成器模型 generator = generator_model() # 创建判别器模型 discriminator = discriminator_model() # 生成随机数 noise = tf.random.normal([1, noise_dim]) # 传入生成器生成一张图片 generated_image = generator(noise, training=False) # 显示出图片，刚开始模型还没有训练，所以生成的图片会得到噪声图片 plt.imshow(generated_image[0, :, :, 0], cmap=\\'gray\\') plt.show() 结果输出为：\\n\\n代码 19-1：手写数字图像生成（片段 2）\\n\\n# 定义 2 分类交叉熵代价函数 cross_entropy = tf.keras.losses.BinaryCrossentropy()\\n\\n# 判别器 loss，传入对真实图片的判断结果以及对假图片的判断结果 def discriminator_loss(real_output, fake_output): # tf.ones_like(real_output)表示对真实图片的判断结果应该全为 1 real_loss = cross_entropy(tf.ones_like(real_output), real_output) # tf.zeros_like(fake_output)表示对假图片的判断结果应该全为 0 fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # 求总 loss，再返回 total_loss = real_loss + fake_loss\\n\\nreturn total_loss\\n\\n# 生成器 loss，传入判别器对假图片的判断结果\\n\\n682\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com def generator_loss(fake_output): # 对于生成器来说，生成器希望判别器对假图片的判断结果都是 1 # 所以标签设定为 tf.ones_like(fake_output)，全为 1 # 生成器模型在训练过程中会不断优化自身参数，使得模型生成逼真的假图片 return cross_entropy(tf.ones_like(fake_output), fake_output) # 由于我们需要分别训练两个网络，判别器和生成器的优化器是不同的。 generator_optimizer = tf.keras.optimizers.Adam(3e-4) discriminator_optimizer = tf.keras.optimizers.Adam(1e-4) # 把生成器模型和判别器模型以及对应的优化器存入 checkpoint checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, generator=generator, discriminator=discriminator) # 用于管理模型 # checkpoint 为需要保存的内容 # \\'checkpoint_dir\\'为模型保存位置 # max_to_keep 设置最多保留几个模型 manager = tf.train.CheckpointManager(checkpoint, \\'checkpoint_dir\\', max_to_keep=3)\\n\\n# 我们将重复使用该随机数，这个随机数用于在训练过程中生成图片并显示和保存 seed = tf.random.normal([16, noise_dim])\\n\\n# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 @tf.function # 定义模型的训练 def train_step(images): # 生成一个批次的随机数，这个随机数用于模型训练 noise = tf.random.normal([batch_size, noise_dim]) # 固定写法，使用 tf.GradientTape()来计算梯度 with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # 产生一个批次的假图片 generated_images = generator(noise, training=True) # 传入真图片到判别器中，得到预测结果 real_output = discriminator(images, training=True) # 传入假图片到判别器中，得到预测结果 fake_output = discriminator(generated_images, training=True) # 计算生成器 loss gen_loss = generator_loss(fake_output) # 计算判别器 loss disc_loss = discriminator_loss(real_output, fake_output) # 传入 loss 和模型参数，计算生成器的权值调整 gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\\n\\n683\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 传入 loss 和模型参数，计算判别器的权值调整 gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variabl es) # 生成器的权值调整 generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_var iables)) # 判别器的权值调整 discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trai nable_variables))\\n\\n# 生成图片并保存显示 def generate_and_save_images(model, epoch, test_input): # 注意 training 设定为 False，所有层都在预测模式下运行 predictions = model(test_input, training=False) # 画 16 张子图 for i in range(16): plt.subplot(4, 4, i+1) # 显示图片 plt.imshow(predictions[i, :, :, 0], cmap=\\'gray\\') # 不显示刻度 plt.axis(\\'off\\') # 保存图片 plt.savefig(\\'image_at_epoch_{:04d}.png\\'.format(epoch)) # 显示图片 plt.show() # 训练模型 def train(dataset, epochs): # 训练 epochs 周期 for epoch in range(epochs): # 每次获得一个批次的真实图片传入 train_step 函数进行训练 for image_batch in dataset: train_step(image_batch) # 显示和保存图片 generate_and_save_images(generator, epoch, seed) # 每 5 个 epoch 保存一次模型 if epoch % 5 == 0: # 保存模型 # checkpoint_number 设置模型编号 manager.save(checkpoint_number=epoch)\\n\\n# 模型训练 train(train_dataset, epochs) 结果输出为：\\n\\n684\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n……\\n\\n……\\n\\n最后训练得到的生成图片已经比较接近真实的 MNIST 数据集的图片了，有些假图片看起\\n\\n来就跟真的一样。\\n\\n19.4 参考文献\\n\\n[1] Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative adversarial\\n\\nnets[C]//Advances in neural information processing systems. 2014: 2672-2680.\\n\\n685\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[2] Karras T, Laine S, Aila T. A style-based generator architecture for generative\\n\\nadversarial networks[C]//Proceedings of the IEEE conference on computer vision and\\n\\npattern recognition. 2019: 4401-4410.\\n\\n[3] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep\\n\\nConvolutional Generative Adversarial Networks [J]. arXiv preprint arXiv:1511.06434,\\n\\n2015.\\n\\n[4] Isola P, Zhu J Y, Zhou T, et al. Image-to-image translation with conditional\\n\\nadversarial networks[C]//Proceedings of the IEEE conference on computer vision and\\n\\npattern recognition. 2017: 1125-1134.\\n\\n[5] Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-\\n\\nconsistent adversarial networks[C]//Proceedings of the IEEE international conference\\n\\non computer vision. 2017: 2223-2232.\\n\\n[6] Zhang H, Xu T, Li H, et al. Stackgan: Text to photo-realistic image synthesis with\\n\\nstacked generative adversarial networks[C]//Proceedings of the IEEE international\\n\\nconference on computer vision. 2017: 5907-5915.\\n\\n[7] Brock A, Donahue J, Simonyan K. Large scale gan training for high fidelity natural\\n\\nimage synthesis[J]. arXiv preprint arXiv:1809.11096, 2018.\\n\\n[8] Ledig C, Theis L, Huszár F, et al. Photo-realistic single image super-resolution\\n\\nusing a generative adversarial network[C]//Proceedings of the IEEE conference on\\n\\ncomputer vision and pattern recognition. 2017: 4681-4690.\\n\\n686\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 20 章 模型部署\\n\\n这一章节我们来了解一下模型部署。深度学习的模型训练好以后要在工程中应用，需要\\n\\n部署到服务器中。其实就是我们需要运行一个用于数据预测的后台服务程序，这个后台服务\\n\\n程序中运行着我们训练好的模型，然后等待其他客户端程序把数据传给用于数据预测的后台\\n\\n服务程序。后台服务程序把接收到的数据传给模型进行预测，再把模型的预测结果返回给客\\n\\n户端程序。如图 20.1 所示。\\n\\n图 20.1\\n\\n后台的服务程序可以自行编写，也可以使用谷歌官方提供的模型部署工具 Tensorflow\\n\\nServing。推荐在 Docker 中搭建 Tensorflow Serving。\\n\\n20.1 Tensorflow Serving 环境部署\\n\\nTensorflow Serving 是一个用于为机器学习模型提供灵活高性能服务的系统，专为生产\\n\\n环境设计。使用 Tensorflow Serving 我们可以很容易的部署新的模型到生产环境中。\\n\\nTensorflow Serving 有多种安装方式，不过 Tensorflow 官方建议我们使用 Docker 来\\n\\n安装 Tensorflow Serving，所以下面给大家介绍在 Docker 中搭建 Tensorflow Serving 的\\n\\n687\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n环境的方法。Docker 是一种轻量级的虚拟化技术，和传统的虚拟机不同，Docker 启动速度\\n\\n更快，性能更好，占用的内存和硬盘空间小，并且具有更好的迁移性，所以近几年得到了快\\n\\n速发展和大规模的应用。\\n\\n20.1.1 安装 Docker\\n\\n首先第一步我们需要先安装 Docker，Docker 可以在 Linux，MacOS 和 Windows 环境\\n\\n下安装，软件下载的官网地址为：https://docs.docker.com/get-docker/。具体安装方式\\n\\n可以查看官网说明。\\n\\n如果我们需要使用 GPU 的话，还需要安装 NVIDIA 的 Docker 工具 nvidia-docker，安\\n\\n装方式可以查看：https://github.com/NVIDIA/nvidia-docker#quick-start。不过 nvidia-\\n\\ndocker 目前只支持 Linux 的系统。\\n\\n20.1.2 拉取 Tensorflow Serving 镜像\\n\\n安装并运行 Docker 以后，在命令提示符中执行：\\n\\ndocker pull tensorflow/serving\\n\\n默认下载最新版本的 Tensorflow Serving 镜像。如果是下载最新版本的 GPU 版本的镜\\n\\n像，可以执行：\\n\\ndocker pull tensorflow/serving:latest-gpu\\n\\n688\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n20.2 运行客户端和服务器程序\\n\\n20.2.1 准备 SavedModel 模型\\n\\n在本书第 7 章，介绍 Tensorflow 模型的保存和载入的时候，有介绍过 SavedModel 是\\n\\nTensorflow 中一种模型的格式，它的优点是与语言无关。在 Tensorflow Serving 中所使用\\n\\n的模型要求必须为 SavedModel 格式的模型。下面作为演示，我们可以先产生一个\\n\\nSavedModel 模型，如代码 20-1 所示。\\n\\n代码 20-1：生成 SavedModel 模型\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28), name=\\'image\\'), tf.keras.layers.Dense(10, activation=\\'softmax\\', name=\\'output\\') ])\\n\\n# 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd, loss=\\'mse\\', metrics=[\\'accuracy\\'])\\n\\n# 传入训练集数据和标签训练模型\\n\\n689\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test,y_test)) # 保存模型为 SavedModel 格式 # 1 在这里用于表示模型的版本号 model.save(\\'my_model/1\\') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/3 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0368 - accuracy: 0.7843 - val_loss: 0.0212 - val_accuracy: 0.880 8 Epoch 2/3 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0202 - accuracy: 0.8820 - val_loss: 0.0175 - val_accuracy: 0.896 4 Epoch 3/3 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0177 - accuracy: 0.8937 - val_loss: 0.0160 - val_accuracy: 0.904 0\\n\\n我们训练了一个 MNIST 图像识别模型，设置了模型的输入名称为“image”，模型的输\\n\\n出名称为“output”，后面会用到。然后把模型保存到“my_model/1”文件夹中，这里的\\n\\n1 表示模型的版本号。\\n\\n20.2.2 启动 Tensorflow Serving 服务器程序\\n\\n接下来我们就可以启动 Tensorflow Serving 的服务器程序了，就是我们需要运行一个后\\n\\n台程序，在这个后台程序中载入 SavedModel 模型，等待客户端程序传输数据。\\n\\nTensorflow Serving 支持 gRPC 和 REST API 两种请求方式。\\n\\n我们需要在命令提示符中运行下面格式的命令，如图 20.2 所示。\\n\\n690\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 20.2 启动服务器程序命令\\n\\n首先大家要注意这是一条比较长的命令，为了让大家看清楚，所以我把这条长命令分为\\n\\n了很多行。大家在命令行中运行的时候需要把“\\\\”符号去掉，然后组成一条连续的长命令。\\n\\n还有就是大家需要注意什么地方有空格，什么地方没有空格，需要跟图中一致。比如\\n\\n“run”，“-p”，“--mount”，“-e”，”-t”,“ {gRPC}:{gRPC}”，\\n\\n“{Model_Name}”等后面是有空格的；”type=bind,””{SavedModel_Path},”后面是\\n\\n没有空格的。\\n\\ndocker run 表示在 Docker 中运行，{gRPC}表示填入 gRPC 端口号，可以自定义，\\n\\n{REST API}表示填入 REST API 端口号，可以自定义。Source={SavedModel_Path}表示填\\n\\n入我们准备的 SavedModel 模型的路径，注意要填入 SavedModel 模型所在的绝对路径，\\n\\n不包括版本号。target=/models/{Model_Name}表示把 SavedModel 模型挂载到 Docker\\n\\n中的/models/{Model_Name}文件夹。MODEL_NAME={Model_Name}表示设置模型名\\n\\n字，{Model_Name}表示模型名字，可以自定义。最后的 tensorflow/serving 表示运行\\n\\ntensorflow/serving。如果要用 GPU 的话可以改成 tensorflow/serving:latest-gpu。当然\\n\\n前提是前面已经安装 nvidia-docker 并拉取 tensorflow/serving:latest-gpu 镜像。\\n\\n我的 SavedModel 保存在$(pwd)/my_model/1 文件夹下，下面给大家看一下我这里运\\n\\n行的一个完整命令，$(pwd)表示当前位置的绝对路径：\\n\\n691\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\ndocker run -p 8500:8500 -p 8501:8501 --mount\\n\\ntype=bind,source=$(pwd)/my_model,target=/models/my_model -e\\n\\nMODEL_NAME=my_model -t tensorflow/serving\\n\\n如果运行成功的话，会看到很多输出信息，如：\\n\\n2020-05-23 10:04:05.996573: I tensorflow_serving/model_servers/serve r.cc:86] Building single TensorFlow model file config: model_name: m y_model model_base_path: /models/my_model 2020-05-23 10:04:05.998649: I tensorflow_serving/model_servers/serve r_core.cc:462] Adding/updating models. 2020-05-23 10:04:05.998684: I tensorflow_serving/model_servers/serve r_core.cc:573] (Re-)adding model: my_model 2020-05-23 10:04:06.126071: I tensorflow_serving/core/basic_manager. cc:739] Successfully reserved resources to load servable {name: my_mo del version: 1} 2020-05-23 10:04:06.126126: I tensorflow_serving/core/loader_harnes s.cc:66] Approving load for servable version {name: my_model version: 1} 2020-05-23 10:04:06.126144: I tensorflow_serving/core/loader_harnes s.cc:74] Loading servable version {name: my_model version: 1} 2020-05-23 10:04:06.126589: I external/org_tensorflow/tensorflow/cc/ saved_model/reader.cc:31] Reading SavedModel from: /models/my_model/ 1 2020-05-23 10:04:06.133228: I external/org_tensorflow/tensorflow/cc/ saved_model/reader.cc:54] Reading meta graph with tags { serve } 2020-05-23 10:04:06.133263: I external/org_tensorflow/tensorflow/cc/ saved_model/loader.cc:264] Reading SavedModel debug info (if presen t) from: /models/my_model/1 2020-05-23 10:04:06.134544: I external/org_tensorflow/tensorflow/cor e/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2020-05-23 10:04:06.184545: I external/org_tensorflow/tensorflow/cc/ saved_model/loader.cc:203] Restoring SavedModel bundle. 2020-05-23 10:04:06.241474: I external/org_tensorflow/tensorflow/cc/ saved_model/loader.cc:152] Running initialization op on SavedModel b undle at path: /models/my_model/1 2020-05-23 10:04:06.245208: I external/org_tensorflow/tensorflow/cc/ saved_model/loader.cc:333] SavedModel load for tags { serve }; Statu s: success: OK. Took 118607 microseconds.\\n\\n692\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 693 2020-05-23 10:04:06.246544: I tensorflow_serving/servables/tensorflo w/saved_model_warmup.cc:105] No warmup data file found at /models/my _model/1/assets.extra/tf_serving_warmup_requests 2020-05-23 10:04:06.258998: I tensorflow_serving/core/loader_harnes s.cc:87] Successfully loaded servable version {name: my_model versio n: 1} 2020-05-23 10:04:06.265112: I tensorflow_serving/model_servers/serve r.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ... [warn] getaddrinfo: address family for nodename not supported 2020-05-23 10:04:06.272848: I tensorflow_serving/model_servers/serve r.cc:378] Exporting HTTP/REST API at:localhost:8501 ... [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\\n\\n大家看到类似信息说明 Tensorflow Serving 的服务程序已经在后台运行了，在打印的信\\n\\n息中我们可以看到“Running gRPC ModelServer at 0.0.0.0:8500”和\\n\\n“Exporting HTTP/REST API at:localhost:8501”，这两个信息在客户端程序中需\\n\\n要使用。\\n\\n20.2.3 Tensorflow Serving 客户端 gRPC 程序\\n\\n使用 gPRC 程序我们需要先安装 tensorflow-serving-api，打开命令提示符，输入命\\n\\n令：\\n\\npip install tensorflow-serving-api\\n\\n然后我们还需要在命令行使用 saved_model_cli 命令查看 SavedModel 模型的一些基本\\n\\n信息：\\n\\nsaved_model_cli show --dir my_model/1 --all\\n\\n这里的 my_model/1 为我的 SavedModel 模型位置。运行该命令后我们会看到很多输\\n\\n出信息，其中比较重要的部分如下：\\n\\nsignature_def[\\'serving_default\\']: The given SavedModel SignatureDef contains the following input(s): inputs[\\'image_input\\'] tensor_info: dtype: DT_FLOAT\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com shape: (-1, 28, 28) name: serving_default_image_input:0 The given SavedModel SignatureDef contains the following output(s): outputs[\\'output\\'] tensor_info: dtype: DT_FLOAT shape: (-1, 10) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict\\n\\n这里我们可以看到模型的签名 signature 为[\\'serving_default\\']，我们之前没有设置过模\\n\\n型的签名，所以这里使用的是默认签名。模型的输入 inputs 为[\\'image_input\\']，其实就是在\\n\\n我之前设置的模型输入名称“image”基础上增加了“_input”。模型的输出 outputs 为\\n\\n[\\'output\\']，跟我之前设置的模型输出名一样。实现客户端 gRPC 程序的代码如代码 20-2 所\\n\\n示。\\n\\n代码 20-2：客户端 gRPC 程序（片段 1）\\n\\nfrom tensorflow_serving.apis import predict_pb2 from tensorflow_serving.apis import prediction_service_pb2_grpc import grpc\\n\\n# 向 TensorFlow Serving 服务请求预测结果。 def request_server(img, server_url): # 为服务器创建一个通道 channel = grpc.insecure_channel(server_url) # 在客户端中实现 stub，利用这个 stub 可以调用相应的服务器中的服务 stub = prediction_service_pb2_grpc.PredictionServiceStub(channel) # 定义请求 request = predict_pb2.PredictRequest() # 设置模型名称，需要跟启动 tf-serving 服务器时模型的名字一样 request.model_spec.name = \"my_model\" # 模型签名，可以使用 saved_model_cli 命令查看 request.model_spec.signature_name = \"serving_default\" # 模型输入名称为\"image_input\"，之前模型保存的时候设置为\"image\"后面的\"_input\"是程 序自动加上的 # 设置要传输的数据 img，数据的格式 tf.float32，数据的形状 img.shape request.inputs[\"image_input\"].CopyFrom(tf.make_tensor_proto(img, dtype=tf.float32, sha pe=img.shape)) # 传数据获得预测结果，最多等待 5 秒 response = stub.Predict(request, 5.0)\\n\\n694\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # output 为模型输出名称，之前模型保存的时候设置的，变成 array 后返回 return np.asarray(response.outputs[\"output\"].float_val)\\n\\nimport tensorflow as tf import matplotlib.pyplot as plt import numpy as np\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理 x_train, x_test = x_train / 255.0, x_test / 255.0 # x_test 中第 5 张图片标签为 1 plt.imshow(x_test[5],cmap=\\'gray\\') # 显示图片 plt.show() 结果输出为：\\n\\n代码 20-2：客户端 gRPC 程序（片段 2）\\n\\n# grpc 地址及端口，启动 tf-serving 服务器程序的时候有看到过 server_url = \\'0.0.0.0:8500\\' # 预测一个数据 pre = request_server(x_test[5], server_url) print(\"预测结果为：\",np.argmax(pre)) 结果输出为： 预测结果为： 1\\n\\n695\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 20-2：客户端 gRPC 程序（片段 3）\\n\\n# 预测一个批次的数据，比如一次性预测 16 个数据 num = 16 # 获得预测结果 pre = request_server(x_test[:num], server_url) # reshape 变成 16 行 10 列 pre = pre.reshape((num,10)) print(\"预测结果为：\",np.argmax(pre,axis=1)) print(\"真实标签为：\",y_test[:num]) 结果输出为： 预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5] 真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\\n\\n20.2.4 Tensorflow Serving 客户端 REST API 程序\\n\\nTensorflow Serving 还可以使用 REST API 请求，并且 REST API 看起来更简单一些。\\n\\n实现客户端 REST API 程序的代码如代码 20-3 所示。\\n\\n代码 20-3：客户端 REST API 程序\\n\\nimport tensorflow as tf import matplotlib.pyplot as plt import numpy as np\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理 x_train, x_test = x_train / 255.0, x_test / 255.0\\n\\nimport json import numpy import requests # 定义模型签名，可以使用 saved_model_cli 命令查看 # 定义 instances，一次性传入 16 张图进行预测 data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[0:16].tolist()}) # 定义 headers\\n\\n696\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com headers = {\"content-type\": \"application/json\"} # 定义 url，启动 tf-serving 服务器程序的时候有看到过 # /models/my_model 为模型挂载到 Docker 中的位置 url = \\'http://localhost:8501/v1/models/my_model:predict\\' # 传输数据进行预测，得到返回结果 json_response = requests.post(url, data=data, headers=headers) # 对结果进行解析，然后变成 array pre = numpy.array(json.loads(json_response.text)[\"predictions\"]) print(\"预测结果为：\",np.argmax(pre,axis=1)) print(\"真实标签为：\",y_test[:16]) 结果输出为： 预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5] 真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\\n\\n697\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n专业术语汇总\\n\\n前言\\n\\n全注释代码：本书中所使用的代码风格，最大的特点是注释所有程序。\\n\\n第 1 章-深度学习介绍\\n\\n深度学习（Deep Learning）：多层神经网络算法。上世纪 60 年代叫做感知器，上世纪 80 年\\n\\n代叫做神经网络，21 世纪后改名为深度学习。\\n\\n人工智能（Artificial Intelligence）：1956 年美国达特茅斯会上提出的一个抽象概念，它不\\n\\n是任何具体的机器或算法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工\\n\\n智能。\\n\\n图灵测试（Turing Test）：具体解释见正文。\\n\\n机器学习（Machine Learning）：人工智能是抽象的概念，那么就需要具体的算法让它落地，\\n\\n机器学习就是一大类具体智能算法的统称。机器学习不是一个算法，而是很多算法的统称。使\\n\\n用机器学习算法我们可以解决生活中如人脸识别，垃圾邮件分类，语音识别等具体问题。\\n\\n训练集（Training Set）：可以用来训练，构建模型。\\n\\n验证集（Validation Set）：模型训练阶段测试模型的效果。\\n\\n测试集（Testing Set）：模型训练好之后最后再用于测试模型的效果。\\n\\nK 折交叉检验（K-fold Cross-Validation）：具体解释见正文。\\n\\n监督学习（Supervised Learning）：具体解释见正文。\\n\\n分类（Classification）：预测类别，并且类别是已知的。比如图像识别，文本分类都是属于分\\n\\n类任务。\\n\\n698\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n回归（Regression）：预测数值，可以是连续型的数值。比如预测国家人口增长，公司销售业\\n\\n绩等。\\n\\n标签（Label）：数据的标签。\\n\\n非监督学习（Unsupervised Learning）：具体解释见正文。\\n\\n聚类（Clustering）：把数据划分成不同的类别，并且类别是未知的。比如某电商平台可以根\\n\\n据用户的行为数据把用户划分为不同的聚类。\\n\\n半监督学习（Semi-Supervised Learning）：具体解释见正文。\\n\\n强化学习（Reinforcement Learning）：具体解释见正文。\\n\\n决策树（Decision Tree）：具体解释见正文。\\n\\n线性回归（Linear Regreesion）：具体解释见正文。\\n\\nKNN（K-Nearest Neighbor）：具体解释见正文。\\n\\n欧氏距离（Euclidean Distance）：也叫欧几里得距离，欧几里得空间中两点间直线的距离，\\n\\n也就是我们日常生活中用得最多的距离计算方法。\\n\\nK-Means：具体解释见正文。\\n\\n神经网络（Neural Network）：具体解释见正文。\\n\\n输入层（Input Layer）：神经网络的信号输入层。\\n\\n隐藏层（Hidden Layers）：神经网络的中间的网络层。\\n\\n输出层（Output Layer）：神经网络信号输出的层。\\n\\n神经元（Neuron）：神经网络中的基本结构，大量的神经元组成了神经网络。\\n\\n权值（Weights）：神经网络中可以变化的参数，神经网络的训练就是训练网络的权值。\\n\\n激活函数（Activation Function）：神经元在进行信号汇总以后会经过一个激活函数后再输\\n\\n出，激活函数的主要作用是给网络增加非线性。\\n\\n699\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n朴素贝叶斯（Naive Bayes）：经典的机器学习算法，朴素贝叶斯法是基于贝叶斯定理与特征\\n\\n条件独立假设的分类方法。\\n\\n支持向量机（Support Vector Machine）：简称 SVM，经典的机器学习算法，支持向量机是\\n\\n一类按监督学习方式对数据进行二分类的广义线性分类器，其决策边界是对学习样本求解的最\\n\\n大边距超平面。\\n\\nAdaboost：经典的机器学习算法，Adaboost 是一种迭代算法，其核心思想是针对同一个训\\n\\n练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分\\n\\n类器（强分类器）。\\n\\n弱人工智能（Weak AI）：具体解释见正文。\\n\\n强人工智能（Strong AI）：具体解释见正文。\\n\\n人工神经网络（Artificial Neural Networks）：简称 ANN，人工构建的神经网络算法。\\n\\n控制论（Cybernetics）：控制论看作是一门研究机器、生命社会中控制和通讯的一般规律的\\n\\n科学，是研究动态系统在变的环境条件下如何保持平衡状态或稳定状态的科学。\\n\\n联结主义（Connectionism）：又称为仿生学派（Bionicsism）或生理学派（Physiologism），\\n\\n其原理主要为神经网络及神经网络间的连接机制与学习算法。\\n\\n卷积神经网络（Convolutional Neural Network）：简称 CNN，一种包含卷积计算的多层\\n\\n网络结构，深度学习代表算法之一。在计算机视觉领域有着非常多的应用。\\n\\n长短时记忆网络（Long Short Term Memory Network）：简称 LSTM 是一种时间循环神\\n\\n经网络，是为了解决一般的 RNN（循环神经网络）存在的长期依赖问题而专门设计出来的。\\n\\n深度残差网络（Deep Residual Network）：一种深度的卷积神经网络，网络层数可以多达上\\n\\n百层，其中的残差结构是它的特色。\\n\\n700\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n感知器（Perceptron）：早期的神经网络模型，只有输入层和输出层，只能用于线性问题的求\\n\\n解，不能解决非线性问题。\\n\\nHopfield 神经网络：Hopfield 神经网络是一种递归神经网络，由约翰·霍普菲尔德在 1982 年\\n\\n发明，现在已经基本不用了。\\n\\n玻尔兹曼机（Boltzmann Machine）：是一种可通过输入数据集学习概率分布的随机生成神\\n\\n经网，现在已经基本不用了。\\n\\n受限玻尔兹曼机（Restricted Boltzmann Machine）：对玻尔兹曼机的改良，现在已经基本\\n\\n不用了。\\n\\nBP（Back Propagation）算法：多层感知器的误差反向传播算法，BP 神经网络也是整个神\\n\\n经网络体系中的精华，广泛应用于分类识别，逼近，回归，压缩等领域。该算法从 1986 年一\\n\\n直沿用至今，在实际应用中，包括深度学习在内的大部分的神经网络都使用了 BP 算法。\\n\\nBP 神经网络（Back Propagation Neural network）：主要指的是 20 世纪 80-90 年代使用\\n\\nBP 算法的多层神经网络。\\n\\n深度置信网络（Deep Belief Net：DBN）：多个受限玻尔兹曼机堆叠而成，深度学习灵感的\\n\\n开端。现在已经基本不用了。\\n\\nNLP (Natural Language Processing) ：自然语言处理。\\n\\nGPU（Graphics Processing Unit）：图形处理器，可用于打游戏，图像渲染或高性能计算。\\n\\nTPU（Tensor Processing Unit）：Tensor 处理器，专门用于机器学习计算。\\n\\n第 3 章-单层感知器与线性神经网络\\n\\n偏置值（Bias）：与输入信号无关的偏置信号。\\n\\n701\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nsign(x)激活函数：神经网络中最早使用的激活函数，当 x＞0 时，输出值为 1；当 x＝0 时，\\n\\n输出值为 0,；当 x＜0 时，输出值为-1。\\n\\n学习率（Learning Rate）：可以用来调节模型训练的速度快慢。\\n\\n代价函数（Loss Function）：也称为目标函数或损失函数，通常用来定义模型的误差。\\n\\n迭代周期（Epoch）：迭代周期。把所有训练集数据训练一次称为训练一个周期。\\n\\n超参数（Hyperparameters）：机器学习或者深度学习中经常用到的一个概念，我们可以认为\\n\\n是根据经验来人为设置的一些模型相关的参数。\\n\\n参数（Parameters）：一般指的是模型中需要训练的变量，如模型的权值和偏置值。\\n\\npurelin 函数：线性函数，y=x。\\n\\n第 4 章-BP 神经网络\\n\\n均方差（Mean-Square Error, MSE）：也称为二次代价函数，用来表示模型的误差，多用于\\n\\n回归问题。\\n\\n二次代价函数：也就是均方差代价函数。\\n\\n导数（Derivative）：具体解释见正文。\\n\\n偏导数（Partial Derivative）：具体解释见正文。\\n\\n方向导数（Directional Derivative）：具体解释见正文。\\n\\n梯度（Gradient）：具体解释见正文。\\n\\n梯度下降法（Gradient Descent）：神经网络的常用的优化算法，用于最小化代价函数的值。\\n\\n全局最小值（Global Minimum）：代价函数的最小值，只有一个。\\n\\n局部极小值（Local Minimum）：代价函数的局部最小值，可能会有多个。\\n\\n702\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nsigmoid 函数：也称为逻辑函数。上世纪 80 年代，BP 神经网络中最开始使用的 S 型非线性\\n\\n激活函数。取值范围 0-1 之间，导数范围 0-0.25 之间。\\n\\ntanh 函数：一种 S 型非线性激活函数，取值范围-1-1 之间，导数范围 0-1 之间。\\n\\nsoftsign 函数：一种 S 型非线性激活函数，取值范围-1-1 之间，导数范围 0-1 之间。\\n\\nReLU 函数（The Rectified Linear Unit）：ReLU 的中文名称是校正线性单元，一种模拟生\\n\\n物神经元激活函数的新型非线性激活函数，广泛应用于深度学习中，可以用来抵抗梯度消失问\\n\\n题。\\n\\n欠拟合（Under-Fitting）：模型的拟合程度不够，训练集和测试集都无法得到很好的结果。\\n\\n过拟合（Over-Fitting）：模型对训练集拟合程度过好，使得模型在训练集的预测结果比较好，\\n\\n在测试集的预测结果比较差。\\n\\n梯度消失（Vanishing Gradient）：误差反向传播过程中学习信号越来越小的现象。\\n\\n梯度爆炸（Exploding Gradient）：误差反向传播过程中学习信号越来越大的现象。\\n\\n稀疏性（Sparsity）：神经网络的稀疏性指的是网络中神经元输出为 0 的数量，输出为 0 的神\\n\\n经元数量越多，网络越稀疏。\\n\\nL1 正则化（L1 Regularization）：一种正则化手段，可以使得神经网络变得稀疏，所有网络\\n\\n权值都会趋近于 0，部分网络权值会变成 0。\\n\\nDropout：一种正则化手段，在神经网络训练过程中让网络变稀疏进行训练。\\n\\n准确率（Accuracy）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n\\n精确率（查准率，Precision）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n\\n召回率（查全率，Recall）：机器学习常见的分类评估指标，具体含义查看书中介绍。\\n\\n第 6 章-网络优化方法\\n\\n703\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n交叉熵（Cross Entropy）：一种代价函数，用于表示模型的误差，主要用于分类任务。\\n\\n对数似然（Log Likelihood）代价函数：一种代价函数，用于表示模型的误差，主要用于分类\\n\\n任务，与 softmax 函数搭配使用。\\n\\n标签平滑（Label Smoothing）：也称为标签平滑正则化(label-smoothing regularization)，\\n\\n简称 LSR，一种正则化方法。通过调节数据标签的数值来达到抵抗过拟合的效果。\\n\\n数据增强（Data Augmentation）：对现有数据进行处理，生成更多训练数据的方法。\\n\\nEarly-Stopping：一种提前停止模型训练的策略。\\n\\nL2 正则化（L2 Regularization）：一种正则化手段，会使所有网络权值都会趋近于 0，但是\\n\\n一般不会等于 0。\\n\\n第 8 章-卷积神经网络 CNN\\n\\nCV(Computer Vision)：计算机视觉。\\n\\n卷积窗口（Convolution Window）：进行卷积计算的一个窗口。\\n\\n特征图（Feature Map）：卷积计算后得到的用于表示图像特征的图。\\n\\n视觉感受野（Receptive field of vision）：视网膜上一定的区域或范围。\\n\\n局部感受野（Local Receptive Field）：卷积网络中的局部感受野指的是后一层神经元只连接\\n\\n前一层的部分神经元。\\n\\n权值共享（Weight Sharing）：同一卷积层中的同一个卷积窗口的权值是共享的。\\n\\n卷积核（Convolution Kernel）：就是卷积窗口。\\n\\n池化（Pooling）：卷积网络中常用的一种特征提取的计算。\\n\\n最大池化（Max-Pooling）：提取池化窗口中的最大值。\\n\\n平均池化(Mean-Pooling)：提取池化窗口中的平均值。\\n\\n704\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n随机池化(Stochastic Pooling)：提取池化窗口中随机一个值。\\n\\nValid Padding：不会进行填充的一种 padding。\\n\\nSame Padding：可能会进行填充的一种 padding。\\n\\n滤波器（Filter）：由一个或多个不同的卷积核组成，一个滤波器可以产生一个特征图。\\n\\n第 9 章-序列模型\\n\\n循环神经网络（Recurrent Neural Network）：简称 RNN，一种常用的深度学习算法，专门\\n\\n用来处理序列数据。\\n\\nSimple Recurrent Networks (SRN)：早期的结构比较简单的循环神经网络。\\n\\nSimpleRNN：早期的结构比较简单的循环神经网络。\\n\\nSeq2Seq：Sequence to Sequence 模型，由编码器 Encoder 和解码器 Decoder 组成。可\\n\\n以用于机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。\\n\\n记忆块（Memory Block）：LSTM 网络中的核心结构。\\n\\n遗忘门（Forget Gate）：LSTM 网络中用于控制信号遗忘的控制门。\\n\\n输入门（Input Gate）：LSTM 网络中用于控制信号输入的控制门。\\n\\n输出门（Output Gate）：LSTM 网络中用于控制信号输出的控制门。\\n\\n记忆单元（Cell）：LSTM 网络中用于保存信号的单元。\\n\\nHidden State：LSTM 的 memory block 输出信号。\\n\\nCell State：LSTM 的 memory block 中间 Cell 位置的信号。\\n\\n双向 RNN（Bidirectional RNN）：同时利用前向传递和反向传递的信号进行计算的 RNN。\\n\\n第 10 章-经典图像识别模型介绍(上)\\n\\n705\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n迁移学习（Transfer Learning）：深度学习中的迁移学习指的是把训练好的模型经过少量修\\n\\n改和训练后，即可用于新的类似的任务中。\\n\\n模型融合（Ensemble Model）：把多个不同的模型组合起来进行训练或预测，有可能会得到\\n\\n更好的结果。\\n\\nLRN（Local Response Normalization）：局部响应归一化。一种数据归一化计算，在 AlexNet\\n\\n和 GoogleNet 中曾使用。\\n\\n批量标准化（Batch Normalization）：深度学习中常用的一种网络标准化操作，可以使得网\\n\\n络输入的数据分布相对稳定，加速模型的训练。\\n\\n退化问题（Degradation Problem）：网络模型层数越多，效果越差的现象。\\n\\n残差块（Residual Block）：残差网络（ResNet）中的基本组成单元，用于解决退化问题。\\n\\n第 11 章-经典图像识别模型介绍(下)\\n\\n分组卷积（Group Convolution）：将特征图分为不同的组，再对每组特征图分别进行卷积。\\n\\n第 12 章-图像识别项目实战\\n\\n微调（Finetune）：对预训练的模型参数进行微调。\\n\\n第 13 章-验证码识别项目\\n\\n多任务学习（Multi-task Learning）：同时训练多个不同的任务。\\n\\nCTC(Connectionist Temporal Classification)：用来解决输入序列和输出序列难以一一对\\n\\n应的问题。主要用于语音识别和 OCR(Optical Character Recognition)领域\\n\\nOCR(Optical Character Recognition)：光学字符识别。\\n\\n706\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n贪心算法（Greedy Search）：对问题求解时，总是做出当前看来最好的选择，不一定能得到\\n\\n全局最优解。\\n\\n集束搜索算法（Beam Search）：对问题求解时，做出当前看来最好的 N 个选择，不一定能得\\n\\n到全局最优解。当 N 等于 1 时就是贪心算法。\\n\\n第 14 章-自然语言处理 NLP 发展历程（上）\\n\\n语法规则（Grammar Rules）：语言使用的规则。\\n\\n词性（Part of Speech）：词的词性，如名词，动词，形容词等\\n\\n构词法（Morphologie）：研究词形变化现象和规则的学问。\\n\\n上下文无关文法（Context Independent Grammar）：跟上下文无关的文法规则。\\n\\n上下文相关文法（Context Dependent Grammar）：跟上下文相关的文法规则。\\n\\n语料库（Corpus）：大量文本的数据集。\\n\\n二元模型（Bigram Model）：一个词的出现概率只与它前面一个词相关。\\n\\nN 元模型（N-Gram Model）：一个词的出现概率由前面 N-1 个词决定。\\n\\n神经网络语言模型 NNLM（Neural Net Language Model）：最早基于神经网络训练出来\\n\\n的语言模型。\\n\\n词向量（Word Embedding）：用一个向量来表达一个词包含的信息。\\n\\nWord2vec：word to vector，将词转化为向量的一套训练方法。\\n\\n连续词袋模型 CBOW（Continuous Bag-of-Words）：通过上下文词汇预测中间词汇。\\n\\nSkip-Gram 模型：通过中间词汇预测上下文词汇。\\n\\n层次 softmax（Hierarchical Softmax）：对 softmax 进行优化的一种策略，可以加快模型\\n\\n训练速度。\\n\\n707\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n负采样（Negative Sampling）：具体解释见正文。\\n\\n上下文向量（Context Vector）：Seq2Seq 中用来表示 Encoder 中整个序列的信息。\\n\\nWordPiece：为了减少词汇数量，把词拆分为一片一片。\\n\\n第 15 章-自然语言处理 NLP 发展历程（下）\\n\\nLayer Normmalization ：与 Batch Normalization 类似的 一种归一化计算。 Layer\\n\\nNormmalization 是计算一个数据中，所有特征维度的平均值和标准差，然后再对这个数据进\\n\\n行归一化计算。\\n\\n分词向量（Token Embeddings）：也就是词向量。\\n\\n位置向量（Position Embeddings）：表示每个 token 的位置信息。\\n\\n段落向量（Segment Embeddings）：用来标注哪几个 token 是第一句话，哪几个 token 是\\n\\n第二句话。\\n\\n分词元素（Token）：分词的基本单位，可以是一个词汇或一个字符或其他自定义元素。\\n\\n掩码语言模型（Masked Language Model）：简称 MLM，Bert 模型中使用的训练方法，简\\n\\n单的说就是完形填空。\\n\\nMLM：掩码语言模型（Masked Language Model）。\\n\\n预测下一个句子（Next Sentence Prediction）：简称 NSP，Bert 模型中使用的训练方法，\\n\\n意思就是预测下一个句子。\\n\\nNSP：预测下一个句子（Next Sentence Prediction）。\\n\\nGLUE(General Language Understanding Evaluation): GLUE 是一个自然语言任务集合\\n\\n命名实体识别 NER（Named Entity Recognition）：判断一个句子中的单词是不是人名，机\\n\\n构名，地名，以及其他所有以名称为标识的实体。\\n\\n708\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 16 章-NLP 任务项目实战\\n\\n维特比算法（Viterbi Algorithm）：维特比算法是应用最广泛的动态规划算法之一，主要应用\\n\\n在数字通信，语音识别，机器翻译，分词等领域，用于求解最优路径问题。\\n\\n条件随机场 CRF（Conditional Random Field）：主要用于分词标注，词性标注，命名实体\\n\\n识别等序列标注任务的无向图模型。\\n\\n带泄露修正线性单元 Leaky ReLU：ReLU 的变形，当输入为负数时也有输出值和梯度都不为\\n\\n0。\\n\\n指数线性单元 ELU(Exponential Linear Unit)：ReLU 的变形，当输入为负数时也有输出值\\n\\n和梯度都不为 0。\\n\\n扩展指数线性单元 SELU(Scaled Exponential Linear Unit)：ReLU 的变形，可以使得神经\\n\\n网络每一层的激活值都会满足均值接近于 0，标准差接近于 1 的正态分布。\\n\\n自归一化神经网络(Self-Normalizing Neural Networks)：简称为 SNN，表示使用了 SELU\\n\\n激活函数的网络。\\n\\nSNN：自归一化神经网络。\\n\\nAlpha Dropout：Alpha Dropout 是一种保持信号均值和方差不变的 Dropout，改层的作用\\n\\n是即使在 Dropout 的时候也保持数据的自规范性\\n\\n高斯误差线性单元 GELU(Gaussian Error Linear Unit)：BERT 模型中使用的激活函数。\\n\\nSwish：谷歌提出的一种较新的激活函数。\\n\\n第 17 章-音频信号处理\\n\\n709\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n自动语言识别(Automatic Speech Recognition)：简称 ASR，将人的语音转换为文本的技\\n\\n术。\\n\\n梅尔滤波器组（Mel Filter Banks）：模拟人耳听力特点设计出来的一组滤波器。\\n\\n梅尔频率倒谱系数 (Mel-frequency cepstral coefficients)：简称 MFCC，梅尔频谱进行离\\n\\n散余弦变换后得到的音频特征。\\n\\n模拟信号（Analog Signal）：连续变化的物理量表示的信号。\\n\\n数字信号（Digital Signal）：离散的数值信号。\\n\\n采样频率（Sampling frequency）：信号采集速率。\\n\\n量化位数（Quantization Bits）：对模拟信号进行数字化时的精度。\\n\\n傅里叶变换（Fourier Transform）：将时域（Time Domain）信号转换为频域（Frequency\\n\\nDomain）信号。\\n\\n离散傅里叶变换（Discrete Fourier Transform）：简称 DFT，对离散的数值信号进行的傅里\\n\\n叶变换。\\n\\n快速傅里叶变换（Fast Fourier Transform）：简称 FFT，FFT 是 DFT 的快速算法。\\n\\n短时傅里叶变换（short-term Fourier transform）：简称 STFT，将信号加上滑动时间窗，\\n\\n并对每个时间窗口内的数据进行 FFT 称为 STFT。\\n\\n时域（Time Domain）信号：表示信号强弱与时间的关系。\\n\\n频域（Frequency Domain）信号：表示信号强弱与频率的关系。\\n\\n频谱图（Spectrum）：一段时间内信号频率与强弱的关系图，可以通过傅里叶变换得到。\\n\\n声谱图（Spectrogram）：由一段时间内的多张频谱图组成。\\n\\n梅尔频谱（Mel Spectrogram）：声谱图经过梅尔滤波器组后得到梅尔频谱。\\n\\n共振峰（Formants）：语音的主要频率成分。\\n\\n710\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n包络（Spectral Envelope）：将所有共振峰连接起来的平滑曲线。\\n\\n包络细节（Spectral Details）:频谱曲线的高频信号。\\n\\n倒谱（Cepstrum）：对频谱图再做一次傅里叶变换后得到。\\n\\n伪频率（Pseudo-Frequency）：倒谱中的频率，并不是真正的音频信号的频率，它表示的是\\n\\n频谱图中波形的频率。\\n\\n离散余弦变换（Discrete Fourier Transform）：简称 DCT，DCT 类似于 DFT，DCT 只使用\\n\\n实数。\\n\\n第 18 章-图像风格转移\\n\\n格拉姆矩阵（Gram Matrix）：计算图像特征图的 Gram 矩阵可以用于表示图像的风格，具体\\n\\n计算见正文。\\n\\n第 19 章-生成对抗网络 GANs\\n\\n转置卷积（Transposed Convolution）：转置卷积又名反卷积（deconvolution）或是分数\\n\\n步长卷积（fractially straced convolutions）。是一种上采样操作，卷积后可以得到分辨率更\\n\\n大的图像。\\n\\n下采样（Subsampled）：通过某些操作增加图像的分辨率。\\n\\n上采样（Upsampling）：通过某些操作减小图片的分辨率。\\n\\n711\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n结束语\\n\\n这本书的内容暂时到这里就结束了，不过对于大家的人工智能之旅才刚刚开始。这本书\\n\\n的内容对大家来说只是一个起点，人工智能/深度学习领域还有更多更深入更有趣的技术和应\\n\\n用等待大家学习和发现。\\n\\n这本书对于我来说也只是一个新的起点，我之后还会不断更新更多人工智能相关的开源\\n\\n教程。本书涉及的代码和资料也可以到我的 Github 上查看和下载。\\n\\n本书主页，以及源代码，资料下载：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2\\n\\n免费学习人工智能的慕课平台 AI MOOC：\\n\\nhttps://mooc.ai-xlab.com\\n\\n提交错误或意见反馈可以到 Github Issues 页面提交：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2/issues\\n\\n我的 B 站主页：\\n\\nhttps://space.bilibili.com/390756902\\n\\n我的微信公众号：\\n\\nAI MOOC 人工智能平台\\n\\n联系邮箱：\\n\\nqinbf@ai-xlab.com\\n\\n712', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "loader1 = UnstructuredPDFLoader(\"深度学习从0到1-基于Tensorflow2.pdf\")#, mode=\"elements\")\n",
    "pages1 = loader1.load()\n",
    "pages1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80031dfe-808a-4278-b562-6d6f889f03f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:39:04.335532Z",
     "iopub.status.busy": "2023-11-30T06:39:04.335532Z",
     "iopub.status.idle": "2023-11-30T06:39:04.344545Z",
     "shell.execute_reply": "2023-11-30T06:39:04.344342Z",
     "shell.execute_reply.started": "2023-11-30T06:39:04.335532Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cddb828-feb2-4e68-9c63-0c32ec578308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:34:27.538394Z",
     "iopub.status.busy": "2023-11-30T06:34:27.538394Z",
     "iopub.status.idle": "2023-11-30T06:34:27.546034Z",
     "shell.execute_reply": "2023-11-30T06:34:27.545810Z",
     "shell.execute_reply.started": "2023-11-30T06:34:27.538394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages1[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fa3bf-b1a6-4e25-9883-7e9047bc14cd",
   "metadata": {},
   "source": [
    "## 使用mode=\"elements\"\n",
    "\n",
    "会按某种规则分割文档，metadata包含的信息更多\n",
    "\n",
    "观察category情况，分类并不准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db469e79-0da6-42ce-912b-6fdda2d3f1c3",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T06:34:36.864078Z",
     "iopub.status.busy": "2023-11-30T06:34:36.864078Z",
     "iopub.status.idle": "2023-11-30T06:35:31.596092Z",
     "shell.execute_reply": "2023-11-30T06:35:31.594936Z",
     "shell.execute_reply.started": "2023-11-30T06:34:36.864078Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'Title'}),\n",
       " Document(page_content='0', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 1, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='说明', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((272.08, 79.37104), (272.08, 105.29103999999995), (331.75239999999997, 105.29103999999995), (331.75239999999997, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='本电子书为书籍原稿的开源版本，基本上没有进行什么排版，纸质书籍估计要 2021 年 3', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 144.12400000000002), (54.279903999999995, 156.12400000000002), (539.4603999999999, 156.12400000000002), (539.4603999999999, 144.12400000000002)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='月后才能购买。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 176.764), (54.279903999999995, 188.764), (141.83190399999998, 188.764), (141.83190399999998, 176.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='本书虽然为开源电子书，但仅供个人学习使用。未经许可不能用于个人或企业的商业用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 209.404), (75.279904, 221.404), (531.28, 221.404), (531.28, 209.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='途，违法盗版和销售，必究其法律责任。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 242.04399999999998), (54.279903999999995, 254.04399999999998), (279.832, 254.04399999999998), (279.832, 242.04399999999998)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='本书主页，以及源代码，资料下载：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 274.6840000000001), (54.279903999999995, 286.6840000000001), (270.832, 286.6840000000001), (270.832, 274.6840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='https://github.com/Qinbf/Deep-Learning-Tensorflow2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 307.08400000000006), (75.279904, 319.08400000000006), (390.52144, 319.08400000000006), (390.52144, 307.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='本书配套免费视频教程可以到免费学习人工智能的慕课平台 AI MOOC 学习：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 339.72400000000005), (75.279904, 351.72400000000005), (487.66383999999994, 351.72400000000005), (487.66383999999994, 339.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'cddf58ecdc72ee2ad5a621beb9cd1159', 'page_number': 2, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='https://mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 372.36400000000003), (75.279904, 384.36400000000003), (223.300648, 384.36400000000003), (223.300648, 372.36400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='提交错误或意见反馈可以到 Github Issues 页面提交：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 405.004), (75.279904, 417.004), (365.81224, 417.004), (365.81224, 405.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='https://github.com/Qinbf/Deep-Learning-Tensorflow2/issues', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 437.644), (75.279904, 449.644), (429.70888, 449.644), (429.70888, 437.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='我的 B 站主页：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 470.28400000000005), (75.279904, 482.28400000000005), (164.36118399999995, 482.28400000000005), (164.36118399999995, 470.28400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '28220bdbd39913af407b6c2c1f8b0011', 'page_number': 2, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='https://space.bilibili.com/390756902', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 502.684), (75.279904, 514.684), (287.81824, 514.684), (287.81824, 502.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='我的微信公众号：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 535.3240000000001), (75.279904, 547.3240000000001), (174.83190399999998, 547.3240000000001), (174.83190399999998, 535.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='AI MOOC 人工智能平台', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 567.9639999999999), (75.279904, 579.9639999999999), (208.663936, 579.9639999999999), (208.663936, 567.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='联系邮箱：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 600.604), (75.279904, 612.604), (138.83190399999998, 612.604), (138.83190399999998, 600.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'Title'}),\n",
       " Document(page_content='qinbf@ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 633.244), (75.279904, 645.244), (187.663936, 645.244), (187.663936, 633.244)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'EmailAddress'}),\n",
       " Document(page_content='1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 2, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 3, 'category': 'Title'}),\n",
       " Document(page_content='本书谨献给我的妻子刘露斯，以及正在阅读此书的各位读者朋友。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (405.832, 381.48400000000004), (405.832, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 3, 'category': 'Title'}),\n",
       " Document(page_content='愿人工智能给我们带来更美好的未来。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (261.832, 413.884), (261.832, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 3, 'category': 'Title'}),\n",
       " Document(page_content='2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '3fc16fcd4a9276f3e903e0c0d949c1d0', 'page_number': 3, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='序言', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((272.08, 79.37104), (272.08, 105.29103999999995), (331.75239999999997, 105.29103999999995), (331.75239999999997, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='本书的由来', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 165.2449600000001), (54.279903999999995, 187.32496000000003), (170.81557600000002, 187.32496000000003), (170.81557600000002, 165.2449600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='本书的序言可能有点长，因为这是我和大家的第一次见面，我希望可以把关于我和这本书', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 209.404), (75.279904, 221.404), (541.880704, 221.404), (541.880704, 209.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='的故事讲清楚，让大家对我有一个更好的了解，说不定哪天我们会成为朋友。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 242.04399999999998), (54.279903999999995, 254.04399999999998), (465.832, 254.04399999999998), (465.832, 242.04399999999998)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='大约在 3 年前的某个下午，电子工业出版社的张迪编辑联系到我，让我写一本关于人工智', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 274.6840000000001), (75.279904, 286.6840000000001), (541.8810159999999, 286.6840000000001), (541.8810159999999, 274.6840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='能的书。第一次有人找我写书，不免还是有些小激动，想象中写书是一件很酷的事情，真正写', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 307.08400000000006), (54.279903999999995, 319.08400000000006), (541.8783040000001, 319.08400000000006), (541.8783040000001, 307.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='的时候才知道写书是一件很苦的事情。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 339.72400000000005), (54.279903999999995, 351.72400000000005), (261.832, 351.72400000000005), (261.832, 339.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='我毕业于上海大学物理系本科，大学期间做过很多嵌入式软硬件相关的开发项目。由于觉', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 372.36400000000003), (75.279904, 384.36400000000003), (541.8807039999999, 384.36400000000003), (541.8807039999999, 372.36400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用，所以我在大学校内开过', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 405.004), (54.279903999999995, 417.004), (541.879504, 417.004), (541.879504, 405.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='一年的嵌入式培训班，以更通俗易懂的方式和切合实际应用的内容给几百个本校同学（包括本', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 437.644), (54.279903999999995, 449.644), (541.8807039999999, 449.644), (541.8807039999999, 437.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='科/硕士/博士）上过课。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 470.28400000000005), (54.279903999999995, 482.28400000000005), (188.08580799999996, 482.28400000000005), (188.08580799999996, 470.28400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='我最早是从 2015 年开始接触人工智能技术，公司内部刚好需要开发人工智能相关的产品。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 502.684), (54.279903999999995, 514.684), (547.8795279999999, 514.684), (547.8795279999999, 502.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='当时谷歌的深度学习框架 Tensorflow 都还没有开源，我主要是学习了一些机器学习相关的算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 535.3240000000001), (54.279903999999995, 547.3240000000001), (541.8805600000001, 547.3240000000001), (541.8805600000001, 535.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='法和应用。随着 Tensorflow 在 2015 年 11 月开源，AlphaGo 在 2016 年 3 月战胜人类顶级', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 567.9639999999999), (54.279903999999995, 579.9639999999999), (541.8800799999999, 579.9639999999999), (541.8800799999999, 567.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='围棋选手，我知道新的人工智能的时代就要到来。2016 年我学习了当时最热门的两个深度学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 600.604), (54.279903999999995, 612.604), (541.8800799999999, 612.604), (541.8800799999999, 600.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='习框架 Tensorflow 和 Caffe 并用这两个框架完成了公司里面的一些深度学习项目。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 633.244), (54.279903999999995, 645.244), (498.92560000000003, 645.244), (498.92560000000003, 633.244)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='当时市面上关于深度学习的书籍和学习资料都非常少，所以在 2017 年的时候我录制了一', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 665.884), (54.279903999999995, 677.884), (541.8800799999999, 677.884), (541.8800799999999, 665.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='些深度学习相关的视频教程放到了网上，就有了后来出版社找我写书的故事。几乎每个月都会', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 698.284), (54.279903999999995, 710.284), (541.8807039999999, 710.284), (541.8807039999999, 698.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='有出版社的人联系我出书，我才知道原来获得出书的机会不难，真正难的是认真坚持把一本书', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 730.924), (54.279903999999995, 742.924), (541.880704, 742.924), (541.880704, 730.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 4, 'category': 'Title'}),\n",
       " Document(page_content='3', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'db8b176ddc4dcbf9f40482b5fd99d6d6', 'page_number': 4, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='给写完。这本书历时 3 年，不过也不是真的写了 3 年，写的过程中断断续续也暂停了很多次。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.87936, 87.96400000000006), (541.87936, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='我估算了一下真正写书的时间大概是用了 1200 个小时。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (355.98040000000003, 120.60400000000004), (355.98040000000003, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='最近两年我做了很多场人工智能的线下培训，给中国移动，中国电信，中国银行，华夏银', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.87888, 153.24400000000003), (541.87888, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='行，太平洋保险，国家电网，中海油，格力电器等企业以及多个研究所的科研人员和多个高校', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.8800799999999, 185.88400000000001), (541.8800799999999, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='的老师上过课，大家学完后的反馈基本上都是挺好的。虽然我这两年一直在从事人工智能的教', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (541.880704, 218.284), (541.880704, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='育培训工作，但是我也一直没有真正下定决心要做人工智能教育培训这件事。因为现如今人工', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (541.8807039999999, 250.9240000000001), (541.8807039999999, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='智能的各种学习资料已经很多了，网上也有各种人工智能专家大师的课程，这些专家大师基本', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (541.8807039999999, 283.5640000000001), (541.8807039999999, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='上都是博士，教授或来自名企。并且从课程的包装上看，内容还是不错的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (453.832, 316.20400000000006), (453.832, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='不过长期以来，我一直在关注人工智能技术和教育培训的发展。人工智能目前还处于高速', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (541.880704, 348.84400000000005), (541.880704, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (541.8800799999999, 381.48400000000004), (541.8800799999999, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='令人满意，还存在着许多问题。这些问题并不是几个专家大师所能解决的，而是需要更多人的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (541.880704, 413.884), (541.880704, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='努力和付出。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (129.83190399999998, 446.524), (129.83190399999998, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='人工智能教育是一件很有意义的事情，因为它有可能关乎国家，甚至人类的未来。尽管将', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 467.16400000000004), (75.279904, 479.16400000000004), (541.879504, 479.16400000000004), (541.879504, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='会面临无数困难，我还是决定加入其中，以这本书作为开始。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (381.832, 511.80400000000003), (381.832, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 569.88496), (54.279903999999995, 591.96496), (386.84104, 591.96496), (386.84104, 569.88496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='AI MOOC 是我自己创办的一个免费的人工智能慕课平台，网站地址为 https://mooc.ai-', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 613.8040000000001), (78.279904, 625.8040000000001), (541.88464, 625.8040000000001), (541.88464, 613.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='xlab.com。以后我会在上面不断更新最新的人工智能课程。我的目标是让所有人都能有机会', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 646.444), (54.279903999999995, 658.444), (541.17088, 658.444), (541.17088, 646.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='学习到最前沿最好的人工智能课程。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 679.0840000000001), (54.279903999999995, 691.0840000000001), (249.83190399999998, 691.0840000000001), (249.83190399999998, 679.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='如果大家觉得我创作的内容不错，可以帮我多多宣传，感谢。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 711.724), (75.279904, 723.724), (402.832, 723.724), (402.832, 711.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'Title'}),\n",
       " Document(page_content='4', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1549f1e267af8a5f57cb3567a216b05d', 'page_number': 5, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='人工智能的学习', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 80.76496000000009), (54.279903999999995, 102.84496000000001), (214.81559199999998, 102.84496000000001), (214.81559199999998, 80.76496000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='这里想跟大家简单聊一下关于人工智能的学习，人工智能是一门需要“内外兼修”的学科，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 124.92400000000009), (75.279904, 136.9240000000001), (541.880704, 136.9240000000001), (541.880704, 124.92400000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='既要修炼外功招式，又要进行内功修行。这里的外功招式主要指的是使用编程语言去实现一些', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 157.56400000000008), (54.279903999999995, 169.56400000000008), (541.880704, 169.56400000000008), (541.880704, 157.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 189.96400000000006), (54.279903999999995, 201.96400000000006), (465.832, 201.96400000000006), (465.832, 189.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='很多时候武功招式是很容易学的，可以短时间内快速提升，但同时也很容易达到一定的上', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 222.60400000000004), (75.279904, 234.60400000000004), (541.880704, 234.60400000000004), (541.880704, 222.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='限。如果想要突破上限更进一步，就要把内功给修炼好。所以我们在学习人工智能相关技术的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 255.24400000000003), (54.279903999999995, 267.244), (541.880704, 267.244), (541.880704, 255.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='时候，尽量把相关算法理论理解清楚，同时要多写代码提高编程能力，并在实践过程中加深对', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 287.884), (54.279903999999995, 299.884), (541.880704, 299.884), (541.880704, 287.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='算法的理解。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 320.524), (54.279903999999995, 332.524), (129.83190399999998, 332.524), (129.83190399999998, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='本书的特色', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 390.36496), (54.279903999999995, 412.44496000000004), (170.81557600000002, 412.44496000000004), (170.81557600000002, 390.36496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='本书的脉络框架主要是根据深度学习知识由浅入深的发展来编写的，对于 Tensorflow 的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 434.524), (75.279904, 446.524), (541.8800799999999, 446.524), (541.8800799999999, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='使用技巧基本上不会单独讲解，而是会结合深度学习理论知识或实际应用案例来讲解。所以很', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (541.8807039999999, 479.16400000000004), (541.8807039999999, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='多 Tensorflow 的使用技巧在目录上可能没有得到很好的体现，这些 Tensorflow 使用技巧的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (541.8800799999999, 511.80400000000003), (541.8800799999999, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='彩蛋在书里的程序中等着大家发现哦！相信大家看完这本书以后就可以熟练掌握 Tensorflow', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (541.87288, 544.444), (541.87288, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='的使用了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (117.83190399999998, 577.0840000000001), (117.83190399999998, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='本书是一本“内外兼修”的书，既包含详细的算法理论的介绍，又包括详细的代码讲解。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 597.484), (75.279904, 609.484), (545.5827040000001, 609.484), (545.5827040000001, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='我一直在思考人工智能技术的教学方式，所以也形成了自己的教学风格和对教育的理解。这一', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (541.88032, 642.124), (541.88032, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='套方式方法收到过很多同学的积极反馈，但也不一定适合所有人。我觉得不同的教学风格就像', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 662.764), (54.279903999999995, 674.764), (541.880704, 674.764), (541.880704, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='是不同类型的音乐，每个人喜欢的音乐类型可能都会不一样。AI 教育的发展需要各种类型的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (541.58104, 707.404), (541.58104, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='教学方式百花齐放。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (165.83190399999998, 740.044), (165.83190399999998, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='本书的主要特色总结如下：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 760.684), (75.279904, 772.684), (222.83190399999998, 772.684), (222.83190399999998, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 6, 'category': 'Title'}),\n",
       " Document(page_content='5', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '034ba6a81bf9fdefec7d0bc14815873f', 'page_number': 6, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='一.所有公式推导都有详细步骤，并解释每个符号。数学公式是算法的根本，要理解算法的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 76.20400000000006), (75.279904, 88.20400000000006), (541.88008, 88.20400000000006), (541.88008, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='本质就要理解数学公式的含义，所以掌握一些基础的深度学习相关的数学内容也是很重要的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (546.6759040000001, 120.60400000000004), (546.6759040000001, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='大家看到数学一般都会比较头疼，所以本书中所有数学公式都会列出详细推导步骤，并解释每', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.8807039999999, 153.24400000000003), (541.8807039999999, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='个相关符号的含义，帮助大家理解。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (249.83190399999998, 185.88400000000001), (249.83190399999998, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='二.注释每一行代码。我一直觉得我在教学中使用的代码具有一定个人风格，代码逻辑结构', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 206.524), (75.279904, 218.524), (541.879408, 218.524), (541.879408, 206.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='清晰，程序在容易理解的基础上尽量精简，最大的特点可能就是注释比代码多。我给这种代码', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (541.880704, 250.9240000000001), (541.880704, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.804), (54.279903999999995, 283.804), (541.8808, 283.804), (541.8808, 271.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='对于初学者而言，最好是可以理解每一行代码，每个函数，函数中所使用的每个参数，这样学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.8783040000001, 316.20400000000006), (541.8783040000001, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='习会感觉比较扎实。所以本书中所有代码都是全注释代码。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (369.832, 348.84400000000005), (369.832, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='三. 程序皆为完整程序。本书一共 82 个代码应用案例，所有的代码都是可以从头到尾运', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 369.72400000000005), (75.279904, 381.72400000000005), (541.8800799999999, 381.72400000000005), (541.8800799999999, 369.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='行的完整程序，并附带真实运行结果，不存在程序片段样例。我觉得程序片段对于初学者的学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (541.8800799999999, 413.884), (541.8800799999999, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='习不太友好，大家拿到一个程序片段往往还是不知道如何使用，或者用起来的时候出现很多错', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (541.880704, 446.524), (541.880704, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='误，所以我在书中使用的所有程序都是可以从头到尾直接运行的完整程序。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (453.832, 479.16400000000004), (453.832, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='四.一图胜千言。深度学习中很多模型结构，计算流程之类的内容很难用公式或者语言表达', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 500.04400000000004), (75.279904, 512.0440000000001), (541.879408, 512.0440000000001), (541.879408, 500.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='清楚，但往往一张好的图片就可以说明一切。本书一共使用了约 500 张图片，在本书的创作', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (541.8800799999999, 544.444), (541.8800799999999, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='过程中，大约有 200 个小时是花在画图以及思考如何画图上。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (384.94311999999996, 577.0840000000001), (384.94311999999996, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='五.逻辑结构清晰，讲解细致。这个不需要多介绍，大家看的时候就知道了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 597.724), (75.279904, 609.724), (478.25967999999995, 609.724), (478.25967999999995, 597.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='勘误和支持', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 667.56496), (54.279903999999995, 689.6449600000001), (170.81557600000002, 689.6449600000001), (170.81557600000002, 667.56496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 7, 'category': 'Title'}),\n",
       " Document(page_content='6', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '4546e66d0fcd9adcf25e1e3cefca64fa', 'page_number': 7, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='7', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 8, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='本书很多思想和知识体系都是我基于自己的理解建立的，由于本人水平有限，本书一定存', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (541.8807039999999, 87.96400000000006), (541.8807039999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='在不少理解不当或者不准确的地方，恳请大家批评指正。如果大家有更多宝贵意见，欢迎发送', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.8800799999999, 120.60400000000004), (541.8800799999999, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='邮件至邮箱 qinbf@ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (229.59947200000002, 153.24400000000003), (229.59947200000002, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c81784df2d154049a8e93926cd1797db', 'page_number': 8, 'category': 'NarrativeText'}),\n",
       " Document(page_content='， 或 者 到 我 的 Github 留言 ： https://github.com/Qinbf/Deep-Learning-', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.88464, 185.88400000000001), (541.88464, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='Tensorflow2/issues。期待大家的真挚反馈和支持。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (334.27144, 218.284), (334.27144, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='致谢', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 276.36496), (54.279903999999995, 298.4449599999999), (104.815576, 298.4449599999999), (104.815576, 276.36496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='在本书的撰写和研究期间，感谢我的妻子刘露斯对我的支持和鼓励。感谢我的朋友王惠东', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 320.524), (75.279904, 332.524), (541.880704, 332.524), (541.880704, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='对本书部分章节的校阅。感谢电子工业出版社张迪编辑的耐心等待，感谢出版社对本书的耐心', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 353.16400000000004), (54.279903999999995, 365.16400000000004), (541.880704, 365.16400000000004), (541.880704, 353.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='修订和整理。最后感谢各位读者朋友选择了这本书，感谢大家的信任。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 385.564), (54.279903999999995, 397.564), (429.832, 397.564), (429.832, 385.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='覃秉丰', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((505.88007999999996, 450.84400000000005), (505.88007999999996, 462.84400000000005), (545.4320799999999, 462.84400000000005), (545.4320799999999, 450.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='2020 年 9 月于上海', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((437.6944, 483.48400000000004), (437.6944, 495.48400000000004), (545.4320799999999, 495.48400000000004), (545.4320799999999, 483.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 8, 'category': 'Title'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 9, 'category': 'Title'}),\n",
       " Document(page_content='目录', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((272.08, 79.37104), (272.08, 105.29103999999995), (331.75239999999997, 105.29103999999995), (331.75239999999997, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 9, 'category': 'Title'}),\n",
       " Document(page_content='前言 第 1 章 深度学习背景介绍 1.1 人工智能 1.2 机器学习 1.2.1 训练数据，验证数据和测试数据 1.2.2 学习方式 1.2.3 机器学习常用算法 1.3 人工智能，机器学习，神经网络以及深度学习之间的关系 1.4 深度学习应用 1.5 神经网络深度学习发展史 1.5.1 神经网络诞生-20 时间 40-60 年代 1.5.2 神经网络复兴-20 时间 80-90 年代 1.5.3 深度学习-2006 年至今 1.6 深度学习领域重要人物 1.7 新一轮人工智能爆发的三要素', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 118.08400000000006), (54.279903999999995, 358.324), (408.84328, 358.324), (408.84328, 118.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '52daa71ebc31058156b21dc21c01ed18', 'page_number': 9, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 2 章 搭建 Python 编程环境 2.1 Python 介绍 2.2 Anaconda 安装 2.3 Jupyter Notebook 的简单使用 2.3.1 启动 Jupyter Notebook 2.3.2 修改 Jupyter Notebook 默认启动路径 2.3.3 Jupyter Notebook 浏览器无法打开 2.3.4 Jupyter Notebook 基本操作', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 378.96400000000006), (54.279903999999995, 504.964), (336.2104, 504.964), (336.2104, 378.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '52daa71ebc31058156b21dc21c01ed18', 'page_number': 9, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='第 3 章 单层感知器与线性神经网络 3.1 生物神经网络 3.2 单层感知器 3.2.1 单层感知器介绍 3.2.2 单层感知器计算举例 3.2.3 单层感知器的另一种表达形式 3.3 单层感知器的学习规则 3.3.1 单层感知器的学习规则介绍 3.3.2 单层感知器的学习规则计算举例 3.4 学习率 3.5 模型的收敛条件 3.6 模型的超参数和参数的区别 3.7 单层感知器分类案例 3.8 线性神经网络 3.8.1 线性神经网络介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 525.604), (54.279903999999995, 765.844), (309.79648, 765.844), (309.79648, 525.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '52daa71ebc31058156b21dc21c01ed18', 'page_number': 9, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='8', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '52daa71ebc31058156b21dc21c01ed18', 'page_number': 9, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 3.8.2 线性神经网络分类案例 3.9 线性神经网络处理异或问题', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 94.56400000000008), (334.96816, 94.56400000000008), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 10, 'category': 'Title'}),\n",
       " Document(page_content='第 4 章 单层感知器与线性神经网络 4.1 BP 神经网络介绍及发展背景 4.2 代价函数 4.3 梯度下降法 4.3.1 梯度下降法（Gradient Descent）介绍 4.3.2 梯度下降法（Gradient Descent）二维例子 4.3.3 梯度下降法（Gradient Descent）三维例子 4.4 Delta 学习规则 4.5 常用激活函数讲解 4.5.1 Sigmoid 函数 4.5.2 Tanh 函数 4.5.3 Softsign 函数 4.5.4 ReLU 函数 4.6 BP 网络模型和公式推导 4.6.1 BP 网络模型 4.6.2 BP 算法推导 4.6.3 BP 算法推导补充说明 4.7 BP 算法推导结论总结 4.8 梯度消失与梯度爆炸 4.8.1 梯度消失 4.8.2 梯度爆炸 4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题 4.9 使用 BP 神经网络解决异或问题 4.10 分类模型评估方法 4.10.1 准确率/精确率/召回率/F1 值 4.10.2 混淆矩阵 4.11 独热编码（One-Hot Encoding） 4.12 BP 神经网络完成手写数字识别 4.13 Sklearn 手写数字识别', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 115.20400000000006), (54.279903999999995, 583.444), (390.46239999999995, 583.444), (390.46239999999995, 115.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 10, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 5 章 深度学习框架 Tensorflow 基础使用 5.1 Tensorflow 介绍 5.1.1 Tensorflow 简介 5.1.2 静态图和动态图机制 Eager Execution 5.1.3 tf.keras 5.2 Tensorflow-cpu 安装 5.2.1 Tensorflow-cpu 在线安装 5.2.2 安装过程中可能遇到的问题汇总 5.2.3 Tensorflow-cpu 卸载 5.2.4 Tensorflow-cpu 更新', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 604.0840000000001), (54.279903999999995, 762.724), (334.75744, 762.724), (334.75744, 604.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 10, 'category': 'NarrativeText'}),\n",
       " Document(page_content='9', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((535.01248, 48.964000000000055), (535.01248, 61.32400000000007), (545.3377599999999, 61.32400000000007), (545.3377599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 10, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 5.2.5 Tensorflow-cpu 指定版本的安装 5.3 Tensorflow-gpu 安装 5.3.1 Tensorflow-gpu 了解最新版本情况 5.3.2 Tensorflow-gpu 安装 CUDA 5.3.3 Tensorflow-gpu 安装 cuDNN 库 5.3.4 Tensorflow-gpu 在线安装 5.3.5 Tensorflow-gpu 卸载 5.3.6 Tensorflow-gpu 更新 5.4 Tensorflow 基本概念 5.5 Tensorflow 基础使用 5.5.1 TF1 转 TF2 工具 5.5.2 Tensorflow 基本操作 5.5.3 拟合线性函数 5.5.4 拟合非线性函数 5.6 手写数字图片分类任务 5.6.1 MNIST 数据集介绍 5.6.2 Softmax 函数介绍 5.6.3 简单 MNIST 数据集分类模型-没有高级封装 5.6.4 简单 MNIST 数据集分类模型-keras 高级封装', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 371.524), (374.02696, 371.524), (374.02696, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 11, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 6 章 网络优化方法 6.1 交叉熵代价函数 6.1.1 均方差代价函数的缺点 6.1.2 引入交叉熵代价函数 6.1.3 交叉熵代价函数推导过程 6.1.4 Softmax 与对数似然代价函数 6.1.5 交叉熵程序 6.2 过拟合（Over-Fitting） 6.2.1 什么是过拟合 6.2.2 抵抗过拟合的方法 6.3 数据增强（Data Augmentation） 6.4 提前停止训练（Early-Stopping） 6.5 Dropout 6.5.1 Dropout 介绍 6.5.2 Dropout 程序 6.6 正则化（Regularization） 6.6.1 正则化介绍 6.6.2 正则化程序 6.7 标签平滑（Label Smoothing） 6.7.1 标签平滑（Label Smoothing）介绍 6.7.2 标签平滑（Label Smoothing）程序 6.8 优化器（Optimizer） 6.8.1 梯度下降法 SGD', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 392.164), (54.279903999999995, 762.724), (325.01895999999994, 762.724), (325.01895999999994, 392.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 11, 'category': 'NarrativeText'}),\n",
       " Document(page_content='10', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 11, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 6.8.2 Momentum 6.8.3 NAG（Nesterov Accelerated Gradient） 6.8.4 Adagrad 6.8.5 Adadelta 6.8.6 RMRprop 6.8.7 Adam 6.8.8 优化器程序', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 175.92399999999998), (347.97616, 175.92399999999998), (347.97616, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 12, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='第 7 章 Tensorflow 模型的保存和载入 7.1 交叉熵代价函数 7.1.1 Keras 保存模型 7.1.2 Keras 载入模型 7.2 SavedModel 模型保存和载入 7.2.1 SavedModel 保存模型 7.2.2 SavedModel 载入模型 7.3 单独保存模型结构 7.3.1 保存模型结构 7.3.2 载入模型结构 7.4 单独保存模型参数 7.4.1 保存模型参数 7.4.2 载入模型参数 7.5 ModelCheckpoint 自动保存模型 7.6 Checkpoint 模型保存和载入 7.6.1 Checkpoint 模型保存 7.6.2 Checkpoint 模型载入', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 196.56400000000008), (54.279903999999995, 469.444), (274.99168, 469.444), (274.99168, 196.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 12, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 8 章 卷积神经网络 CNN 8.1 计算机视觉介绍 8.1.1 计算机视觉应用介绍 8.1.2 计算机视觉技术介绍 8.2 卷积神经网络简介 8.2.1 BP 神经网络存在的问题 8.2.2 局部感受野和权值共享 8.3 卷积的具体计算 8.4 卷积的步长 8.5 不同的卷积核 8.6 池化（Pooling） 8.7 Padding 8.8 常见的卷积计算总结 8.8.1 对 1 张图像进行卷积生成 1 张特征图 8.8.2 对 1 张图像进行卷积生成多张特征图 8.8.3 对多张图像进行卷积生成 1 张特征图 8.8.4 对多张图像进行卷积生成多张特征图', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 490.084), (54.279903999999995, 762.724), (334.44088, 762.724), (334.44088, 490.084)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 12, 'category': 'NarrativeText'}),\n",
       " Document(page_content='11', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 12, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 8.9 经典的卷积神经网络 8.10 卷积神经网络应用于 MNIST 数据集分类 8.11 识别自己写的数字图片 8.12CIFAR-10 数据集分类', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 127.20400000000006), (334.96816, 127.20400000000006), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 13, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='第 9 章 序列模型 9.1 序列模型应用 9.2 循环神经网络 RNN 9.2.1 循环神经网络介绍 9.2.2 Elman network 和 Jordan network 9.3 RNN 的不同架构 9.3.1 一对一架构 9.3.2 多对一架构 9.3.3 多对多架构 9.3.4 一对多架构 9.3.5 Seq2Seq 架构 9.4 传统 RNN 的缺点 9.5 长短时记忆网络 LSTM 9.6 Peephole LSTM 和 FC-LSTM 9.6.1 Peephole LSTM 介绍 9.6.2 FC-LSTM 介绍 9.7 其他 RNN 模型 9.7.1 门控循环单元 GRU 9.7.2 双向 RNN（Bidirectional RNN） 9.7.3 Stacked Bidirectional RNN 9.8 LSTM 网络应用于 MNIST 数据集分类', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 147.84400000000005), (54.279903999999995, 485.764), (315.46816, 485.764), (315.46816, 147.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 13, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 10 章 经典图像识别模型介绍（上） 10.1 图像数据集 ImageNet 10.1.1 ImageNet 介绍 10.1.2 李飞飞简介 10.1.3 ImageNet 的深远影响 10.1.4 ImageNet Challenge 历年优秀作品 10.2 AlexNet 10.3 VGGNet 10.4 GoogleNet 10.4.1 1×1 卷积介绍 10.4.2 Inception 结构 10.4.3 GoogleNet 网络结构 10.5 Batch Normalization 10.5.1 Batch Normalization 提出背景 10.5.2 数据标准化（Normalization） 10.5.3 Batch Normalization 模型训练阶段', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 506.404), (54.279903999999995, 762.724), (328.49944, 762.724), (328.49944, 506.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 13, 'category': 'NarrativeText'}),\n",
       " Document(page_content='12', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 13, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 10.5.4 Batch Normalization 模型预测阶段 10.5.5 Batch Normalization 作用分析 10.6 ResNet 10.6.1 ResNet 背景介绍 10.6.2 残差块（Residual Block）介绍 10.6.3 ResNet 网络介绍 10.6.4 ResNet-V2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 175.92399999999998), (334.96816, 175.92399999999998), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 14, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 11 章 经典图像识别模型介绍（下） 11.1 Inception 模型系列 11.1.1 Inception-v2/v3 优化策略 11.1.2 Inception-v2/v3 模型结构 11.1.3 Inception-v4 和 Inception-ResNet 介绍 11.2 ResNeXt 11.2.1 分组卷积（Group Convolution）介绍 11.2.2 ResNeXt 中的分组卷积 11.2.3 ResNeXt 的网络结构 11.3 SENet 11.3.1 SENet 介绍 11.3.2 SENet 结果分析', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 196.56400000000008), (54.279903999999995, 387.84400000000005), (349.76895999999994, 387.84400000000005), (349.76895999999994, 196.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 14, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 12 章 图像识别项目实战 12.1 图像数据准备 12.1.1 数据集介绍 12.1.2 数据集准备 12.1.3 切分数据集程序 12.2 AlexNet 图像识别 12.3 VGGNet 图像识别 12.4 函数式（functional）模型 12.4.1 函数式（functional）模型介绍 12.4.2 使用函数式模型进行 MNIST 图像识别 12.5 模型可视化 plot_model 12.5.1 使用 plot_model 进行模型可视化 12.5.2 plot_model 升级版 12.6 GoolgeNet 图像识别 12.7 Batch Normalization 使用 12.8 ResNet 图像识别 12.9 ResNeXt 图像识别 12.10 SENet 图像识别 12.11 使用预训练模型进行迁移学习 12.11.1 使用训练好的模型进行图像识别 12.11.2 使用训练好的模型进行迁移学习 12.11.3 载入训练好的模型进行预测', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 408.48400000000004), (54.279903999999995, 762.724), (344.58928, 762.724), (344.58928, 408.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 14, 'category': 'NarrativeText'}),\n",
       " Document(page_content='13', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '985199b626a7eff4b55345aa97808c31', 'page_number': 14, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 15, 'category': 'Title'}),\n",
       " Document(page_content='第 13 章 验证码识别项目实战 13.1 多任务学习介绍 13.2 验证码数据集生成 13.3 tf.data 介绍 13.4 使用 tf.data 完成多任务学习-验证码识别 13.4.1 使用 tf.data 完成多任务学习模型训练 13.4.2 使用 tf.data 完成多任务学习模型预测 13.5 使用自定义数据生成器完成验证码识别 13.5.1 使用自定义数据生成器完成模型训练 13.5.2 使用自定义数据生成器完成模型预测 13.6 挑战变长验证码识别 13.6.1 挑战变长验证码识别模型训练 13.6.2 挑战变长验证码识别模型预测 13.7 CTC 算法 13.7.1 CTC 算法介绍 13.7.2 贪心算法（Greedy Search）和集束搜索算法（Beam Search） 13.7.3 CTC 存在的问题 13.8 CTC 算法-验证码识别 13.8.1 使用 CTC 算法训练验证码模型 13.8.2 使用 CTC 算法训练验证码预测', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 82.56400000000008), (54.279903999999995, 404.164), (469.58752, 404.164), (469.58752, 82.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 15, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 14 章 自然语言处理 NLP 发展历程（上） 14.1 多任务学习介绍 14.1.1 文本分类/情感分类 14.1.2 分词标注 14.1.3 机器翻译 14.1.4 聊天机器人 14.1.5 自动摘要 14.1.6 文章生成 14.1.7 图片描述 14.2 从传统语言模型到神经语言模型 14.2.1 规则模型 14.2.2 统计语言模型 14.2.3 词向量（word embedding） 14.2.4 神经语言模型 14.3 word2vec 14.3.1 word2vec 介绍 14.3.2 word2vec 模型训练 14.3.3 word2vec 训练 trick 和可视化效果 14.4 CNN 在 NLP 领域的使用 14.5 RNN 在 NLP 领域的使用 14.5.1 使用 RNN 进行文本分类', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 424.804), (54.279903999999995, 762.724), (324.49768, 762.724), (324.49768, 424.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 15, 'category': 'NarrativeText'}),\n",
       " Document(page_content='14', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 15, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 14.5.2 使用 RNN 进行中文分词标注 14.6 Seq2Seq 模型在 NLP 领域的使用 14.7 Attention 机制 14.7.1 Attention 思想的介绍 14.7.2 Bahdanau Attention 介绍 14.7.3 Luong Attention 介绍 14.7.4 谷歌机器翻译系统 GNMT 介绍 14.7.5 Attention 机制在视觉和语音领域的应用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 192.24400000000003), (355.13032, 192.24400000000003), (355.13032, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 16, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 15 章 自然语言处理 NLP 发展历程（下） 15.1 NLP 新的开始-Transformer 模型 15.1.1 Transformer 模型结构和输入数据介绍 15.1.2 Self-Attention 介绍 15.1.3 Multi-Head Attention 介绍 15.1.4 Layer Normalization 介绍 15.1.5 Decoder 结构介绍 15.1.6 Decoder 中的 Multi-Head Attention 和模型训练 15.2 BERT 模型 15.2.1 BERT 模型介绍 15.2.2 BERT 模型训练 15.2.3 BERT 模型应用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 212.88400000000001), (54.279903999999995, 404.164), (395.82375999999994, 404.164), (395.82375999999994, 212.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 16, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 16 章 NLP 任务项目实战 16.1 Python 介绍 16.1.1 项目数据和模型说明 16.1.2 一维卷积英语电影评论情感分类程序 16.2 二维卷积中文微博情感分类项目 16.3 双向 LSTM 中文微博情感分类项目 16.4 堆叠双向 LSTM 中文分词标注项目 16.4.1 中文分词标注模型训练 16.4.2 维特比算法（Viterbi Algorithm） 16.4.3 中文分词标注模型预测 16.5 最新的一些激活函数介绍 16.5.1 Leaky ReLU 16.5.2 ELU 16.5.3 SELU 16.5.4 GELU 16.5.5 Swish 16.6 BERT 模型简单使用 16.6.1 安装 tf2-bert 模块并准备预训练模型 16.6.2 使用 BERT 进行文本特征提取 16.6.3 使用 BERT 进行完形填空 16.7 BERT 电商用户多情绪判断项目', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 424.804), (54.279903999999995, 762.724), (340.11856, 762.724), (340.11856, 424.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 16, 'category': 'NarrativeText'}),\n",
       " Document(page_content='15', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 16, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 16.7.1 项目背景介绍 16.7.2 模型训练 16.7.3 模型预测', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 110.88400000000001), (334.96816, 110.88400000000001), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 17, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 17 章 音频信号处理 17.1 深度学习在声音领域的应用介绍 17.1.1 音频分类 17.1.2 音频事件检测 17.1.3 语音识别 17.1.4 音乐检索 17.1.5 音乐生成 17.1.6 语音合成 17.1.7 语音克隆 17.2 MFCC 和 Mel Filter Banks 17.2.1 音频数据采集 17.2.2 分帧加窗 17.2.3 傅里叶变换 17.2.4 梅尔滤波器（Mel Filter Banks） 17.2.5 梅尔频率倒谱系数 MFCC 17.3 语音分类项目 17.3.1 音频处理库 librosa 介绍 17.3.2 音频分类项目-模型训练 17.3.3 音频分类项目-模型预测', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 131.524), (54.279903999999995, 436.804), (312.89008, 436.804), (312.89008, 131.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 17, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 18 章 图像风格转换 18.1 图像风格转换实现原理 18.1.1 代价函数的定义 18.1.2 格拉姆矩阵（Gram Matrix）介绍 18.2 图像风格转换项目实战 18.3 遮挡图像风格转换项目实战', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 457.444), (54.279903999999995, 551.044), (319.94488, 551.044), (319.94488, 457.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 17, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 19 章 生成对抗网络 GANs 19.1 生成对抗网络的应用 19.1.1 图像生成 19.1.2 向量空间运算 19.1.3 改变年龄或美颜 19.1.4 图像转换 19.1.5 文本转图像 19.1.6 超分辨率 19.1.7 换脸 19.2 DCGAN 介绍 19.2.1 DCGAN 原理 19.2.2 转置卷积（Transposed Convolution）介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 571.444), (54.279903999999995, 762.724), (369.53272, 762.724), (369.53272, 571.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 17, 'category': 'NarrativeText'}),\n",
       " Document(page_content='16', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 17, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 19.2.3 DCGAN 模型结构 19.3 手写数字图像生成', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 94.56400000000008), (334.96816, 94.56400000000008), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 18, 'category': 'NarrativeText'}),\n",
       " Document(page_content='第 20 章 模型部署 20.1 Tensorflow Serving 环境部署 20.1.1 安装 Docker 20.1.2 拉取 Tensorflow Serving 镜像 20.2 运行客户端和服务器程序 20.2.1 准备 SavedModel 模型 20.2.2 启动 Tensorflow Serving 服务器程序 20.2.3 Tensorflow Serving 客户端 gRPC 程序 20.2.4 Tensorflow Serving 客户端 REST API 程序', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 115.20400000000006), (54.279903999999995, 257.524), (360.7084, 257.524), (360.7084, 115.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 18, 'category': 'NarrativeText'}),\n",
       " Document(page_content='专业术语汇总 结束语', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 278.164), (54.279903999999995, 306.48400000000004), (129.567904, 306.48400000000004), (129.567904, 278.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 18, 'category': 'Title'}),\n",
       " Document(page_content='17', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ab95918395ec9e6d5e18b2420f7e13dd', 'page_number': 18, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='第 1 章-深度学习背景介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((148.332376, 79.37104), (148.332376, 105.29103999999995), (455.49976, 105.29103999999995), (455.49976, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='本章主要介绍人工智能，机器学习，神经网络，深度学习相关的一些概念，应用，发展史', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 127.80400000000009), (78.279904, 139.8040000000001), (541.881904, 139.8040000000001), (541.881904, 127.80400000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='以及重要人物等背景信息。这些背景知识虽然对我们的实际应用没有直接帮助，但是可以加深', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 160.44400000000007), (54.279903999999995, 172.44400000000007), (541.8807039999999, 172.44400000000007), (541.8807039999999, 160.44400000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='我们对人工智能这个行业的理解，属于内功修行的范畴。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 193.08400000000006), (54.279903999999995, 205.08400000000006), (357.832, 205.08400000000006), (357.832, 193.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='1.1 人工智能', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 279.96496), (98.279896, 302.04495999999995), (234.9142, 302.04495999999995), (234.9142, 279.96496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='1997 年 5 月 3 日-1997 年 5 月 11 日一场别开生面的比赛在纽约的公平大厦举行，吸引', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 340.684), (78.279904, 352.684), (541.8800799999999, 352.684), (541.8800799999999, 340.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='了全世界的关注。对垒的双方分别是世界国际象棋冠军卡斯帕罗夫和 IBM 的超级计算机“深', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 372.96400000000006), (54.279903999999995, 385.32400000000007), (541.8800799999999, 385.32400000000007), (541.8800799999999, 372.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='蓝”。经过六场激烈的比赛，“深蓝”最终战胜了卡斯帕罗夫，赢得了具有特殊意义的胜利。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 405.60400000000004), (54.279903999999995, 417.96400000000006), (547.07872, 417.96400000000006), (547.07872, 405.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='而这一次比赛也载入了人类的史册。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 438.004), (54.279903999999995, 450.36400000000003), (249.567904, 450.36400000000003), (249.567904, 438.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='而另一场可以载入人类史册的人机大战发生在 2016 年 3 月 9 日-2016 年 3 月 15 日。这', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 471.004), (78.279904, 483.004), (541.8800799999999, 483.004), (541.8800799999999, 471.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='一次比赛双方是世界顶级围棋棋手李世石和 Google 的人工智能 AlphaGo。赛前有很多人并', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 503.644), (54.279903999999995, 515.644), (541.8800799999999, 515.644), (541.8800799999999, 503.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='不看好 AlphaGo，认为 AlphaGo 会惨败。没想到 AlphaGo 最终以 4:1 大胜李世石，从而一', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 536.2840000000001), (54.279903999999995, 548.2840000000001), (541.8800799999999, 548.2840000000001), (541.8800799999999, 536.2840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '7fd3c2b4e436d3b130ecc099a68786a7', 'page_number': 19, 'category': 'NarrativeText'}),\n",
       " Document(page_content='战成名。由于 AlphaGo 的胜利，AlphaGo 用到的深度学习（Deep Learning）技术以及人', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 569.164), (54.279903999999995, 581.164), (541.8800799999999, 581.164), (541.8800799999999, 569.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='工智能（Artificial Intelligence）也成为了当下最热门的技术话题。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 601.8040000000001), (54.279903999999995, 613.8040000000001), (423.322, 613.8040000000001), (423.322, 601.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='人工智能（Artificial Intelligence），英文缩写 AI。AI 第一次被提出来是在 1956 年，是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 633.9639999999999), (75.279904, 645.9639999999999), (541.8800799999999, 645.9639999999999), (541.8800799999999, 633.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议 （Dartmouth', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 666.604), (54.279903999999995, 678.604), (545.4313599999999, 678.604), (545.4313599999999, 666.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='Conference）上一同定义出来的。人工智能只是一个抽象概念，它不是任何具体的机器或算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 699.244), (54.279903999999995, 711.244), (541.08616, 711.244), (541.08616, 699.244)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。比如几年前我们', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 731.884), (54.279903999999995, 743.884), (541.8807039999999, 743.884), (541.8807039999999, 731.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='去洗车的时候会看到洗车店写着自动化洗车，看起来很高级。今天我们再去看，可能它改成了', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 764.524), (54.279903999999995, 776.524), (541.880704, 776.524), (541.880704, 764.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 19, 'category': 'Title'}),\n",
       " Document(page_content='18', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ebe19f4063353b174618fe13a89f43cb', 'page_number': 19, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='人工智能洗车，看起来更高级。实际上它的技术并没有改变，只是改了一个名字。随着人工智', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.8783040000001, 87.96400000000006), (541.8783040000001, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='能技术的大热，很多商品都挂上了人工智能的标签，实际上任何看起来有一点智能的算法和机', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.880704, 120.60400000000004), (541.880704, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='器都可以称为人工智能，所以人工智能这个标签并不能代表某个商品的技术水平。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (489.832, 153.24400000000003), (489.832, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='提到人工智能，不得不说到一个非常著名的关于人工智能的测试，图灵测试（Turing Test）。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 174.12400000000002), (78.279904, 186.12400000000002), (553.8800799999999, 186.12400000000002), (553.8800799999999, 174.12400000000002)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='图灵测试是由计算机科学之父图灵提出来的，指的是测试者和被测试者（被测试者有可能是人', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (541.880704, 218.284), (541.880704, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (541.88056, 250.9240000000001), (541.88056, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='后，如果有 30%的测试者不能确定被测试者是人还是机器，那么说明这台机器通过了测试。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (541.582, 283.5640000000001), (541.582, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='虽然图灵测试早在 1950 年被提出，但是至今没有机器能够很好地通过图灵测试。偶尔会', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.20400000000006), (78.279904, 316.20400000000006), (541.8795279999999, 316.20400000000006), (541.8795279999999, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='有一些新闻报道说某某机器通过了图灵测试，但是这些通过图灵测试的机器往往会受到很多人', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (541.879504, 348.84400000000005), (541.879504, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='质疑，并且经不住多次实验。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (213.83190399999998, 381.48400000000004), (213.83190399999998, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='人工智能早期阶段，迅速解决了一些对于人类来说比较困难，但是对于计算机来说相对容', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 401.884), (78.279904, 413.884), (541.880704, 413.884), (541.880704, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='易的问题，比如下棋，推理，路径规划等等。我们下象棋的时候，通常需要思考很久才能推算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (541.881904, 446.524), (541.881904, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='出几步棋之后棋盘战局的变化，并且经常还会有看错看漏的情况。而计算机能在一瞬间计算出', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (541.880704, 479.16400000000004), (541.880704, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='七八步棋甚至十几步棋之后棋盘的情况，并从中选出对自己最有利的下法来与对手对弈。面对', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (541.880704, 511.80400000000003), (541.880704, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='如此强大的对手，人类早在 20 年前就已经输了。可能有人会想到人工智能在象棋领域早就战', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (541.879456, 544.444), (541.879456, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='胜了人类最顶尖的选手，为什么在围棋领域一直到 2016 年才出了个 AlphaGo 把人类顶级棋', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (541.8800799999999, 577.0840000000001), (541.8800799999999, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋 AI 的时候可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (541.8800799999999, 609.484), (541.8800799999999, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='以使用暴力计算的方法，把几步之内所有可能的走法都遍历一次，然后选一个最优下法。同样', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (541.880704, 642.124), (541.880704, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='的方法放到围棋上就行不通了，围棋每一步的可能性都太多了，用暴力计算法设计出来的围棋', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 662.764), (54.279903999999995, 674.764), (541.880704, 674.764), (541.880704, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='AI，它的棋力是很差的。虽然 AlphaGo 的计算非常快，可以在短时间完成大量运算，但是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (540.47992, 707.404), (540.47992, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='AlphaGo 比其他棋类 AI 强的地方并不是计算能力，而是它的算法，也可以理解为它拥有更强', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (541.8808, 740.044), (541.8808, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 20, 'category': 'Title'}),\n",
       " Document(page_content='大的“智慧”。就像是进行小学速算比赛，题目是 100 以内的加减法，10 个小学生为一队，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (547.8800799999999, 772.684), (547.8800799999999, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c07f3548c5d33f7b34e8718e1ec8c6ef', 'page_number': 20, 'category': 'NarrativeText'}),\n",
       " Document(page_content='19', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c07f3548c5d33f7b34e8718e1ec8c6ef', 'page_number': 20, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='1 个数学系的博士为另一队。如果比赛内容是 1 分钟哪个队做的正确题目多，小学生队肯定是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.8800799999999, 87.96400000000006), (541.8800799999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='能够战胜数学博士的。如果是进行大学生数学建模比赛，那 10000 个小学生也赢不了 1 个数', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.88008, 120.60400000000004), (541.88008, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='学博士。对于解决复杂的问题，需要的往往不只是计算速度，更多的应该是智慧。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (489.832, 153.24400000000003), (489.832, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 173.88400000000001), (78.279904, 185.88400000000001), (541.8791200000001, 185.88400000000001), (541.8791200000001, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='成得很差。人类的视觉从眼睛采集信息开始，但起到主要作用的是大脑。人类的每个脑半球中', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (541.880704, 218.284), (541.880704, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='都有着非常复杂的视觉皮层，包含着上亿个神经元以及几百亿条神经元之间的连接。人类的大', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (541.8807039999999, 250.9240000000001), (541.8807039999999, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='脑就像是一台超级计算机，可以轻松处理非常复杂的图像问题。神经元之间的电信号可以快速', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (541.880704, 283.5640000000001), (541.880704, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='传递，但是就像前面说到的，对于复杂的问题，计算速度只是一方面。人类的视觉能力是通过', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.8783040000001, 316.20400000000006), (541.8783040000001, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='几亿年地不断进化，不断演变最终才得到的，更强的视觉和听觉能力使得人类可以拥有更强的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (541.880704, 348.84400000000005), (541.880704, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='生存能力。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (117.83190399999998, 381.48400000000004), (117.83190399999998, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='在人工智能的早期阶段，计算机的智能通常是基于人工制定的“规则”，我们可以通过详', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 401.884), (78.279904, 413.884), (541.71088, 413.884), (541.71088, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='细的规则去定义下棋的套路，推理的方法，以及路径规划的方案。但是我们却很难用规则去详', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (541.880704, 446.524), (541.880704, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='细描述图片中的物体，比如我们要判断一张图片中是否存在猫。那我们首先要通过规则去定义', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (541.880704, 479.16400000000004), (541.880704, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='一只猫，如图 1.1 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (188.794792, 511.80400000000003), (188.794792, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='图 1.1 猫（Cat）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.53312, 695.404), (263.53312, 707.404), (360.17872, 707.404), (360.17872, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='观察图 1.1 中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 728.044), (78.279904, 740.044), (533.242792, 740.044), (533.242792, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='体，和一条长尾巴，然后可以定义一套规则在图片中寻找猫。这看起来好像是可行的，但是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (534.279904, 772.684), (534.279904, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 21, 'category': 'Title'}),\n",
       " Document(page_content='20', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'e0ba1cd310e3fa991c538f66fab28458', 'page_number': 21, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='如果我们遇到的是图 1.2，图 1.3 中的猫该怎么办？（我家领养的猫，刚来的时候上厕所比较', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.20568, 87.96400000000006), (541.20568, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='臭，故取名“臭臭”）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (171.83190399999998, 120.60400000000004), (171.83190399999998, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='图 1.2 藏起来的“臭臭”', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((231.09848799999997, 336.84400000000005), (231.09848799999997, 348.84400000000005), (368.61328, 348.84400000000005), (368.61328, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='图 1.3 盘成一团的“臭臭”', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((237.09848799999997, 630.124), (237.09848799999997, 642.124), (386.61328, 642.124), (386.61328, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='猫可能只露出身体的一部分，可能会摆出奇怪的造型，那么我们又要针对这些情况定义', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 662.764), (78.279904, 674.764), (534.279904, 674.764), (534.279904, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='新的规则。从这个例子中大家应该能看得出来，即使是一只很普通的家养宠物，都可能会出', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (534.279904, 707.404), (534.279904, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='现无数种不同的外形。如果我们使用人工定义的规则去定义这个物体，那么可能需要设置非', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (534.279904, 740.044), (534.279904, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='常大量的规则，并且效果也不一定会很好。仅仅一个物体就这么复杂，而现实中常见的各种', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (534.279904, 772.684), (534.279904, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 22, 'category': 'Title'}),\n",
       " Document(page_content='21', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2b44e224caece746bdf467ff59d2f9e1', 'page_number': 22, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='物体成千上万，所以在图像识别领域，使用使用人为定义的规则去做识别肯定是行不通的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (534.279904, 87.96400000000006), (534.279904, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='很多其他的领域也同样存在这种问题。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (261.832, 120.60400000000004), (261.832, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='1.2 机器学习', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 195.48496000000011), (98.279896, 217.56496000000004), (229.414216, 217.56496000000004), (229.414216, 195.48496000000011)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='由于人们没有办法设计出足够复杂的规则来精确描述世界，所以 AI 系统需要具备自我学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 256.20400000000006), (78.279904, 268.20400000000006), (541.8800799999999, 268.20400000000006), (541.8800799999999, 256.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='习的能力，即从原始数据中获取有用的知识。这种能力被称为机器学习（Machine Learning）。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 289.08400000000006), (54.279903999999995, 301.08400000000006), (547.8800799999999, 301.08400000000006), (547.8800799999999, 289.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='人工智能是抽象的概念，而机器学习是具体的可以落地的算法。机器学习不是一个算法，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 321.48400000000004), (78.279904, 333.48400000000004), (547.0779040000001, 333.48400000000004), (547.0779040000001, 321.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='而是一大类具体智能算法的统称。使用机器学习算法我们可以解决生活中如人脸识别，垃圾邮', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 353.884), (54.279903999999995, 365.884), (541.8807039999999, 365.884), (541.8807039999999, 353.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='件分类，语音识别等具体问题。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 386.524), (54.279903999999995, 398.524), (225.83190399999998, 398.524), (225.83190399999998, 386.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='机器学习其实与人类学习的过程类似。打个比方：假如我们现在都是原始人，并不知道太', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 419.164), (78.279904, 431.164), (541.880704, 431.164), (541.880704, 419.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='阳和月亮是什么东西。但是我们可以观察天上的太阳和月亮，并且把太阳出来时候的光线和温', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 451.80400000000003), (54.279903999999995, 463.80400000000003), (541.880704, 463.80400000000003), (541.880704, 451.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='度记录下来，把月亮出来时候的光线和温度记录下来（这就相当于是收集数据）。观察了 100', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 484.444), (54.279903999999995, 496.444), (541.87432, 496.444), (541.87432, 484.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='天之后，我们进行思考，总结这 100 天的规律我们可以发现，太阳和月亮是交替出现的（偶尔', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 517.0840000000001), (54.279903999999995, 529.0840000000001), (541.8800799999999, 529.0840000000001), (541.8800799999999, 517.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='同时出现可以忽略）。出太阳的时候光线比较亮，温度比较高。月亮出来的时候光线比较暗，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 549.484), (54.279903999999995, 561.484), (540.9135040000001, 561.484), (540.9135040000001, 549.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='温度比较低（这相当于是分析数据，建立模型）。之后我们看到太阳准备落山，月亮准备出来', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 582.124), (54.279903999999995, 594.124), (540.715504, 594.124), (540.715504, 582.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='的时候我们就知道温度要降低可能要多穿树叶或毛皮（原始人没有衣服），光线也准备要变暗', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 614.764), (54.279903999999995, 626.764), (541.075792, 626.764), (541.075792, 614.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='了（预测未来的情况）。机器学习也可以利用已有的数据进行学习，获得一个训练好的模型，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 647.404), (54.279903999999995, 659.404), (540.873904, 659.404), (540.873904, 647.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='然后可以利用此模型预测未来的情况。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 680.0440000000001), (54.279903999999995, 692.0440000000001), (261.832, 692.0440000000001), (261.832, 680.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 23, 'category': 'Title'}),\n",
       " Document(page_content='22', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b65c0c80e9e8fa45ccc924a5bd1438ed', 'page_number': 23, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='图 1.4 中表现了机器学习与人类思维的对比。我们可以使用历史数据来训练一个机器学习', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (541.880392, 87.96400000000006), (541.880392, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='的模型，模型训练好之后，再放入新的数据，模型就可以对新的数据进行预测分析。人类也善', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.8796, 120.60400000000004), (541.8796, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='于从以往的经验中总结规律，当遇到新的问题时，我们可以根据之前的经验来预测未来的结果。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (547.880704, 153.24400000000003), (547.880704, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='图 1.4 机器学习与人类思维的对比', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((219.09848799999997, 320.524), (219.09848799999997, 332.524), (404.61328, 332.524), (404.61328, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='1.2.1 训练数据，验证数据和测试数据', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 364.79296000000005), (86.279896, 380.87296000000003), (354.89104, 380.87296000000003), (354.89104, 364.79296000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='通常我们在做机器学习分析的时候，会把数据分成两大部分。一部分是训练数据（Training', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 411.96400000000006), (78.279904, 423.96400000000006), (545.4719200000001, 423.96400000000006), (545.4719200000001, 411.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='Data），可以用来训练，构建模型。另一部分是测试数据（Testing Data），可以用来验证模', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 444.60400000000004), (54.279903999999995, 456.60400000000004), (541.8800799999999, 456.60400000000004), (541.8800799999999, 444.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='型的好坏。这两部分就有点像我们上学时课本中的习题。正文中的例题是训练数据，有答案和', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 476.764), (54.279903999999995, 488.764), (541.880704, 488.764), (541.880704, 476.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='详细讲解，是用来教我们学习新知识的，可以看作是用来对我们进行训练。而课后习题是测试', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 509.40400000000005), (54.279903999999995, 521.404), (541.880704, 521.404), (541.880704, 509.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='数据，我们要先做题，做完之后再对答案，是用来检查我们学习效果的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 542.0440000000001), (54.279903999999995, 554.0440000000001), (441.832, 554.0440000000001), (441.832, 542.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='有时我们会把数据分成三部分，即训练集（Training Set）、验证集（Validation Set）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 574.924), (78.279904, 586.924), (541.8800799999999, 586.924), (541.8800799999999, 574.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='和测试集（Testing Set）。训练集还是用来训练模型。验证集是在模型的训练阶段评估模型的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 607.5640000000001), (54.279903999999995, 619.5640000000001), (541.8800799999999, 619.5640000000001), (541.8800799999999, 607.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='好坏，可以用于确定模型的参数或结构。等模型训练好，并且结构和参数都调整好之后，再用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 639.9639999999999), (54.279903999999995, 651.9639999999999), (541.8796, 651.9639999999999), (541.8796, 639.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='测试集来评估模型的好坏。通常我们可以把所有数据的 60%分配给训练集，20%分配的验证', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 672.364), (54.279903999999995, 684.364), (541.8736, 684.364), (541.8736, 672.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='集，20%分配给测试集。或者 80%分配给训练集，10%分配给验证集，10%分配给测试集。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 705.004), (54.279903999999995, 717.004), (541.8800799999999, 717.004), (541.8800799999999, 705.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 24, 'category': 'Title'}),\n",
       " Document(page_content='23', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a5f593c3d624b64838290e09ff7a4c19', 'page_number': 24, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='不过这个数据划分不是绝对的，还需要看具体情况。有时候我们只划分训练集和测试集，训练', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.880704, 87.96400000000006), (541.880704, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (525.832, 120.60400000000004), (525.832, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='K 折交叉检验(K-fold Cross-Validation) —— K 折交叉检验的大致思想是把数据集分', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.48400000000004), (78.279904, 153.48400000000004), (541.8800799999999, 153.48400000000004), (541.8800799999999, 141.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '5c5da07c7b6b8db0317ede75649a68e5', 'page_number': 25, 'category': 'NarrativeText'}),\n",
       " Document(page_content='成 K 份，每次取一份作为测试集，取余下的 K-1 份作为训练集。重复训练 K 次，每次训练都', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.8800799999999, 185.88400000000001), (541.8800799999999, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='从 K 个部分中选一个不同的部分作为测试集（要保证 K 个部分的数据都分别做过测试），剩下', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (541.87984, 218.284), (541.87984, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='的 K-1 份做训练集。最后把得到的 K 个结果做平均。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (337.29472000000004, 250.9240000000001), (337.29472000000004, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b0846064609c2a7641555a6ad8eaeadc', 'page_number': 25, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='1.2.2 学习方式', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 283.1929600000001), (86.279896, 299.27296), (194.89112799999998, 299.27296), (194.89112799999998, 283.1929600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b0846064609c2a7641555a6ad8eaeadc', 'page_number': 25, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='在机器学习或者人工智能领域，不同的问题可能会有不同的学习方式。主要的学习方法有：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 330.124), (78.279904, 342.124), (547.880704, 342.124), (547.880704, 330.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='监督学习（Supervised Learning） —— 监督学习也称为有监督学习，通常可以用于', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 363.004), (78.279904, 375.004), (541.6878399999999, 375.004), (541.6878399999999, 363.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='分类（Classification）以及回归（Regression）的问题。它的主要特点是，所有的数据都有', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 395.644), (54.279903999999995, 407.644), (541.8798400000001, 407.644), (541.8798400000001, 395.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='与之相对应的标签（Label）。比如我们想做一个识别手写数字的模型，那么我们的数据集就是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 428.284), (54.279903999999995, 440.284), (541.879408, 440.284), (541.879408, 428.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='大量手写数字的图片，并且每一张图片都有对应的标签，如图 1.5：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 460.684), (54.279903999999995, 472.684), (413.79472000000004, 472.684), (413.79472000000004, 460.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='图 1.5 标签为 3', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((268.07992, 639.9639999999999), (268.07992, 651.9639999999999), (355.63192000000004, 651.9639999999999), (355.63192000000004, 639.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='图片是一个手写数字 3，所以这张图片的标签可以设置为 3。同样的，如果是一张手写', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 672.364), (78.279904, 684.364), (530.3540800000001, 684.364), (530.3540800000001, 672.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='数字 8 的图片，那么该图片的标签就可以是 8。或者我们要建立一个判别垃圾邮件的模型，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 705.004), (54.279903999999995, 717.004), (533.3540800000001, 717.004), (533.3540800000001, 705.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 25, 'category': 'Title'}),\n",
       " Document(page_content='24', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1db81990159388f5d4caa5394e75c32f', 'page_number': 25, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='那我们先要对邮件进行标记，标记出哪些属于垃圾邮件，哪些不属于垃圾邮件，然后建立模', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (534.279904, 87.96400000000006), (534.279904, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='型。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (81.83190400000001, 120.60400000000004), (81.83190400000001, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='监督学习在建模过程中，会将预测结果与训练数据的实际结果（也就是标签）做对比，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.24400000000003), (78.279904, 153.24400000000003), (534.28, 153.24400000000003), (534.28, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='如果预测结果跟实际结果不符合，将通过一些方式去调整模型的参数，直到模型的预测结果', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (534.279904, 185.88400000000001), (534.279904, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='能达到比较高的准确率。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (189.83190399999998, 218.284), (189.83190399999998, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='非监督学习（Unsupervised Learning)）—— 非监督学习也称为无监督学习，通常可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 239.164), (78.279904, 251.164), (541.8500799999999, 251.164), (541.8500799999999, 239.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='以用于聚类（Clustering）的问题。非监督学习中，所有的数据都是没有标签的。可以使用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.804), (54.279903999999995, 283.804), (535.938112, 283.804), (535.938112, 271.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='机器学习的方法让数据自动聚类。例如许多公司都拥有庞大的客户信息数据库，使用非监督', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (534.279904, 316.20400000000006), (534.279904, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (534.279904, 348.84400000000005), (534.279904, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='们对不同细分市场的客户进行更有效的销售或者广告推送。或许我们事先并不知道有哪些细', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (534.28, 381.48400000000004), (534.28, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='分市场，也不知道哪些客户属于细分市场 A，哪些客户属于细分市场 B。不过没关系，我们', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (532.2524799999999, 413.884), (532.2524799999999, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='可以让非监督学习算法在数据中挖掘这一切信息。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (321.832, 446.524), (321.832, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='半监督学习（Semi-Supervised Learning）—— 半监督学习是监督学习和非监督学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 467.40400000000005), (78.279904, 479.40400000000005), (532.15288, 479.40400000000005), (532.15288, 467.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='习相结合的一种学习方式，通常可以用于分类以及回归问题。主要是用来解决使用少量带标', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (534.279904, 511.80400000000003), (534.279904, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='签的数据和大量没有标签的数据进行训练和分类的问题。此类算法首先试图对没有标签的数', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (534.279904, 544.444), (534.279904, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='据进行建模，然后再对带有标签的数据进行预测。说个题外话，半监督学习一般用得比较', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (522.279904, 577.0840000000001), (522.279904, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='少，原因很简单，因为标签不足的情况通常很容易解决，只要找很多人来打标签就可以了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (534.279904, 609.484), (534.279904, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='大型 AI 公司可能会有几百人的数据标注团队，每天的工作就是给各种数据打标签。因为顶尖', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (540.2506, 642.124), (540.2506, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='大公司 AI 技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 662.764), (54.279903999999995, 674.764), (540.2506, 674.764), (540.2506, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='以现在有一句叫做人工智能，先有人工，后有智能，有多少人工，就有多少智能。这是玩笑', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (534.279904, 707.404), (534.279904, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='话，大家看看就好，标签很重要，不过人工智能的核心还是算法，说不定以后有一天我们可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (534.279904, 740.044), (534.279904, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='以开发出不需要标签就可以什么都学会的算法。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (309.832, 772.684), (309.832, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 26, 'category': 'Title'}),\n",
       " Document(page_content='25', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '5474ef154a1e2f8ed48b9ad706a926b3', 'page_number': 26, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='强化学习（Reinforcement Learning）—— 强化学习灵感来源于心理学中的行为主', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 76.20400000000006), (78.279904, 88.20400000000006), (531.28, 88.20400000000006), (531.28, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (534.279904, 120.60400000000004), (534.279904, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='够获得最大利益的习惯性行为。强化学习没有任何的标签来告诉算法应该怎么做，它会先去', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (534.279904, 153.24400000000003), (534.279904, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='尝试做一些动作，然后得到一个结果，通过判断这个结果是对还是错来对之前的动作进行反', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (534.279904, 185.88400000000001), (534.279904, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='馈。AlphaGo 中就用到了强化学习。不过目前强化学习的落地应用还比较少，大部分的应用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (539.15488, 218.284), (539.15488, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='还都只是用于打游戏。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (177.83190399999998, 250.9240000000001), (177.83190399999998, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='1.2.3 机器学习常用算法', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 283.1929600000001), (86.279896, 299.27296), (258.89104000000003, 299.27296), (258.89104000000003, 283.1929600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 330.124), (78.279904, 342.124), (477.832, 342.124), (477.832, 330.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 363.004), (78.279904, 375.004), (520.65688, 375.004), (520.65688, 363.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 395.404), (54.279903999999995, 407.404), (534.279904, 407.404), (534.279904, 395.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 428.04400000000004), (54.279903999999995, 440.04400000000004), (522.279904, 440.04400000000004), (522.279904, 428.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 460.684), (54.279903999999995, 472.684), (530.2336, 472.684), (530.2336, 460.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 493.084), (54.279903999999995, 505.084), (93.83190399999998, 505.084), (93.83190399999998, 493.084)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='图 1.6 决策树(Decision Tree)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((230.957872, 737.644), (230.957872, 749.644), (392.75392, 749.644), (392.75392, 737.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 27, 'category': 'Title'}),\n",
       " Document(page_content='26', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '79f21e0f3d5ac7f92912dce6be78b0bd', 'page_number': 27, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 76.20400000000006), (78.279904, 88.20400000000006), (535.80928, 88.20400000000006), (535.80928, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (534.28, 120.60400000000004), (534.28, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (534.279904, 153.24400000000003), (534.279904, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='这些数据来建立回归模型，如图 1.7 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (284.79472000000004, 185.88400000000001), (284.79472000000004, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='图 1.7 线性回归(Linear Regreesion)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((212.052616, 401.884), (212.052616, 413.884), (411.6592, 413.884), (411.6592, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='模型建立好之后，我们可以得到一条最符合房屋面积跟房屋价格关系的直线。根据这个', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 434.524), (78.279904, 446.524), (534.279904, 446.524), (534.279904, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='模型，我们可以把一个新的房屋面积输入，就能得到该房屋的价格预测值。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (453.832, 479.16400000000004), (453.832, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='KNN（K-Nearest Neighbor） —— KNN 算法又称为 k 近邻分类(k-nearest neighbor', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 500.04400000000004), (78.279904, 512.0440000000001), (545.39728, 512.0440000000001), (545.39728, 500.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='classification)算法，是一种监督学习算法。最简单的最近邻算法就是遍历所有已知标签的样', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (540.104008, 544.444), (540.104008, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='本集中的数据，计算它们和需要分类的样本之间的距离（这里的距离一般指的是 欧氏距离', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.3240000000001), (54.279903999999995, 577.3240000000001), (541.88032, 577.3240000000001), (541.88032, 565.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='（Euclidean Distance)），同时记录目前的最近点。KNN 查找的是已知标签的样本集中跟需', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.724), (54.279903999999995, 609.724), (541.8800799999999, 609.724), (541.8800799999999, 597.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '723ddbe0f895b6fe2d05c1227527ebd6', 'page_number': 28, 'category': 'NarrativeText'}),\n",
       " Document(page_content='要分类的样本最邻近的 K 个样本，需要分类的样本最终的标签是由这 K 个样本的标签决定的，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (541.8800799999999, 642.124), (541.8800799999999, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '723ddbe0f895b6fe2d05c1227527ebd6', 'page_number': 28, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='采用的方式是“多数表决”。也就是在这 K 个样本中哪种标签最多，那么需要分类的样本就归', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 662.764), (54.279903999999995, 674.764), (541.87984, 674.764), (541.87984, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='为哪一类。下图中，方形表示分类 1，圆形表示分类 2，图中正中心的五角星表示需要分类的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (541.87984, 707.404), (541.87984, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='样本。当 K 等于 1 时，其实就是计算距离五角星最近的样本属于哪一个分类。图 1.8 中，我们', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (541.88008, 740.044), (541.88008, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='可以看到距离五角星最近的是方形，属于分类 1，所以我们可以把五角星归为分类 1。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (509.90608, 772.684), (509.90608, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 28, 'category': 'Title'}),\n",
       " Document(page_content='27', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'bc79ef25fb867276ddde6bdb5df0c293', 'page_number': 28, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='图 1.8 KNN 分类，K 等于 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((236.93151999999998, 304.20400000000006), (236.93151999999998, 316.20400000000006), (386.78031999999996, 316.20400000000006), (386.78031999999996, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='当我们取 K=5 时，其实就是找出距离五角星最近的 5 个样本，然后统计这 5 个样本哪', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 336.84400000000005), (78.279904, 348.84400000000005), (529.90888, 348.84400000000005), (529.90888, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='种分类比较多。图 1.9 中我们可以看到，有 1 个方形和 4 个圆形，那么圆形比较多，所以我', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (535.3170399999999, 381.48400000000004), (535.3170399999999, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='们可以把五角星归为分类 2。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (211.86901600000002, 413.884), (211.86901600000002, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='图 1.9 KNN 分类，K 等于 5', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((236.93151999999998, 662.764), (236.93151999999998, 674.764), (386.78031999999996, 674.764), (386.78031999999996, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='这里我们可以看到，五角星最终的分类跟 K 的取值有很大关系。K 值取多少，模型的效', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 695.404), (78.279904, 707.404), (534.51424, 707.404), (534.51424, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='果才比较好呢？这可能需要对模型进一步调试，才能得到答案，比如我们可以不断改变 K', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (520.9, 740.044), (520.9, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 29, 'category': 'Title'}),\n",
       " Document(page_content='值，然后用测试集来做测试，最终选取一个可以使得测试误差比较小的 K 值。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 760.684), (54.279903999999995, 772.684), (467.44912, 772.684), (467.44912, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2d7b3f1d4b129e6845ae9608d0317de0', 'page_number': 29, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='28', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2d7b3f1d4b129e6845ae9608d0317de0', 'page_number': 29, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='K-Means —— K-Means 是一种无监督学习算法，通常可以用于聚类分析。所谓聚类', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 76.20400000000006), (78.279904, 88.20400000000006), (535.6334079999999, 88.20400000000006), (535.6334079999999, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='问题，就是给定一个元素集合 A，集合中的每个元素有 n 个可观测的属性。我们需要使用某', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (535.1178399999999, 120.60400000000004), (535.1178399999999, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='种方法把 A 划分为 k 个子集，并且要使得每个子集内部元素之间的差异尽可能小，不同子集', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (537.256456, 153.24400000000003), (537.256456, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8d6371b1ad225f976d577d6a54bb22ae', 'page_number': 30, 'category': 'NarrativeText'}),\n",
       " Document(page_content='之间元素的差异尽可能大。K-Means 算法的计算过程比较直观也比较简单：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (459.75568, 185.88400000000001), (459.75568, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='（1）先从没有标签的元素集合 A 中随机取 k 个元素，作为 k 个子集各自的重心。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 206.284), (78.279904, 218.284), (512.3788, 218.284), (512.3788, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '7ff7c3ff185a6248b9278677e7e974eb', 'page_number': 30, 'category': 'NarrativeText'}),\n",
       " Document(page_content='（2）分别计算剩下的元素到 k 个子集重心的距离（这里的距离也可以使用欧氏距离），', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 238.9240000000001), (78.279904, 250.9240000000001), (535.8502, 250.9240000000001), (535.8502, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='根据距离将这些元素分别划归到最近的子集。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (297.832, 283.5640000000001), (297.832, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='（3）根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.20400000000006), (78.279904, 316.20400000000006), (541.317016, 316.20400000000006), (541.317016, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='算数平均数）。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (135.83190399999998, 348.84400000000005), (135.83190399999998, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='（4）将集合 A 中全部元素按照新的重心然后再重新聚类。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 369.48400000000004), (78.279904, 381.48400000000004), (391.31224, 381.48400000000004), (391.31224, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ff8ef5299f9f9b5b3f063dd0dc55895b', 'page_number': 30, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='（5）重复第（4）步，直到聚类结果不再发生变化。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 401.884), (78.279904, 413.884), (359.90608000000003, 413.884), (359.90608000000003, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='K-Means 运行过程如图 1.10~图 1.12 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((90.27990399999999, 434.524), (90.27990399999999, 446.524), (333.65608000000003, 446.524), (333.65608000000003, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0675fc70ff1f9d709194ad7ad485c506', 'page_number': 30, 'category': 'NarrativeText'}),\n",
       " Document(page_content='图 1.10 K-Means 算法，第 1 次迭代', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((213.32408800000002, 646.444), (213.32408800000002, 658.444), (410.38792, 658.444), (410.38792, 646.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 30, 'category': 'Title'}),\n",
       " Document(page_content='29', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '3f210dc80518e7db7b46c539f67851b0', 'page_number': 30, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='图 1.11 K-Means 算法，第 5 次迭代', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((213.32408800000002, 255.24400000000003), (213.32408800000002, 267.244), (410.38792, 267.244), (410.38792, 255.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='图 1.12 K-Means 算法，第 9 次迭代', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((213.32408800000002, 467.16400000000004), (213.32408800000002, 479.16400000000004), (410.38792, 479.16400000000004), (410.38792, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='聚类模型一共迭代了 9 次，最终收敛。从图中我们可以看得出来第 1 次迭代的时候，模', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 499.80400000000003), (78.279904, 511.80400000000003), (536.3540800000001, 511.80400000000003), (536.3540800000001, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='型的聚类效果是很差的，一看就不太合理。迭代了 5 次之后，模型有了一些改善，聚类的效', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (535.3170399999999, 544.444), (535.3170399999999, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='果已经不错了，不过看得出来还有一些提高的空间。迭代 9 次之后，模型就训练好了，很好', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (535.3170399999999, 577.0840000000001), (535.3170399999999, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='地把没有标签的数据分成了 4 类。相同类别之间的差距比较小，不同类别之间的差距比较', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (523.317016, 609.484), (523.317016, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='大。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (81.83190400000001, 642.124), (81.83190400000001, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='神经网络（Neural Network）—— 神经网络是一种模拟人类大脑神经网络结构构建', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 663.004), (78.279904, 675.004), (530.69992, 675.004), (530.69992, 663.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='出来的算法。神经网络的结构可以有多层，多层的神经网络可以由输入层（Input Layer），', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.644), (54.279903999999995, 707.644), (536.71744, 707.644), (536.71744, 695.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='隐藏层（Hidden Layers）以及输出层（Output Layer）组成。其中隐藏层可能有 0 到多', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.284), (54.279903999999995, 740.284), (532.5279999999999, 740.284), (532.5279999999999, 728.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 31, 'category': 'Title'}),\n",
       " Document(page_content='30', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6233cc4f7d9a1dbf16bef95acdab8c57', 'page_number': 31, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='个，所以最简单的神经网络就只有输入层和输出层。神经网络的每一层都由若干个神经元', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 76.20400000000006), (54.279903999999995, 88.20400000000006), (522.28, 88.20400000000006), (522.28, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='（Neuron）节点组成。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.84400000000005), (54.279903999999995, 120.84400000000005), (187.458856, 120.84400000000005), (187.458856, 108.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='信号从输出层传入网络，与神经元的权值（Weights）作用后再经过激活函数', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.48400000000004), (78.279904, 153.48400000000004), (488.00247999999993, 153.48400000000004), (488.00247999999993, 141.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='（Activation Function）传入下一层。每一层信号的输出都是下一层的输入，直到把信号', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 174.12400000000002), (54.279903999999995, 186.12400000000002), (532.065064, 186.12400000000002), (532.065064, 174.12400000000002)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='传到输出层得出结果。网络结构如图 1.13 所示：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (315.832, 218.284), (315.832, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='图 1.13 神经网络（Neural Network）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((206.0116, 516.124), (206.0116, 528.124), (417.70024, 528.124), (417.70024, 516.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='神经网络是深度学习的重要基础，在后面的章节中我们会从头开始详细学习神经网络的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 548.764), (78.279904, 560.764), (534.279904, 560.764), (534.279904, 548.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='搭建以及应用，这里只是先做一个简单介绍。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 581.164), (54.279903999999995, 593.164), (297.832, 593.164), (297.832, 581.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='除了上面介绍的这些算法以外，机器学习领域还有很多其他的算法，如朴素贝叶斯', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 614.0440000000001), (78.279904, 626.0440000000001), (510.28, 626.0440000000001), (510.28, 614.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='(Naive Bayes)，支持向量机 SVM(Support Vector Machine)， Adaboost 等。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 646.684), (54.279903999999995, 658.684), (502.85727999999995, 658.684), (502.85727999999995, 646.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 32, 'category': 'Title'}),\n",
       " Document(page_content='31', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '9fb39accb3c45834be70def27ad6f6bd', 'page_number': 32, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='1.3 人工智能、机器学习，神经网络以及深度学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 80.76496000000009), (98.279896, 102.84496000000001), (542.746792, 102.84496000000001), (542.746792, 80.76496000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='习之间的关系', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 129.48496000000011), (54.279903999999995, 151.56496000000004), (192.815584, 151.56496000000004), (192.815584, 129.48496000000011)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='新闻媒体在报道 AlphaGo 的时候，可能人工智能，机器学习，神经网络和深度学习这', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 190.20400000000006), (78.279904, 202.20400000000006), (530.154904, 202.20400000000006), (530.154904, 190.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='几个词都有用到过。对于初学者来说，难免容易混淆。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 222.84400000000005), (54.279903999999995, 234.84400000000005), (345.832, 234.84400000000005), (345.832, 222.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='人工智能 —— 我们先说说人工智能，人工智能是这几个词中最早出现的。1956 年，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 255.72400000000005), (78.279904, 267.72400000000005), (531.3500799999999, 267.72400000000005), (531.3500799999999, 255.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='在美国达特茅斯会议（Dartmouth Conference）上被提出。人工智能其实是一种抽象的概', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 288.124), (54.279903999999995, 300.124), (534.61984, 300.124), (534.61984, 288.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='念，并不是指任何实际的算法。人工智能可以对人的意识、思维进行模拟，但又不是人的智', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 320.764), (54.279903999999995, 332.764), (534.279904, 332.764), (534.279904, 320.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='能。有时候我们还会把人工智能分为弱人工智能（Weak AI）和强人工智能（Strong AI）。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 353.404), (54.279903999999995, 365.404), (543.2401600000001, 365.404), (543.2401600000001, 353.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='弱人工智能是擅长于单个方面技能的人工智能。比如 AlphaGo 能战胜了众多世界围棋', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 385.80400000000003), (78.279904, 397.80400000000003), (530.1548799999999, 397.80400000000003), (530.1548799999999, 385.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='冠军的，在围棋领域所向披靡，但它只会下围棋，做不了其他事情。我们目前的人工智能相', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 418.444), (54.279903999999995, 430.444), (534.279904, 430.444), (534.279904, 418.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='关的技术，比如图像识别，语言识别，自然语言处理等等，基本都是处于弱人工智能阶段。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 451.08400000000006), (54.279903999999995, 463.08400000000006), (537.832, 463.08400000000006), (537.832, 451.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='强人工智能指的是在各方面都能和人类智能差不多的人工智能，人类能干的脑力劳动它', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 483.72400000000005), (78.279904, 495.72400000000005), (534.28, 495.72400000000005), (534.28, 483.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 516.364), (54.279903999999995, 528.364), (534.279904, 528.364), (534.279904, 516.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='些科幻电影中才能看到。著名的教育心理学教授 Linda Gottfredson 把智能定义为“一种宽', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 548.764), (54.279903999999995, 560.764), (539.01424, 560.764), (539.01424, 548.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 581.404), (54.279903999999995, 593.404), (534.279904, 593.404), (534.279904, 581.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='经验中学习等操作。”强人工智能在进行这些操作时应该跟人类一样得心应手。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 614.0440000000001), (54.279903999999995, 626.0440000000001), (477.832, 626.0440000000001), (477.832, 614.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='机器学习 —— 机器学习是最近 20 多年兴起的一门多领域交叉学科，涉及概率论、统', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 646.924), (78.279904, 658.924), (532.2760000000001, 658.924), (532.2760000000001, 646.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='计学、逼近学、凸分析、计算复杂性理论等多门学科。关于机器学习，上一小节我们已经做', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 679.3240000000001), (54.279903999999995, 691.3240000000001), (534.28, 691.3240000000001), (534.28, 679.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='了一些讨论说明，我们可以发现机器学习包含很多具体的算法。既然人工智能是飘在天上的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 711.9639999999999), (54.279903999999995, 723.9639999999999), (534.279904, 723.9639999999999), (534.279904, 711.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 33, 'category': 'Title'}),\n",
       " Document(page_content='32', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '457b9bd0b70b58d682e5aa0f492f9534', 'page_number': 33, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='概念，那我们就需要一些具体的算法使得人工智能可以落地应用，而一般来说，这些具体的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (534.279904, 87.96400000000006), (534.279904, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='智能算法可以统称为机器学习算法。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (249.83190399999998, 120.60400000000004), (249.83190399999998, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='神经网络 —— 神经网络是众多机器学习算法中的其中一个，是模仿人类大脑神经结构', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.48400000000004), (78.279904, 153.48400000000004), (536.201776, 153.48400000000004), (536.201776, 141.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='构建出来的一种算法，构建出来的网络称为人工神经网络（Artificial Neural Networks，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 174.12400000000002), (54.279903999999995, 186.12400000000002), (535.9204, 186.12400000000002), (535.9204, 174.12400000000002)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='ANN）。神经网络算法在机器学习中并不算特别出色，所以一开始的时候并没有引起人们的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.524), (54.279903999999995, 218.524), (533.658808, 218.524), (533.658808, 206.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='特别关注。神经网络的发展已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代神经网络', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (531.5024799999999, 250.9240000000001), (531.5024799999999, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='的雏形出现在控制论（Cybernetics）中，20 世纪 80 年代到 90 年代表现为联结主', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.804), (54.279903999999995, 283.804), (493.96743999999995, 283.804), (493.96743999999995, 271.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='（Connectionism）。直到 2006 年神经网络重新命名为深度学习，再次兴起。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.4440000000001), (54.279903999999995, 316.4440000000001), (476.12104, 316.4440000000001), (476.12104, 304.4440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='深度学习 —— 深度学习的基础其实就是神经网络，之所以后来换了一种叫法，主要是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 337.08400000000006), (78.279904, 349.08400000000006), (536.201776, 349.08400000000006), (536.201776, 337.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='由于之前的神经网络算法中网络的层数不能太深，也就是不能有太多层网络，网络层数过多', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (534.279904, 381.48400000000004), (534.279904, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='会使得网络无法训练。随着神经网络理论的发展，科学家研究出了多种方式使得训练深层的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (534.279904, 413.884), (534.279904, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='网络也成为可能，深度学习由此诞生。如卷积神经网络（Convolutional Neural', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.764), (54.279903999999995, 446.764), (486.3496, 446.764), (486.3496, 434.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='Network, CNN），长短时记忆网络（Long Short Term Memory Network, LSTM），深', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.40400000000005), (54.279903999999995, 479.40400000000005), (539.6764, 479.40400000000005), (539.6764, 467.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='度残差网络（Deep Residual Network）等都属于深度学习，其中深度残差网络的深度可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 500.04400000000004), (54.279903999999995, 512.0440000000001), (532.0475200000001, 512.0440000000001), (532.0475200000001, 500.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='以到达 1000 层，甚至更多。深层的网络有助于挖掘数据中深层的特征，可以使得网络拥有', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (532.428328, 544.444), (532.428328, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='更强大的性能。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (141.83190399999998, 577.0840000000001), (141.83190399999998, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='图 1.14 描绘了人工智能、机器学习、神经网络和深度学习之间的关系。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 597.484), (78.279904, 609.484), (459.832, 609.484), (459.832, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 34, 'category': 'Title'}),\n",
       " Document(page_content='33', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1b8294226c2fa49b52e17562051be722', 'page_number': 34, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='图 1.14 人工智能、机器学习、神经网络和深度学习之间的关系', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((143.57994399999995, 255.24400000000003), (143.57994399999995, 267.244), (480.13192000000004, 267.244), (480.13192000000004, 255.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='1.4 深度学习应用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 342.12496), (98.279896, 364.20496), (278.91423999999995, 364.20496), (278.91423999999995, 342.12496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='深度学习最早兴起于图像识别，在最近几年可以说是已经深入各行各业。深度学习在计算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 402.84400000000005), (78.279904, 414.84400000000005), (541.880704, 414.84400000000005), (541.880704, 402.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='机视觉，语音识别，自然语言处理，机器人控制，生物信息，医疗，法律，金融，推荐系统，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 435.48400000000004), (54.279903999999995, 447.48400000000004), (546.6363040000001, 447.48400000000004), (546.6363040000001, 435.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='搜索引擎，电脑游戏，娱乐等领域均有应用。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 468.124), (54.279903999999995, 480.124), (297.832, 480.124), (297.832, 468.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='图像识别 —— 图像识别可以说是深度学习最早实现突破性成就的领域。如今计算机对', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 501.004), (78.279904, 513.004), (539.4970959999998, 513.004), (539.4970959999998, 501.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='图片的识别能力已经跟人类不相上下。我们把一张图片输入神经网络，经过网络的运算，最后', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 533.164), (54.279903999999995, 545.164), (541.880704, 545.164), (541.880704, 533.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='可以得到图片的分类。如图 1.15 所示，我们可以看到，对于每一张图片，神经网络都给出了', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.8040000000001), (54.279903999999995, 577.8040000000001), (541.8800799999999, 577.8040000000001), (541.8800799999999, 565.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='5 个最有可能的分类，排在最上面的可能性最大。图中的置信度表示的就是该图片的概率值。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 598.444), (54.279903999999995, 610.444), (547.63432, 610.444), (547.63432, 598.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 35, 'category': 'Title'}),\n",
       " Document(page_content='34', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c28556546a6a6a7a5877264950a2f3de', 'page_number': 35, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 36, 'category': 'Title'}),\n",
       " Document(page_content='图 1.15 图像识别', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 255.24400000000003), (263.57992, 267.244), (360.13192000000004, 267.244), (360.13192000000004, 255.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 36, 'category': 'Title'}),\n",
       " Document(page_content='目标检测 —— 利用深度学习我们还可以识别图片中的特定物体，然后对该物体进行标', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 288.124), (78.279904, 300.124), (538.8970959999999, 300.124), (538.8970959999999, 288.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 36, 'category': 'Title'}),\n",
       " Document(page_content='注，如图 1.16 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 320.524), (54.279903999999995, 332.524), (171.83190399999998, 332.524), (171.83190399999998, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2797f28f1a8e02f8311c790a77845671', 'page_number': 36, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='图 1.16 目标检测[1]', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((258.56248, 596.89504), (258.56248, 609.484), (365.1496, 609.484), (365.1496, 596.89504)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2797f28f1a8e02f8311c790a77845671', 'page_number': 36, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='人脸识别 —— 深度学习还可以识别图像中的人脸，判断是男人还是女人，判断人的年龄，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 630.364), (78.279904, 642.364), (553.880176, 642.364), (553.880176, 630.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 36, 'category': 'Title'}),\n",
       " Document(page_content='判断图像中的人是谁等，如图 1.17 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 662.764), (54.279903999999995, 674.764), (279.832, 674.764), (279.832, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 36, 'category': 'Title'}),\n",
       " Document(page_content='35', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'fbcc49b5d58b60287f032c8805c1a4c1', 'page_number': 36, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 37, 'category': 'Title'}),\n",
       " Document(page_content='图 1.17 人脸识别', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 271.5640000000001), (263.57992, 283.5640000000001), (360.13192000000004, 283.5640000000001), (360.13192000000004, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 37, 'category': 'Title'}),\n",
       " Document(page_content='目标分割 —— 目标分割识别出图中的物体，并且可以划分出物体的边界，如图 1.18 所', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.4440000000001), (78.279904, 316.4440000000001), (541.8800799999999, 316.4440000000001), (541.8800799999999, 304.4440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 37, 'category': 'Title'}),\n",
       " Document(page_content='示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (81.83190400000001, 348.84400000000005), (81.83190400000001, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 37, 'category': 'Title'}),\n",
       " Document(page_content='图 1.18 目标分割[2]', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((258.56248, 629.53504), (258.56248, 642.124), (365.1496, 642.124), (365.1496, 629.53504)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '074d8a3fd2bc5406bc97c3c52e3a4ee6', 'page_number': 37, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='描述图片 —— 把一张图片输入神经网络中，就可以输出对这张图片的文字描述，如图', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 663.004), (78.279904, 675.004), (538.597096, 675.004), (538.597096, 663.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 37, 'category': 'Title'}),\n",
       " Document(page_content='1.19 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (120.83190399999998, 707.404), (120.83190399999998, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'efbf8ae30ee846cc6fd53f3d3487e634', 'page_number': 37, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='36', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'efbf8ae30ee846cc6fd53f3d3487e634', 'page_number': 37, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 38, 'category': 'Title'}),\n",
       " Document(page_content='图 1.19 图片描述', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 369.48400000000004), (263.57992, 381.48400000000004), (360.13192000000004, 381.48400000000004), (360.13192000000004, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 38, 'category': 'Title'}),\n",
       " Document(page_content='图片风格转换 —— 利用深度学习实现一张图片加上另一张图片的风格，然后生成一张', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 402.124), (78.279904, 414.124), (538.8959199999999, 414.124), (538.8959199999999, 402.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 38, 'category': 'Title'}),\n",
       " Document(page_content='新的图片，如图 1.20 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (207.83190399999998, 446.524), (207.83190399999998, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 38, 'category': 'Title'}),\n",
       " Document(page_content='37', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1f8366c5503c70dd994d9ce8b3acbfb1', 'page_number': 38, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='图 1.20 图片风格转换[3]', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((246.56236, 433.93504), (246.56236, 446.524), (377.1496, 446.524), (377.1496, 433.93504)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='语音识别 —— 深度学习还可以用来识别人说的话，把语音数据转换为文本数据，如图', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 467.40400000000005), (78.279904, 479.40400000000005), (538.8970959999999, 479.40400000000005), (538.8970959999999, 467.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='1.21 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (120.83190399999998, 511.80400000000003), (120.83190399999998, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b8ba8b0834562f53ddc224181287b67c', 'page_number': 39, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='图 1.21 语音识别', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 646.444), (263.57992, 658.444), (360.13192000000004, 658.444), (360.13192000000004, 646.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='文本分类 —— 使用深度学习对多个文本进行分类，比如判断一个评论是好评还是差评，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 679.3240000000001), (78.279904, 691.3240000000001), (547.880176, 691.3240000000001), (547.880176, 679.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='或者判断一篇新闻是属于娱乐新闻，体育新闻还是科技新闻，如图 1.22 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 711.724), (54.279903999999995, 723.724), (471.832, 723.724), (471.832, 711.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 39, 'category': 'Title'}),\n",
       " Document(page_content='38', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0a94fbfa3ea93dc40ac96534b3917d43', 'page_number': 39, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='图 1.22 文本分类', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 271.5640000000001), (263.57992, 283.5640000000001), (360.13192000000004, 283.5640000000001), (360.13192000000004, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='机器翻译 —— 使用深度学习进行机器翻译，如图 1.23 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 304.4440000000001), (75.279904, 316.4440000000001), (410.75368000000003, 316.4440000000001), (410.75368000000003, 304.4440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='图 1.23 机器翻译', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 467.16400000000004), (263.57992, 479.16400000000004), (360.13192000000004, 479.16400000000004), (360.13192000000004, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='诗词生成 —— 把一个诗词的题目传入神经网络，就可以生成一篇诗词，如图 1.24 所示，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 500.04400000000004), (78.279904, 512.0440000000001), (541.8800799999999, 512.0440000000001), (541.8800799999999, 500.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='其就是 AI 写的一首诗。虽然这首诗有些看不太懂，但是已经“有内味了”。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (453.80248, 544.444), (453.80248, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '38196daf4cecbda3359db1a911f5fbff', 'page_number': 40, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='图 1.24 诗句生成', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 760.684), (263.57992, 772.684), (360.13192000000004, 772.684), (360.13192000000004, 760.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 40, 'category': 'Title'}),\n",
       " Document(page_content='39', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ef1ba02b94e4640e27846c28b2eb6eea', 'page_number': 40, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 76.20400000000006), (75.279904, 88.20400000000006), (449.201776, 88.20400000000006), (449.201776, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='https://make.girls.moe/#/，设置好动漫人物的头发颜色，头发长度，眼睛颜色，是否戴帽', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (537.76036, 120.60400000000004), (537.76036, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='子等信息就可以生成符合条件的动漫人物。并且可以生成无数张不重复的照片，如图 1.25 所', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (540.28, 153.24400000000003), (540.28, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (81.83190400000001, 185.88400000000001), (81.83190400000001, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='图 1.25 图像生成', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((263.57992, 467.16400000000004), (263.57992, 479.16400000000004), (360.13192000000004, 479.16400000000004), (360.13192000000004, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='这里只是列举了非常少量的例子，深度学习的已经逐渐深入各行各业，深入我们的生活', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 499.80400000000003), (78.279904, 511.80400000000003), (534.279904, 511.80400000000003), (534.279904, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='中。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (81.83190400000001, 544.444), (81.83190400000001, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='1.5 神经网络深度学习发展史', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 619.08496), (98.279896, 641.1649600000001), (388.91416, 641.1649600000001), (388.91416, 619.08496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='神经网络的发展历史中有过三次热潮，分别发展在 20 世纪 40 年代到 60 年代，20 世纪', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 680.0440000000001), (78.279904, 692.0440000000001), (541.88008, 692.0440000000001), (541.88008, 680.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='80 年代到 90 年代，以及 2006 年至今。每一次神经网络的热潮都伴随着人工智能的兴起，人', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 712.684), (54.279903999999995, 724.684), (541.8798400000001, 724.684), (541.8798400000001, 712.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='工智能和神经网络一直以来都有着非常密切的关系。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 745.0840000000001), (54.279903999999995, 757.0840000000001), (333.832, 757.0840000000001), (333.832, 745.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 41, 'category': 'Title'}),\n",
       " Document(page_content='40', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'e5861cc7f6f4dc5eaf17164ae25b8871', 'page_number': 41, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='1.5.1 神经网络诞生-20 世纪 40-60 年代', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 74.63296000000003), (86.279896, 90.71295999999995), (373.03167999999994, 90.71295999999995), (373.03167999999994, 74.63296000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 42, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='1943 年，神经病学家和神经元解剖学家 W.S.McCulloch 和数学家 W.A.Pitts在生物物理', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 121.56400000000008), (78.279904, 133.56400000000008), (541.8800799999999, 133.56400000000008), (541.8800799999999, 121.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='学期刊发表文章提出神经元的数学描述和结构。并且证明了只要有足够的简单神经元，在这些', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 154.20400000000006), (54.279903999999995, 166.20400000000006), (541.8807039999999, 166.20400000000006), (541.8807039999999, 154.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='神经元互相连接并同步运行的情况下，可以模拟任何计算函数，这种神经元的数学模型称为 M-', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 186.84400000000005), (54.279903999999995, 198.84400000000005), (541.88464, 198.84400000000005), (541.88464, 186.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '585f819de142c0d4273c5aa483a760ec', 'page_number': 42, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='P 模型。该模型把神经元的动作描述为：1.神经元的活动表现为兴奋或抑制的二值变化；2.任', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 219.48400000000004), (54.279903999999995, 231.48400000000004), (541.8800799999999, 231.48400000000004), (541.8800799999999, 219.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='何兴奋性突触输入激励后，使神经元兴奋；3.任何抑制性突触有输入激励后，使神经元抑制；', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 251.88400000000001), (54.279903999999995, 263.884), (546.31648, 263.884), (546.31648, 251.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='4.突触的值不随时间改变；5.突触从感知输入到传送出一个输出脉冲的延时时间是 0.5ms。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 284.524), (54.279903999999995, 296.524), (534.44512, 296.524), (534.44512, 284.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='尽管现在看来 M-P 模型过于简单，并且观点也不是完全正确，不过这个模型被认为是第', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 317.164), (78.279904, 329.164), (541.8799839999999, 329.164), (541.8799839999999, 317.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='一个仿生学的神经网络模型，他们提出的很多观点一直沿用至今，比如说他们认为神经元有两', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 349.80400000000003), (54.279903999999995, 361.80400000000003), (541.880704, 361.80400000000003), (541.880704, 349.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='种状态，要不就是兴奋，要不就是抑制。这跟后面要提到的单层感知器非常类似，单层感知器', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 382.444), (54.279903999999995, 394.444), (541.8783040000001, 394.444), (541.8783040000001, 382.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='的输出要不就是 0 要不就是 1。他们最重要的贡献就是开创了神经网络这个研究方向，为今天', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 415.08400000000006), (54.279903999999995, 427.08400000000006), (541.8789280000001, 427.08400000000006), (541.8789280000001, 415.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='神经网络的发展奠定了基础。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 447.48400000000004), (54.279903999999995, 459.48400000000004), (213.83190399999998, 459.48400000000004), (213.83190399999998, 447.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='1949 年 ，另一 位心 理学 家', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 480.124), (78.279904, 492.124), (247.540792, 492.124), (247.540792, 480.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='Donald Olding Hebb 在他的 一 本名为', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((280.65376, 480.124), (280.65376, 492.124), (520.0398399999999, 492.124), (520.0398399999999, 480.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='《The organization of behavior: A neuropsychological theory》[4]的书提出了 Hebb 算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 512.1750400000001), (54.279903999999995, 524.764), (541.8800799999999, 524.764), (541.8800799999999, 512.1750400000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6bfef0ca8da09c879a6770bbeb1f0514', 'page_number': 42, 'category': 'NarrativeText'}),\n",
       " Document(page_content='法。他也是首先提出“连接主义”（connectionism）这一名词的人之一，这个名词的含义是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 545.404), (54.279903999999995, 557.404), (541.2906399999999, 557.404), (541.2906399999999, 545.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='大脑的活动是靠脑细胞的组合连接实现的。Hebb 认为，如果源和目的神经元均被激活兴奋时，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 578.0440000000001), (54.279903999999995, 590.0440000000001), (547.88008, 590.0440000000001), (547.88008, 578.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='它们之间突触的连接强度将会增强。他指出在神经网络中，信息存储在连接权值中。并提出假', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 610.684), (54.279903999999995, 622.684), (541.880704, 622.684), (541.880704, 610.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='设神经元 A 到神经元 B 连接权与从 B 到 A 的连接权是相同的。他这里提到的这个权值的思想', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 643.0840000000001), (54.279903999999995, 655.0840000000001), (541.8796, 655.0840000000001), (541.8796, 643.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='也被应用到了我们目前所使用的神经网络中，我们通过调节神经元之间的连接权值来得到不同', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 675.724), (54.279903999999995, 687.724), (541.879504, 687.724), (541.879504, 675.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='的神经网络模型，实现不同的应用。虽然这些理论在今天看来是理所当然的，不过在当时看来', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 708.364), (54.279903999999995, 720.364), (541.8800799999999, 720.364), (541.8800799999999, 708.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='这是一种全新的想法，算得上是开创性的理论。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 741.004), (54.279903999999995, 753.004), (309.832, 753.004), (309.832, 741.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 42, 'category': 'Title'}),\n",
       " Document(page_content='41', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a86e580a5d71d16d079a51297f5674df', 'page_number': 42, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='1958 年 ， 计算 机学 家 Frank Rosenblatt 提 出 了 一种神经网络 结 构，称为 感 知 器', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 76.20400000000006), (78.279904, 88.20400000000006), (541.87936, 88.20400000000006), (541.87936, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 43, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(Perceptron)。他提出的这个感知器可能是世界上第一个真正意义上的人工神经网络。感知', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.84400000000005), (54.279903999999995, 120.84400000000005), (539.8084239999998, 120.84400000000005), (539.8084239999998, 108.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='器提出之后在 60 年代就掀起了神经网络研究的第一次热潮。很多人都认为只要使用成千上万', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.880128, 153.24400000000003), (541.880128, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='的神经元，他们就能解决一切问题。现在看来可能会让人感觉 too young too naive，不过感', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.8796, 185.88400000000001), (541.8796, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '71f69c64905708bc77885498e4cddb0a', 'page_number': 43, 'category': 'NarrativeText'}),\n",
       " Document(page_content='知器在当时确实是影响非凡。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (213.83190399999998, 218.284), (213.83190399999998, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='这股感知器热潮持续了 10 年，直到 1969 年，人工智能的创始人之一的 M.Minsky 和', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 238.9240000000001), (78.279904, 250.9240000000001), (541.8800799999999, 250.9240000000001), (541.8800799999999, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='S.Papert 出版了一本名为《感知器》[5]的书，书中指出简单神经网络只能运用于线性问题的求', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 270.97504000000004), (54.279903999999995, 283.5640000000001), (541.8800799999999, 283.5640000000001), (541.8800799999999, 270.97504000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='解，能够求解非线性问题的网络应具有隐层，而从理论上还不能证明将感知器模型扩展到多层', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.880704, 316.20400000000006), (541.880704, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='网络是有意义的。由于 Minsky 在学术界的地位和影响，其悲观论点极大地影响了当时的人工', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (541.88032, 348.84400000000005), (541.88032, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='神经网络研究，为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。这本书出版不不久之后，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (547.880704, 381.48400000000004), (547.880704, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='几乎所有为神经网络提供的研究基金都枯竭了，没有人愿意把钱浪费在没有意义的事情上。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (537.832, 413.884), (537.832, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='1.5.2 神经网络复兴-20 世纪 80-90 年代', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 446.15296), (86.279896, 462.23296), (373.03167999999994, 462.23296), (373.03167999999994, 446.15296)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd4205eaf7f2c51c425cc19eea25f1ef8', 'page_number': 43, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='1982 年，美国加州理工学院的优秀物理学家 John J.Hopfield 博士提出了 Hopfield 神', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 493.324), (78.279904, 505.324), (541.8800799999999, 505.324), (541.8800799999999, 493.324)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='经网络。Hopfield 神经网络引用了物理力学的分析方法，把网络作为一种动态系统并研究这', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 525.9639999999999), (54.279903999999995, 537.9639999999999), (541.7431119999999, 537.9639999999999), (541.7431119999999, 525.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='种网络动态系统的稳定性。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 558.364), (54.279903999999995, 570.364), (201.83190399999998, 570.364), (201.83190399999998, 558.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='1985 年，G.E.Hinton 和 T.J.Sejnowski借助统计物理学的概念和方法提出了一种随机神', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 591.004), (78.279904, 603.004), (541.8800799999999, 603.004), (541.8800799999999, 591.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='经网络模型——玻尔兹曼机(Boltzmann Machine)。一年后他们又改进了模型，提出了受限', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 623.884), (54.279903999999995, 635.884), (541.88008, 635.884), (541.88008, 623.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='玻尔兹曼机(Restricted Boltzmann Machine)。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 656.524), (54.279903999999995, 668.524), (323.57800000000003, 668.524), (323.57800000000003, 656.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='1986 年，Rumelhart，Hinton，Williams 提出了 BP(Back Propagation)算法[6]（多层', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 688.33504), (78.279904, 700.924), (541.8800799999999, 700.924), (541.8800799999999, 688.33504)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='感知器的误差反向传播算法）。到今天为止，这种多层感知器的误差反向传播算法还是非常基', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 721.3240000000001), (54.279903999999995, 733.3240000000001), (540.675904, 733.3240000000001), (540.675904, 721.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='础的算法，凡是学神经网络的人，必然要学习 BP 算法。我们现在的深度网络模型基本上都是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 753.964), (54.279903999999995, 765.964), (541.88032, 765.964), (541.88032, 753.964)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 43, 'category': 'Title'}),\n",
       " Document(page_content='42', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '3db5522efd66618ff44cad2b8bb938d7', 'page_number': 43, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='在这个算法的基础上发展出来的。使用 BP 算法的多层神经网络也称为 BP 神经网络（Back', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 76.20400000000006), (54.279903999999995, 88.20400000000006), (545.4560799999999, 88.20400000000006), (545.4560799999999, 76.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='Propagation Neural network）。BP 神经网络主要指的是 20 世纪 80-90 年代使用 BP 算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.84400000000005), (54.279903999999995, 120.84400000000005), (541.8800799999999, 120.84400000000005), (541.8800799999999, 108.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '997a97d0cec980ada0f7c71845b15399', 'page_number': 44, 'category': 'NarrativeText'}),\n",
       " Document(page_content='法的神经网络，虽然现在的深度学习也用 BP 算法，不过网络名称已经不叫 BP 神经网络了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.8800799999999, 153.24400000000003), (541.8800799999999, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '997a97d0cec980ada0f7c71845b15399', 'page_number': 44, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='早期的 BP 神经网络的神经元层数不能太多，一旦网络层数过多，就会使得网络无法训练，具', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.8802, 185.88400000000001), (541.8802, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='体原因在后面的章节中会详细说明。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (249.83190399999998, 218.284), (249.83190399999998, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='Hopfield 神经网络，玻尔兹曼机以及受限玻尔兹曼机由于目前已经较少使用，所以本书', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 238.9240000000001), (78.279904, 250.9240000000001), (541.7158, 250.9240000000001), (541.7158, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='后面章节不再详细介绍这三种网络。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (249.83190399999998, 283.5640000000001), (249.83190399999998, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='1.5.3 深度学习-2006 年至今', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 315.83296000000007), (86.279896, 331.91296000000006), (291.34432, 331.91296000000006), (291.34432, 315.83296000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c4cca38bdb7ab86123c3b09e45cd8983', 'page_number': 44, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='2006 年，多伦多大学的教授 Geoffrey Hinton 提出了深度学习。他在世界顶级学术期刊', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 362.764), (78.279904, 374.764), (541.8800799999999, 374.764), (541.8800799999999, 362.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='《 Science 》上发表了 一篇论 文《 Reducing the dimensionality of data with neural', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 395.404), (54.279903999999995, 407.404), (545.431384, 407.404), (545.431384, 395.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '208d17490e5f9ad49bd487a286f264b9', 'page_number': 44, 'category': 'NarrativeText'}),\n",
       " Document(page_content='networks》[7]，论文中提出了两个观点：①多层人工神经网络模型有很强的特征学习能力，深', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 427.45504), (54.279903999999995, 440.04400000000004), (541.8800799999999, 440.04400000000004), (541.8800799999999, 427.45504)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='度学习模型学习得到的特征数据对原始数据有更本质的代表性，这将大大便于分类和可视化问', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 460.684), (54.279903999999995, 472.684), (541.879504, 472.684), (541.879504, 460.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='题；②对于深度神经网络很难训练达到最优的问题，可以采用逐层训练方法解决。将上层训练', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 493.324), (54.279903999999995, 505.324), (541.8800799999999, 505.324), (541.8800799999999, 493.324)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='好的结果作为下层训练过程中的初始化参数。在这一文献中深度模型的训练过程中逐层初始化', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 525.724), (54.279903999999995, 537.724), (541.8800799999999, 537.724), (541.8800799999999, 525.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='采用无监督学习方式。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 558.364), (54.279903999999995, 570.364), (177.83190399999998, 570.364), (177.83190399999998, 558.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='Hinton 在论文中提出了一种新的网络结构深度置信网络（Deep Belief Net：DBN），这', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 591.244), (78.279904, 603.244), (541.88008, 603.244), (541.88008, 591.244)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='种网络使得训练深层的神经网络成为可能。深度置信网络由于目前已经较少使用，所以本书后', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 623.644), (54.279903999999995, 635.644), (541.8807039999999, 635.644), (541.8807039999999, 623.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='面章节不再详细介绍这种网络。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 656.2840000000001), (54.279903999999995, 668.2840000000001), (225.85590399999998, 668.2840000000001), (225.85590399999998, 656.2840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='2012 年，Hinton 课题组为了证明深度学习的潜力，首次参加 ImageNet 图像识别比赛，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 688.684), (78.279904, 700.684), (541.8800799999999, 700.684), (541.8800799999999, 688.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='通过 CNN 网络 AlexNet 一举夺得冠军。也正是由于该比赛，CNN 吸引了众多研究者的注意。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 721.3240000000001), (54.279903999999995, 733.3240000000001), (545.4320799999999, 733.3240000000001), (545.4320799999999, 721.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 44, 'category': 'Title'}),\n",
       " Document(page_content='43', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '7b2da8f06206cf9d15ae11742fcee33a', 'page_number': 44, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='44', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 45, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='2014 年，香港中文大学教授汤晓鸥领导的计算机视觉研究组开发了名为 DeepID 的深度', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (541.8800799999999, 87.96400000000006), (541.8800799999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='学习模型， 在 LFW (Labeled Faces in the Wild，人脸识别使用非常广泛的测试基准)数据库', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.8800799999999, 120.60400000000004), (541.8800799999999, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8f5284fc4b9369465f5c0ba0079f16b3', 'page_number': 45, 'category': 'NarrativeText'}),\n",
       " Document(page_content='上获得了 99.15%的识别率，人用肉眼在 LFW 上的识别率为 97.52%，深度学习在学术研究层', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.8800799999999, 153.24400000000003), (541.8800799999999, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='面上已经超过了人用肉眼的识别。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (237.83190399999998, 185.88400000000001), (237.83190399999998, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='2016 年 3 月人工智能围棋比赛，由位于英国伦敦的谷歌（Google）旗下 DeepMind 公', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 206.284), (78.279904, 218.284), (541.8800799999999, 218.284), (541.8800799999999, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='司的开发的 AlphaGo 战胜了世界围棋冠军、职业九段选手李世石，并以 4:1 的总比分获胜。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (544.66984, 250.9240000000001), (544.66984, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '740cf5515793b2281ddff09419f87da7', 'page_number': 45, 'category': 'NarrativeText'}),\n",
       " Document(page_content='2018 年 6 月，OpenAI 的研究人员开发了一种技术，可以在未标记的文本上训练 AI，可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 271.5640000000001), (78.279904, 283.5640000000001), (541.8798400000001, 283.5640000000001), (541.8798400000001, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='以大量减少人工标注的时间。几个月后谷歌推出了一个名为 BERT 的模型，该模型在学习了几', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.8796, 316.20400000000006), (541.8796, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='百万个句子 以 后 学 会 了如何预 测 漏掉的单词。 在多 项', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 337.08400000000006), (54.279903999999995, 349.08400000000006), (352.527904, 349.08400000000006), (352.527904, 337.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='NLP (Natural Language', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((392.95287999999994, 337.08400000000006), (392.95287999999994, 349.08400000000006), (545.4524799999999, 349.08400000000006), (545.4524799999999, 337.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='Processing) 测试中，它的表现都接近人类。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.72400000000005), (54.279903999999995, 381.72400000000005), (299.21464, 381.72400000000005), (299.21464, 369.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='2020 年 6 月，OpenAI 发布了有史以来最大的 NLP 模型 GPT-3，GPT-3 模型参数达到', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 401.884), (78.279904, 413.884), (541.8800799999999, 413.884), (541.8800799999999, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='了 1750 亿个参数，模型训练花费了上千万美元。GPT-3 训练方法很简单，但是却非常全能，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (547.8800799999999, 446.524), (547.8800799999999, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6941d39b552ca13c7e3d413b1ce3ae1c', 'page_number': 45, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='可以完成填空，翻译，问答，阅读理解，数学计算，语法纠错等多项任务。随着 NLP 技术的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (541.8800799999999, 479.16400000000004), (541.8800799999999, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='发展，相信在将来 AI 可以逐渐理解我们的语言，跟我们进行顺畅的对话，甚至成为我们的保', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (541.8799839999999, 511.80400000000003), (541.8799839999999, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='姆，老师或朋友。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (153.83190399999998, 544.444), (153.83190399999998, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='今天，人脸识别技术已经应用在了我们生活的方方面面，比如上下班打卡，飞机高铁出行，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 565.0840000000001), (78.279904, 577.0840000000001), (541.8807039999999, 577.0840000000001), (541.8807039999999, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='出门住酒店，刷脸支付等。我们已经离不开深度学习技术，而深度学习技术仍在快速发展中。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (546.8739040000002, 609.484), (546.8739040000002, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 45, 'category': 'Title'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='1.6 深度学习领域重要人物', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 80.52496000000008), (98.279896, 102.60496), (366.91432, 102.60496), (366.91432, 80.52496000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='深度学习领域有很多做出过卓越贡献的大师，下面简单介绍几位。前面的 3 位大师', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.48400000000004), (78.279904, 153.48400000000004), (541.1677599999999, 153.48400000000004), (541.1677599999999, 141.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='Geoffrey Hinton、Yann LeCun、Yoshua Bengio 江湖人称“深度学习三巨头”，为了表彰 3', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.8747999999999, 185.88400000000001), (541.8747999999999, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '3463a847219b3ef0439fc3d5eac80ca6', 'page_number': 46, 'category': 'NarrativeText'}),\n",
       " Document(page_content='位大师对于神经网络深度学习领域的贡献，2018 年计算机领域最高奖项图灵奖颁给了他们。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.524), (54.279903999999995, 218.524), (544.9803999999999, 218.524), (544.9803999999999, 206.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='1.Geoffrey Hinton', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 239.404), (78.279904, 251.404), (190.50042399999998, 251.404), (190.50042399999998, 239.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。Hinton 是反向传', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 271.804), (78.279904, 283.804), (540.54352, 283.804), (540.54352, 271.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='播算法和对比散度算法的发明人之一，也是深度学习的积极推动者。目前担任多伦多大学计', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.4440000000001), (54.279903999999995, 316.4440000000001), (534.279904, 316.4440000000001), (534.279904, 304.4440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='算机科学系教授。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 337.08400000000006), (54.279903999999995, 349.08400000000006), (153.83190399999998, 349.08400000000006), (153.83190399999998, 337.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='2013 年 3 月加入 Google，领导 Google Brain 项目。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 369.48400000000004), (78.279904, 381.48400000000004), (371.61904, 381.48400000000004), (371.61904, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='Hinton 被人们称为“深度学习教父”，可以说是目前对深度学习领域影响最大的人。而', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 402.124), (78.279904, 414.124), (534.543568, 414.124), (534.543568, 402.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='且如今在深度学习领域活跃的大师，有很多都是他的弟子，可以说是桃李满天下。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.764), (54.279903999999995, 446.764), (489.856, 446.764), (489.856, 434.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='2.Yann LeCun', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 467.644), (78.279904, 479.644), (162.52192, 479.644), (162.52192, 467.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='法国出生的计算机科学家，他最著名的工作是光学字符识别和计算机视觉上使用卷积神经', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 500.04400000000004), (78.279904, 512.0440000000001), (541.879504, 512.0440000000001), (541.879504, 500.04400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='网络（CNN），他也被称为卷积网络之父。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.684), (54.279903999999995, 544.684), (283.37104, 544.684), (283.37104, 532.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '5dd3f5217bdafc560950bd77d89c7ba1', 'page_number': 46, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='曾在多伦多大学跟随 Geoffrey Hinton 做博士后。1988 年加入贝尔实验室，在贝尔实验', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 565.0840000000001), (78.279904, 577.0840000000001), (541.8800799999999, 577.0840000000001), (541.8800799999999, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='室工作期间开发了一套能够识别手写数字的卷积神经网络系统，并把它命名为 LeNet。这个系', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.724), (54.279903999999995, 609.724), (541.87984, 609.724), (541.87984, 597.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='统能自动识别银行支票。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.364), (54.279903999999995, 642.364), (189.83190399999998, 642.364), (189.83190399999998, 630.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='2003 年去了纽约大学担任教授，现在是纽约大学终身教授。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 663.004), (78.279904, 675.004), (400.98040000000003, 675.004), (400.98040000000003, 663.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='2013 年 12 月加入了 Facebook，成为 Facebook 人工智能实验室的第一任主任。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 695.644), (78.279904, 707.644), (515.6718400000001, 707.644), (515.6718400000001, 695.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='3.Yoshua Bengio', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 728.524), (78.279904, 740.524), (181.51213599999997, 740.524), (181.51213599999997, 728.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 46, 'category': 'Title'}),\n",
       " Document(page_content='45', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '784033d2369b22489cd863a949000ddd', 'page_number': 46, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='毕业于麦吉尔大学，在 MIT 和贝尔实验室做过博士后研究员，自 1993 年之后就在蒙特', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (536.55928, 87.96400000000006), (536.55928, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='利尔大学任教。在预训练问题，自动编码器降噪等领域做出重大贡献。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (429.832, 120.60400000000004), (429.832, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='这“三巨头”中的前两人早已投身工业界，而 Bengio 仍留在学术界教书，他曾说过：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.24400000000003), (78.279904, 153.24400000000003), (532.51024, 153.24400000000003), (532.51024, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='“我留在学术圈是为全人类作贡献，而不是为某一公司赚钱”。他说这句话一定是因为他很有', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (540.279904, 185.88400000000001), (540.279904, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='钱，开个玩笑。每个领域的发展不仅需要做前沿的研究，还需要不断培养新的新鲜血液加入', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (534.279904, 218.284), (534.279904, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='到这个行业中，所以如果大学教授都去工作的话，上课教书的人就少了。所以 Bengio 能留', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (532.5102400000001, 250.9240000000001), (532.5102400000001, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='在学术圈，对行业的发展也是一件好事。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (273.832, 283.5640000000001), (273.832, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='2017 年初 Bengio 选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.20400000000006), (78.279904, 316.20400000000006), (539.6588079999999, 316.20400000000006), (539.6588079999999, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='指的显然是 Google 和 Facebook）成为人工智能变革中的唯一大玩家，这对研究社区没有', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (531.94792, 348.84400000000005), (531.94792, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='好处，对人类也没有好处。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (201.83190399999998, 381.48400000000004), (201.83190399999998, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='4.Andrew Ng（吴恩达）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 402.124), (78.279904, 414.124), (221.39048799999998, 414.124), (221.39048799999998, 402.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='Andrew Ng 是美籍华人，曾经是斯坦福大学计算机科学系和电气工程系的副教授，斯', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 434.524), (78.279904, 446.524), (530.4712959999999, 446.524), (530.4712959999999, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='坦福人工智能实验室主任。他还与 Daphne Koller 一起创建了在线教育平台 Coursera。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (523.56424, 479.16400000000004), (523.56424, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='2011 年，Andrew Ng 在 Google 创建了 Google Brain 项目，通过分布式集群计算机', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 499.80400000000003), (78.279904, 511.80400000000003), (534.2212, 511.80400000000003), (534.2212, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='开发超大规模的人工神经网络。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (225.83190399999998, 544.444), (225.83190399999998, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='2014 年 5 月，Andrew Ng 加入百度，负责百度大脑计划，并担任百度公司首席科学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 565.0840000000001), (78.279904, 577.0840000000001), (526.6568560000001, 577.0840000000001), (526.6568560000001, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='家。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (81.83190400000001, 609.484), (81.83190400000001, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='2017 年 3 月，Andrew Ng 从百度离职，目前自己创业。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 630.124), (78.279904, 642.124), (386.20888, 642.124), (386.20888, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='LeCun 是 Hinton 的 博士生，另一位人工智能大师 Jordan 曾经申请过 Hinton 的博士', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 662.764), (78.279904, 674.764), (534.08656, 674.764), (534.08656, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='生，Bengio 是 Jordan 的博士后，Andrew Ng 是 Jordan 的博士生，LeCun 与 Bengio 曾', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 695.404), (54.279903999999995, 707.404), (531.70768, 707.404), (531.70768, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='经是同事。这个圈子很小，大家都认识，这几位大师互相之间有着很深的渊源。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (477.832, 740.044), (477.832, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 47, 'category': 'Title'}),\n",
       " Document(page_content='46', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8d0081f03cc978896f124c0d5bbc8561', 'page_number': 47, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='曾经神经网络的圈子很小，基本上入了这个圈以后就没什么前途了。正是由于这个圈子', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (534.279904, 87.96400000000006), (534.279904, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='里的这些大师前辈们的不懈努力，把神经网络算法不断优化，才有了今天的深度学习和今天', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (534.279904, 120.60400000000004), (534.279904, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='人工智能的新局面。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (165.83190399999998, 153.24400000000003), (165.83190399999998, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='1.7 新一轮人工智能爆发的三要素', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 227.8849600000001), (98.279896, 249.96496000000002), (432.91432, 249.96496000000002), (432.91432, 227.8849600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='这一轮人工智能大爆发的主要原因有 3 个，深度学习算法，大数据，以及高性能计算。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 288.84400000000005), (78.279904, 300.84400000000005), (538.8690399999999, 300.84400000000005), (538.8690399999999, 288.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='深度学习算法 —— 之前人工智能领域的实际应用主要是使用传统的机器学习算法，虽', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 321.72400000000005), (78.279904, 333.72400000000005), (540.09592, 333.72400000000005), (540.09592, 321.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='然这些传统的机器学习算法在很多领域都取得了不错的效果，不过仍然有非常大的提升空间。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 353.884), (54.279903999999995, 365.884), (546.8343040000001, 365.884), (546.8343040000001, 353.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='深度学习出现后，计算机视觉，自然语言处理，语音识别等领域都取得了非常大的进步。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 386.524), (54.279903999999995, 398.524), (525.832, 398.524), (525.832, 386.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='大数据 —— 如果把人工智能比喻成一个火箭，那么这个火箭需要发射升空，它的燃料就', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 419.404), (78.279904, 431.404), (541.880176, 431.404), (541.880176, 419.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='是大数据。以前在实验室环境下很难收集到足够多的样本，现在的数据相对以前在数量、覆盖', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 451.80400000000003), (54.279903999999995, 463.80400000000003), (541.880704, 463.80400000000003), (541.880704, 451.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='性和全面性方面都获得了大幅提升。一般来说深度学习模型想要获得好的效果，就需要把大量', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 484.444), (54.279903999999995, 496.444), (541.8807039999999, 496.444), (541.8807039999999, 484.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='的数据放到模型中进行训练。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 517.0840000000001), (54.279903999999995, 529.0840000000001), (213.83190399999998, 529.0840000000001), (213.83190399999998, 517.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='高性能计算 —— 以前高性能计算大家 用的是 CPU 集群，现在做深度学习都是 用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 549.724), (78.279904, 561.724), (541.8800799999999, 561.724), (541.8800799999999, 549.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='GPU(Graphics Processing Unit)或 TPU(Tensor Processing Unit)。想要使用大量的数据', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 582.364), (54.279903999999995, 594.364), (541.8796, 594.364), (541.8796, 582.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='来训练复杂的深度学习模型那就必须要具备高性能计算能力。GPU 就是我们日常所说的显卡，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 614.764), (54.279903999999995, 626.764), (547.8800799999999, 626.764), (547.8800799999999, 614.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0f059820a02f7a9a5ddb8fcf29a6ca2b', 'page_number': 48, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='平时主要用于打游戏。但是 GPU 不仅可以用于打游戏，还可以用来训练模型，性价比很高，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 647.404), (54.279903999999995, 659.404), (541.880008, 659.404), (541.880008, 647.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0f059820a02f7a9a5ddb8fcf29a6ca2b', 'page_number': 48, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='买显卡的理由又多了一个。如果只是使用几个 CPU 来训练一个复杂模型可能会需要花费几周', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 680.0440000000001), (54.279903999999995, 692.0440000000001), (541.8800799999999, 692.0440000000001), (541.8800799999999, 680.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='甚至几个月的时间。把数百块 GPU 连接起来做成集群，用这些集群来训练模型，原来一个月', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 712.684), (54.279903999999995, 724.684), (541.8800799999999, 724.684), (541.8800799999999, 712.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 745.0840000000001), (54.279903999999995, 757.0840000000001), (541.8800799999999, 757.0840000000001), (541.8800799999999, 745.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 48, 'category': 'Title'}),\n",
       " Document(page_content='47', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ac8dc8674559ad07df4284891eec3a44', 'page_number': 48, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='间。TPU 是谷歌专门为机器学习量身定做的处理器，执行每个操作所需的晶体管数量更少，效', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.879264, 87.96400000000006), (541.879264, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='率更高。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (105.83190399999998, 120.60400000000004), (105.83190399999998, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='工欲善其事，必先利其器。下一章节我们将介绍如何搭建 python 开发环境，为我们后续', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (541.8796, 153.24400000000003), (541.8796, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='的学习做准。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (129.83190399999998, 185.88400000000001), (129.83190399999998, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='1.8 参考文献', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 243.72496), (54.279903999999995, 265.80495999999994), (185.4142, 265.80495999999994), (185.4142, 243.72496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 287.884), (54.279903999999995, 299.884), (545.4289119999997, 299.884), (545.4289119999997, 287.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='arXiv:1804.02767, 2018.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 320.524), (54.279903999999995, 332.524), (192.867064, 332.524), (192.867064, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd71e781c59c64e352763b42fbdc9516c', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='[2] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 353.16400000000004), (54.279903999999995, 365.16400000000004), (545.4291999999999, 365.16400000000004), (545.4291999999999, 353.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd71e781c59c64e352763b42fbdc9516c', 'page_number': 49, 'category': 'NarrativeText'}),\n",
       " Document(page_content='international conference on computer vision. 2017: 2961-2969.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 385.564), (54.279903999999995, 397.564), (418.14832, 397.564), (418.14832, 385.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='[3] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 418.20400000000006), (54.279903999999995, 430.20400000000006), (545.430304, 430.20400000000006), (545.430304, 418.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8038514927fa5711e46187345857792a', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='arXiv:1508.06576, 2015.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 450.84400000000005), (54.279903999999995, 462.84400000000005), (192.867064, 462.84400000000005), (192.867064, 450.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8038514927fa5711e46187345857792a', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='[4] Hebb D O. The organization of behavior: A neuropsychological theory[M].', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 483.48400000000004), (54.279903999999995, 495.48400000000004), (500.1423040000001, 495.48400000000004), (500.1423040000001, 483.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '8038514927fa5711e46187345857792a', 'page_number': 49, 'category': 'NarrativeText'}),\n",
       " Document(page_content='Psychology Press, 2005.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 516.124), (54.279903999999995, 528.124), (193.833856, 528.124), (193.833856, 516.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='[5] Minsky M, Papert S A. Perceptrons: An introduction to computational', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 548.764), (54.279903999999995, 560.764), (473.8035040000001, 560.764), (473.8035040000001, 548.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='geometry[M]. MIT press, 2017.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 581.164), (54.279903999999995, 593.164), (232.90415199999998, 593.164), (232.90415199999998, 581.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 49, 'category': 'Title'}),\n",
       " Document(page_content='[6] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 613.8040000000001), (54.279903999999995, 625.8040000000001), (500.78056, 625.8040000000001), (500.78056, 613.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a9026b8e4e64998afb6320021116f057', 'page_number': 49, 'category': 'NarrativeText'}),\n",
       " Document(page_content='propagating errors[J]. nature, 1986, 323(6088): 533-536.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 646.444), (54.279903999999995, 658.444), (377.87104, 658.444), (377.87104, 646.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a9026b8e4e64998afb6320021116f057', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='[7] Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets[J].', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 679.0840000000001), (54.279903999999995, 691.0840000000001), (542.501104, 691.0840000000001), (542.501104, 679.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a9026b8e4e64998afb6320021116f057', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='Neural computation, 2006, 18(7): 1527-1554.', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 711.724), (54.279903999999995, 723.724), (314.46088000000003, 723.724), (314.46088000000003, 711.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a9026b8e4e64998afb6320021116f057', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='48', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a9026b8e4e64998afb6320021116f057', 'page_number': 49, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='第 2 章-搭建 Python 编程环境', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((123.836776, 79.37104), (123.836776, 105.29103999999995), (479.99536, 105.29103999999995), (479.99536, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='本章节内容与深度学习没有直接关系，不过随着人工智能技术的发展，Python 已经成为', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 127.80400000000009), (78.279904, 139.8040000000001), (541.8800799999999, 139.8040000000001), (541.8800799999999, 127.80400000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='时下最热门的编程语言之一，广泛应用于机器学习和深度学习的应用中。目前大多数深度学习', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 160.44400000000007), (54.279903999999995, 172.44400000000007), (541.880704, 172.44400000000007), (541.880704, 160.44400000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='框架的主要编程语言都是 Python，Python 可谓是目前人工智能领域的第一语言。本书中使', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 193.08400000000006), (54.279903999999995, 205.08400000000006), (541.8800799999999, 205.08400000000006), (541.8800799999999, 193.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='用的所有代码都是 python 程序，所以这一章节我们主要学习 python 编程环境的搭建。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 225.72400000000005), (54.279903999999995, 237.72400000000005), (523.69912, 237.72400000000005), (523.69912, 225.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='如果大家之前有 python 基础那这一章节的内容就比较简单了，直接跳过也可以。如果大', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 258.36400000000003), (78.279904, 270.36400000000003), (541.8798879999999, 270.36400000000003), (541.8798879999999, 258.36400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='家之前完全没有学过 python，那么建议大家还是先学习 python 的使用，不然后续编程实践', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 290.764), (54.279903999999995, 302.764), (541.8800799999999, 302.764), (541.8800799999999, 290.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='的内容可能会碰到很多问题。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 323.404), (54.279903999999995, 335.40400000000005), (213.83190399999998, 335.40400000000005), (213.83190399999998, 323.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='2.1 Python 介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 410.28496000000007), (98.279896, 432.36496000000005), (266.37808, 432.36496000000005), (266.37808, 410.28496000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='Python 是一种面向对象的解释型计算机程序设计语言，由荷兰人 Guido van Rossum 于', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 471.004), (78.279904, 483.004), (541.8800799999999, 483.004), (541.8800799999999, 471.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='1989 年发明。Python 具有丰富强大的库，常被称为“胶水语言”，因为它能够把其他语言（尤', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 503.644), (54.279903999999995, 515.644), (541.8814239999999, 515.644), (541.8814239999999, 503.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='其是 C/C++）制作各种模块轻松联结在一起。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 536.2840000000001), (54.279903999999995, 548.2840000000001), (303.81424, 548.2840000000001), (303.81424, 536.2840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '4c318cb9e0b37a8128c98770ea3c655e', 'page_number': 50, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='Python 的主要优点是开发效率高，可移植性强，可拓展性强，应用广泛等，主要的缺点', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 568.924), (78.279904, 580.924), (541.8808, 580.924), (541.8808, 568.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='是程序运行效率相比 C/C++来说比较慢。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 601.5640000000001), (54.279903999999995, 613.5640000000001), (279.81424, 613.5640000000001), (279.81424, 601.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'da124f9619258c507decab295805e018', 'page_number': 50, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='Python 的主要应用领域有系统编程，网络爬虫，人工智能，科学计算，WEB 开发，系统', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 633.9639999999999), (78.279904, 645.9639999999999), (541.87936, 645.9639999999999), (541.87936, 633.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='运维，大数据，云计算，量化交易，金融分析，图形界面。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 666.604), (54.279903999999995, 678.604), (369.832, 678.604), (369.832, 666.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 699.244), (78.279904, 711.244), (541.8767199999999, 711.244), (541.8767199999999, 699.244)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='广告等项目都在大量使用 Python 开发。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 731.884), (54.279903999999995, 743.884), (272.44311999999996, 743.884), (272.44311999999996, 731.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='CIA: 美国中情局网站就是用 Python 开发的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 764.524), (78.279904, 776.524), (325.33, 776.524), (325.33, 764.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 50, 'category': 'Title'}),\n",
       " Document(page_content='49', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '495c0e2f0d24dd0184a85220f995b63b', 'page_number': 50, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='NASA: 美国航天局(NASA)大量使用 Python 进行数据分析和运算。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.96400000000006), (78.279904, 87.96400000000006), (440.48416, 87.96400000000006), (440.48416, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='YouTube:世界上最大的视频网站 YouTube 就是用 Python 开发的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 108.60400000000004), (78.279904, 120.60400000000004), (438.832, 120.60400000000004), (438.832, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='Dropbox:美国最大的在线云存储网站，全部用 Python 实现，每天网站处理 10 亿个文件', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.24400000000003), (78.279904, 153.24400000000003), (541.8800799999999, 153.24400000000003), (541.8800799999999, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='的上传和下载。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (141.83190399999998, 185.88400000000001), (141.83190399999998, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='Instagram:美国最大的图片分享社交网站，每天超过 3 千万张照片被分享，全部用 python', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 206.284), (78.279904, 218.284), (541.8915999999999, 218.284), (541.8915999999999, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='开发。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (93.83190399999998, 250.9240000000001), (93.83190399999998, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='Facebook:大量的基础库均通过 Python 实现的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 271.5640000000001), (78.279904, 283.5640000000001), (342.66208, 283.5640000000001), (342.66208, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='Redhat: 世界上最流行的 Linux 发行版本中的 yum 包管理工具就是用 python 开发的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.20400000000006), (78.279904, 316.20400000000006), (545.3142399999999, 316.20400000000006), (545.3142399999999, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='豆瓣: 公司几乎所有的业务均是通过 Python 开发的。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 336.84400000000005), (78.279904, 348.84400000000005), (365.332, 348.84400000000005), (365.332, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='知乎: 国内最大的问答社区，通过 Python 开发。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 369.48400000000004), (78.279904, 381.48400000000004), (341.332, 381.48400000000004), (341.332, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='2.2 Anaconda 安装', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 456.12496), (98.279896, 478.20496), (297.92776000000003, 478.20496), (297.92776000000003, 456.12496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='推荐的 Python 安装方式是使用 Anaconda 对 Python 进行安装。Anaconda 是一个开源', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 517.0840000000001), (75.279904, 529.0840000000001), (541.8800799999999, 529.0840000000001), (541.8800799999999, 517.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='的 Python 发行版本，其中包含了 Numpy,Pandas,Matplotlib 等多个常用的 Python 包和依', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 549.484), (54.279903999999995, 561.484), (541.8800799999999, 561.484), (541.8800799999999, 549.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='赖项。Anaconda 的官方下载地址为：https://www.anaconda.com/download/。官方下载', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 582.124), (54.279903999999995, 594.124), (541.88032, 594.124), (541.88032, 582.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='地址上大家看到的是最新的 python 安装包的下载，如果想下载之前版本的 python，可以通', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 614.764), (54.279903999999995, 626.764), (541.8800799999999, 626.764), (541.8800799999999, 614.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='过下面这个地址：https://repo.continuum.io/archive/。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 647.404), (54.279903999999995, 659.404), (364.69912, 659.404), (364.69912, 647.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='目前 Python 常用的版本有 2.7 和 3.6/3.7/3.8 版本，python 官方已经宣布以后 python2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 680.0440000000001), (75.279904, 692.0440000000001), (541.8747999999999, 692.0440000000001), (541.8747999999999, 680.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ea8b5f4a74ede48f9e9536cc6c02ad45', 'page_number': 51, 'category': 'NarrativeText'}),\n",
       " Document(page_content='将会停止维护，python 以后会逐渐往 python3 的方向发展，所以推荐大家学习 python3。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 712.684), (54.279903999999995, 724.684), (541.8800799999999, 724.684), (541.8800799999999, 712.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 51, 'category': 'Title'}),\n",
       " Document(page_content='之后 python 的版本还会不断更新，可能还会继续推出 3.9/3.10/4.0 等。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 745.0840000000001), (54.279903999999995, 757.0840000000001), (442.94512, 757.0840000000001), (442.94512, 745.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2c94be037dba4ecab313c3eeb033e3ee', 'page_number': 51, 'category': 'NarrativeText'}),\n",
       " Document(page_content='50', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2c94be037dba4ecab313c3eeb033e3ee', 'page_number': 51, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='Python2 和 python3 稍微有些差异，python3.6/3.7/3.8 之间的差异就不大了，所以我', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 75.96400000000006), (75.279904, 87.96400000000006), (541.8800799999999, 87.96400000000006), (541.8800799999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='们不一定要安装最新的 python，因为有些软件可能跟最新的 python 会不兼容。比如现在', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.25872, 120.60400000000004), (541.25872, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='python 的最新版本是 3.8，那么我们可以安装 3.6/3.7 的版本，这样兼容性会稍微好一些。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (538.7812, 153.24400000000003), (538.7812, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0e7354b82a48446ea8d7edea6aa9a787', 'page_number': 52, 'category': 'NarrativeText'}),\n",
       " Document(page_content='Python 程序在 Windows,Linux,MacOS 下基本是差不多的，所以在 Windows 上可以运', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 173.88400000000001), (75.279904, 185.88400000000001), (541.8800799999999, 185.88400000000001), (541.8800799999999, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='行的 Python 程序，在其他系统一般也能运行。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (308.44311999999996, 218.284), (308.44311999999996, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='下面我们主要讲解 Anaconda 在 Windows 环境下的安装，其他系统的安装方式略有不', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 238.9240000000001), (78.279904, 250.9240000000001), (541.8800799999999, 250.9240000000001), (541.8800799999999, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='同，如果你熟悉其他系统的话，安装起来应该也是很简单的。如果我们要安装最新版本的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (526.4079039999999, 283.5640000000001), (526.4079039999999, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='Anaconda，首先打开 Anaconda 下载网址，根据系统选择相应的 Anaconda 安装包。选择', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.8800799999999, 316.20400000000006), (541.8800799999999, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='Python3.7 版本、64 位的安装包进行下载，如图 2.1 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (374.44311999999996, 348.84400000000005), (374.44311999999996, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='图 2.1 Anaconda 下载', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((249.91287999999997, 548.764), (249.91287999999997, 560.764), (373.79895999999997, 560.764), (373.79895999999997, 548.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='如果我 们 要安装之前 版 本 的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 581.164), (78.279904, 593.164), (280.797904, 593.164), (280.797904, 581.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='Anaconda ， 可 以打开网 址', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((343.3348, 581.164), (343.3348, 593.164), (517.56952, 593.164), (517.56952, 581.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='https://repo.continuum.io/archive/，出现如图 2.2 所示的界面。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 613.8040000000001), (54.279903999999995, 625.8040000000001), (411.66207999999995, 625.8040000000001), (411.66207999999995, 613.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 52, 'category': 'Title'}),\n",
       " Document(page_content='51', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '5b4c11e3a210603e49eab80d8ba40887', 'page_number': 52, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='图 2.2 各种版本的 Anaconda', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((230.688328, 336.84400000000005), (230.688328, 348.84400000000005), (393.02344, 348.84400000000005), (393.02344, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='Anaconda2 表示安装 python2，Anaconda3 表示安装 python3，具体是 python3.X，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 369.48400000000004), (78.279904, 381.48400000000004), (541.8800799999999, 381.48400000000004), (541.8800799999999, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='从安装包的文件名是看不出来的。Windows/MacOSX/Linux 表示对应的操作系统。有 64 表', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.884), (54.279903999999995, 413.884), (541.8800799999999, 413.884), (541.8800799999999, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='示 64 位的系统，没有 64 表示 32 位的系统。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (298.05447999999996, 446.524), (298.05447999999996, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='安装包下载好之后，双击安装包进行安装。如图 2.3 所示，单击 Next 按钮,。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 467.16400000000004), (75.279904, 479.16400000000004), (485.80071999999996, 479.16400000000004), (485.80071999999996, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 53, 'category': 'Title'}),\n",
       " Document(page_content='52', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '689adea096b25440bfb424ade40e4d4a', 'page_number': 53, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 54, 'category': 'Title'}),\n",
       " Document(page_content='图 2.3 Anaconda 安装流程（1）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((210.394408, 75.96400000000006), (210.394408, 87.96400000000006), (389.3176, 87.96400000000006), (389.3176, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 54, 'category': 'Title'}),\n",
       " Document(page_content='然后单击 I Agree 按钮，如图 2.4 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 108.60400000000004), (75.279904, 120.60400000000004), (293.02144, 120.60400000000004), (293.02144, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 54, 'category': 'Title'}),\n",
       " Document(page_content='图 2.4 Anaconda 安装流程（2）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((220.894408, 434.524), (220.894408, 446.524), (399.8176, 446.524), (399.8176, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 54, 'category': 'Title'}),\n",
       " Document(page_content='接下来可以选择 All Users，单击 Next 按钮，如图 2.5 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 467.16400000000004), (75.279904, 479.16400000000004), (403.83976, 479.16400000000004), (403.83976, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 54, 'category': 'Title'}),\n",
       " Document(page_content='53', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '45f25fec32e406eece437adde3571c28', 'page_number': 54, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='图 2.5 Anaconda 安装流程（3）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((220.894408, 75.96400000000006), (220.894408, 87.96400000000006), (399.8176, 87.96400000000006), (399.8176, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='接下来选择一个 Anaconda 的安装路径，如图 2.6 所示，可以是任何路径，不一定要跟', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 108.60400000000004), (75.279904, 120.60400000000004), (534.06304, 120.60400000000004), (534.06304, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='图中的路径一致。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (153.83190399999998, 153.24400000000003), (153.83190399999998, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='图 2.6 Anaconda 安装流程（4）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((220.894408, 467.16400000000004), (220.894408, 479.16400000000004), (399.8176, 479.16400000000004), (399.8176, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='最后勾选“Add Anaconda to the system PATH environment variable”和', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 499.80400000000003), (75.279904, 511.80400000000003), (484.13536, 511.80400000000003), (484.13536, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='“Register Anaconda as the system Python3.6”，然后单击 Install 按钮，Anaconda 就', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 532.444), (54.279903999999995, 544.444), (531.4204, 544.444), (531.4204, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='开始安装了。这里注意，一定要勾选相应选项，其目的是让软件帮我们自动配置环境变量，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (534.279904, 577.0840000000001), (534.279904, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='如图 2.7 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 597.484), (54.279903999999995, 609.484), (140.794792, 609.484), (140.794792, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 55, 'category': 'Title'}),\n",
       " Document(page_content='54', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1c556ee4a6454f0de13536edafdac4cf', 'page_number': 55, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='图 2.7 Anaconda 安装流程（5）', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((220.894408, 369.48400000000004), (220.894408, 381.48400000000004), (399.8176, 381.48400000000004), (399.8176, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='安装的过程大家不要心急，耐心等待，不要随意关闭软件的窗口，等确认软件已经安装', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 401.884), (75.279904, 413.884), (531.279904, 413.884), (531.279904, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='完毕再关闭窗口。后面软件会有提示是否要安装 VSCode，VSCode 是一款很好用的编译', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (522.30328, 446.524), (522.30328, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='器，可以用于开发各种编程语言写的程序，包括 python。大家感兴趣的话可以安装，不安', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (530.21344, 479.16400000000004), (530.21344, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='装也可以。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (117.83190399999998, 511.80400000000003), (117.83190399999998, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='2.3 Jupyter Notebook 的简单使用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 586.68496), (98.279896, 608.76496), (447.7276, 608.76496), (447.7276, 586.68496)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='Python 有非常多的集成开发环境可以使用，比如 Jupyter Notebook，Spyder，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 647.404), (75.279904, 659.404), (505.36384, 659.404), (505.36384, 647.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='PyCharm，Eclipse，VSCode 等等，每种开发环境都各有优缺点，这里就不一一介绍了。如', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 680.0440000000001), (54.279903999999995, 692.0440000000001), (540.8658399999999, 692.0440000000001), (540.8658399999999, 680.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='果大家之前已经有熟悉并喜欢的开发环境可以继续使用，如果大家是初学者对各种开发环境', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 712.684), (54.279903999999995, 724.684), (534.279904, 724.684), (534.279904, 712.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='不了解的话推荐大家可以先使用 Jupyter Notebook。Jupyter Notebook 的优点是界面和', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 745.0840000000001), (54.279903999999995, 757.0840000000001), (531.3385599999999, 757.0840000000001), (531.3385599999999, 745.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 56, 'category': 'Title'}),\n",
       " Document(page_content='55', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'eb5fa9ab734549259c943d25d3ad65be', 'page_number': 56, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='功能都比较简洁，并且可以实时运行查看程序结果，还可以把程序运行的结果保存在文件', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (522.279904, 87.96400000000006), (522.279904, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='中。缺点是不太好开发大型程序，不过对于初学者来说，我们可能暂时还不会接触到大型程', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (534.279904, 120.60400000000004), (534.279904, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='序，Jupyter Notebook 基本就够用了。本书中的程序基本都是在 Jupyter Notebook 中完', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (534.33856, 153.24400000000003), (534.33856, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='成的，它是安装完 Anaconda 后自带的一个 Python 开发环境。界面简洁，使用简单，适合', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (536.71144, 185.88400000000001), (536.71144, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='快速实验和用于学习。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (177.83190399999998, 218.284), (177.83190399999998, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='我会给大家提供书中 Jupyter Notebook 的程序文件以及 python 的程序文件。Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 238.9240000000001), (75.279904, 250.9240000000001), (541.25368, 250.9240000000001), (541.25368, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='Notebook 的程序文件是以“.ipynb”结尾，只能在 Jupyter Notebook 中运行，不能在命', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.5640000000001), (54.279903999999995, 283.5640000000001), (535.98496, 283.5640000000001), (535.98496, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='令提示符/终端运行；python 的程序文件是以“.py”结尾，不能在 Jupyter Notebook 中运', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (541.774, 316.20400000000006), (541.774, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='行，可以在其他 python 集成开发环境或者命令提示符/终端运行。Jupyter Notebook 的程', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 336.84400000000005), (54.279903999999995, 348.84400000000005), (536.8698400000001, 348.84400000000005), (536.8698400000001, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='序文件可以在 Jupyter Notebook 环境中转成 python 程序文件。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 369.48400000000004), (54.279903999999995, 381.48400000000004), (406.29472000000004, 381.48400000000004), (406.29472000000004, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='2.3.1 启动 Jupyter Notebook', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 413.51296), (86.279896, 429.59296), (304.93024, 429.59296), (304.93024, 413.51296)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='Anaconda 安装完成后桌面上不会增加新的图标，我们需要搜索 Jupyter Notebook，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 460.684), (75.279904, 472.684), (530.6296, 472.684), (530.6296, 460.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='找到这个开发环境，Jupyter 的图标如图 2.8 所示，找到后可以右键单击图标，然后发送到', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 493.084), (54.279903999999995, 505.084), (530.20168, 505.084), (530.20168, 493.084)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='桌面快捷方式。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 525.724), (54.279903999999995, 537.724), (141.83190399999998, 537.724), (141.83190399999998, 525.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='图 2.8 Jupyter Notebook', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((239.058472, 688.684), (239.058472, 700.684), (381.65344, 700.684), (381.65344, 688.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='双击 Jupyter Notebook，打开后可以看到 Jupyter 是在网页中进行编程的，在 Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 721.3240000000001), (75.279904, 733.3240000000001), (538.72984, 733.3240000000001), (538.72984, 721.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='的界面中我们可以对我们电脑本地的文件进行新建，删除和修改，如图 2.9 所示', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 753.964), (54.279903999999995, 765.964), (476.79472000000004, 765.964), (476.79472000000004, 753.964)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 57, 'category': 'Title'}),\n",
       " Document(page_content='56', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b04f87bf3a3487b5cc9a818c642dc452', 'page_number': 57, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='图 2.9 Jupyter 主界面', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((250.34368, 189.96400000000006), (250.34368, 201.96400000000006), (370.36816, 201.96400000000006), (370.36816, 189.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='2.3.2 修改 Jupyter Notebook 默认启动路径', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 234.23296000000005), (86.279896, 250.31295999999998), (408.93015999999994, 250.31295999999998), (408.93015999999994, 234.23296000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='大家打开 Jupyter 后，可能会在的主界面中看到一些熟悉的文件，这些文件正是我们电', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 281.164), (75.279904, 293.164), (531.238888, 293.164), (531.238888, 281.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='脑本地的一些文件，其实 Jupyter 的主界面对应的是我们电脑中的一个路径，这个路径是可', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 313.804), (54.279903999999995, 325.804), (534.238888, 325.804), (534.238888, 313.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='以修改的，我们可以创建一个新的文件夹，专门用于写 python 程序。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 346.4440000000001), (54.279903999999995, 358.4440000000001), (428.76544, 358.4440000000001), (428.76544, 346.4440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='Jupyter Notebook 的默认启动路径为：”C:\\\\User\\\\你的用户名\\\\”。所以第一次打开', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 379.08400000000006), (75.279904, 391.08400000000006), (521.60608, 391.08400000000006), (521.60608, 379.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='Jupyter Notebook 我们会看到”C:\\\\User\\\\你的用户名\\\\”这个路径的文件出现在 Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 411.72400000000005), (54.279903999999995, 423.72400000000005), (525.1220800000001, 423.72400000000005), (525.1220800000001, 411.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='Notebook 的主界面。其实 Jupyter Notebook 的启动路径不一定要修改，如果你想使', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 444.36400000000003), (54.279903999999995, 456.36400000000003), (512.8288, 456.36400000000003), (512.8288, 444.36400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='用”C:\\\\User\\\\你的用户名\\\\”或者你觉得修改 Jupyter Notebook 默认路径比较麻烦，那么你', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 476.764), (54.279903999999995, 488.764), (539.60608, 488.764), (539.60608, 476.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='可以使用默认的”C:\\\\User\\\\你的用户名\\\\”路径作为 Jupyter Notebook 的工作路径。只要把', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 509.40400000000005), (54.279903999999995, 521.404), (539.60608, 521.404), (539.60608, 509.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='python 相关的程序（比如书中代码）复制到”C:\\\\User\\\\你的用户名\\\\”路径下，在 Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 542.0440000000001), (54.279903999999995, 554.0440000000001), (534.52648, 554.0440000000001), (534.52648, 542.0440000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='Notebook 的主界面就可以看到你复制的程序，然后在 Jupyter Notebook 环境中就可以对', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 574.684), (54.279903999999995, 586.684), (536.8288, 586.684), (536.8288, 574.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='这些程序进行修改和运行了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 607.3240000000001), (54.279903999999995, 619.3240000000001), (213.83190399999998, 619.3240000000001), (213.83190399999998, 607.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='如果希望把程序存放在其他路径，使用其他路径作为 Jupyter Notebook 的工作路径，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 639.9639999999999), (75.279904, 651.9639999999999), (532.80928, 651.9639999999999), (532.80928, 639.9639999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='那么就进行下面的操作：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 672.364), (54.279903999999995, 684.364), (189.83190399999998, 684.364), (189.83190399999998, 672.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='首先我们要右键 Jupyter Notebook 的图标，查看属性，然后看到目标，目标最后如果', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 705.004), (75.279904, 717.004), (532.80928, 717.004), (532.80928, 705.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 58, 'category': 'Title'}),\n",
       " Document(page_content='有%USERPROFILE%，则把后面的%USERPROFILE%删掉，如图 2.10 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 737.644), (54.279903999999995, 749.644), (466.13656, 749.644), (466.13656, 737.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0a088b79fb9efe6d3946f7e290eddb7f', 'page_number': 58, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='57', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '0a088b79fb9efe6d3946f7e290eddb7f', 'page_number': 58, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='图 2.10 删除%USERPROFILE%', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((224.50376799999998, 238.9240000000001), (224.50376799999998, 250.9240000000001), (396.20824, 250.9240000000001), (396.20824, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 59, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='下一步需要生成配置文件，打开命令提示符执行：jupyter notebook --generate-config，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 271.5640000000001), (75.279904, 283.5640000000001), (547.8800799999999, 283.5640000000001), (547.8800799999999, 271.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='我们会看到如图 2.11 所示的结果。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (243.83190399999998, 316.20400000000006), (243.83190399999998, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='图 2.11 生成配置文件', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((250.07991999999996, 369.48400000000004), (250.07991999999996, 381.48400000000004), (370.63192000000004, 381.48400000000004), (370.63192000000004, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='我 们 可 以看到 配置文件生成 的 位置， 本 书例子中配置文件生成 的 位置', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 401.884), (75.279904, 413.884), (472.035904, 413.884), (472.035904, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='是 C:\\\\Users\\\\qin\\\\.jupyter\\\\jupyter_notebook_config.py，进入系统盘，用户文件下，可以看', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (541.8796, 446.524), (541.8796, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='到一个.jupyter 的文件，如图 2.12 所示', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (266.13256, 479.16400000000004), (266.13256, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='图 2.12 .jupyter 文件', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((262.65424, 728.044), (262.65424, 740.044), (379.05784, 740.044), (379.05784, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 59, 'category': 'Title'}),\n",
       " Document(page_content='58', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '7bc8ee9d6325bb578d48a7b94a4a8039', 'page_number': 59, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='进入.jupyter 文件夹中找到 jupyter_notebook_config.py 文件，用文本工具打开', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 75.96400000000006), (75.279904, 87.96400000000006), (503.3833599999999, 87.96400000000006), (503.3833599999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='jupyter_notebook_config.py 文件，找 c.NotebookApp.notebook_dir 配置，“#”为注', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (526.81504, 120.60400000000004), (526.81504, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='释，先把它前面的“#”给去掉，然后填入你想要的 Python 程序存放路径。如图 2.13 所', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (522.54952, 153.24400000000003), (522.54952, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'db8c16745c9b82f23569e67dc03de3f5', 'page_number': 60, 'category': 'NarrativeText'}),\n",
       " Document(page_content='示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (81.83190400000001, 185.88400000000001), (81.83190400000001, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='图 2.13 修改 Jupyter 工作路径', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((236.60044, 369.48400000000004), (236.60044, 381.48400000000004), (405.11152, 381.48400000000004), (405.11152, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='图中的例子是在“E/test”，大家不一定要使用这个路径，可以任意设置其他路径。注意', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 401.884), (75.279904, 413.884), (534.209584, 413.884), (534.209584, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='这里设置的路径必须是本地已经存在的路径。注意路径最好是全英文，如果路径有中文需要', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (534.279904, 446.524), (534.279904, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='把 jupyter_notebook_config.py 文件另存为 UTF-8 的格式。注意路径中的斜杠是“/”不是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 467.16400000000004), (54.279903999999995, 479.16400000000004), (541.6508799999999, 479.16400000000004), (541.6508799999999, 467.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='“\\\\”。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 499.80400000000003), (54.279903999999995, 511.80400000000003), (95.272096, 511.80400000000003), (95.272096, 499.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '551ea3a40b221aa349994de4d3499b6f', 'page_number': 60, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='顺利的话，重新启动 Jupyter Notebook 就可以看到 Jupyter 的主界面跳转到了你设置', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 532.444), (75.279904, 544.444), (532.76824, 544.444), (532.76824, 532.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='的路径。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 565.0840000000001), (54.279903999999995, 577.0840000000001), (105.83190399999998, 577.0840000000001), (105.83190399999998, 565.0840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='如果是使用 Linux 或者 MacOS 的话可以先在终端用 cd 命令跳转到你的程序所在路径，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 597.484), (75.279904, 609.484), (538.2760000000001, 609.484), (538.2760000000001, 597.484)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='然后使用命令：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 630.124), (54.279903999999995, 642.124), (141.83190399999998, 642.124), (141.83190399999998, 630.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='jupyter notebook', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 662.764), (75.279904, 674.764), (178.453, 674.764), (178.453, 662.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='打开 Jupyter Notebook 软件，这时你会看到你的程序所在路径已经成为你的 Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 695.404), (75.279904, 707.404), (533.32024, 707.404), (533.32024, 695.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='Notebook 的工作路径。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 728.044), (54.279903999999995, 740.044), (190.85142399999998, 740.044), (190.85142399999998, 728.044)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 60, 'category': 'Title'}),\n",
       " Document(page_content='59', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'cf4afe7fd7bdc9fb3d94c23bd11dd0b4', 'page_number': 60, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='2.3.3 Jupyter Notebook 浏览器无法打开', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 74.63296000000003), (86.279896, 90.71295999999995), (385.66455999999994, 90.71295999999995), (385.66455999999994, 74.63296000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='如果电脑的浏览器太老，有可能会出现 Jupyter Notebook 无法打开的情况，Jupyter', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 121.56400000000008), (75.279904, 133.56400000000008), (530.32024, 133.56400000000008), (530.32024, 121.56400000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='Notebook 闪退，或者是浏览器一片空白。这个时候可以下载安装一个新的谷歌浏览器，然', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 154.20400000000006), (54.279903999999995, 166.20400000000006), (535.29952, 166.20400000000006), (535.29952, 154.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='后再打开 Jupyter Notebook 的配置文件，在任意位置加入如下命令：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 186.84400000000005), (54.279903999999995, 198.84400000000005), (431.36128, 198.84400000000005), (431.36128, 186.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='import webbrowser', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((66.27990399999999, 219.48400000000004), (66.27990399999999, 231.48400000000004), (182.54869599999998, 231.48400000000004), (182.54869599999998, 219.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='webbrowser.register(\"chrome\",None,webbrowser.GenericBrowser(u\"C:/ProgramFile', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((66.27990399999999, 251.88400000000001), (66.27990399999999, 263.884), (539.0487039999998, 263.884), (539.0487039999998, 251.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='s(x86)/Google/Chrome/Application/chrome.exe\"))', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((66.27990399999999, 284.524), (66.27990399999999, 296.524), (355.50568, 296.524), (355.50568, 284.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content=\"c.NotebookApp.browser = 'chrome'\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((66.27990399999999, 317.164), (66.27990399999999, 329.164), (274.54096, 329.164), (274.54096, 317.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='该命令的作用是把 Jupyter Notebook 的默认浏览器设置为谷歌浏览器，其中', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((66.27990399999999, 349.80400000000003), (66.27990399999999, 361.80400000000003), (475.80928, 361.80400000000003), (475.80928, 349.80400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\"为谷歌浏览器的执行', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 382.444), (54.279903999999995, 394.444), (530.2955199999999, 394.444), (530.2955199999999, 382.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='文件所在位置，每台电脑位置可能不同，需要自己查看修改。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 415.08400000000006), (54.279903999999995, 427.08400000000006), (381.832, 427.08400000000006), (381.832, 415.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='2.3.4 Jupyter Notebook 基本操作', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 459.11296000000004), (86.279896, 475.19296), (337.66455999999994, 475.19296), (337.66455999999994, 459.11296000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='接下来新建一个文件，单击右上角的 New 按钮，然后单击 Python 选项，这样就可以创', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 506.28400000000005), (75.279904, 518.2840000000001), (537.93016, 518.2840000000001), (537.93016, 506.28400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='建一个新的文件，如图 2.14 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 538.684), (54.279903999999995, 550.684), (243.83190399999998, 550.684), (243.83190399999998, 538.684)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='图 2.14 创建新文件', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((266.57992, 685.5640000000001), (266.57992, 697.5640000000001), (375.13192000000004, 697.5640000000001), (375.13192000000004, 685.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='创建好文件之后，可以看到如图 2.15 所示的界面。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 717.964), (75.279904, 729.964), (348.832, 729.964), (348.832, 717.964)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 61, 'category': 'Title'}),\n",
       " Document(page_content='60', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'dc22dbe8be9d047dd3154a6630cc7a23', 'page_number': 61, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='图 2.15 Jupyter 编译界面', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((251.32504, 173.88400000000001), (251.32504, 185.88400000000001), (390.3868, 185.88400000000001), (390.3868, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='单击 Untitled 的位置可以修改文件名字，如图 2.16 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 206.284), (75.279904, 218.284), (388.99791999999997, 218.284), (388.99791999999997, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '9bc4de087b879a24ad35134fff3a6a8a', 'page_number': 62, 'category': 'NarrativeText'}),\n",
       " Document(page_content='图 2.16 Jupyter 修改文件名', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((245.325064, 353.16400000000004), (245.325064, 365.16400000000004), (396.3868, 365.16400000000004), (396.3868, 353.16400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='然后就可以开始编程了，按照惯例，我们先来写一个“hello world”，写完之后，按', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 385.564), (75.279904, 397.564), (517.56304, 397.564), (517.56304, 385.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='“Shift+Enter”组合键执行程序，按住 Shift 不要放手，然后按 Enter。如图 2.17 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 418.20400000000006), (54.279903999999995, 430.20400000000006), (529.98616, 430.20400000000006), (529.98616, 418.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='图 2.17 执行 hello world', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((250.9384, 581.164), (250.9384, 593.164), (390.77344, 593.164), (390.77344, 581.164)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='一个框内可以执行多行代码，如图 2.18 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 613.8040000000001), (75.279904, 625.8040000000001), (324.832, 625.8040000000001), (324.832, 613.8040000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 62, 'category': 'Title'}),\n",
       " Document(page_content='61', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b895beeabc12637ccfa0e9374733129a', 'page_number': 62, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='图 2.18 执行多行代码', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((260.57992, 75.96400000000006), (260.57992, 87.96400000000006), (381.13192000000004, 87.96400000000006), (381.13192000000004, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='把光标移动到函数的内部，然后按“Shift+Tab”组合键可以查看该函数的使用方法，先按', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 108.60400000000004), (75.279904, 120.60400000000004), (541.88056, 120.60400000000004), (541.88056, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='住 Shift 不要放手，然后按两下 Tab，如图 2.19 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (347.00968, 153.24400000000003), (347.00968, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='图 2.19 查看函数说明', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((260.57992, 336.84400000000005), (260.57992, 348.84400000000005), (381.13192000000004, 348.84400000000005), (381.13192000000004, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='Jupyter 还有很多神奇的用法，大家有兴趣可以去探索，这里就不过多介绍了。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 369.48400000000004), (75.279904, 381.48400000000004), (495.79096, 381.48400000000004), (495.79096, 369.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='下一章我们将正式开始进入神经网络深度学习的大门。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 401.884), (75.279904, 413.884), (366.832, 413.884), (366.832, 401.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 63, 'category': 'Title'}),\n",
       " Document(page_content='62', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd05b6ef5967f8a1636aa73483434bff2', 'page_number': 63, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='第 3 章-单层感知器与线性神经网络', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((96.332392, 79.37104), (96.332392, 105.29103999999995), (507.49984, 105.29103999999995), (507.49984, 79.37104)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络 ANN 的设', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 127.80400000000009), (78.279904, 139.8040000000001), (541.88008, 139.8040000000001), (541.88008, 127.80400000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='计实际上是从生物体的神经网络结构获得的灵感。模仿生物神经网络我们构造出了单层感知器，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 160.44400000000007), (54.279903999999995, 172.44400000000007), (553.8800799999999, 172.44400000000007), (553.8800799999999, 160.44400000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='在单层感知器的基础上经过不断地优化才得到了后来的神经网络算法。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 192.72400000000005), (54.279903999999995, 205.08400000000006), (429.568, 205.08400000000006), (429.568, 192.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='3.1 生物神经网络', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 263.6449600000001), (98.279896, 285.72496), (273.41416, 285.72496), (273.41416, 263.6449600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='生物神经网络一般是指生物的大脑神经元，细胞等组成的网络，用于产生生物的意识，帮', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 324.36400000000003), (78.279904, 336.36400000000003), (541.880704, 336.36400000000003), (541.880704, 324.36400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='助生物进行思考和行动。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 357.004), (54.279903999999995, 369.004), (189.83190399999998, 369.004), (189.83190399999998, 357.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='神经细胞构是构成神经系统的基本单元，简称为神经元。神经元主要由三部分构成：①细', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 389.644), (78.279904, 401.644), (541.880704, 401.644), (541.880704, 389.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='胞体；②轴突；③树突。如 3.1 图所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 422.284), (54.279903999999995, 434.284), (272.79472000000004, 434.284), (272.79472000000004, 422.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='图 3.1 生物神经元结构', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((249.09848799999997, 650.2840000000001), (249.09848799999997, 662.2840000000001), (374.61328, 662.2840000000001), (374.61328, 650.2840000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='每个神经元伸出的突起分 2 种，树突和轴突。树突分支比较多，每个分支还可以再分支，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 682.924), (78.279904, 694.924), (547.8799839999999, 694.924), (547.8799839999999, 682.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='长度一般比较短，作用是接受信号。轴突只有一个，从细胞体的一个凸出部分伸出，长度一般', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 715.564), (54.279903999999995, 727.564), (541.8783040000001, 727.564), (541.8783040000001, 715.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 64, 'category': 'Title'}),\n",
       " Document(page_content='63', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '43123e51cc2ef72074bbfbf0012f0d4c', 'page_number': 64, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='比较长，作用是把从树突和细胞表面传入细胞体的神经信号传出到其他神经元。轴突的末端分', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (541.8807039999999, 87.96400000000006), (541.8807039999999, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='为许多小支，连接到其他神经元的树突上。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (285.832, 120.60400000000004), (285.832, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='大脑可视作为 1000 多亿神经元组成的神经网络。神经元的信息传递和处理是一种电化学', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 141.24400000000003), (78.279904, 153.24400000000003), (541.8795279999999, 153.24400000000003), (541.8795279999999, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='活动。树突由于电化学作用接受外界的刺激，通过胞体内的活动体现为轴突电位，当轴突电位', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.880536, 185.88400000000001), (541.880536, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='达到一定的值则形成神经脉冲或动作电位；再通过轴突末梢传递给其它的神经元。从控制论的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.284), (54.279903999999995, 218.284), (541.8800799999999, 218.284), (541.8800799999999, 206.284)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='观点来看，这一过程可以看作一个多输入单输出非线性系统的动态过程。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 238.9240000000001), (54.279903999999995, 250.9240000000001), (441.832, 250.9240000000001), (441.832, 238.9240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='3.2 单层感知器', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 325.80496000000005), (98.279896, 347.88496000000004), (251.4142, 347.88496000000004), (251.4142, 325.80496000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='3.2.1 单层感知器介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 385.1929600000001), (86.279896, 401.27296000000007), (242.89112799999998, 401.27296000000007), (242.89112799999998, 385.1929600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='受到生物神经网络的启发，计算机学家 Frank Rosenblatt 在 20 世纪 60 年代提出了一种', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 432.124), (78.279904, 444.124), (541.8800799999999, 444.124), (541.8800799999999, 432.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ab7f8bdea34eb62734f41d9cf482bec0', 'page_number': 65, 'category': 'NarrativeText'}),\n",
       " Document(page_content='模拟生物神经网络的的人工神经网络结构，称为感知器（Perceptron）。图 3.1 为单层感知器', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 464.764), (54.279903999999995, 476.764), (541.8800799999999, 476.764), (541.8800799999999, 464.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='结构图。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 497.40400000000005), (54.279903999999995, 509.40400000000005), (105.83190399999998, 509.40400000000005), (105.83190399999998, 497.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='图 3.1 单层感知器', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((261.09855999999996, 725.644), (261.09855999999996, 737.644), (362.61328, 737.644), (362.61328, 725.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='图中𝑥\"，𝑥#，𝑥$为输入信号，类似于生物神经网络中的树突。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 757.804), (78.279904, 771.4048), (404.61952, 771.4048), (404.61952, 757.804)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 65, 'category': 'Title'}),\n",
       " Document(page_content='64', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1100e9f663c1339a098c727dcd4bf9b1', 'page_number': 65, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='65', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤\"，𝑤#，𝑤$分别为𝑥\"，𝑥#，𝑥$的权值，它可以调节输入信号的值的大小，让输入信号变大', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 75.48400000000004), (78.279904, 89.08479999999997), (541.8796, 89.08479999999997), (541.8796, 75.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 108.60400000000004), (54.279903999999995, 120.60400000000004), (541.8792159999999, 120.60400000000004), (541.8792159999999, 108.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='传递到细胞核的过程中信号会发生变化。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 141.24400000000003), (54.279903999999995, 153.24400000000003), (273.832, 153.24400000000003), (273.832, 141.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='公式∑ (𝑤(𝑥() + 𝑏', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 172.92399999999998), (78.279904, 187.00479999999993), (167.215432, 187.00479999999993), (167.215432, 172.92399999999998)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f5bb3e29e018b27dda1066eff0908394', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((110.944192, 178.60479999999995), (110.944192, 187.00479999999993), (113.89259200000001, 187.00479999999993), (113.89259200000001, 178.60479999999995)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f5bb3e29e018b27dda1066eff0908394', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='表示细胞的输入信号在细胞核的位置进行汇总 ∑ 𝑤(𝑥(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((167.56088799999998, 172.92399999999998), (167.56088799999998, 187.00479999999993), (444.41008, 187.00479999999993), (444.41008, 172.92399999999998)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((417.68631999999997, 178.60479999999995), (417.68631999999997, 187.00479999999993), (420.63471999999996, 187.00479999999993), (420.63471999999996, 178.60479999999995)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a2a3a397811fd14abc05d3b523dc18ee', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='，然后再加上该细', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((445.31152, 173.88400000000001), (445.31152, 185.88400000000001), (541.4747199999999, 185.88400000000001), (541.4747199999999, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='胞本身自带的信号 b。b一般称为偏置值（Bias），相当于是神经元内部自带的信号。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 206.04399999999998), (54.279903999999995, 218.524), (503.57800000000003, 218.524), (503.57800000000003, 206.04399999999998)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='f(x)称为激活函数，可以理解为信号在轴突上进行的线性或非线性变化。在单层感知器中', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 238.44400000000007), (78.279904, 250.9240000000001), (540.92176, 250.9240000000001), (540.92176, 238.44400000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='最开始使用的激活函数是 sign(x)激活函数。该函数的特点是当 x＞0 时，输出值为 1；当 x＝', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 271.08400000000006), (54.279903999999995, 283.5640000000001), (541.8800799999999, 283.5640000000001), (541.8800799999999, 271.08400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6144ed9ad58f0db5048b85ede9b51113', 'page_number': 66, 'category': 'NarrativeText'}),\n",
       " Document(page_content='0 时，输出值为 0,；当 x＜0 时，输出值为-1。sign(x)函数图像如图 3.2 所示。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 304.20400000000006), (54.279903999999995, 316.20400000000006), (473.02144, 316.20400000000006), (473.02144, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6144ed9ad58f0db5048b85ede9b51113', 'page_number': 66, 'category': 'NarrativeText'}),\n",
       " Document(page_content='图 3.2 sign 函数图像', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((254.914, 548.764), (254.914, 560.764), (368.79807999999997, 560.764), (368.79807999999997, 548.764)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='y 就是𝑓(∑ (𝑤(𝑥() + 𝑏 (', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 580.204), (78.279904, 594.2848), (188.334304, 594.2848), (188.334304, 580.204)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '543918845bbe0e0010ab9521e87428d0', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content=')，为单层感知器的输出结果。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((188.68, 580.204), (188.68, 593.164), (353.13112, 593.164), (353.13112, 580.204)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='3.2.2 单层感知器计算举例', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 659.99296), (86.279896, 676.07296), (274.89112, 676.07296), (274.89112, 659.99296)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='假如有一个单层感知器有 3 个输入𝑥\"，𝑥#，𝑥$，同时已知 b=-0.6，𝑤\"=𝑤#=𝑤$=0.5，那', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 706.444), (78.279904, 720.0448), (541.88008, 720.0448), (541.88008, 706.444)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 66, 'category': 'Title'}),\n",
       " Document(page_content='么根据单层感知器的计算公式𝑓(∑ (𝑤(𝑥() + 𝑏', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 738.604), (54.279903999999995, 752.6848), (286.9828, 752.6848), (286.9828, 738.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd5ebe14a9cb62b6d39cb117fa0aeb2cf', 'page_number': 66, 'category': 'NarrativeText'}),\n",
       " Document(page_content='(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((230.71153599999997, 744.2848), (230.71153599999997, 752.6848), (233.65993599999996, 752.6848), (233.65993599999996, 744.2848)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd5ebe14a9cb62b6d39cb117fa0aeb2cf', 'page_number': 66, 'category': 'UncategorizedText'}),\n",
       " Document(page_content=')我们就可以得到如图 3.3 计算结果。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((287.32, 738.604), (287.32, 751.564), (486.74248, 751.564), (486.74248, 738.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'd5ebe14a9cb62b6d39cb117fa0aeb2cf', 'page_number': 66, 'category': 'NarrativeText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 67, 'category': 'Title'}),\n",
       " Document(page_content='图 3.3 单层感知器计算', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((249.09848799999997, 304.20400000000006), (249.09848799999997, 316.20400000000006), (374.61328, 316.20400000000006), (374.61328, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 67, 'category': 'Title'}),\n",
       " Document(page_content='𝑥\"=0,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 335.884), (78.279904, 349.9648), (417.3592, 349.9648), (417.3592, 335.884)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=0,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 1 − 0.6) = −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 368.524), (78.279904, 382.6048), (417.3592, 382.6048), (417.3592, 368.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=0,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 0 − 0.6) = −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 400.924), (78.279904, 415.0048), (417.3592, 415.0048), (417.3592, 400.924)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=0,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 433.564), (78.279904, 447.64480000000003), (408.39448, 447.64480000000003), (408.39448, 433.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=1,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 466.204), (78.279904, 480.2848), (417.3592, 480.2848), (417.3592, 466.204)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=1,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 1 − 0.6) = 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 498.844), (78.279904, 512.9248), (408.39448, 512.9248), (408.39448, 498.844)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=1,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 0 − 0.6) = 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 531.4839999999999), (78.279904, 545.5648000000001), (408.39448, 545.5648000000001), (408.39448, 531.4839999999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑥\"=1,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 564.124), (78.279904, 578.2048), (408.39448, 578.2048), (408.39448, 564.124)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f213e2091472ddf18a3110d9c852f702', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='3.2.3 单层感知器的另一种表达形式', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 643.67296), (86.279896, 659.75296), (338.89119999999997, 659.75296), (338.89119999999997, 643.67296)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 67, 'category': 'Title'}),\n",
       " Document(page_content='单层感知器的另一种表达形式如图 3.4。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 690.604), (78.279904, 702.604), (293.79472000000004, 702.604), (293.79472000000004, 690.604)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 67, 'category': 'Title'}),\n",
       " Document(page_content='66', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'f8e8dbc1b4d6204eb2f77b66db360eb9', 'page_number': 67, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='图 3.4 单层感知器的另一种表达形式', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((213.09848799999997, 304.20400000000006), (213.09848799999997, 316.20400000000006), (410.61328, 316.20400000000006), (410.61328, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='其实这种表达形式跟 3.2.1 中的单层感知器是一样的。只不过是把偏置值 b 变成了输入', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 336.84400000000005), (78.279904, 348.84400000000005), (541.8800799999999, 348.84400000000005), (541.8800799999999, 336.84400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='𝑤< × 𝑥<，其中𝑥<=1。所以𝑤< × 𝑥<实际上就是𝑤<，把∑ (𝑤(𝑥()', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 368.524), (54.279903999999995, 382.6048), (358.78, 382.6048), (358.78, 368.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((323.33608, 374.20480000000003), (323.33608, 382.6048), (326.28448, 382.6048), (326.28448, 374.20480000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'a73fce2a08df8187588584bf169fa517', 'page_number': 68, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='公式展开得到：𝑤\" × 𝑥\" + 𝑤# × 𝑥# +', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((358.84095999999994, 369.004), (358.84095999999994, 382.6048), (541.8791200000001, 382.6048), (541.8791200000001, 369.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='𝑤$ × 𝑥$ + 𝑤<。所以这两个单层感知器的表达不一样，但是计算结果是一样的。如图 3.4 的表', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 401.404), (54.279903999999995, 415.0048), (541.88008, 415.0048), (541.88008, 401.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'cde98820abb42bd0354fff65404415a2', 'page_number': 68, 'category': 'NarrativeText'}),\n",
       " Document(page_content='达形式更加简洁，更适合使用矩阵来进行运算。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 434.524), (54.279903999999995, 446.524), (309.832, 446.524), (309.832, 434.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='3.3 单层感知器的学习规则', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((98.279896, 521.4049600000001), (98.279896, 543.48496), (366.91432, 543.48496), (366.91432, 521.4049600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='3.3.1 单层感知器的学习规则介绍', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 580.79296), (86.279896, 596.87296), (322.89112, 596.87296), (322.89112, 580.79296)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='感知器的学习规则就是指感知器中的权值参数训练的方法，在本章节中我们暂时先不解释', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 627.724), (78.279904, 639.724), (541.879504, 639.724), (541.879504, 627.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='这个学习规则是怎么推导出来的。等第 4 章我们讲到 Delta 学习规则的时候我们再来解释感', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 660.364), (54.279903999999995, 672.364), (541.8800799999999, 672.364), (541.8800799999999, 660.364)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='知器的学习规则是如何推导的。在这里我们可以先接受下面的公式即可。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 693.004), (54.279903999999995, 705.004), (441.832, 705.004), (441.832, 693.004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='在 3.2.3 中我们已知单层感知器表达式可以写成：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 725.644), (78.279904, 737.644), (342.72064, 737.644), (342.72064, 725.644)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 68, 'category': 'Title'}),\n",
       " Document(page_content='67', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '9d00698613471152c1215d8b725ee01e', 'page_number': 68, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((241.891456, 64.49776000000008), (241.891456, 113.21776), (343.25679999999994, 113.21776), (343.25679999999994, 64.49776000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='B', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((343.47999999999996, 82.15024000000005), (343.47999999999996, 96.07024000000001), (351.95727999999997, 96.07024000000001), (351.95727999999997, 82.15024000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='公式(3.1)中：y 表示感知器的输出；f 是 sign 激活函数；n 是输入信号的个数 i=0,1,2...', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((70.229848, 124.92400000000009), (70.229848, 136.9240000000001), (530.13352, 136.9240000000001), (530.13352, 124.92400000000009)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='∆𝑤( = 𝜂(𝑡 − 𝑦)𝑥(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((246.77036799999996, 154.87024000000008), (246.77036799999996, 171.53776000000005), (348.49888, 171.53776000000005), (348.49888, 154.87024000000008)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '4e41b9293c21842fe59fc827dad117a6', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='公式(3.2)中：∆𝑤(表示第 i 个权值的变化；𝜂表示学习率(Learning Rate)，用来调节权值', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 189.72400000000005), (75.279904, 203.32479999999998), (541.8800799999999, 203.32479999999998), (541.8800799999999, 189.72400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='变化的大小；t 是正确的标签(target)。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 222.60400000000004), (54.279903999999995, 234.60400000000004), (263.78896000000003, 234.60400000000004), (263.78896000000003, 222.60400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='因为单层感知器的激活函数为 sign 函数，所以 t 和 y 的取值都为±1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.129976, 255.24400000000003), (75.129976, 267.244), (435.26007999999996, 267.244), (435.26007999999996, 255.24400000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='t=y 时，∆𝑤(为 0；t=1，y=-1 时，∆𝑤(为 2；t=-1，y=1 时，∆𝑤(为-2。由式(3.2)可以推', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.129976, 287.404), (75.129976, 301.00479999999993), (541.8800799999999, 301.00479999999993), (541.8800799999999, 287.404)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '2f5530372db711e7487715103ce3ee67', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='出：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 320.524), (54.279903999999995, 332.524), (81.83190400000001, 332.524), (81.83190400000001, 320.524)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='∆𝑤( = ±2𝜂𝑥(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((258.7852, 350.71024), (258.7852, 366.65776), (336.4839999999999, 366.65776), (336.4839999999999, 350.71024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '083e09387f4e64117efc6cfe613c5103', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='权值的调整公式为：', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 385.564), (78.279904, 397.564), (189.83190399999998, 397.564), (189.83190399999998, 385.564)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='𝑤( = 𝑤( + ∆𝑤(', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((254.99104, 415.75024), (254.99104, 431.69776), (340.27815999999996, 431.69776), (340.27815999999996, 415.75024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b26cdc332bd284c71b6fa663e2c503ae', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='3.3.2 单层感知器的学习规则计算举例', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((86.279896, 462.47296000000006), (86.279896, 478.55296000000004), (354.89104, 478.55296000000004), (354.89104, 462.47296000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='假设有一个单层感知器如图 3.1 所示，已知有三个输入 x0=1，x1=0，x2=-1，权值', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 509.40400000000005), (78.279904, 521.404), (520.60408, 521.404), (520.60408, 509.40400000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='w0=-5，w1=0，w2=0，学习率𝜂=1，正确的标签 t=1。(注意在这个例子中偏置值 b 用', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 541.5640000000001), (54.279903999999995, 554.0440000000001), (520.4809599999999, 554.0440000000001), (520.4809599999999, 541.5640000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='𝑤< × 𝑥<来表示，x0 的值固定为 1)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 574.204), (54.279903999999995, 587.8048), (235.470568, 587.8048), (235.470568, 574.204)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='Step1：我们首先计算感知器的输出。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 607.3240000000001), (78.279904, 619.3240000000001), (282.2224, 619.3240000000001), (282.2224, 607.3240000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((243.057976, 628.49776), (243.057976, 677.21776), (344.45679999999993, 677.21776), (344.45679999999993, 628.49776)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'ad8216eaaef5d44f9d4bd4748b697487', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='B', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((344.67999999999995, 646.15024), (344.67999999999995, 660.8670400000001), (357.22191999999995, 660.8670400000001), (357.22191999999995, 646.15024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 69, 'category': 'Title'}),\n",
       " Document(page_content='= sign(−5 × 1 + 0 × 0 + 0 × (−1) + 0)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 686.23024), (54.279903999999995, 701.42704), (445.58896, 701.42704), (445.58896, 686.23024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='= sign(−5)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 718.8702400000001), (54.279903999999995, 734.0670399999999), (278.28423999999995, 734.0670399999999), (278.28423999999995, 718.8702400000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='= −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 752.2302400000001), (54.279903999999995, 766.70704), (242.026432, 766.70704), (242.026432, 752.2302400000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='68', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(3.1)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((511.88392, 82.39024000000006), (511.88392, 96.86703999999997), (546.0003999999999, 96.86703999999997), (546.0003999999999, 82.39024000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(3.2)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((511.88392, 155.5902400000001), (511.88392, 170.30704000000003), (546.0003999999999, 170.30704000000003), (546.0003999999999, 155.5902400000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(3.3)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((511.88392, 350.71024), (511.88392, 365.90704), (546.0003999999999, 365.90704), (546.0003999999999, 350.71024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='(3.4)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((511.88392, 415.75024), (511.88392, 430.94704), (546.0003999999999, 430.94704), (546.0003999999999, 415.75024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 69, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 75.96400000000006), (54.279903999999995, 87.96400000000006), (486.72064, 87.96400000000006), (486.72064, 75.96400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 106.15024000000005), (75.279904, 122.81776000000002), (321.87832, 122.81776000000002), (321.87832, 106.15024000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 138.79024000000004), (75.279904, 155.45776), (321.24352, 155.45776), (321.24352, 138.79024000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 171.43024000000003), (75.279904, 188.09776), (354.41727999999995, 188.09776), (354.41727999999995, 171.43024000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤< = 𝑤< + ∆𝑤< = −5 + 2 = −3', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 204.55024000000003), (75.279904, 220.49775999999997), (268.72191999999995, 220.49775999999997), (268.72191999999995, 204.55024000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 237.19024000000002), (54.279903999999995, 253.13775999999996), (246.85187199999996, 253.13775999999996), (246.85187199999996, 237.19024000000002)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤# = 𝑤# + ∆𝑤# = 0 − 2 = −2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 269.83024), (54.279903999999995, 285.77776000000006), (258.26295999999996, 285.77776000000006), (258.26295999999996, 269.83024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='Step2：重新计算感知器的输出。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 304.20400000000006), (78.279904, 316.20400000000006), (258.22264, 316.20400000000006), (258.22264, 304.20400000000006)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((243.057976, 325.3777600000001), (243.057976, 374.09776), (344.45679999999993, 374.09776), (344.45679999999993, 325.3777600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'b585cf0f756d3d596b6aec95126e5248', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='B', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((344.67999999999995, 343.03024), (344.67999999999995, 357.74704), (357.22191999999995, 357.74704), (357.22191999999995, 343.03024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='= sign(−3 × 1 + 0 × 0 + (−2) × (−1) + 0)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 383.11024000000003), (54.279903999999995, 398.30704000000003), (467.66895999999997, 398.30704000000003), (467.66895999999997, 383.11024000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='= sign(−1)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 415.75024), (54.279903999999995, 430.94704), (278.28423999999995, 430.94704), (278.28423999999995, 415.75024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='= −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 449.11024000000003), (54.279903999999995, 463.58704000000006), (242.026432, 463.58704000000006), (242.026432, 449.11024000000003)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 483.48400000000004), (54.279903999999995, 495.48400000000004), (486.72064, 495.48400000000004), (486.72064, 483.48400000000004)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 513.6702399999999), (75.279904, 530.33776), (321.87832, 530.33776), (321.87832, 513.6702399999999)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 546.31024), (75.279904, 562.97776), (321.24352, 562.97776), (321.24352, 546.31024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 578.71024), (75.279904, 595.3777600000001), (354.41727999999995, 595.3777600000001), (354.41727999999995, 578.71024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤< = 𝑤< + ∆𝑤< = −3 + 2 = −1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((75.279904, 612.07024), (75.279904, 628.0177600000001), (268.72191999999995, 628.0177600000001), (268.72191999999995, 612.07024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 644.71024), (54.279903999999995, 660.65776), (246.85187199999996, 660.65776), (246.85187199999996, 644.71024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='𝑤# = 𝑤# + ∆𝑤# = −2 − 2 = −4', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 677.35024), (54.279903999999995, 693.29776), (268.72191999999995, 693.29776), (268.72191999999995, 677.35024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'c68556ff6865dbfe7767b41e2f079535', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='Step3：重新计算感知器的输出。', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((78.279904, 711.724), (78.279904, 723.724), (258.22264, 723.724), (258.22264, 711.724)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((243.057976, 732.8977600000001), (243.057976, 781.61776), (344.45679999999993, 781.61776), (344.45679999999993, 732.8977600000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '1ebd3a0c9614973801351492d8edfde3', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " Document(page_content='B', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((344.67999999999995, 750.55024), (344.67999999999995, 765.26704), (357.22191999999995, 765.26704), (357.22191999999995, 750.55024)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 70, 'category': 'Title'}),\n",
       " Document(page_content='69', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((527.81248, 48.964000000000055), (527.81248, 61.32400000000007), (545.1745599999999, 61.32400000000007), (545.1745599999999, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': 'df7e70e5021544f4834bbee64a9e3789', 'page_number': 70, 'category': 'UncategorizedText'}),\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "loader2 = UnstructuredPDFLoader(\"深度学习从0到1-基于Tensorflow2.pdf\", mode=\"elements\")\n",
    "pages2 = loader2.load()\n",
    "pages2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f02eb56-a296-428f-a3ba-51b0832a46c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:36:16.805775Z",
     "iopub.status.busy": "2023-11-30T06:36:16.805775Z",
     "iopub.status.idle": "2023-11-30T06:36:16.816226Z",
     "shell.execute_reply": "2023-11-30T06:36:16.814996Z",
     "shell.execute_reply.started": "2023-11-30T06:36:16.805775Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9616"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1da81242-5a65-4ede-ac3e-40d30f79945a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:36:45.494818Z",
     "iopub.status.busy": "2023-11-30T06:36:45.493745Z",
     "iopub.status.idle": "2023-11-30T06:36:45.499637Z",
     "shell.execute_reply": "2023-11-30T06:36:45.499436Z",
     "shell.execute_reply.started": "2023-11-30T06:36:45.494818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'coordinates', 'filename', 'last_modified', 'filetype', 'page_number', 'category'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c660046-5de8-40c4-87ea-45ef2e9bfa26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:37:54.449817Z",
     "iopub.status.busy": "2023-11-30T06:37:54.448816Z",
     "iopub.status.idle": "2023-11-30T06:37:54.457469Z",
     "shell.execute_reply": "2023-11-30T06:37:54.457177Z",
     "shell.execute_reply.started": "2023-11-30T06:37:54.449817Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 48.964000000000055), (54.279903999999995, 61.32400000000007), (334.96816, 61.32400000000007), (334.96816, 48.964000000000055)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 71, 'category': 'Title'})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e528d5d-3104-46fa-a69d-c06f94c1c67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:37:57.304761Z",
     "iopub.status.busy": "2023-11-30T06:37:57.303755Z",
     "iopub.status.idle": "2023-11-30T06:37:57.314876Z",
     "shell.execute_reply": "2023-11-30T06:37:57.314266Z",
     "shell.execute_reply.started": "2023-11-30T06:37:57.304761Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='= sign(−1 × 1 + 0 × 0 + (−4) × (−1) + 0)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 73.51024000000007), (54.279903999999995, 88.70704), (467.66895999999997, 88.70704), (467.66895999999997, 73.51024000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '710eef3a519aa7eb6b3446585b3c6d00', 'page_number': 71, 'category': 'UncategorizedText'})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99f751bc-912d-476a-96ff-f4d82f3d65f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:37:57.833093Z",
     "iopub.status.busy": "2023-11-30T06:37:57.833093Z",
     "iopub.status.idle": "2023-11-30T06:37:57.840532Z",
     "shell.execute_reply": "2023-11-30T06:37:57.840123Z",
     "shell.execute_reply.started": "2023-11-30T06:37:57.833093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='= sign(3)', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 106.15024000000005), (54.279903999999995, 121.34703999999999), (267.82528, 121.34703999999999), (267.82528, 106.15024000000005)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 71, 'category': 'Title'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17abcc95-5ba8-49bb-b50b-7f451e880dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:37:58.515170Z",
     "iopub.status.busy": "2023-11-30T06:37:58.512037Z",
     "iopub.status.idle": "2023-11-30T06:37:58.524114Z",
     "shell.execute_reply": "2023-11-30T06:37:58.523974Z",
     "shell.execute_reply.started": "2023-11-30T06:37:58.515170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='= 1', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 139.51024000000007), (54.279903999999995, 153.98703999999998), (231.567448, 153.98703999999998), (231.567448, 139.51024000000007)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'parent_id': '6864a5f977ed7a56fecfe389aa5aa8b0', 'page_number': 71, 'category': 'UncategorizedText'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[1003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6bea576-f2d1-4568-b654-6f1679ddb217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:37:59.007690Z",
     "iopub.status.busy": "2023-11-30T06:37:59.007690Z",
     "iopub.status.idle": "2023-11-30T06:37:59.015130Z",
     "shell.execute_reply": "2023-11-30T06:37:59.014832Z",
     "shell.execute_reply.started": "2023-11-30T06:37:59.007690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='由于 y=1 与正确的标签 t=1 相同，说明感知器经过训练后得到了我们想要的结果，我们', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'coordinates': {'points': ((54.279903999999995, 173.88400000000001), (54.279903999999995, 185.88400000000001), (541.880008, 185.88400000000001), (541.880008, 173.88400000000001)), 'system': 'PixelSpace', 'layout_width': 595.28, 'layout_height': 841.89}, 'filename': '深度学习从0到1-基于Tensorflow2.pdf', 'last_modified': '2021-11-18T19:55:26', 'filetype': 'application/pdf', 'page_number': 71, 'category': 'Title'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[1004]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a406df9-9667-4527-9be8-3acfb2df1baa",
   "metadata": {},
   "source": [
    "# PyPDFLoader\n",
    "\n",
    "按页读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ab09326-dc46-4e72-b2a5-be202720afa5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T06:42:35.043662Z",
     "iopub.status.busy": "2023-11-30T06:42:35.043662Z",
     "iopub.status.idle": "2023-11-30T06:43:07.142108Z",
     "shell.execute_reply": "2023-11-30T06:43:07.141101Z",
     "shell.execute_reply.started": "2023-11-30T06:42:35.043662Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 0                      \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 0}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 1 说明   本电子书为书籍原稿的开源版本，基本上没有进行什么排版，纸质书籍估计要2021年3月后才能购买。 本书虽然为开源电子书，但仅供个人学习使用。未经许可不能用于个人或企业的商业用途，违法盗版和销售，必究其法律责任。   本书主页，以及源代码，资料下载： https://github.com/Qinbf/Deep-Learning-Tensorflow2 本书配套免费视频教程可以到免费学习人工智能的慕课平台AI MOOC学习： https://mooc.ai-xlab.com 提交错误或意见反馈可以到Github Issues页面提交： https://github.com/Qinbf/Deep-Learning-Tensorflow2/issues 我的B站主页： https://space.bilibili.com/390756902 我的微信公众号： AI MOOC人工智能平台 联系邮箱： qinbf@ai-xlab.com     ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 1}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 2          本书谨献给我的妻子刘露斯，以及正在阅读此书的各位读者朋友。 愿人工智能给我们带来更美好的未来。           ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 2}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 3 序言  本书的由来 本书的序言可能有点长，因为这是我和大家的第一次见面，我希望可以把关于我和这本书的故事讲清楚，让大家对我有一个更好的了解，说不定哪天我们会成为朋友。 大约在3年前的某个下午，电子工业出版社的张迪编辑联系到我，让我写一本关于人工智能的书。第一次有人找我写书，不免还是有些小激动，想象中写书是一件很酷的事情，真正写的时候才知道写书是一件很苦的事情。 我毕业于上海大学物理系本科，大学期间做过很多嵌入式软硬件相关的开发项目。由于觉得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用， 所以我在大学校内开过一年的嵌入式培训班， 以更通俗易懂的方式和切合实际应用的内容给几百个本校同学 （包括本科/硕士/博士）上过课。  我最早是从2015年开始接触人工智能技术， 公司内部刚好需要开发人工智能相关的产品。当时谷歌的深度学习框架Tensorflow都还没有开源，我主要是学习了一些机器学习相关的算法和应用。随着Tensorflow在2015年11月开源，AlphaGo在2016年3月战胜人类顶级围棋选手，我知道新的人工智能的时代就要到来。2016年我学习了当时最热门的两个深度学习框架Tensorflow和Caffe并用这两个框架完成了公司里面的一些深度学习项目。  当时市面上关于深度学习的书籍和学习资料都非常少，所以在2017年的时候我录制了一些深度学习相关的视频教程放到了网上， 就有了后来出版社找我写书的故事。 几乎每个月都会有出版社的人联系我出书， 我才知道原来获得出书的机会不难， 真正难的是认真坚持把一本书', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 3}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 4 给写完。 这本书历时3年， 不过也不是真的写了3年， 写的过程中断断续续也暂停了很多次。我估算了一下真正写书的时间大概是用了1200个小时。  最近两年我做了很多场人工智能的线下培训，给中国移动，中国电信，中国银行，华夏银行，太平洋保险，国家电网，中海油，格力电器等企业以及多个研究所的科研人员和多个高校的老师上过课， 大家学完后的反馈基本上都是挺好的。 虽然我这两年一直在从事人工智能的教育培训工作， 但是我也一直没有真正下定决心要做人工智能教育培训这件事。 因为现如今人工智能的各种学习资料已经很多了， 网上也有各种人工智能专家大师的课程， 这些专家大师基本上都是博士，教授或来自名企。并且从课程的包装上看，内容还是不错的。  不过长期以来，我一直在关注人工智能技术和教育培训的发展。人工智能目前还处于高速发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分令人满意，还存在着许多问题。这些问题并不是几个专家大师所能解决的，而是需要更多人的努力和付出。 人工智能教育是一件很有意义的事情，因为它有可能关乎国家，甚至人类的未来。尽管将会面临无数困难，我还是决定加入其中，以这本书作为开始。  免费人工智能慕课平台AI MOOC AI MOOC是我自己创办的一个免费的人工智能慕课平台，网站地址为https://mooc.ai-xlab.com。以后我会在上面不断更新最新的人工智能课程。我的目标是让所有人都能有机会学习到最前沿最好的人工智能课程。 如果大家觉得我创作的内容不错，可以帮我多多宣传，感谢。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 4}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 5 人工智能的学习 这里想跟大家简单聊一下关于人工智能的学习， 人工智能是一门需要 “内外兼修” 的学科，既要修炼外功招式， 又要进行内功修行。 这里的外功招式主要指的是使用编程语言去实现一些人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。 很多时候武功招式是很容易学的，可以短时间内快速提升，但同时也很容易达到一定的上限。如果想要突破上限更进一步，就要把内功给修炼好。所以我们在学习人工智能相关技术的时候，尽量把相关算法理论理解清楚，同时要多写代码提高编程能力，并在实践过程中加深对算法的理解。  本书的特色 本书的脉络框架主要是根据深度学习知识由浅入深的发展来编写的，对于Tensorflow的使用技巧基本上不会单独讲解， 而是会结合深度学习理论知识或实际应用案例来讲解。 所以很多Tensorflow的使用技巧在目录上可能没有得到很好的体现，这些Tensorflow使用技巧的彩蛋在书里的程序中等着大家发现哦！相信大家看完这本书以后就可以熟练掌握Tensorflow的使用了。 本书是一本“内外兼修”的书，既包含详细的算法理论的介绍，又包括详细的代码讲解。我一直在思考人工智能技术的教学方式， 所以也形成了自己的教学风格和对教育的理解。 这一套方式方法收到过很多同学的积极反馈， 但也不一定适合所有人。 我觉得不同的教学风格就像是不同类型的音乐，每个人喜欢的音乐类型可能都会不一样。AI教育的发展需要各种类型的教学方式百花齐放。 本书的主要特色总结如下： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 5}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 6 一.所有公式推导都有详细步骤，并解释每个符号。数学公式是算法的根本，要理解算法的本质就要理解数学公式的含义，所以掌握一些基础的深度学习相关的数学内容也是很重要的。大家看到数学一般都会比较头疼， 所以本书中所有数学公式都会列出详细推导步骤， 并解释每个相关符号的含义，帮助大家理解。 二.注释每一行代码。我一直觉得我在教学中使用的代码具有一定个人风格， 代码逻辑结构清晰，程序在容易理解的基础上尽量精简，最大的特点可能就是注释比代码多。我给这种代码风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得对于初学者而言，最好是可以理解每一行代码，每个函数，函数中所使用的每个参数，这样学习会感觉比较扎实。所以本书中所有代码都是全注释代码。 三. 程序皆为完整程序。本书一共82个代码应用案例，所有的代码都是可以从头到尾运行的完整程序，并附带真实运行结果，不存在程序片段样例。我觉得程序片段对于初学者的学习不太友好， 大家拿到一个程序片段往往还是不知道如何使用， 或者用起来的时候出现很多错误，所以我在书中使用的所有程序都是可以从头到尾直接运行的完整程序。 四.一图胜千言。深度学习中很多模型结构， 计算流程之类的内容很难用公式或者语言表达清楚，但往往一张好的图片就可以说明一切。本书一共使用了约500张图片，在本书的创作过程中，大约有200个小时是花在画图以及思考如何画图上。 五.逻辑结构清晰，讲解细致。这个不需要多介绍，大家看的时候就知道了。  勘误和支持 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 6}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 7 本书很多思想和知识体系都是我基于自己的理解建立的， 由于本人水平有限， 本书一定存在不少理解不当或者不准确的地方，恳请大家批评指正。如果大家有更多宝贵意见，欢迎发送邮件至邮箱qinbf@ai-xlab.com ，或者到我的Github留言：https://github.com/Qinbf/Deep-Learning-Tensorflow2/issues。期待大家的真挚反馈和支持。  致谢 在本书的撰写和研究期间，感谢我的妻子刘露斯对我的支持和鼓励。感谢我的朋友王惠东对本书部分章节的校阅。 感谢电子工业出版社张迪编辑的耐心等待， 感谢出版社对本书的耐心修订和整理。最后感谢各位读者朋友选择了这本书，感谢大家的信任。  覃秉丰 2020年9月于上海        ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 7}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 8 目录 前言 第1章  深度学习背景介绍     1.1  人工智能     1.2  机器学习         1.2.1  训练数据，验证数据和测试数据         1.2.2  学习方式         1.2.3  机器学习常用算法     1.3  人工智能，机器学习，神经网络以及深度学习之间的关系     1.4  深度学习应用     1.5  神经网络深度学习发展史         1.5.1  神经网络诞生-20时间40-60年代         1.5.2  神经网络复兴-20时间80-90年代         1.5.3  深度学习-2006年至今     1.6  深度学习领域重要人物     1.7  新一轮人工智能爆发的三要素  第2章  搭建Python编程环境     2.1  Python介绍     2.2  Anaconda安装     2.3  Jupyter Notebook的简单使用         2.3.1  启动Jupyter Notebook         2.3.2  修改Jupyter Notebook默认启动路径         2.3.3  Jupyter Notebook浏览器无法打开         2.3.4  Jupyter Notebook基本操作    第3章  单层感知器与线性神经网络     3.1  生物神经网络     3.2  单层感知器         3.2.1  单层感知器介绍         3.2.2  单层感知器计算举例         3.2.3  单层感知器的另一种表达形式     3.3  单层感知器的学习规则         3.3.1  单层感知器的学习规则介绍         3.3.2  单层感知器的学习规则计算举例     3.4  学习率     3.5  模型的收敛条件     3.6  模型的超参数和参数的区别     3.7  单层感知器分类案例     3.8  线性神经网络         3.8.1  线性神经网络介绍 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 8}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 9         3.8.2  线性神经网络分类案例     3.9  线性神经网络处理异或问题  第4章  单层感知器与线性神经网络     4.1  BP神经网络介绍及发展背景     4.2  代价函数     4.3  梯度下降法         4.3.1  梯度下降法（Gradient Descent）介绍         4.3.2  梯度下降法（Gradient Descent）二维例子         4.3.3  梯度下降法（Gradient Descent）三维例子     4.4  Delta学习规则     4.5  常用激活函数讲解         4.5.1  Sigmoid函数         4.5.2  Tanh函数         4.5.3  Softsign函数         4.5.4  ReLU函数     4.6  BP网络模型和公式推导         4.6.1  BP网络模型         4.6.2  BP算法推导         4.6.3  BP算法推导补充说明     4.7  BP算法推导结论总结     4.8  梯度消失与梯度爆炸         4.8.1  梯度消失         4.8.2  梯度爆炸         4.8.3  使用ReLU函数解决梯度消失和梯度爆炸的问题     4.9  使用BP神经网络解决异或问题     4.10  分类模型评估方法         4.10.1  准确率/精确率/召回率/F1值         4.10.2  混淆矩阵     4.11  独热编码（One-Hot Encoding）     4.12  BP神经网络完成手写数字识别     4.13  Sklearn手写数字识别  第5章  深度学习框架Tensorflow基础使用     5.1  Tensorflow介绍         5.1.1  Tensorflow简介         5.1.2  静态图和动态图机制Eager Execution         5.1.3  tf.keras     5.2  Tensorflow-cpu安装         5.2.1  Tensorflow-cpu在线安装         5.2.2  安装过程中可能遇到的问题汇总         5.2.3  Tensorflow-cpu卸载         5.2.4  Tensorflow-cpu更新 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 9}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 10         5.2.5  Tensorflow-cpu指定版本的安装     5.3  Tensorflow-gpu安装         5.3.1  Tensorflow-gpu了解最新版本情况         5.3.2  Tensorflow-gpu安装CUDA         5.3.3  Tensorflow-gpu安装cuDNN库         5.3.4  Tensorflow-gpu在线安装         5.3.5  Tensorflow-gpu卸载         5.3.6  Tensorflow-gpu更新     5.4  Tensorflow基本概念     5.5  Tensorflow基础使用         5.5.1  TF1转TF2工具         5.5.2  Tensorflow基本操作         5.5.3  拟合线性函数         5.5.4  拟合非线性函数     5.6  手写数字图片分类任务         5.6.1  MNIST数据集介绍         5.6.2  Softmax函数介绍         5.6.3  简单MNIST数据集分类模型-没有高级封装         5.6.4  简单MNIST数据集分类模型-keras高级封装  第6章  网络优化方法     6.1  交叉熵代价函数         6.1.1  均方差代价函数的缺点         6.1.2  引入交叉熵代价函数         6.1.3  交叉熵代价函数推导过程         6.1.4  Softmax与对数似然代价函数         6.1.5  交叉熵程序     6.2  过拟合（Over-Fitting）         6.2.1  什么是过拟合         6.2.2  抵抗过拟合的方法     6.3  数据增强（Data Augmentation）     6.4  提前停止训练（Early-Stopping）     6.5  Dropout         6.5.1  Dropout介绍         6.5.2  Dropout程序     6.6  正则化（Regularization）         6.6.1  正则化介绍         6.6.2  正则化程序     6.7  标签平滑（Label Smoothing）         6.7.1  标签平滑（Label Smoothing）介绍         6.7.2  标签平滑（Label Smoothing）程序     6.8  优化器（Optimizer）         6.8.1  梯度下降法SGD ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 10}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 11         6.8.2  Momentum         6.8.3  NAG（Nesterov Accelerated Gradient）         6.8.4  Adagrad         6.8.5  Adadelta         6.8.6  RMRprop         6.8.7  Adam         6.8.8  优化器程序  第7章  Tensorflow模型的保存和载入     7.1  交叉熵代价函数         7.1.1  Keras保存模型         7.1.2  Keras载入模型     7.2  SavedModel模型保存和载入         7.2.1  SavedModel保存模型         7.2.2  SavedModel载入模型     7.3  单独保存模型结构         7.3.1  保存模型结构         7.3.2  载入模型结构     7.4  单独保存模型参数         7.4.1  保存模型参数         7.4.2  载入模型参数     7.5  ModelCheckpoint自动保存模型     7.6  Checkpoint模型保存和载入         7.6.1  Checkpoint模型保存         7.6.2  Checkpoint模型载入  第8章  卷积神经网络CNN     8.1  计算机视觉介绍         8.1.1  计算机视觉应用介绍         8.1.2  计算机视觉技术介绍     8.2  卷积神经网络简介         8.2.1  BP神经网络存在的问题         8.2.2  局部感受野和权值共享     8.3  卷积的具体计算     8.4  卷积的步长     8.5  不同的卷积核     8.6  池化（Pooling）     8.7  Padding     8.8  常见的卷积计算总结         8.8.1  对1张图像进行卷积生成1张特征图         8.8.2  对1张图像进行卷积生成多张特征图         8.8.3  对多张图像进行卷积生成1张特征图         8.8.4  对多张图像进行卷积生成多张特征图 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 11}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 12     8.9  经典的卷积神经网络     8.10 卷积神经网络应用于MNIST数据集分类     8.11 识别自己写的数字图片     8.12CIFAR-10数据集分类  第9章  序列模型     9.1  序列模型应用     9.2  循环神经网络RNN         9.2.1  循环神经网络介绍         9.2.2  Elman network和Jordan network     9.3  RNN的不同架构         9.3.1  一对一架构         9.3.2  多对一架构         9.3.3  多对多架构         9.3.4  一对多架构         9.3.5  Seq2Seq架构     9.4  传统RNN的缺点     9.5  长短时记忆网络LSTM     9.6  Peephole LSTM和FC-LSTM         9.6.1  Peephole LSTM介绍         9.6.2  FC-LSTM介绍     9.7  其他RNN模型         9.7.1  门控循环单元GRU         9.7.2  双向RNN（Bidirectional RNN）         9.7.3  Stacked Bidirectional RNN     9.8  LSTM网络应用于MNIST数据集分类  第10章  经典图像识别模型介绍（上）     10.1  图像数据集ImageNet         10.1.1  ImageNet介绍         10.1.2  李飞飞简介         10.1.3  ImageNet的深远影响         10.1.4  ImageNet Challenge历年优秀作品     10.2  AlexNet     10.3  VGGNet     10.4  GoogleNet         10.4.1  1×1卷积介绍         10.4.2  Inception结构         10.4.3  GoogleNet网络结构     10.5  Batch Normalization         10.5.1  Batch Normalization提出背景         10.5.2  数据标准化（Normalization）         10.5.3  Batch Normalization模型训练阶段 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 12}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 13         10.5.4  Batch Normalization模型预测阶段         10.5.5  Batch Normalization作用分析     10.6  ResNet     10.6.1  ResNet背景介绍     10.6.2  残差块（Residual Block）介绍     10.6.3  ResNet网络介绍     10.6.4  ResNet-V2  第11章  经典图像识别模型介绍（下）     11.1  Inception模型系列         11.1.1  Inception-v2/v3优化策略         11.1.2  Inception-v2/v3模型结构         11.1.3  Inception-v4和Inception-ResNet介绍     11.2  ResNeXt         11.2.1  分组卷积（Group Convolution）介绍         11.2.2  ResNeXt中的分组卷积         11.2.3  ResNeXt的网络结构     11.3  SENet         11.3.1  SENet介绍         11.3.2  SENet结果分析  第12章  图像识别项目实战     12.1  图像数据准备         12.1.1  数据集介绍         12.1.2  数据集准备         12.1.3  切分数据集程序     12.2  AlexNet图像识别     12.3  VGGNet图像识别     12.4  函数式（functional）模型         12.4.1  函数式（functional）模型介绍         12.4.2  使用函数式模型进行MNIST图像识别     12.5  模型可视化plot_model         12.5.1  使用plot_model进行模型可视化         12.5.2  plot_model升级版     12.6  GoolgeNet图像识别     12.7  Batch Normalization使用     12.8  ResNet图像识别     12.9  ResNeXt图像识别     12.10  SENet图像识别     12.11  使用预训练模型进行迁移学习         12.11.1  使用训练好的模型进行图像识别         12.11.2  使用训练好的模型进行迁移学习         12.11.3  载入训练好的模型进行预测 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 13}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 14  第13章  验证码识别项目实战     13.1  多任务学习介绍     13.2  验证码数据集生成     13.3  tf.data介绍     13.4  使用tf.data完成多任务学习-验证码识别         13.4.1  使用tf.data完成多任务学习模型训练         13.4.2  使用tf.data完成多任务学习模型预测     13.5  使用自定义数据生成器完成验证码识别         13.5.1  使用自定义数据生成器完成模型训练         13.5.2  使用自定义数据生成器完成模型预测     13.6  挑战变长验证码识别         13.6.1  挑战变长验证码识别模型训练         13.6.2  挑战变长验证码识别模型预测     13.7  CTC算法         13.7.1  CTC算法介绍         13.7.2  贪心算法（Greedy Search）和集束搜索算法（Beam Search）         13.7.3  CTC存在的问题     13.8  CTC算法-验证码识别         13.8.1  使用CTC算法训练验证码模型         13.8.2  使用CTC算法训练验证码预测  第14章  自然语言处理NLP发展历程（上）     14.1  多任务学习介绍         14.1.1  文本分类/情感分类         14.1.2  分词标注         14.1.3  机器翻译         14.1.4  聊天机器人         14.1.5  自动摘要         14.1.6  文章生成         14.1.7  图片描述     14.2  从传统语言模型到神经语言模型         14.2.1  规则模型         14.2.2  统计语言模型         14.2.3  词向量（word embedding）         14.2.4  神经语言模型     14.3  word2vec         14.3.1  word2vec介绍         14.3.2  word2vec模型训练         14.3.3  word2vec训练trick和可视化效果     14.4  CNN在NLP领域的使用     14.5  RNN在NLP领域的使用         14.5.1  使用RNN进行文本分类 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 14}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 15         14.5.2  使用RNN进行中文分词标注     14.6  Seq2Seq模型在NLP领域的使用     14.7  Attention机制         14.7.1  Attention思想的介绍         14.7.2  Bahdanau Attention介绍         14.7.3  Luong Attention介绍         14.7.4  谷歌机器翻译系统GNMT介绍         14.7.5  Attention机制在视觉和语音领域的应用  第15章  自然语言处理NLP发展历程（下）     15.1  NLP新的开始-Transformer模型         15.1.1  Transformer模型结构和输入数据介绍         15.1.2  Self-Attention介绍         15.1.3  Multi-Head Attention介绍         15.1.4  Layer Normalization介绍         15.1.5  Decoder结构介绍         15.1.6  Decoder中的Multi-Head Attention和模型训练     15.2  BERT模型         15.2.1  BERT模型介绍         15.2.2  BERT模型训练         15.2.3  BERT模型应用  第16章  NLP任务项目实战     16.1  Python介绍         16.1.1  项目数据和模型说明         16.1.2  一维卷积英语电影评论情感分类程序     16.2  二维卷积中文微博情感分类项目     16.3  双向LSTM中文微博情感分类项目     16.4  堆叠双向LSTM中文分词标注项目         16.4.1  中文分词标注模型训练         16.4.2  维特比算法（Viterbi Algorithm）         16.4.3  中文分词标注模型预测     16.5  最新的一些激活函数介绍         16.5.1  Leaky ReLU         16.5.2  ELU         16.5.3  SELU         16.5.4  GELU         16.5.5  Swish     16.6  BERT模型简单使用         16.6.1  安装tf2-bert模块并准备预训练模型         16.6.2  使用BERT进行文本特征提取         16.6.3  使用BERT进行完形填空     16.7  BERT电商用户多情绪判断项目 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 15}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 16         16.7.1  项目背景介绍         16.7.2  模型训练         16.7.3  模型预测  第17章  音频信号处理     17.1  深度学习在声音领域的应用介绍         17.1.1  音频分类         17.1.2  音频事件检测         17.1.3  语音识别         17.1.4  音乐检索         17.1.5  音乐生成         17.1.6  语音合成         17.1.7  语音克隆     17.2  MFCC和Mel Filter Banks         17.2.1  音频数据采集         17.2.2  分帧加窗         17.2.3  傅里叶变换         17.2.4  梅尔滤波器（Mel Filter Banks）         17.2.5  梅尔频率倒谱系数MFCC     17.3  语音分类项目         17.3.1 音频处理库librosa介绍         17.3.2 音频分类项目-模型训练         17.3.3 音频分类项目-模型预测  第18章  图像风格转换     18.1  图像风格转换实现原理         18.1.1  代价函数的定义         18.1.2  格拉姆矩阵（Gram Matrix）介绍     18.2  图像风格转换项目实战     18.3  遮挡图像风格转换项目实战  第19章  生成对抗网络GANs     19.1 生成对抗网络的应用         19.1.1  图像生成         19.1.2  向量空间运算         19.1.3  改变年龄或美颜         19.1.4  图像转换         19.1.5  文本转图像         19.1.6  超分辨率         19.1.7   换脸     19.2  DCGAN介绍         19.2.1  DCGAN原理         19.2.2  转置卷积（Transposed Convolution）介绍 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 16}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 17         19.2.3  DCGAN模型结构     19.3  手写数字图像生成  第20章  模型部署     20.1 Tensorflow Serving环境部署         20.1.1  安装Docker         20.1.2  拉取Tensorflow Serving镜像     20.2  运行客户端和服务器程序         20.2.1  准备SavedModel模型         20.2.2  启动Tensorflow Serving服务器程序         20.2.3  Tensorflow Serving客户端gRPC程序         20.2.4  Tensorflow Serving客户端REST API程序  专业术语汇总 结束语               ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 17}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 18 第1章-深度学习背景介绍 本章主要介绍人工智能，机器学习，神经网络，深度学习相关的一些概念，应用，发展史以及重要人物等背景信息。 这些背景知识虽然对我们的实际应用没有直接帮助， 但是可以加深我们对人工智能这个行业的理解，属于内功修行的范畴。  1.1 人工智能 1997年5月3日-1997年5月11日一场别开生面的比赛在纽约的公平大厦举行，吸引了全世界的关注。对垒的双方分别是世界国际象棋冠军卡斯帕罗夫和IBM的超级计算机“深蓝”。经过六场激烈的比赛，“深蓝”最终战胜了卡斯帕罗夫，赢得了具有特殊意义的胜利。而这一次比赛也载入了人类的史册。 而另一场可以载入人类史册的人机大战发生在2016年3月9日-2016年3月15日。 这一次比赛双方是世界顶级围棋棋手李世石和Google的人工智能AlphaGo。赛前有很多人并不看好AlphaGo，认为AlphaGo会惨败。没想到AlphaGo最终以4:1大胜李世石，从而一战成名。由于AlphaGo的胜利，AlphaGo用到的深度学习（Deep Learning）技术以及人工智能（Artificial Intelligence）也成为了当下最热门的技术话题。 人工智能（Artificial Intelligence），英文缩写AI。AI第一次被提出来是在1956年，是由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议（Dartmouth Conference）上一同定义出来的。人工智能只是一个抽象概念，它不是任何具体的机器或算法。 任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。 比如几年前我们去洗车的时候会看到洗车店写着自动化洗车，看起来很高级。今天我们再去看，可能它改成了', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 18}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 19 人工智能洗车，看起来更高级。实际上它的技术并没有改变，只是改了一个名字。随着人工智能技术的大热， 很多商品都挂上了人工智能的标签， 实际上任何看起来有一点智能的算法和机器都可以称为人工智能，所以人工智能这个标签并不能代表某个商品的技术水平。 提到人工智能， 不得不说到一个非常著名的关于人工智能的测试，图灵测试（Turing Test）。图灵测试是由计算机科学之父图灵提出来的， 指的是测试者和被测试者 （被测试者有可能是人或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之后，如果有30%的测试者不能确定被测试者是人还是机器，那么说明这台机器通过了测试。 虽然图灵测试早在1950年被提出，但是至今没有机器能够很好地通过图灵测试。偶尔会有一些新闻报道说某某机器通过了图灵测试， 但是这些通过图灵测试的机器往往会受到很多人质疑，并且经不住多次实验。 人工智能早期阶段， 迅速解决了一些对于人类来说比较困难， 但是对于计算机来说相对容易的问题，比如下棋，推理，路径规划等等。我们下象棋的时候，通常需要思考很久才能推算出几步棋之后棋盘战局的变化， 并且经常还会有看错看漏的情况。 而计算机能在一瞬间计算出七八步棋甚至十几步棋之后棋盘的情况， 并从中选出对自己最有利的下法来与对手对弈。 面对如此强大的对手，人类早在20年前就已经输了。可能有人会想到人工智能在象棋领域早就战胜了人类最顶尖的选手，为什么在围棋领域一直到2016年才出了个AlphaGo把人类顶级棋手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋AI的时候可以使用暴力计算的方法，把几步之内所有可能的走法都遍历一次，然后选一个最优下法。同样的方法放到围棋上就行不通了， 围棋每一步的可能性都太多了， 用暴力计算法设计出来的围棋AI，它的棋力是很差的。虽然AlphaGo的计算非常快，可以在短时间完成大量运算，但是AlphaGo比其他棋类AI强的地方并不是计算能力，而是它的算法，也可以理解为它拥有更强大的“智慧”。就像是进行小学速算比赛，题目是100以内的加减法，10个小学生为一队，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 19}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 20 1个数学系的博士为另一队。如果比赛内容是1分钟哪个队做的正确题目多，小学生队肯定是能够战胜数学博士的。如果是进行大学生数学建模比赛，那10000个小学生也赢不了1个数学博士。对于解决复杂的问题，需要的往往不只是计算速度，更多的应该是智慧。 对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完成得很差。人类的视觉从眼睛采集信息开始，但起到主要作用的是大脑。人类的每个脑半球中都有着非常复杂的视觉皮层， 包含着上亿个神经元以及几百亿条神经元之间的连接。 人类的大脑就像是一台超级计算机， 可以轻松处理非常复杂的图像问题。 神经元之间的电信号可以快速传递，但是就像前面说到的，对于复杂的问题，计算速度只是一方面。人类的视觉能力是通过几亿年地不断进化， 不断演变最终才得到的， 更强的视觉和听觉能力使得人类可以拥有更强的生存能力。 在人工智能的早期阶段，计算机的智能通常是基于人工制定的“规则” ，我们可以通过详细的规则去定义下棋的套路，推理的方法，以及路径规划的方案。但是我们却很难用规则去详细描述图片中的物体， 比如我们要判断一张图片中是否存在猫。 那我们首先要通过规则去定义一只猫，如图1.1所示。 \\n 图1.1 猫（Cat） 观察图1.1中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身体，和一条长尾巴，然后可以定义一套规则在图片中寻找猫。这看起来好像是可行的，但是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 20}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 21 如果我们遇到的是图1.2，图1.3中的猫该怎么办？（我家领养的猫，刚来的时候上厕所比较臭，故取名“臭臭” ） \\n 图1.2 藏起来的“臭臭” \\n 图1.3 盘成一团的“臭臭” 猫可能只露出身体的一部分，可能会摆出奇怪的造型，那么我们又要针对这些情况定义新的规则。从这个例子中大家应该能看得出来，即使是一只很普通的家养宠物，都可能会出现无数种不同的外形。如果我们使用人工定义的规则去定义这个物体，那么可能需要设置非常大量的规则，并且效果也不一定会很好。仅仅一个物体就这么复杂，而现实中常见的各种\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 21}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 22 物体成千上万，所以在图像识别领域，使用使用人为定义的规则去做识别肯定是行不通的。很多其他的领域也同样存在这种问题。  1.2机器学习 由于人们没有办法设计出足够复杂的规则来精确描述世界，所以AI系统需要具备自我学习的能力， 即从原始数据中获取有用的知识。 这种能力被称为机器学习（Machine Learning）。 人工智能是抽象的概念，而机器学习是具体的可以落地的算法。机器学习不是一个算法，而是一大类具体智能算法的统称。 使用机器学习算法我们可以解决生活中如人脸识别， 垃圾邮件分类，语音识别等具体问题。 机器学习其实与人类学习的过程类似。打个比方：假如我们现在都是原始人，并不知道太阳和月亮是什么东西。 但是我们可以观察天上的太阳和月亮， 并且把太阳出来时候的光线和温度记录下来，把月亮出来时候的光线和温度记录下来（这就相当于是收集数据） 。观察了100天之后， 我们进行思考， 总结这100天的规律我们可以发现， 太阳和月亮是交替出现的（偶尔同时出现可以忽略） 。出太阳的时候光线比较亮，温度比较高。月亮出来的时候光线比较暗，温度比较低（这相当于是分析数据，建立模型） 。之后我们看到太阳准备落山，月亮准备出来的时候我们就知道温度要降低可能要多穿树叶或毛皮（原始人没有衣服） ，光线也准备要变暗了（预测未来的情况） 。机器学习也可以利用已有的数据进行学习，获得一个训练好的模型，然后可以利用此模型预测未来的情况。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 22}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 23 图1.4中表现了机器学习与人类思维的对比。 我们可以使用历史数据来训练一个机器学习的模型，模型训练好之后，再放入新的数据，模型就可以对新的数据进行预测分析。人类也善于从以往的经验中总结规律， 当遇到新的问题时， 我们可以根据之前的经验来预测未来的结果。 \\n 图1.4 机器学习与人类思维的对比 1.2.1训练数据，验证数据和测试数据 通常我们在做机器学习分析的时候， 会把数据分成两大部分。 一部分是训练数据（Training Data），可以用来训练，构建模型。另一部分是测试数据（Testing Data），可以用来验证模型的好坏。这两部分就有点像我们上学时课本中的习题。正文中的例题是训练数据，有答案和详细讲解，是用来教我们学习新知识的，可以看作是用来对我们进行训练。而课后习题是测试数据，我们要先做题，做完之后再对答案，是用来检查我们学习效果的。 有时我们会把数据分成三部分，即训练集（Training Set）、验证集（Validation Set）和测试集（Testing Set）。训练集还是用来训练模型。验证集是在模型的训练阶段评估模型的好坏，可以用于确定模型的参数或结构。等模型训练好，并且结构和参数都调整好之后，再用测试集来评估模型的好坏。通常我们可以把所有数据的60%分配给训练集，20%分配的验证集，20%分配给测试集。或者80%分配给训练集，10%分配给验证集，10%分配给测试集。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 23}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 24 不过这个数据划分不是绝对的，还需要看具体情况。有时候我们只划分训练集和测试集，训练集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。 K折交叉检验(K-fold Cross-Validation) —— K折交叉检验的大致思想是把数据集分成K份，每次取一份作为测试集，取余下的K-1份作为训练集。重复训练K次，每次训练都从K个部分中选一个不同的部分作为测试集（要保证K个部分的数据都分别做过测试） ，剩下的K-1份做训练集。最后把得到的K个结果做平均。 1.2.2学习方式 在机器学习或者人工智能领域， 不同的问题可能会有不同的学习方式。 主要的学习方法有： 监督学习（Supervised Learning） —— 监督学习也称为有监督学习，通常可以用于分类（Classification）以及回归（Regression）的问题。它的主要特点是，所有的数据都有与之相对应的标签（Label）。 比如我们想做一个识别手写数字的模型， 那么我们的数据集就是大量手写数字的图片，并且每一张图片都有对应的标签，如图1.5： \\n 图1.5 标签为3 图片是一个手写数字3，所以这张图片的标签可以设置为3。同样的，如果是一张手写数字8的图片，那么该图片的标签就可以是8。或者我们要建立一个判别垃圾邮件的模型，\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 24}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 25 那我们先要对邮件进行标记，标记出哪些属于垃圾邮件，哪些不属于垃圾邮件，然后建立模型。 监督学习在建模过程中，会将预测结果与训练数据的实际结果（也就是标签）做对比，如果预测结果跟实际结果不符合，将通过一些方式去调整模型的参数，直到模型的预测结果能达到比较高的准确率。 非监督学习（Unsupervised Learning)）—— 非监督学习也称为无监督学习，通常可以用于聚类（Clustering）的问题。非监督学习中，所有的数据都是没有标签的。可以使用机器学习的方法让数据自动聚类。例如许多公司都拥有庞大的客户信息数据库，使用非监督学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我们对不同细分市场的客户进行更有效的销售或者广告推送。或许我们事先并不知道有哪些细分市场，也不知道哪些客户属于细分市场A，哪些客户属于细分市场B。不过没关系，我们可以让非监督学习算法在数据中挖掘这一切信息。 半监督学习（Semi-Supervised Learning）—— 半监督学习是监督学习和非监督学习相结合的一种学习方式，通常可以用于分类以及回归问题。主要是用来解决使用少量带标签的数据和大量没有标签的数据进行训练和分类的问题。此类算法首先试图对没有标签的数据进行建模，然后再对带有标签的数据进行预测。说个题外话，半监督学习一般用得比较少，原因很简单，因为标签不足的情况通常很容易解决，只要找很多人来打标签就可以了。大型AI公司可能会有几百人的数据标注团队，每天的工作就是给各种数据打标签。因为顶尖大公司AI技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所以现在有一句叫做人工智能，先有人工，后有智能，有多少人工，就有多少智能。这是玩笑话，大家看看就好，标签很重要，不过人工智能的核心还是算法，说不定以后有一天我们可以开发出不需要标签就可以什么都学会的算法。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 25}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 26 强化学习（Reinforcement Learning）—— 强化学习灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能够获得最大利益的习惯性行为。强化学习没有任何的标签来告诉算法应该怎么做，它会先去尝试做一些动作，然后得到一个结果，通过判断这个结果是对还是错来对之前的动作进行反馈。AlphaGo中就用到了强化学习。不过目前强化学习的落地应用还比较少，大部分的应用还都只是用于打游戏。 1.2.3机器学习常用算法 机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。 决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图1.6所示。 \\n 图1.6 决策树(Decision Tree) \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 26}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 27 线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用这些数据来建立回归模型，如图1.7所示。 \\n 图1.7 线性回归(Linear Regreesion) 模型建立好之后，我们可以得到一条最符合房屋面积跟房屋价格关系的直线。根据这个模型，我们可以把一个新的房屋面积输入，就能得到该房屋的价格预测值。 KNN（K-Nearest Neighbor） —— KNN算法又称为k近邻分类(k-nearest neighbor classification)算法，是一种监督学习算法。最简单的最近邻算法就是遍历所有已知标签的样本集中的数据，计算它们和需要分类的样本之间的距离（这里的距离一般指的是欧氏距离（Euclidean Distance)），同时记录目前的最近点。KNN查找的是已知标签的样本集中跟需要分类的样本最邻近的K个样本， 需要分类的样本最终的标签是由这K个样本的标签决定的，采用的方式是“多数表决” 。也就是在这K个样本中哪种标签最多，那么需要分类的样本就归为哪一类。下图中，方形表示分类1，圆形表示分类2，图中正中心的五角星表示需要分类的样本。当K等于1时，其实就是计算距离五角星最近的样本属于哪一个分类。图1.8中，我们可以看到距离五角星最近的是方形，属于分类1，所以我们可以把五角星归为分类1。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 27}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 28 \\n 图1.8 KNN分类，K等于1 当我们取K=5时，其实就是找出距离五角星最近的5个样本，然后统计这5个样本哪种分类比较多。图1.9中我们可以看到，有1个方形和4个圆形，那么圆形比较多，所以我们可以把五角星归为分类2。 \\n 图1.9 KNN分类，K等于5 这里我们可以看到，五角星最终的分类跟K的取值有很大关系。K值取多少，模型的效果才比较好呢？这可能需要对模型进一步调试，才能得到答案，比如我们可以不断改变K值，然后用测试集来做测试，最终选取一个可以使得测试误差比较小的K值。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 28}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 29 K-Means —— K-Means是一种无监督学习算法，通常可以用于聚类分析。所谓聚类问题，就是给定一个元素集合A，集合中的每个元素有n个可观测的属性。我们需要使用某种方法把A划分为k个子集，并且要使得每个子集内部元素之间的差异尽可能小，不同子集之间元素的差异尽可能大。K-Means算法的计算过程比较直观也比较简单： （1）先从没有标签的元素集合A中随机取k个元素，作为k个子集各自的重心。 （2）分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧氏距离） ，根据距离将这些元素分别划归到最近的子集。 （3）根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的算数平均数） 。 （4）将集合A中全部元素按照新的重心然后再重新聚类。 （5）重复第（4）步，直到聚类结果不再发生变化。 K-Means运行过程如图1.10~图1.12所示。 \\n 图1.10 K-Means算法，第1次迭代 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 29}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 30 \\n 图1.11 K-Means算法，第5次迭代 \\n 图1.12 K-Means算法，第9次迭代 聚类模型一共迭代了9次，最终收敛。从图中我们可以看得出来第1次迭代的时候，模型的聚类效果是很差的，一看就不太合理。迭代了5次之后，模型有了一些改善，聚类的效果已经不错了，不过看得出来还有一些提高的空间。迭代9次之后，模型就训练好了，很好地把没有标签的数据分成了4类。相同类别之间的差距比较小，不同类别之间的差距比较大。 神经网络（Neural Network）—— 神经网络是一种模拟人类大脑神经网络结构构建出来的算法。神经网络的结构可以有多层，多层的神经网络可以由输入层（Input Layer），隐藏层（Hidden Layers）以及输出层（Output Layer）组成。其中隐藏层可能有0到多\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 30}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 31 个，所以最简单的神经网络就只有输入层和输出层。神经网络的每一层都由若干个神经元（Neuron）节点组成。 信号从输出层传入网络，与神经元的权值（Weights）作用后再经过激活函数（Activation Function）传入下一层。每一层信号的输出都是下一层的输入，直到把信号传到输出层得出结果。网络结构如图1.13所示： \\n 图1.13 神经网络（Neural Network） 神经网络是深度学习的重要基础，在后面的章节中我们会从头开始详细学习神经网络的搭建以及应用，这里只是先做一个简单介绍。 除了上面介绍的这些算法以外，机器学习领域还有很多其他的算法，如朴素贝叶斯(Naive Bayes)，支持向量机SVM(Support Vector Machine)， Adaboost等。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 31}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 32 1.3 人工智能、 机器学习， 神经网络以及深度学习之间的关系 新闻媒体在报道AlphaGo的时候，可能人工智能，机器学习，神经网络和深度学习这几个词都有用到过。对于初学者来说，难免容易混淆。 人工智能 —— 我们先说说人工智能，人工智能是这几个词中最早出现的。1956年，在美国达特茅斯会议（Dartmouth Conference）上被提出。人工智能其实是一种抽象的概念，并不是指任何实际的算法。人工智能可以对人的意识、思维进行模拟，但又不是人的智能。有时候我们还会把人工智能分为弱人工智能（Weak AI）和强人工智能（Strong AI）。 弱人工智能是擅长于单个方面技能的人工智能。比如AlphaGo能战胜了众多世界围棋冠军的，在围棋领域所向披靡，但它只会下围棋，做不了其他事情。我们目前的人工智能相关的技术，比如图像识别，语言识别，自然语言处理等等，基本都是处于弱人工智能阶段。 强人工智能指的是在各方面都能和人类智能差不多的人工智能，人类能干的脑力劳动它都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一些科幻电影中才能看到。著名的教育心理学教授Linda Gottfredson 把智能定义为“一种宽泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从经验中学习等操作。”强人工智能在进行这些操作时应该跟人类一样得心应手。 机器学习 —— 机器学习是最近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近学、凸分析、计算复杂性理论等多门学科。关于机器学习，上一小节我们已经做了一些讨论说明，我们可以发现机器学习包含很多具体的算法。既然人工智能是飘在天上的', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 32}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 33 概念，那我们就需要一些具体的算法使得人工智能可以落地应用，而一般来说，这些具体的智能算法可以统称为机器学习算法。 神经网络 —— 神经网络是众多机器学习算法中的其中一个，是模仿人类大脑神经结构构建出来的一种算法，构建出来的网络称为人工神经网络（Artificial Neural Networks，ANN）。神经网络算法在机器学习中并不算特别出色，所以一开始的时候并没有引起人们的特别关注。神经网络的发展已经经历了三次发展浪潮：20世纪40年代到60年代神经网络的雏形出现在控制论（Cybernetics）中，20世纪80年代到90年代表现为联结主（Connectionism）。直到2006年神经网络重新命名为深度学习，再次兴起。 深度学习 —— 深度学习的基础其实就是神经网络，之所以后来换了一种叫法，主要是由于之前的神经网络算法中网络的层数不能太深，也就是不能有太多层网络，网络层数过多会使得网络无法训练。随着神经网络理论的发展，科学家研究出了多种方式使得训练深层的网络也成为可能，深度学习由此诞生。如卷积神经网络（Convolutional Neural Network, CNN），长短时记忆网络（Long Short Term Memory Network, LSTM），深度残差网络（Deep Residual Network）等都属于深度学习，其中深度残差网络的深度可以到达1000层，甚至更多。深层的网络有助于挖掘数据中深层的特征，可以使得网络拥有更强大的性能。 图1.14描绘了人工智能、机器学习、神经网络和深度学习之间的关系。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 33}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 34 \\n 图1.14 人工智能、机器学习、神经网络和深度学习之间的关系  1.4 深度学习应用 深度学习最早兴起于图像识别， 在最近几年可以说是已经深入各行各业。 深度学习在计算机视觉，语音识别，自然语言处理，机器人控制，生物信息，医疗，法律，金融，推荐系统，搜索引擎，电脑游戏，娱乐等领域均有应用。 图像识别 —— 图像识别可以说是深度学习最早实现突破性成就的领域。如今计算机对图片的识别能力已经跟人类不相上下。我们把一张图片输入神经网络，经过网络的运算，最后可以得到图片的分类。如图1.15所示，我们可以看到，对于每一张图片，神经网络都给出了5个最有可能的分类，排在最上面的可能性最大。图中的置信度表示的就是该图片的概率值。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 34}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 35 \\n 图1.15 图像识别 目标检测 —— 利用深度学习我们还可以识别图片中的特定物体，然后对该物体进行标注，如图1.16所示。 \\n 图1.16 目标检测[1] 人脸识别 —— 深度学习还可以识别图像中的人脸， 判断是男人还是女人， 判断人的年龄，判断图像中的人是谁等，如图1.17所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 35}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 36 \\n 图1.17 人脸识别 目标分割 —— 目标分割识别出图中的物体，并且可以划分出物体的边界，如图1.18所示。 \\n 图1.18 目标分割[2] 描述图片 —— 把一张图片输入神经网络中，就可以输出对这张图片的文字描述，如图1.19所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 36}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 37 \\n 图1.19 图片描述 图片风格转换 —— 利用深度学习实现一张图片加上另一张图片的风格，然后生成一张新的图片，如图1.20所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 37}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 38 \\n 图1.20 图片风格转换[3] 语音识别 —— 深度学习还可以用来识别人说的话，把语音数据转换为文本数据，如图1.21所示。 \\n 图1.21 语音识别 文本分类 —— 使用深度学习对多个文本进行分类，比如判断一个评论是好评还是差评，或者判断一篇新闻是属于娱乐新闻，体育新闻还是科技新闻，如图1.22所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 38}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 39 \\n 图1.22 文本分类 机器翻译 —— 使用深度学习进行机器翻译，如图1.23所示。 \\n 图1.23 机器翻译 诗词生成 —— 把一个诗词的题目传入神经网络， 就可以生成一篇诗词， 如图1.24所示，其就是AI写的一首诗。虽然这首诗有些看不太懂，但是已经“有内味了” 。 \\n 图1.24 诗句生成 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 39}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 40 图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站https://make.girls.moe/#/，设置好动漫人物的头发颜色，头发长度，眼睛颜色，是否戴帽子等信息就可以生成符合条件的动漫人物。并且可以生成无数张不重复的照片，如图1.25所示。 \\n 图1.25 图像生成 这里只是列举了非常少量的例子，深度学习的已经逐渐深入各行各业，深入我们的生活中。  1.5 神经网络深度学习发展史 神经网络的发展历史中有过三次热潮，分别发展在20世纪40年代到60年代，20世纪80年代到90年代，以及2006年至今。每一次神经网络的热潮都伴随着人工智能的兴起，人工智能和神经网络一直以来都有着非常密切的关系。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 40}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 41 1.5.1神经网络诞生-20世纪40-60年代 1943年， 神经病学家和神经元解剖学家W.S.McCulloch和数学家W.A.Pitts在生物物理学期刊发表文章提出神经元的数学描述和结构。 并且证明了只要有足够的简单神经元， 在这些神经元互相连接并同步运行的情况下， 可以模拟任何计算函数， 这种神经元的数学模型称为M-P模型。该模型把神经元的动作描述为：1.神经元的活动表现为兴奋或抑制的二值变化；2.任何兴奋性突触输入激励后，使神经元兴奋；3.任何抑制性突触有输入激励后，使神经元抑制；4.突触的值不随时间改变；5.突触从感知输入到传送出一个输出脉冲的延时时间是0.5ms。 尽管现在看来M-P模型过于简单，并且观点也不是完全正确，不过这个模型被认为是第一个仿生学的神经网络模型， 他们提出的很多观点一直沿用至今， 比如说他们认为神经元有两种状态，要不就是兴奋，要不就是抑制。这跟后面要提到的单层感知器非常类似，单层感知器的输出要不就是0要不就是1。他们最重要的贡献就是开创了神经网络这个研究方向，为今天神经网络的发展奠定了基础。 1949年，另一位心理学家Donald Olding Hebb在他的一本名为《The organization of behavior: A neuropsychological theory》[4]的书提出了Hebb算法。他也是首先提出“连接主义” （connectionism）这一名词的人之一，这个名词的含义是大脑的活动是靠脑细胞的组合连接实现的。Hebb认为， 如果源和目的神经元均被激活兴奋时，它们之间突触的连接强度将会增强。他指出在神经网络中，信息存储在连接权值中。并提出假设神经元A到神经元B连接权与从B到A的连接权是相同的。他这里提到的这个权值的思想也被应用到了我们目前所使用的神经网络中， 我们通过调节神经元之间的连接权值来得到不同的神经网络模型，实现不同的应用。虽然这些理论在今天看来是理所当然的，不过在当时看来这是一种全新的想法，算得上是开创性的理论。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 41}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 42 1958年，计算机学家Frank Rosenblatt提出了一种神经网络结构，称为感知器(Perceptron)。他提出的这个感知器可能是世界上第一个真正意义上的人工神经网络。感知器提出之后在60年代就掀起了神经网络研究的第一次热潮。很多人都认为只要使用成千上万的神经元，他们就能解决一切问题。现在看来可能会让人感觉too young too naive，不过感知器在当时确实是影响非凡。 这股感知器热潮持续了10年，直到1969年，人工智能的创始人之一的M.Minsky和S.Papert出版了一本名为《感知器》[5]的书，书中指出简单神经网络只能运用于线性问题的求解， 能够求解非线性问题的网络应具有隐层， 而从理论上还不能证明将感知器模型扩展到多层网络是有意义的。由于Minsky在学术界的地位和影响，其悲观论点极大地影响了当时的人工神经网络研究， 为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。 这本书出版不不久之后，几乎所有为神经网络提供的研究基金都枯竭了，没有人愿意把钱浪费在没有意义的事情上。 1.5.2神经网络复兴-20世纪80-90年代 1982年，美国加州理工学院的优秀物理学家John J.Hopfield博士提出了Hopfield神经网络。Hopfield神经网络引用了物理力学的分析方法，把网络作为一种动态系统并研究这种网络动态系统的稳定性。 1985年，G.E.Hinton和T.J.Sejnowski借助统计物理学的概念和方法提出了一种随机神经网络模型——玻尔兹曼机(Boltzmann Machine)。一年后他们又改进了模型，提出了受限玻尔兹曼机(Restricted Boltzmann Machine)。 1986年，Rumelhart，Hinton，Williams提出了BP(Back Propagation)算法[6]（多层感知器的误差反向传播算法） 。到今天为止，这种多层感知器的误差反向传播算法还是非常基础的算法，凡是学神经网络的人，必然要学习BP算法。我们现在的深度网络模型基本上都是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 42}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 43 在这个算法的基础上发展出来的。使用BP算法的多层神经网络也称为BP神经网络（Back Propagation Neural network）。BP神经网络主要指的是20世纪80-90年代使用BP算法的神经网络，虽然现在的深度学习也用BP算法，不过网络名称已经不叫BP神经网络了。早期的BP神经网络的神经元层数不能太多，一旦网络层数过多，就会使得网络无法训练，具体原因在后面的章节中会详细说明。 Hopfield神经网络，玻尔兹曼机以及受限玻尔兹曼机由于目前已经较少使用，所以本书后面章节不再详细介绍这三种网络。 1.5.3深度学习-2006年至今 2006年，多伦多大学的教授Geoffrey Hinton提出了深度学习。他在世界顶级学术期刊《Science》上发表了一篇论文《Reducing the dimensionality of data with neural networks》[7]，论文中提出了两个观点：①多层人工神经网络模型有很强的特征学习能力，深度学习模型学习得到的特征数据对原始数据有更本质的代表性， 这将大大便于分类和可视化问题；②对于深度神经网络很难训练达到最优的问题，可以采用逐层训练方法解决。将上层训练好的结果作为下层训练过程中的初始化参数。 在这一文献中深度模型的训练过程中逐层初始化采用无监督学习方式。 Hinton在论文中提出了一种新的网络结构深度置信网络（Deep Belief Net：DBN），这种网络使得训练深层的神经网络成为可能。 深度置信网络由于目前已经较少使用， 所以本书后面章节不再详细介绍这种网络。 2012年，Hinton课题组为了证明深度学习的潜力， 首次参加ImageNet图像识别比赛，通过CNN网络AlexNet一举夺得冠军。 也正是由于该比赛，CNN吸引了众多研究者的注意。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 43}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 44 2014年，香港中文大学教授汤晓鸥领导的计算机视觉研究组开发了名为DeepID的深度学习模型， 在LFW (Labeled Faces in the Wild，人脸识别使用非常广泛的测试基准)数据库上获得了99.15%的识别率， 人用肉眼在LFW上的识别率为97.52%， 深度学习在学术研究层面上已经超过了人用肉眼的识别。 2016年3月人工智能围棋比赛，由位于英国伦敦的谷歌（Google）旗下DeepMind公司的开发的AlphaGo战胜了世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜。 2018年6月，OpenAI的研究人员开发了一种技术，可以在未标记的文本上训练AI，可以大量减少人工标注的时间。几个月后谷歌推出了一个名为BERT的模型，该模型在学习了几百万个句子以后学会了如何预测漏掉的单词。在多项NLP (Natural Language Processing) 测试中，它的表现都接近人类。 2020年6月，OpenAI发布了有史以来最大的NLP模型GPT-3，GPT-3模型参数达到了1750亿个参数，模型训练花费了上千万美元。GPT-3训练方法很简单，但是却非常全能，可以完成填空，翻译，问答，阅读理解，数学计算，语法纠错等多项任务。随着NLP技术的发展，相信在将来AI可以逐渐理解我们的语言，跟我们进行顺畅的对话，甚至成为我们的保姆，老师或朋友。 今天， 人脸识别技术已经应用在了我们生活的方方面面， 比如上下班打卡， 飞机高铁出行，出门住酒店，刷脸支付等。我们已经离不开深度学习技术，而深度学习技术仍在快速发展中。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 44}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 45 1.6 深度学习领域重要人物 深度学习领域有很多做出过卓越贡献的大师，下面简单介绍几位。前面的3位大师Geoffrey Hinton、Yann LeCun、Yoshua Bengio江湖人称“深度学习三巨头” ，为了表彰3位大师对于神经网络深度学习领域的贡献，2018年计算机领域最高奖项图灵奖颁给了他们。 1.Geoffrey Hinton 英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。Hinton是反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者。目前担任多伦多大学计算机科学系教授。 2013年3月加入Google，领导Google Brain项目。 Hinton被人们称为“深度学习教父” ，可以说是目前对深度学习领域影响最大的人。而且如今在深度学习领域活跃的大师，有很多都是他的弟子，可以说是桃李满天下。 2.Yann LeCun 法国出生的计算机科学家， 他最著名的工作是光学字符识别和计算机视觉上使用卷积神经网络（CNN） ，他也被称为卷积网络之父。 曾在多伦多大学跟随Geoffrey Hinton做博士后。1988年加入贝尔实验室，在贝尔实验室工作期间开发了一套能够识别手写数字的卷积神经网络系统， 并把它命名为LeNet。 这个系统能自动识别银行支票。 2003年去了纽约大学担任教授，现在是纽约大学终身教授。 2013年12月加入了Facebook，成为Facebook人工智能实验室的第一任主任。 3.Yoshua Bengio ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 45}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 46 毕业于麦吉尔大学，在MIT和贝尔实验室做过博士后研究员，自1993年之后就在蒙特利尔大学任教。在预训练问题，自动编码器降噪等领域做出重大贡献。 这“三巨头”中的前两人早已投身工业界，而Bengio仍留在学术界教书，他曾说过：“我留在学术圈是为全人类作贡献，而不是为某一公司赚钱” 。他说这句话一定是因为他很有钱，开个玩笑。每个领域的发展不仅需要做前沿的研究，还需要不断培养新的新鲜血液加入到这个行业中，所以如果大学教授都去工作的话，上课教书的人就少了。所以Bengio能留在学术圈，对行业的发展也是一件好事。 2017年初Bengio选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他指的显然是Google和Facebook）成为人工智能变革中的唯一大玩家，这对研究社区没有好处，对人类也没有好处。 4.Andrew Ng（吴恩达） Andrew Ng是美籍华人，曾经是斯坦福大学计算机科学系和电气工程系的副教授，斯坦福人工智能实验室主任。他还与Daphne Koller一起创建了在线教育平台Coursera。 2011年，Andrew Ng在Google创建了Google Brain项目，通过分布式集群计算机开发超大规模的人工神经网络。 2014年5月，Andrew Ng加入百度，负责百度大脑计划，并担任百度公司首席科学家。 2017年3月，Andrew Ng从百度离职，目前自己创业。 LeCun是Hinton的 博士生，另一位人工智能大师Jordan曾经申请过Hinton的博士生，Bengio是Jordan的博士后，Andrew Ng是Jordan的博士生，LeCun与Bengio曾经是同事。这个圈子很小，大家都认识，这几位大师互相之间有着很深的渊源。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 46}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 47 曾经神经网络的圈子很小，基本上入了这个圈以后就没什么前途了。正是由于这个圈子里的这些大师前辈们的不懈努力，把神经网络算法不断优化，才有了今天的深度学习和今天人工智能的新局面。  1.7 新一轮人工智能爆发的三要素 这一轮人工智能大爆发的主要原因有3个，深度学习算法，大数据，以及高性能计算。 深度学习算法 —— 之前人工智能领域的实际应用主要是使用传统的机器学习算法，虽然这些传统的机器学习算法在很多领域都取得了不错的效果，不过仍然有非常大的提升空间。深度学习出现后，计算机视觉，自然语言处理，语音识别等领域都取得了非常大的进步。 大数据 —— 如果把人工智能比喻成一个火箭， 那么这个火箭需要发射升空， 它的燃料就是大数据。以前在实验室环境下很难收集到足够多的样本，现在的数据相对以前在数量、覆盖性和全面性方面都获得了大幅提升。 一般来说深度学习模型想要获得好的效果， 就需要把大量的数据放到模型中进行训练。 高性能计算 —— 以前高性能计算大家用的是CPU集群，现在做深度学习都是用GPU(Graphics Processing Unit)或TPU(Tensor Processing Unit)。 想要使用大量的数据来训练复杂的深度学习模型那就必须要具备高性能计算能力。GPU就是我们日常所说的显卡，平时主要用于打游戏。但是GPU不仅可以用于打游戏，还可以用来训练模型，性价比很高，买显卡的理由又多了一个。如果只是使用几个CPU来训练一个复杂模型可能会需要花费几周甚至几个月的时间。把数百块GPU连接起来做成集群，用这些集群来训练模型，原来一个月才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 47}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 48 间。TPU是谷歌专门为机器学习量身定做的处理器， 执行每个操作所需的晶体管数量更少， 效率更高。  工欲善其事，必先利其器。下一章节我们将介绍如何搭建python开发环境，为我们后续的学习做准。  1.8参考文献 [1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018. [2] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2961-2969. [3] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint arXiv:1508.06576, 2015. [4] Hebb D O. The organization of behavior: A neuropsychological theory[M]. Psychology Press, 2005. [5] Minsky M, Papert S A. Perceptrons: An introduction to computational geometry[M]. MIT press, 2017. [6] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors[J]. nature, 1986, 323(6088): 533-536. [7] Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets[J]. Neural computation, 2006, 18(7): 1527-1554.  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 48}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 49 第2章-搭建Python编程环境 本章节内容与深度学习没有直接关系，不过随着人工智能技术的发展，Python已经成为时下最热门的编程语言之一， 广泛应用于机器学习和深度学习的应用中。 目前大多数深度学习框架的主要编程语言都是Python，Python可谓是目前人工智能领域的第一语言。本书中使用的所有代码都是python程序，所以这一章节我们主要学习python编程环境的搭建。 如果大家之前有python基础那这一章节的内容就比较简单了，直接跳过也可以。如果大家之前完全没有学过python，那么建议大家还是先学习python的使用，不然后续编程实践的内容可能会碰到很多问题。  2.1 Python介绍 Python是一种面向对象的解释型计算机程序设计语言， 由荷兰人Guido van Rossum于1989年发明。Python具有丰富强大的库， 常被称为 “胶水语言” ， 因为它能够把其他语言 （尤其是C/C++）制作各种模块轻松联结在一起。 Python的主要优点是开发效率高，可移植性强，可拓展性强，应用广泛等，主要的缺点是程序运行效率相比C/C++来说比较慢。 Python的主要应用领域有系统编程，网络爬虫，人工智能，科学计算，WEB开发，系统运维，大数据，云计算，量化交易，金融分析，图形界面。 谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google广告等项目都在大量使用Python开发。 CIA: 美国中情局网站就是用Python开发的。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 49}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 50 NASA: 美国航天局(NASA)大量使用Python进行数据分析和运算。 YouTube:世界上最大的视频网站YouTube就是用Python开发的。 Dropbox:美国最大的在线云存储网站， 全部用Python实现， 每天网站处理10亿个文件的上传和下载。 Instagram:美国最大的图片分享社交网站， 每天超过3千万张照片被分享， 全部用python开发。 Facebook:大量的基础库均通过Python实现的。 Redhat: 世界上最流行的Linux发行版本中的yum包管理工具就是用python开发的。 豆瓣: 公司几乎所有的业务均是通过Python开发的。 知乎: 国内最大的问答社区，通过Python开发。  2.2 Anaconda安装 推荐的Python安装方式是使用Anaconda对Python进行安装。Anaconda是一个开源的Python发行版本，其中包含了Numpy,Pandas,Matplotlib等多个常用的Python包和依赖项。Anaconda的官方下载地址为：https://www.anaconda.com/download/。官方下载地址上大家看到的是最新的python安装包的下载，如果想下载之前版本的python，可以通过下面这个地址：https://repo.continuum.io/archive/。 目前Python常用的版本有2.7和3.6/3.7/3.8版本，python官方已经宣布以后python2将会停止维护，python以后会逐渐往python3的方向发展，所以推荐大家学习python3。之后python的版本还会不断更新，可能还会继续推出3.9/3.10/4.0等。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 50}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 51 Python2和python3稍微有些差异，python3.6/3.7/3.8之间的差异就不大了，所以我们不一定要安装最新的python，因为有些软件可能跟最新的python会不兼容。比如现在python的最新版本是3.8，那么我们可以安装3.6/3.7的版本，这样兼容性会稍微好一些。 Python程序在Windows,Linux,MacOS下基本是差不多的，所以在Windows上可以运行的Python程序，在其他系统一般也能运行。 下面我们主要讲解Anaconda在Windows环境下的安装，其他系统的安装方式略有不同，如果你熟悉其他系统的话，安装起来应该也是很简单的。如果我们要安装最新版本的Anaconda，首先打开Anaconda下载网址，根据系统选择相应的Anaconda安装包。选择Python3.7版本、64位的安装包进行下载，如图2.1所示。 \\n 图2.1 Anaconda下载  如果我们要安装之前版本的Anaconda，可以打开网址https://repo.continuum.io/archive/，出现如图2.2所示的界面。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 51}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 52 \\n 图2.2 各种版本的Anaconda Anaconda2 表示安装python2，Anaconda3表示安装python3， 具体是python3.X，从安装包的文件名是看不出来的。Windows/MacOSX/Linux表示对应的操作系统。有64表示64位的系统，没有64表示32位的系统。 安装包下载好之后，双击安装包进行安装。如图2.3所示，单击Next按钮,。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 52}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 53 图2.3 Anaconda安装流程（1） 然后单击I Agree按钮，如图2.4所示。 \\n 图2.4 Anaconda安装流程（2） 接下来可以选择All Users，单击Next按钮，如图2.5所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 53}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 54 图2.5 Anaconda安装流程（3） 接下来选择一个Anaconda的安装路径，如图2.6所示，可以是任何路径，不一定要跟图中的路径一致。 \\n 图2.6 Anaconda安装流程（4） 最后勾选“Add Anaconda to the system PATH environment variable”和“Register Anaconda as the system Python3.6” ，然后单击Install按钮，Anaconda就开始安装了。这里注意，一定要勾选相应选项，其目的是让软件帮我们自动配置环境变量，如图2.7所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 54}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 55 \\n 图2.7 Anaconda安装流程（5） 安装的过程大家不要心急，耐心等待，不要随意关闭软件的窗口，等确认软件已经安装完毕再关闭窗口。后面软件会有提示是否要安装VSCode，VSCode是一款很好用的编译器，可以用于开发各种编程语言写的程序，包括python。大家感兴趣的话可以安装，不安装也可以。  2.3 Jupyter Notebook的简单使用 Python有非常多的集成开发环境可以使用，比如Jupyter Notebook，Spyder，PyCharm，Eclipse，VSCode等等，每种开发环境都各有优缺点，这里就不一一介绍了。如果大家之前已经有熟悉并喜欢的开发环境可以继续使用，如果大家是初学者对各种开发环境不了解的话推荐大家可以先使用Jupyter Notebook。Jupyter Notebook的优点是界面和\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 55}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 56 功能都比较简洁，并且可以实时运行查看程序结果，还可以把程序运行的结果保存在文件中。缺点是不太好开发大型程序，不过对于初学者来说，我们可能暂时还不会接触到大型程序，Jupyter Notebook基本就够用了。本书中的程序基本都是在Jupyter Notebook中完成的，它是安装完Anaconda后自带的一个Python开发环境。界面简洁，使用简单，适合快速实验和用于学习。 我会给大家提供书中Jupyter Notebook的程序文件以及python的程序文件。Jupyter Notebook的程序文件是以“.ipynb”结尾，只能在Jupyter Notebook中运行，不能在命令提示符/终端运行；python的程序文件是以“.py”结尾，不能在Jupyter Notebook中运行，可以在其他python集成开发环境或者命令提示符/终端运行。Jupyter Notebook的程序文件可以在Jupyter Notebook环境中转成python程序文件。 2.3.1启动Jupyter Notebook Anaconda安装完成后桌面上不会增加新的图标，我们需要搜索Jupyter Notebook，找到这个开发环境，Jupyter的图标如图2.8所示，找到后可以右键单击图标，然后发送到桌面快捷方式。 \\n 图2.8 Jupyter Notebook 双击Jupyter Notebook，打开后可以看到Jupyter是在网页中进行编程的，在Jupyter的界面中我们可以对我们电脑本地的文件进行新建，删除和修改，如图2.9所示 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 56}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 57  图2.9 Jupyter主界面 2.3.2 修改Jupyter Notebook默认启动路径 大家打开Jupyter后，可能会在的主界面中看到一些熟悉的文件，这些文件正是我们电脑本地的一些文件，其实Jupyter的主界面对应的是我们电脑中的一个路径，这个路径是可以修改的，我们可以创建一个新的文件夹，专门用于写python程序。 Jupyter Notebook的默认启动路径为：”C:\\\\User\\\\你的用户名\\\\”。所以第一次打开Jupyter Notebook我们会看到”C:\\\\User\\\\你的用户名\\\\”这个路径的文件出现在Jupyter Notebook的主界面。其实Jupyter Notebook的启动路径不一定要修改，如果你想使用”C:\\\\User\\\\你的用户名\\\\”或者你觉得修改Jupyter Notebook默认路径比较麻烦，那么你可以使用默认的”C:\\\\User\\\\你的用户名\\\\”路径作为Jupyter Notebook的工作路径。只要把python相关的程序（比如书中代码）复制到”C:\\\\User\\\\你的用户名\\\\”路径下，在Jupyter Notebook的主界面就可以看到你复制的程序，然后在Jupyter Notebook环境中就可以对这些程序进行修改和运行了。 如果希望把程序存放在其他路径，使用其他路径作为Jupyter Notebook的工作路径，那么就进行下面的操作： 首先我们要右键Jupyter Notebook的图标，查看属性，然后看到目标，目标最后如果有%USERPROFILE%，则把后面的%USERPROFILE%删掉，如图2.10所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 57}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 58 \\n 图2.10 删除%USERPROFILE% 下一步需要生成配置文件，打开命令提示符执行：jupyter notebook --generate-config，我们会看到如图2.11所示的结果。  图2.11 生成配置文件 我们可以看到配置文件生成的位置，本书例子中配置文件生成的位置是 C:\\\\Users\\\\qin\\\\.jupyter\\\\jupyter_notebook_config.py， 进入系统盘， 用户文件下， 可以看到一个.jupyter的文件，如图2.12所示 \\n 图2.12 .jupyter文件 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 58}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 59 进入.jupyter文件夹中找到jupyter_notebook_config.py文件，用文本工具打开jupyter_notebook_config.py文件，找c.NotebookApp.notebook_dir配置， “#”为注释，先把它前面的“#”给去掉，然后填入你想要的Python程序存放路径。如图2.13所示。 \\n 图2.13 修改Jupyter工作路径 图中的例子是在“E/test” ，大家不一定要使用这个路径，可以任意设置其他路径。注意这里设置的路径必须是本地已经存在的路径。注意路径最好是全英文，如果路径有中文需要把jupyter_notebook_config.py文件另存为UTF-8的格式。注意路径中的斜杠是“/”不是“\\\\”。 顺利的话，重新启动Jupyter Notebook就可以看到Jupyter的主界面跳转到了你设置的路径。 如果是使用Linux或者MacOS的话可以先在终端用cd命令跳转到你的程序所在路径，然后使用命令： jupyter notebook 打开Jupyter Notebook软件，这时你会看到你的程序所在路径已经成为你的Jupyter Notebook的工作路径。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 59}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 60 2.3.3 Jupyter Notebook浏览器无法打开 如果电脑的浏览器太老，有可能会出现Jupyter Notebook无法打开的情况，Jupyter Notebook闪退，或者是浏览器一片空白。这个时候可以下载安装一个新的谷歌浏览器，然后再打开Jupyter Notebook的配置文件，在任意位置加入如下命令： import webbrowser webbrowser.register(\"chrome\",None,webbrowser.GenericBrowser(u\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\")) c.NotebookApp.browser = \\'chrome\\' 该命令的作用是把Jupyter Notebook的默认浏览器设置为谷歌浏览器，其中\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\"为谷歌浏览器的执行文件所在位置，每台电脑位置可能不同，需要自己查看修改。 2.3.4 Jupyter Notebook基本操作 接下来新建一个文件，单击右上角的New按钮，然后单击Python选项，这样就可以创建一个新的文件，如图2.14所示。 \\n 图2.14 创建新文件 创建好文件之后，可以看到如图2.15所示的界面。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 60}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 61  图2.15 Jupyter编译界面 单击Untitled的位置可以修改文件名字，如图2.16所示。 \\n 图2.16 Jupyter修改文件名 然后就可以开始编程了，按照惯例，我们先来写一个“hello world” ，写完之后，按“Shift+Enter”组合键执行程序，按住Shift不要放手，然后按Enter。如图2.17所示。 \\n 图2.17 执行hello world 一个框内可以执行多行代码，如图2.18所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 61}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 62 图2.18 执行多行代码 把光标移动到函数的内部， 然后按“Shift+Tab”组合键可以查看该函数的使用方法， 先按住Shift不要放手，然后按两下Tab，如图2.19所示。 \\n 图2.19 查看函数说明 Jupyter还有很多神奇的用法，大家有兴趣可以去探索，这里就不过多介绍了。 下一章我们将正式开始进入神经网络深度学习的大门。            \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 62}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 63 第3章-单层感知器与线性神经网络 本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络ANN的设计实际上是从生物体的神经网络结构获得的灵感。模仿生物神经网络我们构造出了单层感知器，在单层感知器的基础上经过不断地优化才得到了后来的神经网络算法。  3.1生物神经网络 生物神经网络一般是指生物的大脑神经元，细胞等组成的网络，用于产生生物的意识，帮助生物进行思考和行动。 神经细胞构是构成神经系统的基本单元，简称为神经元。神经元主要由三部分构成：①细胞体；②轴突；③树突。如3.1图所示。 \\n 图3.1 生物神经元结构 每个神经元伸出的突起分2种，树突和轴突。树突分支比较多，每个分支还可以再分支，长度一般比较短，作用是接受信号。轴突只有一个，从细胞体的一个凸出部分伸出，长度一般\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 63}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 64 比较长， 作用是把从树突和细胞表面传入细胞体的神经信号传出到其他神经元。 轴突的末端分为许多小支，连接到其他神经元的树突上。 大脑可视作为1000多亿神经元组成的神经网络。 神经元的信息传递和处理是一种电化学活动。树突由于电化学作用接受外界的刺激，通过胞体内的活动体现为轴突电位，当轴突电位达到一定的值则形成神经脉冲或动作电位；再通过轴突末梢传递给其它的神经元。从控制论的观点来看，这一过程可以看作一个多输入单输出非线性系统的动态过程。  3.2单层感知器 3.2.1单层感知器介绍 受到生物神经网络的启发， 计算机学家Frank Rosenblatt在20世纪60年代提出了一种模拟生物神经网络的的人工神经网络结构，称为感知器（Perceptron） 。图3.1为单层感知器结构图。 \\n 图3.1 单层感知器 图中𝑥\"，𝑥#，𝑥$为输入信号，类似于生物神经网络中的树突。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 64}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 65 𝑤\"，𝑤#，𝑤$分别为𝑥\"，𝑥#，𝑥$的权值，它可以调节输入信号的值的大小，让输入信号变大(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突传递到细胞核的过程中信号会发生变化。 公式∑(𝑤(𝑥()+𝑏(表示细胞的输入信号在细胞核的位置进行汇总∑𝑤(𝑥((，然后再加上该细胞本身自带的信号b。b一般称为偏置值（Bias），相当于是神经元内部自带的信号。 f(x)称为激活函数，可以理解为信号在轴突上进行的线性或非线性变化。在单层感知器中最开始使用的激活函数是sign(x)激活函数。该函数的特点是当x＞0时，输出值为1；当x＝0时，输出值为0,；当x＜0时，输出值为-1。sign(x)函数图像如图3.2所示。 \\n 图3.2 sign函数图像 y就是𝑓(∑(𝑤(𝑥()+𝑏()，为单层感知器的输出结果。  3.2.2单层感知器计算举例 假如有一个单层感知器有3个输入𝑥\"，𝑥#，𝑥$，同时已知b=-0.6，𝑤\"=𝑤#=𝑤$=0.5，那么根据单层感知器的计算公式𝑓(∑(𝑤(𝑥()+𝑏()我们就可以得到如图3.3计算结果。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 65}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 66 \\n 图3.3 单层感知器计算 𝑥\"=0,\\t𝑥#=0,\\t𝑥$=0：sign(0.5×0+0.5×0+0.5×0−0.6)=−1 𝑥\"=0,\\t𝑥#=0,\\t𝑥$=1：sign(0.5×0+0.5×0+0.5×1−0.6)=−1 𝑥\"=0,\\t𝑥#=1,\\t𝑥$=0：sign(0.5×0+0.5×1+0.5×0−0.6)=−1 𝑥\"=0,\\t𝑥#=1,\\t𝑥$=1：sign(0.5×0+0.5×1+0.5×1−0.6)=1 𝑥\"=1,\\t𝑥#=0,\\t𝑥$=0：sign(0.5×1+0.5×0+0.5×0−0.6)=−1 𝑥\"=1,\\t𝑥#=0,\\t𝑥$=1：sign(0.5×1+0.5×0+0.5×1−0.6)=1 𝑥\"=1,\\t𝑥#=1,\\t𝑥$=0：sign(0.5×1+0.5×1+0.5×0−0.6)=1 𝑥\"=1,\\t𝑥#=1,\\t𝑥$=1：sign(0.5×1+0.5×1+0.5×1−0.6)=1  3.2.3单层感知器的另一种表达形式 单层感知器的另一种表达形式如图3.4。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 66}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 67 \\n 图3.4 单层感知器的另一种表达形式 其实这种表达形式跟3.2.1中的单层感知器是一样的。只不过是把偏置值b变成了输入𝑤<×𝑥<， 其中𝑥<=1。 所以𝑤<×𝑥<实际上就是𝑤<，把∑(𝑤(𝑥()(公式展开得到：𝑤\"×𝑥\"+𝑤#×𝑥#+𝑤$×𝑥$+𝑤<。所以这两个单层感知器的表达不一样，但是计算结果是一样的。如图3.4的表达形式更加简洁，更适合使用矩阵来进行运算。  3.3 单层感知器的学习规则 3.3.1单层感知器的学习规则介绍 感知器的学习规则就是指感知器中的权值参数训练的方法， 在本章节中我们暂时先不解释这个学习规则是怎么推导出来的。等第4章我们讲到Delta学习规则的时候我们再来解释感知器的学习规则是如何推导的。在这里我们可以先接受下面的公式即可。 在3.2.3中我们已知单层感知器表达式可以写成： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 67}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 68 𝑦=𝑓>?(𝑤(𝑥()@(A<B(3.1) 公式(3.1)中：y表示感知器的输出；f是sign激活函数；n是输入信号的个数i=0,1,2... ∆𝑤(=𝜂(𝑡−𝑦)𝑥((3.2) 公式(3.2)中：∆𝑤(表示第i个权值的变化；𝜂表示学习率(Learning Rate)，用来调节权值变化的大小；t是正确的标签(target)。 因为单层感知器的激活函数为sign函数，所以t和y的取值都为±1 t=y时，∆𝑤(为0；t=1，y=-1时，∆𝑤(为2；t=-1，y=1时，∆𝑤(为-2。由式(3.2)可以推出： ∆𝑤(=±2𝜂𝑥((3.3) 权值的调整公式为： 𝑤(=𝑤(+∆𝑤((3.4) 3.3.2单层感知器的学习规则计算举例 假设有一个单层感知器如图3.1所示，已知有三个输入x0=1，x1=0，x2=-1，权值w0=-5，w1=0，w2=0，学习率𝜂=1，正确的标签t=1。(注意在这个例子中偏置值b用𝑤<×𝑥<来表示，x0的值固定为1) Step1：我们首先计算感知器的输出。 𝑦=𝑓>?(𝑤(𝑥()@(A<B \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(−5×1+0×0+0×(−1)+0) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(−5) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−1 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 68}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 69  由于y=-1与正确的标签t=1不相同，所以需要对感知器中的权值进行调节。  ∆𝑤<=𝜂(𝑡−𝑦)𝑥<=1×(1+1)×1=2  ∆𝑤\"=𝜂(𝑡−𝑦)𝑥\"=1×(1+1)×0=0 ∆𝑤#=𝜂(𝑡−𝑦)𝑥#=1×(1+1)×(−1)=−2 𝑤<=𝑤<+∆𝑤<=−5+2=−3  𝑤\"=𝑤\"+∆𝑤\"=0+0=0  𝑤#=𝑤#+∆𝑤#=0−2=−2 Step2：重新计算感知器的输出。 𝑦=𝑓>?(𝑤(𝑥()@(A<B \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(−3×1+0×0+(−2)×(−1)+0) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(−1) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−1  由于y=-1与正确的标签t=1不相同，所以需要对感知器中的权值进行调节。  ∆𝑤<=𝜂(𝑡−𝑦)𝑥<=1×(1+1)×1=2  ∆𝑤\"=𝜂(𝑡−𝑦)𝑥\"=1×(1+1)×0=0 ∆𝑤#=𝜂(𝑡−𝑦)𝑥#=1×(1+1)×(−1)=−2 𝑤<=𝑤<+∆𝑤<=−3+2=−1  𝑤\"=𝑤\"+∆𝑤\"=0+0=0  𝑤#=𝑤#+∆𝑤#=−2−2=−4 Step3：重新计算感知器的输出。 𝑦=𝑓>?(𝑤(𝑥()@(A<B ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 69}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 70 \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(−1×1+0×0+(−4)×(−1)+0) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=sign(3) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=1  由于y=1与正确的标签t=1相同，说明感知器经过训练后得到了我们想要的结果，我们就可以结束训练了。  把上面的例子写成python程序的话，可以得到代码3-1。 代码3-1：单层感知器学习规则计算举例 # 导入numpy 科学计算包 import numpy as np # 定义输入 x0 = 1 x1 = 0 x2 = -1 # 定义权值 w0 = -5 w1 = 0 w2 = 0 # 定义正确的标签 t = 1 # 定义学习率lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如100 for i in range(100):     # 打印权值     print(w0,w1,w2)     # 计算感知器的输出     y = np.sign(w0 * x0 + w1 * x1 + w2*x2)     # 如果感知器输出不等于正确的标签     if(y != t):         # 更新权值         w0 = w0 + lr * (t-y) * x0         w1 = w1 + lr * (t-y) * x1 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 70}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 71         w2 = w2 + lr * (t-y) * x2     # 如果感知器输出等于正确的标签     else:         # 训练结束         print('done')         # 退出循环      break 运行结果如下： -5 0 0 -3 0 -2 -1 0 -4 done  下面我们还可以用矩阵运算的方式来完成同样的计算，代码3-2为矩阵运算的方式来进行单层感知器学习规则的计算。 代码3-2：单层感知器学习规则计算举例(矩阵计算) # 导入numpy 科学计算包 import numpy as np # 定义输入，用大写字母表示矩阵 # 一般我们习惯用一行来表示一个数据，如果存在多个数据就用多行来表示 X = np.array([[1,0,-1]]) # 定义权值，用大写字母表示矩阵 # 神经网络中权值的定义可以参考神经网络的输入是输出神经元的个数 # 在本例子中输入神经元个数为3个，输出神经元个数为1个，所以可以定义3行1列的W W = np.array([[-5],               [0],               [0]]) # 定义正确的标签 t = 1 # 定义学习率lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如100 for i in range(100):     # 打印权值     print(W)     # 计算感知器的输出，np.dot可以看做是矩阵乘法     y = np.sign(np.dot(X,W))     # 如果感知器输出不等于正确的标签 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 71}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 72     if(y != t):         # 更新权值         # X.T表示X矩阵的转置         # 这里一个步骤可以完成代码3-1中下面3行代码完成的事情         # w0 = w0 + lr * (t-y) * x0         # w1 = w1 + lr * (t-y) * x1         # w2 = w2 + lr * (t-y) * x2         W = W + lr * (t - y) * X.T     # 如果感知器输出等于正确的标签     else:         # 训练结束         print('done')         # 退出循环      break 运行结果如下：  [[-5]  [ 0]  [ 0]] [[-3]  [ 0]  [-2]] [[-1]  [ 0]  [-4]] done  3.4 学习率 学习率是人为设定的一个超参数， 主要是在训练阶段用来控制模型参数调整的快慢。 关于学习率主要有3个要点需要注意： （1）学习率𝜼取值一般取0-1之间； （𝟐）学习率太大容易造成权值调整不稳定； （3）学习率太小，模型参数调整太慢，迭代次数太多。 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 72}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 73 你可以想象一下在洗热水澡的时候：如果每次调节的幅度很大，那水温要不就是太热，要不就是太冷，很难得到一个合适的水温；如果一开始的时候水很冷，每次调节的幅度都非常小，那么需要调节很多次，花很长时间才能得到一个合适的水温。学习率的调整也是这样一个道理。图3.5表示不同大小的学习率对模型训练的影响。 \\n 图3.5 不同大小的学习率对模型训练的影响 图中的纵坐标loss代表代价函数（Loss Function），在后面的章节中有更详细的介绍，这里我们可以把它近似理解为模型的预测值与真实值之间的误差。我们训练模型的主要目的就是为了降低loss值，减少模型预测值与真实值之间的误差。横坐标Epoch代表模型的迭代周期，把所有训练数据都训练一遍可以称为迭代了一个周期。 从图中我们可以看到，如果使用非常大的学习率（very high lr）来训练模型，loss会一直处于一个比较大的位置，模型不能收敛，这肯定不是我们想要的结果。如果使用比较大的学习率（high lr）来训练模型，loss会下降很快，但是最后loss最终不能得到比较比较小的值，所以结果也不理想。如果使用比较小的学习率（low lr）来训练模型，模型收敛的速度会很慢，需要等待很长时间模型才能收敛。最理想的结果是使用合适的学习率（good lr）来\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 73}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 74 训练模型，使用合适的学习率，模型的loss值下降得比较快，并且最后的loss也能够下降到一个比较小的位置，结果最理想。 看到这里大家可能会有一个疑问，学习率的值到底取多少比较合适？这个问题其实是没有明确答案的，需要根据建模的经验以及测试才能找到合适的学习率。不过学习率的选择也有一些小的trick可以使用，比如说最开始我们设置一个学习率为0.01，经过测试我们发现学习率太小了需要调大一点，那么我们可以改成0.03。如果0.03还需要调大，我们可以调到0.1。同理，如果0.01太大了，需要调小，那么我们可以调到0.003。如果0.003还需要调小，我们可以调到0.001。所以常用的学习率可以选择： 1，0.3，0.1，0.03，0.01，0.003，0.001，0.0003，0.0001 ... 当然这也不是绝对的，其他的学习率的取值你也可以去尝试。  3.5 模型的收敛条件 通常模型的收敛条件可以有以下3个： （1）loss小于某个预先设定的较小的值； （2）两次迭代之间权值的变化已经很小了； （3）设定最大迭代次数，当迭代超过最大次数就停止。 第一种很容易理解，模型的训练目的就是为了减少loss值，那么我们可以设定一个比较小的数值，每一次训练的时候我们都同时计算一下loss值的大小，当loss值小于某个预先设定的阈值，就可以认为模型收敛了。那么就可以结束训练。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 74}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 75 第二种的意思是， 每一次训练我们可以记录模型权值的变化， 如果我们发现两次迭代之间模型的权值变化已经很小， 那么说明模型已经几乎不需要做权值地调整了， 那么就可以认为模型收敛，可以结束训练。 第三种是用得最多的方式。 我们可以预先设定一个比较大的模型迭代周期， 比如迭代100次，或者10000次，或者1000000次等（需要根据实际情况来选择）。模型完成规定次数的训练之后我们就可以认为模型训练完毕。 如果达到我们设置的训练次数以后我们发现模型还没有训练好的话，我们可以继续增加训练次数，让模型继续训练就可以了。  3.6 模型的超参数和参数的区别 模型的超参数（Hyperparameters）是机器学习或者深度学习中经常用到的一个概念，我们可以认为是根据经验来人为设置的一些模型相关的参数。 比如说前面提到的学习率， 学习率需要根据经验来人为设置。 比如模型的迭代次数， 也是需要在模型训练之前预先进行人为设置。 而前面提到的权值和偏置值则是参数 （Parameters）， 一般指的是模型中需要训练的变量。我们会给权值和偏置值进行随机初始化赋值， 模型在训练过程中会不断调节这些参数， 进行模型优化。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 75}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 76 3.7 单层感知器分类案例 题目：假设我们有4个2维的数据，数据的特征分别是(3,3),(4,3),(1,1),(2,1)。(3,3),(4,3)这两个数据的标签为1，(1,1),(2,1)这两个数据的标签为-1。构建神经网络来进行分类。 思路： 我们要分类的数据是2维数据， 所以只需要2个输入节点 （一般输入数据有几个特征，我们就设置几个输入神经元） ，我们可以把神经元的偏置值也设置成一个输入节点，使用3.2.3中的方式。这样我们需要3个输入节点。 输入数据有4个(1,3,3),(1,4,3),(1,1,1),(1,2,1) 数据对应的标签为(1,1,-1,-1) 初始化权值w1,w2,w3取0到1的随机数 学习率lr(learning rate)设置为0.1 激活函数为sign函数 我们可以构建一个单层感知器如图3.6所示。 \\n 图3.6 单层感知器 代码3-3为单层感知器应用案例。 代码3-3：单层感知器案例 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 76}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 77 import numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3],               [1,4,3],               [1,1,1],               [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1],               [1],               [-1],               [-1]])  # 权值初始化，3行1列 # np.random.random可以生成0-1的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0  # 更新一次权值 def train():     # 使用全局变量W     global W     # 同时计算4个数据的预测值     # Y的形状为(4,1)-4行1列     Y = np.sign(np.dot(X,W))      # T - Y得到4个的标签值与预测值的误差E。形状为(4,1)     E = T - Y      # X.T表示X的转置矩阵，形状为(3,4)     # 我们一共有4个数据，每个数据3个值。定义第i个数据的第j个特征值为xij     # 如第1个数据，第2个值为x12     # X.T.dot(T - Y)为一个3行1列的数据：     # 第1行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第1个神经元对应的权值     # 第2行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第2个神经元对应的权值     # 第3行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整3个神经元对应的权值     # X.shape表示X的形状X.shape[0]得到X的行数，表示有多少个数据 # X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式3.2看起来有些不同，原因是这里的计算是矩阵运算，书中公式3.2是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的     delta_W = lr * (X.T.dot(E)) / X.shape[0]  W = W + delta_W # 训练100次 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 77}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 78 for i in range(100):     #更新一次权值     train()     # 打印当前训练次数     print('epoch:',i + 1)     # 打印当前权值     print('weights:',W)     # 计算当前输出      Y = np.sign(np.dot(X,W))      # .all()表示Y中的所有值跟T中所有值都对应相等，结果才为真     if(Y == T).all():          print('Finished')         # 跳出循环         break  #————————以下为画图部分————————# # 正样本的xy坐标 x1 = [3,4] y1 = [3,3] # 负样本的xy坐标 x2 = [1,2] y2 = [1,1]  # 计算分类边界线的斜率以及截距 # 神经网络的信号总和为w0×x0+w1×x1+w2×x2 # 当信号总和大于0再进过激活函数，模型的预测值会得到1 # 当信号总和小于0再进过激活函数，模型的预测值会得到-1 # 所以当信号总和w0×x0+w1×x1+w2×x2=0时为分类边界线表达式 # 我们在画图的时候把x1，x2分别看成是平面坐标系中的x和y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d =  -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 78}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 79 epoch: 1 weights: [[0.83669451]  [0.58052698]  [0.25564497]] epoch: 2 weights: [[0.73669451]  [0.43052698]  [0.15564497]] epoch: 3 weights: [[0.63669451]  [0.28052698] [0.05564497]] …… epoch: 16 weights: [[-0.01330549]  [ 0.13052698]  [ 0.20564497]] epoch: 17 weights: [[-0.11330549]  [-0.01947302]  [ 0.10564497]] Finished \\n 因为权值的初始化使用的是随机的初始化方式，所以每一次训练的周期以及画出来的图可能都是不一样的。这里我们可以看到单层感知器的一个问题，虽然单层感知器可以顺利地完成分类任务，但是使用单层感知器来做分类的时候，最后得到的分类边界距离某一个类别比较近，而距离另一个类别比较远，并不是一个特别理想的分类效果。图3.7中的分类效果应该才是比较理想的分类效果，分界线在两个类别比较中间的位置。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 79}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 80 \\n 图3.7 单层感知器比较理想的分类边界  3.8 线性神经网络 3.8.1线性神经网络介绍 线性神经网络跟单层感知器非常类似， 只是把单层感知器的sign激活函数改成了purelin函数： 𝑦=𝑥\\t(3.5) purelin函数也称为线性函数，函数图像如图3.8所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 80}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 81 图3.8 线性函数  3.8.2线性神经网络分类案例 参考“单层感知器案例”， 我们这次使用线性神经网络来完成相同的任务。线性神经网络的程序跟单层感知器的程序非常相似，大家可以思考一下需要修改哪些地方。 大家可以仔细阅读代码3-4，找到修改了的部分。 代码3-4：线性神经网络案例 import numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3],               [1,4,3],               [1,1,1],               [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1],               [1],               [-1],               [-1]])  # 权值初始化，3行1列 # np.random.random可以生成0-1的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0  # 更新一次权值 def train():     # 使用全局变量W     global W     # 同时计算4个数据的预测值     # Y的形状为(4,1)-4行1列     Y = np.dot(X,W) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 81}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 82     # T - Y得到4个的标签值与预测值的误差E。形状为(4,1)     E = T - Y      # X.T表示X的转置矩阵，形状为(3,4)     # 我们一共有4个数据，每个数据3个值。定义第i个数据的第j个特征值为xij     # 如第1个数据，第2个值为x12     # X.T.dot(T - Y)为一个3行1列的数据：     # 第1行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第1个神经元对应的权值     # 第2行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第2个神经元对应的权值     # 第3行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整3个神经元对应的权值     # X.shape表示X的形状X.shape[0]得到X的行数，表示有多少个数据     # X.shape[1]得到列数，表示每个数据有多少个特征值。     # 这里的公式跟书中公式3.2看起来有些不同，原因是这里的计算是矩阵运算，书中公式3.2是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的     delta_W = lr * (X.T.dot(E)) / X.shape[0]  W = W + delta_W # 训练100次 for i in range(100):     #更新一次权值     train()  #————————以下为画图部分————————# # 正样本的xy坐标 x1 = [3,4] y1 = [3,3] # 负样本的xy坐标 x2 = [1,2] y2 = [1,1]  # 计算分类边界线的斜率以及截距 # 神经网络的信号总和为w0×x0+w1×x1+w2×x2 # 当信号总和大于0再进过激活函数，模型的预测值会得到1 # 当信号总和小于0再进过激活函数，模型的预测值会得到-1 # 所以当信号总和w0×x0+w1×x1+w2×x2=0时为分类边界线表达式 # 我们在画图的时候把x1，x2分别看成是平面坐标系中的x和y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d =  -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 82}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 83 # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下： \\n  线性神经网络的程序有两处是对单层感知器程序进行了修改。 第一处是在train()函数中，将Y = np.sign(np.dot(X,W))改成了Y = np.dot(X,W)。因为线性神经网络的激活函数是y=x，所以这里就不需要np.sign()了。 第二处是在for i in range(100)中，把原来的： # 训练100次 for i in range(100):     #更新一次权值     train()     # 打印当前训练次数     print('epoch:',i + 1)     # 打印当前权值     print('weights:',W)     # 计算当前输出      Y = np.sign(np.dot(X,W))      # .all()表示Y中的所有值跟T中所有值都对应相等，结果才为真     if(Y == T).all():          print('Finished')         # 跳出循环         break 改成了： # 训练100次 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 83}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 84 for i in range(100):     #更新一次权值     train() 在单层感知器中，当y等于t时，∆𝑤就会为0，模型训练就结束了，所以可以提前跳出循环。单层感知器使用的模型收敛条件是两次迭代模型的权值已经不再发生变化，则可以认为模型收敛。 而在线性神经网络中，y会一直逼近t的值，不过一般不会得到等于t的值，所以可以对模型不断进行优化。线性神经网络使用的模型收敛条件是设置一个最大迭代次数，当训练了一定次数后就可以认为模型收敛了。 对比单层感知器和线性神经网络所得到的结果，我们可以看得出线性神经网络所得到的结果会比单层感知器得到的结果更理想。但是线性神经网络也还不够优秀，当使用它处理非线性问题的时候，它就不能很好完成工作了。  3.9 线性神经网络处理异或问题 首先我们先来回顾一下异或运算： （1）0与0异或等于0； （2）0与1异或等于1； （3）1与0异或等于1； （4）1与1异或等于0。 线性神经网络-处理异或问题的代码如代码3-5所示。 代码3-5：线性神经网络-处理异或问题 import numpy as np import matplotlib.pyplot as plt ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 84}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 85 # 输入数据 # 4个数据分别对应0与0异或，0与1异或，1与0异或，1与1异或 X = np.array([[1,0,0],               [1,0,1],               [1,1,0],                 [1,1,1]]) # 标签，分别对应4种异或情况的结果 # 注意这里我们使用-1作为负标签 T = np.array([[-1],               [1],               [1],               [-1]])  # 权值初始化，3行1列 # np.random.random可以生成0-1的随机数 W = np.random.random([3,1])  # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0  # 更新一次权值 def train():     # 使用全局变量W     global W     # 计算网络预测值     Y = np.dot(X,W)     # 计算权值的改变     delta_W = lr * (X.T.dot(T - Y)) / X.shape[0] # 更新权值 W = W + delta_W # 训练100次 for i in range(100):     #更新一次权值     train()  #————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1] ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 85}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 86  #计算分界线的斜率以及截距 k = - W[1] / W[2] d = - W[0] / W[2]  # 设定两个点 xdata = (-2,3) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下： \\n  从结果我们能够看出用一条直线并不能把异或问题中的两个类别给划分开来，因为这是一个非线性的问题，可以使用非线性的方式来进行求解。  其中一种方式是我们可以给神经网络加入非线性的输入。 代码3-5中的输入信号只有3个信号x0,x1,x2，我们可以利用这3个信号得到带有非线性特征的输入：x0,x1,x2,x1×x1,x1×x2,x2×x2，其中x1×x1,x1×x2,x2×x2为非线性特征。引入非线性输入的线性神经网络如图3.9所示。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 86}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 87 \\n 图3.9 引入非线性输入的线性神经网络 线性神经网络引入非线性特征解决异或问题的代码如代码3-6所示。 代码3-6：线性神经网络引入非线性特征解决异或问题 import numpy as np import matplotlib.pyplot as plt # 输入数据 # 原来X的3个特征分别为：x0,x1,x2 # X = np.array([[1,0,0], #               [1,0,1], #               [1,1,0],   #               [1,1,1]]) # 给网络输入非线性特征 # 现在X的6个特征分别为：x0,x1,x2,x1×x1,x1×x2,x2×x2 X = np.array([[1,0,0,0,0,0],               [1,0,1,0,0,1],               [1,1,0,1,0,0],               [1,1,1,1,1,1]]) # 标签，分别对应4种异或情况的结果 T = np.array([[-1],               [1],               [1],               [-1]]) # 权值初始化，6行1列 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 87}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 88 # np.random.random可以生成0-1的随机数 W = np.random.random([6,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0  # 更新一次权值 def train():     # 使用全局变量W     global W     # 计算网络预测值     Y = np.dot(X,W)     # 计算权值的改变     delta_W = lr * (X.T.dot(T - Y)) / X.shape[0] # 更新权值 W = W + delta_W # 训练1000次 for i in range(1000):     #更新一次权值     train()  # 计算模型预测结果并打印 Y = np.dot(X,W) print(Y)  #————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1]  # 神经网络信号的总合为：w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2 # 当w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2=0时为分类边界线 # 其中x0为1，我们可以把x1，x2分别看成是平面坐标系中的x和y # 可以得到：w0 + w1x + w2y + w3xx + w4xy + w5yy = 0 # 通分可得：w5y² + (w2+w4x)y + w0 + w1x + w3x² = 0 # 其中 a = w5, b = w2+w4x, c = w0 + w1x + w3x² # 根据一元二次方程的求根公式：ay²+by+c=0，y=[-b±(b^2-4ac)^(1/2)]/2a def calculate(x,root):     # 定义参数     a = W[5] ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 88}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 89     b = W[2] + x * W[4]     c = W[0] + x * W[1] + x * x * W[3]     # 有两个根     if root == 1:         return (- b + np.sqrt(b * b - 4 * a * c)) / (2 * a)     if root == 2:         return (- b - np.sqrt(b * b - 4 * a * c)) / (2 * a)      # 从-1到2之间均匀生成100个点 xdata = np.linspace(-1,2,100) # 使用第一个求根公式计算出来的结果画出第一条红线 plt.plot(xdata,calculate(xdata,1),'r') # 使用第二个求根公式计算出来的结果画出第二条红线 plt.plot(xdata,calculate(xdata,2),'r') # 蓝色点表示正样本 plt.plot(x1,y1,'bo') # 黄色点表示负样本 plt.plot(x2,y2,'yo') # 绘图 plt.show() 运行结果如下： [[-0.98650596]  [ 0.990989  ]  [ 0.990989  ] [-0.99302749]] \\n  从输出的预测值我们可以看出，预测值与真实标签的数值是非常接近的，几乎相等，说明预测值很符合我们想要的结果。而从输出图片中也能观察到两条曲线的内部是负样本所属的类别，两条曲线的外部是正样本所属的类别。这两条曲线很好地把两个类别区分开了。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 89}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 90  线性神经网络可以通过引入非线性的输入特征来解决非线性问题，但这并不是一种非常好的解决方案。 下一章节我们将介绍一种新的神经网络，BP神经网络。 通过学习BP神经网络我们可以获得更好的解决问题的思路。                    ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 90}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 91 第4章-BP神经网络 这一章节可能是本书在数学上最难的一章，详细介绍了BP算法的具体推导流程。BP算法是神经网络深度学习中最重要的算法之一，了解BP算法可以让我们更理解神经网络深度学习模型优化训练的本质，属于内功修行的基础内容。 不过作为初学者我们也要学会量力而行，BP算法的推导对于初学者来说我觉得可以作为选学的知识，也就是可学可不学。如果大家数学基础比较好的话，可以好好看一下本章的推导过程，为后面的学习打好基础。如果数学基础没这么好也没关系，关于BP算法的推导可以先跳过， 我们大概知道它是神经网络深度学习的核心优化算法即可， 并不会影响到我们对后面知识的学习，也不会影响到我们写程序做应用。我们在学习的过程中如果遇到困难，不要被它卡住，可以先暂时放一放，等自身积累足够多之后再回过头来看之前遇到的问题，或许就可以迎刃而解了。  4.1 BP神经网络介绍及发展背景 BP(back propagation)神经网络是1986年由Rumelhart和McClelland为首的科学家提出的概念，他们在《Parallel Distributed Processing》[1]一书中对BP神经网络进行了详细的分析。BP神经网络是一种按照误差逆向传播算法训练的多层前馈神经网络，它是20世纪末期神经网络算法的核心，也是如今深度学习算法的基础。 感知器对人工神经网络的发展发挥了极大的作用， 但是它的结构只有输入层和输出层， 不能解决非线性问题的求解。Minsky和Papert在颇具影响力的《Perceptron》一书中指出，简单的感知器只能求解线性问题， 能够求解非线性问题的网络应该具有隐藏层， 但是对隐藏层', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 91}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 92 神经元的学习规则还没有合理的理论依据。 从前面介绍的感知器学习规则来看， 其权值的调整取决于期望输出与实际输出之差： ∆𝑤(=𝜂(𝑡−𝑦)𝑥((4.1) 但是对于各个隐藏层的节点来说， 不存在已知的期望输出， 因而该学习规则不能用于隐藏层的权值调整。 BP算法的基本思想是，学习过程由信号的正向传播和误差的反向传播两个过程组成。 正向传播时，把样本的特征从输入层进行输入，信号经过各个隐藏层逐层处理后，最后从输出层传出。对于网络的实际输出与期望输出之间的误差，把误差信号从最后一层逐层反传，从而获得各个层的误差学习信号，再根据误差学习信号来修正各个层神经元的权值。 这种信号正向传播与误差反向传播， 然后各个层调整权值的过程是周而复始地进行的。 权值不断调整的过程， 也就是网络学习训练的过程。 进行此过程直到网络输出误差减小到预先设置的阈值以下，或者是超过预先设置的最大训练次数。  4.2 代价函数 代价函数也称为损失函数， 英文称为loss function或cost function， 有些地方我们会看到使用loss表示代价函数的值，有些地方我们会看到用cost表示代价函数的值。为了统一规范，本书中我们统一使用代价函数这个名字，英文使用loss。 代价函数并没有准确的定义， 一般我们可以理解为是一个人为定义的函数， 我们可以利用这个函数来优化模型的参数。最简单常见的一个代价函数是均方差（Mean-Square Error, MSE）代价函数，也称为二次代价函数： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 92}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 93 𝐸=12𝑁(𝑇−𝑌)#=12𝑁?(𝑡(−𝑦()#P(A\"(4.2) 矩阵可以用大写字母来表示，这里的T表示真实标签，Y表示网络输出，i表示第i个数据。N表示训练样本的个数(注意这里的N是一个大于0的整数，不是矩阵) T-Y可以到每个训练样本与真实标签的误差。误差的值有正有负，我们可以求平方，把所有的误差值都变成正的，然后除以2N。这里2没有特别的含义，主要是我们对均方差代价函数求导的时候，公式中的2次方的2可以跟分母中的2约掉，使得公式推导看起来更加整齐简洁。除以N表示求每个样本误差平均的平均值。 公式可以用矩阵形式来表达，也可以拆分为用Σ来累加各个训练样本的真实标签与网络输出的误差的平方。  4.3梯度下降法 4.3.1 梯度下降法（Gradient Descent）介绍 在求解机器学习算法的模型参数时， 梯度下降法是最常用的方法之一。 在学习梯度下降法之前我们先来了解一下导数（Derivative）、偏导数（Partial Derivative）、方向导数（Directional Derivative）和梯度(Gradient)的概念。 导数 —— 导数的概念就如图4.1所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 93}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 94 \\n 图4.1 导数 导数的定义如下： 𝑓R(𝑥<)=limUV→<Δ𝑦Δ𝑥=limUV→<𝑓(𝑥<+Δ𝑥)−𝑓(𝑥<)Δ𝑥(4.3) 𝑓R(𝑥<)表示函数f在x0处的导数 𝛥𝑥表示x的变化量 𝛥𝑦:\\t𝑓(𝑥<+𝛥𝑥)−𝑓(𝑥<)表示函数的增量 𝑙𝑖𝑚^V→<表示𝛥𝑥趋近于0 dx表示x的变化量𝛥𝑥趋近于0 dy表示𝑓R(𝑥<)𝑑𝑥 总的来说𝑓R(𝑥<)反映的是函数𝑦=𝑓(𝑥)在x轴上某一点处沿x轴正方向的变化率/变化趋势。也就是在x轴上的某一点，如果𝑓′(𝑥)＞0，说明𝑓(𝑥)的函数值在x点沿x轴正方向是趋向于增加的；如果𝑓′(𝑥)<0，说明𝑓(𝑥)的函数值在x点沿x轴正方向是趋向于减小的。 偏导数 —— 偏导数的定义如下： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 94}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 95 𝜕𝜕𝑥(𝑓(𝑥<,𝑥\",…,𝑥@)=limUV→<Δ𝑦Δ𝑥=limUV→<𝑓(𝑥<,…,𝑥(+Δ𝑥,…,𝑥@)−𝑓(𝑥<,…,𝑥(,…,𝑥@)Δ𝑥(4.4) 可以看到，导数与偏导数本质是一致的，都是当自变量的变化量趋近于0时，函数值的变化量与自变量变化量比值的极限。直观地说，偏导数也就是函数在某一点上沿坐标轴正方向的的变化率。   区别在于：   导数，指的是一元函数中，函数𝑦=𝑓(𝑥)在某一点处沿x轴正方向的变化率；   偏导数，指的是多元函数中，函数𝑦=𝑓(𝑥<,𝑥\",…,𝑥@)在某一点处沿某一坐标轴(𝑥<,𝑥\",…,𝑥@)正方向的变化率。 方向导数 —— 方向导数的定义如下： 𝜕𝜕𝑙𝑓(𝑥<,𝑥\",…,𝑥@)=limUe→<Δ𝑦Δ𝑥=limUe→<𝑓(𝑥<+Δ𝑥<,…,𝑥(+Δ𝑥(,…,𝑥@+Δ𝑥@)−𝑓(𝑥<,…,𝑥(,…,𝑥@)𝜌(4.5) 其中𝜌=g(Δ𝑥<)#+⋯+(Δ𝑥()#+⋯+(Δ𝑥@)# 𝑙表示某个方向 在前面导数和偏导数的定义中，均是沿坐标轴正方向讨论函数的变化率。那么当我们讨论函数沿任意方向的变化率时，也就引出了方向导数的定义，即：某一点在某一趋近方向上的导数值。  通俗的解释是：  我们不仅要知道函数在坐标轴正方向上的变化率（即偏导数） ，而且还要设法求得函数在其他特定方向上的变化率。而方向导数就是函数在其他特定方向上的变化率。  梯度 —— 梯度的定义如下： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 95}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 96 𝑔𝑟𝑎𝑑𝑓(𝑥<,𝑥\",…,𝑥@)=l𝜕𝑓𝜕𝑥<,…,𝜕𝑓𝜕𝑥(,…,𝜕𝑓𝜕𝑥@m(4.6) 对于𝑓(𝑥<,…,𝑥(,…,𝑥@)上的某一点来说存在很多个方向导数，梯度的方向是函数𝑓(𝑥<,…,𝑥(,…,𝑥@)在某一点增长最快的方向，梯度的模则是该点上方向导数的最大值，梯度的模等于： |𝑔𝑟𝑎𝑑𝑓(𝑥<,𝑥\",…,𝑥@)|=o(𝜕𝑓𝜕𝑥<)#+⋯+l𝜕𝑓𝜕𝑥(m#+⋯+(𝜕𝑓𝜕𝑥@)#(4.7)\\t这里注意三点： 1. 梯度是一个向量，即有方向有大小  2. 梯度的方向是最大方向导数的方向 3. 梯度的值是最大方向导数的值   梯度下降法 —— 既然在变量空间的某一点处， 函数沿梯度方向具有最大的变化率， 那么在优化代价函数的时候，就可以沿着负梯度方向去减小代价函数的值。计算过程可以描述如下： 𝑅𝑒𝑝𝑒𝑎𝑡{ \\t\\t\\t\\t\\t\\t\\t\\t𝑥<=𝑥<−𝜂𝜕𝑓𝜕𝑥<   ……… \\t\\t\\t\\t\\t\\t\\t\\t𝑥(=𝑥(−𝜂𝜕𝑓𝜕𝑥( ……… \\t\\t\\t\\t\\t\\t\\t\\t𝑥@=𝑥@−𝜂𝜕𝑓𝜕𝑥@ } \\t\\t\\t\\t𝑅𝑒𝑝𝑒𝑎𝑡表示不断重复 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 96}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 97 \\t\\t\\t\\t𝑥=𝑥−𝜂uvuV表示参数调整，𝜂表示学习率  4.3.2 梯度下降法（Gradient Descent）二维例子 4.2中我们已经知道了代价函数的定义，代价函数的值越小，说明模型的预测值越接近真实标签的值。代价函数中的预测值y是跟神经网络中的参数w和b相关的。我们可以先考虑一个简单的情况，假如神经网络只有一个参数w，参数w与代价函数loss的关系如图4.2所示。 \\n 图4.2 参数w与代价函数loss的关系图    假设w的初始值是-3，我们需要使用梯度下降法来不断优化w的取值，使得loss值不断减少，首先我们应该先计算w=-3时的梯度，如图4.3所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 97}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 98 \\n 图4.3 w为-3时的梯度 从图4.3中我们可以看出，当w为-3时，w所处位置的梯度应该是一个负数，梯度下降法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个正数，w的值应该变大。根据梯度下降法的优化公式： 𝑤=𝑤−𝜂𝜕𝑓𝜕𝑤(4.8) 学习率𝜂一般是一个大于0的数，uvux为负数，我们可以判断出w的值会变大。变大的数值跟学习率大小𝜂有关，也跟函数f在w处的梯度大小有关。 假设w变大移动到了w=2的位置，我们需要再次计算w=2时的梯度，如图4.4所示。 \\n 图4.4  w为2时的梯度 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 98}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 99 从图4.4中我们可以看出，当w为2时，w所处位置的梯度应该是一个正数，梯度下降法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个负数，w的值应该变小。 学习率𝜂一般是一个大于0的数，uvux为正数，我们可以判断出w的值会变小。变小的数值跟学习率大小𝜂有关，也跟函数f在w处的梯度大小有关。 我们可以发现不管w处于那一个位置，当w向着负梯度的方向进行移动时，实际上就是向着可以使loss值减小的方向进行移动。这就有点类似一个小球在山坡上面，它总是往坡底的方向进行移动， 只不过它每一次是移动一步， 这个步子的大小会受到学习率和所处位置梯度的大小所影响。  4.3.3 梯度下降法（Gradient Descent）三维例子 我们可以再考虑一个稍微复杂一点点的情况，假如神经网络有两个参数w1和w2，参数w1和w2与代价函数loss的关系如图4.5所示。 \\n 图4.5 w1和w2与loss的关系图 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 99}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 100 我们在图中随机选取两个w1和w2的初始值p1和p2，然后从p1,p2这两个初始位置开始使用梯度下降法优化网络参数，得到如图4.6所示的结果。 \\n 图4.6 从p1,p2初始点开始优化网络  图4.6中可以看到网络参数的优化过程其实就是p1,p2两个 “小球“从初始点开始， 每次移动一步，不断向坡底进行移动。在这个过程中整个网络的loss值是在不断变小的。 同时我们还可以观察到一个现象，p1“小球“最后走到了图中的全局最小值（Global Minimum），而p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果， 有些时候我们可以得到loss的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是loss的局部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存在的一个缺点。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 100}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 101 不过大家不用太担心这个问题， 一般实际模型训练的时候局部极小值的情况不常出现。 如果我们担心模型得到的结果是局部极小值的话可以让模型多训练几次， 然后取最好的那一次结果作为模型的最终结果就可以了。  4.4 Delta学习规则 1986年，认知心理学家McClelland和Rumelhart在神经网络训练中引入了𝛿（Delta）规则，该规则也可以称为连续感知器学习规则。 𝛿（Delta）学习规则是一种利用梯度下降法的一般性的学习规则， 其实就是利用梯度下降法来最小化代价函数。比如代价函数为前面公式4.2介绍的均方差代价函数，为了简单我们只计算一个样本的均方差公式， 如果是计算多个样本可以求所有样本代价函数的平均值。 一个样本的均方差公式定义如下：𝐸=\"#(𝑇−𝑌)#=\"#(𝑡−𝑦)#=\"#(𝑡−𝑓(𝑊𝑋))#(4.9) 误差E是W的函数，我们可以使用梯度下降法来最小化E的值，权值矩阵的变化∆W等于负的学习率−𝜂乘以E对W进行求导： ∆𝑊=−𝜂𝐸R=𝜂𝑋~(𝑡−𝑦)𝑓R(𝑊𝑋)=𝜂𝑋~𝛿(4.10) 注意这里的X和W都是矩阵，所以这里求导的时候是对矩阵W进行求导，矩阵求导的方式跟单个元素求导的方式有一些不同。下面公式是单个w元素的权值变化计算： ∆𝑤(=−𝜂𝐸R=𝜂𝑥((𝑡−𝑦)𝑓R(𝑊𝑋)=𝜂𝑥(𝛿(4.11) 这里的𝛿（Delta）符号没有什么特别的含义，就是用来替代(𝑡−𝑦)𝑓R(𝑊𝑋)。∆𝑤(表示第i个权值的变化。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 101}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 102 在上一章节中关于单层感知器的权值变化公式是如何得到的还没有解释，这里我们可以看到当我们使用线性激活函数y=x时，激活函数的导数𝑓R(𝑊𝑋)=1，所以： ∆𝑤(=−𝜂𝐸R=𝜂𝑥((𝑡−𝑦)(4.12) 公式4.12跟感知器的学习规则公式3.2是一样的，所以使用Delta学习规则我们可以推导出感知器的学习规则。  4.5常用激活函数讲解 神经网络的激活函数其实有很多种，在前面的章节中我们介绍过两种激活函数，sign函数和purelin函数。sign函数也称为符号函数，因为sign(x)中x＞0，函数结果为1；sign(x)中x＜0，函数结果为-1。purelin函数也称为线性函数，表达式为y=x。这两种激活函数在处理复杂非线性问题的时候都不能得到很好的结果， 线性函数的分类边界也是线性的， 所以不能区别非线性的复杂边界， 比如一条直线不能区分异或问题的两个类别。 下面我们介绍几个在BP神经网络中常用的非线性激活函数，sigmoid函数，tanh函数，softsign函数和ReLU函数，使用这些非线性激活函数可以帮助我们解决复杂的非线性问题。 4.5.1 sigmoid函数 sigmoid函数 —— sigmoid函数也称为逻辑函数(logical function)，函数的公式为 𝑓(𝑥)=11+𝑒\\x7fV(4.13) 函数图像如图4.7所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 102}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 103 \\n 图4.7 sigmoid函数图像 图中我们可以看出函数的取值范围是0-1之间，当x趋向于-∞的时候函数值趋向于0；当x趋向于+∞的时候函数值趋向于1。  4.5.2tanh函数 tanh函数 —— tanh函数也称为双曲正切函数，函数的公式为 𝑓(𝑥)=𝑒V−𝑒\\x7fV𝑒V+𝑒\\x7fV(4.14) 函数图像如图4.8所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 103}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 104 图4.8 tanh函数图像 图中我们可以看出函数的取值范围是-1-1之间，当x趋向于-∞的时候函数值趋向于-1；当x趋向于+∞的时候函数值趋向于1。 4.5.3 softsign函数 softsign函数 —— softsign函数的公式为： 𝑓(𝑥)=𝑥1+|𝑥|(4.15) 函数图像如图4.9所示。 \\n 图4.9 softsign函数图像 图中我们可以看出函数的取值范围是-1-1之间，当x趋向于-∞的时候函数值趋向于-1；当x趋向于+∞的时候函数值趋向于1。 我们可以通过图4.10对比一下这三种函数的区别。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 104}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 105 \\n 图4.10 三种函数对比 它们这三个激活函数都是S形函数，形状相似，只不过sigmoid函数取值范围是0-1之间，tanh函数和softsign函数取值范围是-1-1之间。我们还可以观察到softsign函数相对于tanh函数而言过渡更加平滑，在x等于0附近函数的数值改变更缓慢。 4.5.4 ReLU函数 该函数最早源自2011年的一篇论文《Deep Sparse Rectifier Neural Networks》[2]。它是模拟生物神经元的激活函数设计出来的一个人工神经网络激活函数。图4.11为生物神经元放电曲线图。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 105}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 106 \\n 图4.11 生物神经元放电曲线图[2] 图4.11中可以看到当输入电压不足时，生物神经元放电为0，电压达到一定的阈值以后生物神经元才会开始放电，并且放电速率跟输入电压成正相关关系。 ReLU函数 —— ReLU(The Rectified Linear Unit)函数的公式为 𝑓(𝑥)=max\\t(0,𝑥)(4.16) 函数图像如图4.12所示。 \\n 图4.12 ReLU函数图像 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 106}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 107 当x小于0时，y等于0。当x大于0时，y等于x。ReLU的中文名称是校正线性单元，虽然在x小于0时函数是线性的，x大于0时函数也是线性的，但是组合起来之后，函数就具有了非线性的特征。这种非线性的特征是怎么体现的呢，我们可以观察下面的一系列图片，首先看到图4.13。 \\n 图4.13 使用tanh作为激活函数的分类边界 图4.13使用的是tanh作为激活函数训练出来的分类模型，其实使用sigmoid或者softsign函数也可以得到类似结果。我使用了带有4个隐藏层的神经网训练了出了这个模型，图中有两个类别的数据，并且我们可以观察到一个类似椭圆形的分类边界把两个类别给区分开了。我们再观察图4.14： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 107}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 108 图4.14 使用ReLu作为激活函数的分类边界 我使用带有4个隐藏层的神经网络训练出了这个模型。我们发现使用ReLU激活函数得到的分类边界跟使用tanh激活函数得到分类边界是差不多的，并不能看出ReLU函数的特点。同样的一个学习任务和数据，我改变了神经网络的层数，只使用2个隐藏层，依然使用ReLU激活函数得到了图4.15所示的结果。 \\n 图4.15 使用ReLU作为激活函数的分类边界 我们观察图4.15可以得到一些结论： （1）我们可以发现ReLU激活函数所描绘出来的边界其实是一条一条的直线构成的，不存在曲线。图4.14中的边界看起来像一个椭圆，实际上它也是由一段一段很小的直线构成的。 （2）神经网络的层数会影响模型的拟合效果，层数越多，模型就可以拟合出更复杂的分类边界。 模型的拟合效果其实还跟其他一些因素相关，比如说每一层隐藏层的神经元越多，那么模型的拟合能力也就越强。模型训练的周期越多，模型的拟合能力就越强。关于模型拟合强弱的问题，再后面的章节中我们还会进一步讨论。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 108}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 109 另外我们再来看一下ReLU应用于回归预测时的特点，我看一下图4.16和图4.17。 \\n 图4.16 使用tanh激活函数训练的回归模型 \\n 图4.17 使用ReLU激活函数训练的回归模型 我们发现了跟分类中类似的情况，tanh激活函数得到的回归线是一条曲线，而ReLU激活函数得到的是由一段一段直线构成的回归线。 大家可以思考一个问题，上面介绍的这几个激活函数，哪一个效果比较好，为什么？这个问题在4.8小节中我们再继续讨论。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 109}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 110 4.6 BP网络模型和公式推导 这一小节我们将学习BP算法的推导流程，如果觉得这个小节内容有一定难度可以直接跳到下一小节进行学习。BP算法其实是在Delta学习规则的基础上做了进一步的推广，Delta是对单层感知器定义了计算流程和代价函数，然后用梯度下降法来最小化代价函数。BP算法是对多层神经网络定义了计算流程和代价函数， 然后再使用梯度下降法来最小化代价函数。 由于BP算法的广泛使用，所以一般的全连接多层神经网络我们也称为BP神经网络。 BP网络中不仅有输入层和输出层，在输入层和输出层中间还可以添加隐藏层。输入层的神经元个数一般跟输入数据相关， 输出层的神经元个数一般跟标签相关， 而网络中间的隐藏层的层数和隐藏层神经元的个数都是超参数。 也就是说隐藏层的层数以及隐藏层每一层的神经元个数我们都可以随意设置，主要靠经验和实验来决定。通常来说隐藏层的层数越多，隐藏层每一层神经元个数越多，这个神经网络结构就越复杂，越能拟合复杂的函数曲线，处理复杂的分类回归问题。反之，隐藏层层数越少，隐藏层每一层神经元个数越少，网络结构就越简单，它所能够拟合的函数曲线就越简单，比较适合处理简单的分类回归问题。 网络的结构不是越复杂越好， 也不是越简单越好。 网络的结构复杂度需要跟我们要解决的问题相关，如果问题越复杂，那么网络结构就要越复杂；如果问题简单，那么就要用结构简单的网络来建模。如果网络结构的复杂度跟要解决的问题不匹配的话就会出现欠拟合（Under-Fitting）或者过拟合 （Over-Fitting）。 什么是欠拟合 （Under-Fitting） 和过拟合 （Over-Fitting），在后面的章节中再详细介绍。 总之一个好的网络结构是需要很多的经验加大量的实验才能获得。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 110}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 111 4.6.1 BP网络模型[3] 假设我们有一个2层（统计神经网络层数的时候一般输入层忽略不计）的神经网络如图4.18所示。 \\n 图4.18 BP神经网络 该网络的输入向量为𝑋=(𝑥\",𝑥#,…,𝑥(,…,𝑥@)，图中𝑥<=1表示输入层偏置值。隐藏层输出向量为𝑌\"=(𝑦\"\",𝑦#\",…,𝑦\\x81\",…,𝑦\\x82\")，图中𝑦<\"=1表示隐藏层偏置值。输出层输出向量为𝑌#=(𝑦\"#,𝑦##,…,𝑦\\x83#,…,𝑦\\x84#)。期望输出𝑇=(𝑡\",𝑡#,…,𝑡\\x83,…,𝑡\\x84)。输入层到隐藏层之间的权值用矩阵𝑊\"表示，𝑤(\\x81\"表示𝑊\"矩阵中第i行第j列的权值。隐藏层到输出层之间的权值用矩阵𝑊#表示，𝑤\\x81\\x83#表示𝑊#矩阵中第j行第k列的权值。另外我们定义𝑛𝑒𝑡\"为隐藏层中权值𝑊\"乘以输入层信号𝑋的总和，𝑛𝑒𝑡\\x81\"表示隐藏层中第j个神经元得到的输入信号总和。𝑛𝑒𝑡#为输出层中权值𝑊#乘以隐藏层信号𝑌\"的总和，𝑛𝑒𝑡\\x83#表示输出层中第k个神经元得到的输入信号总和。 对于隐藏层有： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 111}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 112 𝑛𝑒𝑡\\x81\"=?𝑤(\\x81\"𝑥(\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗=1,2,…,𝑚@(A<(4.17) 𝑦\\x81\"=𝑓(𝑛𝑒𝑡\\x81\")\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗=1,2,…,𝑚(4.18) 对于输出层有： 𝑛𝑒𝑡\\x83#=?𝑤\\x81\\x83#𝑦\\x81\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘=1,2,…,𝑙\\x82\\x81A<(4.19) 𝑦\\x83#=𝑓(𝑛𝑒𝑡\\x83#)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘=1,2,…,𝑙(4.20) 公式4.18和4.20中的激活函数假设我们都使用sigmoid函数，sigmoid函数的公式在上文中的公式4.13。sigmoid函数具有连续、可导的特点，它的导数为： 𝑓′(𝑥)=𝑓(𝑥)[1−𝑓(𝑥)](4.21)  4.6.2 BP算法推导 根据上文中提到的代价函数，当网络输出与期望输出不同时，会存在输出误差E，为了简单我们只计算一个样本的均方差公式， 如果是计算多个样本可以求所有样本代价函数的平均值。一个样本的均方差公式定义如下： 𝐸=12(𝑇−𝑌#)#=12?(𝑡\\x83−𝑦\\x83#)#\\x84\\x83A\"(4.22) 将以上误差定义式展开至隐藏层： 𝐸=12?[𝑡\\x83−𝑓(𝑛𝑒𝑡\\x83#)\\t]#\\x84\\x83A\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=12?\\x8a𝑡\\x83−𝑓\\x8b?𝑤\\x81\\x83#𝑦\\x81\"\\x82\\x81A<\\x8c\\t\\x8d#\\x84\\x83A\"(4.23) 再进一步展开至输入层： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 112}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 113 𝐸=12?\\x8a𝑡\\x83−𝑓\\x8b?𝑤\\x81\\x83#𝑓\\x8e𝑛𝑒𝑡\\x81\"\\x8f\\t\\x82\\x81A<\\x8c\\t\\x8d#\\x84\\x83A\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=12?\\x8a𝑡\\x83−𝑓\\x8b?𝑤\\x81\\x83#𝑓>?𝑤(\\x81\"𝑥(@(A<B\\t\\x82\\x81A<\\x8c\\t\\x8d#\\x84\\x83A\"(4.24) 从公式4.23和4.24中可以看出，网络的误差E是跟神经网络各层权值𝑤(\\x81\"和𝑤\\x81\\x83#相关的，因此调整各层的权值，就可以改变误差E的值。我们的目标就是要得到比较小的误差值，所以我们可以采用梯度下降法来最小化误差E的值。根据梯度下降法，我们可以得到： ∆𝑤(\\x81\"=−𝜂𝜕𝐸𝜕𝑤(\\x81\"\\t\\t\\t\\t\\t\\t\\t\\t𝑖=0,1,2,…,𝑛;𝑗=1,2,…,𝑚(4.25) ∆𝑤\\x81\\x83#=−𝜂𝜕𝐸𝜕𝑤\\x81\\x83#\\t\\t\\t\\t\\t\\t\\t\\t𝑗=0,1,2,…,𝑚;𝑘=1,2,…,𝑙(4.26) 在下面的推导过程中均默认对于隐藏层有：𝑖=0,1,2,…,𝑛;𝑗=1,2,…,𝑚；对于输出层有：𝑗=0,1,2,…,𝑚;𝑘=1,2,…,𝑙。 根据微积分的链式法则可以得到，对于隐藏层有： ∆𝑤(\\x81\"=−𝜂𝜕𝐸𝜕𝑤(\\x81\"=−𝜂𝜕𝐸𝜕𝑛𝑒𝑡\\x81\"𝜕𝑛𝑒𝑡\\x81\"𝜕𝑤(\\x81\"(4.27) 根据微积分的链式法则可以得到，对于输出层有： ∆𝑤\\x81\\x83#=−𝜂𝜕𝐸𝜕𝑤\\x81\\x83#=−𝜂𝜕𝐸𝜕𝑛𝑒𝑡\\x83#𝜕𝑛𝑒𝑡\\x83#𝜕𝑤\\x81\\x83#(4.28) 我们可以定义一个误差信号，命名为𝛿（Delta），令： δ\\x81\"=−𝜕𝐸𝜕𝑛𝑒𝑡\\x81\"(4.29) δ\\x83#=−𝜕𝐸𝜕𝑛𝑒𝑡\\x83#(4.30) 综合公式4.17,4.27,4.29，可以得到输入层到隐藏层的权值调整公式为： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 113}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 114 ∆𝑤(\\x81\"=𝜂δ\\x81\"𝑥((4.31) 综合公式4.19,4.28,4.30，可以得到隐藏层到输出层的权值调整公式为： ∆𝑤\\x81\\x83#=𝜂δ\\x83#𝑦\\x81\"(4.32) 可以看出在公式4.31和4.32中，只要求出δ\\x81\"和δ\\x83#的值，就可以计算出∆𝑤(\\x81\"和∆𝑤\\x81\\x83#的值了。 对于隐藏层，δ\\x81\"可以展开为： δ\\x81\"=−𝜕𝐸𝜕𝑛𝑒𝑡\\x81\"=−𝜕𝐸𝜕𝑦\\x81\"𝜕𝑦\\x81\"𝜕𝑛𝑒𝑡\\x81\"=−𝜕𝐸𝜕𝑦\\x81\"𝑓R\\x8e𝑛𝑒𝑡\\x81\"\\x8f(4.33)  对于输出层，δ\\x83#可以展开为： δ\\x83#=−𝜕𝐸𝜕𝑛𝑒𝑡\\x83#=−𝜕𝐸𝜕𝑦\\x83#𝜕𝑦\\x83#𝜕𝑛𝑒𝑡\\x83#=−𝜕𝐸𝜕𝑦\\x83#𝑓R(𝑛𝑒𝑡\\x83#)(4.34) 在公式4.33和4.34中，求网络误差对各层输出的偏导，对于输出层： 𝜕𝐸𝜕𝑦\\x83#=−(𝑡\\x83−𝑦\\x83#)(4.35) 对于隐藏层： 𝜕𝐸𝜕𝑦\\x81\"=𝜕12∑\\x92𝑡\\x83−𝑓\\x8e∑𝑤\\x81\\x83#𝑦\\x81\"\\x82\\x81A<\\x8f\\t\\x93#\\x84\\x83A\"𝜕𝑦\\x81\"=−?\\x94𝑡\\x83−𝑓\\x8b?𝑤\\x81\\x83#𝑦\\x81\"\\x82\\x81A<\\x8c\\x95𝑓R\\x8b?𝑤\\x81\\x83#𝑦\\x81\"\\x82\\x81A<\\x8c\\x84\\x83A\"𝑤\\x81\\x83#=−?(𝑡\\x83−𝑦\\x83#)𝑓R(𝑛𝑒𝑡\\x83#)\\x84\\x83A\"𝑤\\x81\\x83#(4.36) 将式（4.35）带入式（4.34） ，再根据sigmoid函数的求导式（4.21） ，可以得到： δ\\x83#=−𝜕𝐸𝜕𝑦\\x83#𝑓R(𝑛𝑒𝑡\\x83#)=(𝑡\\x83−𝑦\\x83#)𝑦\\x83#(1−𝑦\\x83#)(4.37) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 114}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 115 δ\\x81\"=−𝜕𝐸𝜕𝑦\\x81\"𝑓R\\x8e𝑛𝑒𝑡\\x81\"\\x8f=>?(𝑡\\x83−𝑦\\x83#)𝑓R(𝑛𝑒𝑡\\x83#)\\x84\\x83A\"𝑤\\x81\\x83#B𝑓R\\x8e𝑛𝑒𝑡\\x81\"\\x8f=>?(𝑡\\x83−𝑦\\x83#)𝑦\\x83#(1−𝑦\\x83#)\\x84\\x83A\"𝑤\\x81\\x83#B𝑓R\\x8e𝑛𝑒𝑡\\x81\"\\x8f=>?δ\\x83#\\x84\\x83A\"𝑤\\x81\\x83#B𝑦\\x81\"\\x8e1−𝑦\\x81\"\\x8f(4.38) 将公式4.37带入4.32中，得到隐藏层到输出层权值调整： ∆𝑤\\x81\\x83#=𝜂δ\\x83#𝑦\\x81\"=𝜂(𝑡\\x83−𝑦\\x83#)𝑦\\x83#(1−𝑦\\x83#)𝑦\\x81\"(4.39) 将公式4.38带入4.31中，得到输入层到隐藏层权值调整： ∆𝑤(\\x81\"=𝜂δ\\x81\"𝑥(=𝜂>?δ\\x83#\\x84\\x83A\"𝑤\\x81\\x83#B𝑦\\x81\"\\x8e1−𝑦\\x81\"\\x8f𝑥((4.40) 对于一个多层的神经网络，假设一共有h个隐藏层，按顺序将各隐藏层节点数分别记为：𝑚\",𝑚#,…,𝑚\\x96，输入神经元个数为n，输出神经元个数为𝑙；各隐藏层输出分别记为：𝑌\",𝑌#,…,𝑌\\x96，输入层的输入记为：𝑋，输出层的输出记为：𝑌\\x96\\x97\"；各层权值矩阵分别记为：𝑊\",𝑊#,…,𝑊\\x96\\x97\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，𝑊\\x96\\x97\"表示最后一个隐藏层到输出层的权值矩阵；各层学习信号分别记为：𝜹\",𝜹#,…,𝜹\\x96\\x97\"，𝜹\\x96\\x97\"表示输出层计算出的学习信号；则各层权值调整计算公式为： 对于输出层： ∆𝑤\\x81\\x83\\x99\\x97\"=𝜂δ\\x83\\x96\\x97\"𝑦\\x81\\x96=𝜂\\x8e𝑡\\x83−𝑦\\x83\\x96\\x97\"\\x8f𝑦\\x83\\x96\\x97\"\\x8e1−𝑦\\x83\\x96\\x97\"\\x8f𝑦\\x81\\x96(4.41)𝑗=0,1,2,…,𝑚\\x96;𝑘=1,2,…,𝑙\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t 对于第h隐藏层： ∆𝑤(\\x81\\x99=𝜂δ\\x81\\x96𝑦(\\x96\\x7f\"=𝜂>?δ\\x83\\x96\\x97\"\\x84\\x83A\"𝑤\\x81\\x83\\x96\\x97\"B𝑦\\x81\\x96\\x8e1−𝑦\\x81\\x96\\x8f𝑦(\\x96\\x7f\"(4.42)𝑖=0,1,2,…,𝑚\\x96\\x7f\";𝑗=1,2,…,𝑚\\x96\\t\\t\\t\\t\\t 按照以上规律逐层类推，则第一个隐藏层的权值调整公式为： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 115}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 116 ∆𝑤\\x9a\\x9b\"=𝜂δ\\x9b\"𝑥\\x9a=𝜂\\x8b?δ\\x9c#\\x82\\x9d\\x9cA\"𝑤\\x9b\\x9c#\\x8c𝑦\\x9b\"\\x8e1−𝑦\\x9b\"\\x8f𝑥\\x9a(4.43)𝑝=0,1,2,…,n;𝑞=1,2,…,𝑚\"\\t\\t\\t\\t\\t\\t\\t\\t\\t 4.6.3 BP算法推导的补充说明 我们已经从头到尾详细推导了一遍BP算法的整个流程，在这一小节中对BP算法再做两点补充说明。 1.网络的偏置值 在上文中我们的推导过程一直是使用权值w来进行计算的， 如果我们把偏置值独立出来，那么偏置值的参数应该怎么调整呢？ 我们可以看到公式4.31以及4.32，在公式4.31中，把i的取值设置为0，并且我们知道𝑥<=1，所以我们可以得到： ∆𝑏\\x81\"=𝜂δ\\x81\"(4.44) 在公式4.31中，把j的取值设置为0，并且我们知道𝑦<=1，所以我们可以得到： ∆𝑏\\x83#=𝜂δ\\x83#(4.45) 如果是把偏置值单独拿出来计算的话就是公式4.44和4.45的表达式。 2.用矩阵形式来表达BP学习算法 下面我们直接给出BP学习算法矩阵表达形式的结果，具体推导过程跟上文中的推导过程类似，不过会涉及到矩阵求导的相关知识，大家有兴趣的话可以自己推导一下。如果是把BP学习算法写成矩阵的形式来表达，假设一共有h个隐藏层。输入数据的矩阵为𝑋，𝑋中的每一行表示一个数据，列表示数据的特征。比如我们一次性输入3个数据，每个数据有4个特征，那么𝑋就是一个3行4列的矩阵。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 116}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 117 各隐藏层输出分别记为：𝑌\",𝑌#,…,𝑌\\x96，输出层的输出记为：𝑌\\x96\\x97\"。𝑌中的每一个行表示一个数据的标签。比如我们有3个数据，每个数据有1个标签，那么𝑌就是一个3行1列的矩阵。 各层权值矩阵分别记为：𝑊\",𝑊#,…,𝑊\\x96\\x97\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，𝑊\\x96\\x97\"表示最后一个隐藏层到输出层的权值矩阵。权值矩阵的行等于前一层的神经元个数，权值矩阵的列对应于后一层的神经元个数。比如在输入层和第一个隐藏层之间的权值矩阵是𝑊\"，输入层有3个神经元，第一个隐藏层有10个神经元，那么𝑊\"就是一个3行10列的矩阵。 各层学习信号分别记为：𝜹\",𝜹#,…,𝜹\\x96\\x97\"，𝜹\\x96\\x97\"表示输出层计算出的学习信号。 对于输出层的学习信号𝜹\\x96\\x97\"： 𝛅\\x96\\x97\"=(𝑇−𝑌ℎ+1)∘𝑓R(𝑌ℎ𝑊ℎ+1)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=(𝑇−𝑌ℎ+1)∘𝑌ℎ+1∘(1−𝑌ℎ+1)(4.46) 公式4.46中的\"∘\"符号是element-wise multiplication，意思是矩阵中的元素对应相乘。例如下面的例子： >𝑎\"\"𝑎\"#𝑎\"$𝑎#\"𝑎##𝑎#$𝑎$\"𝑎$#𝑎$$B∘>𝑏\"\"𝑏\"#𝑏\"$𝑏#\"𝑏##𝑏#$𝑏$\"𝑏$#𝑏$$B=>𝑎\"\"𝑏\"\"𝑎\"#𝑏\"#𝑎\"$𝑏\"$𝑎#\"𝑏#\"𝑎##𝑏##𝑎#$𝑏#$𝑎$\"𝑏$\"𝑎$#𝑏$#𝑎$$𝑏$$B 对于第h隐藏层的学习信号𝜹\\x96： 𝛅\\x96=𝛅\\x96\\x97\"(𝑊\\x96\\x97\")~∘𝑓R(𝑌ℎ−1𝑊ℎ)\\t\\t\\t\\t\\t\\t\\t\\t\\t=𝛅\\x96\\x97\"(𝑊\\x96\\x97\")~∘𝑌ℎ∘(1−𝑌ℎ)(4.47) 对于第1隐藏层的学习信号𝜹\"： 𝛅\"=𝛅#(𝑊#)~∘𝑓R(𝑋𝑊1)\\t\\t\\t\\t\\t\\t\\t\\t\\t=𝛅#(𝑊#)~∘𝑌1∘(1−𝑌1)(4.48) 对于输出层的权值矩阵𝑊\\x96\\x97\"： ∆𝑊ℎ+1=𝜂(𝑌ℎ)~𝛅\\x96\\x97\"(4.49) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 117}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 118 对于第h隐藏层权值矩阵𝑊\\x96： ∆𝑊ℎ=𝜂(𝑌ℎ−1)~𝛅\\x96(4.50) 对于第1隐藏层权值矩阵𝑊\"： ∆𝑊1=𝜂(𝑋)~𝛅\"(4.51)  4.7 BP算法推导结论总结 上一小节我们推导了BP算法的公式，可能部分同学暂时先跳过了详细推导的部分。如果推导过程看起来有点复杂， 我们只看最后推导得到的结论即可。 最后推导的结论也就是权值调整的公式为： ∆𝑊ℎ=𝜂(𝑌ℎ−1)~𝛅\\x96(4.52) 这里的∆𝑊\\x96表示第h层权值矩阵W的变化，𝜂表示学习率，𝑌\\x96\\x7f\"表示网络第h-1层的输出，𝜹\\x96表示第h层的学习信号。 𝜂学习率是为人设置的超参数，𝑌\\x96\\x7f\"网络第h-1层的输出只要把数据传入网络中就可以计算出来， 所以这里要重点关注的是第h层的学习信号𝜹\\x96。 学习信号有两个不同的公式， 输出层的学习信号公式为： 𝛅\\x96\\x97\"=(𝑇−𝑌ℎ+1)∘𝑓R(𝑌ℎ𝑊ℎ+1)(4.53)  这里的𝜹\\x96\\x97\"表示输出层的学习信号，T表示数据的标签值，𝑌\\x96\\x97\"表示模型的预测值，𝑓R表示激活函数的导数，𝑌\\x96𝑊\\x96\\x97\"表示输出层信号的汇总。  T是已知的数据标签，Y\\x99\\x97\"可以传入数据计算得到，激活函数确定以后𝑓R也是已知的，𝑌\\x96传入数据可以计算得到，𝑊\\x96\\x97\"在网络进行随机初始化以后也确定下来了。所以这个公式里面', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 118}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 119 的所有值都是已知的，或者可以计算得到，把𝜹\\x96\\x97\"计算出来以后再带入到4.52的公式中就可以计算出输出层的权值矩阵要怎么要调整了。  除了输出层以外，剩下的网络层的学习信号的公式都是： 𝛅\\x96=𝛅\\x96\\x97\"(𝑊\\x96\\x97\")~∘𝑓R(𝑌ℎ−1𝑊ℎ)(4.54) 从这个公式我们可以看到，第h层的学习信号𝜹\\x96，跟它的下一层h+1层的学习信号𝜹\\x96\\x97\"有关系， 还跟它的下一层h+1层的权值矩阵的转置(𝑊\\x96\\x97\")~有关系， 以及跟𝑓R(𝑌\\x96\\x7f\"𝑊\\x96)相关。 所以我们在使用BP算法的时候需要先根据网络预测的误差计算最后一层的学习信号，然后再计算倒数第二层的学习信号， 然后再计算倒数第三层的学习信号以此类推， 从后向前计算，因此BP算法叫做误差反向传播算法。计算得到每一层的学习信号以后再根据公式4.52来计算每一层的权值矩阵如何调整，最后对所有层的权值矩阵进行更新。  4.8 梯度消失与梯度爆炸 前面给大家留了一个思考题， 在我们介绍的几种激活函数中， 哪种激活函数的效果是最好的。其实这个问题的答案很简单，在介绍它们的时候，一般排在越后面的说明效果就越好，所以ReLU是最好的。开个玩笑，下面我们来具体分析一下这几个激活函数的不同效果。 4.8.1 梯度消失 根据上文BP算法中的推导，我们从公式4.49,,4.50,4.51中可以知道，权值的调整∆𝑊是跟学习信号𝛿相关的。同时我们从4.46,4.47,4.48中可以知道在学习信号𝛿表达式中存在𝑓R(𝑥)。也就是说激活函数的导数会影响学习信号𝛿的值，而学习信号𝛿的值会影响权值调整', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 119}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 120 ∆𝑊的值。那么激活函数的值越大，∆𝑊的值就越大；激活函数的值越小，∆𝑊的值也就越小。 假设激活函数为sigmoid函数， 前文中我们已经知道了sigmoid函数的表达式为：𝑓(𝑥)=\"\"\\x97¤¥¦，sigmoid函数的导数为：𝑓′(𝑥)=𝑓(𝑥)[1−𝑓(𝑥)]，我们可以画出sigmoid函数的导数图像如图4.19所示。 \\n 图4.19 sigmoid函数导数 这里我们发现当x=0时，sigmoid函数导数可以取得最大值0.25。x取值较大或较小时，sigmoid函数的导数很快就趋向于0。不管怎么样，sigmoid函数的导数都是一个小于1的数， 学习信号𝛿乘以一个小于1的数， 那么𝛿就会减小。 学习信号从输出层一层一层向前反向传播的时候，每传播一层学习信号就会变小一点，经过多层传播后，学习信号就会接近于0，从而使得权值∆𝑊调整接近于0。∆𝑊接近于0那就意味着该层的参数不会发生改变， 不能进行优化。参数不能优化，那整个网络就不能再进行学习了。学习信号随着网络传播逐渐减小的问题也被称为梯度消失（Vanishing Gradient）的问题。 我们再考虑一下tanh函数的导数，tanh函数的表达式为：𝑓(𝑥)=¤¦\\x7f¤¥¦¤¦\\x97¤¥¦，tanh函数的导数为：𝑓R(𝑥)=1−\\x8e𝑓(𝑥)\\x8f#，tanh函数的导数如图4.20所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 120}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 121 \\n 图4.20 tanh函数导数 tanh函数导数图像看起来比sigmoid函数要好一些，x=0时，tanh函数导数可以取得最大值1。x取值较大或较小时，tanh函数的导数很快就趋向于0。不管怎么样，tanh函数导数的取值总是小于等于1的，所以tanh作为激活函数也会存在梯度消失的问题。 对于softsign函数，softsign函数的表达式为：𝑓(𝑥)=V\"\\x97|V|，softsign函数的导数为：𝑓R(𝑥)=\"(\"\\x97|V|)\\x9d，softsign函数的导数如图4.21所示。 \\n 图4.21 softsign函数导数 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 121}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 122 softsign函数x=0时，softsign函数导数可以取得最大值1。x取值较大或较小时，softsign函数的导数很快就趋向于0。不管怎么样，softsign函数导数的取值总是小于等于1的，所以softsign作为激活函数也会存在梯度消失的问题。 4.8.2 梯度爆炸 当我们使用sigmoid,tanh和softsign作为激活函数时， 它们的导数取值范围都是小于等于1的， 所以会产生梯度消失的问题。 那么我们可能会想到， 如果使用导数大于1的函数作为激活函数，情况会如何？ 如果学习信号𝛿乘以一个大于1的数，那么δ就会变大。学习信号从输出层一层一层向前反向传播的时候，每传播一层学习信号就会变大一点，经过多层传播后，学习信号就会接近于无穷大， 从而使得权值∆𝑊调整接近于无穷大。∆𝑊接近于无穷大那就意味着该层的参数， 处于一种极不稳定的状态， 那么网络就不能正常工作了。 学习信号随着网络传播逐渐增大的问题也被称为梯度爆炸（Exploding Gradient）的问题。 既然激活函数的导数不能小于1也不能大于1，我们可能会想到，能不能使用线性函数y=x，这个函数的导数是1。它既不会梯度消失，也不会梯度爆炸。确实如此，线性函数导数为1的特性是很好，但是，它是一个线性函数，也就是说，它不能处理非线性问题，比如异或分类问题，它就无法解决。而在实际应用中，非常多的应用都是属于非线性问题，所以使用线性函数来作为激活函数存在很大的局限性，所以也不适合。 4.8.3 使用ReLU函数解决梯度消失和梯度爆炸的问题 我们知道ReLU的表达式为：𝑓(𝑥)=𝑚𝑎𝑥\\t(0,𝑥)。当x小于0时，𝑓(𝑥)的取值为0；当x大于0时，𝑓(𝑥)的取值等于x。ReLU函数的导数如图4.22所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 122}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 123 \\n 图4.22 ReLU函数导数 前面我们讨论了当激活函数的导数小于1时，网络会产生梯度消失，激活函数的导数大于1时，网络会产生梯度爆炸。那么当我们使用ReLU作为激活函数的时候，x小于0时，ReLU的导数为0；x大于0时，ReLU的导数为1。导数为1是一个很好的特性，不会使得学习信号越来越小，也不会让学习信号越来越大，可以让学习信号比较稳定地从后向前传播。解决了梯度消失和梯度爆炸的问题，同时计算方便，可以加速网络的训练。 ReLU函数还有一个优点，它是一个非线性的激活函数，可以用来处理非线性问题，它的非线性特性在4.5小节中已经介绍过。 认真思考的同学这个时候可能会发现，ReLU函数看起来是挺好的，既是非线性函数，导数又为1，但是它好像也存在一些问题，当x小于0时，ReLU函数输出为0，导数也为0，有些信号不就丢失掉了吗？ 如果你是这么想的，那你就想对了，确实是丢失了一些信号，但是没关系。在神经网络中，信号是冗余的，也就是说其实网络最后在做预测的时候并不需要从前面传过来的所有的信号，实际上只需要一部分的信号，网络就可以进行预测。并且使用部分信号来进行预测与使用全部信号来进行预测得到的结果相差不大。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 123}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 124 比如我们把网络中输出为0的神经元看成是不工作的神经元， 那么使用ReLU函数以后会产生大量不工作的神经元。 网络中存在不工作的神经元， 我们可以称这个网络具有一定的稀疏性（Sparsity）。不工作的神经元越多，网络就越稀疏。使得网络产生稀疏性的方式很多，除了使用ReLU激活函数以外，还可以使用L1正则化（L1 Regularization）和Dropout，这两个技术在后面的章节中会有详细介绍。 所以使得神经网络变稀疏并不是什么稀奇的事， 也不一定是坏事。 稀疏性这一特性也存在于生物体内的神经网络中，大脑中神经网络的稀疏性高达95%-99%， 也就是说在同一时刻其实大脑中大部分的神经元都是不工作。 人工神经网络中比较常见的网络稀疏性是50%-80%。  4.9 使用BP神经网络解决异或问题 BP神经网络解决异或问题的代码如代码4-1所示。 代码4-1：BP神经网络解决异或问题 import numpy as np import matplotlib.pyplot as plt  # 输入数据 X = np.array([[0,0],               [0,1],               [1,0],               [1,1]]) # 标签 T = np.array([[0],               [1],               [1],               [0]])  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 124}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 125 # 定义一个2层的神经网络：2-10-1 # 输入层2个神经元，隐藏层10个神经元，输出层1个神经元 # 输入层到隐藏层的权值初始化，2行10列 W1 = np.random.random([2,10]) # 隐藏层到输出层的权值初始化，10行1列 W2 = np.random.random([10,1]) # 初始化偏置值，偏置值的初始化一般可以取0，或者一个比较小的常数，如0.1 # 隐藏层的10个神经元偏置 b1 = np.zeros([10]) # 输出层的1个神经元偏置 b2 = np.zeros([1]) # 学习率设置 lr = 0.1 # 定义训练周期数 epochs = 100001 # 定义测试周期数 test = 5000  # 定义sigmoid函数 def sigmoid(x):     return 1/(1+np.exp(-x))  # 定义sigmoid函数导数 def dsigmoid(x):     return x*(1-x)  # 更新权值和偏置值 def update():     global X,T,W1,W2,lr,b1,b2          # 隐藏层输出     L1 = sigmoid(np.dot(X,W1) + b1)     # 输出层输出     L2 = sigmoid(np.dot(L1,W2) + b2)          # 求输出层的学习信号     delta_L2 = (T - L2) * dsigmoid(L2)     # 隐藏层的学习信号     delta_L1 = delta_L2.dot(W2.T) * dsigmoid(L1)          # 求隐藏层到输出层的权值改变     # 由于一次计算了多个样本，所以需要求平均     delta_W2 = lr * L1.T.dot(delta_L2) / X.shape[0]     # 输入层到隐藏层的权值改变 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 125}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 126     # 由于一次计算了多个样本，所以需要求平均     delta_W1 = lr * X.T.dot(delta_L1) / X.shape[0]          # 更新权值     W2 = W2 + delta_W2     W1 = W1 + delta_W1          # 改变偏置值     # 由于一次计算了多个样本，所以需要求平均     b2 = b2 + lr * np.mean(delta_L2, axis=0)     b1 = b1 + lr * np.mean(delta_L1, axis=0)  # 定义空list用于保存loss loss = [] # 训练模型 for i in range(epochs):     # 更新权值     update()     # 每训练5000次计算一次loss值     if i % test == 0:         # 隐藏层输出         L1 = sigmoid(np.dot(X,W1) + b1)         # 输出层输出         L2 = sigmoid(np.dot(L1,W2) + b2)         # 计算loss值         print('epochs:',i,'loss:',np.mean(np.square(T - L2) / 2))         # 保存loss值         loss.append(np.mean(np.square(T - L2) / 2))  # 画图训练周期数与loss的关系图 plt.plot(range(0,epochs,test),loss) plt.xlabel('epochs') plt.ylabel('loss') plt.show()          # 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2) print('output:') print(L2)  # 因为最终的分类只有0和1，所以我们可以把 # 大于等于0.5的值归为1类，小于0.5的值归为0类 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 126}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 127 def predict(x):     if x>=0.5:         return 1     else:         return 0  # map会根据提供的函数对指定序列做映射 # 相当于依次把L2中的值放到predict函数中计算 # 然后打印出结果 print('predict:') for i in map(predict,L2):     print(i) 运行结果如下： epochs: 0 loss: 0.2382731940835196 epochs: 5000 loss: 0.1206923173399693 epochs: 10000 loss: 0.0790971946756123 epochs: 15000 loss: 0.02378338344093093 epochs: 20000 loss: 0.008377749771590743 epochs: 25000 loss: 0.004291050338268038 epochs: 30000 loss: 0.002694668764968099 epochs: 35000 loss: 0.0018982939821333231 epochs: 40000 loss: 0.0014365256397058071 epochs: 45000 loss: 0.001140826866565359 epochs: 50000 loss: 0.0009377943334308873 epochs: 55000 loss: 0.0007910315050028132 epochs: 60000 loss: 0.000680683460806228 epochs: 65000 loss: 0.0005950985467089836 epochs: 70000 loss: 0.0005270339320851203 epochs: 75000 loss: 0.00047177302525578296 epochs: 80000 loss: 0.0004261243077828677 epochs: 85000 loss: 0.00038785770517095713 epochs: 90000 loss: 0.0003553718177062329 epochs: 95000 loss: 0.0003274893656556488 epochs: 100000 loss: 0.00030332701795183955 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 127}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 128 \\n output: [[0.02462022]  [0.97697496]  [0.97534433] [0.02612291]] predict: 0 1 1 0  4.10 分类模型评估方法 4.10.1 准确率/精确率/召回率/F1值 机器学习中有很多分类模型评估指标，比如准确率（Accuracy），精确率（查准率，Precision）和召回率（查全率，Recall）都是比较常见的。 我们先来说一下准确率， 准确也是我们日常生活中用得较多的一个判断指标， 准确率的计算很简单，准确率=所有预测正确的结果除以所有结果。比如一个模型要识别5张图片，最后识别正确4张图片，错了1张，那么准确率就是4/5=80%。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 128}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 129 倘若某人声称创建了一个能够识别登上飞机的恐怖分子的模型， 并且准确率 （accuracy）高达 99%。这能算是个好模型吗？已知美国全年平均有 8 亿人次的乘客，并且在 2000-2017 年间共发现了 19 名恐怖分子。 如果有一个模型将从美国机场起飞的所有乘客都标注为非恐怖分子，那么这个模型达到了接近完美的准确率——99.99999%。这听起来确实令人印象深刻，但是美国国土安全局肯定不会购买这个模型。尽管这个模型拥有接近完美的准确率，但是在这个问题中准确率显然不是一个合适的度量指标。 恐怖分子检测是一个不平衡的分类问题： 我们需要鉴别的类别有两个， 恐怖分子和非恐怖分子，其中一个类别代表了极大多数的数据，而另一个类别数据却很少。比如我们把恐怖分子定义为正例， 非恐怖分子定义为负例， 那么正例类别——恐怖分子， 远远少于负例类别——非恐怖分子的数量。 这种数据不均衡的问题是数据科学中比较常见的， 在数据不均衡的情况下使用准确率并不是评估模型性能的很好的衡量标准。当然，如果是数据比较均衡的情况下，我们还是可以使用准确率来作为分类模型的评估指标。 所以在数据不均衡的场景下， 我们应该考虑的评估指标应该是精确率和召回率。 我们先看一下图4.23。 \\n 图4.23 真实标注与模型预测对比 图中的True Positive(TP)表示模型预测结果是恐怖分子，数据的真实标注也是恐怖分子；False Positive(FP)表示模型预测结果是恐怖分子，数据的真实标注是非恐怖分子；False \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 129}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 130 Negative(FN)表示模型预测结果是非恐怖分子，数据的真实标注是恐怖分子；True Negative(TN)表示模型预测结果是非恐怖分子，数据的真实标注也是非恐怖分子。 这里的True/Fasle和Positive/Negative我们可以这么来理解，True或Fasle表示模型预测结果是否正确，如果预测正确就是True，预测错误就是Fasle。所以相当于TP和TN都表示模型预测是正确的，FP和FN表示模型预测不正确。Positive或Negative表示模型的预测结果。TP和FP模型预测结果都是Positive，TN和FN模型预测结果都是Negative。 看懂这个图以后我们来看一下召回率（recall）的公式： 𝑟𝑒𝑐𝑎𝑙𝑙=𝑇𝑃𝑇𝑃+𝐹𝑁(4.55) 召回率描述的是模型对于正例——恐怖分子的召回能力， 也就是找到恐怖分子的能力。 比如一共有19名恐怖分子，模型可以正确识别出10名恐怖分子，有9名恐怖分子没有识别出来。那么TP=10，FN=9，recall=10/(10+9)=52.63%。比如一共有19名恐怖分子，模型可以正确识别出18名恐怖分子，有1名恐怖分子没有识别出来，那么TP=18，FN=1，recall=18/(18+1)=94.74%。召回率越高说明模型找到恐怖分子的能力越强。 我们再来看一下精确率（precision）的公式： 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛=𝑇𝑃𝑇𝑃+𝐹𝑃(4.56) 精确率描述的是模型对于正例-恐怖分子的判断能力。比如模型可以正确识别出10名恐怖分子，另外还有40人模型判断是恐怖分子，其实这40人是非恐怖分子。那么TP=10，FP=40，precision=10/(10+40)=20%。比如模型可以正确识别9名恐怖分子，另外还有1人模型判断是恐怖分子，其实这1人是非恐怖分子。那么TP=9，FP=1，precision=9/(9+1)=90%。精确率越高说明模型对于恐怖分子的识别越精准。 准确率（accuracy）的公式为： 𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦=𝑇𝑃+𝑇𝑁𝑇𝑃+𝐹𝑁+𝐹𝑃+𝑇𝑁(4.57) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 130}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 131 也就是所有识别正确的结果除以所有结果。 针对不同的问题，我们所关注的评估指标可能也会有所不同。比如2020年初新型冠状病毒爆发时期，我们更关注召回率，因为我们要尽量找到所有带有新型冠状病毒的病人，然后把病人进行隔离观察治疗，宁可抓错100，也不能放过1个。 再举一个信息检索中比较极端的例子，假如一个搜索引擎有10000个网站，其中有100个深度学习相关的网站。当我们搜索“深度学习是什么？”的时候，如果搜索引擎想提高精确率，那么它可以只返回一个跟深度学习相关度最高的网站，如果这个结果是我们想要的，那么精确率就是100%，不过这样做，召回率只有1%。如果搜索引擎想提高召回率，那么它可以返回10000个网站，这样做召回率就可以有100%，不过精确率只有1%。 所以判断一个搜索引擎好坏， 主要看的是前面几十条结果的精确率， 因为我们通常只会查看最前面的几十条结果，特别是最前面的几条结果。最前面的几条结果是我们想要的，我们就会认为这个搜索引擎很好。我们并不是很在意搜索引擎的召回率，比如一共有10000条结果是符合我们想要的结果，搜索引擎给我们返回了1000条还是9000条，其实我们并不在意，因为我们只会看最前面的几十条结果。 在实际应用中，最理想的情况是精确率和召回率都比较高，不过一般来说，很难得到精确率和召回率都很高的结果。很多时候是提高了精确率，召回率就会降低；提高召回率，精确率就会降低。所以我们还需要一个综合评估指标，也就是F值，F值是精确率(P)和召回率(R)的加权调和平均，公式为： 𝐹=((𝛼#+1)×𝑃×𝑅)𝛼#×𝑃+𝑅(4.58) 当参数𝛼=1时，就是最常见的的F1值，即： 𝐹1=2×𝑃×𝑅𝑃+𝑅(4.59) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 131}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 132 F1值综合了P和R的结果，可用于综合评价分类结果的质量。 准确率，召回率，精确率，F1值都是在0-1之间，并且都是越大越好。 最后我再举一个例子， 帮助大家理解这4个评估指标的计算。 比如一个预测恐怖分子的模型结果如图4.24所示。 \\n 图4.24 模型结果 有10个恐怖分子模型预测结果也是恐怖分子（TP） 有10个非恐怖分子模型预测结果是恐怖分子（FP） 有5个恐怖分子模型预测结果是非恐怖分子（FN） 有75个非恐怖分子模型预测结果是非恐怖分子（TN） 准确率计算：(TP+TN)/(TP+FN+FP+TN)=(10+75)/(10+5+10+75)=85% 召回率计算：TP/(TP+FN)=10/(10+5)=66.67% 精确率计算：TP/(TP+FP)=10/(10+10)=50% F1值：(2×50%×66.67%)/(50%+66.67%)=57.14% 4.10.2 混淆矩阵(Confusion Matrix) 在机器学习领域， 混淆矩阵又称为可能性表格或者是错误矩阵。 它是一种特定的矩阵用来呈现算法的效果。我们还是通过例子来讲解，假设有一个人，狗，猫的分类系统，我们的测试样本一共有10个人，15只狗，5只猫，得到如下混淆矩阵，如图4.25所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 132}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 133  图4.25 混淆矩阵 图中表达的意思是，一共有5只猫，其中3中预测正确了，有1只猫被预测成了狗，有1只猫被预测成了人；一共有15只狗，其中有3只狗被预测成了猫，有11只狗预测正确，有1只狗被预测成了人；一共有10个人，其中有1个人被预测成了猫，有两个人被预测成了狗，有7个人预测正确。  4.11独热编码（One-Hot Encoding） 在神经网络， 深度学习的分类问题中， 我们通常会把分类问题的标签转化为独热编码的格式。比如在手写数字识别的任务中，数字有0-9一共10中状态，所以每个数字都可以转换为长度为10的编码： 0->1000000000 1->0100000000 2->0010000000 3->0001000000 4->0000100000 5->0000010000 6->0000001000 猫狗人猫311狗3111人127模型预测真实标签', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 133}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 134 7->0000000100 8->0000000010 9>-0000000001 比如对于根据图片判断性别的模型： 男性可以编码为：10 女性可以编码为：01 比如给花的品种进行分类的模型，假设有红黄蓝三种花： 红花可以编码为：100 黄花可以编码为：010 蓝花可以编码为：001 根据以上的几个例子大家应该都可以了解独热编码是怎么回事了， 在后面的分类应用中我们经常会把分类的标签处理成为独热编码的格式，然后用来训练模型。  4.12 BP神经网络完成手写数字识别 这一小节中我们要自己搭建一个BP网络来完成手写数字识别的功能，我们使用到的训练集是sklearn中自带的手写数字数据集。首先我们先看一下数据集，如代码4-2所示。 代码4-2：手写数字数据集介绍 from sklearn.datasets import load_digits import matplotlib.pyplot as plt  # 载入手写数字数据 digits = load_digits() # 打印数据集的shape，行表示数据集个数，列表示每个数据的特征数 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 134}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 135 print('data shape:',digits.data.shape) # 打印数据标签的shape，数据标签的值为0-9 print('target shape:',digits.target.shape) # 准备显示第0张图片，图片为灰度图 plt.imshow(digits.images[0],cmap='gray') # 显示图片 plt.show() 运行结果如下： data shape: (1797, 64) target shape: (1797,) \\n 观察4-2程序的输出我们可以发现这个数据集中每个数据的图片是一张8×8的图片，分别对应数字0-9。所以我们可以考虑构建一个输入层为64个神经元的神经网络，64个神经元对应于图片中的64个像素点。假设我们设置一层隐藏层，隐藏层有100个神经元。最后设置一个输出层，我们会把标签转变为独热编码(one-hot)的格式，数字0-9一共10个状态，所以输出层我们可以设置10个神经元。数字识别网络结构图如图4.26所示。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 135}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 136 \\n 图4.26 数字识别网络结构图 BP网络完成手写数字识别的代码如代码4-3所示。 代码4-3：BP网络完成手写数字识别 # 导入numpy科学计算库 import numpy as np # 载入画图工具包 import matplotlib.pyplot as plt # 导入手写数字数据集 from sklearn.datasets import load_digits # 用于标签二值化处理，把标签转成独热编码one-hot的格式 from sklearn.preprocessing import LabelBinarizer # 用于把数据集拆分为训练集和测试集 from sklearn.cross_validation import train_test_split # 用于评估分类结果 from sklearn.metrics import classification_report,confusion_matrix  # 定义sigmoid函数 def sigmoid(x):     return 1/(1+np.exp(-x))  # 定义sigmoid函数的导数 def dsigmoid(x):     return x*(1-x)  # 定义神经网络类 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 136}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 137 class NeuralNetwork:     # 初始化网络，定义网络结构     # 假设传入(64,100,10)，说明定义：     # 输入层64个神经元，隐藏层100个神经元，输出层10个神经元     def __init__(self,layers):         # 权值的初始化，范围-1到1         self.W1 = np.random.random([layers[0],layers[1]])*2-1         self.W2 = np.random.random([layers[1],layers[2]])*2-1         # 初始化偏置值         self.b1 = np.zeros([layers[1]])         self.b2 = np.zeros([layers[2]])         # 定义空list用于保存list         self.loss = []         # 定义空list用于保存         self.accuracy = []      # 训练模型     # X为数据输入     # T为数据对应的标签     # lr学习率     # steps训练次数     # batch批次大小     # 使用批量随机梯度下降法，每次随机抽取一个批次的数据进行训练     def train(self,X,T,lr=0.1,steps=20000,test=5000,batch=50):         # 进行steps+1次训练         for n in range(steps+1):             # 随机选取一个批次数据             index = np.random.randint(0,X.shape[0],batch)              x = X[index]             # 计算隐藏层输出             L1 = sigmoid(np.dot(x,self.W1)+self.b1)             # 计算输出层输出             L2 = sigmoid(np.dot(L1,self.W2)+self.b2)             # 求输出层的学习信号             delta_L2 = (T[index]-L2)*dsigmoid(L2)             # 求隐藏层的学习信号             delta_L1= delta_L2.dot(self.W2.T)*dsigmoid(L1)             # 求隐藏层到输出层的权值改变             # 由于一次计算了多个样本，所以需要求平均             self.W2 += lr * L1.T.dot(delta_L2) / x.shape[0]             # 求输入层到隐藏层的权值改变             # 由于一次计算了多个样本，所以需要求平均             self.W1 += lr * x.T.dot(delta_L1) / x.shape[0]              # 改变偏置值 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 137}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 138             self.b2 = self.b2 + lr * np.mean(delta_L2, axis=0)             self.b1 = self.b1 + lr * np.mean(delta_L1, axis=0)                          # 每训练5000次预测一次准确率             if n%test==0:                 # 预测测试集的预测结果                 Y2 = self.predict(X_test)                 # 取得预测结果最大的所在的索引                 # 例如最大值所在的索引是3，那么预测结果就是3                 predictions = np.argmax(Y2,axis=1)                 # 计算准确率                 # np.equal(predictions,y_test)判断预测结果和真实标签是否相等，相等返回True，不相等返回False                 # np.equal(predictions,y_test)执行后得到一个包含多个True和False的列表                 # 然后用np.mean对列表求平均True为1，False为0。                 # 例如一共有10个结果，9个True，一个False，平均后的结果为0.9，即预测的准确率为90%                 acc = np.mean(np.equal(predictions,y_test))                 # 计算loss                 l = np.mean(np.square(y_test - predictions) / 2)                 # 保存准确率                 self.accuracy.append(acc)                 # 保存loss值                 self.loss.append(l)                 # 打印训练次数,准确率和loss                 print('steps:%d accuracy:%.3f loss:%.3f' % (n,acc,l))      # 模型预测结果     def predict(self,x):         L1 = sigmoid(np.dot(x,self.W1)+self.b1)#隐层输出         L2 = sigmoid(np.dot(L1,self.W2)+self.b2)#输出层输出         return L2  # 程序从这里开始运行 # 定义训练次数 steps = 30001 # 定义测试周期数 test = 3000 # 载入数据 digits = load_digits() # 得到数据 X = digits.data # 得到标签 y = digits.target \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 138}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 139 # 输入数据归一化，有助于加快训练速度 # X中原来的数值范围是0-255之间，归一化后变成0-1之间 X -= X.min() X /= X.max() - X.min() # 分割数据1/4为测试数据，3/4为训练数据 # 有1347个训练数据，450个测试数据 X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)   # 创建网络,输入层64个神经元，隐藏层100个神经元，输出层10个神经元 nm = NeuralNetwork([64,100,10]) # 标签转化为独热编码one-hot的格式 labels_train = LabelBinarizer().fit_transform(y_train)  # 开始训练 print('Start training') nm.train(X_train,labels_train,steps=steps,test=test)  # 预测测试数据 predictions = nm.predict(X_test)  # predictions.shape为(450,10) # y_test.shape为(450,) # 所以需要取得预测结果最大的所在的索引，该索引就是网络预测的结果 # np.argmax(predictions,axis=1)执行后得到的形状也变成了(450,) predictions = np.argmax(predictions,axis=1) # 对比测试数据的真实标签与网络预测结果，得到准确率，召回率和F1值 print(classification_report(y_test,predictions)) # 对于测试数据的真实标签与网络预测结果，得到混淆矩阵 print(confusion_matrix(y_test,predictions))  # 训练次数与loss的关系图 plt.plot(range(0,steps+1,test),nm.loss) plt.xlabel('steps') plt.ylabel('loss') plt.show()  # 训练次数与accuracy的关系图 plt.plot(range(0,steps+1,test),nm.accuracy) plt.xlabel('steps') plt.ylabel('accuracy') plt.show() 运行结果如下： Start training steps:0 accuracy:0.111 loss:10.206 steps:3000 accuracy:0.922 loss:0.777 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 139}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 140 steps:6000 accuracy:0.960 loss:0.469 steps:9000 accuracy:0.964 loss:0.389 steps:12000 accuracy:0.967 loss:0.361 steps:15000 accuracy:0.964 loss:0.416 steps:18000 accuracy:0.971 loss:0.342 steps:21000 accuracy:0.969 loss:0.378 steps:24000 accuracy:0.971 loss:0.342 steps:27000 accuracy:0.971 loss:0.360 steps:30000 accuracy:0.971 loss:0.360              precision    recall  f1-score   support            0       1.00      0.98      0.99        45           1       0.93      0.98      0.95        41           2       0.98      1.00      0.99        50           3       1.00      0.93      0.96        40           4       0.98      0.98      0.98        48           5       0.94      0.98      0.96        51           6       0.98      1.00      0.99        42           7       1.00      1.00      1.00        45           8       0.93      0.91      0.92        44           9       0.98      0.95      0.97        44  avg / total       0.97      0.97      0.97       450  [[44  0  0  0  1  0  0  0  0  0]  [ 0 40  0  0  0  0  0  0  1  0]  [ 0  0 50  0  0  0  0  0  0  0]  [ 0  0  0 37  0  2  0  0  1  0]  [ 0  0  0  0 47  0  0  0  0  1]  [ 0  0  0  0  0 50  1  0  0  0]  [ 0  0  0  0  0  0 42  0  0  0]  [ 0  0  0  0  0  0  0 45  0  0]  [ 0  3  1  0  0  0  0  0 40  0] [ 0  0  0  0  0  1  0  0  1 42]] ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 140}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 141 \\n \\n  4.13 Sklearn手写数字识别 上一小节我们学习了如何从头开始搭建一个BP神经网络来完成手写数字识别，其实搭建BP神经网络还有更简单快捷的方法，就是使用scikit-learn模块。scikit-learn是一个常用的python模型，里面封装了大量机器学习算法，其中就包括BP神经网络。下面我们来看一下如何使用scikit-learn中的神经网络算法来进行手写数字识别，如代码4-4所示。 代码4-4：BP网络完成手写数字识别(使用scikit-learn中的神经网络算法) # 载入BP神经网络算法 from sklearn.neural_network import MLPClassifier  from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 141}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 142 import matplotlib.pyplot as plt #载入数据 digits = load_digits() #数据 x_data = digits.data  #标签 y_data = digits.target  # X中原来的数值范围是0-255之间，归一化后变成0-1之间 x_data -= x_data.min() x_data /= x_data.max() - x_data.min() # 分割数据1/4为测试数据，3/4为训练数据 # 有1347个训练数据，450个测试数据 x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.25)  # 定义神经网络模型，模型输入神经元个数和输出神经元个数不需要设置 # hidden_layer_sizes用于设置隐藏层结构： # 比如(50)表示有1个隐藏层，隐藏层神经元个数为50 # 比如(100,20)表示有2个隐藏层，第1个隐藏层有100个神经元，第2个隐藏层有20个神经元 # 比如(100,20,10)表示3个隐藏层，神经元个数分别为100，20，10 # max_iter设置训练次数 mlp = MLPClassifier(hidden_layer_sizes=(100,20), max_iter=500) # fit传入训练集数据开始训练模型 mlp.fit(x_train,y_train) # predict用于模型预测 predictions = mlp.predict(x_test) # 标签数据和模型预测数据进行对比，计算分类评估指标 print(classification_report(y_test, predictions)) 运行结果如下：   precision    recall  f1-score   support             0       1.00      1.00      1.00        35            1       0.98      1.00      0.99        49            2       1.00      0.98      0.99        50            3       0.97      0.97      0.97        38            4       1.00      0.98      0.99        56            5       1.00      0.93      0.96        43            6       1.00      1.00      1.00        47            7       0.94      1.00      0.97        46            8       0.95      1.00      0.97        36            9       0.98      0.96      0.97        50      accuracy                           0.98       450    macro avg       0.98      0.98      0.98       450 weighted avg       0.98      0.98      0.98       450 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 142}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 143  要注意的是scikit-learn中封装的神经网络只是普通的BP神经网络，不具备深度学习算法。如果要实现深度学习算法需要使用专门的深度学习框架，如Tensorflow，在下一章节中我们会详细介绍。  4.14参考文献 [1] McClelland J L, Rumelhart D E, PDP Research Group. Parallel Distributed Processing [J]. Explorations in the Microstructure of Cognition, 1986, 2: 216-271. [2] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]//Proceedings of the fourteenth international conference on artificial intelligence and statistics. 2011: 315-323. [3] 韩力群, 康芊. 人工神经网络理论, 设计及应用——神经细胞, 神经网络和神经系统[J]. 北京工商大学学报: 自然科学版, 2005, 23(1): 52-52.          ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 143}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 144 第5章-深度学习框架Tensorflow基础使用 在介绍正式内容以前，我想先给大家说明一个基本情况，也就是目前深度学习还处于一个非常早期的，不成熟的阶段，所以我们会看到各种各样的人写着各种各样风格的代码。当我们想完成一个应用的时候，我们会有很多种方式和选择，有时候选择太多也不一定是好事，因为我们可能会面临选择的困难。虽然“条条大路通罗马” ，但是有些路好走，有些路不好走；有些路部分人觉得好走，部分人觉得不好走。很多时候我们很难判断哪条路好，哪条路不好。 给大家举一个例子来说明这个问题，如图5.1所示。 \\n 图5.1 条条大路通罗马 比如我们想做一个图像识别的应用，那么首先我们有很多种深度学习的框架可以选择。如果是在2016-2017年左右，那么这个选择还是挺难的，因为每个深度学习的框架都有自己的优缺点，我们可能很难选择学习哪一个框架。当然，这个问题现在相对变得容易了，经过时间的考验，现在业内公认的首选的深度学习框架就是Tensorflow或者Pytorch。Pytorch\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 144}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 145 是最近一两年学术界最喜欢使用的深度学习框架，Tensorflow是落地应用最多的深度学习框架。如果让我推荐的话，我会推荐两者都学，多学总不是坏事。我们这本书主要是以Tensorflow为重点，大家可以先跟着我把Tensorflow学好。 深度学习框架选好之后，接下来要继续选择，每个框架在实现某个具体应用的时候通常都会有很多种实现方式。比如如何载入数据进行数据预处理有很多种方法，如何搭建网络有很多种方法，如何训练模型又有很多种方法。比如图5.1中，假设我们选择了Tensorflow作为我们的深度学习框架，那么我们在搭建网络结构的时候又可以选择使用Tensorflow的高级API：Slim，TFLearn，tf.layers，tf.keras或其他API，最后完成图像识别的应用。由于各种方法比较多，我们全部都学并不是一个明智的选择，所以在本书中我会选择我认为比较容易理解和学习方法来教大家。Tensorflow2.0推出以后，谷歌官方建议大家使用tf.keras来搭建和训练模型。Keras也是我非常喜欢的一款深度学习框架，它是所有深度学习框架中最容易使用的，没有之一，所以也比较适合初学者使用。鉴于Keras的简洁易用性以及容易理解和学习的特点，本书中关于深度学习的应用大部分都会基于tf.keras的API完成。  5.1 Tensorflow介绍  5.1.1 Tensorflow简介 Tensorflow的官网是：https://tensorflow.google.cn/，不需要翻墙。 还有一个需要翻墙的官网是：https://www.tensorflow.org。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 145}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 146 Tensorflow是谷歌基于DisBelief进行研发的第二代人工智能学习系统，并于2015年11月9日开源。Tensorflow可被用于图像识别，语音识别，文本处理等多项机器学习和深度学习领域。并且可以运行在智能手机，个人电脑，数据中心服务器等各种设备上。 目前支持Windows，MacOS，Linux系统，支持CPU/GPU版本，支持单机和分布式版本。 Tensorflow支持多种编程语言， 目前有Python，C++，GO，JAVA，R，SWIFT，JavaScript。最主流的编程语言是Python， 本书主要介绍的编程语言也是Python。 目前Tensorflow支持 64位的Python3.5/3.6/3.7/3.8版本。 2019年3月8日，Google发布最新Tensorflow2.0-Alpha版本，并在2019年10月1日发布了Tensorflow2.0正式版本。新版本的Tensorflow有很多新特性，更快更容易使用更人性化。因为新版本的Tensorflow有较大的更新，所以老版的Tensorflow程序在新版本中几乎都无法继续使用。 如果是作为一个初学者，那么我们应该先学Tensorflow1呢，还是直接学习Tensorflow2。学习Tensorflow1的理由是现在网上的Tensorflow开源程序以及比较成熟的Tensorflow项目基本上都是基于Tensorflow1的，Tensorflow2刚出不久，资源相对来说肯定会比较少一些。不过Tensorflow2肯定是未来发展的趋势，虽然现在还比较新，但是我还是建议大家学习Tensorflow2为主。Tensorflow1和Tensorflow2作为两个大的版本，它们之间肯定会有很多不同之处，下面我选取两个我觉得最大的变化来给大家进行说明。 5.1.2 静态图和动态图机制Eager Execution Tensorflow1版本跟很多其他的“老”深度学习框架一样，都是使用静态图机制，而Tensorflow2版本跟Pytorch一样都是使用现在最新潮的动态图机制。什么是动态图机制我', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 146}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 147 觉得基本上不需要跟大家解释， 动态图机制是一种跟我们平时写Python代码类似的一种机制，用起来很自然。比如代码5-1为Tensorflow2的程序。 代码5-1：动态图 import tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把m1和m2传入 product = tf.matmul(m1,m2) # 打印结果 print(product) 结果输出为： tf.Tensor([[20]], shape=(1, 1), dtype=int32)  动态图程序看起来就跟一段普通的Python程序一样，没什么好特别说明的。不过静态图就没这么好理解了， 因为静态图跟我们平时的编程习惯不符。 在静态图机制中我们需要在一个计算图（Graph）中定义计算的流程，然后再创建一个会话（Session） ，在会话中执行计算图的计算。比如代码5-2为Tensorflow1的程序。 代码5-2：静态图（片段1） # 这个程序我是在Tensorflow1的环境中运行的 import tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把m1和m2传入 product = tf.matmul(m1,m2) # Tensorflow1的程序跟一般的python程序不太一样 # 这个时候打印product，只能看到product的属性，不能计算它的值 # 应该这里我只定义了计算图，图必须在会话中运行，我们还没有定义会话 print(product) 结果输出为： Tensor(\"MatMul:0\", shape=(1, 1), dtype=int32)  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 147}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 148 代码5-2：静态图（片段2） # 定义一个会话 sess = tf.Session() # 调用sess的run方法来执行矩阵乘法 # 计算product，最终计算的结果存放在result中 result = sess.run(product) print(result) # 关闭会话 sess.close() 结果输出为： [[20]] 对比动态图和静态图这两个简单的程序我们就能看出还是动态图使用起来比较简单， 也更加自然。这也是深度学习框架未来的发展趋势，以后静态图机制应该会被慢慢淘汰。 5.1.3 tf.keras 在说tf.keras之前我们先来说一下Keras，Keras是所有深度学习框架中最容易使用，最初是由Google AI 研究人员 Francois Chollet 创建并开发的。Francois 于 2015 年 3 月 27 日将 Keras 的第一个版本发布在他的GitHub。Keras是一个高度封装的深度学习框架，它的后端可以是Theano，Tensorflow或者CNTK。很快，Keras的易用性得到了广大深度学习研究开发者的认可，并引起了Tensorflow官方的注意。并从Tensorflow1.10版本开始加入tf.keras接口，也就是我们在Tensorflow中也可以使用Keras的方式来搭建和训练模型。 不过Keras和tf.keras是分开的两个项目， 它们使用起来基本上是一样的， 只是在细节上会有一些小的不同。随着Tensorflow2.0的推出，谷歌宣布Keras现在是Tensorflow的官方高级API，用于快速简单的模型设计和训练，并推荐大家使用。随着Keras2.3.0的发布，Francois也发表声明推荐深度学习从业人员都应该将代码转成Tensorflow2.0和tf.keras，而不是继续使用Keras。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 148}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 149 在Tensorflow1.0中如何完成我们的深度学习模型训练程序我们有非常多选择，Tensorflow2.0把选择进行了简化，只保留了更好的几种。基于Tensorflow官方推荐以及我个人的使用经验， 我认为在Tensorflow2.0的使用中， 我们可以尽量多使用tf.keras的接口来完成我们的应用。 前面我介绍了很多关于Keras/tf.keras的优点，Keras/tf.keras的缺点是程序运行效率会比纯Tensorflow程序要稍微慢一点点。这和容易理解，程序封装越多，用起来越方便，运行起来自然就会慢一些。不过Tensorflow针对这个问题也做了很多优化，所以实际应用中其实纯Tensorflow和tf.keras速度的差距一般也不会很大。真正影响深度学习运行速度的主要影响因素是模型的复杂度和硬件条件，tf.keras对于速度基本上影响不会很大。  5.2 Tensorflow-cpu安装 https://tensorflow.google.cn/install/pip官方网址可以看到关于使用pip安装Tensorflow比较详细的说明。 5.2.1 Tensorflow-cpu在线安装 使用Windows安装Tensorflow的同学要注意，从 TensorFlow 2.1.0 版本开始，需要安装vc_redist.x64.exe，进入链接https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads。 下载Visual Studio 2015，2017 and 2019下面的x64:vc_redist.x64.exe（或直接从https://aka.ms/vs/16/release/vc_redist.x64.exe链接下载，下载后双击进行安装。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 149}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 150 Tensorflow在Winodws/MacOS/Linux环境下安装方式基本上都是一样的，首先先来介绍CPU版本的安装。安装Tensorflow之前，先要安装Python环境，Python的安装在本书第二章节已经介绍过了，大家先要把Anaconda给安装好，如使用Windows系统，则需要安装Python3.5/3.6/3.7版本的64位的Anaconda。如果大家跟着书中的步骤进行安装的话，先把安装流程全部看完再动手，不然可能会操作错误。Python安装模块的方式都可以用pip install 的命令进行安装。Tensorflow2.0正式发布以后，现在Tesnorflow默认安装的版本就是Tensorflow2的版本， 安装Tensorflow可以用管理员方式打开命令提示符， 运行如下命令： pip install tensorflow-cpu 不过上面命令通常下载速度比较慢，推荐从国内源进行下载速度比较快，使用下面命令下载速度比较快： pip install tensorflow-cpu -i https://pypi.douban.com/simple -i https://pypi.douban.com/simple是国内下载源，安装其他python模型也可以使用该下载源。 执行完之后会自动从网上下载tensorflow安装包并安装，安装tensorflow的同时也会安装和更新一些其他的python包。 顺利的话就运行完这段命令tensorflow就安装好了，安装好之后我们可以在命令行安装的最后看到类似如下信息： Successfully installed absl-py-0.8.1 cachetools-3.1.1 certifi-2019.11.28 gast-0.2.2 google-auth-1.9.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 oauthlib-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.2 tensorflow-2.0.0 urllib3-1.25.7 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 150}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 151 不过一般来说都不会这么顺利，关于可能会出现的问题以及如何解决问题后面会总结。 假设安装没有问题，那么可以打开一个python的运行环境，比如Jupyter，然后运行命令： import tensorflow 如果没有产生错误，那么就代表安装成功了。如果看到警告不要紧张，有警告是正常的，一般警告都可以忽略掉，如图5.2所示表示安装成功。  图5.2 Tensorflow安装成功 5.2.2 安装过程中可能遇到的问题汇总 由于Tensorflow会不断地更新，每个Tensorflow版本我们可能会遇到的问题不同，每个人的电脑环境也有所不同， 所以我这里总结的问题不一定跟大家碰到的问题相同， 也可能会有缺漏，如果问题不同或者有缺漏，大家可以给我反馈，我再进行补充。 问题1：在安装过程中出现“ERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.14.1 which is incompatible. ERROR: keras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.8 which is incompatible.”或者类似错误。 解决方法：这类错误可以忽略不处理。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 151}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 152 问题2：在安装过程中出现“ERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.”。 解决方法：用管理员方式打开命令提示符，然后运行： pip install wrapt --upgrade --ignore-installed 然后再次运行： pip install tensorflow-cpu -i https://pypi.douban.com/simple 如果出错的不是'wrapt'而是其他模块，类似的错误可以用类似的方法解决。 问题3：在安装过程中出现“distributed 1.21.8 requires msgpack,which is not installed.”类似错误。 解决方法：安装“msgpack“，打开命令提示符，然后运行： pip install msgpack -i https://pypi.douban.com/simple 问题4：某条命令在安装过程中出现“PermissionError：[WinError 5] 拒绝访问” 。 解决方法：这个错误主要是权限问题，关闭所有python相关软件，重新用管理员方式打开命令提示符，然后再次运行该命令。 问题5： 在安装过程中模块下载中断并出现 “ReadTimeoutError:HTTPSConnectionPoll”。 解决方法：由于下载的资源在国外，所以网速不好可能会导致下载连接超时，可以尝试重新运行命令再次下载安装。也可以使用国内的下载源进行安装，一般速度会比较快，运行下面的命令使用国内的源进行安装： pip install tensorflow-cpu -i https://pypi.douban.com/simple 问题6：在安装过程中模块下载中断并出现“拒绝访问” 。 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 152}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 153 解决方法：系统权限问题，可以用管理员方式打开命令提示符，然后重新安装，或者是在安装命令后面加上“--user” ，例如： pip install tensorflow-cpu -i https://pypi.douban.com/simple --user 问题7：Tensorflow安装成功后在python环境中运行import tensorflow后出现“ImportError:cannot import name ‘dense_features’from ‘tensorflow.python.feature_column’”。 解决方法：用管理员的方式打开命令提示符，先运行： pip uninstall tensorflow_estimator 再运行 pip install tensorflow_estimator 问题8：Tensorflow安装成功后在python环境中运行import tensorflow后出现“ImportError: DLL load failed with error code -1073741795和ImportError: No module named '_pywrap_tensorflow_internal'”。 解决方法：由于电脑CPU太老导致的错误，解决方法一是安装老版本的Tensorflow，比如Tensorflow1.2.0版本，但是不推荐。推荐的解决方法是换一台新一点的电脑。 问题9：Tensorflow安装成功后在python环境中运行import tensorflow后出现：ERROR:root:Internal Python error in the inspect module.Below is the traceback from this internal error. 解决方法： 安装vc_redist.x64.exe， 具体查看5.2.1中说明。 然后再重新安装Tensorflow。 问题10：Tensorflow安装成功后在python环境中运行import tensorflow后出现 “No module named ‘tensorflow’” ，说明Tensorflow还没有安装好。 解决方法：打开命令提示符，重新安装： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 153}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 154 pip install tensorflow-cpu -i https://pypi.douban.com/simple 问题11：Tensorflow安装成功后在python环境中运行import tensorflow后出现“ImportError：DLL load failed：找不到指定的模型” 。 解决方法： 安装vc_redist.x64.exe， 具体查看5.2.1中说明。 然后再重新安装Tensorflow。 5.2.3 Tensorflow-cpu卸载 如果已经安装好了Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令： pip uninstall tensorflow-cpu 5.2.4 Tensorflow-cpu更新 如果已经安装过Tensorlfow， 现在想把Tensorflow更新到最新版本， 可以用管理员方式打开命令行，执行命令： pip install tensorflow-cpu –upgrade 5.2.5 Tensorflow-cpu指定版本的安装 如果我们想安装Tensorflow指定版本，比如老一点的版本，可以使用指定版本的安装方式， 比如我们想安装Tensorflow1.13.2版本的话， 可以用管理员方式打开命令行， 执行命令： pip install tensorflow==1.13.2  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 154}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 155 5.3 Tensorflow-gpu安装 5.3.1 Tensorflow-gpu了解最新版本情况 先在Tensorflow官网查看Tensorflow-gpu最新的安装情况（https://tensorflow.google.cn/install/gpu），如图5.3所示。 \\n 图5.3 tensorflow-gpu版本最新情况 一般来说比较新的英伟达(NVIDIA)的GPU都可以支持。这里要注意的是CUDA的版本和cuDNN的版本。比如我们在图5.3中看到的Tensorflow-gpu版本需要安装CUDA10.1的版本，cuDNN的版本要求7.6以上。如果Tensorflow出了更新的版本，对应的CUDA和cuDNN的版本可能也会发生变化。 5.3.2 Tensorflow-gpu安装CUDA CUDA（Compute Unified Device Architecture）是英伟达NVIDIA推出的运算平台，是一种通用的并行计算机构，可以使得GPU能够解决复杂的计算问题。CUDA的下载的地址为：https://developer.nvidia.com/cuda-toolkit-archive，如图5.4所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 155}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 156 \\n 图5.4 不同版本CUDA下载  比如我们想下载CUDA10.1，可以点击CUDA Toolkit10.1。如果点击右侧的Online Documentation可以查看关于CUDA安装的一些说明。图5.5为CUDA10.1对于Windows环境的一些要求。 \\n 图5.5 CUDA10.1对Windows环境要求  图中我们可以看到CUDA10.1要求的Windows系统在Table1中，比较常用的系统都可以满足。另外在Table2中我们看到安装CUDA10.1之前我们还需要安装Visual Studio，推荐安装Visual Studio15或Visual Studio17版本。  图5.6为CUDA10.1对于Linux环境的一些要求。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 156}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 157 \\n 图5.6 CUDA10.1对Linux环境要求 准备好CUDA10.1要求的环境以后看我们进入CUDA下载界面，并根据情况做好选择，最后点击Downdload，如图5.7所示。 \\n 图5.7 下载CUDA 安装很简单，跟普通软件一样，一直下一步就可以。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 157}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 158 5.3.3 Tensorflow-gpu安装cuDNN库 cuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络 （Deep Neural Networks） 中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。 cuDNN的下载地址为：https://developer.nvidia.com/cudnn。下载之前需要注册。Tensorflow的GPU版本对cuDNN的版本是有严格要求的，前面我们看到目前Tensorflow2支持的是cuDNN7.6以上版本。 进入下载地址后，选择对应CUDA10.1版本和对应操作系统的cuDNN进行下载，如图5.8所示。 \\n 图5.8 下载cuDNN 下载好了之后可以得到一个压缩包，解压完之后可以看到三个文件夹，我们要做的就是把这三个文件夹中的内容拷贝到CUDA安装目录下面所对应的三个文件夹中，如图5.9（这是我之前配置CUDA9.0和对应cuDNN时的图，其他版本的CUDA和cuDNN也一样）所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 158}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 159 \\n 图5.9 配置cuDNN 5.3.4 Tensorflow-gpu在线安装 安装方式跟CPU版本差不多，用管理员方式打开命令提示符，执行命令： pip install tensorflow-gpu -i https://pypi.douban.com/simple 5.3.5 Tensorflow-gpu卸载 如果已经安装好了Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令： pip uninstall tensorflow-gpu 5.3.6 Tensorflow-gpu更新 如果已经安装过Tensorlfow， 现在想把Tensorflow更新到最新版本， 可以用管理员方式打开命令行，执行命令： pip install tensorflow-gpu –upgrade  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 159}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 160 5.4 Tensorflow基本概念 Tensorflow中的一些基本概念在Tensorflow2版本中已经被隐藏起来，或者已经不再使用了， 不过我还是打算给大家简单介绍一些Tensorflow的基本概念， 虽然之后可能不会用到。 Tensorflow是一个编程系统，使用图(graphs)来表示计算任务，图(graphs)中的节点称之为op(operation)， 一个op获得0个或多个Tensor， 执行计算， 产生0个或多个Tensor，Tensor看作是一个n维的数据。Tensorflow1中图必须在会话（Session）中运行， 如图5.10所示。 \\n 图5.10 会话Session 图中的Tensor表示数据， 一般可以用在数据的输入， 输出， 以及计算的中间流程。Variable表示变量，一般用于记录一些需要变化的数值，比如需要训练的模型参数。虽然可以使用Tensor的地方都可以使用Variable，不过它们还是有一些区别。 图中的Graph表示一个完整的计算任务，最上面的Tensor0和Variable0一起传入一个operation0里面，这个operation0可以是加法，减法，乘法，除法等运算。运算完了之后产\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 160}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 161 生了一个Tensor1，这个Tensor1跟Tensor2一起被送入了operation1，在operation1中进行计算。 再举一个更具体的例子，如图5.11所示。 \\n 图5.11 神经网络计算图 图中的x是一个Tensor，表示数据的输入，图中的W和b是Variable，表示模型需要训练的参数。W和x共同传入了MatMul的operation中，进行矩阵乘法的操作，计算完后得到的Tensor0会传入到Add(operation)中，跟变量b一起进行加法操作，得到Tensor1。Tensor1传入ReLU(operation)激活函数进行计算，然后得到Tensor2再继续传递信号，最终得到Tensor3。 在前面的内容中我们已经介绍过，在Tensorflow2中使用的是动态图机制，也就是说我们不再需要会话，我们可以在任意时候进行计算并得到结果，程序设计起来会更加方便，更加自然。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 161}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 162 5.5 Tensorflow基础使用 1．TF1转TF2工具 Tensorflow2安装好之后， 会自带一个工具可以把Tensorflow1的程序转成Tensorflow2的程序，使用方法是打开命令提示符，然后执行： tf_upgrade_v2 --infile input.py --outfile output.py tf_upgrade_v2为转化工具，input.py为Tensorflow1的程序路径，output.py为新产生的Tensorflow2的程序保存路径。 这个工具的转换效果不能算很好，并不是所有的Tensorflow1的程序都可以使用这个工具转变为Tensorflow2的程序。一些比较复杂的Tensorflow1的程序还是需要进行比较多的改写才能转成Tensorflow2的程序。 所以大家需要把Tensorflow1转成Tensorflow2的时候可以尝试使用，如果发现不行的话可以再自行修改。 2. Tensorflow基本操作 Tensorflow基本操作的代码如代码5-3所示。 代码5-3：Tensorflow基本操作 import tensorflow as tf # 定义一个变量 x = tf.Variable([1,2]) # 定义一个常量 a = tf.constant([3,3]) # 减法op sub = tf.subtract(x, a) # 加法op add = tf.add(x,sub) print(sub) print(add) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 162}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 163 结果输出为： tf.Tensor([-2 -1], shape=(2,), dtype=int32) tf.Tensor([-1  1], shape=(2,), dtype=int32)  3. 拟合线性函数 拟合线性函数的代码如代码5-4所示。 代码5-4：拟合线性函数（片段1） import tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用numpy生成100个从0-1的随机点，作为x x_data = np.random.rand(100) # 生成一些随机扰动 noise = np.random.normal(0,0.01,x_data.shape) # 构建目标值，符合线性分布 y_data = x_data*0.1 + 0.2 + noise # 画散点图 plt.scatter(x_data, y_data) plt.show() 结果输出为： \\n  代码5-4：拟合线性函数（片段2） # 构建一个顺序模型 # 顺序模型为keras中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # Dense为全连接层 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 163}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 164 # 在模型中添加一个全连接层 # units为输出神经元个数，input_dim为输入神经元个数 model.add(tf.keras.layers.Dense(units=1,input_dim=1)) # 设置模型的优化器和代价函数，学习率为0.03 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.03),loss='mse')  # 训练2001个批次 for step in range(2001):     # 训练一个批次数据，返回cost值     cost = model.train_on_batch(x_data,y_data)     # 每500个batch打印一次cost值     if step % 500 == 0:         print('cost:',cost)  # 使用predict对数据进行预测，得到预测值y_pred y_pred = model.predict(x_data)  # 显示随机点 plt.scatter(x_data,y_data) # 显示预测结果 plt.plot(x_data,y_pred,'r-',lw=3) plt.show() 结果输出为： cost: 0.33022374 cost: 0.0003510235 cost: 9.941429e-05 cost: 9.440048e-05 cost: 9.430057e-05 \\n  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 164}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 165 4.拟合非线性函数 拟合非线性函数的代码如代码5-5所示。 代码5-5：拟合非线性函数（片段1） import tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用numpy生成200个均匀分布的点，并新增一个维度 x_data = np.linspace(-0.5,0.5,200)[:,np.newaxis] # 生成一些跟x_data相同shape的随机值作为噪声数据 noise = np.random.normal(0,0.02,x_data.shape) # 构建目标值，符合非线性函数，另外再加上噪声值 y_data = np.square(x_data) + noise # 画散点图 plt.scatter(x_data,y_data) plt.show() 结果输出为： \\n  代码5-5：拟合非线性函数（片段2） # 构建一个顺序模型 # 顺序模型为keras中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # 因为要做非线性回归，所以需要一个带有隐藏层的神经网络 # 并且需要使用非线性的激活函数，比如tanh函数 # keras中input_dim只需要在输入层设置，后面的网络可以自动推断出该层对应的输入 # keras中定义网络结构已经默认设置好权值初始化，所以我们不需要额外进行设置 model.add(tf.keras.layers.Dense(units=10,input_dim=1,activation='tanh')) model.add(tf.keras.layers.Dense(units=1,activation='tanh')) \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 165}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 166 # 设置模型的优化器和代价函数，学习率为0.1 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.3),loss=\\'mse\\')  # 训练3001个批次 for step in range(3001):     # 训练一个批次数据，返回cost值     cost = model.train_on_batch(x_data,y_data)     # 每1000个batch打印一次cost值     if step % 1000 == 0:         # 定义一个2*2的图，当前是第i/1000+1个图         plt.subplot(2,2,step/1000+1)         # 把x_data喂到模型中获得预测值         prediction_value = model.predict(x_data)         # 画散点图         plt.scatter(x_data,y_data)         # 画模型预测曲线图         plt.plot(x_data,prediction_value,\\'r-\\',lw=5)         # 不显示坐标         plt.axis(\\'off\\')         # 图片的标题设置         plt.title(\"picture:\" + str(int(step/1000+1))) plt.show() 结果输出为： \\n 从结果中我们能看得出，随着权值的调整，模型的预测结果也在不断地调整，最终得到比较好的拟合效果。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 166}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 167 5.6 手写数字图片分类任务 5.6.1 MNIST数据集介绍 MNIST是一个手写数字的数据集。其中训练集有60000张图片，测试集有10000张图片，每一张图片包含28*28个像素。数据集的下载网址为：http://yann.lecun.com/exdb/mnist/。MNIST数据集的图片如图5.12 \\n 图5.12 MNIST数据集 MNIST数据集的标签是介于0-9的数字，有时候我们要把标签转化为独热编码(one-hot vectors)，然后再传给模型进行训练。 5.6.2 Softmax函数介绍 在多分类问题中，我们通常会使用softmax函数作为网络输出层的激活函数，softmax函数可以对输出值进行归一化操作，把所有输出值都转化为概率，所有概率值加起来等于1，softmax的公式为： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 167}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 168 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑥)(=exp\\t(𝑥()∑exp\\t(𝑥\\x81)\\x81(5.1) 例如某个神经网络有3个输出值，为[1,5,3]。 计算𝑒\"=2.718，𝑒°=148.413，𝑒$=20.086，𝑒\"+𝑒°+𝑒$=171.217。 𝑝1=¤±¤±\\x97¤²\\x97¤³=0.016，𝑝2=¤²¤±\\x97¤²\\x97¤³=0.867，𝑝3=¤³¤±\\x97¤²\\x97¤³=0.117。 所以加上softmax函数后数值变成了[0.016,0.867,0.117]。 例如手写数字识别的网络最后的输出结果本来是[-0.124,-4.083,-0.62,0.899,-1.193,-0.701,-2.834,6.925,-0.332,2.064]，加上softmax函数后会变成[0.001,0.0,0.001,0.002,0.0,0.0,0.0,0.987,0.001,0.008]。 5.6.3 简单MNIST数据集分类模型-没有高级封装 我们可以考虑先构建一个简单的神经网络， 这个网络只有输入层和输出层， 输入层有784个神经元， 对应每张图片的784个像素点， 输出层有10个神经元， 对应one-hot的标签值，如图5.13： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 168}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 169 图5.13 简单MNIST数据集分类模型 大家刚开始学习tensorflow，所以没有使用tf.keras高级封装的代码我也会准备一些给大家学习，代码5-6没有使用tf.keras来封装模型数据载入和模型训练的过程。 代码5-6：MNIST数据集分类模型-没有高级封装 import tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据x_train的数据形状为（60000，28，28） # 训练集标签y_train的数据形状为（60000） # 测试集数据x_test的数据形状为（10000，28，28） # 测试集标签y_test的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建dataset对象，使用dataset对象来管理数据 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期设置为1（把所有训练集数据训练一次称为训练一个周期） mnist_train = mnist_train.repeat(1) # 批次大小设置为32（每次训练模型传入32个数据进行训练） mnist_train = mnist_train.batch(32)  # 创建dataset对象，使用dataset对象来管理数据 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期设置为1（把所有训练集数据训练一次称为训练一个周期） mnist_test = mnist_test.repeat(1) # 批次大小设置为32（每次训练模型传入32个数据进行训练） mnist_test = mnist_test.batch(32)  # 模型定义 # 先用Flatten把数据从3维变成2维，(60000,28,28)->(60000,784) # 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 169}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 170 # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 计算平均值 train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 计算平均值 test_loss = tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')  # 我们可以用@tf.function装饰器来将python代码转成tensorflow的图表示代码，用于加速代码运行速度 # 定义一个训练模型的函数 @tf.function def train_step(data, label):     # 固定写法，使用tf.GradientTape()来计算梯度     with tf.GradientTape() as tape:         # 传入数据获得模型预测结果         predictions = model(data)         # 对比label和predictions计算loss         loss = tf.keras.losses.MSE(label, predictions)         # 传入loss和模型参数，计算权值调整         gradients = tape.gradient(loss, model.trainable_variables)         # 进行权值调整         optimizer.apply_gradients(zip(gradients, model.trainable_variables))         # 计算平均loss         train_loss(loss)         # 计算平均准确率         train_accuracy(label, predictions)      # 我们可以用@tf.function装饰器来将python代码转成tensorflow的图表示代码，用于加速代码运行速度 # 定义一个模型测试的函数 @tf.function def test_step(data, label):     # 传入数据获得模型预测结果     predictions = model(data)     # 对比label和predictions计算loss     t_loss = tf.keras.losses.MSE(label, predictions)     # 计算平均loss     test_loss(t_loss)     # 计算平均准确率 test_accuracy(label, predictions) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 170}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 171  # 训练10个周期（把所有训练集数据训练一次称为训练一个周期） EPOCHS = 10  for epoch in range(EPOCHS):     # 训练集循环60000/32=1875次     for image, label in mnist_train:         # 每次循环传入一个批次的数据和标签训练模型         train_step(image, label)     # 测试集循环10000/32=312.5->313次     for test_image, test_label in mnist_test:         # 每次循环传入一个批次的数据和标签进行测试         test_step(test_image, test_label)        # 打印结果     template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'     print(template.format(epoch+1,                           train_loss.result(),                            train_accuracy.result(),                           test_loss.result(),                            test_accuracy.result())) 结果输出为： Epoch 1, Loss: 0.017, Accuracy: 0.892, Test Loss: 0.0138, Test Accuracy: 0.909 Epoch 2, Loss: 0.015, Accuracy: 0.905, Test Loss: 0.0134, Test Accuracy: 0.911 Epoch 3, Loss: 0.014, Accuracy: 0.911, Test Loss: 0.0131, Test Accuracy: 0.913 Epoch 4, Loss: 0.0134, Accuracy: 0.914, Test Loss: 0.0129, Test Accuracy: 0.915 Epoch 5, Loss: 0.013, Accuracy: 0.917, Test Loss: 0.0127, Test Accuracy: 0.916 Epoch 6, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0126, Test Accuracy: 0.917 Epoch 7, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0125, Test Accuracy: 0.918 Epoch 8, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0124, Test Accuracy: 0.919 Epoch 9, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accuracy: 0.919 Epoch 10, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122,Test Accuracy: 0.92  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 171}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 172 5.6.4 简单MNIST数据集分类模型-keras高级封装  给大家介绍了没有使用高级封装的程序以后，下面要给大家介绍一下使用tf.keras高级封装的MNIST数据集分类程序，如代码5-7所示。 代码5-7：MNIST数据集分类模型-keras高级封装 import tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据x_train的数据形状为（60000，28，28） # 训练集标签y_train的数据形状为（60000） # 测试集数据x_test的数据形状为（10000，28，28） # 测试集标签y_test的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 # 先用Flatten把数据从3维变成2维，(60000,28,28)->(60000,784) # 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  # sgd定义随机梯度下降法优化器 # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.1) model.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 # 周期大小为10（把所有训练集数据训练一次称为训练一个周期） # 批次大小为32（每次训练模型传入32个数据进行训练） \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 172}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 173 # validation_data设置验证集数据 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test)) 程序的输出结果为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 2s 34us/sample - loss: 0.0374 - accuracy: 0.7822 - val_loss: 0.0214 - val_accuracy: 0.8802 Epoch 2/10 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0203 - accuracy: 0.8816 - val_loss: 0.0175 - val_accuracy: 0.8978 Epoch 3/10 60000/60000 [==============================] - 2s 32us/sample - loss: 0.0177 - accuracy: 0.8932 - val_loss: 0.0160 - val_accuracy: 0.9041 Epoch 4/10 60000/60000 [==============================] - 2s 31us/sample - loss: 0.0165 - accuracy: 0.8994 - val_loss: 0.0151 - val_accuracy: 0.9070 Epoch 5/10 60000/60000 [==============================] - 2s 31us/sample - loss: 0.0157 - accuracy: 0.9031 - val_loss: 0.0145 - val_accuracy: 0.9107 Epoch 6/10 60000/60000 [==============================] - 2s 32us/sample - loss: 0.0151 - accuracy: 0.9063 - val_loss: 0.0140 - val_accuracy: 0.9131 Epoch 7/10 60000/60000 [==============================] - 2s 33us/sample - loss: 0.0147 - accuracy: 0.9090 - val_loss: 0.0137 - val_accuracy: 0.9145 Epoch 8/10 60000/60000 [==============================] - 2s 33us/sample - loss: 0.0143 - accuracy: 0.9112 - val_loss: 0.0134 - val_accuracy: 0.9158 Epoch 9/10 60000/60000 [==============================] - 2s 34us/sample - loss: 0.0140 - accuracy: 0.9122 - val_loss: 0.0132 - val_accuracy: 0.9176 Epoch 10/10 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 173}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 174 60000/60000 [==============================] - 2s 36us/sample - loss: 0.0138 - accuracy: 0.9137 - val_loss: 0.0131 - val_accuracy: 0.9184 对比看来，使用了tf.keras高级封装的程序更简洁，同时也更容易理解，并且程序运行时的结果输出也更友好。 我们在程序运行时可以实时看到模型训练一共要训练多少个周期， 当前训练到第几个周期， 当前周期的进度条， 训练当前周期的剩余时间， 当前训练集的准确率和loss。训练完一个周期之后可以看到训练一个周期所花费的时间， 如果设置了验证集， 可以看到验证集的准确率和loss。 这些信息都是默认输出的， 当然我们也可以把fit方法中的参数verbose设置为0，让模型训练过程中不输出任何信息。不过推荐大家还是保持默认值berbose=1，毕竟看到这些输出信息更有利于我们了解模型的训练情况。 最后模型的测试集准确率大约是92%左右，并不是特别高。 如何可以进一步提升模型的效果，我们将在下一个章节介绍。            ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 174}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 175 第6章-网络优化方法 本章节内容我们将学习神经网络的一些优化方法，包括使用交叉熵代价函数，抵抗过拟合的几种方法和使用不同的模型优化器。这些模型优化方法有些可以比较有效的提升模型收敛速度或模型的效果，有些只是有可能提升模型的效果。所以我们在选择使用不同的网络优化方法的时候，还是需要根据实际的测试情况来进行选择。  6.1 交叉熵代价函数 我们在读高中的时候，每天都会做大量的练习，很多课后作业。但是很多题目我们做错以后，下次再见到这个题目的时候已经不记得了，所以会再次做错同样的题目。因为做错普通的课后作业练习题并不能引起我们的重视，所以印象不深刻。 如果是老师让我们单独上讲台做题目的话， 每次遇到这种情况我们都会比较紧张， 因为全班同学，包括我们的暗恋对象都在看着我们。如果在这个时候，我们把题目给做错了，那就丢人丢大了。而被我们做错的那个题目，也会让我们格外印象深刻，下次遇到这个题目的时候就不容易犯错了。 也就是说我们在犯了更大的错误以后，往往会学到更多东西，进步更快。理想的情况下，我们也希望神经网络可以从错误中快速学习，最好是错误越大，学习越快，因此均方差代价函数通常用在回归任务中，分类任务中我们会使用交叉熵（Cross Entropy）作为代价函数。 6.1.1 均方差代价函数的缺点 我们先来重新思考一下均方差代价函数。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 175}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 176 先看一个小例子，假如有一个简单的神经网络，它只有一个权值w和偏置b，一个输入x和一个输出y，激活函数为sigmoid函数，如图6.1所示。 \\n 图6.1 单输入单输出的简单神经网络 我们要训练这个网络做一个简单的事情，给定x，w和b的值，可以计算出网络输出值y，已知网络的目标值t，然后用梯度下降法来优化网络的参数w和b，使得网络的loss值不断减小。这里我们先把代价函数定义为之前我们学过的均方差代价函数： 𝐸=12𝑁(𝑇−𝑌)#=12𝑁?(𝑡(−𝑦()#P(A\"\\t\\t\\t\\t\\t\\t\\t\\t\\t(6.1)\\t第一次试验，x的值为1，w的初始值设置为0.6，b的初始值设置为0.9，目标值t的值为0，使用梯度下降法学习率0.15，训练300周期，网络的初始参数如图6.2所示。 \\n 图6.2 试验一初始状态 实验一训练了300周期后的状态如图6.3所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 176}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 177 图6.3 试验一训练300次之后的状态 实验一loss的变化如图6.4所示。 \\n 图6.4 试验一loss变化 第二次试验，x的值为1，w的初始值设置为1.85，b的初始值设置为1.85，目标值t的值为0，使用梯度下降法学习率0.15，训练300周期，网络的初始参数如图6.5所示。 \\n 图6.5 试验二初始状态 试验二训练了300周期后的状态如图6.6所示。 \\n 图6.6 试验二训练300次之后的状态 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 177}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 178 实验二loss的变化如图6.7所示。 \\n 图6.7 试验二loss变化 观察实验一和试验二我们会发现试验结果和我们理想的结果不同，我们理想的学习效果应该是误差越大，学习得越快。 从两个试验的loss曲线我们能看到它们不同的学习速度。实验一的初始输出为0.82，距离目标值0的误差相对比较小，但是初始学习速度比较快。实验二的初始输出为0.99，距离目标值0的误差相对比较大，但是初始学习速度比较慢。这个现象不仅仅是在这个小实验中，也会在其他的神经网络应用中出现。我们想进一步理解这个现象，就要分析一下它的代价函数。当N=1时，二次代价函数为 𝐸=12(𝑦−𝑡)#(6.2) 其中E为代价函数，t为目标输出，y为神经网络的输出。 因为激活函数为sigmoid函数，符号为𝜎，所以𝑦=𝜎(𝑧)，𝑧=𝑤𝑥+𝑏。使用链式法则来求权重和偏置的偏导数可以得到： 𝜕𝐸𝜕𝑤=(𝑦−𝑡)𝜎R(𝑧)𝑥(6.3) 𝜕𝐸𝜕𝑏=(𝑦−𝑡)𝜎R(𝑧)(6.4) 把x=1以及t=0带入公式6.3和公式6.4，可以得到： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 178}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 179 𝜕𝐸𝜕𝑤=𝑦𝜎R(𝑧)(6.5) 𝜕𝐸𝜕𝑏=𝑦𝜎R(𝑧)(6.6) 从公式6.5和公式6.6我们可以看出，权值和偏置值的调整是跟激活函数的导数成正比的，我们可以回忆一下sigmoid函数的图像，如图6.8所示。 \\n 图6.8 sigmoid函数图像 从图中我们可以看出，当神经元的输出接近1和0的时候，曲线变得非常平，也就意味着在输出接近1和0的位置函数的导数接近于0。函数的导数接近于0，那么公式6.5和6.6的值就接近于0，其实就是代表网络的参数调节的速度非常慢，网络的优化速度非常慢。 sigmoid函数的导数为：𝑓′(𝑥)=𝑓(𝑥)[1−𝑓(𝑥)]，实验一的初始输出为0.82，初始导数为0.1476。实验二的初始输出为0.99，初始导数为0.0099。所以实验一中网络权值的初始调节速度要比实验二中网络权值的初始调节速度快。但是违反了我们误差越大，应该学习越快的直觉。 6.1.2 引入交叉熵代价函数 我们换一个思路，不改变激活函数而是改变代价函数，改用交叉熵代价函数： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 179}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 180 𝐸=−1𝑁?[𝑡(𝑙𝑛𝑦(+(1−𝑡()ln\\t(1−𝑦()]P(A\"(6.7) 其中N是训练数据的总数，y是网络的预测值，t是网络的目标值。 首先我们先观察一下这个函数的特性： 1. 当我们使用sigmoid激活函数的时候，y的取值范围是0-1之间，t的取值为0或1，所以代价函数的值是非负的。 2. 当目标值t=0时，预测值y越接近于0，代价函数的值E越小，E的最小值为0；当目标值t=0时， 预测值y越接近于1， 代价函数的值E越大，E的最大值为+∞。 3. 当目标值t=1时，预测值y越接近于1，代价函数的值E越小，E的最小值为0；当目标值t=1时， 预测值y越接近于0， 代价函数的值E越大，E的最大值为+∞。 综上所述，交叉熵的值是非负的，并且网络的预测值越接近于目标值，则交叉熵的值就越小，这些都是我们想要的代价函数的特性。均方差代价函数其实也是具备这些特性的。 接下来我们对交叉熵求w的偏导数，当N=1时有： 𝜕𝐸𝜕𝑤\\x81=−¶𝑡(𝜎(𝑧)(−(1−𝑡()1−𝜎(𝑧)(·𝜕𝜎𝜕𝑤\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−¶𝑡𝜎(𝑧)−(1−𝑡)1−𝜎(𝑧)·𝜎R(𝑧)𝑥\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=¶𝜎R(𝑧)𝑥\\x81𝜎(𝑧)\\x8e1−𝜎(𝑧)\\x8f·(𝜎(𝑧)−𝑡)(6.8) Sigmoid函数的导数为： 𝜎R(𝑧)=\\t𝜎(𝑧)\\x8e1−𝜎(𝑧)\\x8f(6.9) 所以： 𝜕𝐸𝜕𝑤\\x81=𝑥\\x81(\\t𝜎(𝑧)−𝑡)\\t\\t=𝑥\\x81(\\t𝑦−𝑡)(6.10) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 180}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 181 这是一个非常优美的公式，我们可以看出权重的学习速度是跟y-t成正比的。y-t就是网络的误差值，误差越大，网络的学习速度越快，这正是我们想要的。sigmoid函数与交叉熵配合使用可以加快网络收敛的速度。 6.1.3 交叉熵代价函数推导过程 以权值b为例，推导交叉熵代价函数，对E求b的偏导数有： 𝜕𝐸𝜕𝑏=𝜕𝐸𝜕𝑦∙𝜕𝑦𝜕𝑧∙𝜕𝑧𝜕𝑏\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=𝜕𝐸𝜕𝑦∙𝜎R(𝑧)∙𝜕(𝑤𝑥+𝑏)𝜕𝑏\\t=𝜕𝐸𝜕𝑦𝜎R(𝑧)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=𝜕𝐸𝜕𝑦𝜎(𝑧)\\x8e1−𝜎(𝑧)\\x8f\\t\\t\\t\\t\\t\\t\\t=𝜕𝐸𝜕𝑦𝑦(1−𝑦)(6.11) 我们希望b对E的导数是跟网络的误差y-t成正比的，因此我们可以让： 𝜕𝐸𝜕𝑏=𝜕𝐸𝜕𝑦𝑦(1−𝑦)=𝑦−𝑡(6.12) 即： 𝜕𝐸𝜕𝑦=𝑦−𝑡𝑦(1−𝑦)=−l𝑡𝑦−1−𝑡1−𝑦m(6.13) 对等式两侧求积分，可以得到： 𝐸=−[𝑡𝑙𝑛𝑦+(1−𝑡)ln(1−𝑦)]\\t(6.14) 公式6.14就是前面介绍的交叉熵函数。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 181}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 182 6.1.4 Softmax与对数似然代价函数 通过前面的内容我们可以知道sigmoid函数配合交叉熵代价函数的使用可以加快网络训练速度，而在处理多分类的任务时，我们经常会使用softmax函数作为输出层的激活函数。当我们使用softmax作为输出层的激活函数时， 与之匹配的代价为对数似然 （Log Likelihood）代价函数。 softmax函数与对数似然代价函数的组合跟sigmoid函数与交叉熵代价函数的组合类似。softmax函数与对数似然代价函数在处理二分类问题的时候可以简化为sigmoid函数与交叉熵代价函数的形式。 对数似然代价函数的公式为： 𝐸=−?𝑡(𝑙𝑜𝑔P(A\"(𝑦()(6.15) 其中，N表示一共有N个输出神经元， 也可以认为是N个分类，𝑡(表示第i个输出神经元的目标值，𝑦(表示第i个输出神经元预测值，取值范围是0-1之间。 假设把一个样本输入到网络中， 只有一个神经元对应了该样本的正确类别（样本的标签为one-hot格式） ， 那么这个神经元输出的概率值越高， 则公式6.15的代价函数的值就越小， 反之，代价函数的值就越大。 softmax的公式为： 𝑦(=e¹º∑𝑒¹»\\x81(6.16) 𝑦(表示输出层第i个神经元的输出，𝑧(表示输出层第i个神经元的输入，e表示自然常数，∑𝑒¹»\\x81表示输出层所有神经元的输入之和。 softmax的求导结果比较特别，需要分为两种情况： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 182}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 183 if\\tj=i:\\t𝜕𝑦(𝜕𝑧\\x81=𝜕le¹º∑𝑒¹»\\x81m𝜕𝑧\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=e¹º∙∑𝑒¹»\\x81−e¹º∙e¹º\\x8e∑𝑒¹»\\x81\\x8f#\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=e¹º∑𝑒¹»\\x81−e¹º∑𝑒¹»\\x81∙e¹º∑𝑒¹»\\x81\\t\\t\\t\\t\\t\\t\\t\\t=𝑦((1−𝑦()(6.17) if\\tj≠i:\\t𝜕𝑦(𝜕𝑧\\x81=𝜕le¹º∑𝑒¹»\\x81m𝜕𝑧\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=0∙∑𝑒¹»\\x81−e¹»∙e¹º\\x8e∑𝑒¹»\\x81\\x8f#\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−e¹»∑𝑒¹»\\x81∙e¹º∑𝑒¹»\\x81\\t\\t=−𝑦\\x81𝑦((6.18) 接下来我们对对数似然代价函数求w的偏导数： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 183}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 184 𝜕𝐸𝜕𝑤\\x81=𝜕𝐸𝜕𝑧\\x81∙𝜕𝑧\\x81𝜕𝑤\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=𝜕\\x8e∑𝑡(log\\t(𝑦()P(A\"\\x8f𝜕𝑧\\x81∙𝜕(𝑤\\x81𝑥\\x81+𝑏\\x81)𝜕𝑤\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−𝑥\\x81?𝑡(1𝑦(P(A\"𝜕𝑦(𝜕𝑧\\x81\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−𝑥\\x81\\x8b𝑡\\x811𝑦\\x81𝜕𝑦\\x81𝜕𝑧\\x81+?𝑡(1𝑦(P(¿\\x81𝜕𝑦(𝜕𝑧\\x81\\x8c\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\x8e应用𝑠𝑜𝑓𝑡𝑚𝑎𝑥的导数\\x8f\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−𝑥\\x81\\x94𝑡\\x811𝑦\\x81𝑦\\x81\\x8e1−𝑦\\x81\\x8f+?𝑡(1𝑦(P(¿\\x81\\x8e−𝑦\\x81𝑦(\\x8f\\x95\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−𝑥\\x81\\x8b𝑡\\x81−𝑡\\x81𝑦\\x81−?𝑡(𝑦\\x81P(¿\\x81\\x8c\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t=−𝑥\\x81>𝑡\\x81−𝑦\\x81?𝑡(P(A\"B=𝑥\\x81\\x8e𝑦\\x81−𝑡\\x81\\x8f(6.19) \\n公式6.19最后的∑𝑡(P(A\"表示所以输出的目标值累加，一般我们会把目标值转成one-hot的数据格式，所以∑𝑡(P(A\"的值为1。从对数似然代价函数的梯度公式我们也能看出，网络权值的调整是跟网络的误差相关的， 误差越大则网络训练速度越快， 跟交叉熵代价函数有类似的结果。 6.1.5 交叉熵程序 简单MNIST数据集分类模型-交叉熵的代码如代码6-1所示。 代码6-1：简单MNIST数据集分类模型-交叉熵（片段1） import tensorflow as tf from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 184}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 185 # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据x_train的数据形状为（60000，28，28） # 训练集标签y_train的数据形状为（60000） # 测试集数据x_test的数据形状为（10000，28，28） # 测试集标签y_test的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 # 先用Flatten把数据从3维变成2维，(60000,28,28)->(60000,784) # 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可 model1 = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  # sgd定义随机梯度下降法优化器，学习率0.1 # loss='mse'定义均方差代价函数 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 # model1用均方差代价函数，model2用交叉熵代价函数 sgd = SGD(0.1) model1.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy']) model2.compile(optimizer=sgd,               loss='categorical_crossentropy',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 # 周期大小为8（把所有训练集数据训练一次称为训练一个周期） epochs = 8 # 批次大小为32（每次训练模型传入32个数据进行训练） \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 185}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 186 batch_size=32 # validation_data设置验证集数据 # 先训练model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) # 再训练model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] - 2s 33us/sample - loss: 0.0515 - accuracy: 0.6711 - val_loss: 0.0295 - val_accuracy: 0.8530 Epoch 2/8 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0260 - accuracy: 0.8587 - val_loss: 0.0218 - val_accuracy: 0.8819 …… Epoch 8/8 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0162 - accuracy: 0.9020 - val_loss: 0.0150 - val_accuracy: 0.9091 Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] - 2s 35us/sample - loss: 0.4165 - accuracy: 0.8858 - val_loss: 0.3117 - val_accuracy: 0.9124 Epoch 2/8 60000/60000 [==============================] - 2s 33us/sample - loss: 0.3144 - accuracy: 0.9114 - val_loss: 0.2916 - val_accuracy: 0.9187 …... Epoch 8/8 60000/60000 [==============================] - 2s 32us/sample - loss: 0.2713 - accuracy: 0.9244 - val_loss: 0.2736 - val_accuracy: 0.9233  代码6-1：简单MNIST数据集分类模型-交叉熵（片段2） # 画出model1验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='mean_squared_error') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 186}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 187 # 画出model2验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='softmax_cross_entropy') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为： \\n history1.history和history2.history保存着mode1和model2训练过程中每个训练周期的训练集准确率和训练集loss以及验证集准确率和验证集loss。例如通过： history1.history['accuracy']可以获得model1的训练集准确率 history1.history['loss']可以获得model1的训练集loss history1.history['val_accuracy']可以获得model1的验证集准确率 history1.history['val_loss']可以获得model1的验证集loss 从输出结果的图中我们可以看出使用交叉熵代价函数来训练模型可以使得模型的收敛速度更快，更少的训练次数和更少的训练时间就可以使得模型得到更好的效果。所以在分类模型中我们通常都是使用交叉熵代价函数。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 187}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 188  6.2 过拟合（Over-Fitting） 6.2.1 什么是过拟合 拟合可以分为三种情况，欠拟合（Under-Fitting） ，正确拟合（Right-Fitting）以及过拟合（Over-Fitting） 。 过拟合在机器学习和深度学习中经常会出现， 简单说来其实就是我们所构建的模型在训练集中表现非常好，但是在测试集中表现得不够好。 图6.9表示的是回归问题中的欠拟合，正确拟合以及过拟合的情况。我们使用相同的训练集和不同的模型来做训练，第一幅图使用比较简单的模型，第二幅图使用合适的模型，第三幅图使用比较复杂的模型。 \\n 图6.9 回归中的三种拟合情况 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 188}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 189 在图6.9中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；第二幅图的拟合效果比较好，并且回归线比较平滑，模型属于正确拟合；第三幅图拟合的效果非常好，预测的回归线与真实的训练样本数据分布的误差几乎为0。假如我们把同样的模型应用到测试集中来做测试，如图6.10所示。 \\n 图6.10 把回归模型应用于测试集 图6.10我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中的表现就不是特别好。 在分类的任务中也有类似的情况。图6.11表示的是分类问题中的欠拟合，正确拟合以及过拟合的情况。 我们使用相同的训练集和不同的模型来做训练， 第一幅图使用比较简单的模型，第二幅图使用合适的模型，第三幅图使用比较复杂的模型： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 189}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 190 \\n 图6.11 分类中的三种拟合情况 在图6.11中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；第二幅图的拟合效果比较好，并且分类边界比较平滑，模型属于正确拟合；第三幅图拟合的效果非常好，分类的误差几乎为0。假如我们把同样的模型应用到测试集中来做测试，如图6.12所示。 \\n 图6.12把分类模型应用于测试集 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 190}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 191 图6.12我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中的表现就不是特别好。 模型的复杂度与模型误差的关系如图6.13所示。 \\n 图6.13 模型复杂度与模型误差的关系 模型复杂度在深度学习中主要指的是网络的层数以及每层网络神经元的各种，网络的层数越多越复杂，神经元的个数越多越复杂。从图6.13中我们可以看到，训练集的误差是随着模型复杂度的提升而不断降低的，测试集的误差是随着模型复杂度的提升而先下降后上升。训练集误差和测试集误差的曲线左端欠拟合的状态，训练误差和测试误差都比较高；中间部分是正确拟合的状态，训练误差和测试误差都比较低；右边部分是过拟合的状态，巡逻误差比较低，测试误差比较高。 6.2.2 抵抗过拟合的方法 常见的抵抗过拟合的方法有：增大数据集，提前停止(Early-Stopping)，Dropout，正则化等，标签平滑(label Smoothing)等。 这几种方法我们单独拿出来放在后面的小节中讲解。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 191}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 192  6.3 数据增强（Data Augmentation） 数据增强就是增加数据量，数据对于机器学习或者深度学习来说非常重要，有时候拥有更多的数据胜过拥有一个好的模型。一般来说更多的数据参与训练，训练得到的模型就更好。如果数据太少，而我们构建的神经网络又太复杂的话就比较容易产生过拟合的现象。 例如在图像领域， 数据增加的手段经常被使用， 我们可以通过对图片进行一些调整来生成更多图片，常用的手段如下： 1. 旋转 | 反射变换(Rotation/reflection): 随机旋转图像一定角度; 改变图像内容的朝向。 2. 翻转变换(flip): 沿着水平或者垂直方向翻转图像。 3. 缩放变换(zoom): 按照一定的比例放大或者缩小图像。 4. 平移变换(shift): 在图像平面上对图像以一定方式进行平移。 5. 尺度变换(scale): 对图像按照指定的尺度因子, 进行放大或缩小。 6. 对比度变换(contrast): 在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变. 对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化。 7. 噪声扰动(noise): 对图像的每个像素RGB进行随机扰动, 常用的噪声模式是椒盐噪声和高斯噪声。 8. 颜色变换(color): 对训练集图像的颜色进行一些有规律的调整。 比如水平翻转，如图6.14所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 192}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 193 \\n 图6.14 水平翻转 比如旋转一定角度，然后再随机裁剪，如图6.15所示。 \\n 图6.15 旋转裁剪 比如调整图像的颜色，如图6.16所示。 \\n 图6.16 颜色变换 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 193}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 194 Tensorflow中有封装好的程序可以非常方便的帮助我们实现图像数据增强的功能，如代码6-2所示。 代码6-2：图像数据增强 from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img import numpy as np  datagen = ImageDataGenerator(     rotation_range = 40,     # 随机旋转度数     width_shift_range = 0.2, # 随机水平平移     height_shift_range = 0.2,# 随机竖直平移     rescale = 1/255,         # 数据归一化     shear_range = 30,       # 随机错切变换     zoom_range = 0.2,        # 随机放大     horizontal_flip = True,  # 水平翻转     brightness_range = (0.7,1.3), # 亮度变化     fill_mode = 'nearest',   # 填充方式 )  # 载入图片 img = load_img('image.jpg') # 把图片变成array，此时数据是3维 # 3维(height,width,channel) x = img_to_array(img) # 在第0个位置增加一个维度 # 我们需要把数据变成4维，然后再做数据增强 # 4维(1,height,width,channel) x = np.expand_dims(x,0) # 生成20张图片 i = 0 # 生成的图片都保存在temp文件夹中，文件名前缀为new_cat,图片格式为jpeg for batch in datagen.flow(x, batch_size=1, save_to_dir='temp', save_prefix='new_cat', save_format='jpeg'):     i += 1     if i==20:         break  使用1张原始图片，程序运行后在temp文件夹中产生了20张差异较大的图片，如图6.17所示。 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 194}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 195 \\n 图6.17 图像数据增强  6.4 提前停止训练（Early-Stopping） Early-Stopping是一种提前结束训练的策略用来防止过拟合。 在训练模型的时候，我们往往会设置一个比较大的迭代次数n。一般的做法是记录到目前为止最好的测试集准确率p，之后连续m个周期没有超过最佳测试集准确率p时，则可以认为p不再提高了， 此时便可以提前停止迭代(Early-Stopping)。 代码6-3是在代码5-7的基础上进行修改得到，加上了Early-Stopping的功能。 代码6-3：简单MNIST数据集分类模型- Early_Stoppping import tensorflow as tf from tensorflow.keras.optimizers import SGD from tensorflow.keras.callbacks import EarlyStopping # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据x_train的数据形状为（60000，28，28） # 训练集标签y_train的数据形状为（60000） \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 195}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 196 # 测试集数据x_test的数据形状为（10000，28，28） # 测试集标签y_test的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 # 先用Flatten把数据从3维变成2维，(60000,28,28)->(60000,784) # 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  # sgd定义随机梯度下降法优化器 # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.5) model.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # EarlyStopping是Callbacks的一种，callbacks用于指定在每个epoch或batch开始和结束的时候进行哪种特定操作 # monitor='val_accuracy',监控验证集准确率 # patience=5,连续5个周期没有超过最高的val_accuracy值，则提前停止训练 # verbose=1，停止训练时提示early stopping early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)  # 传入训练集数据和标签训练模型 # 周期大小为100（把所有训练集数据训练一次称为训练一个周期） # 批次大小为32（每次训练模型传入32个数据进行训练） # validation_data设置验证集数据 # callbacks=[early_stopping]设置early_stopping model.fit(x_train, y_train,            epochs=100,            batch_size=32,             validation_data=(x_test,y_test),        callbacks=[early_stopping]) 结果输出为： Train on 60000 samples, validate on 10000 samples \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 196}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 197 Epoch 1/100 60000/60000 [==============================] - 2s 33us/sample - loss: 0.0267 - accuracy: 0.8420 - val_loss: 0.0167 - val_accuracy: 0.8999 Epoch 2/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0164 - accuracy: 0.8993 - val_loss: 0.0145 - val_accuracy: 0.9095 Epoch 3/100 …… Epoch 30/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0108 - accuracy: 0.9329 - val_loss: 0.0111 - val_accuracy: 0.9293 Epoch 31/100 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0108 - accuracy: 0.9330 - val_loss: 0.0111 - val_accuracy: 0.9299 Epoch 32/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9332 - val_loss: 0.0110 - val_accuracy: 0.9295 Epoch 33/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.9299 Epoch 34/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9344 - val_loss: 0.0110 - val_accuracy: 0.9296 Epoch 35/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0106 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.9286 Epoch 36/100 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0106 - accuracy: 0.9347 - val_loss: 0.0110 - val_accuracy: 0.9299 Epoch 00036: early stopping 虽然我们设置了让模型训练100个周期，不过在训练到第31周期时模型得到了一个val_accuracy为0.9299。之后连续5个周期模型的val_accuracy都没有超过第31周期的val_', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 197}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 198 accuracy值。我们可以认为继续训练模型可能也不会得到更好的结果了，反而可能会出现过拟合的情况，所以就让模型提前停止训练了。  6.5 Dropout 6.5.1 Dropout介绍 Dropout也是一种用于抵抗过拟合的技术，它试图改变网络本身来对网络进行优化。我们先来了解一下它的工作机制， 当我们训练一个普通的神经网络时， 网络的结构可能如图6.18所示。 \\n 图6.18 普通的神经网络[1] Dropout通常是在神经网络隐藏层的部分使用，使用的时候会临时关闭掉一部分的神经元，我们可以通过一个参数来控制神经元被关闭的概率，网络结构如图6.19所示。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 198}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 199 \\n 图6.19使用Dropout的神经网络[1] 更详细的流程如下： 1. 在模型训练阶段我们可以先给Dropout参数设置一个值，例如0.4。意思是大约60%的神经元是工作的，大约40%神经元是不工作的。 2. 给需要进行Dropout的神经网络层的每一个神经元生成一个0-1的随机数(一般是对隐藏层进行Dropout)。如果神经元的随机数小于0.6，那么该神经元就设置为工作状态的；如果神经元的随机数大于等于0.6， 那么该神经元就设置为不工作的， 不工作状态的意思就是不参与计算和训练，可以当这个神经元不存在。 3. 设置好一部分神经元工作一部分神经元不工作之后， 我们会发现神经网络的输出值会发现变化，如图6.18中，如果隐藏层有一半不工作，那么网络输出值就会比原来的值要小，因为计算WX+b时，如果W矩阵中，有一部分的值变成0，那么最后的计算结果肯定会变小。 所以为了使用Dropout的网络层神经元信号的总和不会发生太大的变化，对于工作的神经元的输出信号还需要除以0.4。 4. 训练阶段重复1-3步骤，每一次都随机选择部分的神经元参与训练。 5. 在测试阶段所有的神经元都参与计算。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 199}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 200 Dropout为什么会起作用呢？这个问题很难通过数学推导来证明。我们在介绍ReLU激活函数的时候有提到过神经网络的信号是冗余的， 神经网络在做预测时并不需要隐藏层所有神经元都工作， 只需要一部分隐藏层神经元工作即可。 我们可以抽象地来理解Dropout， 当我们使用Dropout的时候，就有点像我们在训练很多不同的结构更简单的神经网络，最后测试阶段再综合所有的网络结构得到结果。或者另外一种理解方式是我们使用Dropout的时候减少了神经元之间的相互关联，同时强制网络使用更少的特征来做预测，可以增加模型的健壮性。 除了这两种理解方式之外还可以有其他的很多理解方式， 深度学习中很多技巧都是不能用数学推导得到同时又比较难理解的。 但重要的是这些技巧在实际应用中可以帮助我们得到更好的结果。 Dropout比较适合应用于只有少量数据但是需要训练复杂模型的场景，这类场景在图像领域比较常见，所以Dropout经常用于图像领域。 6.5.2 Dropout程序 这部分我们将看到一个Dropout在MNIST数据集识别中的应用，如代码6-4所示。 代码6-4：MNIST数据集分类模型-Dropout（片段1） import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 200}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 201 y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义，model1使用Dropout # Dropout(0.4)表示隐藏层40%神经元不工作 model1 = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dropout(0.4),         Dense(units=100,activation='tanh'),         Dropout(0.4),         Dense(units=10,activation='softmax')         ])  # 在定义一个一模一样的模型用于对比测试，model2不使用Dropout # Dropout(0)表示隐藏层所有神经元都工作，相当于没有Dropout model2 = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dropout(0),         Dense(units=100,activation='tanh'),         Dropout(0),         Dense(units=10,activation='softmax')         ])  # sgd定义随机梯度下降法优化器 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd,               loss='categorical_crossentropy',               metrics=['accuracy']) model2.compile(optimizer=sgd,               loss='categorical_crossentropy',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 # 周期大小为30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为32（每次训练模型传入32个数据进行训练） batch_size=32 # validation_data设置验证集数据 # 先训练model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 201}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 202 # 再训练model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s 62us/sample - loss: 0.4170 - accuracy: 0.8737 - val_loss: 0.2087 - val_accuracy: 0.9370 Epoch 2/30 60000/60000 [==============================] - 3s 54us/sample - loss: 0.2808 - accuracy: 0.9165 - val_loss: 0.1627 - val_accuracy: 0.9498 …… Epoch 30/30 60000/60000 [==============================] - 3s 52us/sample - loss: 0.1006 - accuracy: 0.9689 - val_loss: 0.0824 - val_accuracy: 0.9773 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - loss: 0.2552 - accuracy: 0.9234 - val_loss: 0.1505 - val_accuracy: 0.9542 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - loss: 0.1163 - accuracy: 0.9642 - val_loss: 0.1073 - val_accuracy: 0.9664 …… Epoch 30/30 60000/60000 [==============================] - 3s 57us/sample - loss: 4.9737e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9818  代码6-4：MNIST数据集分类模型-Dropout（片段2） # 画出model1验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Dropout') # 画出model2验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 202}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 203 # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为： \\n 模型训练结果前1-30周期是使用了Dropout的结果，后面的1-30周期是没有使用Dropout的结果。 观察结果我们发现使用了Dropout之后训练集准确率和验证集的准确率相差并不是很大，所以能看出Dropout确实是可以起到抵抗过拟合的作用。我们还可以发现一个有趣的现象就是前1-30周期model1的验证集准确率还高于训练集的准确率， 这是因为模型在计算训练集准确率的时候模型还在使用Dropout，在计算验证集准确率的时候已经不使用Dropout了。使用Dropout的时候模型的准确率会稍微降低一些。同时我们也可以发现，不用Dropout的model2中测试集的准确率看起来比使用Dropout的model1要更高。 事实上使用Dropout之后模型的收敛速度会变慢一些，所以需要更多的训练次数才能得到最好的结果。代码6-3中不用Dropout的model2验证集训练30个周期最高准确率大概是98.2%左右；使用Dropout的model1如果训练足够多的周期，验证集最高准确率可以达到98.8%左右。  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 203}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 204 6.6 正则化（Regularization） 6.6.1 正则化介绍 正则化也叫作规范化，通常用得比较多的方式是L1正则化和L2正则化。L1和L2正则化的使用实际上就是在普通的代价函数（例如均方差代价函数或交叉熵代价函数）后面加上一个正则项，例如加上了L1正则项的交叉熵为： 𝐸=−1𝑁?[𝑡(𝑙𝑛𝑦(+(1−𝑡()ln\\t(1−𝑦()]P(A\"+𝜆2𝑁?|𝑤|x(6.20)  加上L2正则项的交叉熵为： 𝐸=−1𝑁?[𝑡(𝑙𝑛𝑦(+(1−𝑡()ln\\t(1−𝑦()]P(A\"+𝜆2𝑁?𝑤#x(6.21) 公式6.21可以写成： 𝐸=𝐸<+𝜆2𝑁?𝑤#x(6.22)  其中E<是原始的代价函数，𝜆是正则项的系数，𝜆是一个大于0的数，𝜆的值越大那么正则项的影响就越大，𝜆的值越小正则项的影响也就越小，当𝜆为0时，相当于正则项不存在。N表示样本个数。w代表所有的权值参数和偏置值。 我们训练模型的过程中实际上就是使用梯度下降法来最小化代价函数的过程，交叉熵代价函数中的t和y的值越接近，那么代价函数的值就越接近于0。观察带有正则项的代价函数表达式我们可以知道，最小化代价函数的过程中不仅要使得t的值接近于y，还要使得神经网络的权值参数w的值趋近于0。 因为不管是对于L1正则项Â#P∑|𝑤|x还是对于L2正则项Â#P∑𝑤#x，正则项的值都是大于0的，所以最小化正则项的值，实际上就是让w的值接近于0。 L1正则项和L2正则项的区别在于： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 204}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 205 L1正则项会使得神经网络中的很多权值参数变为0，如果神经网络中很多的权值都是0的话那么可以认为网络的复杂度降低了，拟合能力也降低了，因此不容易出现过拟合的情况。 L2正则项会使得神经网络的权值衰减， 权值参数变为接近于0的值， 注意这里的接近于0不是等于零，L2正则化很少会使权值参数等于0。L2正则项之所以有效是因为权值参数w变得很小之后WX+b的计算也是会变成一个接近于0的值。 我们知道在使用sigmoid(x)函数或者tanh(x)函数时，当x的取值在0附近时，函数的曲线是非常接近于一条直线的，如图6.20所示。 \\n 图6.20 tanh函数图像 所以神经网络中增加了很多线性特征减少了很多非线性的特征，网络的复杂度降低了，因此不容易出现过拟合。 6.6.2 正则化程序 这部分我们将看到一个正则化在MNIST数据集识别中的应用，如代码6-5所示。 代码6-5：MNIST手写数字识别-正则化（片段1） import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 205}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 206 import matplotlib.pyplot as plt import numpy as np # 使用l1或l2正则化 from tensorflow.keras.regularizers import l1,l2  # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义，model1使用l2正则化 # l2(0.0003)表示使用l2正则化，正则化系数为0.0003 model1 = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh',kernel_regularizer=l2(0.0003)),         Dense(units=100,activation='tanh',kernel_regularizer=l2(0.0003)),         Dense(units=10,activation='softmax',kernel_regularizer=l2(0.0003))         ])  # 在定义一个一模一样的模型用于对比测试，model2不使用正则化 model2 = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dense(units=100,activation='tanh'),         Dense(units=10,activation='softmax')         ])  # sgd定义随机梯度下降法优化器 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd,               loss='categorical_crossentropy',               metrics=['accuracy']) model2.compile(optimizer=sgd,               loss='categorical_crossentropy',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 206}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 207 # 周期大小为30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为32（每次训练模型传入32个数据进行训练） batch_size=32 # 先训练model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) # 再训练model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s 69us/sample - loss: 0.4083 - accuracy: 0.9208 - val_loss: 0.2928 - val_accuracy: 0.9525 Epoch 2/30 60000/60000 [==============================] - 4s 59us/sample - loss: 0.2626 - accuracy: 0.9601 - val_loss: 0.2285 - val_accuracy: 0.9662 …… Epoch 30/30 60000/60000 [==============================] - 4s 60us/sample - loss: 0.1380 - accuracy: 0.9835 - val_loss: 0.1492 - val_accuracy: 0.9796 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 56us/sample - loss: 0.2563 - accuracy: 0.9222 - val_loss: 0.1415 - val_accuracy: 0.9568 Epoch 2/30 60000/60000 [==============================] - 3s 53us/sample - loss: 0.1178 - accuracy: 0.9634 - val_loss: 0.1115 - val_accuracy: 0.9657 …… Epoch 30/30 60000/60000 [==============================] - 3s 49us/sample - loss: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9817  代码6-5：MNIST手写数字识别-正则化（片段2） # 画出model1验证集准确率曲线图 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 207}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 208 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='L2 Regularization') # 画出model2验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为： \\n 前1-30周期是使用l2正则化的model1的结果，后1-30周期是不使用正则化的model2的结果。从结果上看，使用正则化后model1的训练集准确率和验证集准确率相差不大，说明正则化确实是可以起到抵抗过拟合的作用。但是使用正则化之后验证集准确率的结果并不是非常理想，说明正则化并不是适用于所有场景。在神经网络结构比较复杂，训练数据量比较少的时候，使用正则化效果会比较好。如果网络不算太复杂的话，任务比较简单的时候，使用正则化可能准确率反而会下降。对于Dropout来说也有类似的情况。所以Dropout和正则化需要根据实际使用情况的好坏来决定是否使用。  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 208}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 209 6.7 标签平滑（Label Smoothing） 6.7.1 标签平滑(Label Smoothing)介绍 标签平滑 （label smoothing） 也称为标签平滑正则化 （label-smoothing regularization），简称LSR。从名字就可以看出标签平滑也是一种正则化策略。 我们在做分类模型的时候通常会把标签变成独热编码（one-hot）， 但 是 变 成 独 热 编 码 的标签在模型训练时会使得模型变得“极度自信” ， 容易产生过拟合。 独热编码 （one-hot）可能存在的问题我给大家举个例子大家就容易理解了，如图6.21所示是我写的一个数字。 \\n 图6.21 一个数字 这个数字你能说它100%就是6吗，不一定吧，它也有点像2，说不定还是1或者7只不过手滑了。所以让模型非常自信的认为图中的数字就是6，独热编码(0,0,0,0,0,0,1,0,0,0)，不一定是合适的。可能把它的标签改成(0,0.02,0.2,0.01,0.01,0.01,0.7,0.03,0.01,0.01)会比较好一点。 在MNIST数据集里面实际上确实有一些数字会写得比较奇怪，让人也很难分辨，其它数据集也会有类似的问题，所以让模型“过度自信”就不一定是好事了。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 209}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 210 标签平滑的处理方式很简单， 给大家举一个具体的例子大家就知道了。 我们需要设置一个平滑系数，比如0.1，假设一共有10个种类。某个数据的真实标签为： (0,0,0,0,0,1,0,0,0,0) 经过标签平滑处理以后的标签为： (0.01,0.01,0.01,0.01,0.01,0.91,0.01,0.01,0.01,0.01) 也就类似于下面程序，label_smoothing为平滑系数： new_onehot_labels = onehot_labels * (1 - label_smoothing)                    + label_smoothing / num_classes 6.7.2 标签平滑（Label Smoothing）程序 实现MNIST手写数字识别-标签平滑的代码如代码6-6所示。 代码6-6：MNIST手写数字识别-标签平滑（片段1） import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD from tensorflow.keras.losses import CategoricalCrossentropy import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义，model1不用label smoothing model1 = Sequential([         Flatten(input_shape=(28, 28)), ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 210}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 211         Dense(units=200,activation='tanh'),         Dense(units=100,activation='tanh'),         Dense(units=10,activation='softmax')         ])  # 在定义一个一模一样的模型用于对比测试，model2使用label smoothing model2 = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dense(units=100,activation='tanh'),         Dense(units=10,activation='softmax')         ])  # model1不用label smoothing loss1 = CategoricalCrossentropy(label_smoothing=0) # model2使用label smoothing loss2 = CategoricalCrossentropy(label_smoothing=0.1)  # sgd定义随机梯度下降法优化器 # loss定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd,               loss=loss1,               metrics=['accuracy']) model2.compile(optimizer=sgd,               loss=loss2,               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 # 周期大小为30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为32（每次训练模型传入32个数据进行训练） batch_size=32 # 先训练model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) # 再训练model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 211}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 212 60000/60000 [==============================] - 4s 62us/sample - loss: 0.2526 - accuracy: 0.9235 - val_loss: 0.1460 - val_accuracy: 0.9571 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - loss: 0.1139 - accuracy: 0.9659 - val_loss: 0.0915 - val_accuracy: 0.9700 …… Epoch 30/30 60000/60000 [==============================] - 3s 50us/sample - loss: 4.9963e-04 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9816 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - loss: 0.7274 - accuracy: 0.9243 - val_loss: 0.6323 - val_accuracy: 0.9572 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - loss: 0.6139 - accuracy: 0.9663 - val_loss: 0.6093 - val_accuracy: 0.9654 …… Epoch 30/30 60000/60000 [==============================] - 3s 51us/sample - loss: 0.5127 - accuracy: 0.9996 - val_loss: 0.5527 - val_accuracy: 0.9817  代码6-6：MNIST手写数字识别-标签平滑（片段2） # 画出model1验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='without LSR') # 画出model2验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='LSR') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 212}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 213 \\n  从结果看来使用标签平滑label_smoothing(LSR)后结果稍微好一点点的， 不过不太明显。其实标签平滑label_smoothing作为一个优化策略也并不是每次都能使结果更好，不过它有机会可以让结果更好，所以有时候也值得我们尝试用一下。  6.8 优化器（Optimizer） 目前在tf.keras.optimizers中有下面这些优化器可以使用： Adadelta Adagrad Adam Adamax Ftrl Nadam RMSprop SGD \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 213}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 214 优化器的种类很多， 在Keras中只包含了部分常用的优化器， 不是全部。 之前我们经常使用的优化器是随机梯度下降法 （SGD）， 使用SGD算法来最小化代价函数。 其实其他的一些优化器的基础也是梯度下降法，只不过分别做了一些不同的调整或优化。 下面我们选几种常用的优化器来重点介绍。 6.8.1 梯度下降法SGD 梯度下降法有三种常见的变形，BGD,SGD,MBGD。我们通常把梯度下降法称为随机梯度下降法SGD，但是梯度下降法通常的用的是MBGD算法。 BGD是Batch gradient descent， 表示每次训练都采用整个训练集数据来优化模型。BGD的优点是每次训练都考虑所有的样本， 所以模型优化的方向会比较正确；缺点是每次训练都需要计算大量的数据，所以模型训练的速度比较慢。 SGD是Stochastic gradient descent，表示每次训练都选择训练集中的一个样本来优化模型。SGD的优点是每次只计算一个样本，权值调整速度比较快；缺点是每次只考虑了一个样本，所以模型优化的方向很可能是错误的。 MBGD是Mini-batch gradient descent，表示每次训练都选择训练集中一个批次的数据来优化模型，这里的一个批次常用的取值是32，64等，当然如果取其他的数值也可以。MBGD相当于是结合了BGD和SGD两者的优点，采用一个小批次的数据量来训练模型，这样训练的速度比较快， 同时模型优化的方向也比较正确。 所以目前带有小批次的训练方法是最主流的训练方法。一般我们提到梯度下降法，或者随机梯度下降法SGD的时候，默认就是使用MBGD的方法。 梯度下降法的公式为： 𝑊Ã=𝑊Ã\\x7f\"−𝜂𝛻x𝑓(𝑊Ã\\x7f\")(6.23) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 214}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 215 其中t表示第t时刻，𝜂表示学习率，𝛻x𝑓(𝑊Ã\\x7f\")表示t-1时刻对代价函数f求W的导数。 6.8.2 Momentum Momentum是模拟物理中动量的概念，积累之前的动量来替代真正的梯度。 Momentum的公式为： 𝑉Ã=𝛾𝑉Ã\\x7f\"+𝜂𝛻x𝑓(𝑊Ã\\x7f\")(6.24) 𝑊Ã=𝑊Ã\\x7f\"−𝑉Ã(6.25) 𝛾为动力项， 通常设置为0.9。 当前权值的改变会受到上一次权值改变的影响， 类似于小球向下滚动的时候带上了惯性。这样可以加快小球的向下的速度，同时可以抑制小球振荡。 6.8.3 NAG(Nesterov Accelerated Gradient) NAG的公式为： 𝑉Ã=𝛾𝑉Ã\\x7f\"+𝜂𝛻x𝑓(𝑊Ã\\x7f\"−𝛾𝑉Ã\\x7f\")(6.26) 𝑊Ã=𝑊Ã\\x7f\"−𝑉Ã(6.27) 𝛾为动力项，通常设置为0.9。𝑊Ã\\x7f\"−𝛾𝑉Ã\\x7f\"用来近似代价函数下一步的值，则计算的梯度不是当前位置的梯度，而是下一个位置的梯度。NAG相当于是一个预先知道正确方向的更聪明的小球。 Momentum和NAG都是为了使得梯度更新更加灵活，不过学习率的设置仍然是一个问题，下面介绍的几种优化器针对学习率的问题做出优化，具有自适应学习率的能力。 6.8.4 Adagrad Adagrad的公式为： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 215}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 216 𝐺Ã=𝐺Ã\\x7f\"+𝛻x𝑓(𝑊Ã\\x7f\")#(6.28) 𝑊Ã=𝑊Ã\\x7f\"−𝜂g𝐺Ã\\x7f\"+𝜀∙𝛻x𝑓(𝑊Ã\\x7f\")(6.29) ε的作用是避免分母为0，取值一般是10\\x7fÉ。Adagrad其实是对学习率进行了一个约束。Adagrad主要的优势是人为设定一个学习率后，这个学习率可以自动调节。它的缺点在于，随着迭代次数的增多，学习率也会越来越低，最终会趋向于0。 6.8.5 Adadelta Adadelta的公式为： 𝐺Ã=𝛾𝐺Ã\\x7f\"+(1−𝛾)𝛻x𝑓(𝑊Ã\\x7f\")#(6.29) 𝐸Ã=𝛾𝐸Ã\\x7f\"+(1−𝛾)(∆𝑊Ã)#(6.30) ∆𝑊Ã=−g𝐸Ã\\x7f\"+𝜀g𝐺Ã+𝜀𝛻x𝑓(𝑊Ã)(6.31) 𝑊Ã=𝑊Ã\\x7f\"+∆𝑊Ã\\x7f\"(6.32) 𝛾通常取0.9，Adadelta算是对Adagrad的改进，此时Adadelta已经不用依赖于全局学习率了。 6.8.6 RMRprop RMSprop可以算作Adadelta的一个特例，RMSprop的公式为： 𝐺Ã=𝛾𝐺Ã\\x7f\"+(1−𝛾)𝛻x𝑓(𝑊Ã\\x7f\")#(6.33) 𝑊Ã=𝑊Ã\\x7f\"−𝜂g𝐺Ã\\x7f\"+𝜀∙𝛻x𝑓(𝑊Ã\\x7f\")(6.34) 𝛾通常取0.9，RMSprop依然依赖于全局学习率，RMSprop也算是Adagrad的一种发展。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 216}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 217 6.8.7 Adam Adam(Adaptive Moment Estimation)本质上是带有动量项的RMSprop，Adam的公式为： 𝑚Ã=𝛽\"𝑚Ã\\x7f\"+(1−𝛽\")𝛻x𝑓(𝑊Ã)(6.35) 𝑣Ã=𝛽#𝑣Ã\\x7f\"+(1−𝛽#)𝛻x𝑓(𝑊Ã)#(6.36) \\t𝑚ÌÃ=𝑚Ã1−𝛽\"Ã(6.37) \\t𝑣ÍÃ=𝑣Ã1−𝛽#Ã(6.38) 𝑊Ã=𝑊Ã\\x7f\"−𝜂\\t𝑚ÌÃg\\t𝑣ÍÃ+𝜀(6.39) 𝛽\"通常取0.9, 𝛽#通常取0.999。其中𝑚Ã，𝑣Ã分别是对梯度的一阶矩估计和二阶矩估计，可以看作对期望𝐸|𝛻𝑤𝑓(𝑊𝑡)|，𝐸Î𝛻𝑤𝑓(𝑊𝑡)2Î的估计；\\t𝑚ÌÃ，\\t𝑣ÍÃ是对𝑚Ã，𝑣Ã的校正， 这样可以近似为对期望的无偏估计。Adam大多数情况下效果都比较好， 所以目前用得最多的优化器就是Adam。Adam与其他一些优化器在训练MNIST数据集时的对比，如图6.22所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 217}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 218 图6.22 Adam与其他优化器对比[2] 从图6.22中我们能看出来，在使用多层神经网络训练MNIST数据集时，Adam的优化速度是最快的。 6.8.8 优化器程序 如代码6-7所示，这里给出一个使用Adam优化器的例子，如果想使用其他优化器也类似，调用tensorflow.keras.optimizers里面的优化器即可。 代码6-7：MNIST数据集分类模型-优化器（片段1） import tensorflow as tf from tensorflow.keras.optimizers import SGD,Adam import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 model1 = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  # 定义sgd优化器，学习率0.1 sgd = SGD(0.1) # 定义Adam优化器，学习率0.001,Adam优化器学习率通常较低 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 218}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 219 adam = Adam(0.001) # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 # model1用Adam优化器，model2用sgd优化器 model1.compile(optimizer=adam,               loss='mse',               metrics=['accuracy']) model2.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 # 周期大小为6（把所有训练集数据训练一次称为训练一个周期） epochs = 6 # 批次大小为32（每次训练模型传入32个数据进行训练） batch_size=32 # validation_data设置验证集数据 # 先训练model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) # 再训练model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 2s 36us/sample - loss: 0.0196 - accuracy: 0.8819 - val_loss: 0.0131 - val_accuracy: 0.9175 Epoch 2/6 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0129 - accuracy: 0.9182 - val_loss: 0.0118 - val_accuracy: 0.9241 …… Epoch 6/6 60000/60000 [==============================] - 2s 31us/sample - loss: 0.0107 - accuracy: 0.9327 - val_loss: 0.0109 - val_accuracy: 0.9316 Train on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 3s 47us/sample - loss: 0.0499 - accuracy: 0.6986 - val_loss: 0.0285 - val_accuracy: 0.8521 Epoch 2/6 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 219}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 220 60000/60000 [==============================] - 2s 29us/sample - loss: 0.0257 - accuracy: 0.8583 - val_loss: 0.0216 - val_accuracy: 0.8789 …… Epoch 6/6 60000/60000 [==============================] - 2s 34us/sample - loss: 0.0173 - accuracy: 0.8953 - val_loss: 0.0160 - val_accuracy: 0.9033  代码6-7：MNIST数据集分类模型-优化器（片段2） # 画出model1验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Adam') # 画出model2验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='SGD') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为： \\n  从结果对比我们可以看到使用Adam优化器之后模型的收敛速度加快了很多，最后得到了更好的训练效果。  这一章节我们学习了很多模型优化方法，使用这些模型优化方法把模型训练好以后我们还需要把模型保存下来。如何保存模型将是我们下一章节要介绍的内容。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 220}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 221  6.9参考文献 [1] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural networks from overfitting[J]. The journal of machine learning research, 2014, 15(1): 1929-1958. [2] Kingma D P, Ba J. Adam: A method for stochastic optimization[J]. arXiv preprint arXiv:1412.6980, 2014.              ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 221}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 222 第7章-Tensorflow模型的保存和载入 在Tensorflow1.0中模型的保存和载入通常有两种方式，一种是Checkpoint的方式，还有一种是Protocol buffer的方式，这两种方式都有各自的一些特点。 ——Checkpoint保存的模型通常以“.ckpt”结尾，保存后会得到4个文件，如图7.1中的4个文件.  图7.1 Tensorflow模型文件 Checkpoint是一个文本文件，记录了训练过程中保存的模型的名称，首行记录的是最后（最近）一次保存的模型名称。 .data文件保存的是模型的变量值。 .index文件保存的是.data文件中的数据跟.meta文件中的结构之间的对应关系 .meta文件以“protocol buffer”格式保存了整个模型的结构图，模型上定义的操作等信息。 ——Protocol buffer的方式是把模型的参数转换为常量后进行保存，同时还会保存模型的结构，保存的模型通常以“.pb”结尾，只会得到一个文件。 由于在Tensorflow2中很多时候我们都是使用Tensorflow.keras来搭建和训练模型，所以模型的保存一般也是使用Tensorflow.keras的方式。Tensorflow1.0中所使用的Checkpoint模型保存方式在Tensorflow2中有时也会用到。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 222}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 223 7.1 Keras模型保存和载入 7.1.1 Keras保存模型 使用Keras保存模型操作很简单，如模型为model，可以使用： model.save('path_to_my_model.h5') 来保存模型，'path_to_my_model'为模型保存路径，'h5'为HDF5文件格式。使用model.save来保存模型，可以把模型的结构，权值参数和优化器设置，代价函数设置，metrics设置全部保存下来。Keras模型保存参考代码如代码7-1所示。 代码7-1：Keras模型保存 import tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  # 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test)) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 223}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 224  # 保存模型 model.save('my_model/mnist.h5')  结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 35us/sample - loss: 0.0379 - accuracy: 0.7752 - val_loss: 0.0214 - val_accuracy: 0.8808 …… Epoch 5/5 60000/60000 [==============================] - 2s 31us/sample - loss: 0.0156 - accuracy: 0.9043 - val_loss: 0.0145 - val_accuracy: 0.9098  模型训练好之后会生成一个h5模型文件保存在'my_model/mnist.h5'。  7.1.2 Keras载入模型 使用Keras载入模型操作也很简单，可以使用： tensorflow.keras.models.load_model('path_to_my_model.h5') 来载入模型，'path_to_my_model'为模型所在路径。Keras模型载入参考代码如代码7-2所示。 代码7-2：Keras模型载入 import tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 载入模型 model = load_model('my_model/mnist.h5') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 224}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 225  # 再训练5个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 34us/sample - loss: 0.0150 - accuracy: 0.9073 - val_loss: 0.0141 - val_accuracy: 0.9137 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0137 - accuracy: 0.9139 - val_loss: 0.0130 - val_accuracy: 0.9180  从输出结果可以看到模型是在已经训练了5个周期的基础上继续训练的。并且使用model.save保存模型的时候，不仅保存的模型的结构和权值参数，还保存了模型的优化器，代价函数，metrics这些设置。所以在载入模型之后，我们不需要设置优化器，代价函数和metrics，就可以直接使用fit对模型进行训练。  7.2 SavedModel模型保存和载入 7.2.1 SavedModel保存模型 SavedModel是Tensorflow中一种模型格式，SavedModel的优点是与语言无关，比如可以用时python训练模型，然后在Jave中非常方便的加载模型。SavedModel中包含了计算图和网络的权值，一个SavedModel模型包含以下内容： assets/ saved_model.pb variables/ ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 225}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 226      variables.data-00000-of-00001      variables.index 其中saved_model.pb包含计算图结构，variables文件夹保存模型训练得到的权值。assets文件夹一般是空的，可以添加一些可能需要的外部文件。 假设程序中训练好的模型为model，那么可以使用： model.save('path_to_saved_model')  来保存模型，注意这里的'path_to_saved_model'为模型保存的路径，保存后会得到一个文件夹，所以'path_to_saved_model'不需要加后缀。  model.save可以保存两种格式的模型。当我们使用model.save的时候，如果'path_to_saved_model'没有后缀就是保存为SavedModel格式；如果'path_to_saved_model.h5'有'h5'这个后缀就是保存为Keras的HDF5格式的模型。SavedModel保存模型参考代码如代码7-3所示。 代码7-3：SavedModel模型保存 import tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ])  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 226}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 227 # 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))  # 保存模型为SavedModel格式 model.save('path_to_saved_model')  结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 37us/sample - loss: 0.0373 - accuracy: 0.7806 - val_loss: 0.0217 - val_accuracy: 0.8776 …… Epoch 5/5 60000/60000 [==============================] - 2s 32us/sample - loss: 0.0156 - accuracy: 0.9038 - val_loss: 0.0145 - val_accuracy: 0.9093  7.2.2 SavedModel载入模型  SavedModel模型的载入也很简单，也是使用： tensorflow.keras.models.load_model('path_to_my_model')  来载入就可以了。载入模型以后再次训练的程序基本上跟代码7-2一样，如代码7-4所示。 代码7-4：SavedModel模型载入 import tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 227}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 228 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 载入SavedModel模型 model = load_model('path_to_saved_model')  # 再训练5个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 36us/sample - loss: 0.0151 - accuracy: 0.9065 - val_loss: 0.0140 - val_accuracy: 0.9133 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0138 - accuracy: 0.9141 - val_loss: 0.0130 - val_accuracy: 0.9172  7.3 单独保存模型结构 7.3.1 保存模型结构  有些时候，可能我们只对模型的结构感兴趣，只想保存模型的结构，而不保存模型的权值，优化器和代价函数等内容。那么我们可以使用： config = model.get_config()  来保存模型结构，模型的结构数据是一个python的字典，使用这个模型结构我们可以重建一个一摸一样的模型，然后重新训练这个模型。  另外还有一个保存模型结构的方式是使用： json_config = model.to_json() \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 228}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 229  来保存模型结构。这个方法是使用JSON格式来保存模型结构。单独保存模型结构参考代码如代码7-5所示。 代码7-5：保存模型结构（片段1） from tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout  # 模型定义 model = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dropout(0.4),         Dense(units=100,activation='tanh'),         Dropout(0.4),         Dense(units=10,activation='softmax')         ])  # 保存模型结构 config = model.get_config() print(config) 结果输出为： {'name': 'sequential', 'layers': [{'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'batch_input_shape': (None, 28, 28), 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Den\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 229}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 230 se\\', \\'config\\': {\\'name\\': \\'dense_2\\', \\'trainable\\': True, \\'dtype\\': \\'float32\\', \\'units\\': 10, \\'activation\\': \\'softmax\\', \\'use_bias\\': True, \\'kernel_initializer\\': {\\'class_name\\': \\'GlorotUniform\\', \\'config\\': {\\'seed\\': None}}, \\'bias_initializer\\': {\\'class_name\\': \\'Zeros\\', \\'config\\': {}}, \\'kernel_regularizer\\': None, \\'bias_regularizer\\': None, \\'activity_regularizer\\': None, \\'kernel_constraint\\': None, \\'bias_constraint\\': None}}]}  代码7-5：保存模型结构（片段2） import json # 保存json模型结构文件 with open(\\'model.json\\',\\'w\\') as m: json.dump(json_config,m) config的内容跟json_config的内容是差不多的，所以这里附上一个输出结果。保存json模型结构文件以后，在本地会得到一个model.json文件。 7.3.2 载入模型结构 模型结构保存后，可以使用model_from_json方法再重新把模型的结构载入，模型结构载入的参考代码如代码7-6所示。 代码7-6：载入模型结构 import tensorflow as tf import json   # 读入json文件 with open(\\'model.json\\') as m:     json_config = json.load(m)      # 载入json模型结构得到模型model model = tf.keras.models.model_from_json(json_config)  # summary用于查看模型结构 model.summary() 结果输出为： Model: \"sequential\" _________________________________________________________ Layer (type)                 Output Shape              Param #  ========================================================= ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 230}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 231 flatten (Flatten)            (None, 784)               0        _________________________________________________________ dense (Dense)                (None, 200)               157000   _________________________________________________________ dropout (Dropout)            (None, 200)               0        _________________________________________________________ dense_1 (Dense)              (None, 100)               20100    _________________________________________________________ dropout_1 (Dropout)          (None, 100)               0        _________________________________________________________ dense_2 (Dense)              (None, 10)                1010     ========================================================= Total params: 178,110 Trainable params: 178,110 Non-trainable params: 0 _________________________________________________________  我们可以看到模型打印出来的结构跟代码7-5中定义的结构是一样的。model.summary()可以很方便的打印出模型的结构，并可以看到网络每一层的输出shape和需要训练的参数Param，最后还会统计所有需要训练的参数个数。想了解模型结构的时候model.summary()可以多使用。  7.4 单独保存模型参数 7.4.1 保存模型参数 有时候我们只对模型的权值参数感兴趣， 对模型框架不感兴趣。 这个时候我们可以只获取模型的权值参数，我们可以使用： weights = model.get_weights() 来获取模型的权值参数，权值保存后会得到一个list，list中保存了每一层权值参数的具体数值。获取模型参数以后可以使用： model.set_weights(weights) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 231}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 232 来对模型进行权值进行重新设置。 如果我们想保存模型的参数可以使用： model.save_weights('path_to_my_model.h5')  来保存模型参数。参考代码如代码7-7所示。 代码7-7：保存模型参数 from tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout import numpy as np  # 模型定义 model = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dropout(0.4),         Dense(units=100,activation='tanh'),         Dropout(0.4),         Dense(units=10,activation='softmax')         ])  # 保存模型参数 model.save_weights('my_model/model_weights')  # 获取模型参数 weights = model.get_weights() # 把list转变成array weights = np.array(weights)  # 循环每一层权值 # enumerate相当于循环计数器，记录当前循环次数 # weights保存的数据可以对照print输出查看 for i,w in enumerate(weights):     if i%2==0:         print('{}:w_shape:{}'.format(int(i/2+1),w.shape))     else:         print('{}:b_shape:{}'.format(int(i/2+0.5),w.shape)) 结果输出为： 1:w_shape:(784, 200) 1:b_shape:(200,) 2:w_shape:(200, 100) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 232}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 233 2:b_shape:(100,) 3:w_shape:(100, 10) 3:b_shape:(10,)  7.4.2 载入模型参数  模型的参数载入很简单，使用： model.load_weights('path_to_my_model.h5')  就可以载入参数。不过要注意，载入模型参数之前需要把模型先定义好，或者使用model_from_json方法先载入模型。并且如果我们想进一步训练模型的参数的话，不仅要定义好模型结构，载入模型参数。还需要定义compile中的内容，包括优化器和代价函数等。因为model.save()会保存compile中的内容，而model.save_weights只会保存模型的参数。所以load_weights以后还需要重新定义compile的内容，才能进一步训练模型。 载入模型参数的参考代码如代码7-8所示。 代码7-8：载入模型参数 from tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropou  # 载入模型参数前需要先把模型定义好 # 模型结构需要与参数匹配 # 或者可以使用tf.keras.models.model_from_json载入模型结构 model = Sequential([         Flatten(input_shape=(28, 28)),         Dense(units=200,activation='tanh'),         Dropout(0.4),         Dense(units=100,activation='tanh'),         Dropout(0.4),         Dense(units=10,activation='softmax')         ])  # 载入模型参数 model.load_weights('my_model/model_weights.h5')  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 233}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 234 7.5 ModelCheckpoint自动保存模型  在第6章的抵抗过拟合方法中我们学习了Early-Stopping，我们在学习Early-Stopping的时候使用了： from tensorflow.keras.callbacks import EarlyStopping  复习一下，EarlyStopping是Callbacks的一种，callbacks用于指定在每个epoch或batch开始和结束的时候进行哪种特定操作。这个部分我们要学习的ModelCheckpoint也是Callbacks中的一种，用于自动保存模型。 其中参数monitor可以设置{'val_accuracy','val_loss','accuracy','loss'}，如果设置监测{'val_accuracy','accuracy'}，那么模型准确率大于最大{'val_accuracy','accuracy'}的时候就会保存模型；如果设置监测{'val_loss','loss'}，那么模型loss小于最小{'val_loss','loss'}的时候就会保存模型。ModelCheckpoint的使用方法和说明参数代码如代码7-9所示。 代码7-9：ModelCheckpoint自动保存模型 import tensorflow as tf from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 234}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 235  # 定义优化器，代价函数 adam = Adam(0.001) model.compile(optimizer=adam,               loss='categorical_crossentropy',               metrics=['accuracy'])  # 模型保存位置 output_model = 'ModelCheckpoint/' # log保存位置 output_log = 'log/'  # ModelCheckpoint用于自动保存模型 # filepath可以设置模型保存位置以及模型信息，epoch表示训练周期数，val_accuracy表示验证集准确值 # monitor可选{'val_accuracy','val_loss','accuracy','loss'},一般'val_accuracy'用得比较多 # verbose=1表示保存模型的时候打印信息 # save_best_only=True表示只保存>best_val_accuracy的模型 # CSVLogger也是callbacks，用于生成模型训练的log callbacks = [     ModelCheckpoint(filepath=output_model+'{epoch:02d}-{val_accuracy:.4f}.h5',                     monitor='val_accuracy',                     verbose=1,                     save_best_only=True),     CSVLogger(output_log + 'log.csv') ]  # 传入训练集数据和标签训练模型 model.fit(x_train, y_train,           epochs=6, batch_size=32,           validation_data=(x_test,y_test), callbacks=callbacks) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 59744/60000 [============================>.] - ETA: 0s - loss: 0.3711 - accuracy: 0.8957 ETA: 0s - loss: 0.3733 - accuracy: 0.89 Epoch 00001: val_accuracy improved from -inf to 0.91850, saving model to ModelCheckpoint/01-0.9185.h5 60000/60000 [==============================] - 2s 39us/sample - loss: 0.3709 - accuracy: 0.8958 - val_loss: 0.2899 - val_accuracy: 0.9185 Epoch 2/6 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 235}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 236 59072/60000 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.9185 Epoch 00002: val_accuracy improved from 0.91850 to 0.92120, saving model to ModelCheckpoint/02-0.9212.h5 60000/60000 [==============================] - 2s 39us/sample - loss: 0.2874 - accuracy: 0.9185 - val_loss: 0.2792 - val_accuracy: 0.9212 Epoch 3/6 59872/60000 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9224 Epoch 00003: val_accuracy improved from 0.92120 to 0.92200, saving model to ModelCheckpoint/03-0.9220.h5 60000/60000 [==============================] - 2s 36us/sample - loss: 0.2763 - accuracy: 0.9225 - val_loss: 0.2813 - val_accuracy: 0.9220 Epoch 4/6 58496/60000 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.9243 Epoch 00004: val_accuracy improved from 0.92200 to 0.92630, saving model to ModelCheckpoint/04-0.9263.h5 60000/60000 [==============================] - 2s 38us/sample - loss: 0.2701 - accuracy: 0.9243 - val_loss: 0.2696 - val_accuracy: 0.9263 Epoch 5/6 59936/60000 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9261 Epoch 00005: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - loss: 0.2658 - accuracy: 0.9261 - val_loss: 0.2766 - val_accuracy: 0.9254 Epoch 6/6 58816/60000 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9269 Epoch 00006: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - loss: 0.2624 - accuracy: 0.9267 - val_loss: 0.2866 - val_accuracy: 0.9217 从输出结果我们就可以看出并不是每一个周期模型都会保存，只有val_accuracy大于之前最大的val_accuracy，模型才会保存。程序训练6个周期以后用来保存模型的文件夹得到了4个模型，如图7.2所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 236}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 237 \\n 图7.2 ModelCheckPoint自动保存模型 从模型的文件名我们就可以看出模型是训练了多少个周期得到的，并且还可以看出模型的val_accuracy准确率，只有得到越来越大的val_accuracy模型才会保存。训练第5第6周期的时候，模型的val_accuracy没有超过第4个周期的0.9263，所以第5第6周期的模型没有保存。 训练结束之后我们还会得到一个CSV格式的log文件，log文件中的内容如图7.3所示。 \\n 图7.3 模型训练log文件 在log文件中包含了模型训练每个周期的训练集准确率，训练集loss，验证集准确率，验证集loss。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 237}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 238 7.6 Checkpoint模型保存和载入 7.6.1 Checkpoint模型保存 在Tensorflow2中我们也可以使用Checkpoint来保存和载入模型，用法跟Tensorflow1有些区别，具体使用方法可以参考下面的例子，如代码7-10所示。 代码7-10：Checkpoint模型保存 import tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建dataset对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建dataset对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练loss train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 238}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 239 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 测试loss test_loss = tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy') # 模型训练 @tf.function def train_step(data, label):     with tf.GradientTape() as tape:         # 传入数据预测结果         predictions = model(data)         # 计算loss         loss = tf.keras.losses.MSE(label, predictions)         # 计算权值调整         gradients = tape.gradient(loss, model.trainable_variables)         # 进行权值调整         optimizer.apply_gradients(zip(gradients, model.trainable_variables))         # 计算平均loss         train_loss(loss)         # 计算平均准确率         train_accuracy(label, predictions)      # 模型测试 @tf.function def test_step(data, label):     # 传入数据预测结果     predictions = model(data)     # 计算loss     t_loss = tf.keras.losses.MSE(label, predictions)     # 计算平均loss     test_loss(t_loss)     # 计算平均准确率 test_accuracy(label, predictions) # 定义模型保存，保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # 用于管理模型 # ckpt为需要保存的内容 # 'tf2_ckpts'为模型保存位置 # max_to_keep设置最多保留几个模型 manager = tf.train.CheckpointManager(ckpt, 'tf2_ckpts', max_to_keep=3)  EPOCHS = 5 # 训练5个周期 for epoch in range(EPOCHS): \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 239}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 240     # 循环60000/32=1875次     for image, label in mnist_train:         # 训练模型         train_step(image, label)     # 循环10000/32=312.5->313次     for test_image, test_label in mnist_test:         # 测试模型         test_step(test_image, test_label)        # 打印结果     template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'     print (template.format(epoch+1,                          train_loss.result(),                           train_accuracy.result(),                          test_loss.result(),                           test_accuracy.result()))      # 保存模型     # checkpoint_number设置模型编号 manager.save(checkpoint_number=epoch) 结果输出为： Epoch 1, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0125, Test Accuracy: 0.917 Epoch 2, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0124, Test Accuracy: 0.918 Epoch 3, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0123, Test Accuracy: 0.918 Epoch 4, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accuracy: 0.919 Epoch 5, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122, Test Accuracy: 0.92  7.6.2 Checkpoint模型载入 实现Checkpoint模型载入的代码如代码7-11所示。 代码7-11：Checkpoint模型载入 import tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 240}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 241 # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建dataset对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建dataset对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(10, activation='softmax') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练loss train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 测试loss test_loss = tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy') # 模型训练 @tf.function def train_step(data, label):     with tf.GradientTape() as tape:         # 传入数据预测结果         predictions = model(data)         # 计算loss         loss = tf.keras.losses.MSE(label, predictions)         # 计算权值调整         gradients = tape.gradient(loss, model.trainable_variables)         # 进行权值调整         optimizer.apply_gradients(zip(gradients, model.trainable_variables)) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 241}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 242         # 计算平均loss         train_loss(loss)         # 计算平均准确率         train_accuracy(label, predictions)      # 模型测试 @tf.function def test_step(data, label):     # 传入数据预测结果     predictions = model(data)     # 计算loss     t_loss = tf.keras.losses.MSE(label, predictions)     # 计算平均loss     test_loss(t_loss)     # 计算平均准确率 test_accuracy(label, predictions)  # 定义Checkpoint，用于保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # restore载入Checkpoint # latest_checkpoint表示载入编号最大的Checkpoint ckpt.restore(tf.train.latest_checkpoint('tf2_ckpts/')) # 载入模型后继续训练 EPOCHS = 5 # 训练5个周期 for epoch in range(EPOCHS):     # 循环60000/32=1875次     for image, label in mnist_train:         # 训练模型         train_step(image, label)     # 循环10000/32=312.5->313次     for test_image, test_label in mnist_test:         # 测试模型         test_step(test_image, test_label)     # 打印结果     template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}'     print (template.format(epoch+1,                          train_loss.result(),                           train_accuracy.result(),                          test_loss.result(),                        test_accuracy.result())) 结果输出为： Epoch 1, Loss: 0.0105, Accuracy: 0.934, Test Loss: 0.0116, Test Accuracy: 0.925 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 242}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 243 Epoch 2, Loss: 0.0105, Accuracy: 0.935, Test Loss: 0.0116, Test Accuracy: 0.925 Epoch 3, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accuracy: 0.925 Epoch 4, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accuracy: 0.925 Epoch 5, Loss: 0.0103, Accuracy: 0.936, Test Loss: 0.0116, Test Accuracy: 0.925  这一章节我们学习了Tensorflow2中3种模型保存的方式，使用tf.keras接口把模型保存为h5的文件，保存SavedModel格式的模型以及保存Checkpoint模型。  学习完神经网络和Tensorflow的基础知识，下一章节我们将开始介绍深度学习算法。                ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 243}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 244 第8章-卷积神经网络CNN 计算机视觉是人工智能领域最热门的研究领域之一， 并且是近几年发展最快的人工智能领域之一。10年前的人们一定想象不到如今的计算机视觉可以做到如此优秀的水平，CV(Computer Vision)领域的快速发展主要得益于卷积神经网络的使用。  8.1 计算机视觉介绍 8.1.1 计算机视觉应用介绍 如今计算机视觉的应用已经深入到我们生活中的方方面面，有着许多的实际应用。 人脸识别：使用在高铁进站，酒店住宿，公司门禁等场景下，如图8.1所示。 \\n 图8.1 人脸识别 图像检索：使用在搜索引擎的图片搜索中，以及电商网站的商品检索等，如图8.2所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 244}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 245 \\n 8.2 图像检索 监控：使用在公共场所中用于检测行人车辆的流量以及可疑行为等，如图8.3所示。 \\n 图8.3 监控 光学字符识别OCR：证件识别，车牌识别，文档识别，银行卡识别，名片识别，身份证识别等，如图8.4所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 245}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 246 \\n 图8.4 OCR 自动驾驶：检测交通标志，路上行人和车辆等，如图8.5所示。 \\n 图8.5 自动驾驶  8.1.2 计算机视觉技术介绍 计算机视觉包含很多中技术，下面我们简单介绍5种计算机视觉的常用技术。 1.图像分类： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 246}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 247 图像分类就是图像识别，识别一张图片中的物体，然后给出类别判断。一般对一张图片我们可能会得到多个类别判断，我们可以根据类别的置信度（模型认为图片属于该类别的概率）从高到低进行排序，然后得到可能性最大的几个类别，如图8.6所示。 \\n 图8.6 图像分类 2.目标检测 有时候我们不仅要识别图片是属于什么类别，还需要把它们给框选出来， 确定它们在图片中的位置和大小。如图8.7所示。 \\n 图8.7 目标检测[1] 3.目标跟踪 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 247}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 248 目标跟踪是指在特定场景跟踪某一个或多个特定感兴趣对象的过程，如图8.6所示。  图8.6目标跟踪[2] 4.语义分割 语义分割可以将图像分为不同的语义可解释类别，例如我们可能会把图片中汽车的颜色都用蓝色的表示，所有行人用红色表示。与图像分类或目标检测相比，语义分割可以让我们对图像有更加细致的了解，如图8.7所示。 \\n 图8.7 语义分割[3] 5.实例分割 实例分割可以将不同类型的实例进行分类，比如用4种颜色来表示4辆不同的汽车，用8种颜色表示8个不同的人，如图8.8所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 248}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 249 \\n 图8.8 实例分割[4]  8.2 卷积神经网简介 卷积神经网络就是一种包含卷积计算的神经网络。 卷积计算是一种计算方式， 有一个卷积窗口（Convolution Window）在一个平面上滑动，每次滑动会进行一次卷积计算得到一个数值，卷积窗口滑动计算完成后会得到一个用于表示图像特征的特征图（Feature Map）。下面是一个忽略具体数值计算的卷积计算流程， 具体的卷积数值计算在后面的内容再进行详细介绍： 用一个3×3的卷积窗口对4×4的图片求卷积， 卷积的移动步长为1， 最后得到2×2的特征图，如图8.9所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 249}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 250 \\n 图8.9 卷积计算  8.2.1 BP神经网络存在的问题 在前面的章节中我们使用了BP神经网络来处理MNIST手写数字识别的任务，并且得到了还不错的识别效果。 有一个细节问题当时我们可能没有注意到， 当时我们使用的手写数字图片是28×28的黑白图片，输入数据一共有28×28×1个数据，所以输入层只需要784个神经元。 假如我们有一张1000×1000的彩色图片， 那么输入层神经元就需要1000×1000×3个，我们使用带有一个隐藏层的神经网络，隐藏层神经元个数为1000，那么输入层和隐藏层之间权值的个数就会有30亿个，这是一个非常巨大的数字。 如此大量的权值会带来两个问题， 一个问题是计算量巨大， 要计算这么多权值就需要花费大量时间。 第二个问题是要训练这么多权值就需要大量的训练样本来进行训练， 防止模型过拟合。 因此我们需要使用卷积神经网络解决计算机视觉任务中权值数量巨大的问题。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 250}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 251 8.2.2 局部感受野和权值共享 卷积网络跟神经网络一样，也是受到了生物学的启发。20世纪60年代神经生理学家Hubel和Wiesel通过研究猫的视觉感受野（Receptive field of vision）提出的视觉神经系统的层级结构模型，从简单细胞到复杂细胞、超复杂细胞的层级信息处理结构。他们的研究成果在1981年获得诺贝尔生理学或医学奖。 卷积神经网络的设计借鉴了Hubel和Wiesel的研究，在卷积网络中使用了局部感受野（Local Receptive Field）。卷积层中的神经元连接不是全连接的，而是后一层的每个神经元连接前一层的一部分神经元。如图8.10所示，左边为BP网络的全连接结构，右边为卷积网络的局部连接结构。 \\n 图8.10 全连接和局部连接 图中一条连线就是一个权值，如果神经元不是全连接，那么权值就减少了很多。此外卷积神经网络还用到了权值共享（Weight Sharing）。这里的权值共享指的是同一卷积层中的同一个卷积窗口的权值是共享的。使用3×3的卷积窗口（也就是后一层的一个神经元连接前一层3×3的区域）对1000×1000的图片求卷积， 那么大家思考一下输入层和卷积层之间一共有多少个权值需要训练？ \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 251}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 252 现在公布答案，使用3×3的卷积窗口对1000×1000的图片求卷积，一共有9个权值加1个偏置值需要训练。3×3的卷积窗口就有9个权值，1个卷积窗口还会有1个偏置值。卷积窗口在进行滑动计算的时候窗口内的9个权值是权值共享的，所以一共只有9个权值。同理，假设使用5×5的卷积窗口对500×500的图片求卷积，一共有25个权值加1个偏置值训练训练。卷积层的权值数量跟被卷积的图片大小无关，跟卷积步长也无关，跟卷积窗口的大小相关。  8.3 卷积的具体计算 下面我们来讲解一下卷积的具体计算流程。卷积窗口又称为卷积核（Convolution Kernel），卷积之后生成的图称为特征图。卷积窗口/卷积核一般都是使用正方形的，比如1×1，3×3，5×5等，极少数特殊情况才会使用长方形。对一张图片求卷积实际上就是卷积核在图片上面滑动，并进行卷积计算。卷积计算很简单，就是卷积核与图片中对应位置的数值相乘然后再求和。 我们可以通过下面的具体例子来理解， 假设我们有一个3×3的卷积核， 如图8.11所示。  图8.11 3×3的卷积核 然后我们使用该卷积核，对4×4的图片求卷积，图片如下，图8.12所示。 101010101', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 252}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 253 \\n 图8.12 4×4的图片 3×3的卷积核对4×4的图片求卷积，步长为1，可以分为4个步骤，第一步，对左上方9个数求卷积，如图8.13所示。 \\n 图8.13 卷积第一步 具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。 卷积第二步如图8.14所示。 1110011100110001\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 253}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 254 \\n 图8.14 卷积第二步 具体卷积计算为：1×1+0×1+1×0+0×1+1×1+0×1+1×0+0×1+1×1=3。 卷积第三步如图8.15所示。 \\n 图8.15 卷积第三步 具体卷积计算为：1×0+0×1+1×1+0×0+1×0+0×1+1×0+0×0+1×0=2。 卷积第四步如图8.16所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 254}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 255 \\n 图8.16 卷积第四步 具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。 卷积的符号一般用“*”表示，上述的卷积计算如图8.17所示。 \\n 图8.17 卷积计算  8.4 卷积的步长 卷积的步长指的是卷积每一次移动的步数，前面我们列举的例子中，卷积的步长为1，卷积的步长理论上可以取任意正整数。图8.18中的例子是步长为2的卷积. \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 255}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 256 \\n 图8.18 步长为2的卷积 下图8.19为步长为3的卷积计算. \\n 图8.19步长为3的卷积  8.5 不同的卷积核 使用不同的卷积核来对同一张图片求卷积会得到不同的结果，如图8.20和图8.21所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 256}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 257  图8.20 使用不同卷积核求卷积（1）  图8.21 使用不同卷积核求卷积（2） 所以在卷积神经网络中，我们通常会使用多个不同的卷积核来对同一图像求卷积，目的就是为了可以提取出图像中多种不同的特征。 那么卷积核的取值要怎么取？如果是使用传统的机器学习思维，我们能想到的方法可能是人为设计大量不同的卷积核，然后使用大量图片来做测试，最后分析哪种卷积核提取出来的特征比较有效。 那在深度学习里面，卷积核中的数值实际上就是卷积核的权值。所以说卷积核的取值在卷积神经网络训练最开始的阶段是随机初始化的，之后结合误差反向传播算法，逐渐训练得到最终的结果。训练好的卷积核就可以作为特征提取器，用于提取图像特征，然后传到网络后面的全连接层，用于分类回归等任务。 在同一个卷积核中的权值是共享的，在不同的卷积核中的权值是不共享的。假设使用6个5×5的卷积核对一幅图像求卷积，会产6×5×5=150个权值加6个偏置值，卷积后会得到6个不同的特征图，如图8.22所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 257}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 258 \\n 图8.22 使用多个卷积核计算  8.6 池化（Pooling） 一个经典的卷积层包含3部分， 卷积计算->非线性激活函数->池化 （Pooling）， 如图8.23所示。 \\n 图8.23 经典卷积层的3部分 池化也有一个滑动窗口在图像中进行滑动计算，这一点跟卷积有点类似，不过池化层中没有需要训练的权值。 我们通常会使用多个不同的卷积核来对图像求卷积，之后生成很多个不同的特征图，卷积网络中的权值参数仍然是很多的。池化的一个作用是可以做进一步的特征提取，减少权值参数的个数。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 258}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 259 池化的另一个作用是使得网络的输入具有平移不变形。平移不变形指的是当我们对输入进行少量平移时，经过池化后的数值并不会发生太大变化。这是一个非常有用的性质，因为我们通常关心的是某个特征是否在图像中出现，而不是关心这个特征具体出现的位置。例如我们要判断一张图片中是否有猫，我们并不关心猫是出现在图片上方，还是下方，还是左边，还是右边，我们只关心猫是否出现在图片中，如图8.24所示。 \\n 图8.24 平移不变形 不过稍微要注意的是我们对输入进行少量平移时， 经过池化后的数值并不会发生太大变化。如果对输入平移太多时，池化后的数值还是会发生较大变化的。 池化也有池化窗口，对图像进行扫描计算，这一点跟卷积类似。池化通常可以分为三种方式，最大池化（Max-Pooling），平均池化（Mean-Pooling）和随机池化（Stochastic Pooling）。最大池化指的是提取池化窗口区域内的最大值，平均池化指的是提取池化窗口区域内的平均值，随机池化指的是提取池化窗口区域内的随机值，其中最常用的是最大池化。常用的池化窗口大小为2×2，步长为2。 池化窗口大小为2×2，步长为2的最大池化计算如图8.25所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 259}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 260 \\n 图8.25 最大池化 池化窗口大小为2×2，步长为2的平均池化计算如图8.26所示。 \\n 图8.26 平均池化 随机池化就是从池化窗口中随机取一个值，一般用得比较少。  8.7 Padding 在卷积神经网络中我们通常会堆叠多个卷积层的结构，形成一个深度的卷积神经网络。堆叠多个卷积层结构会碰到一个问题，那就是每一次做卷积，得到的特征图就会比原来的图像要变小一些，这样特征的数量会不断减少。例如使用3×3的卷积核对4×4的图像求卷积，步长为1，卷积后得到一个2×2的特征图，如图8.27所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 260}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 261 \\n 图8.27 卷积后得到的特征图比原图像小 另外在计算卷积的时候图像中间的数据会重复使用多次， 而图像边缘的数据可能只会被用到一次。图8.28表示，使用3×3的卷积核对4×4的图像求卷积，步长为1。 \\n 图8.28 边缘数据计算次数较少 图8.28中四个角的四个数据只计算了一次，而图像中心的四个数据则计算了四次，这就表示卷积容易丢失掉图像的边缘特征（不过其实边缘位置的信息一般来说也没这么重要） 。 针对上述两个问题，我们可以使用Padding的方式来解决。卷积和池化操作都可以使用Padding，Padding一般有两种方式， 一种是Valid Padding， 还有一种是Same Padding。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 261}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 262 Valid Padding其实就是不填充。不填充数据那么卷积后得到的特征图就会比原始图像要小一点，如图8.29所示。 \\n 图8.29 Valid Padding Same Padding指的是通过填充数据（一般都是填充0） ，使得卷积后的特征图的大小跟原始的图像大小相同，如图8.30所示。 \\n 图8.30 Same Padding \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 262}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 263 上图中使用3×3的卷积核对5×5的图像进行求卷积的操作，步长为1。给原图像外圈填充1圈0之后再做卷积， 卷积后得到的特征图大小就可以跟原始图像相同， 也是5×5的大小。 同理如果使用5×5的卷积核对图像进行求卷积的操作，步长为1，给原图像外圈填充2圈0之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。 如果使用7×7的卷积核对图像进行求卷积的操作，步长为1，给原图像外圈填充3圈0之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。 这也是为什么卷积核经常使用单数×单数， 因为我们可以通过填充0的方式得到与原始图像大小相同的特征图。 Same Padding还有另外一种理解方式，就是当步长不为1的时候，Same Padding指的是可能会给平面外部补0。下面举两个例子： 例1：假如有一个28×28的图像，用2×2步长为2的池化窗口对其进行池化的操作，使用Same Padding的方式，池化后得到14×14的特征图；使用Valid Padding的方式，池化后得到14×14的特征图。两种Padding方式得到的结果是相同的。 例2：假如有一个2×3的图像，用2×2步长为2的池化窗口对其进行池化的操作，使用Same Padding的方式，池化后得到1×2的特征图；使用Valid Padding的方式，池化后得到1×1的特征图。Same Padding给原图像补了0，所以可以进行2次池化计算，而Valid Padding不会给图像补0，所以只能进行1次池化计算。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 263}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 264 8.8 常见的卷积计算总结 8.8.1 对1张图像进行卷积生成1张特征图 对1张图像进行卷积生成1张特征图是最简单的一种卷积方式，前面我们已经进行了详解的举例计算，如图8.31所示。 \\n 图8.31 对1张图像进行卷积生成1张特征图  假如我们只统计乘法的计算量，图中一种进行了3×3×4次乘法计算。总共有9个权值和1个偏置值需要训练。 8.8.2 对1张图像进行卷积生成多张特征图 生成多张特征图需要使用多个不同的卷积核， 使用多个不同的卷积核来求卷积。 这里我们使用3个不同的5×5大小的卷积核对28×28的图像求卷积，使用Same Padding的方式，步长为1，卷积计算后生成3个不同的特征图，如图8.32所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 264}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 265 \\n 图8.32 对1张图像进行卷积生成多张特征图 因为每个卷积核中的权值不同，所以使用3个不同的卷积核求卷积会得到3个不同的特征图。一个卷积核会对原始图像进行5×5×28×28次乘法计算，所以总共计算量为5×5×28×28×3=58800。总共有5×5×3=75个权值和3个偏置值需要训练。偏置值数量主要跟特征图数量相关，每个特征图有1个偏置值。 8.8.3 对多张图像进行卷积生成1张特征图 比如我们多1张彩色图片求卷积，彩色图片可以看成是RGB三原色的组合，所以可以看成是3张图像。这里我们对3张28×28的图像求卷积，卷积窗口大小为5×5，使用Same Padding的方式，步长为1，卷积计算后生成1张特征图，如图8.33所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 265}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 266 \\n 图8.33 对多张图像进行卷积生成1张特征图 对3张图像进行卷积的时候先分别对每张图像进行卷积，得到3个大小相同，数值不同的特征图。然后再对每个特征图对应位置的数值进行相加，最后得到1个特征图。 一个卷积核会对原始图像进行5×5×28×28次乘法计算，所以总共计算量为5×5×28×28×3=58800。 这里要注意，我们对不同图像进行卷积的时候， 所使用的卷积核也是不同的，所以总共有5×5×3=75个权值和1个偏置值需要训练。 这里我们把对多张图像进行卷积的多个不同的卷积核称为一个滤波器 （Filter）， 一个滤波器可以产生一个特征图。在我们写程序搭建网络结构的时候，我们需要定义卷积层Filter的数量，实际上就是在定义卷积后生成的特征图的数量。 8.8.4 对多张图像进行卷积生成多张特征图 对多张图像进行卷积生成多张特征图相对来说最难理解同时也是最常见的情况。 在卷积网络中，很多时候都需要对多张图像进行卷积然后生成多张特征图。这里我们使用128个滤波\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 266}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 267 器对64张28×28的图像求卷积，使用Same Padding的方式，步长为1，卷积计算后生成128个不同的特征图。每个滤波器由64个不同的5×5卷积核组成，如图8.34所示。 \\n 图8.34 对多张图像进行卷积生成多张特征图 下面我们来分析一下上面这个例子的计算量和权值数量。1个滤波器对64张图像进行卷积，得到1张特征图。1个滤波器中有64个不同的5×5卷积核。每个5×5卷积核对1张图像求卷积。 1个卷积核对1张图片求卷积的计算量是5×5×28×28，所以1个滤波器64个卷积核的计算量是5×5×28×28×64。一共有128个不同的滤波器，所以总的计算量是5×5×28×28×64×128=160563200。 每个卷积核有5×5个权值，1个滤波器有64个卷积核有5×5×64个权值，128个滤波器有5×5×64×128=204800个权值，加上128个偏置值。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 267}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 268 8.9 经典的卷积神经网络 前面的内容中我们介绍了很多卷积神经网络相关的知识点， 不过大家可能对一个完整的卷积神经网络的结构可能还不太了解。 常见的卷积神经网络结构实际上是多个卷积层叠加起来之后再加上全连接层构成的。 有些卷积网络有几十层或者几百层， 实际上就是因为网络内部的卷积层的数量比较多，如图8.35所示是一个比较典型卷积网络结构。  图8.35 识别猫的卷积神经网络 卷积神经网前面的部分进行卷积池化相当于是进行特征提取， 后面部分进行全连接相当于是利用提取出来的图像特征进行分类。 我们还可以把卷积神经网络应用于MNIST手写数字识别，如图8.36所示。 \\n 图8.36 卷积神经网络应用于手写数字识别 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 268}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 269 为了能让大家看到一目了然的图， 我也特地花了一些时间来研究如何画网络结构以及如何表示图中的计算流程， 后面的内容中大家还会看到更多类似上图的网络结构图。 图中的s表示stride，s1代表卷积或池化的步长为1，s2代表卷积或池化的步长为2，以此类推；conv是卷积（convolution）的缩写；pool表示最大池化（max pooling），fc表示全连接（fully connected）。 图中原始的手写数字的图片是一张28×28的图片，并且是黑白的，所以图片的通道数是1，输入数据是28×28×1的数据，如果是彩色图片，图片的通道数就为3。 该网络结构是一个4层的卷积神经网络（计算神经网络层数的时候，有权值的才算是一层，比如池化层就不能单独算一层） 。第1层为卷积层，使用32个5×5的卷积核对原始图片求卷积，步长为1，Same Padding。因为是Same Padding并且步长为1，所以卷积后的特征图大小跟原图片一样， 可以得到32张28×28的特征图。 池化的计算是在卷积层中进行的，使用2×2，步长为2的池化窗口做池化计算，池化后得到32张14×14的特征图。特征图的长宽都变成了之前的1/2。权值的数量为5×5×32=800，偏置值数量为32（1个特征图会有1个偏置值） 。 第2层也是卷积层，使用64个5×5的卷积核对32张14×14的特征图求卷积，步长为1，Same Padding。因为是Same Padding并且步长为1，所以卷积后的特征图大小跟原图片一样，可以得到64张14×14的特征图。这里对32个特征图求卷积产生出64个特征图涉及到前面我们介绍的对多张图像进行卷积生成多张特征图。 对多张特征图求卷积， 相当于是同时对多张特征图进行特征提取。 同一个特征图中权值是共享的， 不同的特征图之间权值是不同的。 对32张图像求卷积产生1个特征图， 需要使用32个不同的5×5的卷积核，那么就会有5×5×32=800个连接，800个权值。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 269}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 270 所以在我们现在看到的这个例子中，第2个卷积层卷积窗口大小5×5，对32张图像求卷积产生64个特征图，参数个数是5×5×32×64=51200个权值加上64个偏置（1个特征图会有1个偏置值） 。 池化的计算是在卷积层中进行的，使用2×2，步长为2的池化窗口做池化计算，池化后得到64张7×7的特征图。特征图的长宽都变成了之前的1/2。 第3层是全连接层， 第2个池化层之后的64×7×7个神经元跟1024个神经元做全连接。 第4层是输出层，输出10个预测值，对应0-9的10个数字。 这个例子中卷积后产生的特征图的个数32，64是属于卷积神经网络中的超参数，需要我们自己调节和设置， 也可以修改为其他值， 一般设置为2的倍数。 特征图数量越多说明卷积网络提取的特征数量越多， 如果特征图数量设置得太少容易出现欠拟合， 如果特征图数量设置得太多容易出现过拟合，所以需要设置为合适的数值。  8.10 卷积神经网络应用于MNIST数据集分类 实现卷积神经网络应用于MNIST数据集分类的代码如代码8-1所示。 代码8-1：卷积神经网络应用于MNIST数据集分类 import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam # 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在tensorflow中，在做卷积的时候需要把数据变成4维的格式 # 这4个维度是(数据数量，图片高度，图片宽度，图片通道数) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 270}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 271 # 所以这里把数据reshape变成4维数据，黑白图片的通道数是1，彩色图片通道数是3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 定义顺序模型 model = Sequential() # 第一个卷积层 # input_shape 输入数据 # filters 滤波器个数32，生成32张特征图 # kernel_size 卷积窗口大小5*5 # strides 步长1 # padding padding方式 same/valid # activation 激活函数 model.add(Convolution2D(     input_shape = (28,28,1),     filters = 32,     kernel_size = 5,     strides = 1,     padding = 'same',     activation = 'relu' )) # 第一个池化层 # pool_size 池化窗口大小2*2 # strides 步长2 # padding padding方式 same/valid model.add(MaxPooling2D(     pool_size = 2,     strides = 2,     padding = 'same', )) # 第二个卷积层 # filters 滤波器个数64，生成64张特征图 # kernel_size 卷积窗口大小5*5 # strides 步长1 # padding padding方式 same/valid # activation 激活函数 model.add(Convolution2D(64,5,strides=1,padding='same',activation='relu')) # 第二个池化层 # pool_size 池化窗口大小2*2 # strides 步长2 # padding padding方式 same/valid \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 271}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 272 model.add(MaxPooling2D(2,2,'same')) # 把第二个池化层的输出进行数据扁平化 # 相当于把(64,7,7,64)数据->(64,7*7*64) model.add(Flatten()) # 第一个全连接层 model.add(Dense(1024,activation = 'relu')) # Dropout model.add(Dropout(0.5)) # 第二个全连接层 model.add(Dense(10,activation='softmax')) # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test, y_test)) # 保存模型 model.save('mnist.h5') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 73s 1ms/sample - loss: 0.3466 - accuracy: 0.8985 - val_loss: 0.0953 - val_accuracy: 0.9706 Epoch 2/10 60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0986 - accuracy: 0.9706 - val_loss: 0.0601 - val_accuracy: 0.9804 …… Epoch 9/10 60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0263 - val_accuracy: 0.9909 Epoch 10/10 60000/60000 [==============================] - 72s 1ms/sample - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.9928 使用卷积神经网络之后，MNIST手写数字识别的测试集准确率可以提升到99%以上的高水准。  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 272}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 273 8.11 识别自己写的数字图片 在识别MNIST数据集的程序中，我们直接调用了tensorflow打包过的数据，而不是一张一张的图片，所以整个流程可能不够直观。我们可以使用MNIST数据集训练好的模型来识别自己写的数字图片，来检测一下模型的识别效果。 我们可以自己找一张白纸，写一个数字，注意数字要写得粗一些，并且写在图片中间的位置，跟MNIST数据集中的数字类似，如图8.37所示。 \\n 图8.37 手写数字6 然后通过代码8-2来完成数字图片的识别. 代码8-2：识别自己写的数字图片（片段1） import tensorflow as tf from tensorflow.keras.models import load_model import matplotlib.pyplot as plt from PIL import Image import numpy as np  # 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data()  # 获取一张照片，并把它的shape变成二维（784->28×28）,用灰度图显示 plt.imshow(x_train[18],cmap='gray') # 不显示坐标 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 273}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 274 plt.axis('off') plt.show() 结果输出为： \\n  代码8-2：识别自己写的数字图片（片段2） # 载入我自己写的数字图片 img=Image.open('6.jpg') # 显示图片 plt.imshow(img) # 不显示坐标 plt.axis('off') plt.show() 结果输出为： \\n  代码8-2：识别自己写的数字图片（片段3） # 把图片大小变成28×28，并且把它从3D的彩色图变为1D的灰度图 image = np.array(img.resize((28,28)).convert('L')) # 显示图片,用灰度图显示 plt.imshow(image,cmap='gray') # 不显示坐标 plt.axis('off') plt.show() \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 274}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 275 结果输出为： \\n  代码8-2：识别自己写的数字图片（片段4） # 观察发现我自己写的数字是白底黑字，MNIST数据集的图片是黑底白字 # 所以我们需要先把图片从白底黑字变成黑底白字，就是255-image # MNIST数据集的数值都是0-1之间的，所以我们还需要/255.0对数值进行归一化 image = (255-image)/255.0 # 显示图片，用灰度图显示 plt.imshow(image,cmap='gray') # 不显示坐标 plt.axis('off') plt.show() 结果输出为： \\n  代码8-2：识别自己写的数字图片（片段5） # 把数据处理变成4维数据 image = image.reshape((1,28,28,1)) # 载入训练好的模型 model = load_model('mnist.h5') # predict_classes对数据进行预测并得到它的类别 prediction = model.predict_classes(image) print(prediction) 结果输出为： \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 275}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 276 [6]  8.12 CIFAR-10数据集分类 CIFAR-10数据集是深度学习领域比较常用的一个图片数据集， 很多模型都会使用CIFAR-10数据集来检验模型的效果。CIFAR-10数据集一共有10个分类，每个分类的图片都是32×32的彩色图片， 每个分类都有6000张图片， 一共个60000张图片。 其中50000张图片是训练集，10000张图片是测试集。如图8.38所示。 \\n 图8.38 CIFAR-10  另外还有一个数据集叫CIFAR-100，顾名思义就是有100个种类，每个种类有600张图片，一共60000张。其中50000张为训练集，10000张为测试集。CIFAR-10数据集比较用得更多一些，CIFAR-10数据集分类代码如8-3所示。 代码8-3：CIFAR-10数据集分类（片段1） import numpy as np \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 276}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 277 from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data()  # 显示1张图片 # 第3张图片 n = 3 # 一共10个种类 target_name = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] # 显示图片 plt.imshow(x_train[n]) plt.axis('off') # 根据标签获得种类名称 plt.title(target_name[y_train[n][0]]) plt.show() 结果输出为： \\n  代码8-3：CIFAR-10数据集分类（片段2） # 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 转one hot格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10) \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 277}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 278  # 定义卷积网络 model = Sequential() model.add(Convolution2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Convolution2D(filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.2)) model.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.3)) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.4)) model.add(Flatten()) model.add(Dense(10,activation = 'softmax'))  # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuffle=True) 结果输出为： Train on 50000 samples, validate on 10000 samples Epoch 1/100 50000/50000 [==============================] - 9s 181us/sample - loss: 1.9268 - acc: 0.2873 - val_loss: 1.6186 - val_acc: 0.4077 Epoch 2/100 50000/50000 [==============================] - 6s 127us/sample - loss: 1.5641 - acc: 0.4284 - val_loss: 1.4547 - val_acc: 0.4748 Epoch 3/100 50000/50000 [==============================] - 6s 126us/sample - loss: 1.4103 - acc: 0.4897 - val_loss: 1.2902 - val_acc: 0.5436 …… Epoch 98/100 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 278}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 279 50000/50000 [==============================] - 6s 126us/sample - loss: 0.2807 - acc: 0.8987 - val_loss: 0.5496 - val_acc: 0.8293 Epoch 99/100 50000/50000 [==============================] - 6s 126us/sample - loss: 0.2797 - acc: 0.8995 - val_loss: 0.5561 - val_acc: 0.8303 Epoch 100/100 50000/50000 [==============================] - 6s 126us/sample - loss: 0.2822 - acc: 0.8979 - val_loss: 0.5498 - val_acc: 0.8278  训练100个周期，最后得到了83%左右的测试集准确率。  卷积神经网络是如今深度学习中最常用的算法之一， 而另一种非常常用的算法——序列模型将是我们下一章要介绍的内容。  8.13 参考文献 [1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018. [2] Nam H, Han B. Learning multi-domain convolutional neural networks for visual tracking[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 4293-4302. [3] Badrinarayanan V, Kendall A, Cipolla R. Segnet: A deep convolutional encoder-decoder architecture for image segmentation[J]. IEEE transactions on pattern analysis and machine intelligence, 2017, 39(12): 2481-2495. [4] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2961-2969.   ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 279}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 280 第9章-序列模型 1986年 Rumelhart 等人提出循环神经网络（Recurrent Neural Network），简称RNN。RNN跟我们之前学习过的神经网络都不太一样，它是一种序列模型。比如卷积网络是专门用来处理网格化数据（例如图像数据）的神经网络，RNN是专门用来处理序列数据的神经网络。所谓的序列数据指的是跟序列相关的数据，比如一段语音，一首歌曲，一段文字，一段录像等。  9.1 序列模型应用 我们生活中的很多数据都是序列数据，因此序列模型可以应用于我们生活中的很多方面，例如： 语音识别：把语音转换成为文字，如图9.1所示。 \\n 图9.1 语音识别 文本分类：把文章，邮件或用户评论等文本数据做分类，如图9.2所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 280}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 281 \\n 图9.2 文本分类 机器翻译：如把中文翻译成英文，如图9.3所示。  图9.3 机器翻译 视频识别：通过一段视频分析视频中发生的事件，如图9.4所示。  图9.4 视频识别 分词标注： 给一段文字做分词标注， 标注每个字对应的标号。 假如使用4-tag(BMES)标注标签，B表示词的起始位置，M表示词的中间位置，E表示词的结束位置，S表示单字词。可以得到类似如下结果： “人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 281}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 282 9.2 循环神经网络RNN 9.2.1 循环神经网络介绍 循环神经网络RNN的基本结构是BP网络的结构，也是有输入层，隐藏层和输出层。只不过在RNN中隐藏层的输出不仅可以传到输出层，并且还可以传给下一个时刻的隐藏层，如图9.5所示。 \\n 图9.5 RNN结构 图9.5中RNN的结构可以展开为右边的结构，其中x为输入信号，𝑥Ã\\x7f\"为t-1时刻的输入信号，𝑥Ã为t时刻的输入信号，𝑥Ã\\x97\"为t+1时刻的输入信号。ℎÃ\\x7f\"为t-1时刻的隐藏层信号，ℎÃ为t时刻的隐藏层信号，ℎÃ\\x97\"为t+1时刻的隐藏层信号。𝑦Ã\\x7f\"为t-1时刻的输出层信号，𝑦Ã为t时刻的输出层信号，𝑦Ã\\x97\"为t+1时刻的输出层信号。W，U，V为网络的权值矩阵。h是隐藏(hidden)的首字母。 假如图9.5是一个训练好的词性分析模型，有一个句子是“我爱你”，那么先把句子做分词得到“我”， “爱”， “你”三个词，然后依次把这三个词输入到网络中。那么𝑥Ã\\x7f\"为“我”所表示的信号，𝑥Ã为“爱”所表示的信号，𝑥Ã\\x97\"为“你”所表示的信号。而𝑦Ã\\x7f\"输出结果是主\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 282}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 283 语，𝑦Ã输出结果是谓语，𝑦Ã\\x97\"输出结果是宾语，分别得到“我”，“爱”，“你”这三个词的词性。 从结构上可以观察到RNN最大的特点是之前序列输入的信息会对模型之后的输出结果造成影响。 9.2.2 Elman network和Jordan network 循环神经网络RNN有两种常见的模型，一种是Elman network另一种是Jordan network。Elman network和Jordan network也被称为Simple Recurrent Networks (SRN)或SimpleRNN，即简单的循环神经网络。 这两种模型的网络结构是一样的，都如图9.5，只不过它们的计算公式有一点不同。 Elman network的公式为： ℎÃ=𝜎\\x96(𝑊𝑥Ã+𝑈ℎÃ\\x7f\"+𝑏\\x96)\\t(9.1) 𝑦Ã=𝜎Ð\\x8e𝑉ℎÃ+𝑏Ð\\x8f(9.2) Jordan network的公式为： ℎÃ=𝜎\\x96(𝑊𝑥Ã+𝑈𝑦Ã\\x7f\"+𝑏\\x96)(9.3) 𝑦Ã=𝜎Ð\\x8e𝑉ℎÃ+𝑏Ð\\x8f(9.4) 其中𝑥Ã为t时刻的输入信号，ℎÃ为t时刻隐藏层的输出信号，𝑦Ã为t时刻输出层的输出信号。W，U，V对应图9.5中的权值矩阵，b为偏置值。𝜎\\x96和𝜎Ð为激活函数，激活函数可以自行选择。 从上面Elman network和Jordan network的公式对比中可以看出，Elman network的隐层ℎÃ接收的是上时刻的隐层ℎÃ\\x7f\"的信号；而Jordan network的隐层ℎÃ接收的是上时刻的输出层𝑦Ã\\x7f\"的信号。一般Elman network的形式会更常用一些。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 283}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 284  9.3 RNN的不同架构 为了处理不同输入输出组合的各类任务，RNN可以分为以下几种不同的架构。 9.3.1 一对一架构 一对一架构如图9.6所示。 \\n 图9.6 RNN一对一架构 其实就是普通的神经网络，输入序列长度为1，输出序列长度也是1。注意这里的𝑥\"不是一个数值的意思，而是第一个序列输入的意思，𝑥\"可以是多个数值。比如𝑥\"输入MNIST数据集图片的数据，一张图片有784个像素，那么这里的𝑥\"就有784个值。把𝑥\"的数据输入，然后𝑦\"得到图片数据的预测结果。  9.3.2 多对一架构 多对一架构如图9.7所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 284}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 285 \\n 图9.7 RNN多对一架构 模型有多次输入，我们只关心序列输出的最后一个值。比如可以用于情感分类，给模型输入一个句子或一篇文章，一个句子或一篇文章包含很多个词，每个词看成是一个输入信号，那么一个序列被分为多次输入。最后模型的预测结果可以是一个句子或一篇文章的情感分类，比如说是正面的情感还是负面的情感，两个类别，那么模型的最后一个序列的输出可以看成是预测结果。同样的道理，如果做文本分类也是可以用多对一架构。 这里要注意的是，多对一架构并不是说模型只有最后一个序列才有输出值。其实每次给模型输入一个词的信号，模型都会输出一个结果。只不过如果我们需要分析一个句子或者一篇文章的情感，那么我们需要把整个句子或整篇文章的词的数据都输入到模型进行计算之后，再获得模型最终的一个输出结果，模型最终的这个输出结果会更准确。而前面得到的模型输出结果可能就没这么准确。 9.3.3 多对多架构 多对多架构如图9.8所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 285}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 286 \\n 图9.8 RNN多对多架构 序列有多次输入和多次输出。可以应用在Tagging（标注），比如说词性标注，标注句子中的每个词分别是什么词性。输入一个信号，然后就输出这个信号的预测结果。 9.3.4 一对多架构 一对多架构如图9.9所示。 \\n 图9.9 RNN一对多架构 一对多模型是只有一个输入信号，就可以得到很多个输出结果。第一个序列的输出结果会作为输入传给第二个序列，第二个序列的输出会作为输入传给第三个序列，以此类推。比如可以应用于音乐生成和文章生存。给出第一个音符或字，就可以生成一段旋律或者一句话。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 286}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 287 9.3.5 Seq2Seq架构 Seq2Seq的全称是Sequence to Sequence，也就是序列到序列模型。seq2seq也算是多对多架构，如图9.10所示。 \\n 图9.10 RNN的seq2seq架构 seq2seq由两部分组成，左边部分为编码器（encoder），右边部分为解码器（decoder）。Encoder的作用是负责将输入序列压缩成指定长度的向量，相当于是做特征提取。然后把这个向量传给decoder进行计算得到多个序列输出。 经典的多对多RNN架构的输入和输出是等长的，也就是有10个输入就必须有10个输出结果，它的应用场景也比较有限。而seq2seq模型的输入和输出可以是不等长的，它实现了一个序列到另一个序列的转换。比如可以用来做机器翻译，encoder输入一段中文，decoder可以输出一段英文，中文句子的词汇数跟英文句子的词汇数不一定要相同。比如还可以用来做聊天机器人，encoder输入一句话，decoder回复另一句话，这两句话的长度也不一定相同。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 287}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 288 9.4 传统RNN的缺点 我们知道RNN可以根据历史信息来进行预测，假如我们训练了一个可以进行文本填空的RNN模型，下面要进行文本填空： 题目1:有一朵云飘在（）。 对于题目1来说正确的答案应该是“天上”，或者“空中“，或者”天空中“等。经过大量训练之后的RNN可以根据前面文本的信息填出正确的答案。 题目2:我从小生长在美国，父亲是英国人，母亲是美国人。我最喜欢喝牛奶，吃牛肉，长大想当科学家。我的兴趣爱好是看电影，看书，踢足球还有周末跟爷爷去钓鱼。我可以说一口流利的（）。 对于题目2来说因为是从小生长在美国，所以应该是可以说一口流利的“英语“。但是传统的RNN不一定能预测出正确的结果，原因是句子的长度太长了。 为什么句子的长度太长会对RNN的预测产生影响呢？这要考虑到RNN的基本模型结构，传统的RNN基本模型结构是BP网络。我们在学习BP网络的时候有特别讨论过关于梯度消失的问题。就是模型计算得到的误差信号从输出层不断向前传播，以此来调整前面层的权值，使得模型的性能越来越好。但是由于误差信号在每次传递的时候都需要乘以激活函数的导数，当激活函数的导数取值范围是0-1之间时，会使得误差信号越传越小，最终趋近于0。 这个梯度消失的问题在RNN中同样存在，RNN的序列结构展开之后也可以看成是有很多的“层”，在计算误差信号的时候同样会出现梯度消失的问题，使得网络输出的学习信号只能影响到它前面的几层，对它前面的几层的权值进行调节。所以反过来考虑，一个信号的输入，只能影响到它后面的几个序列的输出，并且影响力会越来越弱，如图9.11所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 288}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 289 \\n 图9.11 RNN的梯度消失问题[1]  9.5 长短时记忆网络LSTM LSTM(Long Short Term Memory)是Hochreater和Schmidhuber在1997年提出的一种网络结构，尽管该模型在序列建模上的特性非常突出，但由于当时正是神经网络的下坡期，没有能够引起学术界足够的重视。随着深度学习逐渐发展，后来LSTM的应用也逐渐增多。 LSTM区别于SimpleRNN的地方，主要就在于它在算法中加入了一个判断信息有用与否的“处理器”，这个处理器作用的结构被称为记忆块（Memory Block），如图9.12所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 289}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 290 \\n 图9.12 记忆块（memory block）[1] 图9.12中最下面4个神经元是输入神经元，最上面5个神经元是输出神经元，memory block在隐藏层的位置。传统的BP网络隐藏层是普通的神经元，不过在LSTM里面是结构比较复杂的memory block。memory block内部具体结构如图9.13所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 290}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 291 \\n 图9.13 memory block结构[1] 𝑓Ã=𝜎Ñ\\x8e𝑊v𝑥Ã+𝑈vℎÃ\\x7f\"+𝑏v\\x8f(9.5) 𝑖Ã=𝜎Ñ(𝑊(𝑥Ã+𝑈(ℎÃ\\x7f\"+𝑏()(9.6) 𝑜Ã=𝜎Ñ(𝑊Ò𝑥Ã+𝑈ÒℎÃ\\x7f\"+𝑏Ò)(9.7) 𝑐Ã=𝑓Ã∘𝑐Ã\\x7f\"+𝑖Ã∘𝜎Ó(𝑊Ó𝑥Ã+𝑈ÓℎÃ\\x7f\"+𝑏Ó)(9.8) ℎÃ=𝑜Ã∘𝜎\\x96(𝑐Ã)(9.9) 𝑐̃Ã=𝜎Ó(𝑊Ó𝑥Ã+𝑈ÓℎÃ\\x7f\"+𝑏Ó)(9.10) memory block结构主要包含了三个门：遗忘门（Forget Gate）、输入门（Input Gate）、输出门（Output Gate）与一个记忆单元（Cell）。信号从下面传入，上面传出。首先我们先了解一下公式中符号的含义。 𝑓Ã：遗忘门信号 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 291}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 292 𝑖Ã：输入门信号 𝑜Ã：输出门信号 𝑥Ã：第t个序列的输入 ℎÃ\\x7f\"：第t-1个序列的memory block输出 ℎÃ：第t个序列的memory block输出，也称为Hidden State。 𝑐̃Ã：cell输入信号 𝑐Ã：cell输出信号，也称为Cell State。 𝑐Ã\\x7f\"：第t-1个序列的cell信号 𝜎Ñ：sigmoid函数 𝜎Ó：tanh函数 𝜎\\x96：tanh函数或线性函数 𝑊,𝑈,𝑏：𝑊和𝑈是权值矩阵，𝑏是偏置 观察图9.13，信号从blcok底部传入，传入的信号为第t个序列的输入𝑥Ã，以及第t-1个序列的输出ℎÃ\\x7f\"，也就是上一个时间block的输出信号会传给当前的block做计算。𝑥Ã和ℎÃ\\x7f\"乘以对应的权值矩阵加上偏置值经过激活函数得到𝑐̃Ã的信号，计算公式为9.10，如图9.14所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 292}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 293 图9.14 𝑐̃Ã的信号计算[1] 𝑐̃Ã信号继续传会碰到Input Gate输入门，输入门的计算公式为9.6。输入门的传入信号也是𝑥Ã和ℎÃ\\x7f\"，激活函数为sigmoid函数。我们要注意2个地方： 1.block中一共有3个门，并且这3个门的输入信号都是𝑥Ã和ℎÃ\\x7f\"，它们的计算公式都是差不多的，不过他们的权值矩阵是不同的值，不同的门有不同的权值。 2.3个门的激活函数都是sigmoid函数，所以3个门的输出值都是0-1之间，体现了门的作用。门的作用就是控制信号的开关。 𝑐̃Ã信号和输入门信号𝑖Ã会进行对位相乘，然后再进行传递。𝑖Ã的作用在这里就体现出来了，𝑖Ã的值等于1表示𝑐̃Ã信号会100%传递；𝑖Ã的值等于0表示𝑐̃Ã信号会完全消失；𝑖Ã的值等于0.6表示𝑐̃Ã信号会保留60%的大小进行传递。如图9.15所示。 \\n 图9.15 𝑖Ã的信号计算[1] 𝑐̃Ã和𝑖Ã对位相乘后继续传递到达Cell的位置。Cell的位置有一个Forget Gate遗忘门，遗忘门的计算公式为9.5，跟输入门的计算类似，最后得到0-1之间的结果。当前的𝑐Ã信号计算公式为9.8，表示𝑐̃Ã和𝑖Ã对位相乘后的信号再加上前一个序列的Cell信号𝑐Ã\\x7f\"和𝑓Ã对位相乘的信号。 其实就相当于是在block内部可以保存一个Cell信号为𝑐Ã，这个信号会不断“遗忘”，所以需要乘以遗忘门信号𝑓Ã。具体需要全部遗忘，还是不遗忘，还是遗忘一部分，是由遗忘\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 293}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 294 门信号𝑓Ã来控制的。当前的Cell信号就等于之前的Cell信号进行一些遗忘𝑐Ã\\x7f\"∘𝑓Ã再加上当前传入的信号𝑐̃Ã∘𝑖Ã。如图9.16所示。 \\n 图9.16 𝑐Ã的信号计算[1] 𝑐Ã信号继续传递会碰到Output Gate输出门，输出门的计算公式为9.7，跟输入门和遗忘门类似。整个block最后的输出为ℎÃ，公式为9.9。就是𝑐Ã信号加上tanh激活函数再跟输出门信号𝑜Ã对位相乘得到block的输出ℎÃ，如图9.17所示。 \\n 图9.16 ℎÃ的信号计算[1] memory blocks输出的ℎÃ信号会再乘上输出层的权值矩阵加上偏置值再经过激活函数最后得到LSTM网络的输出结果。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 294}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 295 9.6 Peephole LSTM和FC-LSTM 9.6.1 Peephole LSTM介绍 Peephole LSTM跟LSTM差不多，结构如图9.17所示。 \\n 图9.17 Peephole LSTM结构图[1] 𝑓Ã=𝜎Ñ\\x8e𝑊v𝑥Ã+𝑈v𝑐Ã\\x7f\"+𝑏v\\x8f(9.11) 𝑖Ã=𝜎Ñ(𝑊(𝑥Ã+𝑈(𝑐Ã\\x7f\"+𝑏()(9.12) 𝑜Ã=𝜎Ñ(𝑊Ò𝑥Ã+𝑈Ò𝑐Ã\\x7f\"+𝑏Ò)(9.13) 𝑐Ã=𝑓Ã∘𝑐Ã\\x7f\"+𝑖Ã∘𝜎Ó(𝑊Ó𝑥Ã+𝑈Ó𝑐Ã\\x7f\"+𝑏Ó)(9.14) ℎÃ=𝑜Ã∘𝜎\\x96(𝑐Ã)(9.15) 𝑐̃Ã=𝜎Ó(𝑊Ó𝑥Ã+𝑈Ó𝑐Ã\\x7f\"+𝑏Ó)(9.16) \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 295}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 296 大家可以自己先观察一下Peephole LSTM跟LSTM的结构和公式哪里不同。  不仔细观察可能不容易看出，它们不同之处在与把所有的ℎÃ\\x7f\"都改成了𝑐Ã\\x7f\"，也就是说当前序列的𝑐Ã信号传传给下一个序列的计算，而不是ℎÃ信号。 9.6.2 FC-LSTM介绍  LSTM还有一个结构为FC-LSTM(Fully-Connected LSTM)，结构如图9.18所示。 \\n 图9.18 FC-LSTM结构[1] 𝑓Ã=𝜎Ñ\\x8e𝑊v𝑥Ã+𝑈vℎÃ\\x7f\"+𝑉v𝑐Ã\\x7f\"+𝑏v\\x8f(9.17) 𝑖Ã=𝜎Ñ(𝑊(𝑥Ã+𝑈(ℎÃ\\x7f\"+𝑉(𝑐Ã\\x7f\"+𝑏()(9.18) 𝑜Ã=𝜎Ñ(𝑊Ò𝑥Ã+𝑈ÒℎÃ\\x7f\"+𝑉Ò𝑐Ã\\x7f\"+𝑏Ò)(9.19) 𝑐Ã=𝑓Ã∘𝑐Ã\\x7f\"+𝑖Ã∘𝜎Ó(𝑊Ó𝑥Ã+𝑈ÓℎÃ\\x7f\"+𝑉Ó𝑐Ã\\x7f\"+𝑏Ó)(9.20) \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 296}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 297 ℎÃ=𝑜Ã∘𝜎\\x96(𝑐Ã)(9.21) 𝑐̃Ã=𝜎Ó(𝑊Ó𝑥Ã+𝑈ÓℎÃ\\x7f\"+𝑉Ó𝑐Ã\\x7f\"+𝑏Ó)(9.22) 观察FC-LSTM的结构和公式，我们可以很容易的知道，FC-LSTM的𝑐Ã信号和ℎÃ信号都可以传给下一个序列进行计算。 总结一下，在LSTM中存在3个门，输入门控制信号的输入，遗忘门控制Cell信号的遗忘，输出门控制信号的输出。LSTM的隐藏层中有大量的block，数量我们可以自己设置。经过随时间反向传播(BPTT)算法(跟BP算法类似)训练后LSTM中的block就可以自动判断哪些信号应该让它输入，哪些信号应该保存或遗忘，哪些信号应该让它输出。它的输入门会控制有用的信号进行输入，过滤掉一些无用的信号；它的遗忘门会保留一些重要的信号，忘记一些不太有用的信号；它的输出门会控制输出一些有用的信号，如图9.19所示。 \\n 图9.19 LSTM对信号的控制[1]  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 297}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 298 9.7 其他RNN模型 9.7.1 门控循环单元GRU GRU(Gated Recurrent Unit)这个结构是2014年才出现的，效果跟LSTM差不多，但是用到的参数更少，所以计算速度会更快一些。GRU将遗忘门和输入门合成了一个单一的更新门。GRU的block结构简图9.20所示。 \\n 图9.20 GRU结构 𝑧Ã=𝜎Ñ(𝑊¹𝑥Ã+𝑈¹ℎÃ\\x7f\"+𝑏¹)(9.23) 𝑟Ã=𝜎Ñ(𝑊\\x9c𝑥Ã+𝑈\\x9cℎÃ\\x7f\"+𝑏\\x9c)(9.24) ℎÕÃ=𝑡𝑎𝑛ℎ(𝑊\\x96𝑥Ã+𝑈\\x96(𝑟Ã∘ℎÃ\\x7f\"))(9.25) ℎÃ=(1−𝑧Ã)∘ℎÃ\\x7f\"+𝑧Ã∘ℎÕÃ(9.26) 𝑧Ã是更新门(update gate)，决定ℎÃ的更新情况 𝑟Ã是重置门(reset gate)，决定是否要放弃ℎÃ\\x7f\" ℎÕÃ是候选输出，接收[𝑥Ã,ℎÃ\\x7f\"]  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 298}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 299 ℎÃ是当前输出，接收[ℎÃ\\x7f\",ℎÕÃ] 9.7.2 双向RNN（Bidirectional RNN） 双向RNN(Bidirectional RNN)结构如图9.21所示。 \\n 图9.21 双向RNN ℎÃÖÖÖ⃗=𝑓\\x8e𝑊ÖÖÖ⃗𝑥Ã+𝑉Ö⃗ℎÃ\\x7f\"ÖÖÖÖÖÖÖÖ⃗+𝑏Ö⃗\\x8f(9.27) ℎÃ⃖ÖÖÖ=𝑓\\x8e𝑊⃖ÖÖÖ𝑥Ã+𝑉⃖ÖℎÃ\\x97\"⃖ÖÖÖÖÖÖÖÖ+𝑏⃖Ö\\x8f(9.28) 𝑦Ã=𝑔\\x8e𝑈\\x92ℎÃÖÖÖ⃗;ℎÃ⃖ÖÖÖ\\x93+𝑐\\x8f(9.29) 这里的RNN可以使用任意一种RNN结构SimpleRNN，LSTM或GRU。这里箭头表示从左到右或从右到左传播，对于每个时刻的预测，都需要来自双向的特征向量，拼接（concatenate）后进行结果预测。箭头虽然不同，但参数还是同一套参数。有些模型中也可以使用两套不同的参数。𝑓,𝑔表示激活函数，\\x92ℎÃÖÖÖ⃗;ℎÃ⃖ÖÖÖ\\x93表示数据拼接（concatenate）。 双向的 RNN 是同时考虑“过去”和“未来”的信息。图9.21是一个序列长度为4的双向RNN结构。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 299}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 300 比如输入𝑥\"沿着实线箭头传输到隐层得到ℎ\"，然后还需要再利用𝑥Ã计算得到ℎÃR，利用𝑥$和ℎÃR计算得到ℎ$R，利用𝑥#和ℎ$R计算得到ℎ#R，利用𝑥\"和ℎ#R计算得到ℎ\"R，再把ℎ\"和ℎ\"R进行数据拼接（concatenate），再计算得到输出结果𝑦\"。以此类推同时利用前向传递和反向传递的数据进行结果的预测。 双向RNN就像是我们做阅读理解的时候从头向后读一遍文章，然后又从后往前读一遍文章，然后再做题。有可能从后往前再读一遍文章的时候会有新的不一样的理解，最后模型可能会得到更好的结果。  9.7.3 Stacked Bidirectional RNN 堆叠的双向RNN结构如图9.22所示。 \\n 图9.22 Stacked Bidirectional RNNs \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 300}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 301 ℎÃ(\\x84)ÖÖÖÖÖÖ⃗=𝑓Ù𝑊\\x84ÖÖÖÖÖ⃗ℎÃ\\x84\\x7f\"+𝑉\\x84ÖÖÖÖ⃗ℎÃ\\x7f\"\\x84ÖÖÖÖÖÖÖÖ⃗+𝑏\\x84ÖÖÖ⃗Ú(9.30) ℎÃ(\\x84)⃖ÖÖÖÖÖÖ=𝑓Ù𝑊\\x84⃖ÖÖÖÖÖℎÃ\\x84\\x7f\"+𝑉\\x84⃖ÖÖÖÖℎÃ\\x97\"\\x84⃖ÖÖÖÖÖÖÖÖ+𝑏\\x84⃖ÖÖÖÚ(9.31) 𝑦Ã=𝑔l𝑈ÛℎÃ(\\x84)ÖÖÖÖÖÖ⃗;ℎÃ(\\x84)⃖ÖÖÖÖÖÖÜ+𝑐m(9.32)  注意这里的堆叠RNN结构并不是只有双向RNN才可以堆叠，其实任意的RNN都可以堆叠，比如SimpleRNN，LSTM，GRU这些循环神经网络也可以进行堆叠。堆叠指的是在RNN的结构中叠加多层，类似于BP神经网络中可以叠加多层，增加网络的非线性。图9.22中是一个堆叠了3个隐藏层的RNN网络。  9.8 LSTM网络应用于MNIST数据集分类  LSTM网络是序列模型，一般是比较适合处理序列问题。这里我们把它用于手写数字图片的分类，其实是相当于把图片看成序列。一张MNIST数据集的图片是28*28的大小，我们可以把每一行看成是一个序列输入，那么一张图片就是28行，序列长度为28；每一行有28个数据，每个序列输入28个值，具体实现如代码9-1所示。 代码9-1：LSTM网络应用于MNIST数据集分类 import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.layers import LSTM from tensorflow.keras.optimizers import Adam  # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据x_train的数据形状为（60000，28，28） # 训练集标签y_train的数据形状为（60000） # 测试集数据x_test的数据形状为（10000，28，28） ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 301}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 302 # 测试集标签y_test的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 数据大小-一行有28个像素 input_size = 28 # 序列长度-一共有28行 time_steps = 28 # 隐藏层memory block个数 cell_size = 50   # 创建模型 model = Sequential()  # 循环神经网络的数据输入必须是3维数据 # 数据格式为(数据数量，序列长度，数据大小) # 载入的mnist数据的格式刚好符合要求 # 注意这里的input_shape设置模型数据输入时不需要设置数据的数量 model.add(LSTM(     units = cell_size,      input_shape = (time_steps,input_size), ))  # 50个memory block输出的50个值跟输出层10个神经元全连接 model.add(Dense(10,activation='softmax'))  # 定义优化器 adam = Adam(lr=1e-3)  # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])  # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 14s 236us/sample - loss: 0.5748 - accuracy: 0.8189 - val_loss: 0.2315 - val_accuracy: 0.9303 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 302}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 303 Epoch 2/10 60000/60000 [==============================] - 15s 247us/sample - loss: 0.1953 - accuracy: 0.9416 - val_loss: 0.1521 - val_accuracy: 0.9555 …… Epoch 10/10 60000/60000 [==============================] - 14s 228us/sample - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0644 - val_accuracy: 0.9803 LSTM应用于MNIST数据识别也可以得到不错的结果，不过当然没有卷积网络得到的结果好。更多序列模型的应用案例我们将在后面的章节中进一步介绍。  9.9 参考文献 [1] Graves A. Supervised sequence labelling[M]//Supervised sequence labelling with recurrent neural networks. Springer, Berlin, Heidelberg, 2012: 5-13.            ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 303}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 304 第10章-经典图像识别模型介绍（上） 经典的图像识别模型比较多，并且我希望可以把各种模型的技术细节，设计思路尽可能地给大家介绍清楚。所以经典图像识别模型介绍的部分分为上下两个章节，第10章和第11章。这两个章节的内容都属于内功修行，为了保持内容的连贯性，这两个章节的内容都是算法理论的介绍，相关代码实践的内容我放到了第12章节。大家可以看完第10，11章再看12章，或者是结合第12章的代码来看第10，11章，两种方式都可以。  10.1 图像数据集ImageNet 10.1.1 ImageNet介绍 在正式介绍深度学习的经典图像识别模型之前，我们先来了解一下全世界最大的带有标签的开源图像数据集ImageNet。 ImageNet项目是从2007年由斯坦福教授李飞飞领导发起，ImageNet项目团队从互联网上下载了近10亿张照片，然后使用众包技术（例如亚马逊机械土耳其人平台）来帮助他们为这些图像打标签。在巅峰时期，ImageNet项目有来自167个国家的近50000名工作者为其进行数据的清理，分类，标注。 直到2009年ImageNet项目正式交付使用，在ImageNet数据库中有1500万张左右的照片，包含大约22000种类别，免费提供给全世界的研究者使用。ImageNet的官网地址是：http://www.image-net.org/index。如图10.1所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 304}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 305 \\n 图10.1 ImageNet官网 官网的右上角可以看到当前ImageNet数据库图片的数量为14197122张图片，一共有21841个种类。 10.1.2 李飞飞简介  李飞飞是美籍华人，人工智能学术圈最知名的女性科学家之一。 1976年出生于北京，长在四川，16岁随父母移居美国新泽西州。 1999年毕业于普林斯顿大学。 2005年获得加州理工学院电子工程博士。 2009年加入斯坦福大学担任助理教授。 2012年担任副教授（终生教授），和斯坦福人工智能实验室与视觉实验室主任。 2017年1月入职Google，担任谷歌云首席科学家。 2018年9月，离开谷歌返回斯坦福大学担任教授，同时保留谷歌云的AI/ML顾问。 2020年2月，当选为美国国家工程院院士。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 305}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 306 10.1.3 ImageNet的深远影响 2020年2月李飞飞当选美国国家工程院院士，美国国家工程院(NAE)对于李飞飞的当选给出的理由是“李飞飞为建立大型机器学习和视觉理解知识库作做出了贡献”。这里的“大型机器学习和视觉理解知识库”其实说白了就是ImageNet数据集。为什么创建一个数据集，就可以有资格评选美国院士？下面是我个人对于ImageNet数据集重要性的理解： 一．前瞻性和创新性。ImageNet项目在2007年发起，到2009年交付使用。这个巨大的项目需要耗费大量的人力物力财力，但是这个项目交付以后能发挥多大的作用，在当时并不是十分明确。我们从今天的视角来看，大规模深度学习模型的训练（这里的训练指的是重新训练一个新模型，不是指迁移学习（Transfer Learning））必然需要大规模的数据集才能得到很好的结果，这也是目前深度学习技术的一个局限性。但是在当时，深度学习技术才刚刚萌芽，大家并不明确大规模数据集对于机器学习/深度学习技术会有多大的影响。 二．ImageNet对于计算机视觉领域的巨大影响。如果大家之前稍微有关注过计算机视觉的发展就会发现，在ImageNet交付使用后，特别是2012年以后，计算机视觉领域的技术发展可谓是突飞猛进。图像识别，目标检测，人脸识别等技术的应用效果得到了巨大提升。10年前人脸识别技术我们可能只听说过，没见过，现在走到哪里都有人脸识别。这一切都主要得益于深度学习技术的发展和ImageNet数据集。 ImageNet在2009年免费发布以后，从2010年开始每年都会组织一次计算机视觉的比赛ILSVRC（ImageNet Large Scale Visual Recognition Challenge），简称ImageNet Challenge。这个比赛也是近年来计算机视觉领域最受追捧也最具权威的学术竞赛之一，代表了计算机视觉领域的最高水平。比赛的项目有图像分类，目标定位，目标检测，视频目标检测，场景分类。其中最重要也最受关注的就是图像分类的比赛。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 306}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 307 ImageNet Challenge的图像分类比赛是从ImageNet数据集中选出了1000个生活中常见的分类，120万张图片作为训练集，10万张图片作为测试集，5万张图片作为验证集。参加比赛的人主要都是来自全世界的大公司，学校，研究院等。也有一些创业公司会参赛，因为如果能在这个全世界最知名的图像比赛上拿奖的话，那就证明了获奖公司拥有全世界最顶尖的图像技术水平，之后拿投资，做推广都会很容易。 从ImageNet Challenge比赛中诞生出了很多优秀的深度学习模型，这些模型可以应用于计算机视觉的各种领域，图像识别，目标检测，目标分割，人脸识别等等，极大推动了计算机视觉的发展。 如果大家对ImageNet Challenge比赛感兴趣，也想参赛的话，那么很遗憾，参加不了了。因为这个比赛是从2010年开始举办，到2017年结束，现在这个比赛已经没有了。因为这个比赛的初衷就是希望可以通过比赛来推动计算机视觉技术的发展，很显然，这个目的已经完全达到，比赛中各个项目的模型效果均已接近甚至超过人类水平。 三．ImageNet对于其他技术领域的影响。ImageNet最直接的影响肯定是计算机视觉领域，不过除了计算机视觉，ImageNet也间接推动了其他技术领域的发展。 深度学习的主要应用领域是图像，文本和语音等，每个技术领域都有不同的特点，不过也都有一些相通的地方。比如不管在哪个领域使用深度学习都需要涉及到激活函数，代价函数，网络结构设计等这些方面的内容。ImageNet的发布以及ImageNet Challenge比赛促进了深度学习技术的全面发展，让神经网络技术再一次流行起来，使得我们对神经网络/深度学习的技术有了更深刻的理解。所以当我们在其他领域使用深度学习的时候，ImageNet也起到了潜移默化的作用。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 307}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 308 10.1.4 ImageNet Challenge历年优秀作品 ImageNet Challenge从2010年开始举办到2017年结束，总共举办了8次。在这8年的时间里诞生出了很多非常经典而且优秀的模型，让神经网络变得越来越流行，并出现了多种优秀变体，可谓百花齐放。下面我们简单来回顾一下ImageNet Challenge比赛的历史，图10.2为历年比赛结果（数据来源于http://image-net.org/challenges/LSVRC/）。 \\n 图10.2 ImageNet Challenge历年比赛结果 图10.2中的百分比为ImageNet Challenge图像分类比赛中的错误率，注意这里的错误率为Top5错误率。一般在对ImageNet数据进行建模分类的时候，模型都会给出两个错误率结果，一个是Top1错误率，一个是Top5错误率。Top1错误率表示模型在预测图像分类的时候只能给出一个最可能的预测结果，预测结果跟真实标签相同则表示预测正确；Top5错误率表示模型在预测图像分类的时候可以给出5个最可能的预测结果，这5个最可能的预测结果只要有其中一个跟真实标签相同则表示预测正确。由于ImageNet Challenge图像分\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 308}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 309 类比赛有1000个分类，在做预测的时候有一定的错误容忍性，所以经常使用Top5错误率作为主要指标判断模型好坏。 这里先对历年比赛结果做一个简单的介绍，后面我们还会再具体分析其中一些比较经典和优秀的模型。如果大家仔细看的话会发现，有些年份我列出了冠亚军，有些年份我只列出了冠军。这是因为有些模型虽然在某些年份的比赛中是亚军，但是它的名气，创新程度不亚于冠军，所以我也列出来了。 2010年和2011年的冠军使用的都是SVM算法，我们知道SVM算法是机器学习领域中的经典算法，在深度学习崛起之前，SVM算法在计算机视觉中有着很多的应用。所以ImageNet Challenge比赛的前两届大家用的还是老的思路，使用SVM来进行建模。从结果中我们也可以看出来，使用SVM来进行大规模的图片分类，得到的效果明显不如深度学习。 2012年对深度学习来说也是一个重要的年份，因为这是深度学习在ImageNet Challenge图像分类的比赛上首次获得冠军。创造出这个深度学习模型的冠军团队来自多伦多大学，主要作者是Alex Krizhevsky，所以这个模型被命名为AlexNet。团队成员中还有Geoffrey Hinton，我们在本书最开始介绍深度学习领域的名人时有介绍过他，被称为“深度学习教父”的人。Alex Krizhevsky是Geoffrey Hinton的学生，所以这个工作应该是在Hinton大牛的带领下主要由学生完成的。AlexNet在当时大获成功，相比SVM，图像识别的错误率有了大幅度的下降。2012年比赛的亚军使用的算法还是传统机器学习算法，错误率为26.17%，而AlexNet的错误率已经下降到了16.42%，拉开了巨大差距。从2012年以后，深度学习逐渐崛起，在后来的比赛中，所有人都开始使用深度学习来进行建模。 2013年的冠军来自Clarifai公司，他们用的也是深度学习模型，不过他们获得冠军的网络模型不太有名，网上的资料也不多，后面就不多做介绍了。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 309}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 310 2014年的冠军是来自谷歌的团队完成的，所以给模型命名为GoogleNet。2014年的亚军模型也很有名，是来自牛津大学的研究组VGG (Visual Geometry Group) ，所以给模型起名为VGGNet。这两个模型都是非常有名和经典的模型，所以我在图中都列出来了。 2015年的冠军是来自微软亚洲研究院(MSRA)，他们给模型命名为残差网络（Residual Network），所以模型简称为ResNet。这个网络的层数多达152层，网络结构设计非常具有创新性。 2016年的冠军由中国团队获得，是公安部第三研究所的Trimps-Soushen团队，他们用的也是深度学习模型，不过他们获得冠军的网络模型不太有名，网上的资料也不多，后面就不多做介绍了。2016年的亚军是来自加州大学圣地亚哥分校(UCSD)和Facebook AI Research(FAIR)的团队，他们的模型是在ResNet的基础上进行改进后得到的，所以模型命名为ResNeXt。 2017年的冠军是来自Momenta公司的团队，他们提出了Squeeze-and-Excitation Networks（简称SENet）。 8年来ImageNet Challenge比赛不断推动着计算机视觉技术和深度学习的发展。人类在ImageNet Challenge图像识别比赛上的表现大约是5.1%的错误率[1]，近年的比赛结果已经比人类的错误率要低了许多。2017年是ImageNet Challenge的最后一年，也是一个时代的终结。2017年以后，ImageNet将与全世界最大的数据科学社区Kaggle结合，在Kaggle社区里继续举办比赛。ImageNet Challenge虽然没有了，不过ImageNet的影响将继续延续。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 310}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 311 10.2 AlexNet AlexNet是在ImageNet Challenge图像识别比赛上第一个获得冠军的深度学习模型，由自多伦多大学团队完成，主要作者是Alex Krizhevsky，“深度学习教父” Geoffrey Hinton也在团队中。AlexNet对后来的深度学习模型设计和模型训练都有着重要的启发和指导作用。最早提出AlexNet的论文是《ImageNet Classification with Deep Convolutional Neural Networks》[2]。 这里我想稍微多说几句，由于ImageNet Challenge是一个比赛，比赛中有很多Trick可以帮助模型得到更好的结果，比如在AlexNet中在当时比较创新的使用了ReLU激活函数，和使用Dropout来防止过拟合，然后把每张图片切分为多张进行训练和预测，改变图片的颜色以生成更多的数据集等。比赛中的很多Trick内容比较分散，并且效果不稳定，有时候可以让结果更好，有时候会让结果更差。所以关于模型的介绍我们主要是介绍模型的结构设计，关于模型在比赛中所使用的Trick大家有兴趣可以再另外自行研究。 图10.3为《ImageNet Classification with Deep Convolutional Neural Networks》论文中的网络结构图。 \\n 图10.3 AlexNet网络结构[2] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 311}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 312 图中的Stride表示步长；Max pooling表示最大池化；Dense表示全连接层。输入图片大小为224×224，实际上作者在构建模型的时候使用的图片大小为227×227，主要是为了后续计算方便。 大家初看这个图可能会觉得这个结构看起来有点复杂，可能暗藏玄机，这个模型的输入是227×227的图片（作者把ImageNet Challenge比赛的图片都处理成227×227的固定大小再传入模型进行训练），后来怎么就变成了上下两个部分，这样设计有什么精妙之处吗？ 在当时看来，其实没有什么精妙，只是因为当时算力有限，也没有什么好用的深度学习开源框架。他们手上只有两个GTX580的3GB内存的GPU，为了加快模型的训练速度，所以他们把模型分为两个部分。一个GPU训练上面的部分，一个GPU训练下面的部分，所以网络结构就变成了上下两个部分。我猜测如果尽量不改变模型的设计思路，放在今天的软硬件条件下，AlexNet应该会被设计成图10.4所示的结构。 \\n 图10.4 AlexNet网络结构 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 312}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 313 图中的s表示stride，代表步长，s1代表卷积或池化的步长为1，s2代表卷积或池化的步长为2，以此类推；fc表示fully connected，代表全连接；pool表示max pooling，代表最大池化；conv表示convolution，代表卷积；output表示输出。 其实我猜测的图10.4结构和论文中图10.3结构还是有一点点小区别的，论文中的结构分为上下两个部分以后，注意看图10.3中的卷积的计算，在某些层会分为上下两个部分独立计算，在某些层上下两个部分会一起计算。不过总的来说模型的效果差别不是很大（其实我画的图10.4的AlexNet结构会比原始的AlexNet结构效果差一点点，不过这里我们忽略不计）。我们就以图10.4来看一下AlexNet的网络设计。 把图画好其实就可以节省很多文字讲解了，图中已经把所有的卷积池化计算的窗口大小，步长，以及卷积池化计算以后得到的特征图大小和数量都表示出来了，下面我再简单说明一下即可。 图中卷积和池化的padding方式我没有标出来，有些层使用的是valid padding，有些层使用的是same padding，不同的padding方式对模型结果一般不会有很大影响，所以图中我就省略了。另外其实通过图中的已知的信息我们可以自己判断出padding的方式。 AlexNet是一个8层的网络（卷积层和全连接层中有需要训练的权值，所以这里计算网络层数的时候只计算卷积层和全连接层），除了最后输出层用的是softmax函数以外，其他层用的都是ReLU激活函数。 AlexNet是专门为ImageNet级别的数据集设计的，一共有6000多万个需要训练的参数，参数的数量巨大。 第1层计算。网络的输入是227×227的“臭臭”照片。经过11×11步长为4的卷积计算后，得到96个55×55的特征图。然后再进行3×3步长为2的最大池化计算，得到96个27×27的特征图。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 313}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 314 第2层计算。使用5×5，步长为1的卷积对96个27×27的特征图进行特征提取，得到了256个27×27的特征图。然后再用3×3步长为2的最大池化计算，得到256个13×13的特征图。 第3层计算。使用3×3，步长为1的卷积对256个13×13的特征图进行特征提取，得到了384个13×13的特征图。 第4层计算。使用3×3，步长为1的卷积对384个13×13的特征图进行特征提取，得到了384个13×13的特征图。 第5层计算。使用3×3，步长为1的卷积对384个13×13的特征图进行特征提取，得到了256个13×13的特征图。然后再用3×3步长为2的最大池化计算，得到256个6×6的特征图。 第6层计算。把pool3的256个6×6的特征图数据跟fc1中的4096个神经元进行全连接计算。 第7层计算。把fc2的4096个神经元跟fc1中的4096个神经元进行全连接计算。 第8层计算。把output的1000（ImageNet Challenge比赛有1000个分类）个神经元跟fc2中的4096个神经元进行全连接计算。最后再经过softmax计算得到类别的概率值进行输出。 可能大家会有一些疑问，什么AlexNet要设计成8层的网络？为什么有些卷积后面加上了池化，有些卷积后面没有池化？为什么有些卷积生成的特征图数量是256，有些是384？为什么是384而不是其他的数字？为什么有3个全连接层，为什么是4096个神经元？ 其实这些为什么都很难给出合理的解释，因为直至今天深度学习的可解释性依旧是一个重要科研难题。我觉得AlexNet的网络结构是在Alex团队有限的时间，有限的实验次数下', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 314}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 315 得到的最好的模型结构了。如果给他们更好的设备，更多的时间，做更多的实验，他们肯定会得到更优秀的模型，得到更好的结果。 我们在2012年的时候知道AlexNet是一个正确的方向，它开拓了一个新的并且更好的思路，我们只要沿着这个方向继续往前走，肯定有更多的收获等着我们。  10.3 VGGNet VGGNet是2014年ImageNet Challenge图像识别比赛的亚军。参赛团队是来自牛津大学的研究组VGG (Visual Geometry Group) 。VGGNet的很多设计思想都受到AlexNet的影响，所以跟AlexNet也有一点点相似的地方。VGGNet不仅在图像识别方向有着广泛应用，很多目标检测，目标分割，人脸识别等方面的应用也会使用VGGNet作为基础模型。 VGGNet在2014，2015年左右的流行程度甚至超过了2014年ImageNet Challenge图像识别比赛的冠军GoogleNet，是当时用得最多的深度学习模型。VGGNet被广泛使用也是有一定原因的，VGGNet的网络结构比较简单，也容易搭建，并且VGGNet的单模型结果与GoogleNet相当。ImageNet Challenge是一个比赛，在比赛中我们经常会使用模型融合（Ensemble Model）策略，把多个模型组合在一起，这样有可能会得到更好的结果。2014年，在ImageNet Challenge比赛中，多个GoogleNet融合后的结果比多个VGGNet融合后的结果要更好，所以GoogleNet得到了冠军。最早提出VGGNet的论文是《Very Deep Convolutional Networks for Large-Scale Image Recognition》[3]。 其实，VGGNet有多个版本，如图10.5所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 315}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 316 \\n 图10.5 VGGNet的多个版本[3] 从图中ConvNet Configuration表示网络结构；weight layers表示网络层数；input表示输入；conv表示卷积；maxpool表示最大池化；FC表示全连接层。 我们可以看出VGGNet有6个不同的版本，他们的主要区别是网络层数和网络结构的区别。图中的conv3表示3×3的卷积，conv1表示1×1的卷积；conv3-128表示3×3的卷积计算后生成128个特征图；LRN(Local Response Normalization)是局部响应归一化，一种在AlexNet中使用的数据归一化计算，不过VGGNet的作者认为LRN并没有什么用，所以在VGGNet中并没有使用。 其中使用得比较多的有B，因为它有13层，我们称之为VGG13。使用得比较多的还有D，因为它有16层，我们称之为VGG16。使用得比较多的还有E，因为它有19层，我们称之为VGG19。在ImageNet Challenge图像识别比赛中效果最好的是VGG19，其次到VGG16，最后是VGG13。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 316}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 317 每个版本的模型网络结构不同，所以参数的数量也有所不同。参数数量最少的是A，有1亿3千多万个参数。最多的是E，有1亿4千多万个参数。别看网络中有很多的卷积层，其实网络中大部分的参数都是在全连接层中。比如在VGG16中，卷积层的参数数量占所有参数的13%，而全连接层的参数数量占到了87%。 在很多应用中VGG16似乎用得更多一些，下面我们来看一下VGG16的网络结构图10.6所示。 \\n 图10.6 VGG16网络结构 图中fc表示fully connected，代表全连接；pool表示max pooling，代表最大池化；conv表示convolution，代表卷积；output表示输出。 VGG16的所有卷积都是3×3，步长为1，same padding；所有池化都是2×2，步长为2，same padding；输出层函数为softmax，除了输出层以外，其他层激活函数都是ReLU函数。 VGG16受AlexNet的影响和启发，图片的输入为224×224的大小，卷积层后面也使用了3个全连接层，并且全连接层也是使用4096个神经元。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 317}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 318 VGG16是一个16层的网络，它的结构比较简单易懂，叠加了很多个卷积池化层。2×2，步长为2的池化特会使得特征图的长宽减少为原来1/2，池化后的下一个卷积会使得特征图的数量会变成原来的2倍。 VGG16的输入是224×224大小的图片。 block1为第1，2层，其中包含了2个卷积和1池化，卷积后图像大小没有发生变化224×224，池化后特征图大小变成了112×112，特征图的数量为64。 block2为第3，4层，其中包含了2个卷积和1池化，卷积后图像大小没有发生变化112×112，池化后特征图大小变成了56×56，特征图的数量为128。 block3为第5，6，7层，其中包含了3个卷积和1池化，卷积后图像大小没有发生变化56×56，池化后特征图大小变成了28×28，特征图的数量为256。 block4为第8，9，10层，其中包含了3个卷积和1池化，卷积后图像大小没有发生变化28×28，池化后特征图大小变成了14×14，特征图的数量为512。 block5为第11，12，13层，其中包含了3个卷积和1池化，卷积后图像大小没有发生变化14×14，池化后特征图大小变成了7×7，特征图的数量为512。大家可能会稍微有点疑惑，block5中的特征图的数量按照规律不应该会变成1024吗，但是这里还是512。这里的原因我猜测是作者他们肯定也尝试过1024，但是最后的效果估计跟512的效果差不多。并且改成1024后会增加很多计算量和需要训练的权值，所以最后的版本中就没有使用1024。 第14层计算。把pool5的512个7×7的特征图数据跟fc1中的4096个神经元进行全连接计算。 第15层计算。把fc2的4096个神经元跟fc1中的4096个神经元进行全连接计算。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 318}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 319 第16层计算。把output的1000（ImageNet Challenge比赛有1000个分类）个神经元跟fc2中的4096个神经元进行全连接计算。最后再经过softmax计算得到类别的概率值进行输出。 VGGNet网络结构本身并没有太多创新的内容，它可以看成是对AlexNet网络的改进优化版本。  10.4 GoogleNet GoogleNet是2014年ImageNet Challenge图像识别比赛的冠军。从它的名字我们就可以看出是来自谷歌的团队完成的。前面我们有介绍，GoogleNet之所以获得冠军，是因为它进行模型融合以后得到的效果要比VGGNet模型融合之后的效果要好。不过单模型比拼，它与VGGNet的效果相当。 虽然GoogleNet的模型的效果跟VGGNet相差不大，不过它比VGGNet更具有创新性。GoogleNet有一些更具创新性的设计，为后来的模型设计提供了很多新的思路。最早提出GoogleNet的论文是《Going Deeper with Convolutions》[4]。  10.4.1 1×1卷积介绍  在介绍GoogleNet结构之前，我们必须先来介绍一下什么是1×1卷积。1×1卷积在GoogleNet中有着大量应用，是一个非常重要的设计。它的主要作用主要有两个，一是增加网络非线性，二是减少计算量和需要训练的权值。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 319}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 320 所谓1×1卷积其实很简单，就是卷积核的大小是1×1，其他方面跟之前我们学习的卷积没有区别。图10.7为1×1卷积示意图。 \\n 图10.7 1×1卷积 使用1×1卷积对6×6图像进行特征提取，然后得到6×6的特征图。我们可以这么理解，只考虑对1张图像进行卷积计算时，3×3，5×5这样的大卷积核可以对大范围区域的特征进行提取然后得到1个特征值。1×1的卷积只对图上的1个值进行特征提取然后得到1个特征值。那么下面我们具体来看一下1×1卷积如何应用于实际的网络搭建。我们先考虑一个没有1×1卷积的卷积层计算，如图10.8所示。 \\n 图10.8 没有加入1×1卷积的卷积计算 图中conv表示卷积。 从图中可知192个28×28的特征图经过5×5，步长为1的卷积进行特征提取，得到32个28×28的特征图。这里我们主要考虑一下图中的权值数量和计算量。关于卷积的权值数量和计算量的计算我们在第8章中已有详细介绍，下面我们就不再详细说明了： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 320}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 321 权值数量的计算为：5×5×192×32+32个偏置值=153632。 计算量为（这里我们只计算乘法的计算量）：5×5×28×28×192×32≈120M，M为million百万。 我们对正常卷积计算的权值数量和计算量有了大致的了解，下面我们再来看一下加入1×1卷积后的计算，如图10.9所示。 \\n 图10.9 加入了1×1卷积的卷积计算 图中conv表示卷积。 从图中可知192个28×28的特征图经过两次卷积，最后得到32个28×28的特征图，最左边和最右边的特征图跟图10.8中的左右两边的特征图是完全一样的，只是图10.9中间多了一次1×1的卷积。 从表面上看，我们就可以看出1×1卷积的第一个作用了，增加网络的非线性。因为网络的层数多了一层，层数越多，网络的非线性就越强。 下面我们再来计算一下加入1×1卷积后网络的权值数量和计算量。 权值数量的计算为：第一个卷积层：1×1×192×16+16个偏置值=3088。第二个卷积层：5×5×16×32+32个偏置值=12832。两个卷积层权值数量相加3088+12832=15920，约为图10.9中没有1×1卷积的1/10。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 321}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 322 计算量为（这里我们只计算乘法的计算量）：第一个卷积层：1×1×28×28×192×16≈2.4M，M为million百万。第二个卷积层：5×5×28×28×16×32≈10M。两个卷积层计算量相加2.4M+10M=12.4M，约为图10.9中没有1×1卷积的1/10。 这就是1×1卷积的第二个作用，减少计算量和需要训练的权值。初看这个结果大家可能会有点难接受。前后两端都没有发生变化，看起来明明是多了一个卷积层，感觉上应该会有更多的权值和更多的计算量才对。 其实大家只要仔细再看一下就能发现其中的原因。其中一个原因是1×1卷积本身的计算量和权值数量就很少，另一个重要原因是“16”。1×1卷积计算后生成了16个28×28的特征图，比最后输出的32个28×28特征图的特征数量更少，相当于1×1卷积对原来的特征图进行了特征压缩。特征数量越少，计算量和权值数量自然就越少了。 如果上面计算中我们把16改成160，1×1卷积后产生160个28×28的特征图，那么使用了1×1卷积的计算，它的权值数量和计算量都跟不使用1×1卷积差不多。 所以并不是说用了1×1卷积，就一定可以减少权值数量和计算量，也要看1×1卷积后生成了多少张特征图。不过通常来说，我们不会让1×1卷积生成太多的特征图，所以一般来说加入1×1卷积后是可以减少网络权值数量和计算量的。  10.4.2 Inception结构 在GoogleNet最特别的设计就是Inception结构，所以GoogleNet在后来的版本中改了名字，模型的名字改成了Inception，而GoogleNet就是Inception-v1。Inception结构如图10.10所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 322}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 323 \\n 图10.10 Inception结构[4] 图中的convolutions表示卷积，filter concatenation表示滤波器合并，max pooling表示最大池化，previous layer表示前一层。 图10.10中左边的结构是Inception原始的版本，右边的结构是Inception后来优化的版本了。前面我们已经介绍过1×1卷积的作用，所以在（b）中我们看到1×1卷积应该知道它的用意了，增加网络的层数以增加非线性，同时减少网络的权值数量和计算量。 不过Inception最特别的设计不是在于1×1卷积，而是在于同时使用多种不同尺度的卷积核。我们可以看到Inception结构中使用了1×1卷积，3×3卷积，5×5卷积和一个最大池化。卷积的作用我们应该很清楚了，用来做特征提取。不同的卷积核的数值可以提取不同的特征，那么不同大小的卷积核当然也是可以从不同的尺度来提取特征的。从一个小区域提取出来的特征跟从一个大区域提取出来的特征当然是不一样的。所以Inception具有创新的设计在于使用了多种不同尺度的卷积核来提取不同尺度的特征。 下面我们举一个具体的例子来说明Inception结构的计算，如图10.11所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 323}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 324 \\n 图10.11 Inception module  图中conv表示卷积，pool表示池化。 Inception module是从GoogleNet结构中拿出来的一个具体计算的例子。输入是192个28×28的特征图，Inception module会对这些特征图进行不同的特征提取计算。假如我们把Inception看成是有4个通道的特征提取计算： 第1个通道就是对输入特征做1×1，步长为1，same padding卷积，生成64个28×28的特征图。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 324}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 325 第2个通道就是对输入特征做1×1，步长为1，same padding卷积，生成96个28×28的特征图。然后再做3×3，步长为1，same padding卷积，生成128个28×28的特征图。 第3个通道就是对输入特征做1×1，步长为1，same padding卷积，生成16个28×28的特征图。然后再做5×5，步长为1，same padding卷积，生成32个28×28的特征图。 第4个通道就是对输入特征做3×3，步长为1，same padding的最大池化，生成192个28×28的特征图。然后再做1×1，步长为1，same padding卷积，生成32个28×28的特征图。 最后再把这4个通道分别得到的特征图组合起来，得到64+128+32+32=256个28×28的特征图。 在GoogleNet中叠加了很多个Inception结构，使得网络的层数变得非常多，并且网络特征提取的能力特别强。  10.4.3 GoogleNet网络结构 这一小节我们来具体看一下GoogleNet的网络结构，如图10.12所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 325}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 326 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 326}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 327 图10.12 GoogleNet网络结构[4] 图中的conv表示卷积；MaxPool表示最大池化；LocalRespNorm表示局部响应归一化；DepthConcat表示数据拼接；FC表示全连接层；AveragePool表示平均池化。 我们就先从整体上来了解一下GoogleNet，它是一个22层的网络，网络的输入跟VGGNet一样也是224×224。除了最后一层用的是softmax函数外，其它层的激活函数都是ReLU函数。我们可以看到GoogleNet的主要结构组成是Inception module，一共叠加了9个Inception。GoogleNet网络的一些具体细节如图10.13所示。 \\n 图10.13 GoogleNet结构细节[4] 图中的type表示层的类型；patch size/stride表示窗口大小/步长；output size表示输出大小；depth表示深度；params表示参数数量；ops表示计算量；convolution表示卷积；max pool表示最大池化；avg pool表示平均池化；linear表示全连接层。 别看GoogleNet有22层之多，它的权值参数数量只有600多万，仅约为AlexNet的1/10，VGGNet的1/20。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 327}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 328 GoogleNet的输入是224×224×3的彩色图片，从图中我们可以看到第一个卷积是7×7步长为2，卷积后得到64个112×112的特征图。卷积后进行了一次3×3步长为2的最大池化，得到64个56×56的特征图。 接下来再进行一次1×1步长为1的卷积得到64个56×56的特征图，卷积后再进行3×3步长为1的卷积，得到192个56×56的特征图。这里我们要注意，图中第3行的卷积，depth为2，说明这里是有2层卷积。图中的reduce其实是表示1×1 卷积的意思，#3×3 reduce表示3×3卷积之前的1×1 卷积。#5×5 reduce表示5×5卷积之前的1×1 卷积。 卷积后再进行一次3×3步长为2的最大池化，得到192个28×28的特征图。 下面我们看到了第一个Inception模块inception(3a)，每个inception模块都有两层卷积，所有depth为2。 图中的信息还是很完整的，所以我们只要仔细看一下图中信息我们就可以知道GoogleNet的网络结构了。中间部分的计算这里就省略不讲了，大家可以自己看。 我们可以想一下，在之前的网络中卷积池化计算后得到很多特征图，最后我们还需要做全连接得到最后的分类结果。那么卷积池化计算后得到的特征图是一个4维的数据，所以我们还需要做一个“Flatten”，把4维数据变成2维，因为全连接必须是2维数据，AlexNet和VGGNet中都是这么做的。 GoogleNet的平均池化avg pool设计。我们看一下图中倒数第4行“avg pool”，这是平均池化，这个“avg pool”放在inception(5b)后面，我们之前在介绍池化操作的时候有介绍过平均池化，不过在实际网络搭建中还没有介绍过。这里使用的“avg pool”，它的作用跟“Flatten”的作用其实类似，主要目的是把4维的特征图数据变成2维的数据，再跟后面的1000个分类神经元进行全连接。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 328}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 329 inception(5b)的输出是1024个7×7的特征图，“avg pool”窗口大小为7×7，所以也就是每个特征图求平均得到1个特征值，那么1024个特征图就可以提取出1024个特征值，最后再跟1000个神经元进行全连接。GoogleNet的论文中有提到，把“Flatten”后连接1024个神经元改成“avg pool”得到1024个特征值，ImageNet Challenge图像识别比赛Top1准确率提高了0.6%[4]。另外使用“avg pool”还可以减少模型的权值数量，因为全连接层会产生大量权值，而池化计算是没有权值的。 GoogleNet的辅助分类器auxiliary classifiers设计。最后我还想再给大家介绍一下在图10.13中，GoogleNet的网络有3个输出，中间部分的两个输出是GoogleNet设计的两个辅助分类器。作者引入的两个辅助分类器也会经过softmax函数后输出预测结果，预测结果跟真实标签做对比得到辅助损失aux_loss，该模型总损失等于真实损失和辅助损失的加权和，论文中每个辅助损失使用的权重值是0.3，总的loss公式如下： 𝑡𝑜𝑡𝑎𝑙\\x84ÒÞÞ=𝑟𝑒𝑎𝑙\\x84ÒÞÞ+0.3×𝑎𝑢𝑥\\x84ÒÞÞ±+0.3×𝑎𝑢𝑥\\x84ÒÞÞ\\x9d(10.1) 这两个辅助分类器的作用是增加反向传播的梯度信号[4]，也就是说即使整个网络都是用了ReLU激活函数，但是网络的层的比较多（22层），梯度信号在反向传递的过程中，还是会损失掉一些有用的信号。 所以作者在中间层加入两个辅助分类器，帮助中间层那部分的权值和靠近输入层那部分的权值更好的训练。 辅助分类器只在模型训练阶段起作用，模型预测结果辅助分类器是不使用的。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 329}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 330 10.5 Batch Normalization 在介绍后面新的一些网络模型之前，这小节我们先介绍一下Batch Normalization，因为近几年很多网络中都使用了Batch Normalization技术。 Batch Normalization中文一般称为批量标准化/批量规范化/批量归一化等，本书中我们就称为批量标准化好了。Batch Normalization英文的简称一般为BatchNorm或BN，本书中我们就称为BN好了。BN是Google研究员Sergey Ioffe和Christian Szegedy在2015年提出的一种标准化策略。BN提出以后，很多网络都使用了BN的技术。这里特别说明一下很多网络模型用了BN以后效果有所提升，但并不是所有模型用了BN就会更好，所以我们可以把它看成是一个很可能有效的网络优化策略。下面对BN的介绍主要是参考BN的原始论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》[5]。我觉得BN虽然有效，但并不是一个很好理解的技术，如果大家看了以后不是特别理解的话也不用钻牛角钻尖，先接受它的作用，至于它的原理有时间再慢慢品。  10.5.1 Batch Normalization提出背景 BN的提出主要由于网络的内部协变量偏移（Internal Covariate Shift），简称ICS。BN作者在论文中给出了ICS一个比较规范的定义：在深度学习网络的训练过程中网络内部结点的分布变化称为内部协变量偏移[5]。其实说白了就是深度学习的深层网络之间的关系很复杂，每一层数据的微小变化都会随着网络一层一层的传递而被逐渐放大（类似于蝴蝶效应）。底层网络（假设靠近输入层的网络我们称为底层网络）输入的微小变化，就会引起高', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 330}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 331 层网络（假设靠近输出层的网络我们称为高层网络）输入分布的剧烈变化，高层网络需要不断去重新适应底层网络的参数更新。这就使得网络训练起来比较困难，也比较慢。  10.5.2 数据标准化（Normalization）  在机器学习领域中，数据标准化是一种很常用的数据处理策略。通常就是对输入数据的每个维度的特征进行标准化。具体做法就是所有数据每个维度的特征减去该维度的平均值再除以该维度的标准差。 𝑥Í@=𝑥@−𝜇√𝜎#+𝜖(10.2)  𝑥@为某个特征维度的第n个值，𝜇为该维度的平均值，𝜎为该维度的标准差，𝜖为一个接近于0的常数防止分母为0。如图10.14所示。 \\n 图10.14 数据标准化  图中a有5个数据，每个数据有4个特征，每个特征的大小不一，经过标准化处理以后得到b，b中的数据都是在0附近的一些值，数值大小差不多。经过标准化以后的数据b每个特征的均值都是0，方差为1。标准化以后的数据可以消除特征尺度（有些特征数值比较大，有些特征数值比较小）对于模型训练的影响。并且a中特征之间的相关系数和b中特征之间的相关系数是一样的。特征之间的相关系数不会因为标准化而改变。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 331}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 332  10.5.3 Batch Normalization模型训练阶段 我们了解深度学习模型存在的ICS问题后，BN作者提出了对神经网络每一层数据进行标准化处理的策略。普通的数据标准化只是对输入的样本数据进行标准化处理，然后再放入模型进行训练。而BN是对网络每一层的输入特征进行标准化处理，使得每一层的每个输入特征都是均值为0，方差为1的分布。每一层标准化的公式都如同公式10.2。 在计算网络每一层的每个信号的均值和标准差的时候，我们并不是一次性把所有数据都传入模型进行计算。因为计算机内存大小有限，所以我们训练模型的时候通常都是对数据进行分批次mini-batch的训练。所以这里每层信号计算的均值和标准差都是针对一个批次mini-batch来说的，所以这个算法的名字是Batch Normalization。 不过我们对每一层的输入信号做标准化处理可能会改变该层数据的表达。因为标准化处理会把一组数据变成另一组数据，每一组数据所包含的信息都是不同的，所以不能做完标准化处理就完事了。因此作者还对标准化后的数据进行了线性变换的处理： 𝑦(\\x83)=𝛾(\\x83)𝑥Í(\\x83)+𝛽(\\x83)(10.3) 𝑥Í(\\x83)表示网络某一层第k维度进行标准化后的数值，𝑦(\\x83)表示𝑥Í(\\x83)线性变换后的结果，𝛾(\\x83)和𝛽(\\x83)表示网络某一层第k维度的两个参数。使用𝛾(\\x83)和𝛽(\\x83)这两个参数可以对数据进行线性变换。每一层网络的每一个维度都会有不同的𝛾和𝛽，𝛾和𝛽的具体数值是由网络训练得到的，不是人为设置的。 比如网络某一层某个特征x，该特征的mini-batch计算得到的平均值是𝜇，标准差是𝜎。x进行标准化后得到𝑥Í，𝑥Í经过线性变换后得到y。那么有一个比较特别的结果，当𝛾=𝜎，并且𝛽=𝜇时线性变换后的结果y刚好等于标准化之前的特征x。也就是作者设计的线性变换的计算实际上是可以恢复原始数据的表达的，不过一般不会这么巧，毕竟𝛾和𝛽是通过模型训练', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 332}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 333 得到的。不管怎么说，𝛾和𝛽还是可以一定程度上起到恢复数据表达能力的作用。每层数据标准化和线性变换的计算流程如图10.15所示。 \\n 图10.15 BN计算流程[5] 图中内容就是我们前面讲的流程，先对数据进行标准化，然后再做线性变换。  10.5.4 Batch Normalization模型预测阶段 模型训练阶段我们已经介绍完了，主要就是对每一层数据进行标准化处理和线性变换后再传入下一层，模型训练好之后我们就把每一层每个维度的𝛾和𝛽训练好了。那么在模型预测阶段我们也要对每一层的特征进行标准化处理，不过在测试阶段我们可能只传入一个数据进行预测，只有一个数据的话计算均值和标准差就没有意义了。所以在模型测试阶段使用的均值和标准差的数据其实是使用训练集数据计算得到的。 在模型训练阶段，我们会分批次训练模型，每一个批次在网络的每一层的每个特征都可以计算出该批次的特征均值𝜇和特征方差𝜎#。我们在训练阶段把所有批次的特征均值和特征方差都保存下来，然后计算出所有特征均值的均值𝐸[𝜇]和所有特征方差的均值𝐸[𝜎#]，再把𝐸[𝜇]和𝐸[𝜎#]应用到预测阶段的标准化计算中。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 333}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 334 每一层的特性𝑥先减去用训练集数据计算得到的均值𝐸[𝜇]，再除以用训练集数据计算得到的标准差g𝐸[𝜎#]+𝜖，再做线性变换乘以𝛾加上𝛽，公式如下： 𝑦=𝑥−E[𝜇]g𝐸[𝜎2]+𝜖𝛾+𝛽(10.4)  10.5.5 Batch Normalization作用分析 在BN的原始论文中作者总结了BN的很多作用，不过我觉得BN的主要作用可以简化的总结为： 1.加快模型训练速度。这个作用不需要多说，加快模型训练速度可以节约很多模型训练的时间。 2.具有一定正则化作用。使用了BN可以减少Dropout的使用，甚至不用Dropout，并且可以减少L2正则化的使用。 3.有机会使得模型效果更好。这个效果不是绝对的，不过很多模型使用了BN之后效果确实变得更好了，所以BN值得一试。 在《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》论文中，还使用了ImageNet数据集对BN的效果做了一些实验分析，如图10.16所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 334}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 335 \\n 图10.16 BN实验分析[5] 图中的准确率是使用ImageNet验证集计算得到的，由于这里计算的是Top1准确率，所以这些模型都没有到80%。 Inception就是GoogleNet，学习率为0.0015。这个模型差不多是当时最好的图像识别模型了。 BN-Baseline为加上了BN的Inception，其它训练参数一致。我们可以看到，加上BN后模型训练速度快了很多。 BN-x5跟BN-Baseline结构一样，只不过学习率是Inception的5倍，为0.0075。我们可以看到，学习率变大以后，模型训练得更快了。（如果没有使用BN的话，学习率不能设置得太大，会使得模型调整太剧烈，导致模型无法训练或者训练的效果不好） BN-x30，跟BN-Baseline结构一样，只不过学习率是Inception的30倍。我们可以看到更大的学习率不能使得模型更快，虽然加上BN以后学习率可以设置得大一些，但是也不能太大。 BN-x5-Sigmoid跟BN-x5类似，只不过激活函数用的是Sigmoid函数（其它模型都是用ReLU函数）。不用BN的话Sigmoid在GoogleNet中是无法使用的，由于梯度消失会\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 335}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 336 使得模型无法训练。用了BN以后连Sigmoid函数也work起来了，虽然最后的模型效果还是不太理想。 Steps to match Inception表示这几个模型达到同一准确率的位置。 几个模型的训练结果如图10.17所示。  图10.17 几个模型训练结果[5] 图中的Model表示模型；Mac accuracy表示最大准确率。 从模型训练结果可以看出加上了BN的模型训练速度都比较快。训练结果最好的是BN-x30，最差的是BN-x5-Sigmoid，说明给模型加上BN以后有可能会得到更好的结果。 BN的作者融合了6个BN-x30模型，在ImageNet的验证集得到了4.9%的Top5错误率，在测试集得到了4.82%的Top5错误率，在当时应该是ImageNet数据集最好的结果了。  10.6 ResNet  ResNet是2015年ImageNet Challenge图像识别比赛的冠军，由微软亚洲研究院(MSRA)的研究团队完成，团队的负责人为何恺明。ResNet的论文获得了2016年CVPR(IEEE Conference on Computer Vision and Pattern Recognition)的最佳论文，并\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 336}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 337 且是2019年机器学习领域被引用次数最多的论文，达到了18000多次。下面对ResNet的思路进行介绍，主要是参考论文《Deep Residual Learning for Image Recognition》[6]。  10.6.1 ResNet背景介绍 在介绍ResNet网络之前我们先介绍一下何恺明，因为他是目前计算机视觉领域最知名最活跃的专家之一，其代表作ResNet更是一鸣惊人。 何恺明在广州长大，从小就是好学生，2003年保送清华大学。即便如此他还是参加了广东省高考，得到了900分满分的成绩。 2007年何恺明进入微软亚洲研究院(MSRA)的视觉计算组实习，实习导师是孙剑（现旷视科技首席科学家），当时视觉计算组的负责人是汤晓鸥（商汤科技创始人）。 2011年香港中文大学博士毕业后正式加入MSRA 。 2016年8月，何恺明离开微软亚洲研究院，加入Facebook AI研究院（FAIR）。 2020年1月11日，荣登AI全球最具影响力学者榜单。 观察ImageNet Challenge前几届的优秀模型，我们不难发现一个现象，似乎模型的层数越多，效果就越好。AlexNet有8层，VGG19有19层，GoogleNet有22层。于是ResNet团队就做了一个实验，他们模仿VGGNet的模型，分别设计了20，32，44，56层的网络，并使用CIFAR-10数据集进行测试，测试结果如图10.18所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 337}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 338 \\n 图10.18 不同深度的网络结果对比  图中的iter表示迭代次数，error表示误差。 《Deep Residual Learning for Image Recognition》论文中把模仿VGGNet做出来的一些模型称为“plain network”。实验结果表明，20层的网络误差最低，56层的网络误差最高，并且层数越多误差越大，实验结果刚好是跟我们前面的猜想是相反的。 网络层数不是太多的时候，模型的正确率确实会随着网络的层数增加而提升，不过随着网络层数的增加，正确率也会达到饱和，这个时候如果再继续增加网络层数，那么正确率就会下降。ResNet论文中把这种现象称为退化问题（Degradation Problem），并且ResNet作者认为退化问题不是由过拟合引起的。   10.6.2 残差块（Residual Block）介绍 ResNet之所以叫残差网络（Residual Network），是因为ResNet是由很多残差块（Residual Block）组成。而残差块的使用，可以解决前面说到的退化问题。残差块如图10.19所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 338}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 339 \\n 图10.19 残差块（Residual Block）[6] 图中的weight layer是3×3的卷积层，F(x)表示经过两个卷积层计算后得到的结果，identity表示“恒等映射”也称为“shortcut connections”，说白了就是把x的值不做任何处理直接传过去。最后计算F(x)+x，这里的F(x)跟x是shape相同的信号，所以可以进行element-wise addition，也就是对应位置进行相加。 图10.20也是相同的残差块，加上了BN层。  图10.20 加上BN层的残差块 图中的Conv表示卷积；Batch Norm表示批量标准化。 残差块可以有多种设计方式，比如改变残差块中卷积层的数量，或者残差块中卷积窗口的大小，或者卷积计算后先ReLU后BN，就像是搭积木一样，我们可以随意设置。ResNet研究团队经过很多的测试最终定下了两种他们觉得最好的残差块的结构，如图10.21所示。 \\n 图10.21 两种残差块结构[6] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 339}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 340 图中的1×1，3×3表示卷积窗口大小，64和256表示特征图数量，注意这里的图片是作者给出的示意图，真正搭建模型的时候特征图数量不一定是图中的64和256。图中左边的残差结构有2个卷积层前面我们已经见过，右边的残差结构有3个卷积层，加上BN层后如图10.22所示。  图10.22 3层残差结构 图中的Conv表示卷积；Batch Norm表示批量标准化。 ResNet也有很多个版本，比如ResNet18，ResNet34，ResNet50，ResNet101，ResNet152等，不同的数字表示不同的网络层数，18就是18层，152就是152层。作者在搭建不同版本的ResNet的时候使用了不同的残差结构，ResNet18和ResNet34用的是2层卷积的残差结构，ResNet50，ResNet101，ResNet152用的是3层卷积的残差结构。 残差结构的主要作用是传递信号，把深度学习浅层的网络信号直接传给深层的网络。深度学习中不同的层所包含的信息是不同的，一般我们认为深层的网络所包含的特征可能对最后模型预测更有帮助，但是并不是说浅层的网络所包含的信息就没用，深层网络的特征就是从浅层网络不断提取而得到的。现在我们给网络提供一个“捷径”也就是“shortcut connections”，它可以直接将浅层信号传递给深层网络，跟深层网络的信号结合，来帮助网络得到更好的效果。  10.6.3 ResNet网络结构 图10.23中有3个网络结构，左边为VGG19，中间为模仿VGGNet设计的34层plain network，右边为ResNet34。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 340}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 341 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 341}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 342 图10.23 ResNet网络结构[6] 图中的conv表示卷积；pool表示池化；fc表示全连接层；avg pool表示平均池化；output size表示输出大小；image表示图片。 VGG19和plain network大家自己看看就行，仔细看看就能看懂。plain network中有个地方要注意，plain network没有使用pooling层（池化层不一定要使用）。在网络中有几个位置我们可以看到“7×7conv，64，/2”，“3×3conv，128，/2”，“3×3conv，256，/2”，“3×3conv，512，/2”。这里的7×7和3×3表示卷积窗口大小；65/128/256/512表示卷积后生成多少特征图；/2表示卷积的步长为2，卷积后特征图的长宽都会变为原来的1/2。最后的avg pool为平均池化，是模仿GoogleNet的设计。 我们重点来看看ResNet34，ResNet34是从34层的plain network改进得来的，结构上跟34层的plain network非常相似。主要区别是ResNet34增加了“shortcut connections”，由16个2层的残差结构堆叠而成。不过我们发现“shortcut connections”分为实线和虚线，实线表示残差结构的输入x与残差结构中卷积计算结果F(x)的shape是一样的，可以直接进行对位相加，具体例子如图10.24所示。  图10.24 实线“shortcut connections”例子 图中的Conv表示卷积；Batch Norm表示批量标准化，batch表示批次。 虚线“shortcut connections”表示无法直接进行对位相加的接连。我们可以发现虚线部分的残差块输入x和残差结构中卷积计算结果F(x)的shape是不一致的，输入x的特征图\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 342}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 343 数量是F(x)特征图数量的1/2，并且输入x的特征图长宽是F(x)特征图长宽的2倍。虚线“shortcut connections”在ResNet论文中给出了A，B两种连接方式。 A．zero-padding。先做步长为2的恒等映射，新增的特征图用0填充。ResNet一般不用这种方式，论文中没有写明白具体的操作，网上的资料也比较少，所以下面zero-padding的操作主要来自我的推测，如图10.25表示1张特征图进行步长为2的Identity mapping： \\n 图10.25 步长为2的恒等映射 图中的Identity表示恒等映射，Stride表示步长。 图10.26表示多张特征图步长为2的恒等映射，特征图变成原来的2倍，新增的特征图用0填充： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 343}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 344 图10.26 Identity mapping+zero-padding 图中的Identity表示恒等映射。 图10.27表示zero-padding的“shortcut connections”在ResNet中使用的具体例子：  图10.27 zero-padding 图中的Conv表示卷积；Batch Norm表示批量标准化；batch表示批次；Identity mapping表示恒等映射。 Zero-padding的好处是计算简单并且不需要给网络增加额外的权值，同时也可以得到较好的效果。 B．projection shortcut。ResNet作者把第二种方式称为“projection shortcut”，具体做法是用步长为2，大小为1×1的卷积来对残差块的输入信号x进行特征提取，使x信号和F(x)信号的shape一致。ResNet通常都是使用projection shortcut的方法，如图10.28： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 344}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 345 图10.28 步长为2，1×1卷积 图中的conv表示卷积。 图10.29表示projection shortcut的“shortcut connections”在ResNet中使用的具体例子：  图10.29 projection shortcut 图中的Conv表示卷积；Batch Norm表示批量标准化；batch表示批次。 相比于zero-padding，使用projection shortcut可以让模型获得更好的效果。另外作者还提出了另外一种shortcut连接方案“all shortcuts are projections”。 C．all shortcuts are projections。顾名思义，也就是ResNet中所有的shortcuts，不管是没有特征图数量增加的实线shortcut，还是有特征图数量增加的虚线shortcut，都使用带1×1卷积的projection shortcut来进行连接。 ResNet作者使用imagenet数据集对A，B，C三种shortcut方式进行了评估，结果如图10.30所示。 \\n 图10.30 三种shortcut方式评估[6] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 345}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 346 图中的model表示模型；top-1 err.表示top1错误率；top-5 err.表示top5错误率。 图中的ABC分别表示前面我们提到的三种shortcut方式，ResNet-50，ResNet-101，ResNet-152用的是B(projection shortcut)的方式。我们从实验结果可以看出，C方案比B方案稍微好一点点，B方案比A方案稍微好一点点。C方案需要给网络增加较多的计算量和权值参数，B方案需要给网络增加一点计算量和权值参数，C方法不需要额外的权值参数。ResNet作者基于综合情况考虑，最终选择在模型中使用了B方案。所以我们现在看到的ResNet模型一般都是使用B(projection shortcut)的方式，一般的残差块都是identity mapping恒等映射，只有特征图数量改变的时候使用projection shortcut。 ResNet团队最终在2015年ImageNet Challenge图像识别比赛中，融合了6个不同深度的ResNet模型，得到了3.57%的top5测试集错误率，获得了当年比赛的冠军。图10.31为不同模型的测试结果。 \\n 图10.31 不同模型的测试结果[6] 图中的method表示模型，top-5 err. (test)表示测试集top5错误率。  10.6.4 ResNet-V2 2016年，何恺明所在的ResNet团队又发表了一篇关于ResNet的论文《Identity Mappings in Deep Residual Networks》。在这篇论文中，他们提出了一种关于ResNet的结构优化，并表示新的ResNet结构可以让ResNet获得更好的效果。我们一般把\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 346}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 347 《Identity Mappings in Deep Residual Networks》[7]这篇论文中提到的ResNet结构称为ResNet-V2，如图10.32所示。 \\n 图10.32 残差结构优化[7]  图中的Iterations表示迭代次数；Test Error表示测试集错误率。 (a)original表示原始的ResNet的残差结构，(b)proposed表示新的ResNet的残差结构。主要差别就是(a)结构先卷积后进行BN和激活函数计算，最后执行addition后再进行ReLU计算；(b)结构先进行BN和激活函数计算后卷积，把addition后的ReLU计算放到了残差结构内部。作者使用这两种不同的结构在CIFAR-10数据集上做测试，模型用的是1001层的ResNet模型。从图中结果我们可以看出，(b)proposed的测试集错误率明显更低一些，达到了4.92%的错误率，(a)original的测试集错误率是7.61%。 其实ResNet团队对ResNet的残差结构做了很多不同的尝试，如图10.33所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 347}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 348 \\n 图10.33 shortcut结构的不同尝试[7] 图中(a),(b),(c),(d),(e),(f)都是作者对残差结构的shortcut部分进行的不同尝试，这里我们就不具体介绍了，因为作者对不同shortcut结构的尝试结果如图10.34所示。 \\n 图10.34 不同shortcut结构的测试结果[7] 作者用不同shortcut结构的ResNet-110在CIFAR-10数据集上做测试，发现最原始的(a)original结构是最好的，也就是identity mapping恒等映射是最好的。 然后作者又对残差结构的残差单元进行了不同的尝试，如图10.35所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 348}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 349 \\n 图10.35 不同残差单元测试结果[7] 最好的结果是(e)full pre-activation，其次到(a)original。(a)original的残差结构是应用在最原始的ResNet中的残差结构；(e)full pre-activation的残差结构就是我们前面介绍的ResNet-V2中的残差结构。 从ResNet的设计和发展过程中我们可以知道，深度学习是一门非常注重实验的学科，我们需要有创新的好想法，同时也需要大量的实验来支撑和证明我们的想法。有些时候我们无法从理论上推断哪种模型设计或优化方法是最好的，这个时候我们可能就需要做大量的实验来不断尝试，找到最好的结果。如今ResNet已经得到广泛的应用和肯定，对深度学习和计算机视觉做出了重要贡献。  经典图像识别模型介绍下一章继续。  10.7参考文献 [1] Russakovsky O , Deng J , Su H , et al. ImageNet Large Scale Visual Recognition Challenge[J]. International Journal of Computer Vision, 2015, 115(3):211-252. \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 349}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 350 [2] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012. [3]Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. [4]Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014. [5] Ioffe S , Szegedy C . Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift[J]. 2015. [6] He K , Zhang X , Ren S , et al. Deep Residual Learning for Image Recognition[C]// 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, 2016. [7] He K , Zhang X , Ren S , et al. Identity Mappings in Deep Residual Networks[J]. 2016.           ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 350}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 351 第11章-经典图像识别模型介绍（下） 这一章节我们继续介绍经典图像识别模型。  11.1 Inception模型系列 Inception的前身就是前面我们介绍过的GoogleNet，GoogleNet中提出了一个多种尺度同时进行特征提取的结构称为Inception，所以GoogleNet后来改名变成了Inception-v1。Google的团队后来在Inception-v1的基础上做了更多的研究和优化，提出了Inception-v2，Inception-v3，Inception-v4，Inception-ResNet-v1，Inception-ResNet-v2多个优化版本。 11.1.1 Inception-v2/v3优化策略 Inception-v2和Inception-v3都出自同一篇论文《Rethinking the inception architecture for computer vision》[1]。该论文提出了多种基于Inception-v1的模型优化方法，Inception-v2用了其中的一部分模型优化方法，Inception-v3用了论文中提到的所有优化方法。相当于Inception-v2只是一个过渡版本，Inception-v3一般用得更多。下面我们主要针对论文中所涉及的一些比较重要的优化方法进行讲解，具体是用在Inception-v2还是Inception-v3就不做详细区分了，可以都看成是Inception-v3的内容。顺便说一下之前我们学过的标签平滑（Label Smoothing）就是出自Inception-v3的论文。 Inception-v3最大的优化是模型结构上的优化，在Inception-v3中作者对Inception结构中的卷积进行了分解。分解后的好处是增加了网络的层数，也就是增加了网络的特征提取', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 351}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 352 能力。同时作者还对Inception结构进行了一些调整，设计了不同的Inception，用在模型的不同位置。 我们先回忆一下最原始的Inception结构，如图11.1所示。 \\n 图11.1 原始Inception结构[1] 图中的convolutions表示卷积，filter concatenation表示滤波器合并，max pooling表示最大池化，previous layer表示前一层。 Inception-v3中提出了一个新思路，可以使用两个3×3卷积来替代原始Inception结构中的5×5卷积，如图11.2所示。 \\n 图11.2 分解5×5卷积 将5×5卷积分解为两层的3×3卷积，对于最后得到的特征来说，感受野的大小是相同的，都是5×5的区域。相当于5×5卷积对5×5区域进行特征提取，得到一个特征值；两层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 352}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 353 的3×3卷积对5×5区域进行特征提取，也是得到一个特征值。这两种特征提取的方式类似，不过最后得到的特征值可能是不同的，右边的两层3×3卷积做了两次卷积得到的特征值或许会更好一些。 沿着这个卷积分解的思路继续思考，作者又提出了一种新的卷积分解，把3×3卷积分解为1×3卷积和3×1卷积，如图11.3所示。 \\n 图11.3 分解3×3卷积 把3×3卷积分解为1×3卷积和3×1卷积，道理跟将5×5卷积分解为两层的3×3卷积差不多，对于最后的特征来说，感受野的大小是一样的，并且分解后可以让网络层数变得更多，增加网络的非线性。理论上n×n的卷积都可以分解为1×n卷积和n×1卷积。 作者还分析了减小特征图大小时的操作，如图11.4所示。 \\n 图11.4 减小特征图大小的操作[2] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 353}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 354 图片Pooling表示池化。 作者认为直接使用窗口大小2×2，步长为2的池化来压缩特征图的大小效果不太好。因为特征图的数量不变，但是特征图的长宽变成为原来的1/2，相当于特征值的数量被压缩为原来的1/4了，特征值的数量一下减少太多不利于模型的训练，所以左边的结构不太理想。右边的结构先用Inception来增加特征图数量然后再进行池化减小特征图大小，对于特征的提取来说没什么问题，就是计算量太大。 所以设计了新的Inception结构，在减小特征图大小的同时可以增加特征图的数量，如图11.5所示。 \\n 图11.5 用于减小特征图大小并增加特征图数量[2] 图中Filter Concat表示滤波器拼接；stride表示步长；concat表示拼接；conv表示卷积；pool表示池化。 除此之外作者还根据实验分析和建模经验，设计了一些新的Inception结构，如图11.6所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 354}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 355 \\n 图11.6 一些新的Inception结构[2] 图中Filter Concat表示滤波器拼接；Pool表示池化。 这些不同的Inception结构就像搭积木一样堆叠起来，组成了Inception-v3的模型。 11.1.2 Inception-v2/v3模型结构 Inception-v2/v3模型的结构非常庞大，Inception-v2/v3论文中给出的模型结构描述也不是特别清晰，结构如图11.7所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 355}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 356 \\n 图11.7 Inception-v2/v3模型结构[2] 图中architecture表示结构；Filter Concat表示滤波器拼接；Pool表示池化；type表示层的类型；patch size/stride or remarks表示窗口大小/步长；input size表示输入大小；conv表示卷积；pool表示池化；linear表示全连接层。 图中Inception-v2/v3的结构大家应该能大致看懂，但是好像又看不太懂。那么要如何把Inception-v2/v3结构在书里表示清楚，让大家能看懂，我想了很久。其实要把Inception-v2/v3结构图画出来不难，难的是怎么在书里画出来，书这个信息载体对长图片的支持不太友好。最后我想到了一个比较清晰简洁，在书里看起来也相对比较友好的画结构图的方法——“方块构图法”（我瞎起的名字）。我画的这个结构跟论文中描述的结构细节上有些许不同，我是参考tensorflow.keras.applications.inception_v3中的结构画的，Inception-v2/v3结构图如图11.8所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 356}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 357 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 357}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 358 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 358}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 359 \\n 图11.8 Inception-v2/v3结构图 图中的Conv表示卷积；MaxPool表示最大池化；AvgPool表示平均池化；Concat表示拼接；FC表示全连接层；V表示Valid Padding。 相信这个结构图大家应该是很容易看懂的，我只需要稍微提几个注意事项： 1. 图中卷积和池化默认的步长是1所以没有写出来。如果有“/2”表示步长为2。 2. 图中卷积和池化默认都是same padding所以没有写出来。如果有“V”表示valid padding。 3. 每个卷积层后面有BN和ReLU，图中省略了。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 359}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 360 4. Inception-ABCD表示论文中提到的几种不同类似的Inception模型，不过并不是跟论文中完全一致。 最后我们来看一下Inception-v3在ImageNet数据集中的测试结果，图11.9为Inception-v3单模型测试结果。 \\n 图11.9 Inception-v3单模型测试结果[2] 图中Network表示网络；Crops Evaluated表示模型评估时裁剪出多少张图片进行预测；Top-5 Error表示Top5错误率；Top-1 Error表示Top1错误率。 图11.10为Inception-v3模型融合后的测试结果。 \\n 图11.10 Inception-v3模型融合后测试结果[2] 图中Network表示网络；Models Evaluated表示评估时集成了几个模型；Crops Evaluated表示模型评估时裁剪出多少张图片进行预测；Top-5 Error表示Top5错误率；Top-1 Error表示Top1错误率。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 360}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 361 Inception-v3模型融合后的Top5错误率为3.58%，这个结果跟2015年ImageNet Challenge图像识别比赛的冠军ResNet已经非常接近，ResNet的Top5错误率为3.57%。 11.1.3 Inception-v4和Inception-ResNet介绍 Inception-v3结构的复杂程度以后够复杂了，但是它还有几个升级版本，就是Inception-v4，Inception-ResNet-v1和Inception-ResNet-v2。这几个升级版本都出自同一篇论文《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》[3]。 这几个升级版的Inception模型基本设计思路都是遵循Inception-v3的设计思路，只不过比Inception-v3再稍微更复杂一些。Inception-v4的作者不认同非常深层的网络一定要使用残差单元才行，所以他们设计了没有使用残差单元的深度网络Inception-v4，我大概数了一下论文中的Inception-v4结构，应该是有76层。不过Inception-v4的作者认同加上残差单元以后，模型可以训练得更加快一些。 Inception-ResNet-v1和Inception-ResNet-v2顾名思义就是Inception的设计加上ResNet的残差结构设计得到的模型。 由于Inception-v4，Inception-ResNet-v1和Inception-ResNet-v2的结构设计跟Inception-v3差别不大，并且使用一次“方块构图法”消耗的体力太多，所以这几个模型的具体网络结构就不给大家展示了。下面使用论文中的一些图给大家展示一下Inception-v4和Inception-ResNet-v2的结构，大家大致看一下即可，图11.11为Inception-v4的结构图. ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 361}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 362 \\n 图11.11 Inception-v4结构图[3] 图中的Conv表示卷积；MaxPool表示最大池化；Output表示输出；Input表示输入；Filter concat表示滤波器拼接；Avg Pooling和Average Pooling表示平均池化；stride表示步长。 Inception-v4延续了Inception-v3的设计并进行了一些优化，主要也是使用多个不同的Inception结构堆叠得到深层的网络模型。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 362}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 363 图11.12为Inception-ResNet-v2结构图。 \\n 图11.12 Inception-ResNet-v2结构[3] 图中的Conv表示卷积；MaxPool表示最大池化；Output表示输出；Input表示输入；Filter concat表示滤波器拼接； Average Pooling表示平均池化；stride表示步长。 Inception-ResNet-v2的结构特殊之处就是把Inception和残差单元的设计结合到了一起变成了Inception-resnet模块。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 363}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 364 图11.13为4个Inception模型在ImageNet数据集中，单模型Top5错误率的测试结果。 \\n 图11.13 4种Inception模型在ImageNet数据集测试结果[3] 图中的Epoch表示训练周期；Error表示误差。 从图中我们可以看到Inception-v3和Inception-ResNet-v1效果是差不多的，可能Inception-ResNet-v1稍微好一点点。Inception-v4和Inception-ResNet-v2效果是差不多的，可能Inception-ResNet-v2稍微好一点点。 图11.14为几个模型在ImageNet数据集中单模型测试结果。 \\n 图11.14 几个不同模型的单模型测试结果[3] 图中的Network表示网络；Crops表示从一张图片中裁剪出多少张图片；Top-1 Error表示Top1错误率；Top-5 Error表示Top5错误率。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 364}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 365 Crops中的dense表示直接对一张测试图片进行预测，得到一个预测结果。Crops中的144表示从一张测试图片中按照一定的规则裁剪出144个子区域，然后对这144个区域分别进行预测得到144个预测结果，最后再对这144个预测结果求平均得到最终的一个预测结果[4]。 图11.15为模型融合的测试结果。  图11.15 模型融合的测试结果[3] 图中的Network表示网络；Models表示集成的模型数量；Top-1 Error表示Top1错误率；Top-5 Error表示Top5错误率。 使用1个Inception-v4和3个Inception-ResNet-v2模型进行融合，在ImageNet的验证集中得到了3.1%的Top5错误率，在ImageNet的测试集中得到了3.08%的Top5错误率，这个结果已经比ResNet的模型融合后的结果更好了。  11.2 ResNeXt ResNeXt获得了2016年ImageNet Challenge图像识别比赛的亚军。是由来自加州大学圣地亚哥分校(UCSD)和Facebook AI Research(FAIR)的团队完成。名字中的“Res”表示“ResNet”，名字中的“NeXt”表示“next dimension”，在ResNeXt的论文中“next dimension”被称为“cardinality dimension”。作者提出把cardinality作为深度学习网络中的一个新参数，就像是网络的深度（网络的层数），宽度（特征图数量）一样。\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 365}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 366 最早提出ResNeXt的论文是《Aggregated Residual Transformations for Deep Neural Networks》[5]。在介绍ResNeXt之前，我们先来了解一下ResNeXt网络中的核心内容，分组卷积(Group Convolution)。  11.2.1 分组卷积（Group Convolution）介绍 分组卷积是一种特殊的卷积，最早应该是用在AlexNet网络中，AlexNet的原始结构分为上下两部分，我们可以看成是上下两个通道或者是上下两个分组，如图11.16所示。 \\n 图11.16 AlexNet结构[6] 图中的Stride表示步长；Max Pooling表示最大池化；dense表示全连接层。 AlexNet使用分组卷积主要是当时软硬件条件比较受限，AlexNet团队想用两个GPU来加速模型模型，一个GPU运行上面分组的卷积计算，一个GPU运行下面分组的卷积计算。所以在AlexNet中使用这样的分组卷积设计并不是他们的本意，更多的是巧合。不过有实验证明当初AlexNet里面使用分组卷积是正确的设计，使用了分组卷积以后不仅计算量和权值数量减少了，并且模型准确率也提升了一些[5]，实验结果如图11.17所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 366}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 367 \\n 图11.17 不同分组AlexNet的结果[7] 图中的Model Parameters表示模型参数数量；Top-5 Val. Error表示Top5验证集错误率；groups表示分组数。 图中横坐标表示模型的参数数量，纵坐标表示模型错误率，原始的AlexNet为图中的“2 groups”表示将卷积分为2组，“no groups”表示不分组，”4 groups”表示将卷积分为4组。从图中我们可以看到分组越多模型的参数越少，模型的准确率上下会有浮动，不过变化不是很大。这3个实验结果里将卷积分为2组是最好的选择。 下面我们正式介绍分组卷积，简单来说分组卷积就是将特征图分为不同的组，再对每组特征图分别进行卷积。这里的分组一般都是分为n个等份，理论上其实不是等份也可以，不过一般为了实现方便都是分为等份。分组卷积的好处主要是可以减少模型的计算量和训练参数，同时对模型准确率影响不大，甚至有可能会提高模型准确率。下面我们通过几个图来详细了解一下，图11.18为普通卷积：. \\n 图11.18 普通卷积 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 367}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 368 图中的Conv表示卷积。 这里特征图的大小和卷积和的大小都不是重点内容，所以图中没有标出，我们只要能看出6个特征图卷积后得到12个特征图就可以了。不过为了让大家理解分组卷积的计算量和权值数量这里我们举例计算一下，假设特征图大小是28×28，卷积核大小为5×5，Same Padding。卷积层权值数量为5×5×6×12+12=1812，乘法计算量为5×5×28×28×6×12=1411200。 下面我们看一下分组卷积，分组卷积一般都是把特征图分为n个等份，然后再对n个等份的特征图分别卷积，这里的n可以人为设置，如图11.19所示。 \\n 图11.19 分组卷积 图中的Conv表示卷积。 为了跟普通卷积对比，所以这里分组卷积的例子输入也是6个特征图，输出也是12个特征图。这里我们可以看到把6个特征图分为了3组，每组2个特征图，每组分别进行卷积，卷积后得到4个特征图。最后再把3个组共12个特征图组合起来。假设特征图大小是28×28，卷积核大小为5×5，Same Padding。这里卷积层权值数量为5×5×2×4×3+12=612，乘法计算量为5×5×28×28×2×4×3=470400。权值数量和计算量都约为普通卷积的1/3。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 368}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 369 11.2.2 ResNeXt中的分组卷积  这一小节我们主要学习ResNeXt的核心内容，分组卷积在ResNeXt中的使用。ResNeXt中提出的一个模型调节的新维度“cardinality”其实就是分组卷积中的分组数量，比如cardinality为2表示把卷积分为2组，cardinality为32表示把卷积分为32组。  作者将分组卷积应用到ResNet的残差结构中，如图11.20所示。 \\n 图11.20 残差结构中使用分组卷积[5] 图中的in表示输入；out表示输出；d表示dimension，代表维度；total 32 paths表示总共32个通道。 图中左边为ResNet的残差结构，右边是cardinality为32的新残差结构。每个格子中的3个数字分别表示（输入通道数，卷积核大小，输出通道数）。原始的ResNet的残差结构就不用多说了，ResNeXt中的残差结构也很容易理解，第1层卷积输入是256个特征图，输出是4×32=128个特征图。然后对这128个特征图进行分组，分为32组，每组4个特征图，在第2层卷积进行分组卷积计算。第2层卷积计算后，每组卷积都是产生4个特征图。第3层卷积是对4个特征图进行卷积产生256个特征图。然后再对32个分组产生的32组每组256个特征图进行element-wise addition按位相加，最后再加上shortcut恒等映射传过来的信号，得到残差结构的输出。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 369}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 370 这里大家可能会有个小疑问，为什么左边原始的残差结构第1层卷积输入256个特征图，产生64个特征图。而右边的分组卷积残差结构第1层卷积输入256个特征图，产生4×32=128个特征图。看起来两个残差结构中间部分产生的特征图数量不一致。其实作者之所以这么设计分组卷积特征图的数量主要是为了使得两个残差结构的训练参数的数量大致相同。 我们来计算一下图11.20中左边的残差结构训练参数的数量为（为了计算方便忽略偏置值）：256×64+3×3×64×64+64×256≈70000。右边的分组卷积残差结构参数数量为（为了计算方便忽略偏置值）：C×(256×d+3×3×d×d+d×256)\\t≈70000，其中C=32表示cardinality为32，d=4表示每个分组有4个特征图。右边的残差结构我们也可以表示为32×4d，意思是32个分组每组4个特征图；如果是8×16d表示8个分组，每组16个特张图；如果是1×64d表示1个分组（也就是不分组），每组64个特张图。在作者的设计下，新的分组卷积残差结构权值数量和计算量跟原始的残差结构差不多，不过最后模型效果可以变得更好。 其实在ResNeXt的论文中，作者给出了3种形式的分组卷积残差结构，这3种形式的分组卷积残差结构输入信号和输出信号都是一样的，只是中间部分略有不同，如图11.21所示。 \\n 图11.21 3种形式的分组卷积残差结构[5] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 370}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 371 图中的in表示输入；out表示输出；d表示dimension，代表维度；total 32 paths表示总共32个通道；group表示分组数；equivalent表示相等的；concatenate表示拼接。 前面我们已经仔细分析了(a)结构，实际上(b)结构和(c)结构跟(a)结构也是非常类似的。(b)结构是在第2层卷积输出的位置对32组每组4个特征图进行concatenate，得到了128个特征图。然后再传给第3层卷积进行计算，最后输出256个特征图。(c)结构作者在这里用简化的方式表示分组卷积的计算，注意看(c)结构中有些数字是加粗的，加粗的数字表示跟分组卷积相关。也就是(c)结构的第2层卷积跟(a)，(b)结构都不一样，(c)的第2层卷积分为32组，每组输入4个特征图，输出128个特征图。然后再对这32组每组128个特征图进行element-wise addition按位相加，之后传给第3层卷积。第3层卷积就是输入128个特征图，输出256个特征图。 这3种形式的残差结构作者都进行了实验，发现最后得到的结果基本上都差不多，最终选择了(c)结构。作者认为(c)结构更简单速度也更快。  11.2.3 ResNeXt的网络结构 了解了ResNeXt中使用的残差结构以后，下面我们来看一下ResNeXt的网络结构，如图11.22所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 371}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 372 \\n 图11.22 ResNeXt网络结构[5] 图中的stage表示阶段；conv表示卷积；output表示输出；stride表示步长；d表示dimension，代表维度；max pool表示最大池化；C表示cardinality，代表分组数；global average pool表示全局平均池化；fc表示全连接；params表示参数数量；FLOPs表示计算量。 图中有两个网络的结构，一个是ResNet-50，一个是ResNeXt-50(32×4d)。ResNeXt-50(32×4d)是在ResNet-50网络结构的基础上对残差结构进行了一些修改得到的，所以这两个模型的结构框架基本是一致的。这个结构图还是很容易看懂的，基本上要讲解的地方不多。ResNeXt-50(32×4d)的残差结构是加上了分组卷积的，(32×4d)表示图中的conv2中使用的分组卷积是32个分组每组4个特征图。ResNeXt的结构一般只需要标明第一个分组卷积残差模块的信息，因为后面conv3，conv4，conv5中的分组卷积信息都可以由第一个\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 372}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 373 分组卷积得到。按照ResNeXt的设计思路，所有的分组卷积cardinality都是一样的，比如图中的32。conv2特征图大小是56×56，每组4个特征图；conv3特征图大小是28×28，每组8个特征图；conv4特征图大小是14×14，每组16个特征图；conv5特征图大小是7×7，每组32个特征图。 图中我们还可以看出ResNet-50和ResNeXt-50(32×4d)的权值参数数量和浮点计算量都是差不多的。而ResNet-101和ResNeXt-101(32×4d) 的权值参数数量和浮点计算量也都是差不多的。这4个模型在ImageNet数据集中的测试结果如图11.23所示。 \\n 图11.23 4个模型准确率对比[5] 图中的epochs表示周期；top-1 error表示top1错误率；train表示训练集；val表示验证集。 图中可以看出ResNeXt-50(32×4d)比ResNet-50要更好，ResNeXt-101(32×4d)比ResNet-101要更好。 作者也尝试了一些不同分组的残差模块，测试结果如图11.24所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 373}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 374 \\n 图11.24 不同分组的残差网络测试结果[5] 图中setting表示结构设置；top-1 error表示top1错误率。 图中的setting表示模型第一个分组卷积残差模块的分组数和特征图数量，结果看来32×4d是一个比较好的选择。 图11.25为ResNeXt使用不同大小的图片跟不同模型在ImageNet验证集的单模型对比结果： \\n 图11.25 不同模型测试结果 图中top-1 err表示top1错误率；top-5 err表示top5错误率。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 374}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 375 ResNet和ResNeXt使用的是224×224和320×320的分辨率图片，Inception相关的模型用的是299×299的分辨率图片。结果可以看出使用分辨率比较高的图片准确率也会高一些，ResNeXt-101是上面几个模型中最好的。 ResNeXt模型融合后在ImageNet测试集得到了3.03%的Top5错误率，比Inception-v4/Inception-ResNet-v2的3.08%结果要更好。  11.3 SENet SENet是ImageNet Challenge图像识别比赛2017年的冠军，是来自Momenta公司的团队完成。他们提出了Squeeze-and-Excitation Networks（简称SENet）。SENet不是独立的模型设计，只对模型的一种优化。一般SENet都会结合其它模型一起使用，比如SENet用于ResNet-50中我们就把这个模型称为SE-ResNet-50，比如SENet用于Inception-ResNet-v2中我们就把这个模型称为SE- Inception-ResNet-v2。最早提出SENet的论文是《Squeeze-and-Excitation Networks》[8]。 11.3.1 SENet介绍  我们之前介绍了很多模型，Inception系列的模型使用不同尺度的卷积大小来提取不同的特征，ResNet给模型增加了捷径更有利于信号传递，ResNeXt使用了分组卷积把特征提取进行分组处理。SENet的模型优化思路很有意思，主要是针对特征的channel进行优化。  我们可以想象在进行图像识别的时候，卷积计算后生成了很多特征图，不同的滤波器会得到不同的特征图，不同的特征图代表从图像中提取的不同的特征。我们得到了这么多的特', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 375}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 376 征图，按理来说某些特征图的应该更重要，某些特征图应该没这么重要，并不是所有特征图都一样的重要。所以SENet的核心思想就是给特征图增加注意力和门控机制，增强重要的特征图的信息，减弱不重要的特征图的信息。 那么如何做到增强重要的信息，减弱不重要的信息，我们看一下SENet的名字Squeeze-and-Excitation Networks。其中的“Squeeze”中文意思是“挤压”，在模型中的实际操作其实是压缩特征图的特征，作者使用的压缩特征图的特征的方式是avg pooling平均池化。这个大家应该很熟悉了，求一个特征图所有值的平均值，把avg pooling计算后的结果作为这个特征图压缩后的特征。比如一共有64个特征图，“Squeeze”计算后我们就会得到64个值，代表64个特征图压缩后的特征。 “Excitation”中文意思是“激发”，在模型中的实际操作是调节特征图信号强弱，作者使用的方式是给“Squeeze”计算后的结果加上两个全连接层，最终输出每个特征图对应的激活值，激活值可以改变特征图信号的强弱。每个特征图乘以它所对应的激活值，得到特征图的输出，然后再传给下一层。 文字描述很难具体描述清楚，我们还是看图吧，我们先复习一下普通的ResNet中的残差结构如图11.26所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 376}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 377 \\n 图11.26 普通残差结构 图中的Conv表示卷积；Batch Norm表示批量标准化；Identity mapping表示恒等映射；batch表示批次。 普通的残差结构我们就不需要多说了，下面我们看一下加上了Squeeze-and-Excitation模块后的残差结构如图11.27所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 377}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 378 \\n 图11.27 SE-残差结构 图中的Conv表示卷积；Batch Norm表示批量标准化；Identity mapping表示恒等映射；batch表示批次；AvgPool表示平均池化。 加上Squeeze-and-Excitation模块后的残差结构主要变化是在原来的残差结构最后一个卷积层后面进行Squeeze-and-Excitation的操作。Squeeze就是先做平均池化，得到每一\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 378}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 379 个特征图的压缩特征。图中特征图大小为56×56，所以池化的窗口大小也是56×56。池化过后就是Excitation操作，前面我们有提到Excitation操作有两个全连接层，这是SENet原始论文中的做法，实际我们在写程序的时候也可以用两个窗口大小1×1的卷积层的替代，效果跟全连接是一样的。Excitation操作部分最后的激活函数是Sigmoid函数，作者在这里使用Sigmoid函数主要是利用Sigmoid函数输出范围是0-1这个特性，让Excitation的输出激活值可以起到一个门控的作用。Excitation的输出的激活值会乘以原始残差结构最后一个卷积层的输出结果，对特征图的数值大小进行控制。如果是重要的特征图，会保持比较大的数值；如果是不重要的特征图，特征图的数值就会变小。 SENet的论文《Squeeze-and-Excitation Networks》中也有一些图一并给大家看看好了，如图11.28所示。  图11.28 Squeeze-and-Excitation block[8] 各种符号什么意思我就不解释了，跟我前面介绍的内容差不多，大家随意看看就可以。图11.29和图11.30为SE-Inception模块和SE-ResNet模块。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 379}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 380 \\n 图11.29 SE-Inception模块[8] 图中的Global pooling表示全局池化；W表示图片宽度；H表示图片高度；C表示图片通道数；FC表示全连接层；r表示缩减率，意思是通道数在第一个全连接层缩减多少，总之就是一个超参数，不用细究，一般取值为16。 \\n 图11.30 SE-ResNet模块[8] 图中的Global pooling表示全局池化；W表示图片宽度；H表示图片高度；C表示图片通道数；FC表示全连接层；r表示缩减率，意思是通道数在第一个全连接层缩减多少，总之就是一个超参数，不用细究，一般取值为16。 ResNet-50，SE-ResNet-50，SE-ResNeXt-50(32×4d)模型结构如图11.31所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 380}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 381 \\n 图11.31 3种ResNet模型对比[8] 图中的Output size表示输出大小；conv表示卷积；max pool表示最大池化；stride表示步长；fc表示全连接层；global average pool表示全局平均池化；C表示分组数。 图中𝑓𝑐表示fully connected全连接层，𝑓𝑐后面的两个数字表示SE模块中两个全连接层的输出维度。  11.3.2 SENet结果分析 基础模型增加SE模块后会使得整体模型的参数增加10%左右，计算量增加不多，一般来说模型的效果也会有所提升。作者使用多个模型在ImageNet数据集上进行了测试，图11.32为多个模型在ImageNet验证集测试结果。 \\n 图11.32 多个模型测试结果[8] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 381}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 382 图中original表示模型原始论文中的结果；re-implementation表示SENet作者重新训练模型的结果；SENet表示给这些模型加上SE模块后的结果；top-1 err.表示top1错误率；top-5 err.表示top5错误率；GFLOPs表示计算量。 图中结果可以看出，图中测试的所有模型只要加上SE模块，错误率都能降低，并且模型浮点计算量没有太大变化。图11.33和图11.34也能看出加上SE模块后模型效果可以变得更好： \\n 图11.33 加上SE模块后的模型结果对比1[8] 图中的epochs表示周期；Top-1 error表示Top1错误率；train表示训练集；val表示验证集。 \\n 图11.34 加上SE模块后的模型结果对比2[8] 图中的epochs表示周期；Top-1 error表示Top1错误率；train表示训练集；val表示验证集。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 382}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 383 SENet论文的最后，作者还给了一组很有意思的图。作者用ImageNet数据集训练了一个SE-ResNet-50，然后选出4个种类(goldfish,pug,plane,cliff)的图片，统计这4个种类在SE-ResNet-50模型的每个SE模块的特征图的激活情况，如图11.35所示。 \\n 图11.35 不同SE模块的激活情况[8] 图中的all表示所有1000个种类的平均值；goldfish表示金鱼；pug表示哈巴狗；plane表示飞机；cliff表示悬崖；channel index表示通道；activation表示激活值。 作者观察实验结果得到3个结论： 第一，不同种类的物体在浅层激活分布情况是类似的，如图中的SE_2_3和SE_3_4。也就是不管是识别哪种物体，浅层的卷积层中，重要的特征图总是比较固定的那些。 第二，在更深层一些的位置，不同种类在不同的特征图激活分布不同，因为不同类别对特征有不同的偏好，如图中的SE_4_6和SE_5_1。低层特征通常更普遍，识别不同种类物体\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 383}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 384 可以使用类似的滤波器，而高层特征通常包含更多细节，识别不同种类物体需要使用不同的滤波器。 第三，在模型的最后阶段，SE_5_2呈现出饱和状态，其中大部分激活值都接近于1，也有一些接近于0。对于激活值为1的特征图，相当于SE模块不存在。在网络的最后一个SE模块SE_5_3，不同种类有着类似的分布，只是尺度不同。也就是说SE_5_2和SE_5_3相对来说没有前面的一些SE模块重要，作者通过实验发现删除最后一个阶段的SE模块，总体参数可以显著减少，性能只有一点损失(<0.1%的Top1错误率)。 下一章节我们将介绍经典图像识别模型的代码实现，以及如何使用这些模型进行图像识别。  11.4参考文献 [1] Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014. [2] C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna. Rethinking the inception architecture for computer vision. arXiv preprint arXiv:1512.00567, 2015.  [3] Szegedy C , Ioffe S , Vanhoucke V . Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning[J]. 2016. [4] Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. [5] Xie S , Girshick R , Dollár, Piotr, et al. Aggregated Residual Transformations for Deep Neural Networks[J]. 2016. ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 384}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 385 [6] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012. [7] Ioannou Y , Robertson D , Cipolla R , et al. Deep Roots: Improving CNN Efficiency with Hierarchical Filter Groups[J]. 2016. [8] Hu J , Shen L , Albanie S , et al. Squeeze-and-Excitation Networks[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.                 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 385}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 386 第12章-图像识别项目实战  本章节内容主要是针对第10，11章节经典图像识别模型的程序实现，理论部分就不再重复了，直接上代码。注意代码实现不一定跟原始中的描述完全一致，基本框架以及核心实现跟论文是一致的。我们将结合图像识别项目实战内容给大家讲解模型搭建，由于图像识别技术在各个行业的应用基本上差别不大，不管你是做医疗图像分类，农产品图像分类，工业部件图像分类，天气云图图像分类，生活用品图像分类等，只要是图像分类，所用到的技术和流程都是差不多的。所以为了方便，本章节我们主要使用一个数据集给大家讲解，如果大家有其他图像数据集或自己收集了一些图像数据集也可以用本章内容进行图像分类。  特别要说明一下，本章的重点在于Tensorflow中不同模型的搭建方法，以及图像识别模型的训练流程，因为数据量比较小，我也没有进行调参，所以最后模型的准确率不需要太在意。因为正常图像识别模型训练都不会从头训练（英文是train from scratch），一般我们都在预训练模型的基础上做进一步的训练。由于我们使用的数据集太小，并不是ImageNet级别的大数据集，所以从头训练（train from scratch）很难发挥模型的真正水平。本章12.11小节将会介绍使用预训练模型来进行迁移学习的方法。  12.1 图像数据准备 12.1.1 数据集介绍 在建模之前我们肯定需要先把数据给准备好，图像数据集有很多，大家可以自行收集，我们这里使用的数据集是来自Visual Geometry Group的17 Category Flower Dataset数', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 386}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 387 据集，也就是17种花的数据集。具体是哪17种这个我们可以不用管，反正就是17个类别。每个类别的花有80张图片，一共是1360张图片。单击网址http://www.robots.ox.ac.uk/~vgg/data/flowers/17/。出现如图12.1所示的界面。 \\n 图12.1 17 Category Flower Dataset 我们单击“1.Dataset images”就可以下载数据集了，下载后得到一个名为“17flowers.tgz”的压缩包，解压后得到一个名为“17flowers”的文件夹，打开文件夹里面是一个名为“jpg”的文件夹，再打开“jpg”文件夹，我们会看到1362个文件，其中有1360张图片。我们需要把不是图片的那两个文件给删除，只留下图片文件，如图12.2所示。 \\n 12.2 17种花的图片 观察图片名称我们可以发现是都是由编号构成，前1-80号为第一种花，81到160号为第二种花以此类推，1360张图片一共17种花。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 387}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 388 12.1.2 数据集准备 我们在做图像分类任务的时候，通常需要把数据先整理好，数据整理的格式通常都是每一个类别一个文件夹，文件夹的名称就是类别名称，如图12.3所示。  图12.3 数据集准备 如图我想做一个5分类的图像识别模型，这5个分类分别是”animal”,”flower”,”guitar”,”house”,”plane”,那么我需要在一个新的路径下新建5个文件夹，这5个文件夹的名称修改为”animal”,”flower”,”guitar”,”house”,”plane”。然后把对应类别的图片存放到对应的文件夹下面。如图12.4所示。  图12.4 存放数据 这是图像分类任务的基本操作，正常情况下大家都会这么整理数据。不过Visual Geometry Group的17 Category Flower Dataset数据集所有的图片都是在一个文件夹下面的，所以这里我们还需要写一个程序来帮助我们整理一下图片，我写的这个程序是放在与“17flowers”文件夹相同目录下运行的，如果在其他路径运行，要注意程序中路径的设置，如代码12-1所示。 代码12-1：17Flower数据整理 import os import shutil  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 388}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 389 # 新建文件夹用于存放整理后的图片 os.mkdir(\\'new_17_flowers\\') for i in range(17):     # 17个种类新建17个文件夹0-16     os.mkdir(\\'new_17_flowers\\'+\\'/\\'+str(i))      # 循环所有花的图片     for i,path in enumerate(os.listdir(\\'17flowers/jpg/\\')):     # 定义花的图片完整路径     image_path = \\'17flowers/jpg/\\' + path     # 复制到对应类别，每个类别80张图片     shutil.copyfile(image_path, \\'new_17_flowers\\'+\\'/\\'+str(i//80)+\\'/\\'+path) 运行完程序后就会产生一个新的文件夹“new_17_flowers”，这个文件夹里面有17个子文件夹，名字为flower0- flower16，表示17种花的编号。flower0- flower16文件夹里面都各自存放了80张图片。 12.1.3 切分数据集程序 数据集按照格式准备好以后，我们还需要切分训练集和测试集。因为我经常需要做数据切分的工作，所以就自己写了一个程序专门用于打乱数据并切分训练集和测试集。大家如果之后需要做类似的操作，可以参考或直接使用代码12-2。该程序是放在与“new_17_flowers”文件夹相同的路径下的，如果大家在其他路径运行，需要注意程序中路径的设置。 代码12-2：切分数据集 import os import random import shutil import numpy as np # 数据集路径 DATASET_DIR = \"new_17_flowers\" # 数据切分后存放路径 NEW_DIR = \"data\" # 测试集占比 num_test = 0.2 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 389}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 390  # 打乱所有种类数据，并分割训练集和测试集 def shuffle_all_files(dataset_dir, new_dir, num_test):     # 先删除已有new_dir文件夹     if not os.path.exists(new_dir):         pass     else:         # 递归删除文件夹         shutil.rmtree(new_dir)     # 重新创建new_dir文件夹     os.makedirs(new_dir)     # 在new_dir文件夹目录下创建train文件夹     train_dir = os.path.join(new_dir, 'train')     os.makedirs(train_dir)     # 在new_dir文件夹目录下创建test文件夹     test_dir = os.path.join(new_dir, 'test')     os.makedirs(test_dir)     # 原始数据类别列表     directories = []     # 新训练集类别列表     train_directories = []      # 新测试集类别列表     test_directories = []      # 类别名称列表     class_names = []     # 循环所有类别     for filename in os.listdir(dataset_dir):         # 原始数据类别路径         path = os.path.join(dataset_dir, filename)         # 新训练集类别路径         train_path = os.path.join(train_dir, filename)         # 新测试集类别路径         test_path = os.path.join(test_dir, filename)         # 判断该路径是否为文件夹         if os.path.isdir(path):             # 加入原始数据类别列表             directories.append(path)             # 加入新训练集类别列表             train_directories.append(train_path)             # 新建类别文件夹             os.makedirs(train_path)             # 加入新测试集类别列表             test_directories.append(test_path)             # 新建类别文件夹 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 390}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 391             os.makedirs(test_path)             # 加入类别名称列表             class_names.append(filename)     print('类别列表：',class_names)          # 循环每个分类的文件夹     for i in range(len(directories)):         # 保存原始图片路径         photo_filenames = []         # 保存新训练集图片路径         train_photo_filenames = []         # 保存新测试集图片路径         test_photo_filenames = []         # 得到所有图片的路径         for filename in os.listdir(directories[i]):             # 原始图片路径             path = os.path.join(directories[i], filename)             # 训练图片路径             train_path = os.path.join(train_directories[i], filename)             # 测试集图片路径             test_path = os.path.join(test_directories[i], filename)             # 保存图片路径             photo_filenames.append(path)             train_photo_filenames.append(train_path)             test_photo_filenames.append(test_path)         # list转array         photo_filenames = np.array(photo_filenames)         train_photo_filenames = np.array(train_photo_filenames)         test_photo_filenames = np.array(test_photo_filenames)         # 打乱索引         index = [i for i in range(len(photo_filenames))]          random.shuffle(index)         # 对3个list进行相同的打乱，保证在3个list中索引一致         photo_filenames = photo_filenames[index]         train_photo_filenames = train_photo_filenames[index]         test_photo_filenames = test_photo_filenames[index]         # 计算测试集数据个数         test_sample_index = int((1-num_test) * float(len(photo_filenames)))         # 复制测试集图片         for j in range(test_sample_index, len(photo_filenames)):             # 复制图片             shutil.copyfile(photo_filenames[j], test_photo_filenames[j])         # 复制训练集图片         for j in range(0, test_sample_index): \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 391}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 392             # 复制图片             shutil.copyfile(photo_filenames[j], train_photo_filenames[j])  # 打乱并切分数据集 shuffle_all_files(DATASET_DIR, NEW_DIR, num_test) 运行结果如下： 类别列表： ['flower0', 'flower1', 'flower10', 'flower11', 'flower12', 'flower13', 'flower14', 'flower15', 'flower16', 'flower2', 'flower3', 'flower4', 'flower5', 'flower6', 'flower7', 'flower8', 'flower9']  这个程序运行后会生成一个新的文件夹“data“，”data“文件夹中有两个子文件夹”train“和”test“。”train“表示训练集数据，占数据集的80%，”test“表示测试集数据，占数据集的20%。”train“和”test“文件夹下的子文件夹都是flower0- flower16，就是17种花的类别。“train”的子文件夹下，每个类别有64张图片，“test”的子文件夹下，每个类别有16张图片。  12.2 AlexNet图像识别  这一小节我们要学习如何搭建AlexNet模型并从头进行模型训练，如代码12-3所示。 代码12-3：AlexNet图像识别（片段1） import numpy as np from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt from tensorflow.keras.callbacks import LearningRateScheduler # 类别数 num_classes = 17 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 392}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 393 # 批次大小 batch_size = 32 # 周期数 epochs = 100 # 图片大小 image_size = 224  # 训练集数据进行数据增强 train_datagen = ImageDataGenerator(     rotation_range = 20,     # 随机旋转度数     width_shift_range = 0.1, # 随机水平平移     height_shift_range = 0.1,# 随机竖直平移     rescale = 1/255,         # 数据归一化     shear_range = 10,       # 随机错切变换     zoom_range = 0.1,        # 随机放大     horizontal_flip = True,  # 水平翻转     brightness_range=(0.7, 1.3), # 亮度变化     fill_mode = 'nearest',   # 填充方式 )  # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator(     rescale = 1/255,         # 数据归一化 )   # 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从'data/train'获得训练集数据 # 获得数据后会把图片resize为image_size×image_size的大小 # generator每次会产生batch_size个数据 train_generator = train_datagen.flow_from_directory(     'data/train',     target_size=(image_size,image_size),     batch_size=batch_size,     )  # 测试集数据生成器 test_generator = test_datagen.flow_from_directory(     'data/test',     target_size=(image_size,image_size),     batch_size=batch_size,     ) # 字典的键为17个文件夹的名字，值为对应的分类编号 print(train_generator.class_indices) 运行结果如下： {'flower0': 0, \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 393}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 394  'flower1': 1,  'flower10': 2,  'flower11': 3,  'flower12': 4,  'flower13': 5,  'flower14': 6,  'flower15': 7,  'flower16': 8,  'flower2': 9,  'flower3': 10,  'flower4': 11,  'flower5': 12,  'flower6': 13,  'flower7': 14,  'flower8': 15,  'flower9': 16} 代码12-3：AlexNet图像识别（片段2） # AlexNet model = Sequential() # 卷积层 model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding='valid',input_shape=(image_size,image_size,3),activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid')) model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3), strides=(2,2),padding='valid')) # 全连接层 model.add(Flatten()) model.add(Dense(4096, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(4096, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) # 模型概要 model.summary() \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 394}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 395 # 模型概要输出省略。。。  # 学习率调节函数，逐渐减小学习率 def adjust_learning_rate(epoch):     # 前30周期     if epoch<=30:         lr = 1e-4     # 前30到70周期     elif epoch>30 and epoch<=70:         lr = 1e-5     # 70到100周期     else:         lr = 1e-6     return lr  # 定义优化器 adam = Adam(lr=1e-4)  # 定义学习率衰减策略 callbacks = [] callbacks.append(LearningRateScheduler(adjust_learning_rate))  # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])  # Tensorflow2.1版本之前可以使用fit_generator训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epochs=epochs,validation_data=test_generator,validation_steps=len(test_generator))  # Tensorflow2.1版本(包括2.1)之后可以直接使用fit训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callbacks=callbacks) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 14s 418ms/step - loss: 2.7750 - accuracy: 0.0800 - val_loss: 2.4774 - val_accuracy: 0.1250 Epoch 2/100 34/34 [==============================] - 13s 395ms/step - loss: 2.4628 - accuracy: 0.1296 - val_loss: 2.2861 - val_accuracy: 0.1949 …… Epoch 99/100 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 395}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 396 34/34 [==============================] - 13s 390ms/step - loss: 0.0879 - accuracy: 0.9743 - val_loss: 0.7067 - val_accuracy: 0.8346 Epoch 100/100 34/34 [==============================] - 13s 390ms/step - loss: 0.1061 - accuracy: 0.9660 - val_loss: 0.7062 - val_accuracy: 0.8346 代码12-3：AlexNet图像识别（片段3） # 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 运行结果如下： \\n  12.3 VGGNet图像识别 这一小节我们要学习如何搭建VGGNet模型并从头进行模型训练，由于我们使用的都是同一个数据集案例，所以关于模块导入，参数设定，数据集预处理，模型训练，训练后画图\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 396}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 397 的程序基本都是一样的。主要就是模型搭建部分不同，所以为了节约用纸，我们仅在书中展示模型搭建部分的代码，完整的代码可见于本书相关代码。模型代码如代码12-4所示。 代码12-4：VGGNet图像识别 …… …… …… # VGG16 model = Sequential() # 卷积层 model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu',input_shape=(image_size,image_size,3))) model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 397}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 398 # 全连接层 model.add(Flatten()) model.add(Dense(4096,activation='relu')) model.add(Dropout(0.5)) model.add(Dense(4096,activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes,activation='softmax')) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 15s 447ms/step - loss: 2.8344 - accuracy: 0.0506 - val_loss: 2.8332 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 400ms/step - loss: 2.8252 - accuracy: 0.0542 - val_loss: 2.8332 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 14s 401ms/step - loss: 0.2013 - accuracy: 0.9311 - val_loss: 0.7145 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 14s 400ms/step - loss: 0.1859 - accuracy: 0.9338 - val_loss: 0.7183 - val_accuracy: 0.7868 \\n   观察AlexNet和VGG16模型的训练结果我们其实会发现AlexNet的结果反而比VGG16的结果要好一些。AlexNet测试集的准确率在83%左右，VGG16测试集的准确率在\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 398}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 399 78%左右。由于我们是从新训练模型，并且数据量比较少，VGG16模型比AlexNet结构更复杂，所以更难训练，那么结果差一些也是可以理解的。如果是大量数据的情况下，VGG16得到的结果应该会比AlexNet更好。  12.4 函数式（functional）模型 12.4.1 函数式（functional）模型介绍  在Tenorflow.keras种有两种模型搭建的方法，一种就是我们之前学习使用的Sequential顺序模型，模型就像汉堡一样，是一层一层叠加起来的。除此之外模型搭建还有另外一种方式称为函数式模型。 函数式模型的特点是需要定义模型的输入和输出，并且在模型搭建的过程中也更灵活。下面举个例子，比如我们在构建GoogleNet的Inception结构时，使用函数式模型的方式就会比较方便，下面程序我们将构建GoogleNet中第一个Inception的结构，如代码12-5所示。 代码12-5：函数式编程实现Inception结构 from tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model  # 定义模型输入 inputs = Input(shape=(28,28,192)) # 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D中计算 tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) # 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D中计算 tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 399}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 400 # 注意函数式模型的特点，Conv2D后面的(tower_2)表示把tower_2信号输入到Conv2D中计算 tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(tower_2) # 注意函数式模型的特点，Conv2D后面的(inputs)表示把inputs信号输入到Conv2D中计算 tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) # 注意函数式模型的特点，Conv2D后面的(tower_3)表示把tower_3信号输入到Conv2D中计算 tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu')(tower_3) # 注意函数式模型的特点，MaxPool2D后面的(inputs)表示把inputs信号输入到MaxPool2D中计算 pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs) # 注意函数式模型的特点，Conv2D后面的(pooling)表示把pooling信号输入到Conv2D中计算 pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(pooling) # concatenate合并4个信号，axis=3表示根据channel进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # 查看模型概要 model.summary() 运行结果如下： \\n  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 400}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 401 由于我们第一次讲解函数式编程，所以注释里我强调了很多次要注意函数式模型的特点，输入信号要放在函数的后面。 12.4.2 使用函数式模型进行MNIST图像识别  我们再来看一个函数式模型的完整例子，如代码12-6所示。 代码12-6：使用函数式模型进行MNIST图像识别 import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam from tensorflow.keras.models import Model  # 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在tensorflow中，在做卷积的时候需要把数据变成4维的格式 # 这4个维度是(数据数量，图片高度，图片宽度，图片通道数) # 所以这里把数据reshape变成4维数据，黑白图片的通道数是1，彩色图片通道数是3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 定义模型输入 inputs = Input(shape=(28,28,1)) x = Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu')(inputs) x = MaxPool2D(pool_size=2,strides=2,padding='same')(x) x = Conv2D(64,5,strides=1,padding='same',activation='relu')(x) x = MaxPool2D(pool_size=2,strides=2,padding='same')(x) x = Flatten()(x) x = Dense(1024,activation='relu')(x) x = Dropout(0.5)(x) x = Dense(10,activation='softmax')(x) # 定义模型 model = Model(inputs,x)  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 401}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 402 # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=2,validation_data=(x_test, y_test)) 运行结果如下： Train on 60000 samples, validate on 10000 samples Epoch 1/2 60000/60000 [==============================] - 83s 1ms/sample - loss: 0.3269 - accuracy: 0.9077 - val_loss: 0.0849 - val_accuracy: 0.9752 Epoch 2/2 60000/60000 [==============================] - 87s 1ms/sample - loss: 0.0893 - accuracy: 0.9730 - val_loss: 0.0528 - val_accuracy: 0.9825  12.5 模型可视化plot_model 12.5.1 使用plot_model进行模型可视化 Tensorflow里面有一个小工具可以方便的画出模型结构，很好用。就是tensorflow.keras.utils.plot_model。 使用plot_model前需要做一些准备工作，首先我们先要打开命令提示符安装3个python模块： pip install pydot pip install pydot_ng pip install graphviz 安装好3个python模型后，我们还需要安装一个软件，软件下载网址是：https://graphviz.gitlab.io/download/。 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 402}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 403 里面有Linux，Windows，Mac系统相对应的安装方法，因为每个系统安装方式不太一样，大家可以根据提示操作，搞不定的话可以网上搜索一下安装方法，我就不一一展开了。安装方式如图12.6所示。 \\n 图12.6 安装Graphviz软件 Windows用户应该比较多，我就以Windows为例简单说明一下，Windows版本有一个软件下载地址为：https://www2.graphviz.org/Packages/stable/windows/10/msbuild/Release/Win32/graphviz-2.38-win32.msi。下载完成后双击安装就可以，安装的路径我们要记住，默认路径一般是“C:\\\\Program Files(x86)\\\\Graphviz2.38”，可以使用默认路径或者修改为其他路径都可以。安装好之后，我们还需要把Graphviz软件主目录下bin文件的路径添加到环境变量中，如果是默认路径安装的话就是把“C:\\\\Program Files(x86)\\\\Graphviz2.38\\\\bin”添加到环境变量中。（可能有些同学还不知道怎么添加环境变量，这个内容太基础了，自行通过\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 403}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 404 搜索引擎解决吧）。安装配置好以后最好重启电脑，到此为止准备工作应该就做好了。如果运行时还出现有其他问题的话可以自行通过搜索引擎解决。 前面我们用函数式模型搭建了一个Inception结构，这个Inception结构如果我们看它的summary输出结果，大概可以看出来它的信号传递关系，但是看起来不太直观。summary比较适合用来看顺序模型的结构，看函数式模型就不太方便了。下面我们来学习plot_model的用法，它可以比较直观的绘制出模型的结构，实现代码如代码12-7所示。 代码12-7：画出模型结构plot_model from tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model from tensorflow.keras.utils import plot_model # 定义模型输入 inputs = Input(shape=(28,28,192)) tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(tower_2) tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(inputs) tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu')(tower_3) pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs) pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(pooling) # concatenate合并4个信号，axis=3表示根据channel进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # model表示要画图的模型 # 'model.png'表示图片存放路径 # show_shapes=True画出信号的shape # dpi设置分辨率，默认是96 plot_model(model=model, to_file='model.png', show_shapes=True, dpi=200) 运行结果如下： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 404}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 405 \\n  运行程序后，在程序所在目录下会产生一张名为'model.png'的图片，保存着模型的结构图。这个图我就不需要多解释了，可以清楚地看到信号的传递关系和信号的shape变化。  代码12-6中的模型使用plot_model画出来的结构如图12.7所示。 \\n 图12.7 plot_model绘制模型结构 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 405}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 406 plot_model画出来的图可以很清晰的看到网络各层结构，信号的流动关系，以及信号输入输出的shape。如果以后大家对模型的结构理解得不够好的话，可以用plot_model把模型结构画出来，看着模型结构图来理解模型的结构会容易一些。  12.5.2 plot_model升级版  上一小节我们学习了使用Tensorflow官方的plot_model来绘制网络结构，plot_model确实对我们理解模型结构有着很好的帮助。但是如果你仔细观察的话你会发现好像plot_model画出来的图好像少了些什么重要的内容。对了，这就卷积/池化窗口的大小，卷积/池化的步长，卷积/池化的padding方式，Dense层的激活函数，Dropout的系数等这些具体参数对于我们理解网络具体结构也是非常重要的，但是plot_model没有把这些信息标注出来。  为了可以画出更好的模型结构图，我在Tensorflow官方的plot_model基础上进行的优化，优化后的效果如图12.8和图12.9所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 406}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 407 图12.8 plot_model升级版1 \\n 图12.9 plot_model升级版2 我对原始plot_model的修改主要就是增加了更多的模型细节以及不同模块有不同颜色，简单的模型可能效果不够明显，如果大家在学习复杂模型的时候，显示更多的细节和颜色区分帮助还是很大的。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 407}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 408 我优化过的plot_model已经发布在PyPi：https://pypi.org/project/plot-model/。源代码在我的Github可以看到：https://github.com/Qinbf/plot_model。推荐安装方式是使用pip安装，打开命令提示符输入命令： pip install plot_model 安装好以后通过如下代码导入： from plot_model import plot_model plot_model的使用方式跟Tensorflow中的plot_model一样，不过增加了两个参数。一个是style，可以取值0和1，默认值为0。style=0表示使用新风格，style=1表示使用老风格，大家可以自行尝试。还有一个参数是color，取值为True或False，默认值是True。color=True表示画彩色结构图，color=False表示画黑白结构图。以后大家需要画模型结构图的时候，推荐大家使用我的plot_model。  12.6 GoogleNet图像识别  GoogleNet中包含了很多Inception模块，所以我们可以定义一个Inception函数专门用于实现Inception模块。在调用Inception函数时根据论文中GoogleNet网络结构描述传入不同的参数即可。我们将使用函数式模型来定义GoogleNet，同样我们只展示建模相关代码，如代码12-8所示。 代码12-8：GoogleNet图像识别 …… …… …… # 定义Inception结构 def Inception(x,filters): ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 408}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 409     tower_1 = Conv2D(filters=filters[0],kernel_size=1,strides=1,padding='same',activation='relu')(x)     tower_2 = Conv2D(filters=filters[1],kernel_size=1,strides=1,padding='same',activation='relu')(x)     tower_2 = Conv2D(filters=filters[2],kernel_size=3,strides=1,padding='same',activation='relu')(tower_2)     tower_3 = Conv2D(filters=filters[3],kernel_size=1,strides=1,padding='same',activation='relu')(x)     tower_3 = Conv2D(filters=filters[4],kernel_size=5,strides=1,padding='same',activation='relu')(tower_3)     pooling = MaxPool2D(pool_size=3,strides=1,padding='same')(x)     pooling = Conv2D(filters=filters[5],kernel_size=1,strides=1,padding='same',activation='relu')(pooling)     x = concatenate([tower_1,tower_2,tower_3,pooling],axis=3)     return x      # 定义GoogleNet模型 model_input = Input(shape=(image_size,image_size,3)) x = Conv2D(filters=64,kernel_size=7,strides=2,padding='same',activation='relu')(model_input) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Conv2D(filters=64,kernel_size=1,strides=1,padding='same',activation='relu')(x) x = Conv2D(filters=192,kernel_size=3,strides=1,padding='same',activation='relu')(x) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[64,96,128,16,32,32]) x = Inception(x,[128,128,192,32,96,64]) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[192,96,208,16,48,64]) x = Inception(x,[160,112,224,24,64,64]) x = Inception(x,[128,128,256,24,64,64]) x = Inception(x,[112,144,288,32,64,64]) x = Inception(x,[256,160,320,32,128,128]) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[256,160,320,32,128,128]) x = Inception(x,[384,192,384,48,128,128]) x = AvgPool2D(pool_size=7,strides=7,padding='same')(x) x = Flatten()(x) x = Dropout(0.4)(x) x = Dense(num_classes,activation='softmax')(x) model = Model(inputs=model_input,outputs=x) …… …… …… 运行结果如下： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 409}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 410 Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 16s 477ms/step - loss: 2.7764 - accuracy: 0.0699 - val_loss: 2.5863 - val_accuracy: 0.1140 Epoch 2/100 34/34 [==============================] - 13s 392ms/step - loss: 2.4651 - accuracy: 0.1360 - val_loss: 2.3358 - val_accuracy: 0.1471 …… Epoch 99/100 34/34 [==============================] - 13s 395ms/step - loss: 0.1723 - accuracy: 0.9366 - val_loss: 0.8696 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 13s 393ms/step - loss: 0.1641 - accuracy: 0.9430 - val_loss: 0.8596 - val_accuracy: 0.7904 \\n   GoogleNet的结构是一个个Inception结构叠加得到的，看程序就很容易理解，不过还是建议大家用plot_model()把模型结构图画出来，对照着模型结构图来看理解起来更容易，绝对能够让你清晰理解GoogleNet的具体结构（注意图片太大，dpi不要调太高）。由于plot_model()画出来的图太长我就不放到书里了，大家可以自行操作。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 410}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 411 12.7 Batch Normalization使用  BN我们在之前的内容中学习过，是一种很神奇的网络优化技巧，下面我们通过一个CIFAR10的图像分类来对比一下，使用BN和不使用BN的模型效果，如代码12-9所示。 代码12-9：BN-CIFAR10图像分类 import numpy as np from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Activation from tensorflow.keras.optimizers import Adam,RMSprop import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data() # 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 换one hot格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10)  # 定义卷积网络 model = Sequential() model.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.2))  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.3))  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 411}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 412 model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.4))  model.add(Flatten()) model.add(Dense(10,activation = 'softmax'))  # 定义使用了BN的卷积网络 # 两个模型结构完全一致，区别只在于是否使用BN model_bn = Sequential() model_bn.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.2))  model_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.3))  model_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.4))  model_bn.add(Flatten()) model_bn.add(Dense(10,activation = 'softmax')) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 412}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 413  # 定义优化器 adam = Adam(lr=1e-4)  # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 定义优化器，loss function，训练过程中计算准确率 model_bn.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 history = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuffle=True) history_bn = model_bn.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuffle=True)  plt.plot(np.arange(100),history.history['val_accuracy'],c='b',label='without_bn') # 画出使用BN的模型验证集准确率 plt.plot(np.arange(100),history_bn.history['val_accuracy'],c='y',label='bn') plt.legend() plt.xlabel('epochs') plt.ylabel('accuracy') plt.show() 运行结果如下： \\n  12.8 ResNet图像识别 同样这里我们只展示ResNet建模相关代码，如代码12-10所示。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 413}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 414 代码12-10：ResNet50图像识别 from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,GlobalAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D …… …… …… # 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True):      # projection shortcut     if conv_shortcut == True:         shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x)         # epsilon为BN公式中防止分母为零的值         shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)     else:         # identity_shortcut         shortcut = x     # 3个卷积层     x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Activation('relu')(x)       x = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Activation('relu')(x)       x = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)       x = Add()([x, shortcut])     x = Activation('relu')(x)     return x  # 堆叠残差单元 def stack(x, filters, blocks, strides):     x = block(x, filters, strides=strides)     for i in range(blocks-1):         x = block(x, filters, conv_shortcut=False)     return x      # 定义ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充3圈0，填充后图像从224×224变成230×230 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 414}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 415 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充1圈0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到2维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 19s 546ms/step - loss: 3.0563 - accuracy: 0.1195 - val_loss: 2.8569 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 399ms/step - loss: 2.4523 - accuracy: 0.2022 - val_loss: 2.9909 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 1.0080 - val_accuracy: 0.7794 Epoch 100/100 34/34 [==============================] - 14s 404ms/step - loss: 0.0229 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 415}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 416 \\n   这里我使用了一种比较简洁的方式来搭建ResNet模型，程序比较简洁，不过理解起来可能需要多花点时间，建议一行一行代码仔细理解。同时可以借助plot_model()来帮助模型结构的理解。由于plot_model()画出来的图太长我就不放到书里了，我截取两个局部给大家看看好了，图12.10为identity shortcut残差单元（左）和projection shortcut残差单元（右）。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 416}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 417 \\n 图12.10 identity（左），projection（右） \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 417}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 418  12.9 ResNeXt图像识别 同样这里我们只展示ResNeXt建模相关代码，如代码12-11所示。 代码12-11：ResNeXt50(32×4d)图像识别 from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,GlobalAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D,Lambda …… …… …… # 定义分组卷积 # g_channels 每组的通道数 # groups 多少组 def grouped_convolution_block(init_x, strides, groups, g_channels):     group_list = []     # 分组进行卷积     for c in range(groups):         # 分组取出数据         x = Lambda(lambda x: x[:, :, :, c*g_channels:(c+1)*g_channels])(init_x)         # 分组进行卷积         x = Conv2D(filters=g_channels,kernel_size=3,strides=strides,padding='same',use_bias=False)(x)         # 存入list         group_list.append(x)     # 合并list中的数据     group_merge = concatenate(group_list, axis=3)     x = BatchNormalization(epsilon=1.001e-5)(group_merge)     x = Activation('relu')(x)     return x  # 定义残差单元 def block(x, filters, strides=1, groups=32, conv_shortcut=True):      # projection shortcut     if conv_shortcut == True:         shortcut = Conv2D(filters*2,kernel_size=1,strides=strides,padding='same')(x)         # epsilon为BN公式中防止分母为零的值         shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 418}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 419     else:         # identity_shortcut         shortcut = x     # 3个卷积层     x = Conv2D(filters=filters,kernel_size=1,strides=1,padding='same')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Activation('relu')(x)     # 计算每组的通道数     g_channels = int(filters / groups)      # 进行分组卷积     x = grouped_convolution_block(x, strides, groups, g_channels)       x = Conv2D(filters=filters*2,kernel_size=1,strides=1,padding='same')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Add()([x, shortcut])     x = Activation('relu')(x)     return x  # 堆叠残差单元 def stack(x, filters, blocks, strides, groups=32):     x = block(x, filters, strides=strides, groups=groups)     for i in range(blocks):         x = block(x, filters, groups=groups, conv_shortcut=False)     return x      # 定义ResNeXt50 inputs = Input(shape=(image_size,image_size,3)) # 填充3圈0，填充后图像从224×224变成230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充1圈0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks表示堆叠数量 x = stack(x, filters=128, blocks=2, strides=1) x = stack(x, filters=256, blocks=3, strides=2) x = stack(x, filters=512, blocks=5, strides=2) x = stack(x, filters=1024, blocks=2, strides=2) # 根据特征图大小进行平均池化，池化后得到2维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 419}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 420 # 定义模型 model = Model(inputs=inputs,outputs=x)  # 电脑配置不好的话不要运行summary或者plot_model # model.summary() …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 37s 1s/step - loss: 2.8832 - accuracy: 0.0901 - val_loss: 2.9076 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 17s 490ms/step - loss: 2.4876 - accuracy: 0.1838 - val_loss: 3.1728 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 17s 495ms/step - loss: 0.0328 - accuracy: 0.9982 - val_loss: 0.9105 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 17s 495ms/step - loss: 0.0248 - accuracy: 0.9991 - val_loss: 0.9058 - val_accuracy: 0.8088 \\n ResNeXt50的模型程序跟ResNet50差不多，使用一个函数grouped_convolution_block完成分组卷积的操作。建议大家使用plot_model看一下模型结构（建议dpi使用96或更低的值），groups=32画出来的图太大了，下面给大家看一下groups=4画出来的图的残差结构，如图12.11所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 420}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 421 \\n 图12.11 groups=4的ResNeXt残差单元  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 421}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 422 12.10 SENet图像识别 同样这里我们只展示SE-ResNet50建模相关代码，如代码12-12所示。 代码12-12：SE-ResNet50图像识别 from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,GlobalAvgPool2D,BatchNormalization,Activation,Add,ZeroPadding2D,Multiply …… …… …… # SE模块 def ChannelSE(input_tensor, reduction=16):     # 获得信号通道数     channels = input_tensor.shape[-1]     # SE模块     x = GlobalAvgPool2D()(input_tensor)     # 把2维数据再变成4维(?,1,1,?)     x = x[:, None, None, :]     # 卷积替代全连接层     x = Conv2D(filters=channels//reduction,kernel_size=1,strides=1)(x)     x = Activation('relu')(x)     x = Conv2D(filters=channels,kernel_size=1,strides=1)(x)     x = Activation('sigmoid')(x)     x = Multiply()([input_tensor, x])     return x  # 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True, reduction=16):      # projection shortcut     if conv_shortcut == True:         shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x)         # epsilon为BN公式中防止分母为零的值         shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)     else:         # identity_shortcut         shortcut = x     # 3个卷积层     x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Activation('relu')(x) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 422}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 423       x = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)     x = Activation('relu')(x)       x = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x)     x = BatchNormalization(epsilon=1.001e-5)(x)          # SE模块     x = ChannelSE(x, reduction=reduction)       x = Add()([x, shortcut])     x = Activation('relu')(x)     return x  # 堆叠残差单元 def stack(x, filters, blocks, strides):     x = block(x, filters, strides=strides)     for i in range(blocks-1):         x = block(x, filters, conv_shortcut=False)     return x      # 定义SE-ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充3圈0，填充后图像从224×224变成230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充1圈0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到2维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) …… \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 423}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 424 …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 27s 786ms/step - loss: 2.4803 - accuracy: 0.2114 - val_loss: 2.8556 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 401ms/step - loss: 1.8287 - accuracy: 0.4017 - val_loss: 2.9926 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 14s 407ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.8088 \\n  SE-ResNet50用plot_model画出来的图会很大，大家可以自己运行，下面我就给大家看一下SE-ResNet50其中一个残差单元的图，如图12.12所示。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 424}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 425 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 425}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 426 图12.12 SE-ResNet50残差单元 12.11 使用预训练模型进行迁移学习 12.11.1 使用训练好的模型进行图像识别 本章前面的内容中，我们主要是学习了模型搭建方法，这一小节我们将学习使用迁移学习的方式来训练图像识别模型。图像识别的迁移学习简单的来说就是使用一个已经经过预训练的模型，在这个预训练的模型基础上稍作修改，然后训练自己的数据集，也称为微调（Finetune）。这里的预训练模型通常都是使用ImageNet比赛数据集训练出来的模型。Tensorflow中有很多官方提供的使用ImageNet数据集训练好的预训练模型，我们可以直接下载使用，如图12.13所示。 \\n 图12.13 可用预训练模型 下面我们先看一下如何使用预训练模型来进行图像识别，第一次载入模型需要从网上下载模型，下载的模型会存放在你的用户目录下.keras隐藏文件夹下的models文件夹中（比如C:\\\\User\\\\qin\\\\.keras\\\\models）。我自己准备了一些图片存放在“test”文件夹中用于测试，如代码12-13所示。 代码12-13：使用训练好的ResNet50进行图像识别 from tensorflow.keras.applications.resnet50 import ResNet50 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 426}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 427 # imagenet数据处理工具 from tensorflow.keras.applications.imagenet_utils import decode_predictions,preprocess_input from tensorflow.keras.preprocessing.image import img_to_array,load_img import matplotlib.pyplot as plt import os import numpy as np # 图片大小 image_size = 224 # 存放测试图片的文件夹 image_dir = 'test' # 载入使用imagenet训练好的预训练模型 # include_top=True表示模型包含全连接层 # include_top=False表示模型不包含全连接层 # 下载的程序会存放在你的用户目录下.keras隐藏文件夹下的models文件夹中 resnet50 = ResNet50(weights='imagenet',include_top=True, input_shape=(image_size,image_size,3))  # 循环目录下的图片并进行显示预测 for file in os.listdir(image_dir):     # 测试图片完整路径     file_dir = os.path.join(image_dir,file)     # 读入图片，并resize为224*224大小     img = load_img(file_dir, target_size=(224, 224))     # 显示图片     plt.imshow(img)     plt.axis('off')     plt.show()     # 将图片转化为array     x = img_to_array(img)     # 增加1个维度变成4维数据     # (224, 224, 3)->(1, 224, 224, 3)     x = np.expand_dims(x, axis=0)     # 把像素数值归一化为(-1,1)之间，并让RGB通道减去对应均值     x = preprocess_input(x)      # preds.shap->(1, 1000),1000个概率值     preds = resnet50.predict(x)     # decode_predictions用于预测结果解码     # 将测试结果解码为如下形式：     # [(编码1, 英文名称1, 概率1),(编码2, 英文名称2, 概率2)...]     # top=1表示概率最大的1个结果，top=3表示概率最大的3个结果     predicted_classes = decode_predictions(preds, top=1)     imagenet_id, name, confidence = predicted_classes[0][0] \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 427}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 428     # 打印结果     print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100)) 运行结果如下： \\n This is a sandbar with 44.15% confidence! \\n This is a soup_bowl with 61.99% confidence!  This is a tabby named chouchou with 90.97% confidence! 12.11.2 使用训练好的模型进行迁移学习 现在我们要使用预训练的模型来训练自己的数据集了，为了方便，我还是使用17flowers的数据集，如果大家有其他数据集的话也可以使用。使用VGG16完成迁移学习的代码如代码12-14所示。 代码12-14：使用VGG16完成迁移学习 from tensorflow.keras.applications.vgg16 import VGG16 from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dropout,Flatten,Dense \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 428}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 429 from tensorflow.keras.optimizers import SGD from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img import json import matplotlib.pyplot as plt import numpy as np # 类别数 num_classes = 17 # 批次大小 batch_size = 32 # 周期数 epochs = 40 # 图片大小 image_size = 224 # 训练集数据进行数据增强 train_datagen = ImageDataGenerator(     rotation_range = 20,     # 随机旋转度数     width_shift_range = 0.1, # 随机水平平移     height_shift_range = 0.1,# 随机竖直平移     rescale = 1/255,         # 数据归一化     shear_range = 10,       # 随机错切变换     zoom_range = 0.1,        # 随机放大     horizontal_flip = True,  # 水平翻转     brightness_range=(0.7, 1.3), # 亮度变化     fill_mode = 'nearest',   # 填充方式 )  # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator(     rescale = 1/255,         # 数据归一化 )  # 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从'data/train'获得训练集数据 # 获得数据后会把图片resize为image_size×image_size的大小 # generator每次会产生batch_size个数据 train_generator = train_datagen.flow_from_directory(     'data/train',     target_size=(image_size,image_size),     batch_size=batch_size,     )  # 测试集数据生成器 test_generator = test_datagen.flow_from_directory(     'data/test',     target_size=(image_size,image_size), \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 429}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 430     batch_size=batch_size, )  # 字典的键为17个文件夹的名字，值为对应的分类编号 label = train_generator.class_indices # 把字典的键值对反过来 # 分类编号为键，分类名称为值 label = dict(zip(label.values(),label.keys())) # 保存到json文件中 file = open('label_flower.json','w',encoding='utf-8') json.dump(label, file) # 载入使用imagenet训练好的预训练模型 # include_top=True表示模型包含全连接层 # include_top=False表示模型不包含全连接层 vgg16 = VGG16(weights='imagenet',include_top=False, input_shape=(image_size,image_size,3))  # 搭建全连接层，连接在VGG16模型后面 # 我们主要是利用VGG16卷积网络已经训练好的特征提取能力来提取特征 # 然后搭建新的全连接层来进行新图片类型的分类 top_model = Sequential() top_model.add(Flatten(input_shape=vgg16.output_shape[1:])) top_model.add(Dense(256,activation='relu')) top_model.add(Dropout(0.5)) top_model.add(Dense(num_classes,activation='softmax'))  model = Sequential() model.add(vgg16) model.add(top_model)  # 定义优化器，代价函数，训练过程中计算准确率，设置一个较小的学习率 model.compile(optimizer=SGD(lr=1e-3,momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])  # Tensorflow2.1版本之前可以使用fit_generator训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epochs=epochs,validation_data=test_generator,validation_steps=len(test_generator))  # Tensorflow2.1版本(包括2.1)之后可以直接使用fit训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/40 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 430}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 431 34/34 [==============================] - 15s 440ms/step - loss: 2.8396 - accuracy: 0.1131 - val_loss: 2.2644 - val_accuracy: 0.2904 Epoch 2/40 34/34 [==============================] - 14s 406ms/step - loss: 1.9765 - accuracy: 0.3713 - val_loss: 1.3263 - val_accuracy: 0.6029 …… Epoch 39/40 34/34 [==============================] - 14s 402ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1977 - val_accuracy: 0.9632 Epoch 40/40 34/34 [==============================] - 14s 399ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.1575 - val_accuracy: 0.9706 # 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy') # 图例 plt.legend() # x坐标描述 plt.xlabel('epochs') # y坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() # 模型保存 model.save('vgg16.h5') 运行结果如下： \\n  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 431}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 432 从结果我们可以看到是用了预训练的VGG16模型来训练17flowers数据集，模型的收敛速度非常快，只训练几个周期就得到了很好的结果。并且训练40个周期以后，模型的验证集达到了97%非常高的准确率。 12.11.3 载入训练好的模型进行预测 上一小节我们训练好了一个97%准确率的17种花的识别模型并保存为“vgg16.h5“模型文件，这个小节我们要重新载入这个训练好的模型，使用它对其他图片进行预测。模型分类编号跟分类名称的对应关系在上小节的程序里面也已经保存在“label_flower.json”文件中，可以直接载入。我准备了几张测试图片存放在“flowers_test”文件夹中，测试图片的文件名就是该图片的分类名称，如代码12-15所示。 代码12-15：载入训练好的模型进行预测（片段1） from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.image import img_to_array,load_img import json import os import matplotlib.pyplot as plt import numpy as np # 测试图片存放位置 image_dir = 'flowers_test' # 载入标签json文件 file = open('label_flower.json','r',encoding='utf-8') label = json.load(file) # 键为分类编号，值为分类名称 print(label) 运行结果如下： {'0': 'flower0', '1': 'flower1', '2': 'flower10', '3': 'flower11', '4': 'flower12', '5': 'flower13', '6': 'flower14', '7': 'flower15', '8': 'flower16', '9': 'flower2', '10': 'flower3', '11': 'flower4', '12': 'flower5', '13': 'flower6', '14': 'flower7', '15': 'flower8', '16': 'flower9'} 代码12-15：载入训练好的模型进行预测（片段2） # 载入训练好的模型 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 432}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 433 model = load_model('VGG16.h5')  # 预测函数 def model_predict(file_dir):     # 读入图片，并resize为224*224大小     img = load_img(file_dir, target_size=(224, 224))     # 显示图片     plt.imshow(img)     plt.axis('off')     plt.show()     # 将图片转化为array     x = img_to_array(img)     # 增加1个维度变成4维数据     # (224, 224, 3)->(1, 224, 224, 3)     x = np.expand_dims(x, axis=0)      # 模型预测结果     # predict_classes直接返回预测分类结果，比如:[2]     preds = model.predict_classes(x)     # label字典中的键为字符串，所以这里需要把preds[0]转为str     # 根据分类编号查询label中对应的分类名称     preds = label[str(preds[0])]     return preds  # 循环测试文件夹 for file in os.listdir(image_dir):     # 测试图片完整路径     file_dir = os.path.join(image_dir,file)     # 打印文件路径     print(file_dir)     # 传入文件路径进行预测     preds = model_predict(file_dir)     print('predict:',preds)     print('-'*20) 运行结果如下： flowers_test\\\\flower0.jpg \\n predict: flower0 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 433}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 434 -------------------- flowers_test\\\\flower10.jpg \\n predict: flower10 -------------------- flowers_test\\\\flower5.jpg \\n predict: flower5 --------------------           \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 434}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 435 第13章-验证码识别项目实战 本章属于内外兼修的章节，既有多任务学习和CTC算法介绍，又有大量Tensorflow应用技巧，如tf.data的使用，如何自定义数据生成器，如何自定义Callbacks，多种Callbacks用法，多任务模型的定义和训练。 本章模型训练所需时间较长，如果情况允许的情况下，建议大家使用GPU来训练模型，提高效率。如果使用CPU训练本章模型，每个模型大约需要2天时间。  13.1 多任务学习介绍  多任务学习（Multi-task Learning）是深度学习中很常用的一种模型训练策略，意思其实也很简单，就是同时训练多个任务，给大家举两个例子大家就明白了。比如目标检测项目中，我们既要知道目标所在的位置（也就是预测框坐标值），也要知道预测框内是什么物体。预测框的坐标值是连续型数据，所以是一个回归任务；预测框的物体是一个具体的类别，所以是一个分类任务。如图13.1所示。 \\n 图13.1 目标检测任务  图中的task1和task2可以共享卷积层。task1就是目标检测的回归任务，用来预测目标框的位置，我们只要知道目标框左上角的(x1,y1)坐标和右下角的(x2,y2)坐标就可以把目标框\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 435}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 436 给画出来，所以task1中需要4个神经元来预测4个回归值。task2的作用是判断目标框内是什么物体，假设我们这个目标检测任务一共有5个分类，那么就需要5个神经元来预测5个分类结果。  再给大家举一个例子，比如我们在做人脸识别的时候，我们不仅可以识别人脸所在的位置，还可以识别人的年龄，表情，性别等特征。使用多任务学习的方式，我们可以让模型同时训练多个任务，模型训练好以后，输入一张图片，模型就可以输出人脸的位置，以及人的年龄，表情，性别，如图13.2所示。 \\n 图13.2 人脸识别任务  如图所示，task1任务是识别人脸所在位置，属于回归任务；task2任务是识别人的年龄，也是回归任务；task3任务是识别人的表情，人的表情可以人为的标注几个类别，属于分类任务；task4任务是识别人的性别，当然也是分类任务。所以我们可以看到使用多任务学习模型可以同时训练多个任务，在模型预测阶段也可以同时对多个任务进行预测。 我前面提到的多任务人脸识别的例子中，不同的任务其实也可以共享卷积层。因为卷积层的作用主要是特征提取，先提取图像的特征，然后再使用这些特征来预测人的年龄，表情，性别。用于特征提取的卷积层可以共享，不过不同的任务还需要有自己的task layer，专门用于训练特定任务。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 436}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 437 13.2 验证码数据集生成  验证码想必大家都很熟悉了，下面我们就来介绍一下我们本章要使用的验证码数据集。有一个python模块是专门用来生成验证码图片的，打开命令提示符输入命令：  pip install captcha  验证码图片生成的代码如代码13-1所示。 代码13-1：验证码生成 # 安装验证码生成库:pip install captcha from captcha.image import ImageCaptcha   import random import string  # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits+string.ascii_letters  # 随机产生验证码，长度为4 def random_captcha_text(char_set=characters, captcha_size=4):     # 验证码列表     captcha_text = []     for i in range(captcha_size):         # 随机选择         c = random.choice(char_set)         # 加入验证码列表         captcha_text.append(c)     return captcha_text   # 生成字符对应的验证码 def gen_captcha_text_and_image():     # 验证码图片宽高可以设置，默认width=160, height=60     image = ImageCaptcha(width=160, height=60)     # 获得随机生成的验证码     captcha_text = random_captcha_text()     # 把验证码列表转为字符串     captcha_text = ''.join(captcha_text)     # 保存验证码图片     image.write(captcha_text, 'captcha/' + captcha_text + '.jpg') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 437}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 438  # 产生1000次随机验证码 # 真正的数量可能会少于1000 # 因为重名的图片会被覆盖掉 num = 1000 for i in range(num):     gen_captcha_text_and_image()  print(\"生成完毕\") 程序运行后会在‘captcha’文件夹下产生差不多1000张验证码的图片，虽然生成验证码的程序运行了1000次，不过有可能会产生两张重名的图片，第二张图片会把第一张图片给覆盖掉，所以实际图片可能不到1000张。运行程序后得到的验证码图片如图13.3所示。 \\n 图13.3 验证码图片  13.3 tf.data介绍  tf.data是一个很好用的数据读取管道搭建的API，具有高性能并且简洁易用的特点。我们可以使用tf.data来定义数据从哪里获取，获取以后如何对数据进行处理，处理以后还可以打乱数据，给数据进行分批次等，总而言之tf.data的作用就是用来获取并处理数据的。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 438}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 439  tf.data最常用的用法就是使用tf.data.Dataset.from_tensor_slices来获取数据，例如： dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))  (x_train, y_train)是训练集数据和对应标签。  tf.data.Dataset支持一类特殊的操作：Transformation。一个Dataset通过Transformation可以变成一个新的Dataset。通常我们就是使用Transformation来对数据进行处理的。例如：  1.使用shuffle来打乱数据： dataset_train = dataset_train.shuffle(buffer_size=1000) 2.使用map进行数据处理。map可以接收一个自定义数据处理函数，Dataset中的数据会传入map中的函数进行处理，并返回处理后的数据作为新的Dataset： dataset_train = dataset_train.map(image_function)  3.使用repeat来重复数据。repeat可以将数据序列重复n次，其实也就是重复n个周期epoch。一般我认为就只重复1个周期比较好，因为模型训练的时候(model.fit)还会再设置模型训练周期： dataset_train = dataset_train.repeat(1)  4.使用batch来设置数据产生的批次大小： dataset_train = dataset_train.batch(batch_size) 这几个Transformation是用得比较多的，还有其他的一些Transformation这里我们就不一一列出了。 定义好Dataset以后我们可以使用： x,y = next(iter(dataset_test)) 来获得一个批次的数据和标签，查看数据的情况。 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次数据： for x,y in dataset_test:     pass 模型训练阶段可以把Dataset传入model.fit中进行训练： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 439}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 440 model.fit(x=dataset_train) 除非是在本书相关的实际应用中用到，否则我就不展开介绍Tensorflow的一些细节上的使用了，如果不结合实际应用很多内容感觉说不明白。更多tf.data的使用方法可以参考Tensorflow官方指南（https://tensorflow.google.cn/guide/data）。  13.4 使用tf.data完成多任务学习-验证码识别 13.4.1 使用tf.data完成多任务学习模型训练  本小节我们将介绍使用多任务学习的方法来进行验证码识别，比如我们要识别的验证码有4个字符，我们可以给模型定义4个任务，每个任务负责识别1个字符。第一个任务识别第一个字符，第二个任务识别第二个字符，第三个任务识别第三个字符，第四个任务识别第四个字符。模型框架如图13.4所示。 \\n 13.4 验证码识别模型框架 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 440}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 441 图中的4个输出表示4个任务，每个输出都是62分类是由于我们使用的验证码的字符是数字加上大小写英文字母所以一共62种字符。 代码13-2：tf.data-多任务学习-验证码识别（片段1） import tensorflow as tf  from tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input from tensorflow.keras.optimizers import SGD from tensorflow.keras.models import Model from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau import string import numpy as np import os from plot_model import plot_model  # 字符包含所有数字和所有小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数62 num_classes = len(characters) # 批次大小 batch_size = 64 # 周期数 epochs=100 # 训练集数据，大约50000张图片 # 事先用captcha模块生成，长度都是4 train_dir = \"./captcha/train/\" # 测试集数据，大约10000张图片 # 事先用captcha模块生成，长度都是4 test_dir = \"./captcha/test/\" # 图片宽度 width=160 # 图片高度 height=60  # 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir):     # 存放图片路径     photo_filenames = [] ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 441}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 442     # 存放图片标签     y = []     for filename in os.listdir(dataset_dir):         # 获取文件完整路径         path = os.path.join(dataset_dir, filename)         # 保存图片路径         photo_filenames.append(path)         # 取文件名前4位，也就是验证码的标签         captcha_text = filename[0:4]         # 定义一个空label         label = np.zeros((4, num_classes), dtype=np.uint8)         # 标签转独热编码         for i, ch in enumerate(captcha_text):             # 设置标签，独热编码one-hot格式             # characters.find(ch)得到ch在characters中的位置，可以理解为ch的编号             label[i, characters.find(ch)] = 1         # 保存独热编码的标签         y.append(label)     # 返回图片路径和标签 return np.array(photo_filenames),np.array(y)  # 获取训练集图片路径和标签 x_train,y_train = get_filenames_and_classes(train_dir)  # 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)  # 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label):     # 根据图片路径读取图片内容     image = tf.io.read_file(filenames)     # 将图像解码为jpeg格式的3维数据     image = tf.image.decode_jpeg(image, channels=3)        # 归一化     image = tf.cast(image, tf.float32) / 255.0     # 返回图片数据和标签     return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label):     # transpose改变数据的维度，比如原来的数据shape是(64,4,62)     # 这里的64是批次大小，验证码长度为4有4个标签，62是62个不同的字符 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 442}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 443     # tf.transpose(label,[1,0,2])计算后得到的shape为(4,64,62)     # 原来的第1个维度变成了第0维度，原来的第0维度变成了1维度，第2维不变     # (64,4,62)->(4,64,62)     label = tf.transpose(label,[1,0,2])     # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义4个任务，所以这里返回4个标签     # 每个标签的shape为(64,62)，64是批次大小，62是独热编码格式的标签     return image, (label[0],label[1],label[2],label[3])  # 创建dataset对象，传入训练集图片路径和标签 dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 打乱数据，buffer_size定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_train = dataset_train.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_train = dataset_train.map(image_function) # 数据重复生成1个周期 dataset_train = dataset_train.repeat(1) # 定义批次大小 dataset_train = dataset_train.batch(batch_size) # 注意这个map和前面的map有所不同，第一个map在batch之前，所以是处理每一条数据 # 这个map在batch之后，所以是处理每一个batch的数据 dataset_train = dataset_train.map(label_function)  # 创建dataset对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成1个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个map和前面的map有所不同，第一个map在batch之前，所以是处理每一条数据 # 这个map在batch之后，所以是处理每一个batch的数据 dataset_test = dataset_test.map(label_function)  # 生成一个批次的数据和标签 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 443}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 444 # 可以用于查看数据和标签的情况 x,y = next(iter(dataset_test)) print(x.shape) print(np.array(y).shape) 结果输出为： (64, 60, 160, 3) (4, 64, 62)  代码13-2：tf.data-多任务学习-验证码识别（片段2） # 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次 # for x,y in dataset_test: #     pass # 载入预训练的resnet50模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)) # 设置输入 inputs = Input((height,width,3)) # 使用resnet50进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的4个字符看成是4个不同的任务 # 每个任务负责识别1个字符 # 任务1识别第1个字符，任务2识别第2个字符，任务3识别第3个字符，任务4识别第4个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)  # 4个任务我们可以定义4个loss # loss_weights可以用来设置不同任务的权重，验证码识别的4个任务权重都一样 model.compile(loss={'out0':'categorical_crossentropy',                     'out1':'categorical_crossentropy',                     'out2':'categorical_crossentropy',                     'out3':'categorical_crossentropy'},               loss_weights={'out0':1, \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 444}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 445                             'out1':1,                             'out2':1,                             'out3':1},               optimizer=SGD(lr=1e-2,momentum=0.9),               metrics=['acc'])  # 监控指标统一使用val_loss # 可以使用EarlyStopping来让模型停止，连续6个周期val_loss没有下降就结束训练 # CSVLogger保存训练数据 # ModelCheckpoint保存所有训练周期中val_loss最低的模型 # ReduceLROnPlateau学习率调整策略，连续3个周期val_loss没有下降当前学习率乘以0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),              CSVLogger('Captcha_tfdata.csv'),               ModelCheckpoint('Best_Captcha_tfdata.h5', monitor='val_loss', save_best_only=True),              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]  # 训练模型 # 把之前定义的dataset_train和dataset_test传入进行训练 model.fit(x=dataset_train,           epochs=epochs,           validation_data=dataset_test,           callbacks=callbacks) 结果输出为： Train for 781 steps, validate for 156 steps Epoch 1/100 781/781 [==============================] - 96s 123ms/step - loss: 7.1427 - out0_loss: 1.3058 - out1_loss: 2.1121 - out2_loss: 2.0675 - out3_loss: 1.6573 - out0_acc: 0.6824 - out1_acc: 0.4488 - out2_acc: 0.4548 - out3_acc: 0.5494 - val_loss: 16.5515 - val_out0_loss: 9.0025 - val_out1_loss: 3.4140 - val_out2_loss: 2.1353 - val_out3_loss: 1.9997 - val_out0_acc: 0.0323 - val_out1_acc: 0.2611 - val_out2_acc: 0.4728 - val_out3_acc: 0.4884 …… Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06. 781/781 [==============================] - 88s 113ms/step - loss: 0.0088 - out0_loss: 0.0028 - out1_loss: 0.0020 - out2_loss: 0.0018 - out3_loss: 0.0021 - out0_acc: 1.0000 - out1_acc: 0.9999 - out2_acc: 1.0000 - out3_acc: 1.0000 - val_loss: 0.6167 - val_out0_loss: 0.2020 - val_out1_loss: 0.1470 - val_out2_loss: 0.1508 - val_out3_loss: 0.1168\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 445}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 446  - val_out0_acc: 0.9550 - val_out1_acc: 0.9644 - val_out2_acc: 0.9647 - val_out3_acc: 0.9708 Epoch 00023: early stopping  模型的初始学习率为0.01，随着模型训练学习率会逐渐降低，最后模型训练了23周期就提前停止了。我们可以看到训练集的4个任务准确率基本上都已经是1了，测试集的4个任务准确率大约为0.96左右，有一定的过拟合现象也是正常的。 别看0.96的准确率好像挺高的，验证码识别可是要4个验证码都识别正确，最后的结果才算正确。所以真正的识别正确率大约是4个任务的正确率相乘约等于0.86，结果也还可以，不过这么看好像就不算非常高了。  13.4.2 使用tf.data完成多任务学习模型预测 下面我们再来看一下载入训练好的模型进行准确率计算和验证码结果预测的程序，如代码13-3所示。。 代码13-3：tf.data-多任务学习-验证码识别-模型预测（片段1） import tensorflow as tf  from tensorflow.keras.models import load_model import matplotlib.pyplot as plt import os import numpy as np import string  # 载入之前训练好的模型 model = load_model('Best_Captcha_tfdata.h5')  # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 446}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 447 # 测试集数据，大约10000张图片 # 事先用captcha模块生成，长度都是4 test_dir = \"./captcha/test/\"  # 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir):     # 存放图片路径     photo_filenames = []     # 存放图片标签     y = []     for filename in os.listdir(dataset_dir):         # 获取文件完整路径         path = os.path.join(dataset_dir, filename)         # 保存图片路径         photo_filenames.append(path)         # 取文件名前4位，也就是验证码的标签         captcha_text = filename[0:4]         # 定义一个空label         label = np.zeros((4, num_classes), dtype=np.uint8)         # 标签转独热编码         for i, ch in enumerate(captcha_text):             # 设置标签，独热编码one-hot格式             # characters.find(ch)得到ch在characters中的位置，可以理解为ch的编号             label[i, characters.find(ch)] = 1         # 保存独热编码的标签         y.append(label)     # 返回图片路径和标签     return np.array(photo_filenames),np.array(y)  # 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)  # 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label):     # 根据图片路径读取图片内容     image = tf.io.read_file(filenames)     # 将图像解码为jpeg格式的3维数据     image = tf.image.decode_jpeg(image, channels=3)        # 归一化     image = tf.cast(image, tf.float32) / 255.0     # 返回图片数据和标签 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 447}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 448     return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label):     # transpose改变数据的维度，比如原来的数据shape是(64,4,62)     # 这里的64是批次大小，验证码长度为4有4个标签，62是62个不同的字符     # tf.transpose(label,[1,0,2])计算后得到的shape为(4,64,62)     # 原来的第1个维度变成了第0维度，原来的第0维度变成了1维度，第2维不变     # (64,4,62)->(4,64,62)     label = tf.transpose(label,[1,0,2])     # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义4个任务，所以这里返回4个标签     # 每个标签的shape为(64,62)，64是批次大小，62是独热编码格式的标签     return image, (label[0],label[1],label[2],label[3])  # 创建dataset对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成1个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个map和前面的map有所不同，第一个map在batch之前，所以是处理每一条数据 # 这个map在batch之后，所以是处理每一个batch的数据 dataset_test = dataset_test.map(label_function)  # 用于统计准确率 acc_sum = 0 # 统计批次数量 n = 0 for x,y in dataset_test:     # 计算批次数量     n+=1     # 进行一个批次的预测     pred = model.predict(x)     # 获得对应编号     pred = np.argmax(pred, axis=-1) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 448}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 449     # 获得标签数据     label = np.argmax(y, axis=-1)     # 计算这个批次的准确率然后累加到总的准确率统计中     acc_sum += (pred == label).all(axis=0).mean() # 计算测试集准确率 print(acc_sum / n) 结果输出为： 0.8631052107614607  代码13-3：tf.data-多任务学习-验证码识别-模型预测（片段2） # 把标签编号变成字符串 # 如[2,34,22,45]->\\'2ymJ\\' def labels_to_text(labels):     ret = []     for l in labels:         ret.append(characters[l])     return \"\".join(ret)  # 把一个批次的标签编号都变成字符串 def decode_batch(labels):     ret = []     for label in labels:         ret.append(labels_to_text(label)) return np.array(ret)  # 获得一个批次数据 x,y = next(iter(dataset_test)) # 预测结果 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1) # shape转换 # (4,64)->(64,4) pred = pred.T # 获得标签数据 label = np.argmax(y, axis=-1) # (4,64)->(64,4) label = label.T # 根据编号获得对应验证码 pred = decode_batch(pred) # 根据编号获得对应验证码 label = decode_batch(label) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 449}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 450 # 获取前3张图片数据 for i,image in enumerate(x[:3]):     # 显示图片     plt.imshow(image)     # 设置标题     plt.title('real:%s\\\\npred:%s'%(label[i],pred[i]))     plt.show() 结果输出为： \\n \\n \\n  我们可以看到，要把4个验证码都预测正确其实还是挺难的，因为我这里做的验证码识别是需要区分大小写的，比如第一张图片中的第3个字符正确标签是小x，模型预测结果是\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 450}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 451 大X，这确实很容易判断错误。还有0小o大O等这些都比较容易混淆，所以能得到86%的准确率也还算不错了。  13.5 使用自定义数据生成器完成验证码识别 13.5.1 使用自定义数据生成器完成模型训练  我们之前有用过Tensorflow.keras自带的一个专门用来处理图片数据的生成器ImageDataGenerator，它可以从电脑硬盘读取数据，然后进行数据增强处理，再生成一个一个批次的数据，在model.fit中进行模型训练。 我们现在要做的验证码识别项目使用的数据集是一个python模块自动生成的，所以在训练模型的时候我们可以一边生成数据集一边训练模型，那么我们可以自定义一个生成器来完成这个数据生成的工作。本小节我们也将使用多任务学习的方式来完成验证码识别的模型训练，不过我们这次不是用tf.data来获取和处理数据，我们将通过自定义数据生成器来完成数据的产生和处理，如代码13-4所示。。 代码13-4：自定义数据生成器-验证码识别（片段1） from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau from captcha.image import ImageCaptcha   import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 451}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 452 # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60  # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence  # 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为n个批次， # Sequence一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用captcha模块生产出来的，一边生产一边训练，可以认为数据集是无限的。 class CaptchaSequence(Sequence):     # __getitem__和__len__是必须定义的两个方法     def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60):         # 字符集         self.characters = characters         # 批次大小         self.batch_size = batch_size         # 生成器生成多少个批次的数据         self.steps = steps         # 验证码长度         self.n_len = n_len         # 验证码图片宽度         self.width = width         # 验证码图片高度         self.height = height         # 字符集长度 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 452}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 453         self.num_classes = len(characters)         # 用于产生验证码图片         self.image = ImageCaptcha(width=self.width, height=self.height)         # 用于保存最近一个批次验证码字符         self.captcha_list = []          # 获得index位置的批次数据     def __getitem__(self, index):         # 初始化数据用于保存验证码图片         x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)         # 初始化数据用于保存标签         # n_len是多任务学习的任务数量，这里是4个任务，batch批次大小，num_classes分类数量         y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8)         # 数据清0         self.captcha_list = []         # 生产一个批次数据         for i in range(self.batch_size):             # 随机产生验证码             captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])             self.captcha_list.append(captcha_text)             # 生产验证码图片数据并进行归一化处理             x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0             # j(0-3),i(0-61),ch(单个字符)             # self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号             for j, ch in enumerate(captcha_text):                 # 设置标签，独热编码one-hot格式                 y[j, i, self.characters.find(ch)] = 1         # 返回一个批次的数据和标签         return x, [y[0],y[1],y[2],y[3]]          # 返回批次数量     def __len__(self):         return self.steps   # 测试生成器 # 一共一个批次，批次大小也是1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2):     # 产生一个批次的数据     x, y = data[0]     # 显示图片     plt.imshow(x[0]) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 453}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 454     # 验证码字符和对应编号     plt.title(data.captcha_list[0])     plt.show() 结果输出为： \\n \\n  代码13-4：自定义数据生成器-验证码识别（片段2） # 载入预训练的resnet50模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)) # 设置输入 inputs = Input((height,width,3)) # 使用resnet50进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的4个字符看成是4个不同的任务 # 每个任务负责识别1个字符 # 任务1识别第1个字符，任务2识别第2个字符，任务3识别第3个字符，任务4识别第4个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) # 定义模型 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 454}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 455 model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)  # 4个任务我们可以定义4个loss # loss_weights可以用来设置不同任务的权重，验证码识别的4个任务权重都一样 model.compile(loss={'out0':'categorical_crossentropy',                     'out1':'categorical_crossentropy',                     'out2':'categorical_crossentropy',                     'out3':'categorical_crossentropy'},               loss_weights={'out0':1,                             'out1':1,                             'out2':1,                             'out3':1},               optimizer=SGD(lr=1e-2,momentum=0.9),               metrics=['acc'])  # 监控指标统一使用val_loss # 可以使用EarlyStopping来让模型停止，连续6个周期val_loss没有下降就结束训练 # CSVLogger保存训练数据 # ModelCheckpoint保存所有训练周期中val_loss最低的模型 # ReduceLROnPlateau学习率调整策略，连续3个周期val_loss没有下降当前学习率乘以0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),              CSVLogger('Captcha.csv'),               ModelCheckpoint('Best_Captcha.h5', monitor='val_loss', save_best_only=True),              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)] # 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),           epochs=epochs,           validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_steps),           callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 164s 164ms/step - loss: 10.0266 - out0_loss: 2.3069 - out1_loss: 2.7054 - out2_loss: 2.6668 - out3_loss: 2.3474 - out0_acc: 0.3711 - out1_acc: 0.3144 - out2_acc: 0.3197 - out3_acc: 0.3896 - val_loss: 3.8732 - val_out0_loss: 1.1623 - val_out1_loss: 0.9057 - val_out2_loss: 0.9186 - val_out3_loss: 0.8866 - val_out0_acc: 0.6719 - val_out1_acc: 0.7352 - val_out2_acc: 0.7278 - val_out3_acc: 0.7531 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 455}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 456 …… Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07. 1000/1000 [==============================] - 160s 160ms/step - loss: 0.1092 - out0_loss: 0.0254 - out1_loss: 0.0295 - out2_loss: 0.0283 - out3_loss: 0.0260 - out0_acc: 0.9901 - out1_acc: 0.9880 - out2_acc: 0.9885 - out3_acc: 0.9902 - val_loss: 0.1104 - val_out0_loss: 0.0260 - val_out1_loss: 0.0304 - val_out2_loss: 0.0273 - val_out3_loss: 0.0267 - val_out0_acc: 0.9902 - val_out1_acc: 0.9877 - val_out2_acc: 0.9900 - val_out3_acc: 0.9881 Epoch 00050: early stopping  由于使用自定义数据生成器可以生产出无数张图片，所以相当于模型的训练数据比之前用tf.data从硬盘中读取数据要多了很多。最终我们也可以看到更多的训练数据得到的结果也会更好。  13.5.2 使用自定义数据生成器完成模型预测  下面我们来看一下关于模型预测部分的程序，如代码13-5所示。 代码13-5：自定义数据生成器-验证码识别-模型预测（片段1） from tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 批次大小 batch_size = 64 # 载入训练好的模型 model = load_model('Best_Captcha.h5')  # 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的， \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 456}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 457 # 把所有数据训练一次属于训练一个周期，一个周期可以分为n个批次， # Sequence一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用captcha模块生产出来的，一边生产一边训练，可以认为数据集是无限的。 class CaptchaSequence(Sequence):     # __getitem__和__len__是必须定义的两个方法     def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60):         # 字符集         self.characters = characters         # 批次大小         self.batch_size = batch_size         # 生成器生成多少个批次的数据         self.steps = steps         # 验证码长度         self.n_len = n_len         # 验证码图片宽度         self.width = width         # 验证码图片高度         self.height = height         # 字符集长度         self.num_classes = len(characters)         # 用于产生验证码图片         self.image = ImageCaptcha(width=self.width, height=self.height)         # 用于保存最近一个批次验证码字符         self.captcha_list = []          # 获得index位置的批次数据     def __getitem__(self, index):         # 初始化数据用于保存验证码图片         x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)         # 初始化数据用于保存标签         # n_len是多任务学习的任务数量，这里是4个任务，batch批次大小，num_classes分类数量         y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8)         # 数据清0         self.captcha_list = []         # 生产一个批次数据         for i in range(self.batch_size):             # 随机产生验证码             captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])             self.captcha_list.append(captcha_text)             # 生产验证码图片数据并进行归一化处理             x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0             # j(0-3),i(0-61),ch(单个字符) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 457}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 458             # self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号             for j, ch in enumerate(captcha_text):                 # 设置标签，独热编码one-hot格式                 y[j, i, self.characters.find(ch)] = 1         # 返回一个批次的数据和标签         return x, [y[0],y[1],y[2],y[3]]          # 返回批次数量     def __len__(self):         return self.steps   # 测试模型，随机生成验证码 # 一共一个批次，批次大小也是1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2):     # 产生一个批次的数据     x, y = data[0]     # 预测结果     pred = model.predict(x)     # 获得对应编号     captcha = np.argmax(pred,axis=-1)[:,0]     # 根据编号获得对应验证码     pred = ''.join([characters[x] for x in captcha])     # 显示图片     plt.imshow(x[0])     # 验证码字符和对应编号     plt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred))     plt.show() 结果输出为： \\n \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 458}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 459 \\n  代码13-5：自定义数据生成器-验证码识别-模型预测（片段2） # 自定义验证码生成和预测 # 生成自定义验证码 captcha_text = '0oO0' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成4维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred,axis=-1)[:,0] # 根据编号获得对应验证码 pred = ''.join([characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(captcha_text,pred)) plt.show() 结果输出为： \\n  代码13-5：自定义数据生成器-验证码识别-模型预测（片段3） \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 459}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 460 # 计算准确率，区分大小写 def accuracy(test_steps=100):     # 用于统计准确率     acc_sum = 0     for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):         # 进行一个批次的预测         pred = model.predict(x)         # 获得对应编号         pred = np.argmax(pred, axis=-1)         # 获得标签数据         label = np.argmax(y, axis=-1)         # 计算这个批次的准确率然后累加到总的准确率统计中         acc_sum += (pred == label).all(axis=0).mean()     # 返回平均准确率     return acc_sum / test_steps # 计算准确率，区分大小写 print(accuracy()) 结果输出为： 0.956875  代码13-5：自定义数据生成器-验证码识别-模型预测（片段4） # 计算准确率，忽略大小写 def accuracy2(test_steps=100):     # 用于统计准确率     acc_sum = 0     for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):         # 进行一个批次的预测         pred = model.predict(x)         # 获得对应编号         pred = np.argmax(pred,axis=-1).T         # 保存预测值         pred_list = []         # 把验证码预测值转小写后保存         for c in pred:             # 根据编号获得对应验证码             temp_c = ''.join([characters[x] for x in c])             # 字母都转小写后保存             pred_list.append(temp_c.lower())         # 获得标签数据         label = np.argmax(y, axis=-1).T         # 保存标签         label_list = [] \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 460}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 461         # # 把验证码标签值转小写后保存         for c in label:             # 根据编号获得对应验证码             temp_c = ''.join([characters[x] for x in c])             # 字母都转小写后保存             label_list.append(temp_c.lower())         # 计算这个批次的准确率然后累加到总的准确率统计中         acc_sum += (np.array(pred_list) == np.array(label_list)).mean()     # 返回平均准确率     return acc_sum / test_steps # 计算准确率，忽略大小写 print(accuracy2()) 结果输出为： 0.98546875  我们从测试结果可以看到使用自定义数据生成器产生更多的训练数据以后，模型的准确率提高到了95.69%（区分大小写）非常高的准确率，如果不区分大小写准确率可以进一步提高到98.55%。 在自定义验证码程序段中，我生成了一个“0oO0”验证码，就问大家能不能分辨出哪个是0，哪个是o，哪个是O，反正我肯定是分不出来，但是这个模型还能识别正确（当然这个难度还是很大的，不能保证它每一次都能识别正确）。我觉得我们训练的这个模型在这种类型的验证码识别准确率上应该是超过了人类。  13.6 挑战变长验证码识别 13.6.1 挑战变长验证码识别模型训练  前面我们生成的验证码是固定4位长度的，下面我们将增加难度，挑战不固定长度的验证码识别，验证码长度我设置为3-6位的随机4种长度。程序大体框架跟“代码13-4：自\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 461}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 462 定义数据生成器-验证码识别”差不多，主要是自定义数据生成器的部分做了一些修改，让数据生成器会产生随机长度的验证码。 不过为了保证标签对齐，所以我们还是需要固定标签的数量和多任务学习任务的数量。因为验证码最长是6，所以我们把标签的长度和多任务学习任务数量固定为6，标签不足长度6的情况我们会把标签填充到6。模型的类别数会增加一个空白类别，用于填充。 另外我还给模型增加了一个新的任务，用于预测验证码的长度，这个任务其实可有可无，不过用作演示还是加上给大家看看效果，模型结构如图13.5所示。 \\n  图13.5 变长验证码识别  图中有一共有7个输出，其中6个输出表示验证码识别的6个任务，每个任务有63个类别（62个字符加一个空白符）。还有一个输出表示验证码的长度，有4个类别，分别表示3，4，5，6，一共4种验证码的长度。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 462}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 463 挑战变长验证码识别的代码如代码13-6所示。 代码13-6：挑战变长验证码识别（片段1） from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau from captcha.image import ImageCaptcha   import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # 最长验证码 max_len = 6  # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence  # 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为n个批次， # Sequence一般是定义一个训练周期内每个批次的数据如何产生。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 463}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 464 # 我们这里的验证码数据集使用captcha模块生产出来的，一边生产一边训练，可以认为数据集是无限的。 class CaptchaSequence(Sequence):     # __getitem__和__len__是必须定义的两个方法     def __init__(self, characters, batch_size, steps, width=160, height=60):         # 字符集         self.characters = characters         # 批次大小         self.batch_size = batch_size         # 生成器生成多少个批次的数据         self.steps = steps         # 验证码长度随机，3-6位         self.n_len = np.random.randint(3,7)         # 验证码图片宽度         self.width = width         # 验证码图片高度         self.height = height         # 字符集长度         self.num_classes = num_classes         # 用于产生验证码图片         self.image = ImageCaptcha(width=self.width, height=self.height)         # 用于保存最近一个批次验证码字符         self.captcha_list = []          # 获得index位置的批次数据     def __getitem__(self, index):         # 初始化数据用于保存验证码图片         x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)         # 初始化数据用于保存标签         # 6个验证码识别任务，batch批次大小，num_classes分类数量         y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32)         # 数据清0         self.captcha_list = []         # 初始化数据用于保存判断验证码长度的标签，一共4种情况         len_captcha = np.zeros((self.batch_size, 4), dtype=np.int)         # 生产一个批次数据         for i in range(self.batch_size):             # 随机产生验证码             self.n_len = np.random.randint(3,7)             # 设置标签，独热编码one-hot格式，一共4种情况             len_captcha[i, self.n_len-3] = 1             # 转字符串             captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])             # 保存验证码 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 464}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 465             self.captcha_list.append(captcha_text)             # 生产验证码图片数据并进行归一化处理             x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0             # j(0-3),i(0-61),ch(单个字符)             # self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号             for j, ch in enumerate(captcha_text):                 # 设置标签，独热编码one-hot格式                 y[j, i, self.characters.find(ch)] = 1             # 如果验证码长度不是6，则需要设置空白字符的标签为1             # 空白字符在-1位置             for k in range(len(captcha_text),max_len):                 # 空白字符                 y[k, i, -1] = 1         # 返回一个批次的数据和标签         return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]          # 返回批次数量     def __len__(self):         return self.steps   # 测试生成器 # 一共一个批次，批次大小也是1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2):     # 产生一个批次的数据     x, y = data[0]     # 显示图片     plt.imshow(x[0])     # 验证码字符和对应编号     plt.title(data.captcha_list[0])     plt.show() 结果输出为： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 465}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 466 \\n  代码13-6：挑战变长验证码识别（片段2） # 载入预训练的resnet50模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3))  # 设置输入图片 inputs = Input((height,width,3)) # 使用resnet50进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 每个任务负责识别1个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) x4 = Dense(num_classes, activation='softmax', name='out4')(x) x5 = Dense(num_classes, activation='softmax', name='out5')(x) # 预测验证码长度3-6，4种情况所以定义4个分类 num_x = Dense(4, activation='softmax', name='out_num')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3,x4,x5,num_x]) # 画图 plot_model(model,style=0,dpi=200)  # loss_weights可以用来设置不同任务的权重，验证码识别的6个任务权重都一样 # 相对而言out_num更重要一些，因为如果验证码的长度判断错误，那么识别结果一定是错的 # 所以可以给out_num更大一点的权重 model.compile(loss={'out0':'categorical_crossentropy',                     'out1':'categorical_crossentropy',                     'out2':'categorical_crossentropy', \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 466}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 467                     'out3':'categorical_crossentropy',                     'out4':'categorical_crossentropy',                     'out5':'categorical_crossentropy',                     'out_num':'categorical_crossentropy'},               loss_weights={'out0':1,                             'out1':1,                             'out2':1,                             'out3':1,                             'out4':1,                             'out5':1,                             'out_num':2},               optimizer=SGD(lr=1e-2,momentum=0.9),               metrics=['acc'])  # 监控指标统一使用val_loss # 可以使用EarlyStopping来让模型停止，连续6个周期val_loss没有下降就结束训练 # CSVLogger保存训练数据 # ModelCheckpoint保存所有训练周期中val_loss最低的模型 # ReduceLROnPlateau学习率调整策略，连续3个周期val_loss没有下降当前学习率乘以0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1),              CSVLogger('Captcha2.csv'),               ModelCheckpoint('Best_Captcha2.h5', monitor='val_loss', save_best_only=True),              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]  # 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),             epochs=epochs,             validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_steps),             callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 184s 184ms/step - loss: 14.0520 - out0_loss: 2.2189 - out1_loss: 2.6810 - out2_loss: 2.9503 - out3_loss: 2.5608 - out4_loss: 1.8766 - out5_loss: 1.0524 - out_num_loss: 0.3560 - out0_acc: 0.4063 - out1_acc: 0.3020 - out2_acc: 0.2447 - out3_acc: 0.3636 - out4_acc: 0.5493 - out5_acc: 0.7673 - out_num_acc: 0.8614 - val_loss: 13.9098 - val_out0_loss: 2.5258 - val_out1_loss: 1.9578 - val_out2_loss: 2.3671 - val_out3_loss: 2.5046 - val_out4_loss: 1.6575 - val_out5_loss: 0.9196 - val_out_num_loss: 0.9887 - val_out0_acc: 0.4391 - val_out1_acc: 0.5095 - val_out2_acc: 0.4242 - va\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 467}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 468 l_out3_acc: 0.4322 - val_out4_acc: 0.6039 - val_out5_acc: 0.7880 - val_out_num_acc: 0.8316 …… Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08. 1000/1000 [==============================] - 178s 178ms/step - loss: 0.2524 - out0_loss: 0.0436 - out1_loss: 0.0534 - out2_loss: 0.0558 - out3_loss: 0.0457 - out4_loss: 0.0341 - out5_loss: 0.0173 - out_num_loss: 0.0013 - out0_acc: 0.9825 - out1_acc: 0.9796 - out2_acc: 0.9800 - out3_acc: 0.9823 - out4_acc: 0.9870 - out5_acc: 0.9930 - out_num_acc: 0.9997 - val_loss: 0.2374 - val_out0_loss: 0.0452 - val_out1_loss: 0.0515 - val_out2_loss: 0.0498 - val_out3_loss: 0.0404 - val_out4_loss: 0.0307 - val_out5_loss: 0.0174 - val_out_num_loss: 0.0012 - val_out0_acc: 0.9823 - val_out1_acc: 0.9786 - val_out2_acc: 0.9792 - val_out3_acc: 0.9841 - val_out4_acc: 0.9886 - val_out5_acc: 0.9931 - val_out_num_acc: 0.9997 Epoch 00036: early stopping  从模型最后的结果看来预测验证码长度的任务准确率几乎达到了1，也就是说模型预测验证码的长度是非常准了。6个验证码预测任务中准确率最高的是out5，也就是最后1位验证码的预测。out5准确率明显高于其他任务是因为验证码的长度是3-6，也就是说只要验证码的长度判断正确，那么有75%的可能性最后1位验证码它就是空白符，所以准确率比较高。相对而言out0-out2的准确率就会偏低一些了，因为不可能会有空白符。 13.6.2 挑战变长验证码识别模型预测 实现变长验证码识别-模型预测的代码如代码13-7所示。  代码13-7：变长验证码识别-模型预测（片段1） from tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 468}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 469 # 载入训练好的模型 model = load_model('Best_Captcha2.h5') # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 预测阶段使用的字符多一个空白符在最后 pred_characters = characters + ' ' # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 最长验证码 max_len = 6  # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence  # 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为n个批次， # Sequence一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用captcha模块生产出来的，一边生产一边训练，可以认为数据集是无限的。 class CaptchaSequence(Sequence):     # __getitem__和__len__是必须定义的两个方法     def __init__(self, characters, batch_size, steps, width=160, height=60):         # 字符集         self.characters = characters         # 批次大小         self.batch_size = batch_size         # 生成器生成多少个批次的数据         self.steps = steps         # 验证码长度随机，3-6位         self.n_len = np.random.randint(3,7)         # 验证码图片宽度         self.width = width         # 验证码图片高度         self.height = height         # 字符集长度         self.num_classes = num_classes         # 用于产生验证码图片         self.image = ImageCaptcha(width=self.width, height=self.height)         # 用于保存最近一个批次验证码字符         self.captcha_list = []          # 获得index位置的批次数据 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 469}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 470     def __getitem__(self, index):         # 初始化数据用于保存验证码图片         x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)         # 初始化数据用于保存标签         # 6个验证码识别任务，batch批次大小，num_classes分类数量         y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32)         # 数据清0         self.captcha_list = []         # 初始化数据用于保存判断验证码长度的标签，一共4种情况         len_captcha = np.zeros((self.batch_size, 4), dtype=np.int)         # 生产一个批次数据         for i in range(self.batch_size):             # 随机产生验证码             self.n_len = np.random.randint(3,7)             # 设置标签，独热编码one-hot格式，一共4种情况             len_captcha[i, self.n_len-3] = 1             # 转字符串             captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])             # 保存验证码             self.captcha_list.append(captcha_text)             # 生产验证码图片数据并进行归一化处理             x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0             # j(0-3),i(0-61),ch(单个字符)             # self.characters.find(ch)得到c在characters中的位置，可以理解为c的编号             for j, ch in enumerate(captcha_text):                 # 设置标签，独热编码one-hot格式                 y[j, i, self.characters.find(ch)] = 1             # 如果验证码长度不是6，则需要设置空白字符的标签为1             # 空白字符在-1位置             for k in range(len(captcha_text),max_len):                 # 空白字符                 y[k, i, -1] = 1         # 返回一个批次的数据和标签         return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]          # 返回批次数量     def __len__(self):         return self.steps   # 测试模型 # 一共一个批次，批次大小也是1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2):     # 产生一个批次的数据 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 470}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 471     x, y = data[0]     # 预测结果     pred = model.predict(x)     # 0表示长度3，1表示长度4，2表示长度5，3表示长度6     captcha_len = np.argmax(pred[6],axis=-1)[0]+3     # 打印验证码长度     print('验证码长度：',captcha_len)     # 获得对应编号     captcha = np.argmax(pred[:6],axis=-1)[:,0]     # 根据编号获得对应验证码     # 注意这里需要使用pred_characters，包含空白符     pred = ''.join([pred_characters[x] for x in captcha])     # 显示图片     plt.imshow(x[0])     # 验证码字符和对应编号     plt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred))     plt.show() 结果输出为： 验证码长度： 6 \\n 验证码长度： 5 \\n   代码13-7：变长验证码识别-模型预测（片段2） # 自定义验证码生成和预测 # 生成自定义验证码 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 471}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 472 captcha_text = 'oOxXvV' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成4维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred[:6],axis=-1)[:,0] # 根据编号获得对应验证码 pred = ''.join([pred_characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(captcha_text,pred)) plt.show() 结果输出为： \\n   代码13-7：变长验证码识别-模型预测（片段3） # 计算准确率，区分大小写 def accuracy(test_steps=100):     # 用于统计准确率     acc_sum = 0     for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):         # 进行一个批次的预测         pred = model.predict(x)         # 获得对应编号         pred = np.argmax(pred[:6], axis=-1)         # 获得标签数据         label = np.argmax(y[:6], axis=-1)         # 计算这个批次的准确率然后累加到总的准确率统计中         acc_sum += (pred == label).all(axis=0).mean() \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 472}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 473     # 返回平均准确率     return acc_sum / test_steps # 打印区分大小写准确率 print(accuracy()) 结果输出为： 0.913125   代码13-7：变长验证码识别-模型预测（片段4） # 计算准确率，忽略大小写 def accuracy2(test_steps=100):     # 用于统计准确率     acc_sum = 0     for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps):         # 进行一个批次的预测         pred = model.predict(x)         # 获得对应编号         pred = np.argmax(pred[:6],axis=-1).T         # 保存预测值         pred_list = []         # 把验证码预测值转小写后保存         for c in pred:             # 根据编号获得对应验证码             temp_c = ''.join([pred_characters[x] for x in c])             # 字母都转小写后保存             pred_list.append(temp_c.lower())         # 获得标签数据         label = np.argmax(y[:6], axis=-1).T         # 保存标签         label_list = []         # # 把验证码标签值转小写后保存         for c in label:             # 根据编号获得对应验证码             temp_c = ''.join([pred_characters[x] for x in c])             # 字母都转小写后保存             label_list.append(temp_c.lower())         # 计算这个批次的准确率然后累加到总的准确率统计中         acc_sum += (np.array(pred_list) == np.array(label_list)).mean()     # 返回平均准确率     return acc_sum / test_steps # 打印忽略大小写准确率 print(accuracy2()) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 473}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 474 0.963125   程序运行结果我们可以看到，这个模型可以自动判断验证码的长度，并做出正确识别。就连“oOxXvV”这种几乎不可能识别正确的验证码图片它也能识别正确。不过由于变长验证码难度更大，并且验证码的位数有可能比原来的4位更多，所以验证码的综合准确率相比之前有所下降。  13.7 CTC算法 13.7.1 CTC算法介绍  CTC(Connectionist Temporal Classification)是用来解决输入序列和输出序列难以一一对应的问题，主要用于语音识别和OCR(Optical Character Recognition)领域。语音识别如图13.6所示。 \\n 图13.6 语音识别 比如在语音识别任务中，我们需要将一大段语音跟一段文本对应。最容易想到的方式就是把一大段语音切分为语音片段，然后每个语音片段对应一个字或一个词。但是每个人说话\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 474}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 475 的语速不同，这个切分的规则很难定义。如果每一段语音都通过人为手动切分，虽然方法可行，但是工作量非常大。  同样的在OCR领域也会遇到同样的对齐困难，如图13.7所示。 \\n 图13.7 数据对齐困难  CTC就是用来解决输入数据和输出数据的对齐问题，我们可以通过下面的例子来理解。不管是语音识别或是OCR还是其他类似任务，假设我们先以一定的方法（比如卷积）对输入数据进行特征提取，然后得到6个数据特征，如图13.8中的𝑥\"-𝑥â。 \\n 图13.8 数据对齐  6个特征𝑥\"-𝑥â分别预测出对应的6个字符，然后我们可以将相邻并重复的字符删除，得到最后的结果。这个对齐方式有两个问题，第一个问题是在语音识别，有些音频片段可能是无声的，这个时候应该是没有字符输出的。第二个问题是有些单词本身就存在重复单词，比如“hello”，如果去重的话就会变成“helo”。  为了解决这两个问题，CTC引入了一个空白占位符，用来表示空白输出，这里我们用𝜖来表示，加入空白符以后输入和输出就可以合理的对应上了，如图13.9所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 475}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 476 \\n 图13.9 引入空白符  在这个对齐方式中，如果标签文本存在重复字符，对齐过程中会在两个重复字符当中插入空白符隔开，这样“hello”就不会变成“helo”了。 假设标签文本为“cat”，图13.10中左边的部分都是正确的结果，右边的部分都是错误的结果。 \\n 图13.10 正确对齐和错误对齐   \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 476}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 477 13.7.2 贪心算法（Greedy Search）和集束搜索算法（Beam Search） 下面我们进一步考虑更多的细节，比如我们把一段“hello”的语音进行特征提取，然后再把提取后的特征传入RNN网络中，每传入1个特征RNN网络就会输出一组结果，如图13.11。 \\n 图13.11 CTC算法  图中RNN的每次输出都有5种可能的结果，这5种可能的结果有不同的概率值（图中不同的背景颜色深度表示不同的概率值，颜色越深表示概率越大）。对于一组输入输出(X,Y)来说，CTC的目标是最大化条件概率，公式为13.1。 𝑝(𝑌|𝑋)=?ã𝑝𝑡(𝑎𝑡|𝑋)𝑇𝑡=1𝐴∈𝐴𝑋,𝑌(13.1) \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 477}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 478  𝑝Ã(𝑎Ã|𝑋)表示RNN每个时间序列的输出概率分布，t表示RNN里第t个序列，∏𝑝Ã(𝑎Ã|𝑋)~ÃA\"表示一条路径所有字符概率相乘，∑∏𝑝Ã(𝑎Ã|𝑋)~ÃA\"ç∈çè,é表示多条路径概率相加。  其实有多条路径可以得到“hello”的结果，比如序列长度为10，“heeϵlϵloϵϵ”,“hϵϵeeϵlϵlo”, “ϵϵhheϵlϵlo”, “hϵeeϵlϵloϵ”等结果其实都是表示“hello”。所以“hello”的概率应该是所有有效的“hello”路径概率的总和。 P(“hello”)=P(“heeϵlϵloϵϵ”)+P(“hϵϵeeϵlϵlo”)+P(“ϵϵhheϵlϵlo”)+P(“hϵeeϵlϵloϵ”)+……  可以想象对于一个输出，可以得到这个输出的路径肯定是非常多的。在实际应用中我们不会将所有路径的概率都计算出来，主要是计算量太大了，所以我们需要采用动态规划的思想来计算。CTC主要采用两种动态规划的算法，贪心算法（Greedy Search）和集束搜索算法（Beam Search）。  下面我们举两个简单的例子来说明，贪心算法就是在序列输出的每一个阶段都选取概率最大的一个输出值，比如我们有一个序列有3种输出“a”，“b”，“-”。“-”表示空白符，贪心算法输出的结果如下图13.12所示。 \\n 图13.12 贪心算法（Greedy Search） \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 478}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 479  t0阶段概率最大的是“-”为0.8，t1阶段概率最大的是“-”为0.6，所以贪心算法的输出结果为“--”，概率为0.8×0.6=0.48。一般来说贪心算法计算量小，效果也不错。但有时候贪心算法得到的结果不一定是最好的。如图13.13所示。 \\n 图13.13 贪心算法失效  比如我们计算一下“a”的输出概率：  P(“a”）=P(“aa”)+P(“a-”)+P(“-a”)= 0.2×0.4+0.2×0.6+0.8×0.4=0.52>0.48。所以贪心算法得到的结果不一定是最好的，我们可以使用beam search。  beam search跟贪心算法不同的地方在于beam search会计算当前最好的N个结果，N可以人为设定。还是使用上面的例子，当N等于2时，可以得到图13.14所示。 \\n 图13.14 beam search \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 479}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 480  我们来分析一下，t0时“a”的概率为0.2，空白符“-”的概率为0.8，所以t0我们选出最好的两个结果就是“a”和“-”。t1时我们得到的组合有“aa”，“ab”，“a”，“b”，“”，我们一个一个来分析。 t1时输出“aa”是不可能的，因为如果真的要输出“aa”，必须至少要有一个空白符在两个“a”中间，如“a-a”->“aa”。 t1时输出“ab”也不可能，因为t1时“b”的概率为0。 t1时输出“b”也不可能，因为t1时“b”的概率为0。 t1时输出“a”可以。t0输出“a”，t1输出“a”或“-”，最后的结果都是“a”；t0输出“-”，t1输出“a”，也可以得到“a”。总概率前面我们计算过为0.52。 t1时输出空白“”可以。t0输出“-”，t1也输出“-”，最后得到“”。概率为0.48。 如果有更长的序列，我们将沿着这个结果继续往下分析，并且每个序列只保存概率最大的两个输出。  13.7.3 CTC存在的问题  最后总结一下CTC的几个问题：  1.条件独立性。CTC做了一个假设就是不同时间序列的输出之间是独立的。这个假设对于很多序列问题来说并不成立，输出序列之间往往存在联系。  2.单调对齐。CTC只允许单调对齐，这在语音识别，OCR等领域中可能是有效的。但是在机器翻译中，比如有些中文句子后面的词可能对应于英文句子中前面的词，这个CTC无法做到。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 480}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 481  3.多对一映射。CTC的输入和输出是多对一的关系。这意味着输出长度不能超过输入长度，这在语音识别，OCR等领域问题不大，但是对于某些输出长度大于输入长度的应用CTC就无法处理了。  13.8 CTC算法-验证码识别  13.8.1 使用CTC算法训练验证码模型 下面我们要学习的CTC算法-验证码识别程序要注意的点挺多的，我在程序注释中都已经详细的写清楚了。这里再稍微提一下，由于Tensorflow.keras中没有实现CTC算法的相关功能，所以CTC算法相关计算需要调用Tensorflow中的程序实现，如代码13-8所示。 代码13-8：CTC算法-验证码识别（片段1） from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau from tensorflow.keras import backend as K from captcha.image import ImageCaptcha   import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 481}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 482 # 训练集大小相当于是64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # RNN的cell数量 RNN_cell = 128 # 最长验证码 max_len = 6 # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence # 这里的Sequence定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为n个批次， # Sequence一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用captcha模块生产出来的，一边生产一边训练，可以认为数据集是无限的。 class CaptchaSequence(Sequence):     # __getitem__和__len__是必须定义的两个方法     def __init__(self, characters, batch_size, steps, n_len=max_len, width=160, height=60,                  input_len=10, label_len=max_len):         # 字符集         self.characters = characters         # 批次大小         self.batch_size = batch_size         # 生成器生成多少个批次的数据         self.steps = steps         # 验证码长度随机，3-6位         self.n_len = np.random.randint(3,7)         # 验证码图片宽度         self.width = width         # 验证码图片高度         self.height = height         # 输入长度10，注意这里输入长度指的是RNN模型输出的序列长度，具体要看下面模型搭建部分         # RNN模型输出序列长度为10表示模型最多可以输入10个字符(包含空白符在内)         self.input_len = input_len         # 标签长度         self.label_len = label_len ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 482}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 483         # 字符集长度         self.num_classes = num_classes         # 用于产生验证码图片         self.image = ImageCaptcha(width=self.width, height=self.height)         # 用于保存最近一个批次验证码字符         self.captcha_list = []          # 获得index位置的批次数据     def __getitem__(self, index):         # 初始化数据用于保存验证码图片         x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)         # 初始化数据用于保存标签         y = np.zeros((self.batch_size, self.label_len), dtype=np.int8)         # 输入长度         input_len = np.ones(self.batch_size)*self.input_len         # 标签长度         label_len = np.ones(self.batch_size)*self.label_len         # 数据清0         self.captcha_list = []         # 生产一个批次数据         for i in range(self.batch_size):             # 随机产生验证码             self.n_len = np.random.randint(3,7)             # 转字符串             captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])             # 保存验证码             self.captcha_list.append(captcha_text)             # 生产验证码图片数据并进行归一化处理             x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0             for j, ch in enumerate(captcha_text):                 # 设置标签，这里不需要独热编码                 y[i, j] = self.characters.find(ch)             # 如果验证码长度不是6，则需要设置空白字符             for k in range(len(captcha_text),self.label_len):                 # 空白字符编号为num_classes-1                 y[i, k] = num_classes-1         # 返回一个批次的数据和标签         # 注意这里的标签np.ones(self.batch_size)是没有意义的，只是由于返回的数据必须要有标签         return [x, y, input_len, label_len], np.ones(self.batch_size)          # 返回批次数量     def __len__(self):         return self.steps  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 483}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 484 # 测试生成器 # 一共一个批次，批次大小也是1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2):     # 产生一个批次的数据     [x, y, _, _], _  = data[0]     # 显示图片     plt.imshow(x[0])     # 验证码字符和对应编号     plt.title(data.captcha_list[0])     plt.show() 结果输出为： \\n \\n  代码13-8：CTC算法-验证码识别（片段2） # Keras调用Tensorflow中的ctc_batch_cost # x是模型输出，shape-(?,10,63) # labels是验证码的标签，shape-(?,max_len) # input_len是x的长度，shape-(?,1)，x的长度为10 # label_len是labels的的长度，shape-(?,1)，labels的长度为max_len def ctc_lambda_func(args):     x, labels, input_len, label_len = args     # Tensorflow中封装的ctc计算 return K.ctc_batch_cost(labels, x, input_len, label_len)  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 484}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 485 # 载入预训练的resnet50模型，不包含全连接层 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)) # 设置输入 image_input = Input((height,width,3), name='image_input') # 使用resnet50进行特征提取 x = resnet50(image_input) # resnet50计算后得到的数据shape为(?,2,5,2048) # 10个输入最多对应10个输出，验证码最长为6，理论上只要不出现6个字符都相同的极端情况，长度是够用的。 # 比如极端情况'aaaaaa'，'-'表示空白符，模型输出'a-a-a-a-a-a'至少需要11的长度。 # 不过长度不够可能会影响对连续重复字符的判断效果，比如'aaaa'可能会被识别为'aaa' # 如果要增加输入长度，可以通过增大输入图片的大小或修改网络结构的方式实现 # 这里Reshape的作用是将卷积输出的4维数据转化为RNN输入所要求的3维数据，2*5=10表示序列长度 x = Reshape((10,2048))(x) # Bidirectional为双向RNN，可以把RNN/LSTM/GRU传入Bidirectional中 # GRU中的return_sequences=True表示返回所有序列的结果 # 比如在本程序中return_sequences=True返回的结果shape为(?,10,256) # GRU中的return_sequences=False表示只返回序列last output的结果 # 比如在本程序中return_sequences=False返回的结果shape为(?,256) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name='max_len') # 输入长度 input_len = Input(shape=(1), name='input_len') # 标签长度 label_len = Input(shape=(1), name='label_len') # Lambda的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out) # 画图 plot_model(ctc_model,style=0,show_layer_names=True) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 485}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 486 \\n  代码13-8：CTC算法-验证码识别（片段3） from tensorflow.keras.callbacks import Callback  # 编号转成字符串 def labels_to_text(labels):     ret = []     for l in labels:         # -1是空白符         if l == -1:             ret.append(\\'\\')         else:             ret.append(characters[l])     return \"\".join(ret)  # 把一个批次的编号转为字符串 def decode_batch(labels):     ret = []     for label in labels:         ret.append(labels_to_text(label))     return np.array(ret)  # 自定义Callback \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 486}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 487 class Evaluate(Callback):     def __init__(self):         pass     # 自定义准确率计算     def accuracy(self, model, batch_size=batch_size, steps=test_steps):         # 准确率统计         batch_acc = 0         # 产生测试数据         valid_data = CaptchaSequence(characters, batch_size, steps)         for [X_test, y_test, _, _], _ in valid_data:             # 特别要注意，空白字符的编号为-1             # 这里可以先将我们自定义的空白符标签变成-1             for i,label in enumerate(y_test):                 for j,l in enumerate(label):                     if l == num_classes-1:                         y_test[i,j] = -1             # 将一个批次的标签数据转为字符串形式             y_test = decode_batch(y_test)             # 得到预测结果             y_pred = model.predict(X_test)             # shape[0]为batch_size，shape[1]为max_len             shape = y_pred.shape             # ctc_decode默认使用贪心算法计算出ctc的预测结果             # get_value获得ctc_decode的数值返回numpy array格式的数据             out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[0][0])             # 将一个批次的预测数据转为字符串形式             out = decode_batch(out)             # 对比一个批次的标签和预测数据，计算准确率             batch_acc += (y_test == out).mean()         # 返回准确率         return batch_acc / steps          # 顾名思义，在一个训练周期的末尾会自动调用这个方法     # 这里的epoch是当前训练的周期数     # logs是一个字典用来记录一些模型训练的信息     def on_epoch_end(self, epoch, logs):         # 计算准确率         acc = self.accuracy(model)         # 记录val_acc         logs['val_acc'] = acc         # 打印         print(f'\\\\nacc: {acc*100:.4f}')      \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 487}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 488     # 除了on_epoch_end以外，自定义Callback还可以定义很多方法，比如：     # def on_epoch_begin(self, epoch, logs=None):     # def on_batch_begin(self, batch, logs=None):     # def on_batch_end(self, batch, logs=None):     # 等等，有兴趣的同学可以看tensorflow源码进一步研究。  # loss的计算是在K.ctc_batch_cost中实现的，所以这里定义了一个假的loss，没什么意义，也没有作用，但是必须要定义 ctc_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=SGD(lr=1e-2,momentum=0.9))  # 监控指标统一使用val_acc # 可以使用EarlyStopping来让模型停止，连续6个周期val_acc没有上升就结束训练 # CSVLogger保存训练数据 # ModelCheckpoint保存所有训练周期中val_acc最高的模型 # ReduceLROnPlateau学习率调整策略，连续3个周期val_acc没有上升当前学习率乘以0.1 callbacks = [Evaluate(),              EarlyStopping(monitor='val_acc', patience=6, verbose=1),              CSVLogger('Captcha_ctc.csv'),               ModelCheckpoint('Best_Captcha_ctc.h5', monitor='val_acc', save_best_only=True),              ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=3, verbose=1)              ]  # 训练模型 ctc_model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps),               epochs=epochs,               validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_steps),               callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100  999/1000 [============================>.] - ETA: 0s - loss: 5.8164 acc: 33.6562 1000/1000 [==============================] - 313s 313ms/step - loss: 5.8136 - val_loss: 4.2324 Epoch 2/100  999/1000 [============================>.] - ETA: 0s - loss: 1.7650 acc: 62.4844 …… Epoch 36/100  999/1000 [============================>.] - ETA: 0s - loss: 0.3042 acc: 89.7344 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 488}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 489 Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08. 1000/1000 [==============================] - 306s 306ms/step - loss: 0.3042 - val_loss: 0.2984 Epoch 00036: early stopping  13.8.2 使用CTC算法训练验证码模型-模型预测 关于模型测试阶段，我们需要注意的是使用load_weights的方式载入模型权值，而不能直接用load_model载入模型。因为keras中没有封装ctc的loss，ctc的loss是在tensorflow中定义的，属于keras外部自定义loss。模型save的时候如果包含了自定义loss，那么在load_model的时候也需要声明自定义loss。在这个应用中还是重新搭建一遍模型并使用load_weights载入模型权值比较简单，如代码13-9所示。 代码13-9：CTC算法-验证码识别-模型预测（片段1） from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model from tensorflow.keras import backend as K from captcha.image import ImageCaptcha   import matplotlib.pyplot as plt import numpy as np import string # 字符包含所有数字和所有大小写英文字母，一共62个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 图片宽度 width=160 # 图片高度 height=60 # RNN的cell数量 RNN_cell = 128 # 最长验证码 max_len = 6 # Keras调用Tensorflow中的ctc_batch_cost # x是模型输出，shape-(?,10,63) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 489}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 490 # labels是验证码的标签，shape-(?,max_len) # input_len是x的长度，shape-(?,1)，x的长度为10 # label_len是labels的的长度，shape-(?,1)，labels的长度为max_len def ctc_lambda_func(args):     x, labels, input_len, label_len = args     # Tensorflow中封装的ctc计算     return K.ctc_batch_cost(labels, x, input_len, label_len) # 载入预训练的resnet50模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3)) # 设置输入 image_input = Input((height,width,3), name='image_input') # 使用resnet50进行特征提取 x = resnet50(image_input) # 搭建RNN网络 x = Reshape((10,2048))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name='max_len') # 输入长度 input_len = Input(shape=(1), name='input_len') # 标签长度 label_len = Input(shape=(1), name='label_len') # Lambda的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out)  # 注意这里是load_weights，载入权值，这里不能直接用load_model载入模型 # 因为keras中没有封装ctc的loss，ctc的loss是在tensorflow中定义的，属于keras外部自定义loss # 模型save的时候如果包含了自定义loss，那么在load_model的时候也需要声明自定义loss。 # 在这个应用中还是重新搭建一遍模型并使用load_weights载入模型权值比较简单 model.load_weights('Best_Captcha_ctc.h5')  # 用于预测的字符集多一个空白符 pre_characters = characters + '-'  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 490}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 491 # 使用贪心算法预测结果 def greedy(captcha_text):     # 自定义产生一个验证码     captcha_text = captcha_text     # 产生验证码并归一化     image = ImageCaptcha(width=160, height=60)     x = np.array(image.generate_image(captcha_text)) / 255.0     # 变成4维数据     X_test = np.expand_dims(x, axis=0)     # 用模型进行预测     y_pred = model.predict(X_test)     # 查看y_pred的shape     print(\"y_pred shape:\",y_pred.shape)     # 获得每个序列最大概率的输出所在位置，其实也就是字符编号     argmax = np.argmax(y_pred[0], axis=-1)     print(\\'id\\',\\'\\\\t\\',\\'characters\\')     for x in argmax:         # 打印字符编号和对应的字符         print(x,\\'\\\\t\\',pre_characters[x])     # 使用贪心算法计算预测结果     out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.shape[1], greedy=True)[0][0])     # 把预测结果转化为字符串     out = \\'\\'.join([characters[x] for x in out[0]])     # 显示图片     plt.imshow(X_test[0])     # 设置title     plt.title(\\'pred:\\' + out + \\'\\\\ntrue: \\' + captcha_text)     # show     plt.show() # 生产特定验证码并进行识别 greedy(\\'a0b1C3\\') 结果输出为： y_pred shape: (1, 10, 63) id   characters 10   a 0   0 11   b 1   1 38   C 3   3 62   - 62   - 62   - ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 491}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 492 62   - \\n  代码13-9：CTC算法-验证码识别-模型预测（片段2） # 生产特定验证码并进行识别 # 模型训练阶段我们使用的验证码都是3-6位的 # 预测阶段使用2位长度的验证码也可以识别正确 greedy('aa') 结果输出为： y_pred shape: (1, 10, 63) id   characters 10   a 62   - 10   a 10   a 62   - 62   - 62   - 62   - 62   - 62   - \\n  代码13-9：CTC算法-验证码识别-模型预测（片段3） # 生产特定验证码并进行识别 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 492}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 493 # 模型训练阶段我们使用的验证码都是3-6位的 # 预测阶段使用7位长度的验证码也可以识别正确 # 不过由于我们的模型输入输出长度最多为10，并且模型训练阶段，验证码最多为6位 # 所以如果验证码长度超过6的话识别的效果可能不太理想 greedy('abcdefg') 结果输出为： y_pred shape: (1, 10, 63) id   characters 10   a 11   b 12   c 13   d 14   e 15   f 16   g 62   - 62   - 62   - \\n  代码13-9：CTC算法-验证码识别-模型预测（片段4） # 使用beam search预测结果 def beam_search(captcha_text):     # 自定义产生一个验证码     captcha_text = captcha_text     # 产生验证码并归一化     image = ImageCaptcha(width=160, height=60)     x = np.array(image.generate_image(captcha_text)) / 255.0     # 变成4维数据     X_test = np.expand_dims(x, axis=0)     # 用模型进行预测     y_pred = model.predict(X_test)     # 最好的3个结果     top_paths = 3 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 493}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 494     # 保存最好的3个结果     outs = []     for i in range(top_paths):         labels = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.shape[1],                                           greedy=False,top_paths=top_paths)[0][i])[0]         outs.append(labels)     # 最好的3个结果分别显示出来     for out in outs:         # 转字符串         out = ''.join([characters[x] for x in out])         # 显示图片         plt.imshow(X_test[0])         # 设置title         plt.title('pred:' + out + '\\\\ntrue: ' + captcha_text)         # show         plt.show()  # 生产特定验证码并进行识别 beam_search('AbCd70') 结果输出为： \\n \\n \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 494}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 495 \\n   从CTC算法模型测试结果可以看出，就算训练阶段验证码长度是3-6位，模型也能预测少于3位或多于6位的验证码结果。在使用beam search算法后，模型可以给出概率最大的几个输出结果。               \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 495}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 496 第14章-自然语言处理NLP发展历程（上） 本章主要给大家介绍NLP(Natural Language Processing)技术的发展历程，不过必须先要说清楚的是NLP技术是AI技术领域的一个大方向，所以真的要把NLP发展历程介绍清楚那至少要写一两本书。所以本章介绍的内容主要是近年来NLP与深度学习结合的最重要和最新的一些成果。由于内容比较多，所以分上下两个部分给大家介绍。  14.1 NLP应用介绍  在介绍NLP的具体技术之前，我们先来了解一下NLP的一些实际应用。NLP的任务基本上都可以使用序列模型来完成，如果大家对前面的序列模型忘记了可以先回头看一下。NLP应用中大部分的任务都可以使用seq2seq架构来完成，seq2seq计算细节我们在后面再详细介绍。 14.1.1 文本分类/情感分类  如图14.1： \\n 图14.1 文本分类 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 496}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 497  文本分类就是把一段文本划分到不同的类别；情感分类就是对一段文本中所包含的情感进行分类。其实文本分类或文章句子的情感分类本质上都是一样，都是属于分类任务，套用序列模型里面我们讲过的框架，属于多对一框架。输入一篇文章或句子可以看出是一个序列，整个序列输入结束后我们只需要获得序列最后一个输出即可。对最后一个序列的输出信号进行分类，得到分类结果。 14.1.2 分词标注 这个应用在序列模型的章节中也有介绍过， 可以使用多对多架构完成， 序列的每个输入都会得到一个对应的输出结果。给一段文字做分词标注，标注每个字对应的标号。假如使用4-tag(BMES)标注标签，B表示词的起始位置，M表示词的中间位置，E表示词的结束位置，S表示单字词。可以得到类似如下结果： “人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。 14.1.3 机器翻译 如图14.2： \\n 图14.2 机器翻译  机器翻译是典型的seq2seq应用，比如输入一段中文，中文句子就是一段序列。输出得到一段英文，英文句子也是一段序列。类似这种问题都可以使用seq2seq架构来完成。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 497}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 498 14.1.4 聊天机器人  如图14.3： \\n 图14.3 聊天机器人  聊天机器人也是典型的seq2seq应用，输入一个句子输出一个句子。不过目前的技术发展还不够成熟，纯娱乐性质的聊天机器人用处不大，因为你稍微跟它多聊几句可能就会发现它是个智障。你只能跟它聊今天星期几，明天什么天气之类的话题，无法实现复杂对话。 不过聊天机器人在某些特定领域，如机器人客服领域，还是发挥了很大的作用。很多电商，银行都已经上线了机器人客服的应用，因为在特定领域，大家的聊天内容相对固定，所以比较容易判断用户的意图，然后给出相应的回复。 不过大家要注意像机器人客服这样的应用并不是一个模型就可以搞定所有的事情，虽然模型也会用，不过很多用户意图的判断和对话的回复还是通过规则来实现的。比如匹配句子是否出现了某个词，假设出现“发货”这个词，那说明用户可能想咨询发货相关的问题；假如出现“信用卡”，那用户可能是要咨询信用卡相关业务。并且机器人的回复也不是自动生成的回复，机器人回复的内容基本上也是事先人工设置好的内容。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 498}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 499 14.1.5 自动摘要  自动摘要很容易理解，就是阅读文章后产生出文章的标题，也是属于seq2seq架构。这要求模型具备极强的核心内容提取概括能力，听起来就很难。所以目前自动摘要技术做得也不算非常好，有些时候效果不错，有些时候效果很差。 14.1.6 文章生成  可以给模型输入一段话或者是一大段文章，然后让模型自动生成接下来的内容，生成的文章长度可以人为控制，这也是seq2seq模型。这个应用听起来就是即神奇有趣又不靠谱。下面我们可以看一下实际模型得到的效果，使用金庸小说训练后的模型，给它输入一段文字让它进行后续文章的生成（结果来自：https://github.com/bojone/bert4keras/blob/master/examples/task_language_model.py）。  输入：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。  输出：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。这时见他手中所握，竟是一柄特制的短剑，心中大喜，叫道：：原来是金蛇郎君的剑！原来你便是金蛇郎君的弟子，这一下可要叫我失望了。那人哈哈一笑，说道：好啊！好啊，好啊！我的金蛇剑是我的，不过我是你的。这人道：我姓杨名过，名字叫过。你是我儿子，是我女儿，是不是？你这么大的年纪，怎地自称金刀驸马？我这就给你取个名字，叫作过儿。  输入：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗外，但听她呼吸调匀，正自香梦沉酣。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 499}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 500  输出：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗外，但听她呼吸调匀，正自香梦沉酣。次日清晨，张无忌便和赵敏去买了一匹高头大马，自己骑了随伴。那马甚有神骏，三十六斤重的身躯之中，竟无一头白马。他心中怦怦乱跳，暗想：若能将赵敏引出迷城，我决不致再和她相会，但若和赵姑娘相遇，我一生一世决计再难相见。何况我是她的私生女儿，这般亲热，岂不是好？我如何能和她相见？今后我要教训教训她才好？我教教她，教训她，要她心里快快活活的。他心如刀割，当即回到客店，将张无忌的所在说了。  这是什么玩意儿？目前看来除了搞笑以外，没有其他作用。  另外诗歌生成也是类似的，我们可以给模型传入诗歌的标题，模型就可以产生一首诗出来。 14.1.7 图片描述  图片描述是计算机视觉与NLP相结合的一个技术，首先使用一个预训练的CNN模型对图片数据进行特征提取，然后把CNN模型提取的图像特征传给RNN网络进行文字生成，如图14.4： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 500}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 501 \\n 图14.4 图片描述模型  有些图片得到的效果挺好的，如图14.5： \\n 图14.5 图片描述1  臭臭躺在床上，不过光看背景也不太看得出是床，所以描述是laying on a couch也是合理的。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 501}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 502 有些图片描述的效果就比较奇怪了，如图14.6： \\n 图14.6 图片描述2  一个女人站在人行道上，穿着粉红色的雨伞……很显然该模型不具备生活的常识，生活的常识就是人是不会穿雨伞的，它只是把它识别到的物体给拼凑到一起了。  图片描述在某些特定场景下可以得到不错的效果，不过整体而言效果还是差强人意的。  NLP的应用还有很多，这里我们就不举太多例子了，大家有兴趣可以再自行研究。  14.2 从传统语言模型到神经语言模型  传统的自然语言处理也叫统计自然语言处理，听名字我们就知道传统的自然语言处理技术主要是使用数学和统计学。这跟神经网络/深度学习在自然语言处理中的技术截然不同，神经网络/深度学习主要使用的是数学和玄学（开玩笑）。由于技术上的巨大差异，下面关于统计自然语言处理的部分我们只做简单介绍，重点还是介绍神经网络/深度学习在自然语言处理方面的应用。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 502}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 503 14.2.1 规则模型[1]  在上世纪60年代左右，学术界对人工智能和自然语言处理的普遍理解是：要让机器完成翻译或语言识别等只有人类才能做的事情，就必须先让计算机理解自然语言，而做到这一点就必须让计算机拥有类似我们人类这样的智能。（真正做到这点确实很难，直到今天计算机也没能做到这一步，所以现在几乎所有科学家都不再坚持这一点）。 那么要如何让计算机理解自然语言呢，当时科学家得出的结论是分析语句和获取语义。我们在学校学习外语的时候都要学习语法规则（Grammar Rules），词性（Part of Speech）和构词法（Morphologie）等，这些内容对于我们学习外语有一定的帮助，并且比较容易用计算机的算法描述。大家以为这会是一条正确的道路。 在上世纪80年代以前，自然语言处理工作中的文法规则都是人工写的，直到2000年后，很多公司还是靠人工来总结文法规则。通过人工设计的规则来分析句子虽然可能会有些效果，但是总体而言不太靠谱。比如有下面3个问题： 问题1：我们人类的语言博大精深，几乎有无数种不同的句子，如果真的能有一套规则能描述好每一个句子，那这套规则得有多少条，几亿条还是几百亿条还是更多？这么复杂的一套规则即使真的存在，我们人类可能无法把它写出来。 问题2：我们人类设计的文法规则通常是上下文无关文法（Context Independent Grammar），而实际句子的文法其实应该是跟上下文相关的，属于上下文相关文法（Context Dependent Grammar）。两者的设计难度和计算量都无法相提并论。 问题3：我们人类的语言有些是需要常识来进行判断的。比如“吃饭前我想方便一下”，“你方便的时候我想请你吃饭”，“你方不方便你去方便的时候问你吃饭的事”，这里的“方便”我们都能理解什么意思，但是要跟老外解释清楚就不容易了，更别说计算机。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 503}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 504 14.2.2 统计语言模型[1] 在上世纪80年代末，随着计算能力的提升和数据量的不断增加，过去看似不可能通过统计模型完成的任务，渐渐都变得可能了。到了上世纪90年代末期，大家发现通过统计得到的句法规则甚至比语言学家总结的更有说服力。2005年以后，Google基于统计方法的翻译系统全面超过基于规则的SysTran翻译系统，宣告规则方法学派的全面溃败。 统计语言模型简单来说就是通过统计得到的语言模型。规则模型的主要思想是通过人工设定的规则来描述语言，而统计语言模型是通过统计学找到语言的规律。比如一个句子： “我爱北京天安门，天安门上太阳升”。 意思清晰句子通顺。如果我们调整一些词的位置，得到： “我爱天安门北京，太阳升上天安门” 虽然句子有些不够通顺，但是意思我们还是可以看懂的，假设我们再调整一下句子，得到： “爱北京天安我门，升门天安上太阳” 这句话就基本看不懂什么意思了，为什么会这样？规则方法学派的科学家认为一个句子是否能理解，要看句子是否合乎语法，句子中的语义是否清晰。他们的想法有一定的道理，但是在规则方法学这条路上的困难要远大于方法，所以这条路是走不通的。 著名的语音识别和自然语言处理的专家弗莱德里克·贾里尼克（Frederick Jelinek）提出了一个新的思路，可以使用简单的统计模型来分析描述一个句子。其实方法很简单，一个句子是否合理，我们不需要分析它的语法语义，只需要分析这句话出现的概率。比如上面我们列举的三个天安门的句子，第一个句子出现概率可能是10\\x7f\"<，第二个句子出现的概率可能是', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 504}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 505 10\\x7f$<，第三个句子出现的概率可能是10\\x7f\"<<。第一个句子出现概率最大，所以最合理，第三个句子概率最小所以最不合理。 比如用S表示一个句子，一个句子由若干个顺序排列的词𝑤\",\\t𝑤#,\\t𝑤$,…,\\t𝑤@组成。所以一个句子出现的概率就等于这个句子每一个词出现的条件概率相乘： 𝑃(𝑆)=𝑃(𝑤\",𝑤#,…,𝑤@)=𝑃(𝑤\")∙𝑃(𝑤#|𝑤\")∙𝑃(𝑤$|𝑤\",𝑤#)∙∙∙𝑃(𝑤@|𝑤\",𝑤#,…,𝑤@\\x7f\")(14.1) 其中𝑃(𝑤\")表示第一个词出现的概率，𝑃(𝑤#|𝑤\")是在已知第一个词的前提下，第二个词出现的概率；以此类推，词𝑤@的出现概率取决于它前面所有的词。 每个词出现的条件概率怎么统计？通常在训练NLP模型的时候我们都会准备一个语料库（Corpus），语料库其实就是一个数据集，这个数据集就是大量的文本数据。我们可以在这个数据集中统计每个词𝑃(𝑤Ã)出现的概率，以及前后相邻的两个词𝑃(𝑤Ã|𝑤Ã\\x7f\")出现概率，前后相邻的三个词，四个词，N个词的概率。 不过这个模型存在一个问题，就是计算量的问题。𝑃(𝑤\")很容易统计出来，𝑃(𝑤#|𝑤\")难度也不是很大，𝑃(𝑤$|𝑤\",𝑤#)难度就已经非常大了。并且这个计算量是指数级增长的，如果句子比较长，𝑃(𝑤@|𝑤\",𝑤#,…,𝑤@\\x7f\")可能是无法计算出来的。 好在这个问题存在可以简化的方式。20世纪初，俄国数学家马尔可夫（Andrey Markov）提出每当遇到类似这种情况时，就假设任意一个词𝑤Ã出现的概率只与它前面的词𝑤Ã\\x7f\"相关，这样问题就变得简单了。这种假设在数学上称为马尔可夫假设。于是公式14.1就可以简化为： 𝑃(𝑆)=𝑃(𝑤\",𝑤#,…,𝑤@)=𝑃(𝑤\")∙𝑃(𝑤#|𝑤\")∙𝑃(𝑤$|𝑤#)∙∙∙𝑃(𝑤@|\\t𝑤@\\x7f\")(14.2) 公式14.2对应的统计语言模型是二元模型（Bigram Model）。一个词的出现概率只与它前面一个词相关叫二元模型，一个词的出现概率与它前面两个词相关叫三元模型，一个词', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 505}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 506 的出现概率与它前面三个词相关叫四元模型。以此类推，一个词的出现概率由前面N-1个词决定，称为N元模型（N-Gram Model）。 可以想象N元模型中N的值越大就越接近句子真实的概率，当然N的值越大计算量也会越大。当N从1到2，再从2到3，模型的效果上升显著，而当模型从3到4时，效果的提升就不是很明显了。所以一般三元或四元模型用得比较多，很少人会使用四元以上模型。 举例来说一下基于N-Gram模型的应用，比如在进行文本分类应用的时候。我们可以根据每个类别的语料库训练各自的语言模型，比如情绪二分类，正面情绪有一个语料库，可以训练一个语言模型；负面情绪有一个语料库，可以训练一个语言模型。当新来一个文本的时候，只要根据各自的语言模型，计算每个语言模型下这篇文本发生的概率。文本在哪个模型的概率大，这篇文本就属于哪个类别。 比如在做语音识别的时候，我们识别出了一个句子的发音“woaibeijingtiananmen”，正确的识别结果是“我爱北京天安门”。但其实这个句子的发音可以对应非常多的文本，比如“我碍北京添安们”，“我爱北精天氨门”。通过N-Gram模型我们可以计算出“我爱北京天安门”这句话出现概率是最大的。 统计语言模型可以很好地解决很多问题，但是该模型也存在很多问题： 问题1：很多时候，在计算条件概率时，𝑃(𝑤Ã|𝑤Ã\\x7f\")会得到0值。也就是新文本中两个相邻词𝑤Ã\\x7f\"𝑤Ã在语料库中没有出现过。所以统计语言模型中需要设计各种平滑方法来处理这种情况。 问题2：统计语言模型无法把n取得很大，最多就是3-gram或4-gram。所以统计语言模型无法建模语言中上下文较长的依赖关系。 问题3：统计语言模型无法表征词语之间的相似性。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 506}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 507 14.2.3 词向量（word embedding） 在介绍神经网络语言模型NNLM（Neural Net Language Model）之前，我们先聊一下NNLM中的核心思想-词向量（Word Embedding），word embedding也可以翻译为词嵌入，本书把它称之为词向量。 我们在处理图像时，图像数据就是一个密集的矩阵，矩阵中的每个数值对应着图片中的每个像素点，我们所需的全部信息都储存在原始数据中。如图14.7： \\n 图14.7 图像数据 所以我们把这个图像数据对应的矩阵分析好就行了。如果是分析文本数据，我们通常会给每个词进行编号，比如“猫”的编号是343，“狗”的编号是452。每个词的编号大小一般是跟该词在语料库中出现的频率相关（也有可能是其他编号方式或人为设置的编号），出现的频率越高，编号就越小。从词的编号我们无法知道这个词所包含的含义，也无法知道词与词之间的相关性。 接下来我们可能还会对编号进行one-hot独热编码处理。假设语料库中一共有10000个词，经过独热编码处理后，每个词的数据长度都为10000，其中只有一个1，其余的位置都是0，如： 杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0] 上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 507}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 508 宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0] 北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0] 注意，虽然独热编码处理后，每个词变成了一个向量，但是这种独热编码类型的向量可不是前面我们说的词向量（Word Embedding）。独热编码的向量虽然在某些简单场景下也可以得到不错的效果，但是复杂一些的场景就无法得到好的效果了。我们把一个词看成是1行10000列的数据，把一个句子看成是一个矩阵，那么这个矩阵将会是一个非常稀疏的矩阵，大部分的值都是0，这个稀疏的矩阵也没有多少可以分析的价值。 所以传统的方式不管是将词变成编号还是将词再转成独热编码，都无法对词包含的信息进行一个很好的描述。那么如何才能比较好的去描述一个词呢？用一个向量来描述一个词，或许是一个不错的方法，这就是我们所说的词向量。 为什么用一个向量来描述一个词会是一个有效的方法？通常词向量的长度都是人为设置的，比如我们设置词向量的长度为128，也就是说每个词都会使用一个128维的向量来表示，这个向量的每一个维度都具有抽象的含义（具体的含义我们是无法知道的）。我举一个不是很恰当的例子，假设词向量的某一个维度d表示该词跟我们日常生活的相关性，相关越大，d的数值就越大。比如“猫”这个词在我们日常生活中经常出现，那么“猫”这个词的词向量中维度d的数值就会比较大；而“引力红移”（广义相对论预言的一种电磁辐射波长变长，频率降低的效应）这个词在我们日常生活中几乎不会出现，所以“引力红移”这个词的词向量中维度d的数值就会比较小。如果每一个词都有128个维度可以用来描述它，那么理论上就可以把这个词包含的信息描述得比较好。最后再强调一下，词向量中每个维度的含义是抽象的，无法知道它们的具体含义。 词向量的思想从NNLM中提出，并一直沿用至今，是深度学习在NLP领域中使用的既是基础又是核心的思想。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 508}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 509 14.2.4 神经语言模型  2003年Bengio在他的经典论文《A Neural Probabilistic Language Model》[2]中首次将神经网络融入到语言模型中，并经过训练得到神经网络语言模型NNLM（Neural Net Language Model）。NNLM的模型结构可以看下图14.8： \\n 图14.8 神经语言模型NNLM[2]  图中output表示输出；Matrix表示矩阵；Table look-up in C表示在矩阵C中查询；shared parameters across words表示参数共享。 下面我们说一下NNLM的训练过程，其实很简单，就是传入前面几个词，然后再预测下一个词是什么。具体流程是我们会分析语料库并构建一个字典V，所有的词都在这个字典中，并且每个词在字典中有唯一编号。NNLM每次训练时从语料库中选取一段长度为n的文本（𝑤Ã\\x7f@\\x97\",…,\\t𝑤Ã\\x7f#,𝑤Ã\\x7f\",𝑤Ã）。比如t=10，n=5，那么文本就是（𝑤â,𝑤ì,𝑤É,𝑤í,𝑤\"<）。n可以人为设置，这里的n有点像n-gram模型中的n的意思，分析连续的n个词。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 509}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 510 接下来我们把长度为n的文本序列用它们所对应的编号来替代，例如：（𝑤â,𝑤ì,𝑤É,𝑤í,𝑤\"<）就变成了类似（26,42,267,6582,64）这样的编号。 然后再将编号变为one-hot独热编码格式。假设字典V中一共有10000个词，本文序列长度为5，经过独热编码的处理后文本数据就变成了5行10000列的矩阵，类似下面这样： [[0,…,0,…,1,…,0,…,0,…,0,…,0,…,0,…0,…,0,…0,…0] [0,…,0,…,0,…,1,…,0,…,0,…,0,…,0,…0,…,0,…0,…0] [0,…,0,…,0,…,0,…,0,…,1,…,0,…,0,…0,…,0,…0,…0] [0,…,0,…,0,…,0,…,0,…,0,…,0,…,0,…0,…,0,…1,…0] [0,…,0,…,0,…,0,…,1,…,0,…,0,…,0,…0,…,0,…1,…0]] 然后把最后一个词的独热编码作为模型预测的标签值，其他词的独热编码作为输入传给模型。图14.8中的C称为词特征层，该层有一个权值矩阵Matrix C可以理解为所有词的词向量矩阵（Matrix C在训练开始的时候都是随机值，没有任何意义，经过模型训练以后才能得到有意义的词向量）。比如词向量的长度为128，那么Matrix C可能就是一个10000行128列的权值矩阵，矩阵中的一行表示一个词的词向量。 每个词的独热编码与Matrix C相乘，得到该词对应的词向量的值，如图14.9： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 510}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 511 图14.9 得到每个词的词向量  图14.8中的𝐶(𝑤Ã\\x7f@\\x97\")表示𝑤Ã\\x7f@\\x97\"的词向量，𝐶(𝑤Ã\\x7f#)表示𝑤Ã\\x7f#的词向量，𝐶(𝑤Ã\\x7f\")表示𝑤Ã\\x7f\"的词向量。得到输入的每个词的词向量以后，对这些词向量进行拼接（concatenation），比如对4个长度为128维的词向量进行拼接，得到512维的数据。公式14.3表示多个词向量进行拼接得到x： 𝑥=(𝐶(𝑤Ã\\x7f\"),𝐶(𝑤Ã\\x7f#),…,𝐶(𝑤Ã\\x7f@\\x97\"),)(14.3)  模型最终的输出值y的计算公式为： 𝑦=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑏+𝑊𝑥+𝑈𝑡𝑎𝑛ℎ(𝑑+𝐻𝑥))(14.4)  可以对照着图14.8来看，x为多个词向量拼接后的信号，H为x到隐藏层之间的权值矩阵，d为隐藏层的偏置值，tanh为隐藏层的激活函数，U为隐藏层到输出层之间的权值矩阵。b+Wx为图14.8中的虚线部分，b是偏置值，W是权值矩阵，虚线就是表示可有可无，如果设置了b和W不为0，则计算b+Wx，相当于x可以传给输出层。如果设置b=W=0，相当于不把x直接传给输出层。模型输出神经元的数量等于字典中的词汇数量，最后softmax得到每个词的预测概率值。  NNLM模型就是在训练一个传入前面几个词，然后预测下一个词的模型。这个模型训练好之后，就得到了我们想要的词向量，词向量就保存在前面提到的Matrix C中。Matrix C中的每一行就对应了一个词的词向量，Matrix C的列数表示词向量的长度，可以人为设置。  NNLM能够对句子中更长的依赖关系进行建模，并且得到了每个词的数值表示，然后可以使用词向量来计算词与词之间的相似性，这些都是传统统计模型无法做到的。将词表征为一个向量形式，这个思想直接启发了后来的word2vec的工作。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 511}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 512  14.3 word2vec 14.3.1 word2vec介绍  词向量的思想最早源于2003年Bengio的论文，但是真正发扬光大是在10年后的2013年。2013年托马斯·米科洛夫（Tomas Mikolov）在Google带领的研究团队创造了一套word embedding训练的方法，称之为word2vec。最早提出word2vec的论文是《Efficient estimation of word representations in vector space》[3]。  word2vec就是word to vector的缩写，中文意思就是将词转化为向量。词向量的思想2003年就已经提出，之所以没有得到大规模的应用，一方面是传统统计语言模型在NLP领域已经大规模应用，并且效果也还不错，想要撼动它的地位不容易；另一方面是词向量的思想虽然看起来很美好，但是实际用起来效果也不算很突出。其实词向量的思想是一个正确的方向，为什么实际应用效果不够突出，主要是词向量的训练方法不够好。而word2vec正是一种更好的词向量训练方法。 14.3.2 word2vec模型训练[4]  word2vec的模型训练有两种方式，分别是连续词袋模型CBOW（Continuous Bag-of-Words）和Skip-Gram模型。这两个模型都很简单，CBOW模型是给神经网络传入上下文词汇，然后预测目标词汇。比如我们有一个用于训练的句子是“我爱北京天安门“，可以给模型传入“爱”和“天安门“，然后用”北京“作为要预测的目标词汇。而最简单的CBOW模型就是传入前一个词然后再预测后一个词，如图14.10： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 512}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 513 \\n 14.10 简单CBOW模型[4]  图中的Input layer表示输入层；Hidden layer表示隐藏层；Output layer表示输出层。 这是一个带有一个隐藏层的简单神经网络。数据预处理的部分跟NNLM一样，先准备一个语料库，然后利用语料库构建一个字典，每个词都有一个编号，再把编号变成独热编码。训练模型的时候就把语料库中的句子相邻的两个词作为一组。比如把“我爱北京天安门”变成“我，爱”，“爱，北京”，“北京，天安门”，然后传给模型，前一个词作为输入，后一个词作为标签。图中的输入为词的独热编码，W为保存词向量的矩阵，字典中一共有V个词，人为设置的词向量长度为N，所以词向量矩阵W是V行N列。词向量的长度其实是通过神经网络隐藏层的神经元个数来设置的，隐藏层的神经元个数等于词向量的长度。隐藏层到输出层之间的权值矩阵W’是N行V列，最后得到V个词的概率分布。  这个简单的CBOW模型训练好以后，每个词的词向量组成的矩阵就是输入层到输出层之间的权值矩阵W，W中的每一行就是一个词的词向量。那么更复杂一些的CBOW模型如图14.11： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 513}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 514 \\n 图14.11 标准CBOW模型[4]  图中的Input layer表示输入层；Hidden layer表示隐藏层；Output layer表示输出层。 标准CBOW模型跟前面的简单CBOW模型类似，只不过是使用上下文的词汇来预测目标词汇。具体是使用前后一个词还是前后两个词或是前后三个词可以人为设定。输入的每个词都共用一个权值矩阵W，而模型训练好以后，输入层到隐藏层之间的权值矩阵W就是词向量矩阵。 Skip-Gram模型跟CBOW模型相反，给模型传入一个词汇，然后预测上下文的词汇。比如给模型传入”北京“，然后把”爱“和”天安门“作为要预测的词汇。如图14.12： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 514}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 515 \\n 图14.12 Skip-Gram模型[4]  图中的Input layer表示输入层；Hidden layer表示隐藏层；Output layer表示输出层。 传入一个词汇以后要预测多少个上下文词汇，都是可以人为设置的。模型训练好以后输入层到隐藏层之间的权值矩阵W就是词向量矩阵。  CBOW和Skip-Gram这两种方式都可以用于训练词向量。 14.3.3 word2vec训练trick和可视化效果  word2vec训练过程中有两个trick，主要是用于加速模型训练。分别是层次softmax（Hierarchical Softmax）和 负采样（Negative Sampling）。这两个trick并不是\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 515}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 516 word2vec的精髓，只是训练技巧，所以这里我们只做个简单介绍，大家有兴趣可以再自行研究。  hierarchical softmax最早源于2005年Bengio的论文《Hierarchical Probabilistic Neural Network Language Model》[5]。训练word2vec词向量的时候，模型的输出是一个多分类，并且由于字典中词汇数量巨大，导致分类数量巨大。hierarchical softmax的本质是把N分类问题变成了log(N)次二分类问题，可以加快模型训练速度。不过随着计算能力的提升，以及GPU加速和TPU加速的应用，现在hierarchical softmax已经用得不多了。 negative sampling源自2013年Mikolov自己的论文《Distributed Representations of Words and Phrases and their Compositionality 》[6]。假设训练word2vec词向量时，词典的大小为30000，那么最后softmax分类就会有30000个结果。如果我们用的是CBOW模型，传入上下文词汇，预测目标词汇。我们把标签词汇看成是正样本，其他词汇看成是负样本。那么在模型训练时，模型输出会最大化正样本（也就是标签词汇）的概率，同时最小化负样本（除标签词汇以外的词汇）的概率，而正样本只有1个，负样本有29999个，负样本的数量巨大，所以计算量比较大。负采样的做法是，每次训练时在所有负样本中选取部分（论文作者的建议是小数据集5-20个，大数据集2-5个）进行训练，由于只选取了少量的负样本进行训练，所以在进行模型计算和权值更新时，计算量减少了很多。 word2vec训练得到的词向量通常都比较长，词向量的效果怎么样，我们可以通过可视化的方式来查看。比如如图14.13： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 516}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 517 \\n 图14.13 word2vec可视化1 这是对word2vec训练得到的词向量进行了降维可视化的结果。图中我们可以看到从男人到女人的向量与从国王到皇后的向量是差不多的，也就是从男人变成女人的这个过程与从国王变成女王的过程差不多，似乎有些道理。 图14.14中也是词向量可视化的结果： \\n 图14.14 word2vec可视化2 图中国王的词向量减去男人的词向量再加上女人的词向量得到的结果约等于皇后的词向量。 从这些可视化的结果我们可以看出，word2vec训练出来的词向量确实包含了词语的信息，可以对词语进行比较好的描述。由于word2vec在实际应用中取得了比较好的效果，基\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 517}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 518 于word2vec，后来又出现了phrase2vec（把词组/短语变成向量表示）, sentence2vec（把句子变成向量表示）和doc2vec（把文章段落变成向量表示），NLP技术的发展一下子变成了embedding的世界。  14.4 CNN在NLP领域的使用 说到CNN大家可能会立马想到计算机视觉。确实，CNN广泛应用于计算机视觉领域，并取得了非常好的效果。不过CNN不仅可以用于计算机视觉，在NLP领域同样可以使用，并且效果也很好。下面我们通过一个文本分类的例子来学习NLP领域如何使用CNN网络，这个例子主要参考2015年的一篇论文《A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification》[7]。 这篇论文是在word2vec之后发表的，所以用到了词向量的思想。数据处理以及模型计算的流程如图14.15： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 518}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 519 \\n 图14.15 使用CNN进行文本分类[7] 图中“I like this movie very much!”表示一个英文的句子，中文意思是“我非常喜欢这个电影”；d表示词向量长度；Sentence matrix表示把句子看成是一个矩阵；convolution表示卷积；activation function表示激活函数；3 region sizes(2,3,4)表示卷积窗口的大小为(2,3,4)；2 filters for each region size表示每个尺度的卷积有2个滤波器；totally 6 filters表示总共6个滤波器；2 feature maps for each region size表示每个尺度的卷积有2张特征图；max-pooling表示最大池化；6 univariate vectors concatenated together to form a single feature vector表示池化后的6张特征图组合起来得到一个新的\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 519}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 520 特征向量。softmax function regularization in this layer表示使用softmax激活函数；2 classes表示2分类。 我们可以对照着图来看下面具体模型计算和训练步骤： 1.首先对要分类的句子进行分词，然后获得每个词的词向量。这里关于词向量如何获取和训练要说明一下。有三种方式，一：载入预训练的词向量。预训练的词向量就是收集大量语料库，使用word2vec的方法训练出每个词的词向量，然后直接载入现在的模型中。词向量载入后数值是固定的，只做计算，不参与训练。二：与方式一相同，载入预训练的词向量，不过方式二中词向量会跟模型一起在新数据集中进行微调finetune。三：随机初始化新的词向量，在新数据集中进行训练。通常来说使用方法二训练效果会稍微更好一些，如果训练数据集比较大的话，用方法三随机初始化新的词向量进行训练也可以。 2.把一个句子的信息看成一个矩阵，矩阵的行是每个词汇，列是每个词汇的词向量，所以行数等于词汇数，列数等于词向量长度，然后对这个矩阵进行卷积。这里的卷积计算跟图像中卷积的计算是一样的，我们可以设置卷积核大小和步长。不过要注意的是卷积核的大小通常指的是卷积窗口的行数，比如可以设置为2,3,4等；卷积窗口的列数等于词向量的长度，也就是等于矩阵的列数（图中的d=5就是词向量的长度为5，主要是为了画图方便，实际应用中词向量的长度可能是128，256，300等这些值）。卷积步长一般设置为1。我们可以像Inception结构一样，设置多个不同尺度的卷积来提取不同尺度的信息。比如使用一些2行的卷积，使用一些3行的卷积，使用一些4行的卷积。这就有点像是2行的卷积是对相邻的2个词进行特征提取，3行卷积对相邻的3个词进行特征提取，4行卷积对相邻4个词进行特征提取。 3.卷积计算后会得到一些特征图，接下来我们可以对这些特征图进行池化，这里的池化用的是最大池化，池化窗口大小等于特征图的大小，也就是提取每个特征图的最大值。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 520}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 521 4.把池化后的数据进行拼接（concatenate）。 5.池化数据拼接后与最后的输出层进行全连接，得到分类结果。输出层神经元个数等于分类类别数。  14.5 RNN在NLP领域的使用 RNN是专门用来处理序列问题的，所以RNN在NLP领域的应用很容易理解。这里的RNN指的是所有的RNN类似的模型，包括SimpleRNN，LSTM，GRU，Bidirectional RNN和多层RNN等，下面我们举两个例子来说明。 14.5.1 使用RNN进行文本分类  数据的预处理跟CNN在NLP领域应用一样。先对句子进行分词，分词后获得每个词的词向量（前面我们说过了有3种方式获取并训练词向量）。然后再把每个词的词向量按照序列的顺序传入RNN模型即可，如图14.16： \\n 图14.16 RNN应用于文本分类 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 521}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 522  图中𝑥<,\\t𝑥\",\\t𝑥#分别为三个词的词向量，ℎ<,\\tℎ\",\\tℎ#分别表示RNN隐藏状态Hidden State（比如LSTM的memory block输出），RNN的Hidden State加上一个用于分类的全连接层，得到RNN的预测结果y。𝑦<,\\t𝑦\",\\t𝑦#分别为RNN的3个序列的输出。由于我们的任务是文本分类，所以我们通常只需要关心序列的最后一个输出即可，用序列最后一个输出与真实标签进行对比得到loss训练模型。 14.5.2 使用RNN进行中文分词标注 我们先简单介绍一下中文分词，在中文分词的任务中，句子中的每个字都会被打上标签。假如使用4-tag(BMES)标注标签，B表示词的起始位置，M表示词的中间位置，E表示词的结束位置，S表示单字词。可以得到类似如下结果： “人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。 在这里我们需要把每个字都变成向量，也就是把每个字都看成是一个“词”。同样的我们也是有3种方式获取并训练词向量，跟前面我们提到的一样。然后再把每个字的词向量按照序列的顺序传入RNN模型即可，如图14.17： \\n 图14.17 RNN应用于中文分词标注 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 522}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 523 图中𝑥<-\\t𝑥ì分别为句子每个字的词向量，𝑦<-\\t𝑦ì分别为RNN的8个序列的输出。由于我们的任务是中文分词标注，所以RNN模型的每个输出我们都需要得到。把RNN模型的每个输出跟真实标签进行对比得到loss训练模型。  14.6 Seq2Seq模型在NLP领域的使用  Seq2Seq模型本质上其实也是RNN，只不过它稍微特殊一些，它是由两个RNN组成。一个RNN是编码器Encoder，另一个RNN是解码器Decoder。Seq2Seq可以完成很多NLP的应用，比如机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。下面我们将使用机器翻译的例子给大家讲解Seq2Seq的工作流程，参考Google在2014年的论文《Sequence to Sequence Learning with Neural Networks》[8]，这篇论文也是比较早期的一篇Seq2Seq的论文，应用于机器翻译，并取得了不错的效果。  Seq2Seq应用于机器翻译如图14.18： \\n 图14.18 Seq2Seq应用于机器翻译 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 523}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 524 左边部分为编码器Encoder，输入一个句子每个字的词向量进行计算，𝑥<-\\t𝑥$表示Encoder序列4个输入的词向量值。Encoder的作用是将整个序列的信息压缩成一个向量表示，所以Encoder不需要进行预测。  经过Encoder计算后会得到C，C称为上下文向量（Context Vector），用来表示整个序列的信息。C的实际内容是Encoder最后一个序列的状态，也就是Hidden State，这里我们称为State好了。  图中右边部分为解码器Decoder。得到C以后，我们可以用C给Decoder的State进行初始化（Encoder和Decoder使用的RNN结构一致，所以Encoder最后一个序列的State可以传给Decoder的State进行初始化），然后给Decoder传入句子起始符“<start>”的词向量，起始符可以自己定义，起始符的词向量跟其他词的词向量一样会跟着模型参数一起训练。传入起始符词向量后计算得到𝑦<R，然后再把𝑦<R的词向量作为下一个序列的输入进行计算得到𝑦\"R，然后再把𝑦\"R的词向量作为下一个序列的输入进行计算得到𝑦#R。𝑦#R是“<end>”符号，表示Decoder输出结束。“<end>”符号是句子结束符，可以自定义。  以上是Seq2Seq的计算过程，训练过程只要将真实标签跟Decoder序列输出进行对比得到loss更新网络权值即可。  这里再重复强调一下，Encoder和Decoder的基本架构可以使用SimpleRNN，LSTM，GRU，双向RNN和多层RNN等。在实际应用中，Seq2Seq模型可能会更多地使用多层RNN或多层双向RNN，提升模型拟合能力。如图14.19是一个三层的Seq2Seq模型： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 524}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 525 \\n 图14.19 多层Seq2Seq模型  由此我们可以看到使用Seq2Seq模型就可以使得输入序列的长度和输出序列的长度不再受到限制，可以输入任意长度的序列得到任意长度的输出序列。Seq2Seq的变化形式很多，所以大家也有可能会见到跟上面介绍略有不同的Seq2Seq模型。我们主要理解Seq2Seq的设计思路，细节上的实现可以有多种形式。  14.7 Attention机制 14.7.1 Attention思想的介绍  Attention也就是注意力机制，主要是一种思想，就是我们在做某些应用的时候可以把注意力放在某些重要的信息上，同时忽视一些没这么重要的信息。其实之前我们介绍的SENet\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 525}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 526 的核心技术就是一种Attention的思想，把注意力集中在某些比较重要的特征图通道上。Attention的这种思想在自然语言处理，图像，语音等领域都可以使用，不过一般在自然语言处理领域用得更多。 下面我们还是通过机器翻译的例子来给大家讲解一下Seq2Seq模型如何与Attention进行结合。我们在做机器翻译时，使用Seq2Seq模型的Encoder把整个句子压缩成一个上下文向量C，然后把C传给Decoder得到翻译结果。这样做其实有个缺点，翻译时，翻译的结果过分依赖于上下文向量C，C是通过一整个句子压缩得来的，那么在压缩的过程中不可避免会造成信息的丢失，翻译的结果也不会特别准确。如何可以改进这种情况呢，可以考虑使用Attention机制，如图14.20： \\n 图14.20 Seq2Seq with Attention \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 526}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 527  还是熟悉的例子，这个图不是一个真实的Attention模型，主要是先让大家了解一下Attention的思想。这里主要有两点我们需要注意： 1.在带有Attention的Seq2Seq模型中，上下文向量C的并不是Encoder最后一个序列的State，而是通过Encoder所有序列的State计算得到。 2.Decoder中每个序列的计算都需要用到不同的上下文向量C。 当我们得到Encoder所有序列的State后，Decoder在进行计算时，可以重点关注对当前输出重要的Encoder State，而忽视不重要的Encoder State。比如翻译的第一个英文单词“deep”，主要是通过“深”，“度”这两个输入得到的，在计算时应该重点关注“深”和“度”所对应的State；第二个英文单词“learning”，主要是通过“学”，“习”这两个输入得到的，在计算时应该重点关注“学”和“习”所对应的State。如图14.21： \\n 图14.21 不同序列有不同的attention  那么如何可以得知Encoder中所有的State，与当前Decoder序列相关性的强弱呢？想要得到这个问题的答案，必须建立起Encoder中State与Decoder序列中的State的关系，这也是Attention模型的关键。图14.20中的模型显然没有做到这一点。后面我们将介\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 527}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 528 绍几个实际的Attention模型，由于Attention的各种变化形式很多，这里主要给大家介绍2种比较常见的Attention，Bahdanau Attention和Luong Attention。 14.7.2 Bahdanau Attention介绍  最早提出Bahdanau Attention的论文是2014年的一篇论文《Neural machine translation by jointly learning to align and translate》[9]，论文的第一作者为Dzmitry Bahdanau，所以论文中所使用的Attention也称为Bahdanau Attention。对于Bahdanau Attention的计算流程，我们还是看图片更容易理解，如图14.22： \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 528}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 529 图14.22 Bahdanau Attention 这个图画完，我的第一感觉是像极了PCB电路板设计，这些方块就像是贴片元器件的焊盘，连线就像是电路走线。我在大学做了3年PCB电路设计，看来对我的绘图风格产生了深远的影响…… 言归正传，Bahdanau Attention的计算流程图基本上跟上一小节Seq2Seq with Attention的图差不多。Encoder没什么好说的，获得所有序列的State。Decoder有些小细节我们要注意，使用Encoder最后一个序列的State作为Decoder的初始化State，传入起始信号<start>，起始信号可以人为设定，计算得到Decoder的State信号ℎ<R，并预测出翻译结果𝑦<R，𝑦<R假设我们得到“deep”。在进行下一次预测的时候，我们就要开始计算上下文向量𝐶\"了，注意看𝐶\"的信号是通过Encoder所有的State和Decoder中上一个序列的State信号ℎ<R共同计算得到的，具体怎么计算等下再说。计算得到𝐶\"后，𝐶\"与上一个序列的预测结果“deep”对应的词向量进行拼接（concatenate），然后传入RNN中进行计算得到State信号ℎ\"R，并预测出翻译结果𝑦\"R。后面的计算以此类推，直到得到句子结束符<end>。 下面我们来说一下Bahdanau Attention的上下文向量C具体怎么算。首先我们要知道C是通过Encoder中所有的State计算出来的，我们会根据Attention，给Encoder中的State分配不同的权重。因此有公式： 𝑐(=?𝛼(\\x81ℎ\\x81~\\x81A\"(14.5) 公式中𝑐(表示Decoder中第i序列的上下文向量C，𝛼(\\x81表示Decoder中第i序列对Encoder中第j序列的Attention权重，ℎ\\x81表示Encoder中第j序列的State，T表示Encoder一共有T个序列。举个具体例子大家可能更好理解，比如“深”，“度”，“学”，“习”分别传入Encoder中得到的State是ℎ<,ℎ\",ℎ#,ℎ$。Decoder在翻译', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 529}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 530 “learning”的时候，假设对ℎ<,ℎ\",ℎ#,ℎ$的权重是0.05，0.05，0.6，0.3（注意这里权重的和为1，“learning”对“学”和“习”的权重相对较大），那么在翻译“learning”的时候上下文向量𝐶\\x84¤ð\\x9c@(@Ñ=0.05ℎ<+0.05ℎ\"+0.6ℎ#+0.3ℎ$。 接下来再说一下Attention权重𝛼具体怎么得到，计算𝛼的公式为： 𝛼(=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊ð∙𝑡𝑎𝑛ℎ\\t(𝑊ñ∙𝐻ñ(\\x7f\"+𝑊¤∙𝐻¤))(14.6)\\t这里的𝛼计算有点像是一个神经网络的计算。𝛼(为Decoder中第i个序列的Attention权重，𝐻ñ(\\x7f\"为Decoder中第i-1序列的Hidden State，𝐻¤为Encoder中所有序列的Hidden State。𝑊ñ和𝑊¤分别为𝐻ñ(\\x7f\"和𝐻¤对应的权值矩阵会跟着模型一起训练，tanh为神经网络第一层的激活函数。𝑊ð为第二层的权值矩阵会跟着模型一起训练，softmax为第二层的激活函数。 我们通过图片的方式来仔细理解一下这里的计算，为了画图方便，假设Encoder和Decoder输出的Hidden State都是4个值，Encoder的序列长度为2。我们将计算过程分为几步来讲解，第一步𝑊ñ∙𝐻ñ(\\x7f\"和𝑊¤∙𝐻¤的计算如图14.23： \\n 图14.23 Attention权值计算第一步 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 530}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 531 第二步计算𝑡𝑎𝑛ℎ\\t(𝑊ñ∙𝐻ñ(\\x7f\"+𝑊¤∙𝐻¤)，如图14.24： \\n 图14.24 Attention权值计算第二步  第三步计算𝑊ð∙𝑡𝑎𝑛ℎ\\t(𝑊ñ∙𝐻ñ(\\x7f\"+𝑊¤∙𝐻¤)，如图14.25： \\n  图14.25 Attention权值计算第三步  第四步计算𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊ð∙𝑡𝑎𝑛ℎ\\t(𝑊ñ∙𝐻ñ(\\x7f\"+𝑊¤∙𝐻¤))，如图14.26：  图14.26 Attention权值计算第四步 由于在这个例子中，Encoder的序列长度为2，所以这里会计算得到两个权重的值，那么最后的上下文向量𝐶(计算如图14.27： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 531}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 532 \\n 图14.27 上下文向量C计算 Bahdanau Attention的论文中还给了一些可视化结果，英文翻译成法文时，英文单词和法文单词之间的Attention权重如图14.28： \\n 图14.28 英文单词和法文单词之间的Attention权重[9] 14.7.3 Luong Attention介绍  最早提出Luong Attention的论文是2015年的一篇论文《Effective Approaches to Attention-based Neural Machine Translation》[10]，论文的第一作者为Minh-Thang \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 532}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 533 Luong ，所以论文使用的Attention也称为Luong Attention。Luong Attention基本思想跟Bahdanau Attention差不多，不过总的来说要比Bahdanau Attention更复杂一些，同时也考虑得更加全面。Luong Attention的计算流程图如图14.29： \\n 图14.29 Luong Attention  我们来看看Luong Attention的计算，Encoder也是计算得到所有序列的State。Decoder部分的RNN也是用Encoder最后输出的State信号ℎ$进行State初始化，然后传\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 533}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 534 入<start>句子起始符，得到State信号ℎ<R。接下来计算上下文向量𝐶<，𝐶<是使用Encoder所有序列的State和Decoder的State信号ℎ<R一起计算出来的，具体的怎么算等下再说。得到𝐶<后与ℎ<R进行拼接（concatenate），ℎ<Rò的计算公式为： ℎ0′ó=𝑡𝑎𝑛ℎ\\t(𝑊Ó[𝐶<;ℎ0′])(14.7)  其中[𝐶<;ℎ<R]表示𝐶<与ℎ<R进行拼接（concatenate），𝑊Ó为权值矩阵会跟着模型一起训练，tanh为激活函数。最后输出𝑦<R的计算公式为： 𝑦0′=𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑊Þℎ0′ó)(14.8) 其中𝑊Þ为权值矩阵会跟着模型一起训练，softmax为激活函数。假如预测得到结果“deep”，在进行下一个序列的计算时会把“deep”对应的词向量和ℎ<Rò一起作为输入传入RNN中。后面的计算以此类推，直到得到句子结束符<end>。 下面我们来看一下Luong Attention的上下文向量C怎么计算，C的计算公式跟Bahdanau Attention一样为公式14.5，不过Luong Attention中Attention权重𝛼的计算方式不同。Luong Attention论文中给出了三种计算Attention权重𝛼的方法： 第一种称为“dot”，也就是dot product点乘的意思，公式为14.9： 𝛼=𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎÃ⊺ℎõÞ)(14.9)  Luong Attention论文中把Encoder中的State称为“source state“，所以ℎõÞ表示所有Encoder的State。Decoder中的State称为”target state“，所以ℎÃ为Decoder中的State，ℎÃ⊺表示ℎÃ转置的意思。举个例子吧，假设Decoder和Encoder的State都是输出4个值，Encoder总共有2个序列，如图14.30： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 534}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 535 \\n 图14.30 dot  使用“dot”方式计算Attention权重𝛼是最简单的了，并且计算过程中没有额外的权重需要训练。 第二种方式称为“general”，公式为： 𝛼=𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎÃ⊺𝑊ðℎõÞ)(14.10)  “general”方式跟“dot”方式其实差不多，只是在计算dot product时加入一个可以训练的权值矩阵。 第三种方式称为“concat”，公式为： 𝛼=𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑣ð⊺𝑡𝑎𝑛ℎ(𝑊ð[ℎÃ;ℎõÞ]))(14.11)  第三种方式其实跟Bahdanau Attention计算Attention权重𝛼的公式是一样的。  最后我们再简单说一下Luong Attention论文中提到的“Global attentional model”和“Local attention model”。作者对Attention的细节做了更多的考虑，“Global attentional model”指的是在计算Attention权重𝛼时，考虑Encoder中所有序列的State，如图14.31： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 535}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 536 \\n 图14.31 Global attentional model[10] 图中的Attention Layer表示注意力层；Context vector表示上下文向量；Global align weights表示全局权重。 “Local attention model“指的是在计算Attention权重𝛼时，只考虑Encoder中部分序列的State，如图14.32： \\n 图14.32 Local attention model[10] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 536}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 537 图中的Attention Layer表示注意力层；Context vector表示上下文向量；Local weights表示局部权重；Aligned position表示对齐位置。 我觉得这一部分已经不是Attention最核心的内容了，所以就不展开介绍了，大家有兴趣可以自行阅读论文中的说明。 14.7.4 谷歌机器翻译系统GNMT介绍  2006年是谷歌翻译推出的年份，10年后的2016年谷歌发布了基于深度学习机器翻译系统GNMT(Google's Neural Machine Translation )。谷歌称GNMT与之前采用的基于短语的机器翻译算法(PBMT)相比，翻译误差降低了55%-85%，并且多种语言互译已经接近人类水平，比如英法互译，英语西班牙语互译，我们最关心的中英互译跟人类还是有些差距，不过也已经提高了很多。而GNMT所使用的模型正是Seq2Seq with Attention，最早提出GNMT的论文是《Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》[11]。  下面我们简单介绍一下GNMT的内容，GNMT中使用的是8层的LSTM-Encoder，8层的LSTM-Decoder，并且Encoder的第一层是双向LSTM，如图14.33： \\n \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 537}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 538 图14.33 GNMT结构[11]  图中的GPU1-GPU8表示使用多个GPU加速训练，Encoder的第一层如图14.34： \\n 图14.34 双向LSTM[11]  大家仔细观察一下GNMT的结构还会发现，在多层LSTM结构中竟然还加上了类似ResNet的残差设计，如图14.35： \\n 图14.35 残差设计[11]  深度学习在计算机视觉，自然语言处理和语音等方面的应用很多地方是相通的，所以可以互相学习和借鉴。  GNMT还有更多的细节内容，如为了加快翻译速度，在模型计算过程中使用低精度计算（模型中部分参数使用8bit计算）。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 538}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 539 为了减少词汇数量，使用WordPiece技术，就是把一些词拆成一片一片，比如“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，“saving”，“saved”，“saves”都是保存的意思，是不是有点重复？使用WordPiece拆分后会得到“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很多。 其他细节内容大家有兴趣可以再进一步研究。  14.7.5 Attention机制在视觉和语音领域的应用 Attention机制虽然一般是应用在NLP领域，不过在计算机视觉和语音领域也有着不少应用。2015年的一篇论文《Show, Attend and Tell: Neural Image Caption Generation with Visual Attention》[12]展示了Attention机制在图像标题生成应用中效果，如图14.36： \\n 图14.36 Image Caption Generation with Visual Attention[12] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 539}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 540 图片下面的句子为深度学习网络生成的图片标题，标题中带有下划线的单词所Attention的区域为图片中白色的部分。比如“dog”所Attention的区域就是图片中的狗头，“stop”所Attention的区域为图片中的stop指示牌，“trees”所Attention的区域为除了长颈鹿以外的背景区域。 2015年的一篇论文《Listen, Attend and Spell》[13]展示了Attention在语音识别领域的应用效果，如图14.37： \\n 图14.37 Speech Recognition with Attention[13]  图中的Audio表示语音；Hypothesis表示预测结果；Time表示时间。 图中我们可以看到语音识别的结果与原始语音片段之间的关系，语音识别结果的每个词都会Attention原始语音片段的某些特定区域。  Attention作为一种思想可以应用于各种领域中，大家在研究一些新的问题时也可以考虑加入Attention机制，说不定会得到意想不到的效果。  14.8 参考文献 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 540}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 541  [1] 吴军.数学之美[M].北京:人民邮电出版社 [2] Kandola E J , Hofmann T , Poggio T , et al. A Neural Probabilistic Language Model[J]. Studies in Fuzziness & Soft Computing, 2006, 194:137-186. [3] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013. [4] Rong X. word2vec parameter learning explained[J]. arXiv preprint arXiv:1411.2738, 2014. [5] Morin F, Bengio Y. Hierarchical probabilistic neural network language model[C]//Aistats. 2005, 5: 246-252. [6] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases and their compositionality[C]//Advances in neural information processing systems. 2013: 3111-3119. [7] Zhang Y, Wallace B. A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1510.03820, 2015. [8] Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural networks[C]//Advances in neural information processing systems. 2014: 3104-3112. [9] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014. [10] Luong M T, Pham H, Manning C D. Effective approaches to attention-based neural machine translation[J]. arXiv preprint arXiv:1508.04025, 2015. \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 541}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 542 [11] Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system: Bridging the gap between human and machine translation[J]. arXiv preprint arXiv:1609.08144, 2016. [12] Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation with visual attention[C]//International conference on machine learning. 2015: 2048-2057. [13] Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint arXiv:1508.01211, 2015.               \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 542}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 543 第15章-自然语言处理NLP发展历程（下） 15.1 NLP新的开始-Transformer模型[1]  Transformer可能很多人都知道，就是“变形金刚”嘛，电影我们都看过，下面我们要了解的内容正是NLP领域的“变形金刚”-Transformer模型。为什么说Transformer是NLP新的开始？因为Transformer模型的出现给混乱的NLP领域发展指引了新的方向。NLP领域在2015-2017年左右这段时间发展有些混乱，因为传统的基于统计的NLP模型还有着很多应用，而基于深度学习的CNN，RNN等模型也展现出了不错的效果，未来应该往哪个方向发展，大家都说不准。这时谷歌2017年的一篇论文给我们指引了新的方向，论文很直接，标题直接告诉了我们答案：《Attention is all you need》[2]。没错，NLP新的发展方向既不是CNN也不是RNN，而是Attention。Transformer模型的重要性不在于它刷新了多少项NLP的记录，而在于它提出了一个新的建模方式，为后续的很多“刷榜”模型提供了基础。 15.1.1 Transformer模型结构和输入数据介绍  下面我们使用机器翻译的例子来讲解Transformer。Transformer的基本框架用的也是Seq2Seq模型，注意这里的Seq2Seq， 里面没有用到RNN，原始的Transformer用的是6层的编码器（Encoder）和6层的解码器（Decoder），如图15.1所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 543}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 544 \\n 图15.1 Transformer的Seq2Seq结构  图中的6个Encoder是相同的结构，6个Decoder也是相同的结构，但Encoder和Decoder的结构有些不同。每个Encoder中有两个结构，每个Decoder中有三个结构，如图15.2所示。 \\n 图15.2 Encoder和Decoder内部结构  Transformer中最核心的结构应该就是Self-Attention，Self-Attention具体是什么后面再说。Feed Forward其实就是两个全连接层，并且不会改变数据维度，这里我们就不多做介绍了。每个Encoder和Decoder中都有一个Self-Attention结构和Feed Forward结\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 544}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 545 构。在Decoder中间还有一个Encoder-Decoder-Attention层，Encoder部分最后输出的Attention信息会传给这个层，告诉Decoder要重点关注输入序列的哪些内容。  Transformer的Encoder最开始的输入为每个词的编号，经过一个Embedding层得到单词的词向量，词向量长度为512。Embedding层的权值矩阵会随机初始化然后跟着模型一起训练，为了画图方便，下面图中的词向量长度为4（我们把它想象成长度为512就可以了），如图15.3所示。 \\n 图15.3 Encoder词向量输入  图中的𝑥\"-\\t𝑥#为序列输入，注意Transformer的Encoder中没有使用RNN，所以序列输入不需要每次传入一个值，而是可以一次性传入所有词的词向量。不过一次性传入所有词的词向量会丢失每个词的位置信息，所以除了词向量Embedding以外，输入信息中还会加上一个表示每个词位置的信息Positional Encoding，所以实际的Encoder输入是词向量Embedding加上位置信息Positional Encoding，如图15.4所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 545}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 546 \\n 图15.4 Encoder输入  图中INPUT表示输入；POSITIONAL ENCODING表示位置信息；EMBEDDING WITH TIME SIGNAL表示包含时序信息的信号。 Positional Encoding可以通过固定公式计算出来，也可以通过一个神经网络训练出来，并且效果相差不大。论文中使用的是固定公式计算，其实固定公式也有很多种，论文中使用的固定公式为 𝑃𝐸(\\x9aÒÞ,#()=𝑠𝑖𝑛\\x8b𝑝𝑜𝑠10000#(ñö÷øùú\\x8c\\t\\t\\t\\t\\t\\t\\t(15.1) 𝑃𝐸(\\x9aÒÞ,#(\\x97\")=𝑐𝑜𝑠\\x8b𝑝𝑜𝑠10000#(ñö÷øùú\\x8c\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(15.2) 公式中PE为Positional Encoding得到的值，跟词向量长度一样。pos表示当前词在句子中的位置，𝑑\\x82Òñ¤\\x84为词向量长度512，𝑃𝐸(\\x9aÒÞ,#()表示偶数维度的计算公式，𝑃𝐸(\\x9aÒÞ,#(\\x97\")表示奇数维度的计算公式。词向量长度为512，句子长度为50，PE的值如图15.5所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 546}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 547 \\n 图15.5 Positional Encoding 横坐标为512个维度的值，纵坐标为句子的50个词，这个图看起来有点玄学的感觉。其实这里的核心在于句子中每个词的Positional Encoding不同就可以，所以可以有多种方式计算Positional Encoding的数值。  词向量Embedding和Positional Encoding相加以后传入第一个Encoder的Self-Attention，如图15.6所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 547}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 548 图15.6 输入Encoder 15.1.2 Self-Attention介绍  Self-Attention是Transformer模型中所使用的Attention，基本思想跟我们之前介绍过的Attention差不多。不过Self-Attention主要是计算一个句子中一个词与其他词之间的Attention，所以名字中有个“Self”。比如我们看下面这个例子：  The animal didn't cross the street because it was too tired.  句子中的“it”指的是“animal”还是“street”，我们很容易判断，不过机器是比较难判断的。使用Self-Attention可以让机器把“it”和“animal”联系起来，如图15.7所示。 \\n 图15.7 Self-Attention 下面我们来看一下Self-Attention的具体计算： 第一步——在Self-Attention的计算中会引入3个新的向量，分别是Query，Key，Value。这3个向量是Self-Attention的输入向量x分别乘以3个不同的权值矩阵WQ,WK,WV而得到的。权值矩阵是随机初始化的，维度是（64，512），其中512需要与\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 548}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 549 Self-Attention输入向量维度一致，其实64和512都是人为设置的，理论上都可以修改。Query，Key，Value的计算如图15.8所示。 \\n 图15.8 Self-Attention计算1 第二步——计算Self-Attention的分数值，每个词都会与句子中的所有词计算一个分数值，这个分数值表示该词与句子中所有词之间的关注度。计算方法是该词的Query与每个词的Key做点乘，比如针对例子中“deep”这个词，计算出该词与句子中所有词的分数，假设计算q1·k1得到112，假设计算q1·k2得到96，如图15.9所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 549}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 550 图15.9 Self-Attention计算2 第三步——把前面计算的Score除以g𝑑\\x83，这里的𝑑\\x83为Query，Key，Value的权值矩阵的行数，论文中为64。g𝑑\\x83就是8，Score除以8主要是为了模型训练时得到比较稳定的梯度，理论上取其他值也可以。然后再进行softmax计算，得到当前的词与其他所有词的相关性大小，如图15.10所示。 \\n 图15.10 Self-Attention计算3 第四步——把Value的值与Softmax的结果进行相乘，然后再相加，比如z1=v1×0.88+v2×0.12，如图15.11所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 550}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 551 \\n 图15.11 Self-Attention计算4 每个词都可以计算出一个z值，z值相当于是每个词的Self-Attention特征。以上就是Self-Attention层的主要计算内容了。  在实际应用的时候，一般都是以矩阵的形式来进行计算的，输入Self-Attention层的数据也是一个矩阵，如图15.12所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 551}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 552 \\n 图15.12 矩阵形式的Self-Attention计算1 图中的X中的行数表示输入词汇数量，2行表示2个词；X中的列数表示词向量长度，实际应用中为512。W中的行数为词向量长度，实际应用中为512；W中的列数实际应用中为64。接下来再进行如前面描述的Self-Attention计算，如图15.13所示。 \\n 图15.13 矩阵形式的Self-Attention计算2 15.1.3 Multi-Head Attention介绍  作者为了增强Self-Attention的表达效果，使用了“Multi-Head Attention”，中文就是“多头注意力机制”，虽然名字有点奇怪，但是作用很大。这个“多头注意力机制”理解\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 552}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 553 起来很容易，上一小节我们介绍了Self-Attention的计算流程，我们所介绍的Self-Attention计算就是一个头（Head）。那我们初始化多个Query，Key，Value权值矩阵，进行多次独立地计算，就是“多头注意力机制”了。“多头注意力机制”的主要作用是给模型引入更多的训练参数，可以使得不同的“头”起到不同的Self-Attention的表达效果。我觉得有点像在图像识别中，卷积网络使用多个滤波器，提取图像不同的特征。“Multi-Head Attention”计算如图15.14所示。 \\n 图15.14 Multi-Head Attention计算1  论文中作者用了8个Attention Head，那么每个词就可以计算得到8组Z值了，从𝑍<−𝑍ì，如图15.15所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 553}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 554 \\n 图15.15 Multi-Head Attention计算2  得到8组Z值以后进行拼接（concatenate），然后还需要再乘以一个权值矩阵𝑊ü，得到Self-Attention层的最终输出Z，如图15.16所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 554}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 555 \\n 图15.16 Multi-Head Attention计算3 注意Self-Attention层的最终输出的行数等于句子的词汇数，比如“Thinking Machines”就2个词所以Z只有2行，Z的列数等于最开始时的词向量长度512。 总结一下，“Multi-Head Attention”的整个流程如图15.17所示。 \\n 图15.17 Multi-Head Attention计算全流程 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 555}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 556  使用了Multi-Head Attention”以后，我们可以看到不同的两个Attention Head会关注句子中不同的部位，如图15.18所示。 \\n 图15.18 两个Attention Head关注点不同  对于“it”这个词，一个头主要关注“tired”这个词，另一个头主要关注“The animal”。如果是8个头的话可能会得到下面结果，如图15.19所示。 \\n 图15.19 8个Attention Head \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 556}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 557 15.1.4 Layer Normalization介绍  在Transformer中，每一个子层（Self-Attention，Feed forward）之后都会加上残差模块和Layer Normmalization[3]，如图15.20所示。 \\n 图15.20 残差结构和Layer Normmalization  残差结构应该不需要多说了，跟ResNet中差不多，这里的残差结构是一个恒等映射。如图X+Z的结果会进行Layer Normmalization。Layer Normmalization看名字就知道跟Batch Normmalization应该是差不多的。Batch Normalization是计算一个批次中，每个特征维度的平均值和标准差，然后再对每个特征维度进行标准化计算，如图15.21所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 557}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 558 \\n 图15.21 Batch Normalization  Layer Normmalization是计算一个数据中，所有特征维度的平均值和标准差，然后再对这个数据进行标准化计算，如图15.22所示。 \\n 图15.22 Layer Normmalization Batch Normalization和Layer Normmalization都可以起到数据标准化的效果，不同的场景下可能会得到不同的效果。在Transformer的模型中使用Layer Normmalization效果会更好。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 558}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 559 15.1.5 Decoder结构介绍  Transformer叠加了6个相同结构的Encoder，Encoder最后的输出结果会传给所有Decoder中的Encoder-Decoder Attention层进行计算，如图15.23所示。 \\n 图15.23 Encoder-Decoder  我们也可以看一下《Attention is all you need》论文中的结构图，不过论文中的结构只画出来一个Encoder和一个Decoder（实际上Encoder和Decoder都各有6个），如图15.24所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 559}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 560 \\n 图15.24 Transformer结构[2]  图中Inputs表示输入；Output表示输出；Positional Encoding表示位置信息；Output Probabilities表示输出概率；Linear表示全连接层。 我们可以看到在Decoder中有两个Multi-Head Attention，这两个Multi-Head Attention跟Encoder中的Multi-Head Attention差不多，具体一些细节上的不同后面详细说明。 Decoder阶段的最后Softmax层计算下一个输出单词的概率。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 560}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 561 15.1.6 Decoder中的Multi-Head Attention和模型训练  下面我们来仔细分析一下Decoder中的Multi-Head Attention，先说一下第一个Multi-Head Attention。第一个Multi-Head Attention采用了Mask操作，因为在翻译的时候，我们是先翻译第一个词，然后翻译第二个词，再翻译第三个词。在Decoder的时候，需要根据之前的翻译结果来预测当前的最佳输出。  这里的Mask指的是在模型训练时遮挡住一部分的信息，当前预测结果可以回顾之前的标签信息，但是不能“偷看”之后的标签信息。比如我们有一对训练数据，中文是“我有一只猫”，英文是“I have a cat”。“我有一只猫”的数据会传给Encoder，“<start> I have a cat”会传给Decoder。Decoder的输出标签为“I have a cat <end>”，如图15.25： \\n 图15.25 Decoder预测  Mask的作用就是我们在预测“have”的时候，我们可以借鉴”<start>”和“I”的信息，但是不能偷看“have”，“a”和“cat”的信息。我们在预测“a”的时候，可以借鉴“<start>”，“I”和“have”的信息，但是不能偷看“a”和“cat”的信息。具体的做法\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 561}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 562 是，假设这里的英文句子有5个单词，我们会得到一个5×5的Mask矩阵，被Mask的部分值为负无穷-inf，没有Mask的部分值为1，如图15.26所示。 \\n 图15.26 Mask矩阵  Self-Attention中Query和Key的计算跟Encoder中的一致，使用矩阵的方式计算，如图15.27所示。 \\n 图15.27 Decoder-Self-Attention计算1  得到𝑄𝐾~之后需要进行softmax计算得到Attention Score，在进行softmax计算之前需要先使用Mask矩阵遮挡住每一个单词之后的信息，如图15.28所示。 \\n 图15.28 Decoder-Self-Attention计算2 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 562}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 563  得到𝑀𝑎𝑠𝑘\\t𝑄𝐾~以后再对𝑀𝑎𝑠𝑘\\t𝑄𝐾~每一行进行softmax计算，计算后每一行的和都为1。之后再与Value矩阵相乘，得到Z，如图15.29所示。 \\n 图15.29 Decoder-Self-Attention计算3  矩阵Z中第1行只包含单词1的信息，第2行包含单词1和单词2的信息，以此类推，第5行包含所有单词信息。  后面的计算跟Encoder中的Multi-Head Attention类似，Multi-Head Attention得到多个Z矩阵，然后再乘以一个权值矩阵𝑊ü得到Mask Self-Attention的输出。  Decoder中的第二个Multi-Head Attention层（也就是Encoder-Decoder Attention层）中，会使用Encoder的最终输出C作为Multi-Head Attention的输入来计算Key和Value矩阵，而Query矩阵则是使用上一个Multi-Head Attention的输出进行计算。每个Decoder的Encoder-Decoder Attention层都使用Encoder的输出信息C来计算Key和Value矩阵，有助于Decoder将注意力集中在输入序列中的适当位置。  经过6个叠加的Decoder计算得到最终输出的Z矩阵，因为使用了Mask，所以Z矩阵的第1行只包含单词1的信息，第2行包含单词1和单词2的信息，以此类推。模型最后softmax输出的矩阵每一行会预测一个单词，如图15.30所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 563}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 564 \\n 图15.30 softmax输出  因为在训练阶段Decoder输入序列的长度是等于标签序列长度的，比如：输入序列为“<start> I have a cat”一共5个词，标签序列为“I have a cat <end>”也是5个词。所以Transformer的训练可以并行计算，在训练阶段Encoder的一次前向计算就可以获得Encoder信息C，Decoder的一次前向计算就可以获得序列的预测结果，把预测结果跟标签进行对比，计算loss，使用反向传播算法就可以更新模型参数了。  在模型预测阶段，label是未知的，Decoder就无法进行并行计算了，只能像普通的Seq2Seq模型一样，1次计算得到1个预测结果。然后再运行一遍Decoder计算，把第1次得到的结果传入，得到第2个预测结果；再运行一遍Decoder，传入第1次和第2次的结果，得到第3个预测，一直循环，直到出现结束符。  15.2 BERT模型  Transformer模型是NLP发展历程新的起点，而真正做到大放异彩，取得重大突破的是BERT模型。2018年底谷歌新论文《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》[4]在11种不同的NLP测试中获得最佳成绩，并且在机器阅读理解顶级水平测试SQuAD1.1[5]中超过人类水平。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 564}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 565  我们先说一下它的名字，BERT的全称为Bidirectional Encoder Representations from Transformers，我怀疑这个名字的全称是BERT作者强行拼凑的。大家有没有看过一个1969年美国的喜剧动画芝麻街（Sesame Street），如图15.31所示。 \\n 15.31 芝麻街（Sesame Street）  我也没看过。在2018年初AllenNLP发布了一个新模型ELMo，ELMo是一种比word2vec更好的训练词向量的模型，在BERT发布之前也小火了一把。由于ELMo跟Transformer模型没什么关系，这里我们就不详细介绍了。这里我想说的是ELMo是芝麻街这个动画片的人物，图中最左边的。BERT也是芝麻街的人物，图中从左往右数第三个。所以BERT名字的真正来源，应该是来自于芝麻街。 15.2.1 BERT模型介绍 BERT模型在结构上几乎没有创新，因为BERT模型的结构就是Transformer的Encoder结构，只是具体参数上有些小改动。BERT真正创新的地方在于模型的训练方法，具体如何训练后面会详细介绍。 BERT论文中训练了两种BERT模型，分别是BERT$%&'（L=12，H=768，A=12，总共参数=110M）和BERT(%)*'（L=24，H=1024，A=16，总共参数=340M）。其中的L表示模型层数，L=12表示有12个Encoder层；H表示词向量长度，H=768表示词向量长度为\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 565}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 566 768；A表示Multi-Head Attention中有多少个Head，A=12，表示有12个Head。一般情况下BERT(%)*'模型效果会比BERT$%&'更好一些，BERT结构如图15.32所示。 \\n 图15.32 两种BERT模型 这些超参数其实都是可以人为设置的，论文作者选用了这两组参数来进行建模，其实也可以使用其他参数。 接下来说一下BERT的输入信号，BERT输入信号跟Transformer有一点不同。Transformer输入信号的组成为分词向量（Token Embeddings）和位置向量（Position Embeddings）；BERT输入信号的组成为分词向量（Token Embeddings），段落向量（Segment Embeddings）和位置向量（Position Embeddings）。 关于分词元素（Token），之前的内容一直都没有特别详细的说明这个问题，这里刚好可以说明一下。token就是分词后的结果，这里的“词”不一定是一个词汇，也有可能是一个字符或其他自定义元素。我们最开始使用的分词方式是，比如英文中使用空格作为分词符，中文中需要一些分词算法，把句子分为一个一个的词汇（word）。在后来的一些研究中发现字符级别（character）的分词方法也能得到同样的效果，有时候效果甚至会更好。比如把“hello world”，分为“h”，“e”，“l”，“l”，“o”，“w”，“o”，“r”，\\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 566}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 567 “l”，“d”，把“我有一只猫”分为“我”，“有”，“一”，“只”，“猫”。而在BERT中使用的是WordPiece[6]，WordPiece技术之前我们有介绍过，就是把一些词拆成一片一片，比如“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，“saving”，“saved”，“saves”都是保存的意思，使用WordPiece拆分后会得到“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很多。所以BERT中的token指的是使用WordPiece技术分词后得到的分词元素。BERT输入信号如图15.33所示。 \\n 图15.33 BERT输入信号[4] Token Embeddings就是每个token对应的向量，BERT$%&'中向量长度为768，BERT(%)*'中向量长度为1024。 Segment Embeddings举例说明比较容易理解，BERT可以传入一个句子或者两个句子，假设传入一个句子，句子可以分为5个token，那么Segment Embeddings就是[0，0，0，0，0]；假设传入两个句子，第一个句子可以分为4个token，第二个句子可以分为5个token，那么Segment Embeddings就是[0，0，0，0，1，1，1，1，1]。所以Segment Embeddings就是标注哪几个token是第一个句子，哪几个token是第二个句子。 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 567}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 568 Position Embeddings的作用跟Transformer模型一样，表示每个token的位置信息。不过在BERT模型中的Position Embeddings使用的是可以训练的参数，不是预先设定好的值。 15.2.2 BERT模型训练  BERT模型的最大创新在于模型训练。作者使用了两个任务来训练，一个任务是掩码语言模型（Masked Language Model），简称MLM，简单的说就是完形填空；另一个任务是预测下一个句子（Next Sentence Prediction），简称NSP，就是字面意思预测下一个句子。  我们先来说一下MLM，也就是完形填空。模型训练时会随机mask一个句子中15%的token（使用“[MASK]”符号替代掉原来的字符），然后将“[MASK]”位置的输出信号传给softmax层预测被遮挡的token具体是什么。不过这么做可能会有一个问题，就是所有的token中有15%被遮挡住了，有可能导致某些token模型从来没见过。所以作者还做了如下细节处理，比如有一个句子“my dog is hairy”，我们要遮挡的词是“hairy”， 那么： l 有80%的概率正常使用 “[MASK]”， “my dog is hairy” 会变成my dog is [MASK]”。 l 有10%的概率随机取一个词来替代mask的词， “my dog is hairy”可能会变成my dog is apple”。 l 有10%的概率句子保持不变， “my dog is hairy”可能还是“my dog is hairy”。 随机替换发生的概率只有15%×10%=1.5%，所以基本不会影响模型的语言理解能力。 MLM训练如图15.34所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 568}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 569 \\n 图15.34 MLM训练 下面我们再来说一下NSP，也就是预测下一个句子。其实很简单，就是模型训练时会传入两个句子，模型要做的就是判断这两个句子是不是连续的两个句子。比如输入“[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] “，中文是“男人去商店买牛奶”，所以Label=IsNext，这是两个连续的句子。这里的“[CLS]”字符是表示用于预测结果的字符，“[CLS]”位置的输出信号会传给softmax判断这两个句子是不是连续的。“[MASK]”字符前面介绍过了，用作随机遮挡一部分token。“[SEP]”字符用于表示句子结束，我们可以看到前面的句子中有两个“[SEP]”，第一个“[SEP]”表示第一个句子的结束，第二个“[SEP]”表示第二个句子的结束。这些特殊字符的Token Embeddings跟其他的Token Embeddings一样都会跟着模型参数一起训练。假设有个句子是“[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flightless birds [SEP]“，中文是”男人去商店，企鹅是不会飞的鸟“，所以Label=NotNext，显然第二句话并不是第一句话的下一句。NSP训练如图15.35所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 569}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 570 \\n 图15.35 NSP训练  BERT模型使用了大量没有人工标注，但是又自带标签的数据来进行训练（MLM和NSP都可以看成语料本身就已经自带标签）。BERT论文中使用的训练数据集为BooksCorpus[7]（800M words）和英文的Wikipedia（2500M words），总共33亿个词。谷歌使用64块TPU训练BERT(%)*'花了4天时间，租用这些TPU训练一次模型的价格大约是30万人民币，所以一般情况下我们就不要想复现模型了，直接使用谷歌发布的预训练模型就可以。 15.2.3 BERT模型应用  使用上一小节介绍的方式把BERT模型训练好之后，就可以使用BERT来完成各种NLP任务了，BERT论文中测试的NLP任务大部分都是GLUE(General Language Understanding Evaluation)中的任务，GLUE是一个自然语言任务集合。除了GLUE以外，作者也测试了其他一些任务，BERT论文中涉及的11个NLP任务如图15.36所示 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 570}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 571 \\n 图15.36 BERT测试的NLP任务  BERT作者把这11个应用分为了(a)，(b)，(c)，(d)四个大类，下面我们逐一来介绍，第一个类别是Sentence Pair Classification Tasks，两个句子的分类任务，如图15.37所示。 \\n 图15.37 Sentence Pair Classification Tasks[4]  图中的Class Label表示类别；Sentence Pair Classification Tasks表示句子对分类任务。 名称全名用途(a)MNLImulti-genre natural language inference多类型文本蕴含关系识别判断两个句子是蕴含关系、矛盾关系还是中立关系，3分类(a)QQPquora question pairs文本匹配判断两个问题是不是等价，2分类(a)QNLIquestion natural language inference自然语言问题推理判断两个句子（前面句子是一个问题），后一个句子是否包含前一个句子的答案，2分类(a)STS-Bthe semantic textual similarity benchmark语义文本相似度数据集判断两个句子相似性，有5个等级，5分类(a)MRPCmicrosoft research paraphrase corpus微软研究院释义语料库判断两个文本对语音信息是否等价，2分类(a)RTErecognizing textual entailment识别文本蕴含关系类似于MNLI，只不过是2分类(a)SWAGthe situations with adversarial generations dataset情景对抗生成数据集从四个句子中选择可能是前一句下文的那个，4分类(b)SST-2the stanford sentiment treebank斯坦福情感分类任务电影评论的情感分类，2分类(b)CoLAthe corpus of linguistic acceptability语言可接受性语料库判断一个句子语法是否正确，2分类(c)SQuAD v1.1the standFord question answering dataset斯坦福问答数据集传入两个句子，前一个句子是问题，后一个句子是文本段落。判断问题的答案在文本段落的哪个部分。(d)CoNLL-2003 the conference on natural language learning自然语言学习会议NER命名实体识别，判断一个句子中的单词是不是人名，机构名，地名，以及其他所有以名称为标识的实体\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 571}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 572 也就是传入两个句子，得到分类结果。对应的任务有MNLI，QQP，QNLI，STS-B，MRPC，RTE，SWAG。我们随便举个例子，比如QQP，就是传入两个句子（这两个句子是两个问题），判断这两个问题是不是等价，属于二分类问题。[CLS]对应的输出加上一个用于分类的全连接层，然后Finetune整个模型包括最后的全连接层就可以进行训练了。  第二个类别是Single Sentence Classification，一个句子的分类任务，如图15.38所示。 \\n 图15.38 Single Sentence Classification[4]  图中的Class Label表示类别；Single Sentence Classification Tasks表示单个句子分类任务。 比如情感分类，传入一个句子，判断这个句子是正面情感还是负面情感，属于二分类问题。训练跟第一类差不多，[CLS]对应的输出加上一个用于分类的全连接层，然后Finetune整个模型包括最后的全连接层就可以进行训练了。  第三个类别是Question Answering Tasks，问答任务，如图15.39所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 572}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 573 \\n 图15.39 Question Answering Tasks[4]  图中的Start表示句子的起始；End表示句子的结束；Span表示句子的跨度；Question表示问题；Paragraph表示答案所在段落；Question Answering Tasks表示问答任务。 问答任务，传入两个句子，第一个句子是问题，第二个句子是一段文本，问题的答案在第二个句子中，模型要预测的是答案的位置。有一个权值向量S和一个权值向量E用于预测答案的起始位置和结束位置，每个Paragraph中的token对应的输出为T\"R−T+R，假设标签中i表示答案的起始，j表示答案的结束，j≥i。训练阶段最大化i作为起始位置的概率𝑃(=¤-∙.º∑¤-∙.»»和j作为结束位置的概率𝑃\\x81=¤/∙.»∑¤-∙.»»。然后Finetune整个模型包括S和E就可以进行训练了。预测阶段计算从m到n的区间分数：𝑆∙𝑇\\x82+𝐸∙𝑇@(𝑛≥𝑚)，计算得到最大的区间分数并且n≥m就是预测的答案区间。 第四个类别是Single Sentence Tagging，一个句子的标注任务，如图15.40所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 573}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 574 \\n 图15.40 Single Sentence Tagging[4]  图中Single Sentence表示单个句子；Single Sentence Tagging Tasks表示单个句子的标记任务。 标注任务，比如我们之前说过的分词标注或者是图中的命名实体识别NER（Named Entity Recognition）。命名实体识别就是判断一个句子中的单词是不是人名，机构名，地名，以及其他所有以名称为标识的实体。模型训练就是传入一个句子，句子的每个token的输出都会经过一个全连接层预测是不是命名实体或者命名实体的类型。然后Finetune整个模型包括最后的全连接层就可以进行训练了。 很显然BERT的应用范围不止于此，并且BERT也只是一个新的开端。在BERT模型发布以后，很多类似BERT的模型不断被推出，不断刷新着NLP任务的新纪录，NLP领域也因此迎来了新一轮的快速发展。  15.3参考文献 [1] Alammar, Jay (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 574}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 575 [2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008. [3] Ba J L, Kiros J R, Hinton G E. Layer Normalization[J]. arXiv preprint arXiv:1607.06450, 2016. [4] Devlin J, Chang M W, Lee K, et al. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding J]. arXiv preprint arXiv:1810.04805, 2018. [5] Rajpurkar P, Zhang J, Lopyrev K, et al. Squad: 100,000+ questions for  Machine Comprehension of Text[J]. arXiv preprint arXiv:1606.05250, 2016. [6] Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system: Bridging the gap between human and machine translation[J]. arXiv preprint arXiv:1609.08144, 2016. [7] Zhu Y, Kiros R, Zemel R, et al. Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books[C]//Proceedings of the IEEE international conference on computer vision. 2015: 19-27.         \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 575}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 576     第16章- NLP任务项目实战 这个章节的内容为14，15章节NLP内容的项目实战部分。在前两个章节中我们介绍了多种NLP的技术，涉及的内容比较多，所以本章会选取部分内容完成相关项目的代码实战。相关理论介绍主要参考14，15章的内容，这个章节就不做过多介绍了。  16.1 一维卷积英语电影评论情感分类项目 16.1.1 项目数据和模型说明  在14章的内容中我们有介绍过卷积在文本分类中的使用，当时介绍的是二维卷积在文本分类中的应用。本章的第一个程序我们先来一个开胃菜，先做一个简单一点的程序，使用一维卷积对英语文本进行情感分类，二维卷积的程序我们留在后面再做。这里说的简单，并不是二维卷积比一维卷积难，其实二维卷积和一维卷积在文本分类中的使用几乎没什么区别。这里说的简单指的是数据处理上的简单，我们要使用的数据集是IMDB电影评论数据集，数据分为正面评论和负面评论。这个数据集直接从Tensorflow中获得： from tensorflow.keras.datasets import imdb  我们不需要进行任何数据处理就可以直接载入数据，数据的训练集有25000条评论数据，正面评论12500条，负面评论12500条。测试集数据也是25000条数据，正负样本各', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 576}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 577 占50%。并且句子已经做好了分词，而且还把每个词都变成了编号（词出现的频率越高，编号越小）。例如，测试集第0行的数据如图16.1所示。  图16.1 具体数据展示  下面我们再说一下一维卷积在文本分类中的应用，如图16.2所示。 \\n 图16.2 一维卷积在文本分类中的应用[1] 我们可以用一个简单的方式来理解一维卷积和二维卷积的区别，二维卷积它的kernel_size也是两维的，并且可以沿两个方向进行移动（比如水平方向和竖直方向），二维卷积计算时要求输入数据必须是4维的（数据数量，图片高度，图片宽度，通道数channels）；一维卷积它的kernel_size是一维的，并且只能沿一个方向进行移动，一维卷积计算时要求输入数据必须时3维的（数据数量，序列长度，通道数channels）。在文本分类中，使用一维卷积和二维卷积都可以。 如果是使用一维卷积相当于是对一个序列进行特征提取，如上图中假设我们使用一维卷积，词汇数相当于是序列长度，每个词的词向量长度相当于是通道数channels。我们把kernel_size设置为3，也就是每次卷积会对图中3行数据进行卷积计算（图中的列数其实就\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 577}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 578 是通道数channels），步长一般设置为1就可以，每次走一步。卷积计算后得到特征图，接下来再进行max-pooling计算，最后再进行全连接得到分类结果。 16.1.2 一维卷积英语电影评论情感分类程序 实现一维卷积英语电影评论情感分类的代码如代码16-1所示。 代码16-1：一维卷积英语电影评论情感分类（片段1） from tensorflow.keras.preprocessing import sequence from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout from tensorflow.keras.layers import Embedding from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D from tensorflow.keras.datasets import imdb from plot_model import plot_model # 最大词汇数量 max_words = 10000 # 最长句子设置为400 # 这里句子长度值的是句子词汇数量，句子有100个词则长度为100 maxlen = 400 # 批次大小 batch_size = 32 # 词向量长度 embedding_dims = 128 # 训练周期 epochs = 3 # 滤波器数量 filters = 64 # 卷积核大小 kernel_size = 3 # 载入imdb评论数据集，设置最大词汇数，只保留出现频率最高的前max_words个词 # 出现频率越高，编号越小。词的编号从4开始，也就是频率最大的词编号为4。 # 编号0表示padding，1表示句子的开始(每个句子第一个编号都是1)，2表示OOV，3表示预留(所有的数据中都没有3) # Out-of-vocabulary,简称OOV,表示不在字典中的词 # 数据的标签为0和1。0表示负面情感，1表示正面情感。 (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words) # 查看测试集第0个句子 print(x_test[0]) 结果输出为： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 578}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 579 [1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]  代码16-1：一维卷积英语电影评论情感分类（片段2） # 获得imdb数据集的字典，字典的键是英语词汇，值是编号 # 注意这个字典的编词汇编号跟数据集中的词汇编号是不对应的 # 数据集中的编号减三才能得到这个字典的编号，举个例子： # 比如在x_train中'a'的编号为6，在word2id中'a'的编号为3 word2id = imdb.get_word_index()  # 把字典的键值对反过来：键是编号，值是英语词汇 # 编号数值范围：0-88587 # value+3把字典中词汇的编号跟x_train和x_test数据中的编号对应起来 id2word = dict([(value+3, key) for (key, value) in word2id.items()]) # 设置预留字符 id2word[3] = '[RESERVE]' # 设置Out-of-vocabulary字符 id2word[2] = '[OOV]' # 设置起始字符 id2word[1] = '[START]' # 设置填充字符 id2word[0] = '[PAD]'  # 在词典中查询得到原始英语句子，如果编号不在字典用则用'?'替代 decoded_review = ' '.join([id2word.get(i, '?') for i in x_test[0]]) print(decoded_review) 结果输出为： [START] please give this one a miss br br [OOV] [OOV] and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite [OOV] so all you madison fans give this a miss  代码16-1：一维卷积英语电影评论情感分类（片段3） # 序列填充，因为模型结构是固定的而句子的长度是不固定的，所以我们需要把句子变成相同的长度 # 如果句子长度不足maxlen，则把句子填充到maxlen的长度，如果句子长度超过maxlen，则取句子前maxlen个词 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 579}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 580 x_train = sequence.pad_sequences(x_train, maxlen=maxlen) x_test = sequence.pad_sequences(x_test, maxlen=maxlen) # 填充后所有句子都变成了400的长度 print('x_train shape:', x_train.shape) print('x_test shape:', x_test.shape) print(x_test[0]) 结果输出为： x_train shape: (25000, 400) x_test shape: (25000, 400) [   0    0    0    0    0    0    0    0    0    0    0    0    0     ……    0    0    0    0    0    0    0    0    0    0    1  591  202   14    31    6  717   10   10    2    2    5    4  360    7    4  177 5760   394  354    4  123    9 1035 1035 1035   10   10   13   92  124   89   488 7944  100   28 1668   14   31   23   27 7479   29  220  468    8   124   14  286  170    8  157   46    5   27  239   16  179    2   38.   32   25 7944  451  202   14    6  717]  代码16-1：一维卷积英语电影评论情感分类（片段4） # 构建模型 model = Sequential() # Embedding是一个权值矩阵，包含所有词汇的词向量，Embedding的行数等于词汇数，列数等于词向量长度 # Embedding的作用是获得每个词对应的词向量，这里的词向量是没有经过预训练的随机值，会跟随模型一起训练 # max_words词汇数，embedding_dims词向量长度 # 模型训练时数据输入为(batch, maxlen) model.add(Embedding(max_words,                     embedding_dims))  # 设置一个一维卷积 model.add(Conv1D(filters,                  kernel_size,                  strides=1,                  padding='same',                  activation='relu'))  # 卷积计算后得到的数据为(batch, maxlen, filters) # GlobalMaxPooling1D-全局最大池化计算每一张特征图的最大值 # 池化后得到(batch, filters) model.add(GlobalMaxPooling1D()) # 加上Dropout model.add(Dropout(0.5)) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 580}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 581 # 最后2分类，设置2个神经元 model.add(Dense(2,activation='softmax')) # 画图 plot_model(model) 结果输出为： \\n  代码16-1：一维卷积英语电影评论情感分类（片段5） # sparse_categorical_crossentropy和categorical_crossentropy都是交叉熵代价函数 # categorical_crossentropy需要把标签变成独热编码one-hot # sparse_categorical_crossentropy不需要把标签变成独热编码one-hot(不是真的不需要，而且程序中会自动帮你做转换) # 所以这个程序中的标签没有转独热编码one-hot model.compile(loss='sparse_categorical_crossentropy',               optimizer='adam',               metrics=['accuracy'])  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 581}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 582 # 训练模型 model.fit(x_train, y_train,           batch_size=batch_size,           epochs=epochs,           validation_data=(x_test, y_test)) 结果输出为： Train on 25000 samples, validate on 25000 samples Epoch 1/3 25000/25000 [==============================] - 31s 1ms/sample - loss: 0.4680 - accuracy: 0.7660 - val_loss: 0.3246 - val_accuracy: 0.8635 Epoch 2/3 25000/25000 [==============================] - 31s 1ms/sample - loss: 0.2997 - accuracy: 0.8777 - val_loss: 0.2927 - val_accuracy: 0.8766 Epoch 3/3 25000/25000 [==============================] - 31s 1ms/sample - loss: 0.2161 - accuracy: 0.9168 - val_loss: 0.2991 - val_accuracy: 0.8772  16.2 二维卷积中文微博情感分类项目  上一小节我们使用一维卷积完成了英语情感分类项目，不过大家应该更关心中文的情感分类要怎么做。这一小节我们将从头到尾完整地完成一个中文微博情感分类项目。这里我使用的数据集是从新浪微博收集的12万条数据，正负样本各一半。标签中1表示正面评论，0表示负面评论。数据来源为https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb。如果大家有其他数据的话，也可以使用其他数据。  这一次我们使用的数据需要自己做处理，所以我们需要对句子进行分词，分词后再对每个词根据频率来进行编号。这里我们要使用的分词工具是结巴分词，结巴分词是一个很好用的中文分词工具，安装方式为打开命令提示符，然后输入命令： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 582}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 583  pip install jieba  安装好以后在python程序中直接import jieba就可以使用了。 实现二维卷积中文微博情感分类的代码如代码16-2所示。 代码16-2：二维卷积中文微博情感分类（片段1） # 安装结巴分词 # pip install jieba import jieba  import pandas as pd  import numpy as np  from tensorflow.keras.layers import Dense, Input, Dropout from tensorflow.keras.layers import Conv2D, GlobalMaxPool2D, Embedding, concatenate from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Model,load_model from tensorflow.keras.backend import expand_dims from tensorflow.keras.layers import Lambda import tensorflow.keras.backend as K from sklearn.model_selection import train_test_split import json # 批次大小 batch_size = 128 # 训练周期 epochs = 3 # 词向量长度 embedding_dims = 128 # 滤波器数量 filters = 32 # 这个数据前半部分都是正样本，后半部分都是负样本 data = pd.read_csv('weibo_senti_100k.csv') # 查看数据前5行 data.head() 结果输出为： \\n \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 583}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 584  代码16-2：二维卷积中文微博情感分类（片段2） # 计算正样本数量 poslen = sum(data['label']==1) # 计算负样本数量 neglen = sum(data['label']==0) print('正样本数量：', poslen) print('负样本数量：', neglen) 结果输出为： 正样本数量： 59993 负样本数量： 59995  代码16-2：二维卷积中文微博情感分类（片段3） # 测试一下结巴分词的使用 print(list(jieba.cut('做父母一定要有刘墉这样的心态，不断地学习，不断地进步'))) 结果输出为： ['做', '父母', '一定', '要', '有', '刘墉', '这样', '的', '心态', '，', '不断', '地', '学习', '，', '不断', '地', '进步']  代码16-2：二维卷积中文微博情感分类（片段4） #定义分词函数，对传入的x进行分词 cw = lambda x: list(jieba.cut(x)) # apply传入一个函数，把cw函数应用到data['review']的每一行 # 把分词后的结果保存到data['words']中 data['words'] = data['review'].apply(cw) # 再查看数据前5行 data.head() 结果输出为：   代码16-2：二维卷积中文微博情感分类（片段5） # 计算一条数据最多有多少个词汇 max_length = max([len(x) for x in data['words']]) \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 584}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 585 # 打印看到结果为202，最长的句子词汇数不算太多 # 后面就以202作为标准，把所有句子的长度都填充到202的长度 # 比如最长的句子为2000，那么说明有些句子太长了，我们可以设置一个小一点的值作为所有句子的标准长度 # 比如设置1000，那么超过1000的句子只取前面1000个词，不足1000的句子填充到1000的长度 print(max_length) 结果输出为： 202  代码16-2：二维卷积中文微博情感分类（片段6） # 把data[\\'words\\']中所有的list都变成字符串格式 texts = [\\' \\'.join(x) for x in data[\\'words\\']] # 查看一条评论，现在数据变成了字符串格式，并且词与词之间用空格隔开 # 这是为了满足下面数据处理对格式的要求，下面要使用Tokenizer对数据进行处理 print(texts[4]) 结果输出为： \\'梦想 有 多 大 ， 舞台 就 有 多 大 ! [ 鼓掌 ]\\'  代码16-2：二维卷积中文微博情感分类（片段7） # 实例化Tokenizer，设置字典中最大词汇数为30000 # Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer(num_words=30000) # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts)  # 把词转换为编号，编号大于30000的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts)  # 把序列设定为max_length的长度，超过max_length的部分舍弃，不到max_length则补0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\')   # 获取字典 dict_text = tokenizer.word_index # 在字典中查询词对应编号 print(dict_text[\\'梦想\\']) 结果输出为： 581  代码16-2：二维卷积中文微博情感分类（片段8） # 把token_config保存到json文件中，模型预测阶段可以使用 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 585}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 586 file = open('token_config.json','w',encoding='utf-8') # 把tokenizer变成json数据 token_config = tokenizer.to_json() # 保存json数据 json.dump(token_config, file) print(X[4]) 结果输出为： [   0    0      0    0   ……   0    0    0    0    0    0   581   18   75   77    1    1946   20   18   75   77   19]  代码16-2：二维卷积中文微博情感分类（片段9） # 定义标签 # 01为正样本，10为负样本 positive_labels = [[0, 1] for _ in range(poslen)] negative_labels = [[1, 0] for _ in range(neglen)] # 合并标签 Y = np.array(positive_labels + negative_labels) # 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2) # 定义函数式模型 # 定义模型输入，shape-(batch, 202) sequence_input = Input(shape=(max_length,)) # Embedding层，30000表示30000个词，每个词对应的向量为128维 embedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims) # embedded_sequences的shape-(batch, 202, 128) embedded_sequences = embedding_layer(sequence_input) # embedded_sequences的shape变成了(batch, 202, 128, 1) embedded_sequences = K.expand_dims(embedded_sequences, axis=-1)  # 卷积核大小为3,列数必须等于词向量长度 cnn1 = Conv2D(filters=filters, kernel_size=(3,embedding_dims), activation='relu')(embedded_sequences) cnn1 = GlobalMaxPool2D()(cnn1)  # 卷积核大小为4,列数必须等于词向量长度 cnn2 = Conv2D(filters=filters, kernel_size=(4,embedding_dims), activation='relu')(embedded_sequences) cnn2 = GlobalMaxPool2D()(cnn2)  # 卷积核大小为5,列数必须等于词向量长度 cnn3 = Conv2D(filters=filters, kernel_size=(5,embedding_dims), activation='relu')(embedded_sequences) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 586}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 587 cnn3 = GlobalMaxPool2D()(cnn3)  # 合并 merge = concatenate([cnn1, cnn2, cnn3], axis=-1) # 全连接层 x = Dense(128, activation='relu')(merge) # Dropout层 x = Dropout(0.5)(x) # 输出层 preds = Dense(2, activation='softmax')(x) # 定义模型 model = Model(sequence_input, preds) plot_model(model) 结果输出为： \\n  \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 587}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 588 代码16-2：二维卷积中文微博情感分类（片段10） # 定义代价函数，优化器 model.compile(loss='categorical_crossentropy',               optimizer='adam',               metrics=['acc'])  # 训练模型 model.fit(x_train, y_train,           batch_size=batch_size,           epochs=epochs,           validation_data=(x_test, y_test)) # 保存模型 model.save('cnn_model.h5') 结果输出为： Train on 95990 samples, validate on 23998 samples Epoch 1/3 95990/95990 [==============================] - 30s 318us/sample - loss: 0.0765 - acc: 0.9705 - val_loss: 0.0434 - val_acc: 0.9814 Epoch 2/3 95990/95990 [==============================] - 27s 282us/sample - loss: 0.0415 - acc: 0.9821 - val_loss: 0.0528 - val_acc: 0.9815 Epoch 3/3 95990/95990 [==============================] - 27s 282us/sample - loss: 0.0346 - acc: 0.9832 - val_loss: 0.0720 - val_acc: 0.9793  我们可以看到最后得到的准确率有点高，一般准确率太低我们需要分析原因，有时候准确非常高我们也需要想一想是为什么。我们来看一下原始数据，如图16.3所示。 \\n 图16.3 微博情感分类数据集 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 588}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 589  可以看到原始数据中有大量表情符号，如[爱你]，[哈哈]，[鼓掌]，[可爱]等，这些表情符号中对应的文字从较大程度上代表了这一句话的情感。所以我们做的这个项目之所以得到这么高的准确率，跟这里的表情符号是有很大关系。大家如果使用其他数据集来做情感分类，应该也会得到不错的结果，但是应该很难得到98%这么高的准确率。  模型训练好以后，我们再来看看如何使用训练好的模型进行预测，如代码16-3所示。 代码16-3：中文情感分类模型预测（片段1） from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.preprocessing.text import tokenizer_from_json import jieba import numpy as np # 载入tokenizer json_file = open(\\'token_config.json\\',\\'r\\',encoding=\\'utf-8\\') token_config = json.load(json_file) tokenizer = tokenizer_from_json(token_config) # 载入模型 model = load_model(\\'cnn_model.h5\\') # 情感预测 def predict(text):     # 对句子分词     cw = list(jieba.cut(text))      # list转字符串，元素之间用\\' \\'隔开     texts = \\' \\'.join(cw)     # 把词转换为编号，编号大于30000的词会被过滤掉     sequences = tokenizer.texts_to_sequences([texts])      # model.input_shape为(None, 202)，202为训练模型时的序列长度     # 把序列设定为202的长度，超过202的部分舍弃，不到202则补0     sequences = pad_sequences(sequences, maxlen=model.input_shape[1], padding=\\'pre\\')     # 模型预测     result = np.argmax(model.predict(sequences))     if(result==1):         print(\"正面情绪\")     else:         print(\"负面情绪\")  predict(\"今天阳光明媚，手痒想打球了。\") ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 589}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 590 结果输出为： 正面情绪  代码16-3：中文情感分类模型预测（片段2） predict(\"一大屋子人，结果清早告停水了，我崩溃到现在[抓狂]\") 结果输出为： 负面情绪  16.3 双向LSTM中文微博情感分类项目  上一小节我们讲解了CNN在中文微博情感分类项目中的应用，这一小节我们改用LSTM来完成，前期数据处理部分都是一样的流程，只有建模部分的程序不同。由于之前是第一次讲解完整流程所以加上了很多说明的步骤，下面这个程序把一些说明的步骤给去掉了，更加精简一些，如代码16-4所示。 代码16-4：双向LSTM中文微博情感分类（片段1） # 安装结巴分词 # pip install jieba import jieba  import pandas as pd  import numpy as np  from tensorflow.keras.layers import Dense,Input,Dropout,Embedding,LSTM,Bidirectional from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Model from sklearn.model_selection import train_test_split import json # pip install plot_model from plot_model import plot_model # 批次大小 batch_size = 128 # 训练周期 epochs = 3 # 词向量长度 embedding_dims = 128 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 590}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 591 # cell数量 lstm_cell = 64  ########step1-数据预处理######## # 这个数据前半部分都是正样本，后半部分都是负样本 data = pd.read_csv(\\'weibo_senti_100k.csv\\') # 计算正样本数量 poslen = sum(data[\\'label\\']==1) # 计算负样本数量 neglen = sum(data[\\'label\\']==0) #定义分词函数，对传入的x进行分词 cw = lambda x: list(jieba.cut(x)) # apply传入一个函数，把cw函数应用到data[\\'review\\']的每一行 # 把分词后的结果保存到data[\\'words\\']中 data[\\'words\\'] = data[\\'review\\'].apply(cw) # 计算一条数据最多有多少个词汇 max_length = max([len(x) for x in data[\\'words\\']]) # 把data[\\'words\\']中所有的list都变成字符串格式 texts = [\\' \\'.join(x) for x in data[\\'words\\']] # 实例化Tokenizer，设置字典中最大词汇数为30000 # Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer(num_words=30000) # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts)  # 把词转换为编号，编号大于30000的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts)  # 把序列设定为max_length的长度，超过max_length的部分舍弃，不到max_length则补0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'pre\\')  ########step2-保存tokenizer######## # 把token_config保存到json文件中，模型预测阶段可以使用 file = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\') # 把tokenizer变成json数据 token_config = tokenizer.to_json() # 保存json数据 json.dump(token_config, file)  ########step3-定义标签切分数据######## # 定义标签 # 01为正样本，10为负样本 positive_labels = [[0, 1] for _ in range(poslen)] negative_labels = [[1, 0] for _ in range(neglen)] ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 591}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 592 # 合并标签 Y = np.array(positive_labels + negative_labels) # 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)  ########step4-搭建模型######## # 定义函数式模型 # 定义模型输入，shape-(batch, 202) sequence_input = Input(shape=(max_length,)) # Embedding层，30000表示30000个词，每个词对应的向量为128维 embedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims) # embedded_sequences的shape-(batch, 202, 128) embedded_sequences = embedding_layer(sequence_input) # 双向LSTM x = Bidirectional(LSTM(lstm_cell))(embedded_sequences)  # 全连接层 x = Dense(128, activation='relu')(x) # Dropout层 x = Dropout(0.5)(x) # 输出层 preds = Dense(2, activation='softmax')(x) # 定义模型 model = Model(sequence_input, preds) # 画图 plot_model(model) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 592}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 593 \\n  代码16-4：双向LSTM中文微博情感分类（片段2） ########step5-模型训练和保存######## # 定义代价函数，优化器 model.compile(loss='categorical_crossentropy',               optimizer='adam',               metrics=['acc'])  # 训练模型 model.fit(x_train, y_train,           batch_size=batch_size,           epochs=epochs,           validation_data=(x_test, y_test))  # 保存模型 model.save('lstm_model.h5') 结果输出为： Train on 95990 samples, validate on 23998 samples Epoch 1/3 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 593}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 594 95990/95990 [==============================] - 39s 410us/sample - loss: 0.1177 - acc: 0.9642 - val_loss: 0.0710 - val_acc: 0.9821 Epoch 2/3 95990/95990 [==============================] - 36s 370us/sample - loss: 0.0602 - acc: 0.9816 - val_loss: 0.0532 - val_acc: 0.9814 Epoch 3/3 95990/95990 [==============================] - 35s 367us/sample - loss: 0.0440 - acc: 0.9818 - val_loss: 0.0519 - val_acc: 0.9820   双向LSTM模型最后得到的结果跟CNN差不多，都是98%左右的准确率。双向LSTM模型的预测程序跟16-3完全一样，把模型载入改成载入LSTM模型即可。  16.4 堆叠双向LSTM中文分词标注项目 16.4.1 中文分词标注模型训练  中文分词标注在之前的内容中我们有介绍过，常用的是4-tag(BMES)标注标签，B表示词的起始位置，M表示词的中间位置，E表示词的结束位置，S表示单字词。分词标注的数据需要对每一个字都进行标注。使用的是微软亚洲研究院开源的数据集（http://sighan.cs.uchicago.edu/bakeoff2005/），我会把数据跟书的代码放在一起给大家下载。实现堆叠双向LSTM中文分词标注的代码如代码16-5所示。 代码16-5：堆叠双向LSTM中文分词标注（片段1） import re import numpy as np import pandas as pd from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidirectional from tensorflow.keras.models import Model ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 594}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 595 from sklearn.model_selection import train_test_split # pip install plot_model from plot_model import plot_model import json # 批次大小 batch_size = 256 # 训练周期 epochs = 30 # 词向量长度 embedding_dims = 128 # cell数量 lstm_cell = 64 # 最长的句子设置为128，只保留长度小于128的句子，最好不要截断句子 # 大部分的句子都是小于128长度的 max_length=128 # 读入数据 # {b:begin, m:middle, e:end, s:single}，分别代表每个状态代表的是该字在词语中的位置， # b代表该字是词语中的起始字，m代表是词语中的中间字，e代表是词语中的结束字，s则代表是单字成词 text = open('msr_train.txt').read() # 根据换行符切分数据 text = text.split('\\\\n') # 得到所有的数据和标签 def get_data(s):     # 匹配(.)/(.)格式的数据     s = re.findall('(.)/(.)', s)     if s:         s = np.array(s)         # 返回数据和标签，0为数据，1为标签         return s[:,0],s[:,1]  # 数据 data = [] # 标签 label = [] # 循环每个句子 for s in text:     # 分离文字和标签     d = get_data(s)     if d:         # 0为数据         data.append(d[0])         # 1为标签         label.append(d[1]) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 595}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 596  # 存入DataFrame df = pd.DataFrame(index=range(len(data))) df[\\'data\\'] = data df[\\'label\\'] = label # 只保留长度小于max_length的句子 df = df[df[\\'data\\'].apply(len) <= max_length]  # 把data中所有的list都变成字符串格式 texts = [\\' \\'.join(x) for x in df[\\'data\\']] # 实例化Tokenizer，设置字典中最大词汇数为num_words # Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n tokenizer = Tokenizer() # 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小， tokenizer.fit_on_texts(texts)  # 把词转换为编号，编号大于num_words的词会被过滤掉 sequences = tokenizer.texts_to_sequences(texts)  # 把序列设定为max_length的长度，超过max_length的部分舍弃，不到max_length则补0 # padding=\\'pre\\'在句子前面进行填充，padding=\\'post\\'在句子后面进行填充 X = pad_sequences(sequences, maxlen=max_length, padding=\\'post\\')   # 把token_config保存到json文件中，模型预测阶段可以使用 file = open(\\'token_config.json\\',\\'w\\',encoding=\\'utf-8\\') # 把tokenizer变成json数据 token_config = tokenizer.to_json() # 保存json数据 json.dump(token_config, file) # 计算字典中词的数量，由于有填充的词，所有加1 # 中文的单字词数量一般比较少，这个数据集只有5000多个词 num_words = len(tokenizer.index_word)+1  # 相当于是把字符类型的标签变成了数字类型的标签 tag = {\\'o\\':0, \\'s\\':1, \\'b\\':2, \\'m\\':3, \\'e\\':4} Y = []  # 循环原来的标签 for label in df[\\'label\\']:     temp = []     # 把sbme转变成1234     temp = temp + [tag[l] for l in label]     temp = temp + [0]*(max_length-len(temp))     Y.append(temp) Y = np.array(Y) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 596}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 597  # 切分数据集 x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)  # 定义模型 sequence_input = Input(shape=(max_length)) # Embedding层， # mask_zero=True，计算时忽略0值，也就是填充的数据不参与计算 embedding_layer = Embedding(num_words, embedding_dims, mask_zero=True)(sequence_input) # 双向LSTM，因为我们的任务是分词标签，因此需要LSTM每个序列的Hidden State输出值 # return_sequences=True表示返回所有序列LSTM的输出，默认只返回最后一个序列LSTM的输出 x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(embedding_layer) # 堆叠多个双向LSTM x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x) x = Bidirectional(LSTM(lstm_cell, return_sequences=True))(x) # TimeDistributed该包装器可以把一个层应用到输入的每一个时间步上 # 也就是说LSTM每个序列输出的Hidden State都应该连接一个Dense层并预测出5个结果 # 这5个结果分别对应：sbmeo。o为填充值，对应标签0。 preds = TimeDistributed(Dense(5, activation='softmax'))(x) # 定义模型输入输出 model = Model(inputs=sequence_input, outputs=preds) # 画图 plot_model(model) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 597}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 598 \\n  代码16-5：堆叠双向LSTM中文分词标注（片段2） # 定义代价函数，优化器 # 使用sparse_categorical_crossentropy，标签不需要转变为独热编码one-hot model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # 训练模型 model.fit(x_train, y_train,           batch_size=batch_size,           epochs=epochs,           validation_data=(x_test, y_test)) # 保存模型 model.save('lstm_tag.h5') 结果输出为： Train on 68496 samples, validate on 17124 samples Epoch 1/30 68496/68496 [==============================] - 35s 514us/sample - loss: 0.2811 - accuracy: 0.6381 - val_loss: 0.1426 - val_accuracy: 0.8518 …… \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 598}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 599 Epoch 29/30 68496/68496 [==============================] - 22s 320us/sample - loss: 0.0122 - accuracy: 0.9892 - val_loss: 0.0604 - val_accuracy: 0.9578 Epoch 30/30 68496/68496 [==============================] - 22s 319us/sample - loss: 0.0114 - accuracy: 0.9900 - val_loss: 0.0629 - val_accuracy: 0.9563   最后训练得到的准确率在95%左右。  16.4.2 维特比算法（Viterbi Algorithm）  这一小节我们要介绍维特比算法（Viterbi Algorithm），因为中文分词标注模型预测阶段需要用到。维特比算法是应用最广泛的动态规划算法之一，主要应用在数字通信，语音识别，机器翻译，分词等领域。  就用分词来举例，我们在进行分词的时候，可能会有多种分词结果，把每一种分词结果看成是一条路径，如图16.4所示。 \\n 16.4 多种分词路径 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 599}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 600 图中的O表示填充标注，B代表该字是词语中的起始字，M代表是词语中的中间字，E代表是词语中的结束字，S则代表是单字成词。如果我们要遍历所有路径找到概率最大的路径（最优路径），计算量是非常大的。 维特比算法就是用来解决的最优路径问题的，我没有想到特别简洁又清晰的表达方式把维特比算法给描述清楚，所以我打算直接用一个实际例子来给大家讲解维特比算法的计算流程。这里我使用的是一个真实的分词例子，例子中所有的数值都是真实计算得到的数值。 首先我们先说一下状态转移矩阵，我们把osbme看成是5种状态，这5种状态之间的转移是有一定概率的。比如跟o相关的状态转移（o->s，e->o等）都是不存在的，因为正真分词的时候是不可能出现o这个标注的；再比如s->m，s->e，b->s，b->b，m->s，m->b，e->m，e->e这些状态也都是不可能存在的，这不符合我们的标注规则。这些不可能出现的状态转移我们可以把它们的值设置为-inf（负无穷）。那么存在的状态转移s->s，s->b，b->m，b->e，m->m，m->e，e->s，e->b应该要怎么确定状态转移权重呢？最简单的方式是全都设置为1，表示这些合理的状态转移概率都相等。更好一些的方法可以使用二元模型，统计语料库里s->s的概率，s->b 的概率，一直到e->b的概率。还有再更好一些的方法可以使用条件随机场CRF（Conditional Random Field）。状态转移矩阵的计算不属于维特比算法的内容。这里我们就用一个相对简单的方法——二元模型来进行计算（具体操作在后面程序中），得到的状态转移矩阵如图16.5所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 600}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 601 图16.5 状态转移矩阵 比如我们要对“深度学习”这4个字进行分词，那么我们就要把“深”，“度”，“学”，“习”这4个字对应的词向量传入到模型中，模型的输出结果是“o”，“s”，“b”，“m”，“e”这5个结果的分类概率（“o”表示用了填充的标注）。如图16.6所示。 \\n 图16.6 维特比算法1  我们先把这个图看懂，每个字传入模型中，就会得到5种标注的预测概率值，图中的T表示状态转移矩阵。每一时刻，我们都根据上一时刻的情况和当前时刻的情况来计算当前每个状态的最佳路径，这句话可能有点难理解，但这是维特比算法的核心内容。  假设“度”的标注是“s”，那么路径可能是o->s，s->s，b->s，m->s，e->s。每条路径我们都会计算一个分数（score），我们可以认为分数越高这条路径越好。分数的计算如score(o->s)=𝑃<Ò+𝑇ÒÞ+𝑃\"Þ，𝑃<Ò为模型输入“深”得到“o”的概率，我的模型计算得到的值为5.24×10\\x7fÉ；𝑇ÒÞ为转移矩阵中o->s的值，为-inf；𝑃\"Þ为模型输入“度”得到“s”的概\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 601}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 602 率，我的模型计算得到的值为6.39×10\\x7f°。所以score(o->s)=-inf。同样的方式，我们把o->s，s->s，b->s，m->s，e->s所有的分数计算出来，只保留最高的得分score(e->s)=0.17。  “度”的标注还可能是“o”，“b”，“m”，“e”。所以我们还需要分别计算上一时刻的状态到“o”，“b”，“m”，“e”的最佳路径以及路径得分。最后得到的结果如图16.7所示。 \\n 图16.7 维特比算法2  图中的S表示路径得分Score。接下来计算从“度”到“学”这一阶段。比如计算score(e->s)=使用上一时刻的得分𝑆¤+状态转移得分𝑇¤Þ+这一时刻的得分𝑃#Þ。同样根据上一时刻的情况和当前时刻的情况来计算当前每个状态的最佳路径，结果如图16.8所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 602}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 603 \\n 图16.8 维特比算法3  最后得到的结果如图16.9所示。 \\n 图16.9 维特比算法4 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 603}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 604  最后阶段得到5条最佳路径，o->o->o->o，b->e->s->s，b->e->s->b，b->e->b>m，b->e->b->e。最高得分是4.67，所以最后我们选择的分词标注为b->e->b->e，所以分词结果为：  ['深度', '学习']  最后总结一下，路径的分数是由模型预测的概率作为分数再加上转移矩阵的分数得到的。也就是说如果每个序列模型预测的结果非常准确，其实状态转移矩阵的分数也就不太重要了，甚至可以忽略状态转移矩阵的分数；如果每个序列模型预测的结果不够准确，那么状态转移矩阵的分数就比较关键了，甚至可以适当增加状态转移矩阵分数的权重。所以在早期的一些NLP应用中，模型预测的结果准确率不够高，可能需要使用条件随机场CRF来训练出一个好的状态转移矩阵，这样可以使得标注结果更好。而现在如果我们使用BERT模型来预测序列结果，由于BERT模型预测准确率很高，所以状态转移矩阵就不一定是关键影响因素了。  16.4.3 中文分词标注模型预测 实现中文分词标注模型预测的代码如代码16-6所示。 代码16-6：中文分词标注模型预测（片段1） import numpy as np import re from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.text import tokenizer_from_json from tensorflow.keras.preprocessing.sequence import pad_sequences import json # 句子长度，需要跟模型训练时一致 max_length = 128 # 载入tokenizer json_file = open('token_config.json','r',encoding='utf-8') \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 604}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 605 token_config = json.load(json_file) tokenizer = tokenizer_from_json(token_config) # 获得字典，键为字，值为编号 word_index = tokenizer.word_index # 载入模型 model = load_model('lstm_tag.h5') # 载入数据集做处理主要是为了计算状态转移概率 # 读入数据 text = open('msr_train.txt', encoding='gb18030').read() # 根据换行符切分数据 text = text.split('\\\\n')  # 得到所有的数据和标签 def get_data(s):     # 匹配(.)/(.)格式的数据     s = re.findall('(.)/(.)', s)     if s:         s = np.array(s)         # 返回数据和标签，0为数据，1为标签         return s[:,0],s[:,1]  # 数据 data = [] # 标签 label = [] # 循环每个句子 for s in text:     # 分离文字和标签     d = get_data(s)     if d:         # 0为数据         data.append(d[0])         # 1为标签         label.append(d[1]) # texts二维数据，一行一个句子 # 比如ngrams(texts,2,2)，只计算2-grams # 比如ngrams(texts,2,4)，计算2-grams，3-grams，4-grams def ngrams(texts, MIN_N, MAX_N):     # 定义空字典记录     ngrams_dict = {}     # 循环每一个句子     for tokens in texts:         # 计算一个句子token数量         n_tokens = len(tokens) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 605}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 606         # 词汇组合统计         for i in range(n_tokens):             for j in range(i+MIN_N, min(n_tokens, i+MAX_N)+1):                 # 词汇组合list转字符串                 temp = ''.join(tokens[i:j])                 # 字典计数加一                 ngrams_dict[temp] = ngrams_dict.get(temp, 0) + 1     # 返回字典     return ngrams_dict # 统计状态转移次数 ngrams_dict = ngrams(label,2,2) print(ngrams_dict) 结果输出为： {'sb': 600115, 'be': 1039906, 'es': 659674, 'ss': 427204, 'bm': 215149, 'me': 215149, 'mm': 211874, 'eb': 594480}  代码16-6：中文分词标注模型预测（片段2） # 计算状态转移总次数 sum_num = 0 for value in ngrams_dict.values():     sum_num = sum_num + value # 计算状态转移概率 p_sb = ngrams_dict['sb']/sum_num p_be = ngrams_dict['be']/sum_num p_es = ngrams_dict['es']/sum_num p_ss = ngrams_dict['ss']/sum_num p_bm = ngrams_dict['bm']/sum_num p_me = ngrams_dict['me']/sum_num p_mm = ngrams_dict['mm']/sum_num p_eb = ngrams_dict['eb']/sum_num # p_oo用于表示不可能的转移，-np.inf负无穷 p_oo = -np.inf  # 使用条件随机场CRF来计算转移矩阵有可能效果会更好 # 这里我们用简单的二元模型来定义状态转移矩阵 # oo,os,ob,om,oe, # so,ss,sb,sm,se # bo,bs,bb,bm,be # mo,ms,mb,mm,me # eo,es,eb,em,ee # 其中sm,se,bs,bb,ms,mb,em,ee这几个状态转移是不存在的 # o为填充状态，跟o相关的转移也都不需要考虑 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 606}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 607 transition_params = [[p_oo,p_oo,p_oo,p_oo,p_oo],                      [p_oo,p_ss,p_sb,p_oo,p_oo],                      [p_oo,p_oo,p_oo,p_bm,p_be],                      [p_oo,p_oo,p_oo,p_mm,p_me],                      [p_oo,p_es,p_eb,p_oo,p_oo]]  # 维特比算法 def viterbi_decode(sequence, transition_params):     \"\"\"     Args:       sequence: 一个[seq_len, num_tags]矩阵       transition_params: 一个[num_tags, num_tags]矩阵     Returns:       viterbi: 一个[seq_len]序列     \"\"\"     # 假设状态转移共有num_tags种状态     # 创建一个跟sequence相同形状的网格     score = np.zeros_like(sequence)     # 创建一个跟sequence相同形状的path，用于记录路径     path = np.zeros_like(sequence, dtype=np.int32)     # 起始分数     score[0] = sequence[0]     for t in range(1, sequence.shape[0]):         # t-1时刻score得分加上trans分数，得到下一时刻所有状态转移[num_tags, num_tags]的得分         T = np.expand_dims(score[t - 1], 1) + transition_params         # t时刻score = 计算每个状态转移的最大得分 + 下个序列预测得分         score[t] = np.max(T, 0) + sequence[t]          # 记录每个状态转移的最大得分所在位置          path[t] = np.argmax(T, 0)     # score[-1]为最后得到的num_tags种状态得分     # np.argmax(score[-1])找到最高分数所在位置     viterbi = [np.argmax(score[-1])]     # 回头确定来的路径，相当于知道最高分以后从后往前走     for p in reversed(path[1:]):         viterbi.append(p[viterbi[-1]])     # 反转viterbi列表，把viterbi变成正向路径     viterbi.reverse()     # 计算最大得分，如果需要可以return     # viterbi_score = np.max(score[-1]) return Viterbi  # 小句分词函数 def cut(sentence): ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 607}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 608     # 如果句子大于最大长度，只取max_length个词     if len(sentence) >= max_length:         seq = sentence[:max_length]     # 如果不足max_length，则填充     else:         seq = []         for s in sentence:             try:                 # 在字典里查询编号                 seq.append(word_index[s])             except:                 # 如果不在字典里填充0                 seq.append(0)         seq = seq + [0]*(max_length-len(sentence))     # 获得预测结果，shape(32,5)     preds = model.predict([seq])[0]     # 维特比算法     viterbi = viterbi_decode(preds, transition_params)     # 只保留跟句子相同长度的分词标注     y = viterbi[:len(sentence)]     # 分词     words = []     for i in range(len(sentence)):         # 如果标签为s或b，append到结果的list中         if y[i] in [1, 2]:             words.append(sentence[i])         else:         # 如果标签为m或e，在list最后一个元素中追加内容             words[-1] += sentence[i] return  words  # 根据符号断句 cuts = re.compile(u'([\\\\da-zA-Z ]+)|[。，、？！\\\\.\\\\?,!()（）]') # 先分小句，再对小句分词 def cut_word(s):     result = []     # 指针设置为0     i = 0     # 根据符号断句     for c in cuts.finditer(s):         # 对符号前的部分分词         result.extend(cut(s[i:c.start()]))         # 加入符号         result.append(s[c.start():c.end()]) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 608}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 609         # 移动指针到符号后面         i = c.end()     # 对最后的部分进行分词     result.extend(cut(s[i:]))     return result  print(cut_word('针对新冠病毒感染，要做好“早发现、早报告、早隔离、早治疗”，及时给予临床治疗的措施。')) 结果输出为： ['针对', '新冠', '病毒', '感染', '，', '要', '做好', '“', '早', '发现', '、', '早', '报告', '、', '早', '隔离', '、', '早', '治疗', '”', '，', '及时', '给予', '临床', '治疗', '的', '措施', '。']  代码16-6：中文分词标注模型预测（片段3） print(cut_word ('广义相对论是描写物质间引力相互作用的理论')) 结果输出为： ['广义', '相对论', '是', '描写', '物质', '间', '引力', '相互', '作用', '的', '理论']  代码16-6：中文分词标注模型预测（片段4） print(cut_word('阿尔法围棋（AlphaGo）是第一个击败人类职业围棋选手、第一个战胜围棋世界冠军的人工智能，是谷歌（Google）旗下DeepMind公司戴密斯·哈萨比斯领衔的团队开发。')) 结果输出为： ['阿尔法围棋', '（', 'AlphaGo', '）', '是', '第一个', '击败', '人类', '职业', '围棋', '选手', '、', '第一个', '战胜', '围棋', '世界', '冠军', '的', '人工', '智能', '，', '是', '谷歌', '（', 'Google', '）', '旗', '下', 'DeepMind', '公司', '戴密斯·哈萨比斯', '领衔', '的', '团队', '开发', '。']   经过测试我们看到模型可以得到较好的分词结果，对公司名，人名等这些命名实体也可以得到很好的识别效果。  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 609}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 610 16.5 最新的一些激活函数介绍  NLP实战章节突然又讲到激活函数，大家不要觉得奇怪，肯定是因为下面的NLP实战内容有涉及到新的激活函数的使用。BERT中使用的激活函数为GELU(Gaussian Error Linear Unit)函数[2]，不再是我们熟悉的ReLU函数。在近年的深度学习技术发展中又诞生了许多新的激活函数，既然要介绍GELU函数，那干脆把一些新的激活函数都一起介绍一下吧。  之前我们有介绍过Sign，Sigmoid，Tanh，Softsign，ReLU这些激活函数，这些激活函数中表现最好的自然是ReLU。ReLU的优点是计算简单，可以避免梯度消失。下面要介绍的这些激活函数大部分都跟ReLU有点关系。新的一些激活函数有部分在Tensorflow中可以直接调用，有部分在Tensorflow中没有，需要自行定义，如何自定义激活函数可以参考后面BERT的源代码。 16.5.1 Leaky ReLU  带泄露修正线性单元Leaky ReLU[3]算是ReLU函数的一个变种，可以简写为LReLU，公式为： 𝐿𝑅𝑒𝐿𝑈(𝑥)=1𝑥\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼𝑥\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t\\t(16.1)  LReLU的导数公式为：  𝐿𝑅𝑒𝐿𝑈R(V)=11\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼\\t\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t\\t\\t(16.2) 这里的𝛼是一个人为设置的超参数，一般取值范围是0.1-0.3。𝛼为0.3时，Leaky ReLU函数图像如图16.10所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 610}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 611 \\n 图16.10 Leaky ReLU  Leaky ReLU函数的导数图像如图16.11所示。 \\n 图16.11 Leaky ReLU函数导数 从图中我们就可以看出Leaky ReLU的特点是当x取值为负时，函数也有对应的输出，并且x取值为负时也存在较小的梯度。可以解决ReLU函数中当x取值为负时，函数只能输出0，并且导数也为0的问题。其实总的来说ReLU和Leaky ReLU效果差不多，只不过有些时候使用Leaky ReLU可以得到更好的效果。 16.5.2 ELU 指数线性单元ELU(Exponential Linear Unit)[4]也是一个跟ReLU类似的激活函数，公式为： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 611}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 612 𝐸𝐿𝑈(𝑥)=1𝑥\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼(𝑒V−1)\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t(16.3) ELU的导数为公式： 𝐸𝐿𝑈R(V)=11\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼𝑒V\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.4) 这里的𝛼是一个人为设置的超参数，一般取值范围是0.1-0.3。𝛼为0.3时，ELU函数图像如图16.12所示。 \\n 图16.12 ELU  ELU函数的导数图像如图16.13所示。 \\n 图16.13 ELU函数导数 从图中我们就可以看出ELU跟Leaky ReLU挺像的，当x取值为负时，函数也有对应的输出，并且x取值为负时也存在较小的梯度。只不过ELU中有指数计算，x的值越小，梯度\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 612}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 613 的值也会越接近于0。一般来说使用ELU作为激活函数，模型的效果可能会比使用ReLU要稍微好一些。  16.5.3 SELU 扩展指数线性单元SELU(Scaled Exponential Linear Unit)[5]看名字就知道应该是跟ELU差不多，SELU的公式为： 𝑆𝐸𝐿𝑈(𝑥)=𝜆×1𝑥\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼(𝑒V−1)\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t\\t\\t(16.5) SELU的导数为公式： 𝑆𝐸𝐿𝑈R(V)=𝜆×11\\t\\t\\t\\t\\t\\t\\t𝑖𝑓(𝑥>0)𝛼𝑒V\\t\\t𝑖𝑓(𝑥≤0)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.6) 比ELU公式中多了一个𝜆，大家可能会想又多了一个参数，调参岂不是更困难。这个大家可以放心，作者用一篇包含300多个公式推导的100页左右的论文告诉我们： 𝛼≈1.6732632423543772848170429916717 𝜆≈1.0507009873554804934193349852946 具体的推导过程估计没几个人会去看，大家有兴趣的话可以自行研究。总之得到𝛼和𝜆这两个具体的数值以后，神经网络每一层的激活值都会满足均值接近于0，标准差接近于1的正态分布。可以有效的解决梯度消失问题，同时加快模型收敛速度，这跟Batch Normalization比较类似。而使用了SELU激活函数的网络也被称为自归一化神经网络(Self-Normalizing Neural Networks)，简称SNN。 SNN模型训练有一个条件，就是必须要对网络的权值进行标准化的权值初始化，比如可以使用 lecun_normal(参考内容来自http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)初始化网络权值，否则可能会训练失败。另外如果网络中需要使用Dropout的话，', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 613}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 614 最好使用Alpha Dropout。Alpha Dropout是一种保持信号均值和方差不变的Dropout，该层的作用是即使在Dropout的时候也保持数据的自规范性。 SELU函数图像如图16.14所示。 \\n 图16.14 SELU  SELU函数的导数图像如图16.15所示。 \\n 图16.15 SELU函数导数  SELU良好的自归一化特性使得它在很多任务中都会比ReLU得到更好的效果。 16.5.4 GELU 高斯误差线性单元GELU(Gaussian Error Linear Unit)[6]，BERT模型中使用的激活函数就是GELU。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 614}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 615 GELU的公式为： 𝐺𝐸𝐿𝑈(𝑥)=𝑥𝑃(𝑋≤𝑥)=𝑥Φ(𝑥)\\t\\t\\t\\t\\t\\t\\t\\t(16.7)  其中𝑃(𝑋≤𝑥)表示概率值，Φ(𝑥)指的是x的正态分布的累积分布函数： 𝐺𝐸𝐿𝑈(𝑥)=𝑥𝑃(𝑋≤𝑥)=𝑥5𝑒\\x7f(6\\x7f7)\\x9d#8\\x9d√2𝜋𝜎V\\x7f:𝑑𝑋\\t\\t\\t\\t\\t\\t\\t(16.8)  计算结果可以约等于： 𝐺𝐸𝐿𝑈(𝑥)=0.5𝑥\\x8b1+tanh\\x8ao2𝜋(𝑥+0.044715𝑥$)\\x8d\\x8c\\t\\t\\t(16.9) GELU的导数为公式： 𝐺𝐸𝐿𝑈R(V)=0.5tanh(0.0356774𝑥$+0.797885𝑥)+(0.0535161𝑥$+0.398942𝑥)×𝑠𝑒𝑐ℎ#(0.0356774𝑥$+0.797885𝑥)+0.5\\t\\t\\t\\t\\t\\t\\t\\t(16.10)  概率𝑃(𝑋≤𝑥)中的x表示当前神经元的激活值输入，X的正态分布的累积分布Φ(𝑥)是随着x的变化而变化的。当神经元激活值输入x增大，Φ(𝑥)也会增大；当x减小，Φ(𝑥)也会减小。如果x很小，Φ(𝑥)的值会接近于0，神经元的输出值会接近于0，相当于神经元被Dropout；如果x比较大，Φ(𝑥)的值会接近于1，相当于神经元会保留。 GELU的函数图像如图16.16所示。 \\n 图16.16 GELU \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 615}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 616  GELU函数的导数图像如图16.17所示。 \\n 图16.17 GELU函数导数  GELU激活函数在很多实验中也表现出了比ReLU和ELU更好的效果。 16.5.5 Swish  Swish[7]是由谷歌提出的一个激活函数，谷歌也是做了很多实验证明Swish比Relu要更好，甚至比LReLU，ELU，SELU，GELU这些ReLU的变形还要好。当然Swish真正的效果如何，大家不妨在之后的项目中尝试使用看看，对比一下其他的激活函数就知道了。 Swish的公式为： 𝑆𝑤𝑖𝑠ℎ(𝑥)=𝑥×𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.11)  这里的𝛽是一个人为设置的参数值，也可以通过模型训练得到。 Swish的导数为公式： 𝑆𝑤𝑖𝑠ℎR(𝑥)=𝛽𝑆𝑤𝑖𝑠ℎ(𝑥)+𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥)×\\x8e1−𝛽𝑆𝑤𝑖𝑠ℎ(𝑥)\\x8f\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(16.12)  Swish的函数图像如图16.18所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 616}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 617 \\n  图16.18 Swish  Swish函数的导数图像如图16.19所示。 \\n 图16.19 Swish函数导数  16.6 BERT模型简单使用  16.6.1 安装tf2-bert模块并准备预训练模型 我参考Github上一个做得比较好的BERT开源项目bert4kera(参考内容来自https://github.com/bojone/bert4keras)，在它的基础上进行了进一步的精简，只留下跟\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 617}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 618 BERT相关的最核心的代码，并把它变成了“全注释代码”，主要是方便大家学习和基本使用。我精简和注释过的项目发布在我的Github上：https://github.com/Qinbf/tf2_bert。 BERT模型的完整实现即便是做了很多的精简，整个程序也还是有1000多行的代码。所以在这里我们就不讲解BERT模型实现的细节了，大家可以到我的Github上下载程序来进行学习。下面我们主要讲一下如何使用BERT来完成NLP相关的一些任务。首先我们需要先安装tf2_bert模块，安装方式为打开命令提示符运行命令： pip install tf2-bert 模块安装好以后我们还需要下载预训练模型，可以通过网址（https://github.com/google-research/bert）下载谷歌官方的预训练模型，谷歌提供的预训练模型大部分都是使用英文语料训练出来的。如果大家要使用中文语料训练的BERT模型，推荐大家使用哈工大提供的预训练模型，网址为：https://github.com/ymcui/Chinese-BERT-wwm。 我在哈工大提供的预训练模型中下载了一个简称为“RoBERTa-wwm-ext, Chinese”的模型，下载地址为：http://pan.iflytek.com/#/link/98D11FAAF0F0DBCB094EE19CCDBC98BF，密码为Xe1p。下载好以后得到一个名为“chinese_roberta_wwm_ext_L-12_H-768_A-12”的文件夹，文件夹中的文件如图16.20所示。  图16.20 模型文件 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 618}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 619  其中“bert_config.json”是BERT模型相关的一些配置文件，“vocab.txt”为BERT模型训练时用到的词表，剩下的3个为Tensorflow的模型文件。“ckpt”为“checkpoint”的缩写，“ckpt”这种模型保存格式在Tensorflow1.0中用得比较多，也可以沿用至Tensorflow2。  16.6.2 使用BERT进行文本特征提取  准备工作做好以后，下面我们开始进行BERT模型的使用，首先我们先用预训练的BERT模型来进行文本特征提取，如代码16-7所示。 代码16-7：使用BERT进行文本特征提取（片段1） from tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer import numpy as np # 定义预训练模型路径 model_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12' # BERT参数 config_path = model_dir+'/bert_config.json' # 保存模型权值参数的文件 checkpoint_path = model_dir+'/bert_model.ckpt' # 词表 dict_path = model_dir+'/vocab.txt' # 建立分词器 tokenizer = Tokenizer(dict_path)  # 建立模型，加载权重 model = build_transformer_model(config_path, checkpoint_path)  # 句子0 sentence0 = '机器学习' # 句子1 sentence1 = '深度学习' # 用分词器对句子分词 tokens = tokenizer.tokenize(sentence0) # 分词后自动在句子前加上[CLS]，在句子后加上[SEP] print(tokens) 结果输出为： ['[CLS]', '机', '器', '学', '习', '[SEP]']  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 619}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 620 代码16-7：使用BERT进行文本特征提取（片段2） # 编码测试 token_ids, segment_ids = tokenizer.encode(sentence0) # [CLS]的编号为101，机为3322，器为1690，学为2110，习为739，[SEP]为102 print('token_ids:',token_ids) # 因为只有一个句子所以segment_ids都是0 print('segment_ids:',segment_ids) 结果输出为： token_ids: [101, 3322, 1690, 2110, 739, 102] segment_ids: [0, 0, 0, 0, 0, 0]  代码16-7：使用BERT进行文本特征提取（片段3） # 编码测试 token_ids, segment_ids = tokenizer.encode(sentence0,sentence1) # 可以看到两个句子分词后的结果为： # ['[CLS]', '机', '器', '学', '习', '[SEP]', '深', '度', '学', '习', [SEP]] print('token_ids:',token_ids) # 0表示第一个句子的token，1表示第二个句子的token print('segment_ids:',segment_ids) 结果输出为： token_ids: [101, 3322, 1690, 2110, 739, 102, 3918, 2428, 2110, 739, 102] segment_ids: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  代码16-7：使用BERT进行文本特征提取（片段4） # 增加一个维度表示批次大小为1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids]) # 得到的结果中1表示批次大小，11表示11个token，768表示特征向量长度 # 这里就是把句子的token转化为了特征向量 print(pre.shape) 结果输出为： (1, 11, 768)  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 620}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 621  16.6.3 使用BERT进行完形填空  使用BERT进行完形填空其实就是使用BERT的掩码语言模型MLM来对包含”[MASK]”符号的句子进行预测，把”[MASK]”符号变成合理的词填入到句子中，如代码16-8所示。 代码16-8：使用BERT进行完形填空（片段1） from tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer import numpy as np # 定义预训练模型路径 model_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12' # BERT参数 config_path = model_dir+'/bert_config.json' # 保存模型权值参数的文件 checkpoint_path = model_dir+'/bert_model.ckpt' # 词表 dict_path = model_dir+'/vocab.txt' # 建立分词器 tokenizer = Tokenizer(dict_path)  # 建立模型，加载权重 # with_mlm=True表示使用mlm的功能，模型结构及最后的输出会发生一些变化，可以用来预测被mask的token model = build_transformer_model(config_path, checkpoint_path, with_mlm=True)  # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科') # 把“学”字和“习”字变成“[MASK]”符号 token_ids[3] = token_ids[4] = tokenizer._token_dict['[MASK]'] # 增加一个维度表示批次大小为1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第3，4个位置经过模型预测，[MASK]变成了“学习” print(tokenizer.decode(pre[3:5].argmax(axis=1)))   结果输出为： 学习  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 621}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 622 代码16-8：使用BERT进行完形填空（片段2） # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科') # 把“交”字和“叉”字变成“[MASK]”符号 token_ids[8] = token_ids[9] = tokenizer._token_dict['[MASK]'] # 增加一个维度表示批次大小为1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第8，9个位置经过模型预测，[MASK]变成了“什么”，句子变成了一个疑问句 # 虽然模型没有预测出原始句子的词汇，不过作为完形填空，填入一个“什么”句子也是正确 print(tokenizer.decode(pre[8:10].argmax(axis=1)))   结果输出为： 什么 16.7 BERT电商用户多情绪判断项目 16.7.1 项目背景介绍  之前我们使用的情感分类数据都是网上可以找到的开源数据，并且相对简单。这一小节我们来点更硬核的内容，给大家介绍一个我之前给某化妆品公司做的电商用户多种情绪判断的项目，项目用到的部分标注好的数据我会跟本书的代码一起开放给大家下载，供大家学习和研究使用。项目背景大概就是化妆品公司希望可以通过分析自己用户的评论数据，挖掘影响产品购买的因素，提供产品建议或策略指导，进而提升效率。了解对方需求后，我对用户评论的分析并不只是针对好评还是差评这一个维度来判断，只判断好评差评维度太单一，无法挖掘出更深层次的内容。因此我把用户评论的分析分为了7个不同维度，分别是总体评论，是否为老用户，是否是参与活动购买，产品质量评价，性价比评价，客户物流包装等服务评价，是否考虑在再次购买，如图16.21： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 622}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 623 \\n 图16.21 用户评论7个维度分析  每个维度都有3个分类，在数据的标注中使用 1，0，-1来标注。具体情况如图16.22所示。 \\n 图16.22 7个维度具体标注情况  获得用户评论中更多维度的信息以后就可以对用户评论进行更深入的挖掘和更全面的分析。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 623}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 624 16.7.2 模型训练 实现BERT电商用户多情绪判断-模型训练的代码如代码16-9所示。 代码16-9：BERT电商用户多情绪判断-模型训练（片段1） from tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer from tensorflow.keras.utils import to_categorical from tensorflow.keras.layers import Lambda,Dense,Input,Dropout from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ModelCheckpoint import numpy as np import pandas as pd from plot_model import plot_model # 周期数 epochs = 5 # 批次大小 batch_size = 16 # 验证集占比 validation_split = 0.2 # 句子长度 seq_len = 256 # 载入数据 data = pd.read_excel('reviews.xlsx') # 查看数据前5行 data.head() 结果输出为： \\n  代码16-9：BERT电商用户多情绪判断-模型训练（片段2） # 定义预训练模型路径 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 624}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 625 model_dir = './chinese_roberta_wwm_ext_L-12_H-768_A-12' # BERT参数 config_path = model_dir+'/bert_config.json' # 保存模型权值参数的文件 checkpoint_path = model_dir+'/bert_model.ckpt' # 词表 dict_path = model_dir+'/vocab.txt' # 建立分词器 tokenizer = Tokenizer(dict_path)  # 建立模型，加载权重 bert_model = build_transformer_model(config_path, checkpoint_path)   token_ids = [] segment_ids = [] # 循环每个句子 for s in data['评论'].astype(str):     # 分词并把token变成编号     token_id,segment_id = tokenizer.encode(s, first_length=seq_len)     token_ids.append(token_id)     segment_ids.append(segment_id) token_ids = np.array(token_ids) segment_ids = np.array(segment_ids)  label = [] # 定义标签 def LabelEncoder(y):     # 增加一个维度     y = y[:,np.newaxis]     # 原始标签把-1,0,1变成0,1,2     y = y+1     y = y.astype('uint8')     # 转成独热编码     y = to_categorical(y, num_classes=3)     return y  # 获取7个维度的标签，并把每个维度的标签从-1,0,1变成0,1,2 label = [(LabelEncoder(np.array(data[columns]))) for columns in data.columns[1:]] label = np.array(label) print(label.shape) 结果输出为： (7, 10000, 3)  \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 625}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 626 代码16-9：BERT电商用户多情绪判断-模型训练（片段3） # token输入 token_in = Input(shape=(None,)) # segment输入 segment_in = Input(shape=(None,)) # 使用BERT进行特征提取 x = bert_model([token_in, segment_in]) # 每个序列的第一个字符是句子的分类[CLS],该字符对应的embedding可以用作分类任务中该序列的总表示 # 说白了就是用句子第一个字符的embedding来表示整个句子 # 取出每个句子的第一个字符对应的embedding x = Lambda(lambda x: x[:, 0])(x)  # 多任务学习 # 性价比输出层 x0 = Dropout(0.5)(x) preds0 = Dense(3, activation='softmax',name='out0')(x0) # 产品质量输出层 x1 = Dropout(0.5)(x) preds1 = Dense(3, activation='softmax',name='out1')(x1) # 参加活动输出层 x2 = Dropout(0.5)(x) preds2 = Dense(3, activation='softmax',name='out2')(x2) # 客服物流包装输出层 x3 = Dropout(0.5)(x) preds3 = Dense(3, activation='softmax',name='out3')(x3) # 是否为老顾客输出层 x4 = Dropout(0.5)(x) preds4 = Dense(3, activation='softmax',name='out4')(x4) # 是否会再买输出层 x5 = Dropout(0.5)(x) preds5 = Dense(3, activation='softmax',name='out5')(x5) # 总体评论输出层 x6 = Dropout(0.5)(x) preds6 = Dense(3, activation='softmax',name='out6')(x6) # 定义模型 model = Model([token_in, segment_in], [preds0,preds1,preds2,preds3,preds4,preds5,preds6]) # 画出模型结构 plot_model(model,dpi=200) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 626}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 627 \\n  代码16-9：BERT电商用户多情绪判断-模型训练（片段4） # 定义模型训练的loss，loss_weights，optimizer # loss_weights表示每个任务的权重，可以看情况设置 model.compile(loss={                   'out0': 'categorical_crossentropy',                   'out1': 'categorical_crossentropy',                   'out2': 'categorical_crossentropy',                   'out3': 'categorical_crossentropy',                   'out4': 'categorical_crossentropy',                   'out5': 'categorical_crossentropy',                   'out6': 'categorical_crossentropy'},                 loss_weights={                   'out0': 1.,                   'out1': 1.,                   'out2': 1.,                   'out3': 1.,                   'out4': 1.,                   'out5': 1,                   'out6': 2.},                 optimizer=Adam(1e-5),                 metrics=['accuracy'])  # 保存val_loss最低的模型 callbacks = [ModelCheckpoint(filepath='bert_model/'+'{epoch:02d}.h5',                     monitor='val_loss',                     verbose=1,                     save_best_only=True)]  # 训练模型 model.fit([token_ids, segment_ids], [label[0],label[1],label[2],label[3],label[4],label[5],label[6]], \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 627}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 628           batch_size=batch_size,           epochs=epochs,           validation_split=validation_split,           callbacks=callbacks) 结果输出为： Train on 8000 samples, validate on 2000 samples Epoch 1/5 7984/8000 [============================>.] - ETA: 0s - loss: 3.4144 - out0_loss: 0.2809 - out1_loss: 0.6564 - out2_loss: 0.2141 - out3_loss: 0.4407 - out4_loss: 0.4736 - out5_loss: 0.2666 - out6_loss: 0.5410 - out0_accuracy: 0.9176 - out1_accuracy: 0.7325 - out2_accuracy: 0.9400 - out3_accuracy: 0.8403 - out4_accuracy: 0.8391 - out5_accuracy: 0.9163 - out6_accuracy: 0.8111 …… Epoch 5/5 7984/8000 [============================>.] - ETA: 0s - loss: 0.9488 - out0_loss: 0.0636 - out1_loss: 0.2589 - out2_loss: 0.0501 - out3_loss: 0.0752 - out4_loss: 0.1288 - out5_loss: 0.0652 - out6_loss: 0.1535 - out0_accuracy: 0.9797 - out1_accuracy: 0.9023 - out2_accuracy: 0.9862 - out3_accuracy: 0.9757 - out4_accuracy: 0.9543 - out5_accuracy: 0.9770 - out6_accuracy: 0.9461 Epoch 00005: val_loss did not improve from 2.51170 8000/8000 [==============================] - 287s 36ms/sample - loss: 0.9486 - out0_loss: 0.0635 - out1_loss: 0.2588 - out2_loss: 0.0500 - out3_loss: 0.0751 - out4_loss: 0.1293 - out5_loss: 0.0651 - out6_loss: 0.1534 - out0_accuracy: 0.9797 - out1_accuracy: 0.9022 - out2_accuracy: 0.9862 - out3_accuracy: 0.9758 - out4_accuracy: 0.9540 - out5_accuracy: 0.9770 - out6_accuracy: 0.9461 - val_loss: 3.0706 - val_out0_loss: 0.1404 - val_out1_loss: 0.5145 - val_out2_loss: 0.2064 - val_out3_loss: 0.1928 - val_out4_loss: 0.3246 - val_out5_loss: 0.2494 - val_out6_loss: 0.7211 - val_out0_accuracy: 0.9580 - val_out1_accuracy: 0.8125 - val_out2_accuracy: 0.9515 - val_out3_accuracy: 0.9450 - val_out4_accuracy: 0.9015 - val_out5_accuracy: 0.9185 - val_out6_accuracy: 0.8260 16.7.3 模型预测 实现BERT电商用户多情绪判断-模型预测的代码如代码16-10所示。 代码16-10：BERT电商用户多情绪判断-模型预测（片段1） from tf2_bert.models import build_transformer_model from tf2_bert.tokenizers import Tokenizer ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 628}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 629 from tensorflow.keras.models import load_model import numpy as np # 载入模型 model = load_model('bert_model.h5') # 词表路径 dict_path = './chinese_roberta_wwm_ext_L-12_H-768_A-12'+'/vocab.txt' # 建立分词器 tokenizer = Tokenizer(dict_path)  # 预测函数 def predict(text):     # 分词并把token变成编号，句子长度需要与模型训练时一致     token_ids, segment_ids = tokenizer.encode(text, first_length=256)     # 增加一个维度表示批次大小为1     token_ids = np.expand_dims(token_ids,axis=0)     # 增加一个维度表示批次大小为1     segment_ids = np.expand_dims(segment_ids,axis=0)     # 模型预测     pre = model.predict([token_ids, segment_ids])     # 去掉一个没用的维度     pre = np.array(pre).reshape((7,3))     # 获得可能性最大的预测结果     pre = np.argmax(pre,axis=1)          comment = ''     if(pre[0]==0):         comment += '性价比差,'     elif(pre[0]==1):         comment += '-,'     elif(pre[0]==2):         comment += '性价比好,'      if(pre[1]==0):         comment += '质量差,'     elif(pre[1]==1):         comment += '-,'     elif(pre[1]==2):         comment += '质量好,'      if(pre[2]==0):         comment += '希望有活动,'     elif(pre[2]==1):         comment += '-,'     elif(pre[2]==2):         comment += '参加了活动,' \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 629}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 630      if(pre[3]==0):         comment += \\'客服物流包装差,\\'     elif(pre[3]==1):         comment += \\'-,\\'     elif(pre[3]==2):         comment += \\'客服物流包装好,\\'      if(pre[4]==0):         comment += \\'新用户,\\'     elif(pre[4]==1):         comment += \\'-,\\'     elif(pre[4]==2):         comment += \\'老用户,\\'      if(pre[5]==0):         comment += \\'不会再买,\\'     elif(pre[5]==1):         comment += \\'-,\\'     elif(pre[5]==2):         comment += \\'会继续购买,\\'      if(pre[6]==0):         comment += \\'差评\\'     elif(pre[6]==1):         comment += \\'中评\\'     elif(pre[6]==2):         comment += \\'好评\\'              return pre,comment  pre,comment = predict(\"还没用，不知道怎么样\") print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [1 1 1 1 1 1 1] comment: -,-,-,-,-,-,中评  代码16-10：BERT电商用户多情绪判断-模型预测（片段2） pre,comment = predict(\"质量不错，还会再来，价格优惠\") print(\\'pre:\\',pre) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 630}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 631 print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 1 2 2] comment: 性价比好,质量好,-,-,-,会继续购买,好评  代码16-10：BERT电商用户多情绪判断-模型预测（片段3） pre,comment = predict(\"好用不贵物美价廉，用后皮肤水水的非常不错\") print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 1 1 2] comment: 性价比好,质量好,-,-,-,-,好评  代码16-10：BERT电商用户多情绪判断-模型预测（片段4） pre,comment = predict(\\'一直都用这款产品，便宜又补水，特别好用，今后要一直屯下去。\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 1 1 2 2 2] comment: 性价比好,质量好,-,-,老用户,会继续购买,好评  代码16-10：BERT电商用户多情绪判断-模型预测（片段5） pre,comment = predict(\\'趁着搞活动又囤了几盒，很划算，天天用也不心疼，补水效果还可以的\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [2 2 2 1 1 1 2] comment: 性价比好,质量好,参加了活动,-,-,-,好评  代码16-10：BERT电商用户多情绪判断-模型预测（片段6） pre,comment = predict(\\'我周六买的，星期一才发货，问客服没有回复，不过速度还是快，星期二收到的。发货速度有待改进。\\') print(\\'pre:\\',pre) print(\\'comment:\\',comment) 结果输出为： pre: [1 1 1 0 1 1 0] comment: -,-,-,客服物流包装差,-,-,差评  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 631}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 632 代码16-10：BERT电商用户多情绪判断-模型预测（片段7） pre,comment = predict('人生中第一次差评，差评一是给这个产品，用了过敏；二是给这个客服，说过敏仅支持退货并且运费自理。我的天！那我就不退了吧。只能说自己倒霉咯，过敏了没人管，退货还得自掏腰包，最惨不过我') print('pre:',pre) print('comment:',comment) 结果输出为： pre: [1 0 1 0 1 1 0] comment: -,质量差,-,客服物流包装差,-,-,差评  代码16-10：BERT电商用户多情绪判断-模型预测（片段8） pre,comment = predict('自从朋友推荐就一直使用这款面膜，哈哈哈哈，这款面膜一件用了很久了，每次活动买，比较实惠划算，比较适合我自己。唯一感觉不足的就是乳液太少。发货也特别快，值得购买。会在买的。') print('pre:',pre) print('comment:',comment) 结果输出为： pre: [2 2 2 2 2 2 2] comment: 性价比好,质量好,参加了活动,客服物流包装好,老用户,会继续购买,好评  16.8 参考文献 [1] Kim Y . Convolutional Neural Networks for Sentence Classification[J]. Eprint Arxiv, 2014. [2] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint arXiv:1606.08415, 2016. [3] Maas A L, Hannun A Y, Ng A Y. Rectifier nonlinearities improve neural network acoustic models[C]//Proc. icml. 2013, 30(1): 3. [4] Clevert D A, Unterthiner T, Hochreiter S. Fast and accurate deep network learning by exponential linear units (elus)[J]. arXiv preprint arXiv:1511.07289, 2015. \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 632}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 633 [5] Klambauer G, Unterthiner T, Mayr A, et al. Self-normalizing neural networks[C]//Advances in neural information processing systems. 2017: 971-980.  [6] Hendrycks D, Gimpel K. Gaussian error linear units (gelus)[J]. arXiv preprint arXiv:1606.08415, 2016. [7]Ramachandran P, Zoph B, Le Q V. Searching for activation functions[J]. arXiv preprint arXiv:1710.05941, 2017.     第17章 音频信号处理 深度学习目前应用最广泛的3大领域就是计算机视觉，自然语言处理和语音。计算机视觉和自然语言处理的内容在前面我们都已经有所了解，这一章节我们就来介绍一下语音方面的任务。本章出现的新概念比较多，要想把这一章的内容学好，最好把这些新概念的中英文名称都记住，对应的含义都理解清楚。  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 633}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 634 17.1 深度学习在声音领域的应用介绍 1. 音频分类  音频分类算是音频领域的一个基本应用，就是判断一段音频数据是属于哪一种分类，比如分类可以是人的说话声，飞机轰鸣声，汽车声音，火车声音，小孩哭声，玻璃破碎声，狗叫声，警报声等等，如图17.1所示。  图17.1 语音分类  2.音频事件检测  音频事件检测（Audio Event Detection）其实跟音频分类有点像，就是实时监测环境中的音频事件，这里的音频事件可以看成是某种声音的分类。比如一对新婚夫妻生了一个小婴儿，父母睡眠质量都比较好并且对婴儿哭声不太敏感，半夜婴儿肚子饿，哭了半天父母才能醒过来。如果要解决这个问题我们可以把婴儿的哭声作为要检测的音频事件，检测到婴儿的哭声后，可以触发一个音量比较大的闹钟铃声唤醒婴儿的父母。如图17.2所示。  图17.2 音频事件检测 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 634}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 635 3. 语音识别  语音识别大家应该比较熟悉，就是把语音信息转化为文字信息。在我们的日常生活中语音识别已经得到了较大规模的应用，日常用语的语音识别效果已经可以达到非常高的准确率。 4．音乐检索  音乐检索就是通过一小段音乐去检索出该音乐出自哪一首歌曲，也就是我们日常所说的听歌识曲。不少音乐类APP现在都已经实现了该功能。 5. 音乐生成  AI与音乐的结合在这几年变得越来越频繁，在2019年中国数字音乐产业发展峰会上，有音乐制作公司在现场演示了AI作曲的操作，只需要给AI算法随意唱几个音符，它就可以作出一首完整的歌曲。美国网红歌手Taryn Southern跟AI一起创作了一首歌《Break Free》。AI技术用于音乐生成目前还处于比较早期的阶段，相信在未来我们可以听到更多更好的AI音乐作品。 6. 语音合成  语音合成包括把文本文字合成人声。近几年有部分广告推销电话已经开始时候语音合成技术，使用机器来给我们打电话。如果不仔细分辨的话，有可能还不知道对方是机器人。当然，目前这个技术还不算特别成熟，机器人的声音相比于普通人的声音来说会显得更僵硬一些，说话方式没有人这么自然。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 635}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 636 7. 语音克隆 语音克隆技术指的是克隆某个人的声音。给算法输入某个人的一个声音片段，算法会学习这个人的方式，然后再把这种说话方法跟其他的人声相结合。比如你想模仿“小团团”魔性的声音，就准备一段“小团团”的语言片段传给算法学习，然后算法就可以把你的说话声音变成“小团团”的声音了。  17.2 MFCC和Mel Filter Banks 这一小节我们来介绍一下自动语言识别(Automatic Speech Recognition，简称ASR)领域中最常用的两种语音处理方法： 梅尔滤波器组（Mel Filter Banks）和梅尔频率倒谱系数 (Mel-frequency cepstral coefficients，简称MFCC )。 语音数据处理的流程如图17.3所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 636}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 637 图17.3  语音数据处理的流程 17.2.1 音频数据采集 首先我们来大概了解一下语音中的一些基本概念，语音信号在自然界中是属于模拟信号（Analog Signal），模拟信号是指用连续变化的物理量表示的信号。我们需要把模拟信号变成数字信号（Digital Signal）以后才能进行后续的分析和建模，数字信号指的是离散的数值信号。所以一般我们可以使用数字麦克风（可以直接输出数字信号的麦克风），或者模拟麦克风（输出模拟信号的麦克风）加上模数转换芯片（把模拟信号变成数字信号的芯片）得到数字信号。 在采集声音数据的时候，可以通过设置采样频率（Sampling frequency）来控制信号采集的快慢，比如采样频率为8kHz时，表示每秒可以采集到8000个数据。一个数据就是一个数值，数值的大小表示信号的强弱。我们人耳的听力范围一般是20Hz-20kHz，根据Nyquist采样定理，采样频率至少是信号中的最高频率的两倍，也就是说要采样20Hz-20kHz的信号，需要至少40kHz以上的采样频率。在CD中采用了44.1kHz的采样频率，所以CD可以保存高质量的音频信号。采样频率也不是越高越好，因为采样频率越高，采集到的数据就越多，音频文件也会变得越大。人耳对低频声音比较敏感，对高频声音不太敏感，并且人说话的声音频率也比较低，所以在普通的录音应用中8kHz或16kHz的采样频率会用的比较多。 除了采样频率以外，量化位数（Quantization Bits）也会影响音频文件的大小，量化位数是对模拟信号进行数字化时的精度。比如8位就是用8bit来表示音频信号，16位就是用16bit来表示音频信号。位数越高，数字化后的音频信号就越可能接近原始信号，但所需的存储空间也越大。通常8位和16位用得比较多。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 637}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 638 17.2.2 分帧加窗 我们在分析视频数据的时候会把连续的视频数据拆分为一帧一帧的图像数据来进行分析。处理语音数据的时候也是如此，我们会把一长串语音数据拆分为一帧一帧的数据进行处理。语音数据中的帧指的是一小段语音数据，一般情况下我们会把20-40ms的数据看成是一帧。选择20-40ms这个长度主要是我们假设在短时尺度上音频信号没有太大的变化，如果帧的长度更短的话，我们没有足够的样本来获取可靠的频谱估计，如果帧更长的话，信号在整个帧中变化太大。比较常用的帧长为20-25ms，帧移为10ms，如图17.4所示。 \\n 图17.4 分帧 图中的Amplitude表示振幅；Time表示时间；seconds表示秒。 分帧后一般还会有一个加窗的操作，如常用的窗口有Rectangular Window，Hamming Window和Hanning Window等，如图17.5所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 638}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 639 \\n 图17.5 各种窗口  Rectangular Window其实就是保留分帧后的数据不做处理，Hamming Window和Hanning Window效果差不多，就是增强每一帧数据中间部分的信号，减弱每一帧数据边缘的信号。一般来说Hamming Window和Hanning Window用得比较多。 17.2.3 傅里叶变换  分帧加窗做好以后，下一步就要对每帧数据进行傅里叶变换（Fourier Transform），如图17.6所示。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 639}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 640 图17.6对每帧数据进行傅里叶变换 因为我们使用的数据都是离散的数值信号，对离散的数值信号进行的傅里叶变换也称为离散傅里叶变换（Discrete Fourier Transform，简称DFT）。在计算机中一般会使用更高效，更快速的离散傅里叶变换，称为快速傅里叶变换（Fast Fourier Transform，简称FFT），FFT是DFT的快速算法。  我们这里的具体操作是将信号加上滑动时间窗，并对每个时间窗口内的数据进行FFT，这种操作有一个专门的名词，称为短时傅里叶变换（short-term Fourier transform，简称STFT）。  下面我们就拿FFT来说明一下，傅里叶变换具体是一种什么变换。如果用一句话来说明，傅里叶变换就是将时域（Time Domain）信号转换为频域（Frequency Domain）信号。时域信号就是信号强弱与时间的关系，比如一段语音信号跟时间的关系，如图17.7所示。 \\n 图17.7 时域信号 图中的Amplitude表示振幅；Time表示时间；seconds表示秒。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 640}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 641 任何一段复杂的声音信号我们都可以看成是很多个正余弦波叠加得到的，如图17.8所示。 \\n 图17.8 时域转频域 我们用FFT算法把这图17.8段语音信号转换为频域信号以后，会得到图17.9所示。 \\n 图17.9 频域信号  图中Magnitude表示重要性；Frequency表示频率。 频域信号就是信号强弱与频率的关系，横坐标为频率，纵坐标为重要性，信号频率与强弱的关系图也称为频谱图（Spectrum）。这是一段人说话的语音片段，转换为频域信号后\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 641}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 642 我们可以看到在这段语音中低频的信号比较强，比如250Hz和450Hz左右的信号是最强的，高频的信号很弱。关于FFT的具体细节大家有兴趣的话可以再自行研究，这里我们就不展开介绍了。  对一段语音数据进行STFT以后，得到的结果如图17.10所示。 \\n 图17.10 STFT  图中FFT的结果可以看到不同的频率有不同的灰度值，这里的灰度值表示数值大小，颜色越深表示该频率的振幅越大。使用STFT计算后得到的二维信号我们称之为声谱图（Spectrogram）。 17.2.4 梅尔滤波器组（Mel Filter Banks）  梅尔滤波器组是模拟人耳听力特点设计出来的一组滤波器。前面我们有提到过人耳对低频信号比较敏感，对高频信号不太敏感。比如我们很容易区分500Hz和1000Hz这两个声音信号，但是比较难区分18000Hz和18500Hz这两个声音信号。梅尔滤波器可以模拟人类对声音频率非线性的感知能力，对信号进行进一步的特征提取。梅尔m与赫兹f的转换关系如下： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 642}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 643 𝑚=2595𝑙𝑜𝑔\"<(1+𝑓700)(17.1) 𝑓=700(10\\x82#°í°−1)(17.2)  梅尔Mels与赫兹Hz的关系如图17.11所示。 \\n 图17.11梅尔（Mels）与赫兹（Hz）的关系 下面举例说明一下这些滤波器如何生成。梅尔滤波器组的个数是可以人为设置的，一般设置为40。假设现在我们设置为10个滤波器，10个滤波器需要10+2=12个频率点（这里的2表示最小频率点和最大频率点）。比如我们使用的采样频率是8000Hz，根据Nyquist采样定理，我们采集到的信号频率上限为4000Hz，4000Hz根据公式17.1计算约等于2146.06Mels。现在我们从0-2146.06均匀划分12个点，得到： m(i) = 0，195.10，390.19，585.29，780.39，975.48，1170.58，1365.68，1560.77，1755.87，1950.97，2146.06  这12个Mels转换为Hz等于：  h(i) = 0，132.30，289.60，476.64，699.02，963.44，1277.83，1651.64，2096.10，2624.56，3252.90，4000 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 643}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 644  根据这12个Hz频率点可以得到10个三角滤波器。三角滤波器的特点是三角形区域以外的信号都会被过滤掉，在三角形区域内中间的信号比较强，两边的信号会被减弱。第一个滤波器从第1个频率点开始，在第2个频率点达到最大值1，然后在第3个频率点降为0；第二个滤波器从第2个频率点开始，在第3个频率点达到最大值1，然后在第4个频率点降为0。以此类推得到10个三角滤波器，如图17.12所示。 \\n 图17.12 10个梅尔滤波器组  图中Amplitude表示重要性；Frequency表示频率。 接下来使用梅尔滤波器组对经过STFT计算后得到的声谱图Spectrogram进行滤波，得到梅尔频谱（Mel Spectrogram），如图17.13所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 644}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 645 \\n 图17.13梅尔频谱（Mel Spectrogram）  图17.13为图17.7语音数据对应的梅尔频谱，梅尔滤波器组的个数为40。到这里通过梅尔滤波器组（Mel Filter Banks）计算得到的梅尔频谱（Mel Spectrogram）就可以用来作为这一段语音的特征数据了。然后再使用CNN或者是RNN网络就可以对于这段语音的特征数据进行进一步的分析和预测。 17.2.5 梅尔频率倒谱系数MFCC  在介绍MFCC具体怎么计算之前，我们先介绍一下相关背景。如图17.14所示为一段语音的频谱图。 \\n 图17.14 频谱图 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 645}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 646  峰值就表示语音的主要频率成分，我们把这些峰值称为共振峰（Formants）。共振峰携带了声音的辨识属性，用它就可以识别不同的声音。 我们可以把共振峰提取出来，不仅要提取共振峰的位置，还要提取它们的变化过程，得到包络（Spectral Envelope）。包络就是一条将所有共振峰连接起来的平滑曲线，如图17.15所示。 \\n 图17.15 包络 我们可以认为频谱信号是由包络和包络细节（Spectral Details）组成，如图17.16所示。 \\n 图17.16频谱信号的组成  我们可以认为包络是比较重要的特征，包络细节是不太重要的特征，甚至可能是噪声。现在我们要转换一下思维，如果我们把图中的横坐标Frequency看成是时间，把包络和包络\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 646}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 647 细节看成是波形。那包络的波形属于低频信号，包络细节的波形属于高频信号。那也就是说频谱图中的低频信号是重要特征，高频信号不太重要。  所以我们可以对频谱图再做一次FFT，得到频谱图的倒谱（Cepstrum）。倒谱这个词的英文Cepstrum实际上就是频谱图的英文Spectrum前四个字母顺序颠倒过来得到的。在倒谱中的频率称为伪频率（Pseudo-Frequency），因为它不是真正的音频信号的频率，它表示的是频谱图中波形的频率。 根据我们前面所说，倒谱中的伪频率低频信号是重要特征，所以我们可以只取倒谱中低频信号的特征值，舍弃倒谱中高频信号的特征。具体取多少个倒谱中的低频信号，可以人为设置，对于ASR任务一般取前12-20个。 MFCC信号的具体计算是对梅尔频谱再做一次离散余弦变换（Discrete Fourier Transform，简称DCT），DCT类似于DFT，DCT只使用实数。然后取倒谱中前n个低频信号，n可以人为设置。MFCC可以看成是对梅尔频谱的进一步特征提取，可以得到更适合ASR任务的特征。语音信号是时域连续的，分帧提取的信息只反应了本帧语音的特性，我们还可以计算MFCC的差分信号，常用的是一阶差分和二阶差分，差分的简单计算公式如下： 𝑑(𝑡)=𝑐Ã\\x97\"−𝑐Ã\\x7f\"2\\t\\t\\t\\t\\t\\t\\t\\t(17.3)  其中c为MFCC中的倒谱特征，t为时间，也可以理解为第t帧，d为差分特征。使用原始MFCC的值可以计算出一阶差分∆𝑀𝐹𝐶𝐶，然后使用∆𝑀𝐹𝐶𝐶又可以计算出二阶差分∆#𝑀𝐹𝐶𝐶。实际计算时差分计算公式不一定用的是这一个，也可以使用其他的差分计算公式。图17.7语音数据的MFCC，∆𝑀𝐹𝐶𝐶，∆#𝑀𝐹𝐶𝐶结果如图17.17所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 647}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 648 \\n  图17.17 MFCC及其一阶差分和二阶差分  差分信号可以计算也可以不计算，计算差分信号相当于可以得到多一些特征。得到MFCC后再使用CNN或者是RNN网络就可以对于这段语音的特征数据进行进一步的分析和预测。  17.3 语音分类项目 17.3.1 音频处理库librosa介绍  语音信号有很多复杂的处理流程，因此使用一个封装好的python模块会让事情变得简单很多，下面我们要使用一个专门做音频数据处理的模块librosa。首先，先进行librosa的安装，同样也是打开命令提示符，输入命令： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 648}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 649  pip install librosa  安装好以后就可以使用librosa进行一些音频数据的处理了，我们需要准备一些音频文件，如果你暂时找不到音频文件，那么在下面这个地址可以下载到一些音频文件的demo：http://www.voiptroubleshooter.com/open_speech/american.html。 librosa基本操作的代码如代码17-1所示。 代码17-1：librosa基本操作（片段1） import matplotlib.pyplot as plt import librosa import librosa.display import sklearn import IPython.display as ipd # 播放音频文件 ipd.Audio('OSR_us_000_0010_8k.wav') # 读取一段音频文件 # sr=None表示不设置采样率，默认会使用音频文件自身的采样率 # duration=3.5表示读取该文件前3.5秒的数据 # 读取文件后返回文件数据signal和采样率sample_rate signal,sample_rate  = librosa.load('OSR_us_000_0010_8k.wav', sr=None, duration=3.5) print('sample_rate:',sample_rate) print('signal:',len(signal)) 结果输出为： sample_rate: 8000 signal: 28000  代码17-1：librosa基本操作（片段2） # 画出音频数据的波形图 librosa.display.waveplot(signal, sample_rate) plt.show() 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 649}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 650 \\n  代码17-1：librosa基本操作（片段3） # 提取梅尔频谱特征 # n_fft为FFT窗口长度，hop_length为帧移，n_mels为滤波器个数 melspec = librosa.feature.melspectrogram(signal, sample_rate, n_fft=1024, hop_length=512, n_mels=40) # 取对数 logmelspec = librosa.power_to_db(melspec) # 画出梅尔频谱特征Mel Spectrogram # fmax为最大频率 librosa.display.specshow(logmelspec, sr=sample_rate, fmax=4000, x_axis='time', y_axis='hz') # 设置title plt.title('Mel Spectrogram') # 显示颜色数值 plt.colorbar() plt.show() 结果输出为： \\n  代码17-1：librosa基本操作（片段4） # 计算mfcc,n_mfcc为每帧数据mfcc特征数量 mfcc = librosa.feature.mfcc(signal,sample_rate,n_mfcc=20) # 数据标准化 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 650}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 651 mfcc = sklearn.preprocessing.scale(mfcc, axis=1) # 画出mfcc频谱图 librosa.display.specshow(mfcc,sr=sample_rate) plt.title(\\'MFCC\\') plt.colorbar() plt.show() 结果输出为： \\n  17.3.2 音频分类项目-模型训练  这里我们使用的分类数据集为UrbanSound，数据集地址为https://urbansounddataset.weebly.com/。如果大家有其他数据集的话也可以使用其他数据集。UrbanSound数据集有10个种类的声音，分别是0冷气机，1汽车喇叭，2孩子声音，3狗叫声，4电钻声，5发动机声音，6枪声，7手提钻，8警报声，9街头音乐声。原始数据一共有10个文件夹，每个文件夹里有800多个音频文件，每个文件为某种声音类型的音频数据，时长为几秒。由于数据比较大，所以只使用了其中3个文件夹，大约2500个音频文件。音频文件名中包含标签信息，标签为文件名中的第二个数字，如“7061-6-0-0.wav”标签为6枪声，“9031-3-2-0.wav”标签为3狗叫声，具体实现代码如代码17-2所示。 代码17-2：音频分类项目-模型训练（片段1） import warnings warnings.filterwarnings(\"ignore\") import glob \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 651}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 652 import os # 需要安装tqdm，用于查看进度条 # pip install tqdm from tqdm import tqdm  # pip install librosa import librosa import numpy as np import sklearn from sklearn.model_selection import train_test_split # pip install plot_model from plot_model import plot_model # 音频文件存放位置 # 在'audio/'文件夹下还有fold1，fold2，fold3这3个文件夹 audio_dir = 'audio/' # 批次大小 batch_size = 64 # 训练周期 epochs = 500 # 获取所有wav文件 def get_wav_files(audio_dir):     # 用于保存音频文件路径     audio_files = []     # 循环文件夹     for sub_file in os.listdir(audio_dir):         # 得到文件完整路径         file = os.path.join(audio_dir,sub_file)         # 如果是文件夹         if os.path.isdir(file):             # 得到file文件夹下所有'*.wav'文件             audio_files += glob.glob(os.path.join(file, '*.wav'))     return audio_files  # 获取文件mfcc特征和对应标签 def extract_features(audio_files):     # 用于保存mfcc特征     audio_features = []     # 用于保存标签     audio_labels = []     # 由于特征提取需要时间比较长，可以加上tqdm实时查看进度     for audio in tqdm(audio_files):         # 读入音频文件         # 由于音频文件原始采样率高低不一，这里我们把采样率固定为22050         signal,sample_rate = librosa.load(audio,sr=22050) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 652}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 653         # 由于音频长度长短不一，基本上都在4秒左右，所以我们把所有音频数据的长度都固定为4秒         # 采样率22050，时长为4秒，所以信号数量为22050*4=88200         # 小于88200填充         if len(signal)<88200:             # 给signal信号前面填充0个数据，后面填充88200-len(signal)个数据，填充值为0             signal = np.pad(signal,(0,88200-len(signal)),'constant',constant_values=(0))         # 大于88200，只取前面88200个数据         else:             signal = signal[:88200]         # 获取音频mfcc特征，然后对数据进行转置         # 原始mfcc数据shape为(mfcc特征数，帧数)->(帧数，mfcc特征数)         # 相当于把序列长度的维度放前面，特征数的维度放后面         mfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0])         # 数据标准化         mfcc = sklearn.preprocessing.scale(mfcc, axis=0)         # 保存mfcc特征         audio_features.append(mfcc.tolist())          # 获取label         # 获取文件名第2个数字，第2个数字为标签         label = audio.split('/')[-1].split('-')[1]         # 保存标签         audio_labels.append(int(label))      return np.array(audio_features), np.array(audio_labels)  # 获取所有wav文件 audio_files = get_wav_files(audio_dir) print('文件数量：',len(audio_files)) 结果输出为： 文件数量： 2685  代码17-2：音频分类项目-模型训练（片段2） # 获取文件mfcc特征和对应标签 audio_features,audio_labels = extract_features(audio_files) # 切分训练集和测试集 x_train,x_test,y_train,y_test = train_test_split(audio_features,audio_labels)  from tensorflow.keras.models import Sequential,Model from tensorflow.keras.layers import Conv1D,GlobalMaxPool1D,AlphaDropout,Dense,Input,concatenate from tensorflow.keras.optimizers import Adam \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 653}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 654 from tensorflow.keras.activations import selu from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,ReduceLROnPlateau from tensorflow.keras.regularizers import l2 # 定义模型输入 inputs = Input(shape=(x_train.shape[1:])) # 定义1维卷积，权值初始化使用lecun_normal，主要是为了跟selu搭配 x0 = Conv1D(filters=256, kernel_size=3, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=l2(0.0001))(inputs) x0 =GlobalMaxPool1D()(x0) # 定义1维卷积 x1 = Conv1D(filters=256, kernel_size=4, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=l2(0.0001))(inputs) x1 =GlobalMaxPool1D()(x1) # 定义1维卷积 x2 = Conv1D(filters=256, kernel_size=5, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=l2(0.0001))(inputs) x2 =GlobalMaxPool1D()(x2) # 合并特征 x = concatenate([x0,x1,x2],axis=-1) # 可以用AlphaDropout保持信号均值和方差不变，AlphaDropout一般跟selu搭配 x = AlphaDropout(0.5)(x) # 10分类 preds = Dense(10, activation='softmax', kernel_initializer='lecun_normal')(x) # 定义模型 model = Model(inputs, preds) # 画结构图 plot_model(model, dpi=200) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 654}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 655 \\n  代码17-2：音频分类项目-模型训练（片段3） # 定义优化器 # 因为标签没有转独热编码，所以loss用sparse_categorical_crossentropy model.compile(optimizer=Adam(0.01),                 loss='sparse_categorical_crossentropy',                 metrics=['accuracy'])  # 监控指标统一使用val_accuracy # 可以使用EarlyStopping来让模型停止，连续40个周期val_accuracy没有下降就结束训练 # ModelCheckpoint保存所有训练周期中val_accuracy最高的模型 # ReduceLROnPlateau学习率调整策略，连续20个周期val_accuracy没有提升，当前学习率乘以0.1 callbacks = [EarlyStopping(monitor='val_accuracy', patience=40, verbose=1),              ModelCheckpoint('audio_model/'+'cnn_{val_accuracy:.4f}.h5', monitor='val_accuracy', save_best_only=True),              ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=20, verbose=1)]  # 模型训练 history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), callbacks=callbacks) \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 655}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 656  模型训练最后得到测试集准确率大概为90%左右。 17.3.3 音频分类项目-模型预测  下面我们再看一下模型预测程序，单独准备一些音频测试文件，存放在”audio_test”文件夹下面，具体实现如代码17-3所示。 代码17-3：音频分类项目-模型预测（片段1） import warnings warnings.filterwarnings(\"ignore\") import librosa from tensorflow.keras.models import load_model import glob import os from tqdm import tqdm import numpy as np import sklearn # 测试文件存放路径 audio_dir = \\'audio_test/\\' # 载入模型 model = load_model(\\'audio_model/cnn_0.8943.h5\\') # 获取文件mfcc特征和对应标签 def extract_features(audio_files):     # 用于保存mfcc特征     audio_features = []     # 用于保存标签     audio_labels = []     # 由于特征提取需要时间比较长，可以加上tqdm实时查看进度     for audio in tqdm(audio_files):         # 读入音频文件         # 由于音频文件原始采样率高低不一，这里我们把采样率固定为22050         signal,sample_rate = librosa.load(audio,sr=22050)         # 由于音频长度长短不一，基本上都在4秒左右，所以我们把所有音频数据的长度都固定为4秒         # 采样率22050，时长为4秒，所以信号数量为22050*4=88200         # 小于88200填充         if len(signal)<88200:             # 给signal信号前面填充0个数据，后面填充88200-len(signal)个数据，填充值为0             signal = np.pad(signal,(0,88200-len(signal)),\\'constant\\',constant_values=(0))         # 大于88200，只取前面88200个数据 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 656}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 657         else:             signal = signal[:88200]         # 获取音频mfcc特征，然后对数据进行转置         # 原始mfcc数据shape为(mfcc特征数，帧数)->(帧数，mfcc特征数)         # 相当于把序列长度的维度放前面，特征数的维度放后面         mfcc = np.transpose(librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40), [1,0])         # 数据标准化         mfcc = sklearn.preprocessing.scale(mfcc, axis=0)         # 保存mfcc特征         audio_features.append(mfcc.tolist())          # 获取label         # 获取文件名第2个数字，第2个数字为标签         label = audio.split('/')[-1].split('-')[1]         # 保存标签         audio_labels.append(int(label))      return np.array(audio_features), np.array(audio_labels)  # 获取所有wav文件 audio_files = glob.glob(os.path.join(audio_dir, '*.wav')) print('文件数量：',len(audio_files)) 结果输出为： 文件数量： 10  代码17-3：音频分类项目-模型预测（片段2） # 获取文件mfcc特征和对应标签 audio_features,audio_labels = extract_features(audio_files) # 把测试数据当作一个批次进行预测 preds = model.predict_on_batch(audio_features) # 计算概率最大的类别 preds = np.argmax(preds, axis=1) print('真实标签为：',audio_labels) print('预测结果为：',preds) 结果输出为： 真实标签为： [3 0 5 1 8 7 9 5 2 1] 预测结果为： [3 0 5 1 8 7 9 5 2 1]    \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 657}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 658 第18章 图像风格转换 图像风格转换对应的英文为Image Style Transfer，意思将两个图像，一张内容图像A，一张风格图像B混合在一起，使得输出的图像内容像A，风格像B，如图18.1所示。 \\n 图18.1 图像风格转换[1]  18.1 图像风格转换实现原理 下面主要以《A Neural Algorithm of Artistic Style》[1]这篇论文的思路给大家介绍一下图像风格转换如何实现。我们在之前学习卷积网络的时候有介绍过，卷积的功能主要是特征提取，那么经过大量训练的卷积网络就可以具备良好的特征提取能力。并且，不同的卷积层\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 658}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 659 可以提取不同的特征。一般来说，浅层的卷积主要是提取图像边缘轮廓的特征，而深层的卷积则是提取图像更抽象的特征。因此我们可以选用一个经过预训练的图像识别卷积网络来作为特征提取器，比如可以选择VGG16。 图像风格转换的模型训练其实跟其他的深度学习模型训练类似，模型中有一些需要训练的权值，在图像风格变换中模型需要训练的权值是生成图片的像素值。我们一般使用内容图片来初始化生成图片的像素值，之后生成图片的像素值会随着模型的训练不断变化。我们还需要定义一个代价函数，然后使用优化器最小化代价函数的值。所以这里的重点在于这个代价函数如何定义。  18.1.1 代价函数的定义  我们把代价函数分为内容content loss和风格style loss。Content loss表示生成出来的新图片与作为内容的图片A之间的loss；style loss表示生成出来的新图片与作为风格的图片B之间的loss，总的代价函数公式为： 𝐿ÃÒÃð\\x84=𝛼𝐿ÓÒ@Ã¤@Ã+𝛽𝐿ÞÃÐ\\x84¤(18.1)  其中𝐿ÓÒ@Ã¤@Ã表示content loss，𝐿ÞÃÐ\\x84¤表示style loss，𝛼表示content loss的权重，𝛽表示style loss的权重，权重的值可以人为设定。𝐿ÓÒ@Ã¤@Ã和𝐿ÞÃÐ\\x84¤的计算如图18.2所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 659}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 660 \\n 图18.2 loss计算  图中的卷积网络为一个经过预训练的VGG16模型，在计算𝐿ÞÃÐ\\x84¤时使用的卷积层为Conv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1，𝐿ÞÃÐ\\x84¤的计算公式为： 𝐸==?(𝐺=−𝑆=)#(18.2) 𝐿ÞÃÐ\\x84¤=?𝑤\\x84𝐸\\x84(18.3)  其中L表示不同的卷积层，G为生成图片的特征图计算得到的格拉姆矩阵（Gram Matrix），S为风格图片的特征图计算得到的格拉姆矩阵。这里计算格拉姆的原因是我们可以使用格拉姆矩阵来表示一副图片的风格，关于格拉姆矩阵的具体计算后面再介绍。总之，我们可以计算出风格图片和生成图片Conv1_1，Conv2_1，Conv3_1，Conv4_1，Conv5_1这5个卷积层输出的特征图所计算得到的Gram矩阵𝑆=和𝐺=，根据𝑆=和𝐺=来计算𝐸=。把所有\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 660}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 661 𝐸\\x84乘以对应权重𝑤\\x84，再累加起来得到𝐿ÞÃÐ\\x84¤。权重𝑤\\x84可以人为设置，一般设置为1/5，即所有卷积层的特征权重相等。  在计算𝐿ÓÒ@Ã¤@Ã时使用的是Conv5_2输出的特征图，也可以取多个卷积层输出，不过效果变化不大，𝐿ÓÒ@Ã¤@Ã的计算公式为： 𝐿ÓÒ@Ã¤@Ã=?(𝐺\\x84−𝐶\\x84)#(18.3)  其中𝐺\\x84为生成图片Conv5_2输出的特征图，𝐶\\x84为内容图片Conv5_2输出的特征图。注意在计算𝐿ÓÒ@Ã¤@Ã的时候这里是直接对比特征图𝐺\\x84和特征图𝐶\\x84，并没有计算Gram矩阵。因为计算Gram矩阵可以得到特征图和特征图之间的相关性，对于表示图片的风格是有意义的，跟图片的内容关系不大。  当我们使用优化器最小化代价函数的时候，相当于是在对比风格图片和生成图片的图像风格，然后使得图片风格的差异越小越好；然后再对比生成图片和内容图片的内容特征，然后使得图片内容特征的差异越小越好。生成图片的像素值经过不断的变化，就可以得到风格转换后的结果。  18.1.2 格拉姆矩阵（Gram Matrix）介绍  上一小节我们有提到，在计算图像风格的时候用到了格拉姆矩阵（Gram Matrix），那么这一小节我们主要来介绍一下格拉姆矩阵是如何计算的。 我们使用图像经过卷积计算后得到的特征图来计算Gram矩阵，然后用Gram矩阵表示图像风格。在计算Gram矩阵前，我们先把2维的特征图变成1维的特征向量，如图18.3所示。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 661}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 662 \\n 图18.3 把2维特征图变成1维特征向量  假设我们现在一共有5张特征图，如图所示。特征图的宽为𝑛>，高为𝑛?，所以展开成1维后，得到的特征图矩阵的列数为𝑛?×𝑛>，行数为特征图数量5。  接下来的计算如图18.4所示。 \\n 图18.4 Gram矩阵计算  把前面得到的特征图矩阵乘以该特征图矩阵的转置，得到的结果就是Gram矩阵。在上面这个例子中，因为一共有5张特征图，所以最后得到的Gram矩阵为5×5的矩阵。Gram矩阵可以把图像特征之间的联系提取出来，也就是可以得到特征之间的相关性。所以在图像风格转换中，可以使用Gram矩阵来表示图像的特征。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 662}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 663 18.2 图像风格转换项目实战  在运行程序之前，大家可以自己收集一些风格图片和内容图片，然后尝试使用不同的照片看看可以得到什么结果。也可以尝试设置不同的loss权重，看看图片的变化情况。实现图像风格装换的代码如代码18-1所示。 代码18-1：图像风格转换（片段1） import matplotlib.pyplot as plt import tensorflow as tf import numpy as np from PIL import Image # 设置最长的一条边的长度 max_dim = 800 # 内容图片路径 content_path = '臭臭.jpeg' # 风格图片路径 style_path = 'starry_night.jpg' # 风格权重 style_weight=10 # 内容权重 content_weight=1 # 全变差正则权重 total_variation_weight=1e5 # 训练次数 stpes = 301 # 是否保存训练过程中产生的图片 save_img = True  # 载入图片 def load_img(path_to_img):     # 读取文件内容     img = tf.io.read_file(path_to_img)     # 变成3通道图片数据     img = tf.image.decode_image(img, channels=3, dtype=tf.float32) #     img = tf.image.convert_image_dtype(img, tf.float32)     # 获得图片高度和宽度，并转成float类型     shape = tf.cast(tf.shape(img)[:-1], tf.float32) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 663}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 664     # 最长的边的长度     long_dim = max(shape)     # 图像缩放，把图片最长的边变成max_dim     scale = max_dim / long_dim     new_shape = tf.cast(shape * scale, tf.int32)     # resize图片大小     img = tf.image.resize(img, new_shape)     # 增加1个维度，变成4维数据     img = img[tf.newaxis, :]     return img  # 用于显示图片 def imshow(image, title=None):     # 如图是4维度数据     if len(image.shape) > 3:         # 去掉size为1的维度如(1,300,300,3)->(300,300,3)         image = tf.squeeze(image)     # 显示图片     plt.imshow(image)     if title:         # 设置图片title         plt.title(title)     plt.axis('off')     plt.show()  # 载入内容图片 content_image = load_img(content_path) # 载入风格图片 style_image = load_img(style_path) # 显示内容图片 imshow(content_image, 'Content Image') # 显示风格图片 imshow(style_image, 'Style Image') 结果输出为： \\n \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 664}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 665 \\n  代码18-1：图像风格转换（片段2） # 用于计算content loss # 这里只取了一层的输出进行对比，取多层输出效果变化不大 content_layers = ['block5_conv2']   # 用于计算风格的卷积层 style_layers = ['block1_conv1',                 'block2_conv1',                 'block3_conv1',                  'block4_conv1',                  'block5_conv1']  # 计算层数 num_content_layers = len(content_layers) num_style_layers = len(style_layers) # 创建一个新模型，输入与vgg16一样，输出为指定层的输出 def vgg_layers(layer_names):     # 载入VGG16的卷积层部分     vgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet')     # VGG16的模型参数不参与训练     vgg.trainable = False     # 获取指定层的输出值     outputs = [vgg.get_layer(name).output for name in layer_names]     # 定义一个新的模型，输入与vgg16一样，输出为指定层的输出     model = tf.keras.Model([vgg.input], outputs)     # 返回模型     return model # 获得输出风格层特征的模型 style_extractor = vgg_layers(style_layers) # 图像预处理，主要是减去颜色均值，RGB转BGR preprocessed_input = tf.keras.applications.vgg16.preprocess_input(style_image*255) # 风格图片传入style_extractor，提取风格层的输出 style_outputs = style_extractor(preprocessed_input) \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 665}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 666  # Gram矩阵的计算 def gram_matrix(input_tensor):     # 爱因斯坦求和，bijc表示input_tensor中的4个维度，bijd表示input_tensor中的4个维度     # 例如input_tensor的shape为(1,300,200,32)，那么b=1,i=300,j=200,c=32,d=32     # ->bcd表示计算后得到的数据维度为(1,32,32),得到的结果表示特征图与特征图之间的相关性     result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)     # 特征图的shape     input_shape = tf.shape(input_tensor)     # 特征图的高度乘以宽度得到特征值数量     num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)     # 除以特征值的数量     return result/(num_locations)  # 构建一个返回风格特征和内容特征的模型 class StyleContentModel(tf.keras.models.Model):     def __init__(self, style_layers, content_layers):         super(StyleContentModel, self).__init__()         # 获得输出风格层和内容层特征的模型         self.vgg =  vgg_layers(style_layers + content_layers)         # 用于计算风格的卷积层         self.style_layers = style_layers         # 用于计算content loss的卷积层         self.content_layers = content_layers         # 风格层的数量         self.num_style_layers = len(style_layers)      def call(self, inputs):         # 图像预处理，主要是减去颜色均值，RGB转BGR          preprocessed_input = tf.keras.applications.vgg16.preprocess_input(inputs*255.0)         # 图片传入模型，提取风格层和内容层的输出         outputs = self.vgg(preprocessed_input)         # 获得风格特征输出和内容特征输出         style_outputs, content_outputs = (outputs[:self.num_style_layers],                                            outputs[self.num_style_layers:])         # 计算风格特征的Gram矩阵         style_outputs = [gram_matrix(style_output) for style_output in style_outputs]         # 把风格特征的Gram矩阵分别存入字典         style_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outputs)}         # 把内容特征存入字典 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 666}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 667         content_dict = {content_name:value for content_name, value in zip(self.content_layers, content_outputs)}         # 返回结果         return {'content':content_dict, 'style':style_dict}  # 构建一个返回风格特征和内容特征的模型 extractor = StyleContentModel(style_layers, content_layers) # 计算得到风格图片的风格特征 style_targets = extractor(style_image)['style'] # 计算得到内容图片的内容特征 content_targets = extractor(content_image)['content'] # 初始化要训练的图片 image = tf.Variable(content_image) # 定义优化器 opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1) # 把数值范围限制在0-1之间 def clip_0_1(image):     return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)  # 定义风格和内容loss def style_content_loss(outputs):     # 模型输出的风格特征     style_outputs = outputs['style']     # 模型输出的内容特征     content_outputs = outputs['content']     # 计算风格loss     style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2)                             for name in style_outputs.keys()])     style_loss *= style_weight / num_style_layers     # 计算内容loss     content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2)                               for name in content_outputs.keys()])     content_loss *= content_weight / num_content_layers     # 风格加内容loss     loss = style_loss + content_loss     return loss  # 施加全变差正则，全变差正则化常用于图片去噪，可以使生成的图片更加平滑自然 def total_variation_loss(image):     x_deltas = image[:,:,1:,:] - image[:,:,:-1,:]     y_deltas = image[:,1:,:,:] - image[:,:-1,:,:] \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 667}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 668     return tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)  # 我们可以用@tf.function装饰器来将python代码转成tensorflow的图表示代码，用于加速代码运行速度 @tf.function() # 定义一个训练模型的函数 def train_step(image):     # 固定写法，使用tf.GradientTape()来计算梯度     with tf.GradientTape() as tape:         # 传入图片获得风格特征和内容特征         outputs = extractor(image)         # 计算风格和内容loss         loss = style_content_loss(outputs)         # 再加上全变差正则loss         loss += total_variation_weight*total_variation_loss(image)     # 传入loss和模型参数，计算权值调整     grad = tape.gradient(loss, image)     # 进行权值调整，这里要调整的权值就是image图像的像素值     opt.apply_gradients([(grad, image)])     # 把数值范围限制在0-1之间 image.assign(clip_0_1(image))  # 训练steps次 for n in range(stpes):     # 训练模型     train_step(image)     # 每训练5次打印一次图片     if n%5==0:         imshow(image.read_value(), \"Train step: {}\".format(n))         # 保存图片         if save_img==True:             # 去掉一个维度             s_image = tf.squeeze(image)             # 把array变成Image对象             s_image = Image.fromarray(np.uint8(s_image.numpy()*255))             # 设置保存路径保存图片             s_image.save(\\'temp/\\'+\\'steps_\\'+str(n)+\\'.jpg\\') 结果输出为： ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 668}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 669 \\n …… \\n …… \\n  18.3 遮挡图像风格转换项目实战  我们可以自己制作图片中某些物体的遮挡（Mask），这样可以在做风格转换的时候图片中的某些部分进行了风格转换，某些部分还是保持原有的样子。如图18.5和图18.6所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 669}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 670 \\n 图18.5 遮挡图像风格转换（1） \\n 图18.6 遮挡图像风格转换（2）  图中的左上角的图片内容图片，右上角为风格图片，左下角为遮挡图片，遮挡图片从内容图片中获得，需要自己手动制作。遮挡图片中的白色部分会进行图像风格转换，黑色部分保持不变。右下角为风格转换后的效果。  遮挡图像风格转换其实就是多了一个Mask，其他部分跟之前的图像风格转换是一样的，所以下面只给出遮挡部分的代码，这部分代码放在图像风格转换的代码后面即可，如代码18-2所示。。 代码18-2：遮挡图像风格转换 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 670}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 671 …… # mask图片路径 mask_path = 'mask.jpg' # 载入mask图片 def load_mask(mask_path, shape):     # 读取文件     mask = tf.io.read_file(mask_path)     # 变成图片格式     mask = tf.image.decode_image(mask, channels=1)     mask = tf.image.convert_image_dtype(mask, tf.float32)     # 获得生成图片的宽度和高度     _, width, height, _ = shape     # 把mask图片shape变得跟生成图片一样     mask = tf.image.resize(mask, (width, height))     return mask  # 把mask应用到生成的图片中 def mask_content(content, generated, mask):     # 生成图片的shape     width, height, channels = generated.shape     # 把内容图片变成numpy格式     content = content.numpy()     # 把生成图片变成numpy格式     generated = generated.numpy()     # mask图片黑色部分，把内容图片的像素值填充到生成图片中     for i in range(width):         for j in range(height):             if mask[i, j] == 0.:                 generated[i, j, :] = content[i, j, :]     return generated # 载入mask图片 mask = load_mask(mask_path, image.shape) # 3维降2维 s_mask = tf.squeeze(mask) # 4维降3维 s_image = tf.squeeze(image) # 4维降3维 s_content_image = tf.squeeze(content_image) # 把mask应用到生成的图片中 img = mask_content(s_content_image,s_image,s_mask) # 显示图片 imshow(img)   \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 671}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 672 18.4参考文献  [1] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint arXiv:1508.06576, 2015.                   ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 672}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 673 第19章 生成对抗网络GANs  生成对抗网络（Generative Adversarial Networks，简称GANs）是近几年深度学习领域一个非常热门的新的研究方向。最早是由“深度学习三巨头”之一Yoshua Bengio的学生Ian Goodfellow提出，相关论文为《Generative Adversarial Nets》[1]。经过几年时间的发展，生成对抗网络已经从深度学习的一个新方向发展成为一个庞大的分支，是目前深度学习领域最有发展潜力的算法之一。本书的内容主要还是以入门为主，所以本章节主要还是介绍关于生成对抗网络的基础知识和基本应用。  19.1 生成对抗网络的应用  GANs的应用非常多，下面列举了部分GANs的常见应用。 1.图像生成  你能猜出图19.1中这些人脸的共同点吗？ \\n 图19.1 人脸图片[2] \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 673}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 674  这些图片中的人都不是真人，他们都是由GANs产生的假图片。GANs最擅长做的事就是生成假图片，不只可以生成假的人脸，理论上什么类型的图片它都可以生成。 2.向量空间运算  如图19.2所示，我们可以看到戴眼镜的男人减去男人加上女人可以得到戴眼镜的女人。 \\n 图19.2 向量空间运算[3] 3.图像转换 如图19.4所示，通过简笔画可以转换为真实的物体图像。 \\n 图19.3 图像转换[4] 4.图像风格转换 如图19.4，最左边的一张图片可以转换为右边的4种不同的图像风格。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 674}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 675 \\n 图19.4 图像风格转换[5]  5.文字转图像  如图19.5，给模型传入一段文字，输出的结果为一张图片。 \\n 图19.5 文字转图像[6]  6.图像渐变  如图19.6，一张图片逐渐变化成另一张图片。 \\n \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 675}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 676 19.6 图像渐变[7]  7.超分辨率 如图19.7所示，提升图像的分辨率。 \\n 图19.7 超分辨率[8]  19.2 DCGAN介绍  19.2.1 DCGAN原理  下面我们主要以DCGAN为例，给大家介绍DCGAN的模型设计思路和程序实现，最早提出DCGAN的论文是《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》[3]。  生成对抗网络的核心思想是同时训练两个相互协作，同时又相互竞争的深度神经网络，一个称为生成器 （Generator），另一个称为判别器 （Discriminator）。生成器用来生成假图片，而判别器用来判断图片的真假。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 676}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 677  比如我们可以把警察看成是判别器，把制造假币的犯罪份子看成是生成器。在一开始的时候警察是不知道如何判断真钱和假币的，犯罪份子也不知道如何制造假币，他们会同时开始学习。一段时间后警察的判断能力提高了，他可以识别出哪些是犯罪份子制作的假币，哪些是真钱了，并把识别的过程告诉犯罪份子。犯罪份子根据警察的反馈改进自己的制作工艺，制作出更逼真的假币给警察识别。警察在识别假币的过程中判别能力不断提升，犯罪份子在制作假币的过程中制假能力不断提升。最终犯罪份子可以制作出警察无法判断真假的假币，这个时候模型训练就成功了。  19.2.2 转置卷积（Transposed Convolution）介绍  生成器网络中使用到了转置卷积（Transposed Convolution），所以这里我们先来了解一下。普通的卷积操作是一种下采样（Subsampled）操作，会使得图像的分辨率从大变小。而转置卷积是一种上采样（Upsampling）操作，会使得图像的分辨率从小变大。  下面举两个例子给大家说明。 比如我们使用3×3的卷积核对4×4的图像进行卷积计算，步长为1，Valid Padding，卷积计算后可以得到2×2的特征图，如图19.8所示。 \\n 图19.8 普通卷积（1）  当我们使用同样的条件：3×3的卷积核，步长为1，Valid Padding对2×2的图像进行转置卷积就可以得到4×4的特征图，如图19.9所示。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 677}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 678 \\n 图19.9 转置卷积（1） 比如我们使用3×3的卷积核对5×5的图像进行卷积计算，步长为2，Valid Padding，卷积计算后可以得到2×2的特征图，如图19.10所示。  图19.10 普通卷积（2）  当我们使用同样的条件：3×3的卷积核，步长为2，Valid Padding对2×2的图像进行转置卷积就可以得到5×5的特征图，如图19.11所示。 \\n 图19.11 转置卷积（2）  大家应该能从这里找到些规律了，同样的条件下，对卷积后得到的特征图进行转置卷积可以得到原始图像的大小。不过要注意只是恢复图像的大小，图像的数值不一定会恢复。因为转置卷积的本质还是卷积，转置卷积中的卷积计算跟普通卷积一致，卷积核的具体数值也是需要通过模型训练得到。  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 678}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 679  19.2.3 DCGAN模型结构  下面我们以MNIST数据生成为例来介绍DCGAN的模型结构。DCGAN由两部分模型组成，生成器和判别器，如图19.12所示。 \\n 图19.12 生成器和判别器  判别器的作用是判断一张图片是真还是假，属于二分类问题，所以模型的最后输出只需要1个神经元。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 679}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 680 而生成器的作用是生成假图片，生成器的输入是一个100维的随机数，其实也不一定要是100维，其他任意维度也可以。把随机数加上全连接层再Reshape就可以变成4维图像数据。然后再进行几次转置卷积，使得图像大小不断变大，最后输出28×28的图片。  我们把MNIST数据集中的原始数据看成是真图片，然后把生成器生成的图片看成是假图片。把真图片和假图片都传给判别器进行学习，提升判别器的判断能力，同时利用判别器来提升生成器的造假能力。  19.3 手写数字图像生成 实现手写数字图像生成的代码如代码19-1所示。 代码19-1：手写数字图像生成（片段1） from tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Conv2DTranspose,Reshape,Conv2D,Dropout,Flatten import tensorflow as tf import matplotlib.pyplot as plt import numpy as np import os # Dataset中的buffer buffer_size = 60000 # 批次大小 batch_size = 256 # 训练周期 epochs = 51 # 100维的随机噪声 noise_dim = 100 # 载入MNNIST数据，只需要训练集的图片就可以 (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data() # reshape为4维数据 train_images = train_images.reshape(-1, 28, 28, 1).astype('float32') # 将图片归一化到 [0, 1] 区间内 train_images = train_images/ 255.0 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 680}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 681 # 定义Dataset，用于生成打乱后的批次数据 train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)  # 定义生成器 def generator_model():     # 顺序模型     model = tf.keras.Sequential()     # 传入噪声数据，然后与7*7*256个神经元进行全连接     # 7*7*256主要是为了后面可以Reshape变成(7, 7, 256)     model.add(Dense(7*7*256, input_shape=(noise_dim,)))     model.add(BatchNormalization())     model.add(LeakyReLU())     # 变成4维图像数据(-1,7,7,256)     model.add(Reshape((7, 7, 256)))     # 转置卷积，图像shape变成(-1,7,7,128)     model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))     model.add(BatchNormalization())     model.add(LeakyReLU())     # 转置卷积，图像shape变成(-1,14,14,64)     model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))     model.add(BatchNormalization())     model.add(LeakyReLU())     # 转置卷积，图像shape变成(-1,28,28,1)     # 激活函数使用sigmoid，主要是因为我们把MNIST数据图片归一化为[0,1]之间了，生成的假图片要跟真实图片数据匹配     model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='sigmoid'))     return model  # 定义判别器 def discriminator_model():     # 顺序模型     model = tf.keras.Sequential()     # 传入一张图片数据进行卷积，卷积后图像shape为(1,14,14,64)     model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))     model.add(LeakyReLU())     model.add(Dropout(0.3))     # 卷积后图像shape为(1,7,7,128)     model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))     model.add(LeakyReLU())     model.add(Dropout(0.3)) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 681}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 682     model.add(Flatten())     # 最后输出一个值，激活函数为sigmoid函数，用于判断图片的真假     model.add(Dense(1, activation='sigmoid'))     return model  # 创建生成器模型 generator = generator_model() # 创建判别器模型 discriminator = discriminator_model() # 生成随机数 noise = tf.random.normal([1, noise_dim]) # 传入生成器生成一张图片 generated_image = generator(noise, training=False) # 显示出图片，刚开始模型还没有训练，所以生成的图片会得到噪声图片 plt.imshow(generated_image[0, :, :, 0], cmap='gray') plt.show() 结果输出为： \\n  代码19-1：手写数字图像生成（片段2） # 定义2分类交叉熵代价函数 cross_entropy = tf.keras.losses.BinaryCrossentropy()  # 判别器loss，传入对真实图片的判断结果以及对假图片的判断结果 def discriminator_loss(real_output, fake_output):     # tf.ones_like(real_output)表示对真实图片的判断结果应该全为1     real_loss = cross_entropy(tf.ones_like(real_output), real_output)     # tf.zeros_like(fake_output)表示对假图片的判断结果应该全为0     fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)     # 求总loss，再返回     total_loss = real_loss + fake_loss return total_loss  # 生成器loss，传入判别器对假图片的判断结果 \\n\", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 682}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 683 def generator_loss(fake_output):     # 对于生成器来说，生成器希望判别器对假图片的判断结果都是1     # 所以标签设定为tf.ones_like(fake_output)，全为1     # 生成器模型在训练过程中会不断优化自身参数，使得模型生成逼真的假图片     return cross_entropy(tf.ones_like(fake_output), fake_output) # 由于我们需要分别训练两个网络，判别器和生成器的优化器是不同的。 generator_optimizer = tf.keras.optimizers.Adam(3e-4) discriminator_optimizer = tf.keras.optimizers.Adam(1e-4) # 把生成器模型和判别器模型以及对应的优化器存入checkpoint checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,                                  discriminator_optimizer=discriminator_optimizer,                                  generator=generator,                                  discriminator=discriminator) # 用于管理模型 # checkpoint为需要保存的内容 # 'checkpoint_dir'为模型保存位置 # max_to_keep设置最多保留几个模型 manager = tf.train.CheckpointManager(checkpoint, 'checkpoint_dir', max_to_keep=3)  # 我们将重复使用该随机数，这个随机数用于在训练过程中生成图片并显示和保存 seed = tf.random.normal([16, noise_dim])  # 我们可以用@tf.function装饰器来将python代码转成tensorflow的图表示代码，用于加速代码运行速度 @tf.function # 定义模型的训练 def train_step(images):     # 生成一个批次的随机数，这个随机数用于模型训练     noise = tf.random.normal([batch_size, noise_dim])     # 固定写法，使用tf.GradientTape()来计算梯度     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:         # 产生一个批次的假图片         generated_images = generator(noise, training=True)         # 传入真图片到判别器中，得到预测结果         real_output = discriminator(images, training=True)         # 传入假图片到判别器中，得到预测结果         fake_output = discriminator(generated_images, training=True)         # 计算生成器loss         gen_loss = generator_loss(fake_output)         # 计算判别器loss         disc_loss = discriminator_loss(real_output, fake_output)     # 传入loss和模型参数，计算生成器的权值调整     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 683}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 684     # 传入loss和模型参数，计算判别器的权值调整     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)     # 生成器的权值调整     generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))     # 判别器的权值调整     discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))  # 生成图片并保存显示 def generate_and_save_images(model, epoch, test_input):     # 注意training设定为False，所有层都在预测模式下运行     predictions = model(test_input, training=False)     # 画16张子图     for i in range(16):         plt.subplot(4, 4, i+1)         # 显示图片         plt.imshow(predictions[i, :, :, 0], cmap='gray')         # 不显示刻度         plt.axis('off')     # 保存图片     plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))     # 显示图片     plt.show() # 训练模型 def train(dataset, epochs):     # 训练epochs周期     for epoch in range(epochs):         # 每次获得一个批次的真实图片传入train_step函数进行训练         for image_batch in dataset:             train_step(image_batch)         # 显示和保存图片         generate_and_save_images(generator, epoch, seed)         # 每 5 个 epoch 保存一次模型         if epoch % 5 == 0:             # 保存模型             # checkpoint_number设置模型编号             manager.save(checkpoint_number=epoch)  # 模型训练 train(train_dataset, epochs) 结果输出为： \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 684}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 685 \\n …… \\n …… \\n   最后训练得到的生成图片已经比较接近真实的MNIST数据集的图片了，有些假图片看起来就跟真的一样。  19.4参考文献 [1] Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative adversarial nets[C]//Advances in neural information processing systems. 2014: 2672-2680. \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 685}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 686 [2] Karras T, Laine S, Aila T. A style-based generator architecture for generative adversarial networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2019: 4401-4410. [3] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks [J]. arXiv preprint arXiv:1511.06434, 2015. [4] Isola P, Zhu J Y, Zhou T, et al. Image-to-image translation with conditional adversarial networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1125-1134. [5] Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-consistent adversarial networks[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2223-2232. [6] Zhang H, Xu T, Li H, et al. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks[C]//Proceedings of the IEEE international conference on computer vision. 2017: 5907-5915. [7] Brock A, Donahue J, Simonyan K. Large scale gan training for high fidelity natural image synthesis[J]. arXiv preprint arXiv:1809.11096, 2018. [8] Ledig C, Theis L, Huszár F, et al. Photo-realistic single image super-resolution using a generative adversarial network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4681-4690.   ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 686}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 687 第20章 模型部署 这一章节我们来了解一下模型部署。深度学习的模型训练好以后要在工程中应用，需要部署到服务器中。其实就是我们需要运行一个用于数据预测的后台服务程序，这个后台服务程序中运行着我们训练好的模型，然后等待其他客户端程序把数据传给用于数据预测的后台服务程序。后台服务程序把接收到的数据传给模型进行预测，再把模型的预测结果返回给客户端程序。如图20.1所示。 \\n 图20.1   后台的服务程序可以自行编写，也可以使用谷歌官方提供的模型部署工具Tensorflow Serving。推荐在Docker中搭建Tensorflow Serving。  20.1 Tensorflow Serving环境部署  Tensorflow Serving是一个用于为机器学习模型提供灵活高性能服务的系统，专为生产环境设计。使用Tensorflow Serving我们可以很容易的部署新的模型到生产环境中。 Tensorflow Serving有多种安装方式，不过Tensorflow官方建议我们使用Docker来安装Tensorflow Serving，所以下面给大家介绍在Docker中搭建Tensorflow Serving的\\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 687}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 688 环境的方法。Docker是一种轻量级的虚拟化技术，和传统的虚拟机不同，Docker启动速度更快，性能更好，占用的内存和硬盘空间小，并且具有更好的迁移性，所以近几年得到了快速发展和大规模的应用。  20.1.1 安装Docker  首先第一步我们需要先安装Docker，Docker可以在Linux，MacOS和Windows环境下安装，软件下载的官网地址为：https://docs.docker.com/get-docker/。具体安装方式可以查看官网说明。  如果我们需要使用GPU的话，还需要安装NVIDIA的Docker工具nvidia-docker，安装方式可以查看：https://github.com/NVIDIA/nvidia-docker#quick-start。不过nvidia-docker目前只支持Linux的系统。  20.1.2 拉取Tensorflow Serving镜像  安装并运行Docker以后，在命令提示符中执行：  docker pull tensorflow/serving  默认下载最新版本的Tensorflow Serving镜像。如果是下载最新版本的GPU版本的镜像，可以执行：  docker pull tensorflow/serving:latest-gpu  ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 688}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 689 20.2 运行客户端和服务器程序  20.2.1 准备SavedModel模型  在本书第7章，介绍Tensorflow模型的保存和载入的时候，有介绍过SavedModel是Tensorflow中一种模型的格式，它的优点是与语言无关。在Tensorflow Serving中所使用的模型要求必须为SavedModel格式的模型。下面作为演示，我们可以先产生一个SavedModel模型，如代码20-1所示。 代码20-1：生成SavedModel模型 import tensorflow as tf from tensorflow.keras.optimizers import SGD  # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)  # 模型定义 model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28), name='image'),   tf.keras.layers.Dense(10, activation='softmax', name='output') ])  # 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd,               loss='mse',               metrics=['accuracy'])  # 传入训练集数据和标签训练模型 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 689}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 690 model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test,y_test)) # 保存模型为SavedModel格式 # 1在这里用于表示模型的版本号 model.save('my_model/1')  结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/3 60000/60000 [==============================] - 2s 32us/sample - loss: 0.0368 - accuracy: 0.7843 - val_loss: 0.0212 - val_accuracy: 0.8808 Epoch 2/3 60000/60000 [==============================] - 2s 33us/sample - loss: 0.0202 - accuracy: 0.8820 - val_loss: 0.0175 - val_accuracy: 0.8964 Epoch 3/3 60000/60000 [==============================] - 2s 30us/sample - loss: 0.0177 - accuracy: 0.8937 - val_loss: 0.0160 - val_accuracy: 0.9040  我们训练了一个MNIST图像识别模型，设置了模型的输入名称为“image”，模型的输出名称为“output”，后面会用到。然后把模型保存到“my_model/1”文件夹中，这里的1表示模型的版本号。  20.2.2 启动Tensorflow Serving服务器程序  接下来我们就可以启动Tensorflow Serving的服务器程序了，就是我们需要运行一个后台程序，在这个后台程序中载入SavedModel模型，等待客户端程序传输数据。Tensorflow Serving支持gRPC和REST API两种请求方式。  我们需要在命令提示符中运行下面格式的命令，如图20.2所示。 \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 690}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 691 \\n 图20.2 启动服务器程序命令  首先大家要注意这是一条比较长的命令，为了让大家看清楚，所以我把这条长命令分为了很多行。大家在命令行中运行的时候需要把“\\\\”符号去掉，然后组成一条连续的长命令。还有就是大家需要注意什么地方有空格，什么地方没有空格，需要跟图中一致。比如“run”，“-p”，“--mount”，“-e”，”-t”,“ {gRPC}:{gRPC}”，“{Model_Name}”等后面是有空格的；”type=bind,””{SavedModel_Path},”后面是没有空格的。 docker run表示在Docker中运行，{gRPC}表示填入gRPC端口号，可以自定义，{REST API}表示填入REST API端口号，可以自定义。Source={SavedModel_Path}表示填入我们准备的SavedModel模型的路径，注意要填入SavedModel模型所在的绝对路径，不包括版本号。target=/models/{Model_Name}表示把SavedModel模型挂载到Docker中的/models/{Model_Name}文件夹。MODEL_NAME={Model_Name}表示设置模型名字，{Model_Name}表示模型名字，可以自定义。最后的tensorflow/serving表示运行tensorflow/serving。如果要用GPU的话可以改成tensorflow/serving:latest-gpu。当然前提是前面已经安装nvidia-docker并拉取tensorflow/serving:latest-gpu镜像。  我的SavedModel保存在$(pwd)/my_model/1文件夹下，下面给大家看一下我这里运行的一个完整命令，$(pwd)表示当前位置的绝对路径： \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 691}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 692 docker run -p 8500:8500 -p 8501:8501 --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving  如果运行成功的话，会看到很多输出信息，如： 2020-05-23 10:04:05.996573: I tensorflow_serving/model_servers/server.cc:86] Building single TensorFlow model file config:  model_name: my_model model_base_path: /models/my_model 2020-05-23 10:04:05.998649: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models. 2020-05-23 10:04:05.998684: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: my_model 2020-05-23 10:04:06.126071: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: my_model version: 1} 2020-05-23 10:04:06.126126: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: my_model version: 1} 2020-05-23 10:04:06.126144: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: my_model version: 1} 2020-05-23 10:04:06.126589: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /models/my_model/1 2020-05-23 10:04:06.133228: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve } 2020-05-23 10:04:06.133263: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /models/my_model/1 2020-05-23 10:04:06.134544: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2020-05-23 10:04:06.184545: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle. 2020-05-23 10:04:06.241474: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /models/my_model/1 2020-05-23 10:04:06.245208: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 118607 microseconds. ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 692}),\n",
       " Document(page_content=\"免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 693 2020-05-23 10:04:06.246544: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/my_model/1/assets.extra/tf_serving_warmup_requests 2020-05-23 10:04:06.258998: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: my_model version: 1} 2020-05-23 10:04:06.265112: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ... [warn] getaddrinfo: address family for nodename not supported 2020-05-23 10:04:06.272848: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 ... [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...  大家看到类似信息说明Tensorflow Serving的服务程序已经在后台运行了，在打印的信息中我们可以看到“Running gRPC ModelServer at 0.0.0.0:8500”和“Exporting HTTP/REST API at:localhost:8501”，这两个信息在客户端程序中需要使用。  20.2.3 Tensorflow Serving客户端gRPC程序  使用gPRC程序我们需要先安装tensorflow-serving-api，打开命令提示符，输入命令： pip install tensorflow-serving-api  然后我们还需要在命令行使用saved_model_cli命令查看SavedModel模型的一些基本信息：  saved_model_cli show --dir my_model/1 --all  这里的my_model/1为我的SavedModel模型位置。运行该命令后我们会看到很多输出信息，其中比较重要的部分如下： signature_def['serving_default']:   The given SavedModel SignatureDef contains the following input(s):     inputs['image_input'] tensor_info:         dtype: DT_FLOAT \", metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 693}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 694         shape: (-1, 28, 28)         name: serving_default_image_input:0   The given SavedModel SignatureDef contains the following output(s):     outputs[\\'output\\'] tensor_info:         dtype: DT_FLOAT         shape: (-1, 10)         name: StatefulPartitionedCall:0   Method name is: tensorflow/serving/predict  这里我们可以看到模型的签名signature为[\\'serving_default\\']，我们之前没有设置过模型的签名，所以这里使用的是默认签名。模型的输入inputs为[\\'image_input\\']，其实就是在我之前设置的模型输入名称“image”基础上增加了“_input”。模型的输出outputs为[\\'output\\']，跟我之前设置的模型输出名一样。实现客户端gRPC程序的代码如代码20-2所示。 代码20-2：客户端gRPC程序（片段1） from tensorflow_serving.apis import predict_pb2 from tensorflow_serving.apis import prediction_service_pb2_grpc import grpc  # 向TensorFlow Serving服务请求预测结果。 def request_server(img, server_url):     # 为服务器创建一个通道     channel = grpc.insecure_channel(server_url)     # 在客户端中实现stub，利用这个stub可以调用相应的服务器中的服务     stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)     # 定义请求     request = predict_pb2.PredictRequest()     # 设置模型名称，需要跟启动tf-serving服务器时模型的名字一样     request.model_spec.name = \"my_model\"       # 模型签名，可以使用saved_model_cli命令查看     request.model_spec.signature_name = \"serving_default\"      # 模型输入名称为\"image_input\"，之前模型保存的时候设置为\"image\"后面的\"_input\"是程序自动加上的     # 设置要传输的数据img，数据的格式tf.float32，数据的形状img.shape     request.inputs[\"image_input\"].CopyFrom(tf.make_tensor_proto(img, dtype=tf.float32, shape=img.shape))     # 传数据获得预测结果，最多等待5秒     response = stub.Predict(request, 5.0)   ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 694}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 695     # output为模型输出名称，之前模型保存的时候设置的，变成array后返回     return np.asarray(response.outputs[\"output\"].float_val)   import tensorflow as tf import matplotlib.pyplot as plt import numpy as np  # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理 x_train, x_test = x_train / 255.0, x_test / 255.0 # x_test中第5张图片标签为1 plt.imshow(x_test[5],cmap=\\'gray\\') # 显示图片 plt.show() 结果输出为： \\n  代码20-2：客户端gRPC程序（片段2） # grpc地址及端口，启动tf-serving服务器程序的时候有看到过 server_url = \\'0.0.0.0:8500\\' # 预测一个数据 pre = request_server(x_test[5], server_url) print(\"预测结果为：\",np.argmax(pre)) 结果输出为： 预测结果为： 1  \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 695}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 696 代码20-2：客户端gRPC程序（片段3） # 预测一个批次的数据，比如一次性预测16个数据 num = 16 # 获得预测结果 pre = request_server(x_test[:num], server_url) # reshape变成16行10列 pre = pre.reshape((num,10)) print(\"预测结果为：\",np.argmax(pre,axis=1)) print(\"真实标签为：\",y_test[:num]) 结果输出为： 预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5] 真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]   20.2.4 Tensorflow Serving客户端REST API程序  Tensorflow Serving还可以使用REST API请求，并且REST API看起来更简单一些。实现客户端REST API程序的代码如代码20-3所示。 代码20-3：客户端REST API程序 import tensorflow as tf import matplotlib.pyplot as plt import numpy as np  # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理 x_train, x_test = x_train / 255.0, x_test / 255.0  import json import numpy import requests # 定义模型签名，可以使用saved_model_cli命令查看 # 定义instances，一次性传入16张图进行预测 data = json.dumps({\"signature_name\": \"serving_default\",                    \"instances\": x_test[0:16].tolist()}) # 定义headers ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 696}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 697 headers = {\"content-type\": \"application/json\"} # 定义url，启动tf-serving服务器程序的时候有看到过 # /models/my_model为模型挂载到Docker中的位置 url = \\'http://localhost:8501/v1/models/my_model:predict\\' # 传输数据进行预测，得到返回结果 json_response = requests.post(url, data=data, headers=headers) # 对结果进行解析，然后变成array pre = numpy.array(json.loads(json_response.text)[\"predictions\"]) print(\"预测结果为：\",np.argmax(pre,axis=1)) print(\"真实标签为：\",y_test[:16]) 结果输出为： 预测结果为： [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5] 真实标签为： [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]                ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 697}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 698 专业术语汇总 前言 全注释代码：本书中所使用的代码风格，最大的特点是注释所有程序。  第1章-深度学习介绍 深度学习（Deep Learning）：多层神经网络算法。上世纪60年代叫做感知器，上世纪80年代叫做神经网络，21世纪后改名为深度学习。 人工智能（Artificial Intelligence）：1956年美国达特茅斯会上提出的一个抽象概念，它不是任何具体的机器或算法。 任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。 图灵测试（Turing Test）：具体解释见正文。 机器学习（Machine Learning）： 人工智能是抽象的概念， 那么就需要具体的算法让它落地，机器学习就是一大类具体智能算法的统称。机器学习不是一个算法，而是很多算法的统称。使用机器学习算法我们可以解决生活中如人脸识别，垃圾邮件分类，语音识别等具体问题。 训练集（Training Set）：可以用来训练，构建模型。 验证集（Validation Set）：模型训练阶段测试模型的效果。 测试集（Testing Set）：模型训练好之后最后再用于测试模型的效果。 K折交叉检验（K-fold Cross-Validation）：具体解释见正文。 监督学习（Supervised Learning）：具体解释见正文。 分类（Classification）：预测类别，并且类别是已知的。比如图像识别，文本分类都是属于分类任务。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 698}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 699 回归（Regression）：预测数值，可以是连续型的数值。比如预测国家人口增长，公司销售业绩等。 标签（Label）：数据的标签。 非监督学习（Unsupervised Learning）：具体解释见正文。 聚类（Clustering）：把数据划分成不同的类别，并且类别是未知的。比如某电商平台可以根据用户的行为数据把用户划分为不同的聚类。 半监督学习（Semi-Supervised Learning）：具体解释见正文。 强化学习（Reinforcement Learning）：具体解释见正文。 决策树（Decision Tree）：具体解释见正文。 线性回归（Linear Regreesion）：具体解释见正文。 KNN（K-Nearest Neighbor）：具体解释见正文。 欧氏距离（Euclidean Distance）：也叫欧几里得距离，欧几里得空间中两点间直线的距离，也就是我们日常生活中用得最多的距离计算方法。 K-Means：具体解释见正文。 神经网络（Neural Network）：具体解释见正文。 输入层（Input Layer）：神经网络的信号输入层。 隐藏层（Hidden Layers）：神经网络的中间的网络层。 输出层（Output Layer）：神经网络信号输出的层。 神经元（Neuron）：神经网络中的基本结构，大量的神经元组成了神经网络。 权值（Weights）：神经网络中可以变化的参数，神经网络的训练就是训练网络的权值。 激活函数（Activation Function）：神经元在进行信号汇总以后会经过一个激活函数后再输出，激活函数的主要作用是给网络增加非线性。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 699}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 700 朴素贝叶斯（Naive Bayes）：经典的机器学习算法，朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。 支持向量机（Support Vector Machine）：简称SVM，经典的机器学习算法，支持向量机是一类按监督学习方式对数据进行二分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面。 Adaboost：经典的机器学习算法，Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。 弱人工智能（Weak AI）：具体解释见正文。 强人工智能（Strong AI）：具体解释见正文。 人工神经网络（Artificial Neural Networks）：简称ANN，人工构建的神经网络算法。 控制论（Cybernetics）：控制论看作是一门研究机器、生命社会中控制和通讯的一般规律的科学，是研究动态系统在变的环境条件下如何保持平衡状态或稳定状态的科学。 联结主义（Connectionism）：又称为仿生学派（Bionicsism）或生理学派（Physiologism），其原理主要为神经网络及神经网络间的连接机制与学习算法。 卷积神经网络（Convolutional Neural Network）：简称CNN，一种包含卷积计算的多层网络结构，深度学习代表算法之一。在计算机视觉领域有着非常多的应用。 长短时记忆网络（Long Short Term Memory Network）：简称LSTM是一种时间循环神经网络，是为了解决一般的RNN（循环神经网络）存在的长期依赖问题而专门设计出来的。 深度残差网络（Deep Residual Network）： 一种深度的卷积神经网络， 网络层数可以多达上百层，其中的残差结构是它的特色。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 700}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 701 感知器（Perceptron）：早期的神经网络模型，只有输入层和输出层，只能用于线性问题的求解，不能解决非线性问题。 Hopfield神经网络：Hopfield神经网络是一种递归神经网络， 由约翰·霍普菲尔德在1982年发明，现在已经基本不用了。 玻尔兹曼机（Boltzmann Machine）：是一种可通过输入数据集学习概率分布的随机生成神经网，现在已经基本不用了。 受限玻尔兹曼机（Restricted Boltzmann Machine）：对玻尔兹曼机的改良，现在已经基本不用了。 BP（Back Propagation）算法：多层感知器的误差反向传播算法，BP神经网络也是整个神经网络体系中的精华，广泛应用于分类识别，逼近，回归，压缩等领域。该算法从1986年一直沿用至今，在实际应用中，包括深度学习在内的大部分的神经网络都使用了BP算法。 BP神经网络（Back Propagation Neural network）：主要指的是20世纪80-90年代使用BP算法的多层神经网络。 深度置信网络（Deep Belief Net：DBN）：多个受限玻尔兹曼机堆叠而成，深度学习灵感的开端。现在已经基本不用了。 NLP (Natural Language Processing) ：自然语言处理。 GPU（Graphics Processing Unit）：图形处理器，可用于打游戏，图像渲染或高性能计算。 TPU（Tensor Processing Unit）：Tensor处理器，专门用于机器学习计算。  第3章-单层感知器与线性神经网络 偏置值（Bias）：与输入信号无关的偏置信号。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 701}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 702 sign(x)激活函数：神经网络中最早使用的激活函数，当x＞0时，输出值为1；当x＝0时，输出值为0,；当x＜0时，输出值为-1。 学习率（Learning Rate）：可以用来调节模型训练的速度快慢。 代价函数（Loss Function）：也称为目标函数或损失函数，通常用来定义模型的误差。 迭代周期（Epoch）：迭代周期。把所有训练集数据训练一次称为训练一个周期。 超参数 （Hyperparameters）：机器学习或者深度学习中经常用到的一个概念， 我们可以认为是根据经验来人为设置的一些模型相关的参数。 参数（Parameters）：一般指的是模型中需要训练的变量，如模型的权值和偏置值。 purelin函数：线性函数，y=x。  第4章-BP神经网络 均方差（Mean-Square Error, MSE）：也称为二次代价函数，用来表示模型的误差，多用于回归问题。 二次代价函数：也就是均方差代价函数。 导数（Derivative）：具体解释见正文。 偏导数（Partial Derivative）：具体解释见正文。 方向导数（Directional Derivative）：具体解释见正文。 梯度（Gradient）：具体解释见正文。 梯度下降法 （Gradient Descent）： 神经网络的常用的优化算法， 用于最小化代价函数的值。 全局最小值（Global Minimum）：代价函数的最小值，只有一个。 局部极小值（Local Minimum）：代价函数的局部最小值，可能会有多个。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 702}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 703 sigmoid函数：也称为逻辑函数。上世纪80年代，BP神经网络中最开始使用的S型非线性激活函数。取值范围0-1之间，导数范围0-0.25之间。 tanh函数：一种S型非线性激活函数，取值范围-1-1之间，导数范围0-1之间。 softsign函数：一种S型非线性激活函数，取值范围-1-1之间，导数范围0-1之间。 ReLU函数（The Rectified Linear Unit）：ReLU的中文名称是校正线性单元，一种模拟生物神经元激活函数的新型非线性激活函数， 广泛应用于深度学习中， 可以用来抵抗梯度消失问题。 欠拟合（Under-Fitting）：模型的拟合程度不够，训练集和测试集都无法得到很好的结果。 过拟合 （Over-Fitting）： 模型对训练集拟合程度过好， 使得模型在训练集的预测结果比较好，在测试集的预测结果比较差。 梯度消失（Vanishing Gradient）：误差反向传播过程中学习信号越来越小的现象。 梯度爆炸（Exploding Gradient）：误差反向传播过程中学习信号越来越大的现象。 稀疏性（Sparsity）：神经网络的稀疏性指的是网络中神经元输出为0的数量，输出为0的神经元数量越多，网络越稀疏。 L1正则化（L1 Regularization）：一种正则化手段，可以使得神经网络变得稀疏，所有网络权值都会趋近于0，部分网络权值会变成0。 Dropout：一种正则化手段，在神经网络训练过程中让网络变稀疏进行训练。 准确率（Accuracy）：机器学习常见的分类评估指标，具体含义查看书中介绍。 精确率（查准率，Precision）：机器学习常见的分类评估指标，具体含义查看书中介绍。 召回率（查全率，Recall）：机器学习常见的分类评估指标，具体含义查看书中介绍。  第6章-网络优化方法 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 703}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 704 交叉熵（Cross Entropy）：一种代价函数，用于表示模型的误差，主要用于分类任务。 对数似然（Log Likelihood）代价函数：一种代价函数，用于表示模型的误差，主要用于分类任务，与softmax函数搭配使用。 标签平滑 （Label Smoothing）： 也称为标签平滑正则化(label-smoothing regularization)，简称LSR，一种正则化方法。通过调节数据标签的数值来达到抵抗过拟合的效果。 数据增强（Data Augmentation）：对现有数据进行处理，生成更多训练数据的方法。 Early-Stopping：一种提前停止模型训练的策略。 L2正则化（L2 Regularization）：一种正则化手段，会使所有网络权值都会趋近于0，但是一般不会等于0。  第8章-卷积神经网络CNN CV(Computer Vision)：计算机视觉。 卷积窗口（Convolution Window）：进行卷积计算的一个窗口。 特征图（Feature Map）：卷积计算后得到的用于表示图像特征的图。 视觉感受野（Receptive field of vision）：视网膜上一定的区域或范围。 局部感受野（Local Receptive Field）：卷积网络中的局部感受野指的是后一层神经元只连接前一层的部分神经元。 权值共享（Weight Sharing）：同一卷积层中的同一个卷积窗口的权值是共享的。 卷积核（Convolution Kernel）：就是卷积窗口。 池化（Pooling）：卷积网络中常用的一种特征提取的计算。 最大池化（Max-Pooling）：提取池化窗口中的最大值。 平均池化(Mean-Pooling)：提取池化窗口中的平均值。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 704}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 705 随机池化(Stochastic Pooling)：提取池化窗口中随机一个值。 Valid Padding：不会进行填充的一种padding。 Same Padding：可能会进行填充的一种padding。 滤波器（Filter）：由一个或多个不同的卷积核组成，一个滤波器可以产生一个特征图。  第9章-序列模型 循环神经网络（Recurrent Neural Network）：简称RNN，一种常用的深度学习算法，专门用来处理序列数据。 Simple Recurrent Networks (SRN)：早期的结构比较简单的循环神经网络。 SimpleRNN：早期的结构比较简单的循环神经网络。 Seq2Seq：Sequence to Sequence模型，由编码器Encoder和解码器Decoder组成。可以用于机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。 记忆块（Memory Block）：LSTM网络中的核心结构。  遗忘门（Forget Gate）：LSTM网络中用于控制信号遗忘的控制门。 输入门（Input Gate）：LSTM网络中用于控制信号输入的控制门。 输出门（Output Gate）：LSTM网络中用于控制信号输出的控制门。 记忆单元（Cell）：LSTM网络中用于保存信号的单元。 Hidden State：LSTM的memory block输出信号。 Cell State：LSTM的memory block中间Cell位置的信号。 双向RNN（Bidirectional RNN）：同时利用前向传递和反向传递的信号进行计算的RNN。  第10章-经典图像识别模型介绍(上) ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 705}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 706 迁移学习（Transfer Learning）：深度学习中的迁移学习指的是把训练好的模型经过少量修改和训练后，即可用于新的类似的任务中。 模型融合（Ensemble Model）：把多个不同的模型组合起来进行训练或预测，有可能会得到更好的结果。 LRN（Local Response Normalization）： 局部响应归一化。 一种数据归一化计算， 在AlexNet和GoogleNet中曾使用。 批量标准化（Batch Normalization）：深度学习中常用的一种网络标准化操作，可以使得网络输入的数据分布相对稳定，加速模型的训练。 退化问题（Degradation Problem）：网络模型层数越多，效果越差的现象。 残差块（Residual Block）：残差网络（ResNet）中的基本组成单元，用于解决退化问题。  第11章-经典图像识别模型介绍(下) 分组卷积（Group Convolution）：将特征图分为不同的组，再对每组特征图分别进行卷积。  第12章-图像识别项目实战 微调（Finetune）：对预训练的模型参数进行微调。  第13章-验证码识别项目 多任务学习（Multi-task Learning）：同时训练多个不同的任务。 CTC(Connectionist Temporal Classification)：用来解决输入序列和输出序列难以一一对应的问题。主要用于语音识别和OCR(Optical Character Recognition)领域 OCR(Optical Character Recognition)：光学字符识别。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 706}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 707 贪心算法（Greedy Search）：对问题求解时，总是做出当前看来最好的选择，不一定能得到全局最优解。 集束搜索算法（Beam Search）：对问题求解时，做出当前看来最好的N个选择，不一定能得到全局最优解。当N等于1时就是贪心算法。  第14章-自然语言处理NLP发展历程（上） 语法规则（Grammar Rules）：语言使用的规则。 词性（Part of Speech）：词的词性，如名词，动词，形容词等 构词法（Morphologie）：研究词形变化现象和规则的学问。 上下文无关文法（Context Independent Grammar）：跟上下文无关的文法规则。 上下文相关文法（Context Dependent Grammar）：跟上下文相关的文法规则。 语料库（Corpus）：大量文本的数据集。 二元模型（Bigram Model）：一个词的出现概率只与它前面一个词相关。 N元模型（N-Gram Model）：一个词的出现概率由前面N-1个词决定。 神经网络语言模型NNLM（Neural Net Language Model）：最早基于神经网络训练出来的语言模型。 词向量（Word Embedding）：用一个向量来表达一个词包含的信息。 Word2vec：word to vector，将词转化为向量的一套训练方法。 连续词袋模型CBOW（Continuous Bag-of-Words）：通过上下文词汇预测中间词汇。 Skip-Gram模型：通过中间词汇预测上下文词汇。 层次softmax（Hierarchical Softmax）：对softmax进行优化的一种策略，可以加快模型训练速度。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 707}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 708 负采样（Negative Sampling）：具体解释见正文。 上下文向量（Context Vector）：Seq2Seq中用来表示Encoder中整个序列的信息。 WordPiece：为了减少词汇数量，把词拆分为一片一片。  第15章-自然语言处理NLP发展历程（下） Layer Normmalization：与Batch Normalization类似的一种归一化计算。Layer Normmalization是计算一个数据中， 所有特征维度的平均值和标准差， 然后再对这个数据进行归一化计算。 分词向量（Token Embeddings）：也就是词向量。 位置向量（Position Embeddings）：表示每个token的位置信息。 段落向量（Segment Embeddings）：用来标注哪几个token是第一句话，哪几个token是第二句话。 分词元素（Token）：分词的基本单位，可以是一个词汇或一个字符或其他自定义元素。 掩码语言模型（Masked Language Model）：简称MLM，Bert模型中使用的训练方法，简单的说就是完形填空。 MLM：掩码语言模型（Masked Language Model）。 预测下一个句子（Next Sentence Prediction）：简称NSP，Bert模型中使用的训练方法，意思就是预测下一个句子。 NSP：预测下一个句子（Next Sentence Prediction）。 GLUE(General Language Understanding Evaluation): GLUE是一个自然语言任务集合 命名实体识别NER（Named Entity Recognition）：判断一个句子中的单词是不是人名，机构名，地名，以及其他所有以名称为标识的实体。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 708}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 709  第16章-NLP任务项目实战 维特比算法 （Viterbi Algorithm）： 维特比算法是应用最广泛的动态规划算法之一， 主要应用在数字通信，语音识别，机器翻译，分词等领域，用于求解最优路径问题。 条件随机场CRF（Conditional Random Field）：主要用于分词标注，词性标注，命名实体识别等序列标注任务的无向图模型。 带泄露修正线性单元Leaky ReLU：ReLU的变形，当输入为负数时也有输出值和梯度都不为0。 指数线性单元ELU(Exponential Linear Unit)：ReLU的变形，当输入为负数时也有输出值和梯度都不为0。 扩展指数线性单元SELU(Scaled Exponential Linear Unit)：ReLU的变形，可以使得神经网络每一层的激活值都会满足均值接近于0，标准差接近于1的正态分布。 自归一化神经网络(Self-Normalizing Neural Networks)： 简称为SNN， 表示使用了SELU激活函数的网络。 SNN：自归一化神经网络。 Alpha Dropout：Alpha Dropout是一种保持信号均值和方差不变的Dropout， 改层的作用是即使在Dropout的时候也保持数据的自规范性 高斯误差线性单元GELU(Gaussian Error Linear Unit)：BERT模型中使用的激活函数。 Swish：谷歌提出的一种较新的激活函数。  第17章-音频信号处理 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 709}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 710 自动语言识别(Automatic Speech Recognition)：简称ASR，将人的语音转换为文本的技术。 梅尔滤波器组（Mel Filter Banks）：模拟人耳听力特点设计出来的一组滤波器。 梅尔频率倒谱系数 (Mel-frequency cepstral coefficients)： 简称MFCC， 梅尔频谱进行离散余弦变换后得到的音频特征。 模拟信号（Analog Signal）：连续变化的物理量表示的信号。 数字信号（Digital Signal）：离散的数值信号。 采样频率（Sampling frequency）：信号采集速率。 量化位数（Quantization Bits）：对模拟信号进行数字化时的精度。 傅里叶变换（Fourier Transform）：将时域（Time Domain）信号转换为频域（Frequency Domain）信号。 离散傅里叶变换（Discrete Fourier Transform）：简称DFT，对离散的数值信号进行的傅里叶变换。 快速傅里叶变换（Fast Fourier Transform）：简称FFT，FFT是DFT的快速算法。 短时傅里叶变换（short-term Fourier transform）：简称STFT，将信号加上滑动时间窗，并对每个时间窗口内的数据进行FFT称为STFT。 时域（Time Domain）信号：表示信号强弱与时间的关系。 频域（Frequency Domain）信号：表示信号强弱与频率的关系。 频谱图（Spectrum）：一段时间内信号频率与强弱的关系图，可以通过傅里叶变换得到。 声谱图（Spectrogram）：由一段时间内的多张频谱图组成。 梅尔频谱（Mel Spectrogram）：声谱图经过梅尔滤波器组后得到梅尔频谱。 共振峰（Formants）：语音的主要频率成分。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 710}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 711 包络（Spectral Envelope）：将所有共振峰连接起来的平滑曲线。 包络细节（Spectral Details）:频谱曲线的高频信号。 倒谱（Cepstrum）：对频谱图再做一次傅里叶变换后得到。 伪频率（Pseudo-Frequency）：倒谱中的频率，并不是真正的音频信号的频率，它表示的是频谱图中波形的频率。 离散余弦变换（Discrete Fourier Transform）：简称DCT，DCT类似于DFT，DCT只使用实数。  第18章-图像风格转移 格拉姆矩阵（Gram Matrix）：计算图像特征图的Gram矩阵可以用于表示图像的风格，具体计算见正文。  第19章-生成对抗网络GANs 转置卷积（Transposed Convolution）：转置卷积又名反卷积（deconvolution）或是分数步长卷积（fractially straced convolutions） 。是一种上采样操作，卷积后可以得到分辨率更大的图像。 下采样（Subsampled）：通过某些操作增加图像的分辨率。 上采样（Upsampling）：通过某些操作减小图片的分辨率。     ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 711}),\n",
       " Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 712 结束语 这本书的内容暂时到这里就结束了，不过对于大家的人工智能之旅才刚刚开始。这本书的内容对大家来说只是一个起点，人工智能/深度学习领域还有更多更深入更有趣的技术和应用等待大家学习和发现。 这本书对于我来说也只是一个新的起点，我之后还会不断更新更多人工智能相关的开源教程。本书涉及的代码和资料也可以到我的Github上查看和下载。 本书主页，以及源代码，资料下载： https://github.com/Qinbf/Deep-Learning-Tensorflow2 免费学习人工智能的慕课平台AI MOOC： https://mooc.ai-xlab.com 提交错误或意见反馈可以到Github Issues页面提交： https://github.com/Qinbf/Deep-Learning-Tensorflow2/issues 我的B站主页： https://space.bilibili.com/390756902 我的微信公众号： AI MOOC人工智能平台 联系邮箱： qinbf@ai-xlab.com    ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 712})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader3 = PyPDFLoader(\"深度学习从0到1-基于Tensorflow2.pdf\")\n",
    "pages3 = loader3.load()\n",
    "pages3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bf8034d-f378-4652-a2ab-e7ee400010b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:43:07.627338Z",
     "iopub.status.busy": "2023-11-30T06:43:07.627338Z",
     "iopub.status.idle": "2023-11-30T06:43:07.641950Z",
     "shell.execute_reply": "2023-11-30T06:43:07.641111Z",
     "shell.execute_reply.started": "2023-11-30T06:43:07.627338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "832b8a74-febb-4ed0-87c2-bd3b45ef44d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:43:07.643958Z",
     "iopub.status.busy": "2023-11-30T06:43:07.642970Z",
     "iopub.status.idle": "2023-11-30T06:43:07.658312Z",
     "shell.execute_reply": "2023-11-30T06:43:07.656957Z",
     "shell.execute_reply.started": "2023-11-30T06:43:07.643958Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'page'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages3[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32a3d314-3ab1-4ff3-9c74-d54955e0fae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:43:07.659316Z",
     "iopub.status.busy": "2023-11-30T06:43:07.659316Z",
     "iopub.status.idle": "2023-11-30T06:43:07.672789Z",
     "shell.execute_reply": "2023-11-30T06:43:07.672402Z",
     "shell.execute_reply.started": "2023-11-30T06:43:07.659316Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 100 我们在图中随机选取两个w1和w2的初始值p1和p2，然后从p1,p2这两个初始位置开始使用梯度下降法优化网络参数，得到如图4.6所示的结果。 \\n 图4.6 从p1,p2初始点开始优化网络  图4.6中可以看到网络参数的优化过程其实就是p1,p2两个 “小球“从初始点开始， 每次移动一步，不断向坡底进行移动。在这个过程中整个网络的loss值是在不断变小的。 同时我们还可以观察到一个现象，p1“小球“最后走到了图中的全局最小值（Global Minimum），而p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果， 有些时候我们可以得到loss的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是loss的局部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存在的一个缺点。 \\n', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 100})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages3[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c81294f3-d932-499c-b3df-1fdac4e8d533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:43:07.674318Z",
     "iopub.status.busy": "2023-11-30T06:43:07.673793Z",
     "iopub.status.idle": "2023-11-30T06:43:07.687992Z",
     "shell.execute_reply": "2023-11-30T06:43:07.687992Z",
     "shell.execute_reply.started": "2023-11-30T06:43:07.674318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='免费人工智能慕课平台AI MOOC：mooc.ai-xlab.com \\n 101 不过大家不用太担心这个问题， 一般实际模型训练的时候局部极小值的情况不常出现。 如果我们担心模型得到的结果是局部极小值的话可以让模型多训练几次， 然后取最好的那一次结果作为模型的最终结果就可以了。  4.4 Delta学习规则 1986年，认知心理学家McClelland和Rumelhart在神经网络训练中引入了𝛿（Delta）规则，该规则也可以称为连续感知器学习规则。 𝛿（Delta）学习规则是一种利用梯度下降法的一般性的学习规则， 其实就是利用梯度下降法来最小化代价函数。比如代价函数为前面公式4.2介绍的均方差代价函数，为了简单我们只计算一个样本的均方差公式， 如果是计算多个样本可以求所有样本代价函数的平均值。 一个样本的均方差公式定义如下：𝐸=\"#(𝑇−𝑌)#=\"#(𝑡−𝑦)#=\"#(𝑡−𝑓(𝑊𝑋))#(4.9) 误差E是W的函数，我们可以使用梯度下降法来最小化E的值，权值矩阵的变化∆W等于负的学习率−𝜂乘以E对W进行求导： ∆𝑊=−𝜂𝐸R=𝜂𝑋~(𝑡−𝑦)𝑓R(𝑊𝑋)=𝜂𝑋~𝛿(4.10) 注意这里的X和W都是矩阵，所以这里求导的时候是对矩阵W进行求导，矩阵求导的方式跟单个元素求导的方式有一些不同。下面公式是单个w元素的权值变化计算： ∆𝑤(=−𝜂𝐸R=𝜂𝑥((𝑡−𝑦)𝑓R(𝑊𝑋)=𝜂𝑥(𝛿(4.11) 这里的𝛿（Delta）符号没有什么特别的含义，就是用来替代(𝑡−𝑦)𝑓R(𝑊𝑋)。∆𝑤(表示第i个权值的变化。 ', metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf', 'page': 101})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages3[101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a099cc-7f71-4359-8f36-3a2a2cba24b1",
   "metadata": {},
   "source": [
    "# metadata.keys对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0387300e-8d32-495e-9182-5a77e4e548e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T06:56:56.623904Z",
     "iopub.status.busy": "2023-11-30T06:56:56.623904Z",
     "iopub.status.idle": "2023-11-30T06:56:56.641906Z",
     "shell.execute_reply": "2023-11-30T06:56:56.640688Z",
     "shell.execute_reply.started": "2023-11-30T06:56:56.623904Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFPlumberLoader metadata.keys():\n",
      " dict_keys(['source', 'file_path', 'page', 'total_pages', 'Title', 'Producer', 'Creator', 'CreationDate', 'ModDate']) \n",
      "\n",
      "UnstructuredPDFLoader metadata.keys():\n",
      " dict_keys(['source']) \n",
      "\n",
      "UnstructuredPDFLoader(elements) metadata.keys():\n",
      " dict_keys(['source', 'coordinates', 'filename', 'last_modified', 'filetype', 'page_number', 'category']) \n",
      "\n",
      "PyPDFLoader metadata.keys():\n",
      " dict_keys(['source', 'page']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"PDFPlumberLoader metadata.keys():\\n\",pages[0].metadata.keys(),\"\\n\")\n",
    "print(\"UnstructuredPDFLoader metadata.keys():\\n\",pages1[0].metadata.keys(),\"\\n\")\n",
    "print(\"UnstructuredPDFLoader(elements) metadata.keys():\\n\",pages2[0].metadata.keys(),\"\\n\")\n",
    "print(\"PyPDFLoader metadata.keys():\\n\",pages3[0].metadata.keys(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafecea1-1f4c-4e11-a533-1df831876e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-env",
   "language": "python",
   "name": "chat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
