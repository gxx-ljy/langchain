{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1721e1d-20c4-40eb-8e2e-3309bdcb5ea0",
   "metadata": {},
   "source": [
    "# 加载pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1240189-8061-46b9-9d35-3c02d8489c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:20:03.418351Z",
     "iopub.status.busy": "2023-11-30T10:20:03.417345Z",
     "iopub.status.idle": "2023-11-30T10:21:14.212681Z",
     "shell.execute_reply": "2023-11-30T10:21:14.212681Z",
     "shell.execute_reply.started": "2023-11-30T10:20:03.418351Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "loader = UnstructuredPDFLoader(\"深度学习从0到1-基于Tensorflow2.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32affc9c-99a4-48c8-b0d5-f50936b96a30",
   "metadata": {},
   "source": [
    "# 分割文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d0415e-4ed5-4941-a319-f9bdb046f942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:21:14.241722Z",
     "iopub.status.busy": "2023-11-30T10:21:14.241722Z",
     "iopub.status.idle": "2023-11-30T10:21:14.500867Z",
     "shell.execute_reply": "2023-11-30T10:21:14.500867Z",
     "shell.execute_reply.started": "2023-11-30T10:21:14.241722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs1 = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a63887-0f79-4c4e-8d21-ac4eebf27065",
   "metadata": {},
   "source": [
    "# 连接数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acad39-7e52-43d2-9e16-04c349fc9993",
   "metadata": {},
   "source": [
    "## 方式一：langchain建新表，插入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0fbc09-747d-44fc-a4d9-fa8b5a49cc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:52:30.180687Z",
     "iopub.status.busy": "2023-11-30T10:52:30.180687Z",
     "iopub.status.idle": "2023-11-30T10:52:30.809468Z",
     "shell.execute_reply": "2023-11-30T10:52:30.808032Z",
     "shell.execute_reply.started": "2023-11-30T10:52:30.180687Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"../../model/m3e-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69596540-62b1-4ac3-9153-3fd4c35c2438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:52:31.680398Z",
     "iopub.status.busy": "2023-11-30T10:52:31.680398Z",
     "iopub.status.idle": "2023-11-30T10:52:51.715433Z",
     "shell.execute_reply": "2023-11-30T10:52:51.715433Z",
     "shell.execute_reply.started": "2023-11-30T10:52:31.680398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Milvus\n",
    "vector_db = Milvus.from_documents(\n",
    "    split_docs1,\n",
    "    embedding,\n",
    "    collection_name=\"pdf_test\",\n",
    "    connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba21f68-1f80-4b94-9e7e-b5c6063b0e35",
   "metadata": {},
   "source": [
    "<img src=\"./pic/pdf_test_schema.png\" title=\"\" alt=\"\" width=\"900\" style=\"display: block; margin: auto;\">\n",
    "<img src=\"./pic/pdf_test_data.png\" title=\"\" alt=\"\" width=\"900\" style=\"display: block; margin: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81400abb-19f5-4081-9f5b-35c942dd964e",
   "metadata": {},
   "source": [
    "## 检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "befc747e-e7cd-4b1c-b32e-708644965caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:16:15.984578Z",
     "iopub.status.busy": "2023-11-30T11:16:15.984578Z",
     "iopub.status.idle": "2023-11-30T11:16:16.057975Z",
     "shell.execute_reply": "2023-11-30T11:16:16.056984Z",
     "shell.execute_reply.started": "2023-11-30T11:16:15.984578Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n\\n所示。\\n\\n图 1.6 决策树(Decision Tree)\\n\\n26\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n\\n这些数据来建立回归模型，如图 1.7 所示。\\n\\n图 1.7 线性回归(Linear Regreesion)' metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n",
      "page_content=\"预测被 mask 的 token model = build_transformer_model(config_path, checkpoint_path, with_mlm=True) # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科') # 把“学”字和“习”字变成“[MASK]”符号 token_ids[3] = token_ids[4] = tokenizer._token_dict['[MASK]'] # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第 3，4 个位置经过模型预测，[MASK]变成了“学习”\" metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n",
      "page_content='683\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 传入 loss 和模型参数，计算判别器的权值调整 gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variabl es) # 生成器的权值调整 generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_var iables)) # 判别器的权值调整 discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trai nable_variables))' metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question =  \"机器学习\"\n",
    "sim_docs = vector_db.similarity_search(question , k=3)\n",
    "context = ''\n",
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(sim_docs[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e702c-9b9e-49a9-87d4-5ff1a86303e6",
   "metadata": {},
   "source": [
    "## 方式二：连接已有的表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e95373-78f6-4e13-87fa-2c182a0ebecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:53:19.829153Z",
     "iopub.status.busy": "2023-11-30T10:53:19.829153Z",
     "iopub.status.idle": "2023-11-30T10:53:20.424142Z",
     "shell.execute_reply": "2023-11-30T10:53:20.424142Z",
     "shell.execute_reply.started": "2023-11-30T10:53:19.829153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "vector_db2 = Milvus(\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=\"../../model/m3e-base\"),\n",
    "    connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    "    collection_name=\"pdf_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa714cf1-2b73-4bff-834d-c706bfd8f507",
   "metadata": {},
   "source": [
    "## 检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc26a26-605f-412b-927a-9f9941f5dd17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:16:30.989986Z",
     "iopub.status.busy": "2023-11-30T11:16:30.989986Z",
     "iopub.status.idle": "2023-11-30T11:16:31.054948Z",
     "shell.execute_reply": "2023-11-30T11:16:31.054948Z",
     "shell.execute_reply.started": "2023-11-30T11:16:30.989986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n\\n所示。\\n\\n图 1.6 决策树(Decision Tree)\\n\\n26\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n\\n这些数据来建立回归模型，如图 1.7 所示。\\n\\n图 1.7 线性回归(Linear Regreesion)' metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n",
      "page_content=\"预测被 mask 的 token model = build_transformer_model(config_path, checkpoint_path, with_mlm=True) # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科') # 把“学”字和“习”字变成“[MASK]”符号 token_ids[3] = token_ids[4] = tokenizer._token_dict['[MASK]'] # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第 3，4 个位置经过模型预测，[MASK]变成了“学习”\" metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n",
      "page_content='683\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 传入 loss 和模型参数，计算判别器的权值调整 gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variabl es) # 生成器的权值调整 generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_var iables)) # 判别器的权值调整 discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trai nable_variables))' metadata={'source': '深度学习从0到1-基于Tensorflow2.pdf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question =  \"机器学习\"\n",
    "sim_docs2 = vector_db2.similarity_search(question , k=3)\n",
    "context = ''\n",
    "for i, sim_doc in enumerate(sim_docs2):\n",
    "    print(sim_docs2[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974c390-3a4b-4ceb-9fd5-3b4c0b8a421f",
   "metadata": {},
   "source": [
    "## 方式三：自定义表，插入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21116ae-57c3-4702-ae8e-b7c64d9c9e7e",
   "metadata": {},
   "source": [
    "### 生成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ce226b1-b91c-45a4-83ab-b5ac03390571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T23:49:07.720431Z",
     "iopub.status.busy": "2023-11-30T23:49:07.719359Z",
     "iopub.status.idle": "2023-11-30T23:49:07.727248Z",
     "shell.execute_reply": "2023-11-30T23:49:07.727248Z",
     "shell.execute_reply.started": "2023-11-30T23:49:07.720431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in split_docs1:\n",
    "    sentences.append(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7b528d9-57c1-4520-b935-29a6dc8dfaae",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T23:49:14.005017Z",
     "iopub.status.busy": "2023-11-30T23:49:14.005017Z",
     "iopub.status.idle": "2023-11-30T23:49:14.030687Z",
     "shell.execute_reply": "2023-11-30T23:49:14.030149Z",
     "shell.execute_reply.started": "2023-11-30T23:49:14.005017Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n0\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n说明\\n\\n本电子书为书籍原稿的开源版本，基本上没有进行什么排版，纸质书籍估计要 2021 年 3\\n\\n月后才能购买。\\n\\n本书虽然为开源电子书，但仅供个人学习使用。未经许可不能用于个人或企业的商业用\\n\\n途，违法盗版和销售，必究其法律责任。\\n\\n本书主页，以及源代码，资料下载：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2\\n\\n本书配套免费视频教程可以到免费学习人工智能的慕课平台 AI MOOC 学习：\\n\\nhttps://mooc.ai-xlab.com\\n\\n提交错误或意见反馈可以到 Github Issues 页面提交：\\n\\nhttps://github.com/Qinbf/Deep-Learning-Tensorflow2/issues\\n\\n我的 B 站主页：\\n\\nhttps://space.bilibili.com/390756902\\n\\n我的微信公众号：\\n\\nAI MOOC 人工智能平台',\n",
       " '我的微信公众号：\\n\\nAI MOOC 人工智能平台\\n\\n联系邮箱：\\n\\nqinbf@ai-xlab.com\\n\\n1\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n本书谨献给我的妻子刘露斯，以及正在阅读此书的各位读者朋友。\\n\\n愿人工智能给我们带来更美好的未来。\\n\\n2\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n序言\\n\\n本书的由来\\n\\n本书的序言可能有点长，因为这是我和大家的第一次见面，我希望可以把关于我和这本书\\n\\n的故事讲清楚，让大家对我有一个更好的了解，说不定哪天我们会成为朋友。\\n\\n大约在 3 年前的某个下午，电子工业出版社的张迪编辑联系到我，让我写一本关于人工智\\n\\n能的书。第一次有人找我写书，不免还是有些小激动，想象中写书是一件很酷的事情，真正写\\n\\n的时候才知道写书是一件很苦的事情。\\n\\n我毕业于上海大学物理系本科，大学期间做过很多嵌入式软硬件相关的开发项目。由于觉\\n\\n得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用，所以我在大学校内开过',\n",
       " '得当时学校的嵌入式技术的教学内容比较老套并且不够切合实际应用，所以我在大学校内开过\\n\\n一年的嵌入式培训班，以更通俗易懂的方式和切合实际应用的内容给几百个本校同学（包括本\\n\\n科/硕士/博士）上过课。\\n\\n我最早是从 2015 年开始接触人工智能技术，公司内部刚好需要开发人工智能相关的产品。\\n\\n当时谷歌的深度学习框架 Tensorflow 都还没有开源，我主要是学习了一些机器学习相关的算\\n\\n法和应用。随着 Tensorflow 在 2015 年 11 月开源，AlphaGo 在 2016 年 3 月战胜人类顶级\\n\\n围棋选手，我知道新的人工智能的时代就要到来。2016 年我学习了当时最热门的两个深度学\\n\\n习框架 Tensorflow 和 Caffe 并用这两个框架完成了公司里面的一些深度学习项目。\\n\\n当时市面上关于深度学习的书籍和学习资料都非常少，所以在 2017 年的时候我录制了一\\n\\n些深度学习相关的视频教程放到了网上，就有了后来出版社找我写书的故事。几乎每个月都会\\n\\n有出版社的人联系我出书，我才知道原来获得出书的机会不难，真正难的是认真坚持把一本书\\n\\n3',\n",
       " '有出版社的人联系我出书，我才知道原来获得出书的机会不难，真正难的是认真坚持把一本书\\n\\n3\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n给写完。这本书历时 3 年，不过也不是真的写了 3 年，写的过程中断断续续也暂停了很多次。\\n\\n我估算了一下真正写书的时间大概是用了 1200 个小时。\\n\\n最近两年我做了很多场人工智能的线下培训，给中国移动，中国电信，中国银行，华夏银\\n\\n行，太平洋保险，国家电网，中海油，格力电器等企业以及多个研究所的科研人员和多个高校\\n\\n的老师上过课，大家学完后的反馈基本上都是挺好的。虽然我这两年一直在从事人工智能的教\\n\\n育培训工作，但是我也一直没有真正下定决心要做人工智能教育培训这件事。因为现如今人工\\n\\n智能的各种学习资料已经很多了，网上也有各种人工智能专家大师的课程，这些专家大师基本\\n\\n上都是博士，教授或来自名企。并且从课程的包装上看，内容还是不错的。\\n\\n不过长期以来，我一直在关注人工智能技术和教育培训的发展。人工智能目前还处于高速\\n\\n发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分',\n",
       " '发展的初级阶段，新技术层出不穷，技术革新特别快。而人工智能教育的发展现状并不是十分\\n\\n令人满意，还存在着许多问题。这些问题并不是几个专家大师所能解决的，而是需要更多人的\\n\\n努力和付出。\\n\\n人工智能教育是一件很有意义的事情，因为它有可能关乎国家，甚至人类的未来。尽管将\\n\\n会面临无数困难，我还是决定加入其中，以这本书作为开始。\\n\\n免费人工智能慕课平台 AI MOOC\\n\\nAI MOOC 是我自己创办的一个免费的人工智能慕课平台，网站地址为 https://mooc.ai-\\n\\nxlab.com。以后我会在上面不断更新最新的人工智能课程。我的目标是让所有人都能有机会\\n\\n学习到最前沿最好的人工智能课程。\\n\\n如果大家觉得我创作的内容不错，可以帮我多多宣传，感谢。\\n\\n4\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n人工智能的学习\\n\\n这里想跟大家简单聊一下关于人工智能的学习，人工智能是一门需要“内外兼修”的学科，\\n\\n既要修炼外功招式，又要进行内功修行。这里的外功招式主要指的是使用编程语言去实现一些\\n\\n人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。',\n",
       " '人工智能的算法，完成一些落地应用；而内功修行指的是对算法理论的理解。\\n\\n很多时候武功招式是很容易学的，可以短时间内快速提升，但同时也很容易达到一定的上\\n\\n限。如果想要突破上限更进一步，就要把内功给修炼好。所以我们在学习人工智能相关技术的\\n\\n时候，尽量把相关算法理论理解清楚，同时要多写代码提高编程能力，并在实践过程中加深对\\n\\n算法的理解。\\n\\n本书的特色\\n\\n本书的脉络框架主要是根据深度学习知识由浅入深的发展来编写的，对于 Tensorflow 的\\n\\n使用技巧基本上不会单独讲解，而是会结合深度学习理论知识或实际应用案例来讲解。所以很\\n\\n多 Tensorflow 的使用技巧在目录上可能没有得到很好的体现，这些 Tensorflow 使用技巧的\\n\\n彩蛋在书里的程序中等着大家发现哦！相信大家看完这本书以后就可以熟练掌握 Tensorflow\\n\\n的使用了。\\n\\n本书是一本“内外兼修”的书，既包含详细的算法理论的介绍，又包括详细的代码讲解。\\n\\n我一直在思考人工智能技术的教学方式，所以也形成了自己的教学风格和对教育的理解。这一',\n",
       " '我一直在思考人工智能技术的教学方式，所以也形成了自己的教学风格和对教育的理解。这一\\n\\n套方式方法收到过很多同学的积极反馈，但也不一定适合所有人。我觉得不同的教学风格就像\\n\\n是不同类型的音乐，每个人喜欢的音乐类型可能都会不一样。AI 教育的发展需要各种类型的\\n\\n教学方式百花齐放。\\n\\n本书的主要特色总结如下：\\n\\n5\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n一.所有公式推导都有详细步骤，并解释每个符号。数学公式是算法的根本，要理解算法的\\n\\n本质就要理解数学公式的含义，所以掌握一些基础的深度学习相关的数学内容也是很重要的。\\n\\n大家看到数学一般都会比较头疼，所以本书中所有数学公式都会列出详细推导步骤，并解释每\\n\\n个相关符号的含义，帮助大家理解。\\n\\n二.注释每一行代码。我一直觉得我在教学中使用的代码具有一定个人风格，代码逻辑结构\\n\\n清晰，程序在容易理解的基础上尽量精简，最大的特点可能就是注释比代码多。我给这种代码\\n\\n风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得',\n",
       " '风格起个名字吧，这样以后一说大家就知道了，就起个直白的名字叫“全注释代码”。我觉得\\n\\n对于初学者而言，最好是可以理解每一行代码，每个函数，函数中所使用的每个参数，这样学\\n\\n习会感觉比较扎实。所以本书中所有代码都是全注释代码。\\n\\n三. 程序皆为完整程序。本书一共 82 个代码应用案例，所有的代码都是可以从头到尾运\\n\\n行的完整程序，并附带真实运行结果，不存在程序片段样例。我觉得程序片段对于初学者的学\\n\\n习不太友好，大家拿到一个程序片段往往还是不知道如何使用，或者用起来的时候出现很多错\\n\\n误，所以我在书中使用的所有程序都是可以从头到尾直接运行的完整程序。\\n\\n四.一图胜千言。深度学习中很多模型结构，计算流程之类的内容很难用公式或者语言表达\\n\\n清楚，但往往一张好的图片就可以说明一切。本书一共使用了约 500 张图片，在本书的创作\\n\\n过程中，大约有 200 个小时是花在画图以及思考如何画图上。\\n\\n五.逻辑结构清晰，讲解细致。这个不需要多介绍，大家看的时候就知道了。\\n\\n勘误和支持\\n\\n6\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7',\n",
       " '勘误和支持\\n\\n6\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7\\n\\n本书很多思想和知识体系都是我基于自己的理解建立的，由于本人水平有限，本书一定存\\n\\n在不少理解不当或者不准确的地方，恳请大家批评指正。如果大家有更多宝贵意见，欢迎发送\\n\\n邮件至邮箱 qinbf@ai-xlab.com\\n\\n， 或 者 到 我 的 Github 留言 ： https://github.com/Qinbf/Deep-Learning-\\n\\nTensorflow2/issues。期待大家的真挚反馈和支持。\\n\\n致谢\\n\\n在本书的撰写和研究期间，感谢我的妻子刘露斯对我的支持和鼓励。感谢我的朋友王惠东\\n\\n对本书部分章节的校阅。感谢电子工业出版社张迪编辑的耐心等待，感谢出版社对本书的耐心\\n\\n修订和整理。最后感谢各位读者朋友选择了这本书，感谢大家的信任。\\n\\n覃秉丰\\n\\n2020 年 9 月于上海\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n目录',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n目录\\n\\n前言 第 1 章 深度学习背景介绍 1.1 人工智能 1.2 机器学习 1.2.1 训练数据，验证数据和测试数据 1.2.2 学习方式 1.2.3 机器学习常用算法 1.3 人工智能，机器学习，神经网络以及深度学习之间的关系 1.4 深度学习应用 1.5 神经网络深度学习发展史 1.5.1 神经网络诞生-20 时间 40-60 年代 1.5.2 神经网络复兴-20 时间 80-90 年代 1.5.3 深度学习-2006 年至今 1.6 深度学习领域重要人物 1.7 新一轮人工智能爆发的三要素\\n\\n第 2 章 搭建 Python 编程环境 2.1 Python 介绍 2.2 Anaconda 安装 2.3 Jupyter Notebook 的简单使用 2.3.1 启动 Jupyter Notebook 2.3.2 修改 Jupyter Notebook 默认启动路径 2.3.3 Jupyter Notebook 浏览器无法打开 2.3.4 Jupyter Notebook 基本操作',\n",
       " '第 3 章 单层感知器与线性神经网络 3.1 生物神经网络 3.2 单层感知器 3.2.1 单层感知器介绍 3.2.2 单层感知器计算举例 3.2.3 单层感知器的另一种表达形式 3.3 单层感知器的学习规则 3.3.1 单层感知器的学习规则介绍 3.3.2 单层感知器的学习规则计算举例 3.4 学习率 3.5 模型的收敛条件 3.6 模型的超参数和参数的区别 3.7 单层感知器分类案例 3.8 线性神经网络 3.8.1 线性神经网络介绍\\n\\n8\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 3.8.2 线性神经网络分类案例 3.9 线性神经网络处理异或问题',\n",
       " '第 4 章 单层感知器与线性神经网络 4.1 BP 神经网络介绍及发展背景 4.2 代价函数 4.3 梯度下降法 4.3.1 梯度下降法（Gradient Descent）介绍 4.3.2 梯度下降法（Gradient Descent）二维例子 4.3.3 梯度下降法（Gradient Descent）三维例子 4.4 Delta 学习规则 4.5 常用激活函数讲解 4.5.1 Sigmoid 函数 4.5.2 Tanh 函数 4.5.3 Softsign 函数 4.5.4 ReLU 函数 4.6 BP 网络模型和公式推导 4.6.1 BP 网络模型 4.6.2 BP 算法推导 4.6.3 BP 算法推导补充说明 4.7 BP 算法推导结论总结 4.8 梯度消失与梯度爆炸 4.8.1 梯度消失 4.8.2 梯度爆炸 4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题 4.9 使用 BP 神经网络解决异或问题 4.10 分类模型评估方法 4.10.1 准确率/精确率/召回率/F1 值 4.10.2 混淆矩阵 4.11 独热编码（One-Hot Encoding） 4.12',\n",
       " '值 4.10.2 混淆矩阵 4.11 独热编码（One-Hot Encoding） 4.12 BP 神经网络完成手写数字识别 4.13 Sklearn 手写数字识别',\n",
       " '第 5 章 深度学习框架 Tensorflow 基础使用 5.1 Tensorflow 介绍 5.1.1 Tensorflow 简介 5.1.2 静态图和动态图机制 Eager Execution 5.1.3 tf.keras 5.2 Tensorflow-cpu 安装 5.2.1 Tensorflow-cpu 在线安装 5.2.2 安装过程中可能遇到的问题汇总 5.2.3 Tensorflow-cpu 卸载 5.2.4 Tensorflow-cpu 更新\\n\\n9',\n",
       " '9\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 5.2.5 Tensorflow-cpu 指定版本的安装 5.3 Tensorflow-gpu 安装 5.3.1 Tensorflow-gpu 了解最新版本情况 5.3.2 Tensorflow-gpu 安装 CUDA 5.3.3 Tensorflow-gpu 安装 cuDNN 库 5.3.4 Tensorflow-gpu 在线安装 5.3.5 Tensorflow-gpu 卸载 5.3.6 Tensorflow-gpu 更新 5.4 Tensorflow 基本概念 5.5 Tensorflow 基础使用 5.5.1 TF1 转 TF2 工具 5.5.2 Tensorflow 基本操作 5.5.3 拟合线性函数 5.5.4 拟合非线性函数 5.6 手写数字图片分类任务 5.6.1 MNIST 数据集介绍 5.6.2 Softmax 函数介绍 5.6.3 简单 MNIST 数据集分类模型-没有高级封装 5.6.4 简单 MNIST 数据集分类模型-keras 高级封装',\n",
       " '第 6 章 网络优化方法 6.1 交叉熵代价函数 6.1.1 均方差代价函数的缺点 6.1.2 引入交叉熵代价函数 6.1.3 交叉熵代价函数推导过程 6.1.4 Softmax 与对数似然代价函数 6.1.5 交叉熵程序 6.2 过拟合（Over-Fitting） 6.2.1 什么是过拟合 6.2.2 抵抗过拟合的方法 6.3 数据增强（Data Augmentation） 6.4 提前停止训练（Early-Stopping） 6.5 Dropout 6.5.1 Dropout 介绍 6.5.2 Dropout 程序 6.6 正则化（Regularization） 6.6.1 正则化介绍 6.6.2 正则化程序 6.7 标签平滑（Label Smoothing） 6.7.1 标签平滑（Label Smoothing）介绍 6.7.2 标签平滑（Label Smoothing）程序 6.8 优化器（Optimizer） 6.8.1 梯度下降法 SGD\\n\\n10',\n",
       " '10\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 6.8.2 Momentum 6.8.3 NAG（Nesterov Accelerated Gradient） 6.8.4 Adagrad 6.8.5 Adadelta 6.8.6 RMRprop 6.8.7 Adam 6.8.8 优化器程序\\n\\n第 7 章 Tensorflow 模型的保存和载入 7.1 交叉熵代价函数 7.1.1 Keras 保存模型 7.1.2 Keras 载入模型 7.2 SavedModel 模型保存和载入 7.2.1 SavedModel 保存模型 7.2.2 SavedModel 载入模型 7.3 单独保存模型结构 7.3.1 保存模型结构 7.3.2 载入模型结构 7.4 单独保存模型参数 7.4.1 保存模型参数 7.4.2 载入模型参数 7.5 ModelCheckpoint 自动保存模型 7.6 Checkpoint 模型保存和载入 7.6.1 Checkpoint 模型保存 7.6.2 Checkpoint 模型载入',\n",
       " '第 8 章 卷积神经网络 CNN 8.1 计算机视觉介绍 8.1.1 计算机视觉应用介绍 8.1.2 计算机视觉技术介绍 8.2 卷积神经网络简介 8.2.1 BP 神经网络存在的问题 8.2.2 局部感受野和权值共享 8.3 卷积的具体计算 8.4 卷积的步长 8.5 不同的卷积核 8.6 池化（Pooling） 8.7 Padding 8.8 常见的卷积计算总结 8.8.1 对 1 张图像进行卷积生成 1 张特征图 8.8.2 对 1 张图像进行卷积生成多张特征图 8.8.3 对多张图像进行卷积生成 1 张特征图 8.8.4 对多张图像进行卷积生成多张特征图\\n\\n11\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 8.9 经典的卷积神经网络 8.10 卷积神经网络应用于 MNIST 数据集分类 8.11 识别自己写的数字图片 8.12CIFAR-10 数据集分类',\n",
       " '第 9 章 序列模型 9.1 序列模型应用 9.2 循环神经网络 RNN 9.2.1 循环神经网络介绍 9.2.2 Elman network 和 Jordan network 9.3 RNN 的不同架构 9.3.1 一对一架构 9.3.2 多对一架构 9.3.3 多对多架构 9.3.4 一对多架构 9.3.5 Seq2Seq 架构 9.4 传统 RNN 的缺点 9.5 长短时记忆网络 LSTM 9.6 Peephole LSTM 和 FC-LSTM 9.6.1 Peephole LSTM 介绍 9.6.2 FC-LSTM 介绍 9.7 其他 RNN 模型 9.7.1 门控循环单元 GRU 9.7.2 双向 RNN（Bidirectional RNN） 9.7.3 Stacked Bidirectional RNN 9.8 LSTM 网络应用于 MNIST 数据集分类',\n",
       " '第 10 章 经典图像识别模型介绍（上） 10.1 图像数据集 ImageNet 10.1.1 ImageNet 介绍 10.1.2 李飞飞简介 10.1.3 ImageNet 的深远影响 10.1.4 ImageNet Challenge 历年优秀作品 10.2 AlexNet 10.3 VGGNet 10.4 GoogleNet 10.4.1 1×1 卷积介绍 10.4.2 Inception 结构 10.4.3 GoogleNet 网络结构 10.5 Batch Normalization 10.5.1 Batch Normalization 提出背景 10.5.2 数据标准化（Normalization） 10.5.3 Batch Normalization 模型训练阶段\\n\\n12',\n",
       " '12\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 10.5.4 Batch Normalization 模型预测阶段 10.5.5 Batch Normalization 作用分析 10.6 ResNet 10.6.1 ResNet 背景介绍 10.6.2 残差块（Residual Block）介绍 10.6.3 ResNet 网络介绍 10.6.4 ResNet-V2\\n\\n第 11 章 经典图像识别模型介绍（下） 11.1 Inception 模型系列 11.1.1 Inception-v2/v3 优化策略 11.1.2 Inception-v2/v3 模型结构 11.1.3 Inception-v4 和 Inception-ResNet 介绍 11.2 ResNeXt 11.2.1 分组卷积（Group Convolution）介绍 11.2.2 ResNeXt 中的分组卷积 11.2.3 ResNeXt 的网络结构 11.3 SENet 11.3.1 SENet 介绍 11.3.2 SENet 结果分析',\n",
       " '第 12 章 图像识别项目实战 12.1 图像数据准备 12.1.1 数据集介绍 12.1.2 数据集准备 12.1.3 切分数据集程序 12.2 AlexNet 图像识别 12.3 VGGNet 图像识别 12.4 函数式（functional）模型 12.4.1 函数式（functional）模型介绍 12.4.2 使用函数式模型进行 MNIST 图像识别 12.5 模型可视化 plot_model 12.5.1 使用 plot_model 进行模型可视化 12.5.2 plot_model 升级版 12.6 GoolgeNet 图像识别 12.7 Batch Normalization 使用 12.8 ResNet 图像识别 12.9 ResNeXt 图像识别 12.10 SENet 图像识别 12.11 使用预训练模型进行迁移学习 12.11.1 使用训练好的模型进行图像识别 12.11.2 使用训练好的模型进行迁移学习 12.11.3 载入训练好的模型进行预测\\n\\n13\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '13\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 13 章 验证码识别项目实战 13.1 多任务学习介绍 13.2 验证码数据集生成 13.3 tf.data 介绍 13.4 使用 tf.data 完成多任务学习-验证码识别 13.4.1 使用 tf.data 完成多任务学习模型训练 13.4.2 使用 tf.data 完成多任务学习模型预测 13.5 使用自定义数据生成器完成验证码识别 13.5.1 使用自定义数据生成器完成模型训练 13.5.2 使用自定义数据生成器完成模型预测 13.6 挑战变长验证码识别 13.6.1 挑战变长验证码识别模型训练 13.6.2 挑战变长验证码识别模型预测 13.7 CTC 算法 13.7.1 CTC 算法介绍 13.7.2 贪心算法（Greedy Search）和集束搜索算法（Beam Search） 13.7.3 CTC 存在的问题 13.8 CTC 算法-验证码识别 13.8.1 使用 CTC 算法训练验证码模型 13.8.2 使用 CTC 算法训练验证码预测',\n",
       " '第 14 章 自然语言处理 NLP 发展历程（上） 14.1 多任务学习介绍 14.1.1 文本分类/情感分类 14.1.2 分词标注 14.1.3 机器翻译 14.1.4 聊天机器人 14.1.5 自动摘要 14.1.6 文章生成 14.1.7 图片描述 14.2 从传统语言模型到神经语言模型 14.2.1 规则模型 14.2.2 统计语言模型 14.2.3 词向量（word embedding） 14.2.4 神经语言模型 14.3 word2vec 14.3.1 word2vec 介绍 14.3.2 word2vec 模型训练 14.3.3 word2vec 训练 trick 和可视化效果 14.4 CNN 在 NLP 领域的使用 14.5 RNN 在 NLP 领域的使用 14.5.1 使用 RNN 进行文本分类\\n\\n14',\n",
       " '14\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 14.5.2 使用 RNN 进行中文分词标注 14.6 Seq2Seq 模型在 NLP 领域的使用 14.7 Attention 机制 14.7.1 Attention 思想的介绍 14.7.2 Bahdanau Attention 介绍 14.7.3 Luong Attention 介绍 14.7.4 谷歌机器翻译系统 GNMT 介绍 14.7.5 Attention 机制在视觉和语音领域的应用',\n",
       " '第 15 章 自然语言处理 NLP 发展历程（下） 15.1 NLP 新的开始-Transformer 模型 15.1.1 Transformer 模型结构和输入数据介绍 15.1.2 Self-Attention 介绍 15.1.3 Multi-Head Attention 介绍 15.1.4 Layer Normalization 介绍 15.1.5 Decoder 结构介绍 15.1.6 Decoder 中的 Multi-Head Attention 和模型训练 15.2 BERT 模型 15.2.1 BERT 模型介绍 15.2.2 BERT 模型训练 15.2.3 BERT 模型应用',\n",
       " '第 16 章 NLP 任务项目实战 16.1 Python 介绍 16.1.1 项目数据和模型说明 16.1.2 一维卷积英语电影评论情感分类程序 16.2 二维卷积中文微博情感分类项目 16.3 双向 LSTM 中文微博情感分类项目 16.4 堆叠双向 LSTM 中文分词标注项目 16.4.1 中文分词标注模型训练 16.4.2 维特比算法（Viterbi Algorithm） 16.4.3 中文分词标注模型预测 16.5 最新的一些激活函数介绍 16.5.1 Leaky ReLU 16.5.2 ELU 16.5.3 SELU 16.5.4 GELU 16.5.5 Swish 16.6 BERT 模型简单使用 16.6.1 安装 tf2-bert 模块并准备预训练模型 16.6.2 使用 BERT 进行文本特征提取 16.6.3 使用 BERT 进行完形填空 16.7 BERT 电商用户多情绪判断项目\\n\\n15\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 16.7.1 项目背景介绍 16.7.2 模型训练 16.7.3 模型预测',\n",
       " '第 17 章 音频信号处理 17.1 深度学习在声音领域的应用介绍 17.1.1 音频分类 17.1.2 音频事件检测 17.1.3 语音识别 17.1.4 音乐检索 17.1.5 音乐生成 17.1.6 语音合成 17.1.7 语音克隆 17.2 MFCC 和 Mel Filter Banks 17.2.1 音频数据采集 17.2.2 分帧加窗 17.2.3 傅里叶变换 17.2.4 梅尔滤波器（Mel Filter Banks） 17.2.5 梅尔频率倒谱系数 MFCC 17.3 语音分类项目 17.3.1 音频处理库 librosa 介绍 17.3.2 音频分类项目-模型训练 17.3.3 音频分类项目-模型预测\\n\\n第 18 章 图像风格转换 18.1 图像风格转换实现原理 18.1.1 代价函数的定义 18.1.2 格拉姆矩阵（Gram Matrix）介绍 18.2 图像风格转换项目实战 18.3 遮挡图像风格转换项目实战',\n",
       " '第 19 章 生成对抗网络 GANs 19.1 生成对抗网络的应用 19.1.1 图像生成 19.1.2 向量空间运算 19.1.3 改变年龄或美颜 19.1.4 图像转换 19.1.5 文本转图像 19.1.6 超分辨率 19.1.7 换脸 19.2 DCGAN 介绍 19.2.1 DCGAN 原理 19.2.2 转置卷积（Transposed Convolution）介绍\\n\\n16\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 19.2.3 DCGAN 模型结构 19.3 手写数字图像生成',\n",
       " '第 20 章 模型部署 20.1 Tensorflow Serving 环境部署 20.1.1 安装 Docker 20.1.2 拉取 Tensorflow Serving 镜像 20.2 运行客户端和服务器程序 20.2.1 准备 SavedModel 模型 20.2.2 启动 Tensorflow Serving 服务器程序 20.2.3 Tensorflow Serving 客户端 gRPC 程序 20.2.4 Tensorflow Serving 客户端 REST API 程序\\n\\n专业术语汇总 结束语\\n\\n17\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 1 章-深度学习背景介绍\\n\\n本章主要介绍人工智能，机器学习，神经网络，深度学习相关的一些概念，应用，发展史\\n\\n以及重要人物等背景信息。这些背景知识虽然对我们的实际应用没有直接帮助，但是可以加深\\n\\n我们对人工智能这个行业的理解，属于内功修行的范畴。\\n\\n1.1 人工智能\\n\\n1997 年 5 月 3 日-1997 年 5 月 11 日一场别开生面的比赛在纽约的公平大厦举行，吸引',\n",
       " '了全世界的关注。对垒的双方分别是世界国际象棋冠军卡斯帕罗夫和 IBM 的超级计算机“深\\n\\n蓝”。经过六场激烈的比赛，“深蓝”最终战胜了卡斯帕罗夫，赢得了具有特殊意义的胜利。\\n\\n而这一次比赛也载入了人类的史册。\\n\\n而另一场可以载入人类史册的人机大战发生在 2016 年 3 月 9 日-2016 年 3 月 15 日。这\\n\\n一次比赛双方是世界顶级围棋棋手李世石和 Google 的人工智能 AlphaGo。赛前有很多人并\\n\\n不看好 AlphaGo，认为 AlphaGo 会惨败。没想到 AlphaGo 最终以 4:1 大胜李世石，从而一\\n\\n战成名。由于 AlphaGo 的胜利，AlphaGo 用到的深度学习（Deep Learning）技术以及人\\n\\n工智能（Artificial Intelligence）也成为了当下最热门的技术话题。\\n\\n人工智能（Artificial Intelligence），英文缩写 AI。AI 第一次被提出来是在 1956 年，是\\n\\n由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议 （Dartmouth',\n",
       " '由四位图灵奖得主、信息论创始人和一位诺贝尔得主在美国达特茅斯会议 （Dartmouth\\n\\nConference）上一同定义出来的。人工智能只是一个抽象概念，它不是任何具体的机器或算\\n\\n法。任何类似于人的智能或高于人的智能的机器或算法都可以称为人工智能。比如几年前我们\\n\\n去洗车的时候会看到洗车店写着自动化洗车，看起来很高级。今天我们再去看，可能它改成了\\n\\n18\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n人工智能洗车，看起来更高级。实际上它的技术并没有改变，只是改了一个名字。随着人工智\\n\\n能技术的大热，很多商品都挂上了人工智能的标签，实际上任何看起来有一点智能的算法和机\\n\\n器都可以称为人工智能，所以人工智能这个标签并不能代表某个商品的技术水平。\\n\\n提到人工智能，不得不说到一个非常著名的关于人工智能的测试，图灵测试（Turing Test）。\\n\\n图灵测试是由计算机科学之父图灵提出来的，指的是测试者和被测试者（被测试者有可能是人\\n\\n或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之',\n",
       " '或机器）在隔离的情况下，测试者通过一些装置（如键盘）向被测试者提问。经过多次测试之\\n\\n后，如果有 30%的测试者不能确定被测试者是人还是机器，那么说明这台机器通过了测试。\\n\\n虽然图灵测试早在 1950 年被提出，但是至今没有机器能够很好地通过图灵测试。偶尔会\\n\\n有一些新闻报道说某某机器通过了图灵测试，但是这些通过图灵测试的机器往往会受到很多人\\n\\n质疑，并且经不住多次实验。\\n\\n人工智能早期阶段，迅速解决了一些对于人类来说比较困难，但是对于计算机来说相对容\\n\\n易的问题，比如下棋，推理，路径规划等等。我们下象棋的时候，通常需要思考很久才能推算\\n\\n出几步棋之后棋盘战局的变化，并且经常还会有看错看漏的情况。而计算机能在一瞬间计算出\\n\\n七八步棋甚至十几步棋之后棋盘的情况，并从中选出对自己最有利的下法来与对手对弈。面对\\n\\n如此强大的对手，人类早在 20 年前就已经输了。可能有人会想到人工智能在象棋领域早就战\\n\\n胜了人类最顶尖的选手，为什么在围棋领域一直到 2016 年才出了个 AlphaGo 把人类顶级棋\\n\\n手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋 AI 的时候可',\n",
       " '手击败。比起象棋，围棋的局面发展的可能性要复杂得多。或许我们在设计象棋 AI 的时候可\\n\\n以使用暴力计算的方法，把几步之内所有可能的走法都遍历一次，然后选一个最优下法。同样\\n\\n的方法放到围棋上就行不通了，围棋每一步的可能性都太多了，用暴力计算法设计出来的围棋\\n\\nAI，它的棋力是很差的。虽然 AlphaGo 的计算非常快，可以在短时间完成大量运算，但是\\n\\nAlphaGo 比其他棋类 AI 强的地方并不是计算能力，而是它的算法，也可以理解为它拥有更强\\n\\n大的“智慧”。就像是进行小学速算比赛，题目是 100 以内的加减法，10 个小学生为一队，\\n\\n19\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1 个数学系的博士为另一队。如果比赛内容是 1 分钟哪个队做的正确题目多，小学生队肯定是\\n\\n能够战胜数学博士的。如果是进行大学生数学建模比赛，那 10000 个小学生也赢不了 1 个数\\n\\n学博士。对于解决复杂的问题，需要的往往不只是计算速度，更多的应该是智慧。\\n\\n对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完',\n",
       " '对于一些人类比较擅长的任务，比如图像识别，语音识别，自然语言处理等，计算机却完\\n\\n成得很差。人类的视觉从眼睛采集信息开始，但起到主要作用的是大脑。人类的每个脑半球中\\n\\n都有着非常复杂的视觉皮层，包含着上亿个神经元以及几百亿条神经元之间的连接。人类的大\\n\\n脑就像是一台超级计算机，可以轻松处理非常复杂的图像问题。神经元之间的电信号可以快速\\n\\n传递，但是就像前面说到的，对于复杂的问题，计算速度只是一方面。人类的视觉能力是通过\\n\\n几亿年地不断进化，不断演变最终才得到的，更强的视觉和听觉能力使得人类可以拥有更强的\\n\\n生存能力。\\n\\n在人工智能的早期阶段，计算机的智能通常是基于人工制定的“规则”，我们可以通过详\\n\\n细的规则去定义下棋的套路，推理的方法，以及路径规划的方案。但是我们却很难用规则去详\\n\\n细描述图片中的物体，比如我们要判断一张图片中是否存在猫。那我们首先要通过规则去定义\\n\\n一只猫，如图 1.1 所示。\\n\\n图 1.1 猫（Cat）\\n\\n观察图 1.1 中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身',\n",
       " '观察图 1.1 中的猫，我们可以知道猫有一个圆脑袋，两个三角形的耳朵，又胖又长的身\\n\\n体，和一条长尾巴，然后可以定义一套规则在图片中寻找猫。这看起来好像是可行的，但是\\n\\n20\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n如果我们遇到的是图 1.2，图 1.3 中的猫该怎么办？（我家领养的猫，刚来的时候上厕所比较\\n\\n臭，故取名“臭臭”）\\n\\n图 1.2 藏起来的“臭臭”\\n\\n图 1.3 盘成一团的“臭臭”\\n\\n猫可能只露出身体的一部分，可能会摆出奇怪的造型，那么我们又要针对这些情况定义\\n\\n新的规则。从这个例子中大家应该能看得出来，即使是一只很普通的家养宠物，都可能会出\\n\\n现无数种不同的外形。如果我们使用人工定义的规则去定义这个物体，那么可能需要设置非\\n\\n常大量的规则，并且效果也不一定会很好。仅仅一个物体就这么复杂，而现实中常见的各种\\n\\n21\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n物体成千上万，所以在图像识别领域，使用使用人为定义的规则去做识别肯定是行不通的。\\n\\n很多其他的领域也同样存在这种问题。\\n\\n1.2 机器学习',\n",
       " '很多其他的领域也同样存在这种问题。\\n\\n1.2 机器学习\\n\\n由于人们没有办法设计出足够复杂的规则来精确描述世界，所以 AI 系统需要具备自我学\\n\\n习的能力，即从原始数据中获取有用的知识。这种能力被称为机器学习（Machine Learning）。\\n\\n人工智能是抽象的概念，而机器学习是具体的可以落地的算法。机器学习不是一个算法，\\n\\n而是一大类具体智能算法的统称。使用机器学习算法我们可以解决生活中如人脸识别，垃圾邮\\n\\n件分类，语音识别等具体问题。\\n\\n机器学习其实与人类学习的过程类似。打个比方：假如我们现在都是原始人，并不知道太\\n\\n阳和月亮是什么东西。但是我们可以观察天上的太阳和月亮，并且把太阳出来时候的光线和温\\n\\n度记录下来，把月亮出来时候的光线和温度记录下来（这就相当于是收集数据）。观察了 100\\n\\n天之后，我们进行思考，总结这 100 天的规律我们可以发现，太阳和月亮是交替出现的（偶尔\\n\\n同时出现可以忽略）。出太阳的时候光线比较亮，温度比较高。月亮出来的时候光线比较暗，\\n\\n温度比较低（这相当于是分析数据，建立模型）。之后我们看到太阳准备落山，月亮准备出来',\n",
       " '温度比较低（这相当于是分析数据，建立模型）。之后我们看到太阳准备落山，月亮准备出来\\n\\n的时候我们就知道温度要降低可能要多穿树叶或毛皮（原始人没有衣服），光线也准备要变暗\\n\\n了（预测未来的情况）。机器学习也可以利用已有的数据进行学习，获得一个训练好的模型，\\n\\n然后可以利用此模型预测未来的情况。\\n\\n22\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.4 中表现了机器学习与人类思维的对比。我们可以使用历史数据来训练一个机器学习\\n\\n的模型，模型训练好之后，再放入新的数据，模型就可以对新的数据进行预测分析。人类也善\\n\\n于从以往的经验中总结规律，当遇到新的问题时，我们可以根据之前的经验来预测未来的结果。\\n\\n图 1.4 机器学习与人类思维的对比\\n\\n1.2.1 训练数据，验证数据和测试数据\\n\\n通常我们在做机器学习分析的时候，会把数据分成两大部分。一部分是训练数据（Training\\n\\nData），可以用来训练，构建模型。另一部分是测试数据（Testing Data），可以用来验证模',\n",
       " '型的好坏。这两部分就有点像我们上学时课本中的习题。正文中的例题是训练数据，有答案和\\n\\n详细讲解，是用来教我们学习新知识的，可以看作是用来对我们进行训练。而课后习题是测试\\n\\n数据，我们要先做题，做完之后再对答案，是用来检查我们学习效果的。\\n\\n有时我们会把数据分成三部分，即训练集（Training Set）、验证集（Validation Set）\\n\\n和测试集（Testing Set）。训练集还是用来训练模型。验证集是在模型的训练阶段评估模型的\\n\\n好坏，可以用于确定模型的参数或结构。等模型训练好，并且结构和参数都调整好之后，再用\\n\\n测试集来评估模型的好坏。通常我们可以把所有数据的 60%分配给训练集，20%分配的验证\\n\\n集，20%分配给测试集。或者 80%分配给训练集，10%分配给验证集，10%分配给测试集。\\n\\n23\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过这个数据划分不是绝对的，还需要看具体情况。有时候我们只划分训练集和测试集，训练\\n\\n集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。',\n",
       " '集用于训练模型，不管在模型的训练阶段还是最后的测试阶段都是用测试集来进行测试。\\n\\nK 折交叉检验(K-fold Cross-Validation) —— K 折交叉检验的大致思想是把数据集分\\n\\n成 K 份，每次取一份作为测试集，取余下的 K-1 份作为训练集。重复训练 K 次，每次训练都\\n\\n从 K 个部分中选一个不同的部分作为测试集（要保证 K 个部分的数据都分别做过测试），剩下\\n\\n的 K-1 份做训练集。最后把得到的 K 个结果做平均。\\n\\n1.2.2 学习方式\\n\\n在机器学习或者人工智能领域，不同的问题可能会有不同的学习方式。主要的学习方法有：\\n\\n监督学习（Supervised Learning） —— 监督学习也称为有监督学习，通常可以用于\\n\\n分类（Classification）以及回归（Regression）的问题。它的主要特点是，所有的数据都有\\n\\n与之相对应的标签（Label）。比如我们想做一个识别手写数字的模型，那么我们的数据集就是\\n\\n大量手写数字的图片，并且每一张图片都有对应的标签，如图 1.5：\\n\\n图 1.5 标签为 3',\n",
       " '大量手写数字的图片，并且每一张图片都有对应的标签，如图 1.5：\\n\\n图 1.5 标签为 3\\n\\n图片是一个手写数字 3，所以这张图片的标签可以设置为 3。同样的，如果是一张手写\\n\\n数字 8 的图片，那么该图片的标签就可以是 8。或者我们要建立一个判别垃圾邮件的模型，\\n\\n24\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n那我们先要对邮件进行标记，标记出哪些属于垃圾邮件，哪些不属于垃圾邮件，然后建立模\\n\\n型。\\n\\n监督学习在建模过程中，会将预测结果与训练数据的实际结果（也就是标签）做对比，\\n\\n如果预测结果跟实际结果不符合，将通过一些方式去调整模型的参数，直到模型的预测结果\\n\\n能达到比较高的准确率。\\n\\n非监督学习（Unsupervised Learning)）—— 非监督学习也称为无监督学习，通常可\\n\\n以用于聚类（Clustering）的问题。非监督学习中，所有的数据都是没有标签的。可以使用\\n\\n机器学习的方法让数据自动聚类。例如许多公司都拥有庞大的客户信息数据库，使用非监督\\n\\n学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我',\n",
       " '学习的方法就可以自动对客户进行市场分割，将客户分到不同的细分市场中，从而有助于我\\n\\n们对不同细分市场的客户进行更有效的销售或者广告推送。或许我们事先并不知道有哪些细\\n\\n分市场，也不知道哪些客户属于细分市场 A，哪些客户属于细分市场 B。不过没关系，我们\\n\\n可以让非监督学习算法在数据中挖掘这一切信息。\\n\\n半监督学习（Semi-Supervised Learning）—— 半监督学习是监督学习和非监督学\\n\\n习相结合的一种学习方式，通常可以用于分类以及回归问题。主要是用来解决使用少量带标\\n\\n签的数据和大量没有标签的数据进行训练和分类的问题。此类算法首先试图对没有标签的数\\n\\n据进行建模，然后再对带有标签的数据进行预测。说个题外话，半监督学习一般用得比较\\n\\n少，原因很简单，因为标签不足的情况通常很容易解决，只要找很多人来打标签就可以了。\\n\\n大型 AI 公司可能会有几百人的数据标注团队，每天的工作就是给各种数据打标签。因为顶尖\\n\\n大公司 AI 技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所',\n",
       " '大公司 AI 技术相差不是很大，想要把产品的效果做得更好，就需要大量的带标签的数据。所\\n\\n以现在有一句叫做人工智能，先有人工，后有智能，有多少人工，就有多少智能。这是玩笑\\n\\n话，大家看看就好，标签很重要，不过人工智能的核心还是算法，说不定以后有一天我们可\\n\\n以开发出不需要标签就可以什么都学会的算法。\\n\\n25\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n强化学习（Reinforcement Learning）—— 强化学习灵感来源于心理学中的行为主\\n\\n义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能\\n\\n够获得最大利益的习惯性行为。强化学习没有任何的标签来告诉算法应该怎么做，它会先去\\n\\n尝试做一些动作，然后得到一个结果，通过判断这个结果是对还是错来对之前的动作进行反\\n\\n馈。AlphaGo 中就用到了强化学习。不过目前强化学习的落地应用还比较少，大部分的应用\\n\\n还都只是用于打游戏。\\n\\n1.2.3 机器学习常用算法\\n\\n机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。',\n",
       " '机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n\\n所示。\\n\\n图 1.6 决策树(Decision Tree)\\n\\n26\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n\\n这些数据来建立回归模型，如图 1.7 所示。\\n\\n图 1.7 线性回归(Linear Regreesion)',\n",
       " '图 1.7 线性回归(Linear Regreesion)\\n\\n模型建立好之后，我们可以得到一条最符合房屋面积跟房屋价格关系的直线。根据这个\\n\\n模型，我们可以把一个新的房屋面积输入，就能得到该房屋的价格预测值。\\n\\nKNN（K-Nearest Neighbor） —— KNN 算法又称为 k 近邻分类(k-nearest neighbor\\n\\nclassification)算法，是一种监督学习算法。最简单的最近邻算法就是遍历所有已知标签的样\\n\\n本集中的数据，计算它们和需要分类的样本之间的距离（这里的距离一般指的是 欧氏距离\\n\\n（Euclidean Distance)），同时记录目前的最近点。KNN 查找的是已知标签的样本集中跟需\\n\\n要分类的样本最邻近的 K 个样本，需要分类的样本最终的标签是由这 K 个样本的标签决定的，\\n\\n采用的方式是“多数表决”。也就是在这 K 个样本中哪种标签最多，那么需要分类的样本就归\\n\\n为哪一类。下图中，方形表示分类 1，圆形表示分类 2，图中正中心的五角星表示需要分类的',\n",
       " '为哪一类。下图中，方形表示分类 1，圆形表示分类 2，图中正中心的五角星表示需要分类的\\n\\n样本。当 K 等于 1 时，其实就是计算距离五角星最近的样本属于哪一个分类。图 1.8 中，我们\\n\\n可以看到距离五角星最近的是方形，属于分类 1，所以我们可以把五角星归为分类 1。\\n\\n27\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.8 KNN 分类，K 等于 1\\n\\n当我们取 K=5 时，其实就是找出距离五角星最近的 5 个样本，然后统计这 5 个样本哪\\n\\n种分类比较多。图 1.9 中我们可以看到，有 1 个方形和 4 个圆形，那么圆形比较多，所以我\\n\\n们可以把五角星归为分类 2。\\n\\n图 1.9 KNN 分类，K 等于 5\\n\\n这里我们可以看到，五角星最终的分类跟 K 的取值有很大关系。K 值取多少，模型的效\\n\\n果才比较好呢？这可能需要对模型进一步调试，才能得到答案，比如我们可以不断改变 K\\n\\n值，然后用测试集来做测试，最终选取一个可以使得测试误差比较小的 K 值。\\n\\n28\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '28\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nK-Means —— K-Means 是一种无监督学习算法，通常可以用于聚类分析。所谓聚类\\n\\n问题，就是给定一个元素集合 A，集合中的每个元素有 n 个可观测的属性。我们需要使用某\\n\\n种方法把 A 划分为 k 个子集，并且要使得每个子集内部元素之间的差异尽可能小，不同子集\\n\\n之间元素的差异尽可能大。K-Means 算法的计算过程比较直观也比较简单：\\n\\n（1）先从没有标签的元素集合 A 中随机取 k 个元素，作为 k 个子集各自的重心。\\n\\n（2）分别计算剩下的元素到 k 个子集重心的距离（这里的距离也可以使用欧氏距离），\\n\\n根据距离将这些元素分别划归到最近的子集。\\n\\n（3）根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的\\n\\n算数平均数）。\\n\\n（4）将集合 A 中全部元素按照新的重心然后再重新聚类。\\n\\n（5）重复第（4）步，直到聚类结果不再发生变化。\\n\\nK-Means 运行过程如图 1.10~图 1.12 所示。\\n\\n图 1.10 K-Means 算法，第 1 次迭代\\n\\n29',\n",
       " '图 1.10 K-Means 算法，第 1 次迭代\\n\\n29\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.11 K-Means 算法，第 5 次迭代\\n\\n图 1.12 K-Means 算法，第 9 次迭代\\n\\n聚类模型一共迭代了 9 次，最终收敛。从图中我们可以看得出来第 1 次迭代的时候，模\\n\\n型的聚类效果是很差的，一看就不太合理。迭代了 5 次之后，模型有了一些改善，聚类的效\\n\\n果已经不错了，不过看得出来还有一些提高的空间。迭代 9 次之后，模型就训练好了，很好\\n\\n地把没有标签的数据分成了 4 类。相同类别之间的差距比较小，不同类别之间的差距比较\\n\\n大。\\n\\n神经网络（Neural Network）—— 神经网络是一种模拟人类大脑神经网络结构构建\\n\\n出来的算法。神经网络的结构可以有多层，多层的神经网络可以由输入层（Input Layer），\\n\\n隐藏层（Hidden Layers）以及输出层（Output Layer）组成。其中隐藏层可能有 0 到多\\n\\n30\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '30\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n个，所以最简单的神经网络就只有输入层和输出层。神经网络的每一层都由若干个神经元\\n\\n（Neuron）节点组成。\\n\\n信号从输出层传入网络，与神经元的权值（Weights）作用后再经过激活函数\\n\\n（Activation Function）传入下一层。每一层信号的输出都是下一层的输入，直到把信号\\n\\n传到输出层得出结果。网络结构如图 1.13 所示：\\n\\n图 1.13 神经网络（Neural Network）\\n\\n神经网络是深度学习的重要基础，在后面的章节中我们会从头开始详细学习神经网络的\\n\\n搭建以及应用，这里只是先做一个简单介绍。\\n\\n除了上面介绍的这些算法以外，机器学习领域还有很多其他的算法，如朴素贝叶斯\\n\\n(Naive Bayes)，支持向量机 SVM(Support Vector Machine)， Adaboost 等。\\n\\n31\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.3 人工智能、机器学习，神经网络以及深度学\\n\\n习之间的关系',\n",
       " '1.3 人工智能、机器学习，神经网络以及深度学\\n\\n习之间的关系\\n\\n新闻媒体在报道 AlphaGo 的时候，可能人工智能，机器学习，神经网络和深度学习这\\n\\n几个词都有用到过。对于初学者来说，难免容易混淆。\\n\\n人工智能 —— 我们先说说人工智能，人工智能是这几个词中最早出现的。1956 年，\\n\\n在美国达特茅斯会议（Dartmouth Conference）上被提出。人工智能其实是一种抽象的概\\n\\n念，并不是指任何实际的算法。人工智能可以对人的意识、思维进行模拟，但又不是人的智\\n\\n能。有时候我们还会把人工智能分为弱人工智能（Weak AI）和强人工智能（Strong AI）。\\n\\n弱人工智能是擅长于单个方面技能的人工智能。比如 AlphaGo 能战胜了众多世界围棋\\n\\n冠军的，在围棋领域所向披靡，但它只会下围棋，做不了其他事情。我们目前的人工智能相\\n\\n关的技术，比如图像识别，语言识别，自然语言处理等等，基本都是处于弱人工智能阶段。\\n\\n强人工智能指的是在各方面都能和人类智能差不多的人工智能，人类能干的脑力劳动它\\n\\n都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一',\n",
       " '都能干。创造强人工智能比创造弱人工智能难度要大很多，我们现阶段还做不到，只有在一\\n\\n些科幻电影中才能看到。著名的教育心理学教授 Linda Gottfredson 把智能定义为“一种宽\\n\\n泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念、快速学习和从\\n\\n经验中学习等操作。”强人工智能在进行这些操作时应该跟人类一样得心应手。\\n\\n机器学习 —— 机器学习是最近 20 多年兴起的一门多领域交叉学科，涉及概率论、统\\n\\n计学、逼近学、凸分析、计算复杂性理论等多门学科。关于机器学习，上一小节我们已经做\\n\\n了一些讨论说明，我们可以发现机器学习包含很多具体的算法。既然人工智能是飘在天上的\\n\\n32\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n概念，那我们就需要一些具体的算法使得人工智能可以落地应用，而一般来说，这些具体的\\n\\n智能算法可以统称为机器学习算法。\\n\\n神经网络 —— 神经网络是众多机器学习算法中的其中一个，是模仿人类大脑神经结构\\n\\n构建出来的一种算法，构建出来的网络称为人工神经网络（Artificial Neural Networks，',\n",
       " 'ANN）。神经网络算法在机器学习中并不算特别出色，所以一开始的时候并没有引起人们的\\n\\n特别关注。神经网络的发展已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代神经网络\\n\\n的雏形出现在控制论（Cybernetics）中，20 世纪 80 年代到 90 年代表现为联结主\\n\\n（Connectionism）。直到 2006 年神经网络重新命名为深度学习，再次兴起。\\n\\n深度学习 —— 深度学习的基础其实就是神经网络，之所以后来换了一种叫法，主要是\\n\\n由于之前的神经网络算法中网络的层数不能太深，也就是不能有太多层网络，网络层数过多\\n\\n会使得网络无法训练。随着神经网络理论的发展，科学家研究出了多种方式使得训练深层的\\n\\n网络也成为可能，深度学习由此诞生。如卷积神经网络（Convolutional Neural\\n\\nNetwork, CNN），长短时记忆网络（Long Short Term Memory Network, LSTM），深\\n\\n度残差网络（Deep Residual Network）等都属于深度学习，其中深度残差网络的深度可',\n",
       " '以到达 1000 层，甚至更多。深层的网络有助于挖掘数据中深层的特征，可以使得网络拥有\\n\\n更强大的性能。\\n\\n图 1.14 描绘了人工智能、机器学习、神经网络和深度学习之间的关系。\\n\\n33\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.14 人工智能、机器学习、神经网络和深度学习之间的关系\\n\\n1.4 深度学习应用\\n\\n深度学习最早兴起于图像识别，在最近几年可以说是已经深入各行各业。深度学习在计算\\n\\n机视觉，语音识别，自然语言处理，机器人控制，生物信息，医疗，法律，金融，推荐系统，\\n\\n搜索引擎，电脑游戏，娱乐等领域均有应用。\\n\\n图像识别 —— 图像识别可以说是深度学习最早实现突破性成就的领域。如今计算机对\\n\\n图片的识别能力已经跟人类不相上下。我们把一张图片输入神经网络，经过网络的运算，最后\\n\\n可以得到图片的分类。如图 1.15 所示，我们可以看到，对于每一张图片，神经网络都给出了\\n\\n5 个最有可能的分类，排在最上面的可能性最大。图中的置信度表示的就是该图片的概率值。\\n\\n34\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '34\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.15 图像识别\\n\\n目标检测 —— 利用深度学习我们还可以识别图片中的特定物体，然后对该物体进行标\\n\\n注，如图 1.16 所示。\\n\\n图 1.16 目标检测[1]\\n\\n人脸识别 —— 深度学习还可以识别图像中的人脸，判断是男人还是女人，判断人的年龄，\\n\\n判断图像中的人是谁等，如图 1.17 所示。\\n\\n35\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.17 人脸识别\\n\\n目标分割 —— 目标分割识别出图中的物体，并且可以划分出物体的边界，如图 1.18 所\\n\\n示。\\n\\n图 1.18 目标分割[2]\\n\\n描述图片 —— 把一张图片输入神经网络中，就可以输出对这张图片的文字描述，如图\\n\\n1.19 所示。\\n\\n36\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.19 图片描述\\n\\n图片风格转换 —— 利用深度学习实现一张图片加上另一张图片的风格，然后生成一张\\n\\n新的图片，如图 1.20 所示。\\n\\n37',\n",
       " '新的图片，如图 1.20 所示。\\n\\n37\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.20 图片风格转换[3]\\n\\n语音识别 —— 深度学习还可以用来识别人说的话，把语音数据转换为文本数据，如图\\n\\n1.21 所示。\\n\\n图 1.21 语音识别\\n\\n文本分类 —— 使用深度学习对多个文本进行分类，比如判断一个评论是好评还是差评，\\n\\n或者判断一篇新闻是属于娱乐新闻，体育新闻还是科技新闻，如图 1.22 所示。\\n\\n38\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 1.22 文本分类\\n\\n机器翻译 —— 使用深度学习进行机器翻译，如图 1.23 所示。\\n\\n图 1.23 机器翻译\\n\\n诗词生成 —— 把一个诗词的题目传入神经网络，就可以生成一篇诗词，如图 1.24 所示，\\n\\n其就是 AI 写的一首诗。虽然这首诗有些看不太懂，但是已经“有内味了”。\\n\\n图 1.24 诗句生成\\n\\n39\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站',\n",
       " '图像生成 —— 深度学习还可以用来生成图片。比如我们可以打开网站\\n\\nhttps://make.girls.moe/#/，设置好动漫人物的头发颜色，头发长度，眼睛颜色，是否戴帽\\n\\n子等信息就可以生成符合条件的动漫人物。并且可以生成无数张不重复的照片，如图 1.25 所\\n\\n示。\\n\\n图 1.25 图像生成\\n\\n这里只是列举了非常少量的例子，深度学习的已经逐渐深入各行各业，深入我们的生活\\n\\n中。\\n\\n1.5 神经网络深度学习发展史\\n\\n神经网络的发展历史中有过三次热潮，分别发展在 20 世纪 40 年代到 60 年代，20 世纪\\n\\n80 年代到 90 年代，以及 2006 年至今。每一次神经网络的热潮都伴随着人工智能的兴起，人\\n\\n工智能和神经网络一直以来都有着非常密切的关系。\\n\\n40\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.5.1 神经网络诞生-20 世纪 40-60 年代\\n\\n1943 年，神经病学家和神经元解剖学家 W.S.McCulloch 和数学家 W.A.Pitts在生物物理',\n",
       " '学期刊发表文章提出神经元的数学描述和结构。并且证明了只要有足够的简单神经元，在这些\\n\\n神经元互相连接并同步运行的情况下，可以模拟任何计算函数，这种神经元的数学模型称为 M-\\n\\nP 模型。该模型把神经元的动作描述为：1.神经元的活动表现为兴奋或抑制的二值变化；2.任\\n\\n何兴奋性突触输入激励后，使神经元兴奋；3.任何抑制性突触有输入激励后，使神经元抑制；\\n\\n4.突触的值不随时间改变；5.突触从感知输入到传送出一个输出脉冲的延时时间是 0.5ms。\\n\\n尽管现在看来 M-P 模型过于简单，并且观点也不是完全正确，不过这个模型被认为是第\\n\\n一个仿生学的神经网络模型，他们提出的很多观点一直沿用至今，比如说他们认为神经元有两\\n\\n种状态，要不就是兴奋，要不就是抑制。这跟后面要提到的单层感知器非常类似，单层感知器\\n\\n的输出要不就是 0 要不就是 1。他们最重要的贡献就是开创了神经网络这个研究方向，为今天\\n\\n神经网络的发展奠定了基础。\\n\\n1949 年 ，另一 位心 理学 家\\n\\nDonald Olding Hebb 在他的 一 本名为',\n",
       " '1949 年 ，另一 位心 理学 家\\n\\nDonald Olding Hebb 在他的 一 本名为\\n\\n《The organization of behavior: A neuropsychological theory》[4]的书提出了 Hebb 算\\n\\n法。他也是首先提出“连接主义”（connectionism）这一名词的人之一，这个名词的含义是\\n\\n大脑的活动是靠脑细胞的组合连接实现的。Hebb 认为，如果源和目的神经元均被激活兴奋时，\\n\\n它们之间突触的连接强度将会增强。他指出在神经网络中，信息存储在连接权值中。并提出假\\n\\n设神经元 A 到神经元 B 连接权与从 B 到 A 的连接权是相同的。他这里提到的这个权值的思想\\n\\n也被应用到了我们目前所使用的神经网络中，我们通过调节神经元之间的连接权值来得到不同\\n\\n的神经网络模型，实现不同的应用。虽然这些理论在今天看来是理所当然的，不过在当时看来\\n\\n这是一种全新的想法，算得上是开创性的理论。\\n\\n41\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '41\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1958 年 ， 计算 机学 家 Frank Rosenblatt 提 出 了 一种神经网络 结 构，称为 感 知 器\\n\\n(Perceptron)。他提出的这个感知器可能是世界上第一个真正意义上的人工神经网络。感知\\n\\n器提出之后在 60 年代就掀起了神经网络研究的第一次热潮。很多人都认为只要使用成千上万\\n\\n的神经元，他们就能解决一切问题。现在看来可能会让人感觉 too young too naive，不过感\\n\\n知器在当时确实是影响非凡。\\n\\n这股感知器热潮持续了 10 年，直到 1969 年，人工智能的创始人之一的 M.Minsky 和\\n\\nS.Papert 出版了一本名为《感知器》[5]的书，书中指出简单神经网络只能运用于线性问题的求\\n\\n解，能够求解非线性问题的网络应具有隐层，而从理论上还不能证明将感知器模型扩展到多层\\n\\n网络是有意义的。由于 Minsky 在学术界的地位和影响，其悲观论点极大地影响了当时的人工\\n\\n神经网络研究，为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。这本书出版不不久之后，',\n",
       " '神经网络研究，为刚刚燃起希望之火的人工神经网络泼了一大盘冷水。这本书出版不不久之后，\\n\\n几乎所有为神经网络提供的研究基金都枯竭了，没有人愿意把钱浪费在没有意义的事情上。\\n\\n1.5.2 神经网络复兴-20 世纪 80-90 年代\\n\\n1982 年，美国加州理工学院的优秀物理学家 John J.Hopfield 博士提出了 Hopfield 神\\n\\n经网络。Hopfield 神经网络引用了物理力学的分析方法，把网络作为一种动态系统并研究这\\n\\n种网络动态系统的稳定性。\\n\\n1985 年，G.E.Hinton 和 T.J.Sejnowski借助统计物理学的概念和方法提出了一种随机神\\n\\n经网络模型——玻尔兹曼机(Boltzmann Machine)。一年后他们又改进了模型，提出了受限\\n\\n玻尔兹曼机(Restricted Boltzmann Machine)。\\n\\n1986 年，Rumelhart，Hinton，Williams 提出了 BP(Back Propagation)算法[6]（多层\\n\\n感知器的误差反向传播算法）。到今天为止，这种多层感知器的误差反向传播算法还是非常基',\n",
       " '感知器的误差反向传播算法）。到今天为止，这种多层感知器的误差反向传播算法还是非常基\\n\\n础的算法，凡是学神经网络的人，必然要学习 BP 算法。我们现在的深度网络模型基本上都是\\n\\n42\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在这个算法的基础上发展出来的。使用 BP 算法的多层神经网络也称为 BP 神经网络（Back\\n\\nPropagation Neural network）。BP 神经网络主要指的是 20 世纪 80-90 年代使用 BP 算\\n\\n法的神经网络，虽然现在的深度学习也用 BP 算法，不过网络名称已经不叫 BP 神经网络了。\\n\\n早期的 BP 神经网络的神经元层数不能太多，一旦网络层数过多，就会使得网络无法训练，具\\n\\n体原因在后面的章节中会详细说明。\\n\\nHopfield 神经网络，玻尔兹曼机以及受限玻尔兹曼机由于目前已经较少使用，所以本书\\n\\n后面章节不再详细介绍这三种网络。\\n\\n1.5.3 深度学习-2006 年至今\\n\\n2006 年，多伦多大学的教授 Geoffrey Hinton 提出了深度学习。他在世界顶级学术期刊',\n",
       " '《 Science 》上发表了 一篇论 文《 Reducing the dimensionality of data with neural\\n\\nnetworks》[7]，论文中提出了两个观点：①多层人工神经网络模型有很强的特征学习能力，深\\n\\n度学习模型学习得到的特征数据对原始数据有更本质的代表性，这将大大便于分类和可视化问\\n\\n题；②对于深度神经网络很难训练达到最优的问题，可以采用逐层训练方法解决。将上层训练\\n\\n好的结果作为下层训练过程中的初始化参数。在这一文献中深度模型的训练过程中逐层初始化\\n\\n采用无监督学习方式。\\n\\nHinton 在论文中提出了一种新的网络结构深度置信网络（Deep Belief Net：DBN），这\\n\\n种网络使得训练深层的神经网络成为可能。深度置信网络由于目前已经较少使用，所以本书后\\n\\n面章节不再详细介绍这种网络。\\n\\n2012 年，Hinton 课题组为了证明深度学习的潜力，首次参加 ImageNet 图像识别比赛，\\n\\n通过 CNN 网络 AlexNet 一举夺得冠军。也正是由于该比赛，CNN 吸引了众多研究者的注意。\\n\\n43',\n",
       " '43\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n44\\n\\n2014 年，香港中文大学教授汤晓鸥领导的计算机视觉研究组开发了名为 DeepID 的深度\\n\\n学习模型， 在 LFW (Labeled Faces in the Wild，人脸识别使用非常广泛的测试基准)数据库\\n\\n上获得了 99.15%的识别率，人用肉眼在 LFW 上的识别率为 97.52%，深度学习在学术研究层\\n\\n面上已经超过了人用肉眼的识别。\\n\\n2016 年 3 月人工智能围棋比赛，由位于英国伦敦的谷歌（Google）旗下 DeepMind 公\\n\\n司的开发的 AlphaGo 战胜了世界围棋冠军、职业九段选手李世石，并以 4:1 的总比分获胜。\\n\\n2018 年 6 月，OpenAI 的研究人员开发了一种技术，可以在未标记的文本上训练 AI，可\\n\\n以大量减少人工标注的时间。几个月后谷歌推出了一个名为 BERT 的模型，该模型在学习了几\\n\\n百万个句子 以 后 学 会 了如何预 测 漏掉的单词。 在多 项\\n\\nNLP (Natural Language',\n",
       " 'NLP (Natural Language\\n\\nProcessing) 测试中，它的表现都接近人类。\\n\\n2020 年 6 月，OpenAI 发布了有史以来最大的 NLP 模型 GPT-3，GPT-3 模型参数达到\\n\\n了 1750 亿个参数，模型训练花费了上千万美元。GPT-3 训练方法很简单，但是却非常全能，\\n\\n可以完成填空，翻译，问答，阅读理解，数学计算，语法纠错等多项任务。随着 NLP 技术的\\n\\n发展，相信在将来 AI 可以逐渐理解我们的语言，跟我们进行顺畅的对话，甚至成为我们的保\\n\\n姆，老师或朋友。\\n\\n今天，人脸识别技术已经应用在了我们生活的方方面面，比如上下班打卡，飞机高铁出行，\\n\\n出门住酒店，刷脸支付等。我们已经离不开深度学习技术，而深度学习技术仍在快速发展中。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1.6 深度学习领域重要人物\\n\\n深度学习领域有很多做出过卓越贡献的大师，下面简单介绍几位。前面的 3 位大师\\n\\nGeoffrey Hinton、Yann LeCun、Yoshua Bengio 江湖人称“深度学习三巨头”，为了表彰 3',\n",
       " '位大师对于神经网络深度学习领域的贡献，2018 年计算机领域最高奖项图灵奖颁给了他们。\\n\\n1.Geoffrey Hinton\\n\\n英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。Hinton 是反向传\\n\\n播算法和对比散度算法的发明人之一，也是深度学习的积极推动者。目前担任多伦多大学计\\n\\n算机科学系教授。\\n\\n2013 年 3 月加入 Google，领导 Google Brain 项目。\\n\\nHinton 被人们称为“深度学习教父”，可以说是目前对深度学习领域影响最大的人。而\\n\\n且如今在深度学习领域活跃的大师，有很多都是他的弟子，可以说是桃李满天下。\\n\\n2.Yann LeCun\\n\\n法国出生的计算机科学家，他最著名的工作是光学字符识别和计算机视觉上使用卷积神经\\n\\n网络（CNN），他也被称为卷积网络之父。\\n\\n曾在多伦多大学跟随 Geoffrey Hinton 做博士后。1988 年加入贝尔实验室，在贝尔实验\\n\\n室工作期间开发了一套能够识别手写数字的卷积神经网络系统，并把它命名为 LeNet。这个系\\n\\n统能自动识别银行支票。',\n",
       " '统能自动识别银行支票。\\n\\n2003 年去了纽约大学担任教授，现在是纽约大学终身教授。\\n\\n2013 年 12 月加入了 Facebook，成为 Facebook 人工智能实验室的第一任主任。\\n\\n3.Yoshua Bengio\\n\\n45\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n毕业于麦吉尔大学，在 MIT 和贝尔实验室做过博士后研究员，自 1993 年之后就在蒙特\\n\\n利尔大学任教。在预训练问题，自动编码器降噪等领域做出重大贡献。\\n\\n这“三巨头”中的前两人早已投身工业界，而 Bengio 仍留在学术界教书，他曾说过：\\n\\n“我留在学术圈是为全人类作贡献，而不是为某一公司赚钱”。他说这句话一定是因为他很有\\n\\n钱，开个玩笑。每个领域的发展不仅需要做前沿的研究，还需要不断培养新的新鲜血液加入\\n\\n到这个行业中，所以如果大学教授都去工作的话，上课教书的人就少了。所以 Bengio 能留\\n\\n在学术圈，对行业的发展也是一件好事。\\n\\n2017 年初 Bengio 选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他',\n",
       " '2017 年初 Bengio 选择加入微软成为战略顾问。他表示不希望有一家或者两家公司（他\\n\\n指的显然是 Google 和 Facebook）成为人工智能变革中的唯一大玩家，这对研究社区没有\\n\\n好处，对人类也没有好处。\\n\\n4.Andrew Ng（吴恩达）\\n\\nAndrew Ng 是美籍华人，曾经是斯坦福大学计算机科学系和电气工程系的副教授，斯\\n\\n坦福人工智能实验室主任。他还与 Daphne Koller 一起创建了在线教育平台 Coursera。\\n\\n2011 年，Andrew Ng 在 Google 创建了 Google Brain 项目，通过分布式集群计算机\\n\\n开发超大规模的人工神经网络。\\n\\n2014 年 5 月，Andrew Ng 加入百度，负责百度大脑计划，并担任百度公司首席科学\\n\\n家。\\n\\n2017 年 3 月，Andrew Ng 从百度离职，目前自己创业。\\n\\nLeCun 是 Hinton 的 博士生，另一位人工智能大师 Jordan 曾经申请过 Hinton 的博士',\n",
       " '生，Bengio 是 Jordan 的博士后，Andrew Ng 是 Jordan 的博士生，LeCun 与 Bengio 曾\\n\\n经是同事。这个圈子很小，大家都认识，这几位大师互相之间有着很深的渊源。\\n\\n46\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n曾经神经网络的圈子很小，基本上入了这个圈以后就没什么前途了。正是由于这个圈子\\n\\n里的这些大师前辈们的不懈努力，把神经网络算法不断优化，才有了今天的深度学习和今天\\n\\n人工智能的新局面。\\n\\n1.7 新一轮人工智能爆发的三要素\\n\\n这一轮人工智能大爆发的主要原因有 3 个，深度学习算法，大数据，以及高性能计算。\\n\\n深度学习算法 —— 之前人工智能领域的实际应用主要是使用传统的机器学习算法，虽\\n\\n然这些传统的机器学习算法在很多领域都取得了不错的效果，不过仍然有非常大的提升空间。\\n\\n深度学习出现后，计算机视觉，自然语言处理，语音识别等领域都取得了非常大的进步。\\n\\n大数据 —— 如果把人工智能比喻成一个火箭，那么这个火箭需要发射升空，它的燃料就',\n",
       " '大数据 —— 如果把人工智能比喻成一个火箭，那么这个火箭需要发射升空，它的燃料就\\n\\n是大数据。以前在实验室环境下很难收集到足够多的样本，现在的数据相对以前在数量、覆盖\\n\\n性和全面性方面都获得了大幅提升。一般来说深度学习模型想要获得好的效果，就需要把大量\\n\\n的数据放到模型中进行训练。\\n\\n高性能计算 —— 以前高性能计算大家 用的是 CPU 集群，现在做深度学习都是 用\\n\\nGPU(Graphics Processing Unit)或 TPU(Tensor Processing Unit)。想要使用大量的数据\\n\\n来训练复杂的深度学习模型那就必须要具备高性能计算能力。GPU 就是我们日常所说的显卡，\\n\\n平时主要用于打游戏。但是 GPU 不仅可以用于打游戏，还可以用来训练模型，性价比很高，\\n\\n买显卡的理由又多了一个。如果只是使用几个 CPU 来训练一个复杂模型可能会需要花费几周\\n\\n甚至几个月的时间。把数百块 GPU 连接起来做成集群，用这些集群来训练模型，原来一个月\\n\\n才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时\\n\\n47',\n",
       " '才能训练出来的网络，可以加速到几个小时甚至几分钟就能训练完，可以大大减少模型训练时\\n\\n47\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n间。TPU 是谷歌专门为机器学习量身定做的处理器，执行每个操作所需的晶体管数量更少，效\\n\\n率更高。\\n\\n工欲善其事，必先利其器。下一章节我们将介绍如何搭建 python 开发环境，为我们后续\\n\\n的学习做准。\\n\\n1.8 参考文献\\n\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\n\\narXiv:1804.02767, 2018.\\n\\n[2] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\n\\ninternational conference on computer vision. 2017: 2961-2969.',\n",
       " '[3] Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint\\n\\narXiv:1508.06576, 2015.\\n\\n[4] Hebb D O. The organization of behavior: A neuropsychological theory[M].\\n\\nPsychology Press, 2005.\\n\\n[5] Minsky M, Papert S A. Perceptrons: An introduction to computational\\n\\ngeometry[M]. MIT press, 2017.\\n\\n[6] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-\\n\\npropagating errors[J]. nature, 1986, 323(6088): 533-536.',\n",
       " '[7] Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets[J].\\n\\nNeural computation, 2006, 18(7): 1527-1554.\\n\\n48\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 章-搭建 Python 编程环境\\n\\n本章节内容与深度学习没有直接关系，不过随着人工智能技术的发展，Python 已经成为\\n\\n时下最热门的编程语言之一，广泛应用于机器学习和深度学习的应用中。目前大多数深度学习\\n\\n框架的主要编程语言都是 Python，Python 可谓是目前人工智能领域的第一语言。本书中使\\n\\n用的所有代码都是 python 程序，所以这一章节我们主要学习 python 编程环境的搭建。\\n\\n如果大家之前有 python 基础那这一章节的内容就比较简单了，直接跳过也可以。如果大\\n\\n家之前完全没有学过 python，那么建议大家还是先学习 python 的使用，不然后续编程实践\\n\\n的内容可能会碰到很多问题。',\n",
       " '的内容可能会碰到很多问题。\\n\\n2.1 Python 介绍\\n\\nPython 是一种面向对象的解释型计算机程序设计语言，由荷兰人 Guido van Rossum 于\\n\\n1989 年发明。Python 具有丰富强大的库，常被称为“胶水语言”，因为它能够把其他语言（尤\\n\\n其是 C/C++）制作各种模块轻松联结在一起。\\n\\nPython 的主要优点是开发效率高，可移植性强，可拓展性强，应用广泛等，主要的缺点\\n\\n是程序运行效率相比 C/C++来说比较慢。\\n\\nPython 的主要应用领域有系统编程，网络爬虫，人工智能，科学计算，WEB 开发，系统\\n\\n运维，大数据，云计算，量化交易，金融分析，图形界面。\\n\\n谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google\\n\\n广告等项目都在大量使用 Python 开发。\\n\\nCIA: 美国中情局网站就是用 Python 开发的。\\n\\n49\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nNASA: 美国航天局(NASA)大量使用 Python 进行数据分析和运算。',\n",
       " 'NASA: 美国航天局(NASA)大量使用 Python 进行数据分析和运算。\\n\\nYouTube:世界上最大的视频网站 YouTube 就是用 Python 开发的。\\n\\nDropbox:美国最大的在线云存储网站，全部用 Python 实现，每天网站处理 10 亿个文件\\n\\n的上传和下载。\\n\\nInstagram:美国最大的图片分享社交网站，每天超过 3 千万张照片被分享，全部用 python\\n\\n开发。\\n\\nFacebook:大量的基础库均通过 Python 实现的。\\n\\nRedhat: 世界上最流行的 Linux 发行版本中的 yum 包管理工具就是用 python 开发的。\\n\\n豆瓣: 公司几乎所有的业务均是通过 Python 开发的。\\n\\n知乎: 国内最大的问答社区，通过 Python 开发。\\n\\n2.2 Anaconda 安装\\n\\n推荐的 Python 安装方式是使用 Anaconda 对 Python 进行安装。Anaconda 是一个开源\\n\\n的 Python 发行版本，其中包含了 Numpy,Pandas,Matplotlib 等多个常用的 Python 包和依',\n",
       " '赖项。Anaconda 的官方下载地址为：https://www.anaconda.com/download/。官方下载\\n\\n地址上大家看到的是最新的 python 安装包的下载，如果想下载之前版本的 python，可以通\\n\\n过下面这个地址：https://repo.continuum.io/archive/。\\n\\n目前 Python 常用的版本有 2.7 和 3.6/3.7/3.8 版本，python 官方已经宣布以后 python2\\n\\n将会停止维护，python 以后会逐渐往 python3 的方向发展，所以推荐大家学习 python3。\\n\\n之后 python 的版本还会不断更新，可能还会继续推出 3.9/3.10/4.0 等。\\n\\n50\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nPython2 和 python3 稍微有些差异，python3.6/3.7/3.8 之间的差异就不大了，所以我\\n\\n们不一定要安装最新的 python，因为有些软件可能跟最新的 python 会不兼容。比如现在',\n",
       " '们不一定要安装最新的 python，因为有些软件可能跟最新的 python 会不兼容。比如现在\\n\\npython 的最新版本是 3.8，那么我们可以安装 3.6/3.7 的版本，这样兼容性会稍微好一些。\\n\\nPython 程序在 Windows,Linux,MacOS 下基本是差不多的，所以在 Windows 上可以运\\n\\n行的 Python 程序，在其他系统一般也能运行。\\n\\n下面我们主要讲解 Anaconda 在 Windows 环境下的安装，其他系统的安装方式略有不\\n\\n同，如果你熟悉其他系统的话，安装起来应该也是很简单的。如果我们要安装最新版本的\\n\\nAnaconda，首先打开 Anaconda 下载网址，根据系统选择相应的 Anaconda 安装包。选择\\n\\nPython3.7 版本、64 位的安装包进行下载，如图 2.1 所示。\\n\\n图 2.1 Anaconda 下载\\n\\n如果我 们 要安装之前 版 本 的\\n\\nAnaconda ， 可 以打开网 址\\n\\nhttps://repo.continuum.io/archive/，出现如图 2.2 所示的界面。\\n\\n51',\n",
       " '51\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.2 各种版本的 Anaconda\\n\\nAnaconda2 表示安装 python2，Anaconda3 表示安装 python3，具体是 python3.X，\\n\\n从安装包的文件名是看不出来的。Windows/MacOSX/Linux 表示对应的操作系统。有 64 表\\n\\n示 64 位的系统，没有 64 表示 32 位的系统。\\n\\n安装包下载好之后，双击安装包进行安装。如图 2.3 所示，单击 Next 按钮,。\\n\\n52\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.3 Anaconda 安装流程（1）\\n\\n然后单击 I Agree 按钮，如图 2.4 所示。\\n\\n图 2.4 Anaconda 安装流程（2）\\n\\n接下来可以选择 All Users，单击 Next 按钮，如图 2.5 所示。\\n\\n53\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.5 Anaconda 安装流程（3）',\n",
       " '图 2.5 Anaconda 安装流程（3）\\n\\n接下来选择一个 Anaconda 的安装路径，如图 2.6 所示，可以是任何路径，不一定要跟\\n\\n图中的路径一致。\\n\\n图 2.6 Anaconda 安装流程（4）\\n\\n最后勾选“Add Anaconda to the system PATH environment variable”和\\n\\n“Register Anaconda as the system Python3.6”，然后单击 Install 按钮，Anaconda 就\\n\\n开始安装了。这里注意，一定要勾选相应选项，其目的是让软件帮我们自动配置环境变量，\\n\\n如图 2.7 所示。\\n\\n54\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.7 Anaconda 安装流程（5）\\n\\n安装的过程大家不要心急，耐心等待，不要随意关闭软件的窗口，等确认软件已经安装\\n\\n完毕再关闭窗口。后面软件会有提示是否要安装 VSCode，VSCode 是一款很好用的编译\\n\\n器，可以用于开发各种编程语言写的程序，包括 python。大家感兴趣的话可以安装，不安\\n\\n装也可以。',\n",
       " '装也可以。\\n\\n2.3 Jupyter Notebook 的简单使用\\n\\nPython 有非常多的集成开发环境可以使用，比如 Jupyter Notebook，Spyder，\\n\\nPyCharm，Eclipse，VSCode 等等，每种开发环境都各有优缺点，这里就不一一介绍了。如\\n\\n果大家之前已经有熟悉并喜欢的开发环境可以继续使用，如果大家是初学者对各种开发环境\\n\\n不了解的话推荐大家可以先使用 Jupyter Notebook。Jupyter Notebook 的优点是界面和\\n\\n55\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n功能都比较简洁，并且可以实时运行查看程序结果，还可以把程序运行的结果保存在文件\\n\\n中。缺点是不太好开发大型程序，不过对于初学者来说，我们可能暂时还不会接触到大型程\\n\\n序，Jupyter Notebook 基本就够用了。本书中的程序基本都是在 Jupyter Notebook 中完\\n\\n成的，它是安装完 Anaconda 后自带的一个 Python 开发环境。界面简洁，使用简单，适合\\n\\n快速实验和用于学习。',\n",
       " '快速实验和用于学习。\\n\\n我会给大家提供书中 Jupyter Notebook 的程序文件以及 python 的程序文件。Jupyter\\n\\nNotebook 的程序文件是以“.ipynb”结尾，只能在 Jupyter Notebook 中运行，不能在命\\n\\n令提示符/终端运行；python 的程序文件是以“.py”结尾，不能在 Jupyter Notebook 中运\\n\\n行，可以在其他 python 集成开发环境或者命令提示符/终端运行。Jupyter Notebook 的程\\n\\n序文件可以在 Jupyter Notebook 环境中转成 python 程序文件。\\n\\n2.3.1 启动 Jupyter Notebook\\n\\nAnaconda 安装完成后桌面上不会增加新的图标，我们需要搜索 Jupyter Notebook，\\n\\n找到这个开发环境，Jupyter 的图标如图 2.8 所示，找到后可以右键单击图标，然后发送到\\n\\n桌面快捷方式。\\n\\n图 2.8 Jupyter Notebook',\n",
       " '桌面快捷方式。\\n\\n图 2.8 Jupyter Notebook\\n\\n双击 Jupyter Notebook，打开后可以看到 Jupyter 是在网页中进行编程的，在 Jupyter\\n\\n的界面中我们可以对我们电脑本地的文件进行新建，删除和修改，如图 2.9 所示\\n\\n56\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.9 Jupyter 主界面\\n\\n2.3.2 修改 Jupyter Notebook 默认启动路径\\n\\n大家打开 Jupyter 后，可能会在的主界面中看到一些熟悉的文件，这些文件正是我们电\\n\\n脑本地的一些文件，其实 Jupyter 的主界面对应的是我们电脑中的一个路径，这个路径是可\\n\\n以修改的，我们可以创建一个新的文件夹，专门用于写 python 程序。\\n\\nJupyter Notebook 的默认启动路径为：”C:\\\\User\\\\你的用户名\\\\”。所以第一次打开\\n\\nJupyter Notebook 我们会看到”C:\\\\User\\\\你的用户名\\\\”这个路径的文件出现在 Jupyter',\n",
       " 'Notebook 的主界面。其实 Jupyter Notebook 的启动路径不一定要修改，如果你想使\\n\\n用”C:\\\\User\\\\你的用户名\\\\”或者你觉得修改 Jupyter Notebook 默认路径比较麻烦，那么你\\n\\n可以使用默认的”C:\\\\User\\\\你的用户名\\\\”路径作为 Jupyter Notebook 的工作路径。只要把\\n\\npython 相关的程序（比如书中代码）复制到”C:\\\\User\\\\你的用户名\\\\”路径下，在 Jupyter\\n\\nNotebook 的主界面就可以看到你复制的程序，然后在 Jupyter Notebook 环境中就可以对\\n\\n这些程序进行修改和运行了。\\n\\n如果希望把程序存放在其他路径，使用其他路径作为 Jupyter Notebook 的工作路径，\\n\\n那么就进行下面的操作：\\n\\n首先我们要右键 Jupyter Notebook 的图标，查看属性，然后看到目标，目标最后如果\\n\\n有%USERPROFILE%，则把后面的%USERPROFILE%删掉，如图 2.10 所示。\\n\\n57\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '57\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.10 删除%USERPROFILE%\\n\\n下一步需要生成配置文件，打开命令提示符执行：jupyter notebook --generate-config，\\n\\n我们会看到如图 2.11 所示的结果。\\n\\n图 2.11 生成配置文件\\n\\n我 们 可 以看到 配置文件生成 的 位置， 本 书例子中配置文件生成 的 位置\\n\\n是 C:\\\\Users\\\\qin\\\\.jupyter\\\\jupyter_notebook_config.py，进入系统盘，用户文件下，可以看\\n\\n到一个.jupyter 的文件，如图 2.12 所示\\n\\n图 2.12 .jupyter 文件\\n\\n58\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n进入.jupyter 文件夹中找到 jupyter_notebook_config.py 文件，用文本工具打开\\n\\njupyter_notebook_config.py 文件，找 c.NotebookApp.notebook_dir 配置，“#”为注',\n",
       " '释，先把它前面的“#”给去掉，然后填入你想要的 Python 程序存放路径。如图 2.13 所\\n\\n示。\\n\\n图 2.13 修改 Jupyter 工作路径\\n\\n图中的例子是在“E/test”，大家不一定要使用这个路径，可以任意设置其他路径。注意\\n\\n这里设置的路径必须是本地已经存在的路径。注意路径最好是全英文，如果路径有中文需要\\n\\n把 jupyter_notebook_config.py 文件另存为 UTF-8 的格式。注意路径中的斜杠是“/”不是\\n\\n“\\\\”。\\n\\n顺利的话，重新启动 Jupyter Notebook 就可以看到 Jupyter 的主界面跳转到了你设置\\n\\n的路径。\\n\\n如果是使用 Linux 或者 MacOS 的话可以先在终端用 cd 命令跳转到你的程序所在路径，\\n\\n然后使用命令：\\n\\njupyter notebook\\n\\n打开 Jupyter Notebook 软件，这时你会看到你的程序所在路径已经成为你的 Jupyter\\n\\nNotebook 的工作路径。\\n\\n59\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '59\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n2.3.3 Jupyter Notebook 浏览器无法打开\\n\\n如果电脑的浏览器太老，有可能会出现 Jupyter Notebook 无法打开的情况，Jupyter\\n\\nNotebook 闪退，或者是浏览器一片空白。这个时候可以下载安装一个新的谷歌浏览器，然\\n\\n后再打开 Jupyter Notebook 的配置文件，在任意位置加入如下命令：\\n\\nimport webbrowser\\n\\nwebbrowser.register(\"chrome\",None,webbrowser.GenericBrowser(u\"C:/ProgramFile\\n\\ns(x86)/Google/Chrome/Application/chrome.exe\"))\\n\\nc.NotebookApp.browser = \\'chrome\\'\\n\\n该命令的作用是把 Jupyter Notebook 的默认浏览器设置为谷歌浏览器，其中',\n",
       " '该命令的作用是把 Jupyter Notebook 的默认浏览器设置为谷歌浏览器，其中\\n\\n\"C:/ProgramFiles(x86)/Google/Chrome/Application/chrome.exe\"为谷歌浏览器的执行\\n\\n文件所在位置，每台电脑位置可能不同，需要自己查看修改。\\n\\n2.3.4 Jupyter Notebook 基本操作\\n\\n接下来新建一个文件，单击右上角的 New 按钮，然后单击 Python 选项，这样就可以创\\n\\n建一个新的文件，如图 2.14 所示。\\n\\n图 2.14 创建新文件\\n\\n创建好文件之后，可以看到如图 2.15 所示的界面。\\n\\n60\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.15 Jupyter 编译界面\\n\\n单击 Untitled 的位置可以修改文件名字，如图 2.16 所示。\\n\\n图 2.16 Jupyter 修改文件名\\n\\n然后就可以开始编程了，按照惯例，我们先来写一个“hello world”，写完之后，按',\n",
       " '然后就可以开始编程了，按照惯例，我们先来写一个“hello world”，写完之后，按\\n\\n“Shift+Enter”组合键执行程序，按住 Shift 不要放手，然后按 Enter。如图 2.17 所示。\\n\\n图 2.17 执行 hello world\\n\\n一个框内可以执行多行代码，如图 2.18 所示。\\n\\n61\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 2.18 执行多行代码\\n\\n把光标移动到函数的内部，然后按“Shift+Tab”组合键可以查看该函数的使用方法，先按\\n\\n住 Shift 不要放手，然后按两下 Tab，如图 2.19 所示。\\n\\n图 2.19 查看函数说明\\n\\nJupyter 还有很多神奇的用法，大家有兴趣可以去探索，这里就不过多介绍了。\\n\\n下一章我们将正式开始进入神经网络深度学习的大门。\\n\\n62\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 3 章-单层感知器与线性神经网络\\n\\n本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络 ANN 的设',\n",
       " '本章要学习的主要内容是神经网络算法的基础——单层感知器，人工神经网络 ANN 的设\\n\\n计实际上是从生物体的神经网络结构获得的灵感。模仿生物神经网络我们构造出了单层感知器，\\n\\n在单层感知器的基础上经过不断地优化才得到了后来的神经网络算法。\\n\\n3.1 生物神经网络\\n\\n生物神经网络一般是指生物的大脑神经元，细胞等组成的网络，用于产生生物的意识，帮\\n\\n助生物进行思考和行动。\\n\\n神经细胞构是构成神经系统的基本单元，简称为神经元。神经元主要由三部分构成：①细\\n\\n胞体；②轴突；③树突。如 3.1 图所示。\\n\\n图 3.1 生物神经元结构\\n\\n每个神经元伸出的突起分 2 种，树突和轴突。树突分支比较多，每个分支还可以再分支，\\n\\n长度一般比较短，作用是接受信号。轴突只有一个，从细胞体的一个凸出部分伸出，长度一般\\n\\n63\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n比较长，作用是把从树突和细胞表面传入细胞体的神经信号传出到其他神经元。轴突的末端分\\n\\n为许多小支，连接到其他神经元的树突上。\\n\\n大脑可视作为 1000 多亿神经元组成的神经网络。神经元的信息传递和处理是一种电化学',\n",
       " '大脑可视作为 1000 多亿神经元组成的神经网络。神经元的信息传递和处理是一种电化学\\n\\n活动。树突由于电化学作用接受外界的刺激，通过胞体内的活动体现为轴突电位，当轴突电位\\n\\n达到一定的值则形成神经脉冲或动作电位；再通过轴突末梢传递给其它的神经元。从控制论的\\n\\n观点来看，这一过程可以看作一个多输入单输出非线性系统的动态过程。\\n\\n3.2 单层感知器\\n\\n3.2.1 单层感知器介绍\\n\\n受到生物神经网络的启发，计算机学家 Frank Rosenblatt 在 20 世纪 60 年代提出了一种\\n\\n模拟生物神经网络的的人工神经网络结构，称为感知器（Perceptron）。图 3.1 为单层感知器\\n\\n结构图。\\n\\n图 3.1 单层感知器\\n\\n图中𝑥\"，𝑥#，𝑥$为输入信号，类似于生物神经网络中的树突。\\n\\n64\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n65\\n\\n𝑤\"，𝑤#，𝑤$分别为𝑥\"，𝑥#，𝑥$的权值，它可以调节输入信号的值的大小，让输入信号变大\\n\\n(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突',\n",
       " '(w＞0)，不变(w=0)或者减小(w＜0)。可以理解为生物神经网络中的信号作用，信号经过树突\\n\\n传递到细胞核的过程中信号会发生变化。\\n\\n公式∑ (𝑤(𝑥() + 𝑏\\n\\n(\\n\\n表示细胞的输入信号在细胞核的位置进行汇总 ∑ 𝑤(𝑥(\\n\\n(\\n\\n，然后再加上该细\\n\\n胞本身自带的信号 b。b一般称为偏置值（Bias），相当于是神经元内部自带的信号。\\n\\nf(x)称为激活函数，可以理解为信号在轴突上进行的线性或非线性变化。在单层感知器中\\n\\n最开始使用的激活函数是 sign(x)激活函数。该函数的特点是当 x＞0 时，输出值为 1；当 x＝\\n\\n0 时，输出值为 0,；当 x＜0 时，输出值为-1。sign(x)函数图像如图 3.2 所示。\\n\\n图 3.2 sign 函数图像\\n\\ny 就是𝑓(∑ (𝑤(𝑥() + 𝑏 (\\n\\n)，为单层感知器的输出结果。\\n\\n3.2.2 单层感知器计算举例\\n\\n假如有一个单层感知器有 3 个输入𝑥\"，𝑥#，𝑥$，同时已知 b=-0.6，𝑤\"=𝑤#=𝑤$=0.5，那\\n\\n么根据单层感知器的计算公式𝑓(∑ (𝑤(𝑥() + 𝑏\\n\\n(\\n\\n)我们就可以得到如图 3.3 计算结果。',\n",
       " '(\\n\\n)我们就可以得到如图 3.3 计算结果。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.3 单层感知器计算\\n\\n𝑥\"=0,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 0 + 0.5 × 1 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=0,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 0 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1\\n\\n𝑥\"=1,\\t𝑥#=0,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 0 − 0.6) = −1\\n\\n𝑥\"=1,\\t𝑥#=0,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 0 + 0.5 × 1 − 0.6) = 1',\n",
       " '𝑥\"=1,\\t𝑥#=1,\\t𝑥$=0：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 0 − 0.6) = 1\\n\\n𝑥\"=1,\\t𝑥#=1,\\t𝑥$=1：sign(0.5 × 1 + 0.5 × 1 + 0.5 × 1 − 0.6) = 1\\n\\n3.2.3 单层感知器的另一种表达形式\\n\\n单层感知器的另一种表达形式如图 3.4。\\n\\n66\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.4 单层感知器的另一种表达形式\\n\\n其实这种表达形式跟 3.2.1 中的单层感知器是一样的。只不过是把偏置值 b 变成了输入\\n\\n𝑤< × 𝑥<，其中𝑥<=1。所以𝑤< × 𝑥<实际上就是𝑤<，把∑ (𝑤(𝑥()\\n\\n(\\n\\n公式展开得到：𝑤\" × 𝑥\" + 𝑤# × 𝑥# +\\n\\n𝑤$ × 𝑥$ + 𝑤<。所以这两个单层感知器的表达不一样，但是计算结果是一样的。如图 3.4 的表\\n\\n达形式更加简洁，更适合使用矩阵来进行运算。\\n\\n3.3 单层感知器的学习规则\\n\\n3.3.1 单层感知器的学习规则介绍',\n",
       " '3.3 单层感知器的学习规则\\n\\n3.3.1 单层感知器的学习规则介绍\\n\\n感知器的学习规则就是指感知器中的权值参数训练的方法，在本章节中我们暂时先不解释\\n\\n这个学习规则是怎么推导出来的。等第 4 章我们讲到 Delta 学习规则的时候我们再来解释感\\n\\n知器的学习规则是如何推导的。在这里我们可以先接受下面的公式即可。\\n\\n在 3.2.3 中我们已知单层感知器表达式可以写成：\\n\\n67\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n公式(3.1)中：y 表示感知器的输出；f 是 sign 激活函数；n 是输入信号的个数 i=0,1,2...\\n\\n∆𝑤( = 𝜂(𝑡 − 𝑦)𝑥(\\n\\n公式(3.2)中：∆𝑤(表示第 i 个权值的变化；𝜂表示学习率(Learning Rate)，用来调节权值\\n\\n变化的大小；t 是正确的标签(target)。\\n\\n因为单层感知器的激活函数为 sign 函数，所以 t 和 y 的取值都为±1',\n",
       " '因为单层感知器的激活函数为 sign 函数，所以 t 和 y 的取值都为±1\\n\\nt=y 时，∆𝑤(为 0；t=1，y=-1 时，∆𝑤(为 2；t=-1，y=1 时，∆𝑤(为-2。由式(3.2)可以推\\n\\n出：\\n\\n∆𝑤( = ±2𝜂𝑥(\\n\\n权值的调整公式为：\\n\\n𝑤( = 𝑤( + ∆𝑤(\\n\\n3.3.2 单层感知器的学习规则计算举例\\n\\n假设有一个单层感知器如图 3.1 所示，已知有三个输入 x0=1，x1=0，x2=-1，权值\\n\\nw0=-5，w1=0，w2=0，学习率𝜂=1，正确的标签 t=1。(注意在这个例子中偏置值 b 用\\n\\n𝑤< × 𝑥<来表示，x0 的值固定为 1)\\n\\nStep1：我们首先计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n= sign(−5 × 1 + 0 × 0 + 0 × (−1) + 0)\\n\\n= sign(−5)\\n\\n= −1\\n\\n68\\n\\n(3.1)\\n\\n(3.2)\\n\\n(3.3)\\n\\n(3.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '(3.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。\\n\\n∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2\\n\\n∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0\\n\\n∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2\\n\\n𝑤< = 𝑤< + ∆𝑤< = −5 + 2 = −3\\n\\n𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0\\n\\n𝑤# = 𝑤# + ∆𝑤# = 0 − 2 = −2\\n\\nStep2：重新计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n= sign(−3 × 1 + 0 × 0 + (−2) × (−1) + 0)\\n\\n= sign(−1)\\n\\n= −1\\n\\n由于 y=-1 与正确的标签 t=1 不相同，所以需要对感知器中的权值进行调节。\\n\\n∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2',\n",
       " '∆𝑤< = 𝜂(𝑡 − 𝑦)𝑥< = 1 × (1 + 1) × 1 = 2\\n\\n∆𝑤\" = 𝜂(𝑡 − 𝑦)𝑥\" = 1 × (1 + 1) × 0 = 0\\n\\n∆𝑤# = 𝜂(𝑡 − 𝑦)𝑥# = 1 × (1 + 1) × (−1) = −2\\n\\n𝑤< = 𝑤< + ∆𝑤< = −3 + 2 = −1\\n\\n𝑤\" = 𝑤\" + ∆𝑤\" = 0 + 0 = 0\\n\\n𝑤# = 𝑤# + ∆𝑤# = −2 − 2 = −4\\n\\nStep3：重新计算感知器的输出。\\n\\n@ 𝑦 = 𝑓 >?(𝑤(𝑥() (A<\\n\\nB\\n\\n69\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n= sign(−1 × 1 + 0 × 0 + (−4) × (−1) + 0)\\n\\n= sign(3)\\n\\n= 1\\n\\n由于 y=1 与正确的标签 t=1 相同，说明感知器经过训练后得到了我们想要的结果，我们\\n\\n就可以结束训练了。\\n\\n把上面的例子写成 python 程序的话，可以得到代码 3-1。\\n\\n代码 3-1：单层感知器学习规则计算举例',\n",
       " '代码 3-1：单层感知器学习规则计算举例\\n\\n# 导入 numpy 科学计算包 import numpy as np # 定义输入 x0 = 1\\n\\nx1 = 0\\n\\nx2 = -1 # 定义权值 w0 = -5\\n\\nw1 = 0\\n\\nw2 = 0 # 定义正确的标签 t = 1 # 定义学习率 lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如 100 for i in range(100): # 打印权值 print(w0,w1,w2) # 计算感知器的输出 y = np.sign(w0 * x0 + w1 * x1 + w2*x2) # 如果感知器输出不等于正确的标签 if(y != t): # 更新权值 w0 = w0 + lr * (t-y) * x0\\n\\nw1 = w1 + lr * (t-y) * x1\\n\\n70\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " \"70\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nw2 = w2 + lr * (t-y) * x2 # 如果感知器输出等于正确的标签 else: # 训练结束 print('done') # 退出循环 break\\n\\n运行结果如下： -5 0 0 -3 0 -2 -1 0 -4 done\\n\\n下面我们还可以用矩阵运算的方式来完成同样的计算，代码 3-2 为矩阵运算的方式来进\\n\\n行单层感知器学习规则的计算。\\n\\n代码 3-2：单层感知器学习规则计算举例(矩阵计算)\",\n",
       " '行单层感知器学习规则的计算。\\n\\n代码 3-2：单层感知器学习规则计算举例(矩阵计算)\\n\\n# 导入 numpy 科学计算包 import numpy as np # 定义输入，用大写字母表示矩阵 # 一般我们习惯用一行来表示一个数据，如果存在多个数据就用多行来表示 X = np.array([[1,0,-1]]) # 定义权值，用大写字母表示矩阵 # 神经网络中权值的定义可以参考神经网络的输入是输出神经元的个数 # 在本例子中输入神经元个数为 3 个，输出神经元个数为 1 个，所以可以定义 3 行 1 列的 W W = np.array([[-5], [0], [0]]) # 定义正确的标签 t = 1 # 定义学习率 lr(learning rate) lr = 1 # 定义偏置值 b = 0 # 循环一个比较大的次数，比如 100 for i in range(100): # 打印权值 print(W) # 计算感知器的输出，np.dot 可以看做是矩阵乘法 y = np.sign(np.dot(X,W)) # 如果感知器输出不等于正确的标签\\n\\n71',\n",
       " \"71\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com if(y != t): # 更新权值 # X.T 表示 X 矩阵的转置 # 这里一个步骤可以完成代码 3-1 中下面 3 行代码完成的事情 # w0 = w0 + lr * (t-y) * x0 # w1 = w1 + lr * (t-y) * x1 # w2 = w2 + lr * (t-y) * x2 W = W + lr * (t - y) * X.T # 如果感知器输出等于正确的标签 else: # 训练结束 print('done') # 退出循环 break 运行结果如下： [[-5] [ 0] [ 0]] [[-3] [ 0] [-2]] [[-1] [ 0] [-4]] done\\n\\n3.4 学习率\\n\\n学习率是人为设定的一个超参数，主要是在训练阶段用来控制模型参数调整的快慢。关于\\n\\n学习率主要有 3 个要点需要注意：\\n\\n（1）学习率𝜼取值一般取 0-1 之间；\\n\\n（𝟐）学习率太大容易造成权值调整不稳定；\\n\\n（3）学习率太小，模型参数调整太慢，迭代次数太多。\\n\\n72\",\n",
       " '（3）学习率太小，模型参数调整太慢，迭代次数太多。\\n\\n72\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n你可以想象一下在洗热水澡的时候：如果每次调节的幅度很大，那水温要不就是太热，\\n\\n要不就是太冷，很难得到一个合适的水温；如果一开始的时候水很冷，每次调节的幅度都非\\n\\n常小，那么需要调节很多次，花很长时间才能得到一个合适的水温。学习率的调整也是这样\\n\\n一个道理。图 3.5 表示不同大小的学习率对模型训练的影响。\\n\\n图 3.5 不同大小的学习率对模型训练的影响\\n\\n图中的纵坐标 loss 代表代价函数（Loss Function），在后面的章节中有更详细的介\\n\\n绍，这里我们可以把它近似理解为模型的预测值与真实值之间的误差。我们训练模型的主要\\n\\n目的就是为了降低 loss 值，减少模型预测值与真实值之间的误差。横坐标 Epoch 代表模型\\n\\n的迭代周期，把所有训练数据都训练一遍可以称为迭代了一个周期。\\n\\n从图中我们可以看到，如果使用非常大的学习率（very high lr）来训练模型，loss 会一',\n",
       " '从图中我们可以看到，如果使用非常大的学习率（very high lr）来训练模型，loss 会一\\n\\n直处于一个比较大的位置，模型不能收敛，这肯定不是我们想要的结果。如果使用比较大的\\n\\n学习率（high lr）来训练模型，loss 会下降很快，但是最后 loss 最终不能得到比较比较小的\\n\\n值，所以结果也不理想。如果使用比较小的学习率（low lr）来训练模型，模型收敛的速度\\n\\n会很慢，需要等待很长时间模型才能收敛。最理想的结果是使用合适的学习率（good lr）来\\n\\n73\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n训练模型，使用合适的学习率，模型的 loss 值下降得比较快，并且最后的 loss 也能够下降\\n\\n到一个比较小的位置，结果最理想。\\n\\n看到这里大家可能会有一个疑问，学习率的值到底取多少比较合适？这个问题其实是没\\n\\n有明确答案的，需要根据建模的经验以及测试才能找到合适的学习率。不过学习率的选择也\\n\\n有一些小的 trick 可以使用，比如说最开始我们设置一个学习率为 0.01，经过测试我们发现',\n",
       " '有一些小的 trick 可以使用，比如说最开始我们设置一个学习率为 0.01，经过测试我们发现\\n\\n学习率太小了需要调大一点，那么我们可以改成 0.03。如果 0.03 还需要调大，我们可以调\\n\\n到 0.1。同理，如果 0.01 太大了，需要调小，那么我们可以调到 0.003。如果 0.003 还需要\\n\\n调小，我们可以调到 0.001。所以常用的学习率可以选择：\\n\\n1，0.3，0.1，0.03，0.01，0.003，0.001，0.0003，0.0001 ...\\n\\n当然这也不是绝对的，其他的学习率的取值你也可以去尝试。\\n\\n3.5 模型的收敛条件\\n\\n通常模型的收敛条件可以有以下 3 个：\\n\\n（1）loss 小于某个预先设定的较小的值；\\n\\n（2）两次迭代之间权值的变化已经很小了；\\n\\n（3）设定最大迭代次数，当迭代超过最大次数就停止。\\n\\n第一种很容易理解，模型的训练目的就是为了减少 loss 值，那么我们可以设定一个比较\\n\\n小的数值，每一次训练的时候我们都同时计算一下 loss 值的大小，当 loss 值小于某个预先设\\n\\n定的阈值，就可以认为模型收敛了。那么就可以结束训练。\\n\\n74',\n",
       " '定的阈值，就可以认为模型收敛了。那么就可以结束训练。\\n\\n74\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第二种的意思是，每一次训练我们可以记录模型权值的变化，如果我们发现两次迭代之间\\n\\n模型的权值变化已经很小，那么说明模型已经几乎不需要做权值地调整了，那么就可以认为模\\n\\n型收敛，可以结束训练。\\n\\n第三种是用得最多的方式。我们可以预先设定一个比较大的模型迭代周期，比如迭代 100\\n\\n次，或者 10000 次，或者 1000000 次等（需要根据实际情况来选择）。模型完成规定次数的\\n\\n训练之后我们就可以认为模型训练完毕。如果达到我们设置的训练次数以后我们发现模型还没\\n\\n有训练好的话，我们可以继续增加训练次数，让模型继续训练就可以了。\\n\\n3.6 模型的超参数和参数的区别\\n\\n模型的超参数（Hyperparameters）是机器学习或者深度学习中经常用到的一个概念，\\n\\n我们可以认为是根据经验来人为设置的一些模型相关的参数。比如说前面提到的学习率，学习\\n\\n率需要根据经验来人为设置。比如模型的迭代次数，也是需要在模型训练之前预先进行人为设\\n\\n置。',\n",
       " '率需要根据经验来人为设置。比如模型的迭代次数，也是需要在模型训练之前预先进行人为设\\n\\n置。\\n\\n而前面提到的权值和偏置值则是参数（Parameters），一般指的是模型中需要训练的变量。\\n\\n我们会给权值和偏置值进行随机初始化赋值，模型在训练过程中会不断调节这些参数，进行模\\n\\n型优化。\\n\\n75\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n3.7 单层感知器分类案例\\n\\n题目：假设我们有 4 个 2 维的数据，数据的特征分别是(3,3),(4,3),(1,1),(2,1)。(3,3),(4,3)\\n\\n这两个数据的标签为 1，(1,1),(2,1)这两个数据的标签为-1。构建神经网络来进行分类。\\n\\n思路：我们要分类的数据是 2 维数据，所以只需要 2 个输入节点（一般输入数据有几个特\\n\\n征，我们就设置几个输入神经元），我们可以把神经元的偏置值也设置成一个输入节点，使用\\n\\n3.2.3 中的方式。这样我们需要 3 个输入节点。\\n\\n输入数据有 4 个(1,3,3),(1,4,3),(1,1,1),(1,2,1)\\n\\n数据对应的标签为(1,1,-1,-1)',\n",
       " '数据对应的标签为(1,1,-1,-1)\\n\\n初始化权值 w1,w2,w3 取 0 到 1 的随机数\\n\\n学习率 lr(learning rate)设置为 0.1\\n\\n激活函数为 sign 函数\\n\\n我们可以构建一个单层感知器如图 3.6 所示。\\n\\n图 3.6 单层感知器\\n\\n代码 3-3 为单层感知器应用案例。\\n\\n代码 3-3：单层感知器案例\\n\\n76\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3], [1,4,3], [1,1,1], [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1], [1], [-1], [-1]])',\n",
       " '# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0',\n",
       " '# 更新一次权值 def train(): # 使用全局变量 W global W # 同时计算 4 个数据的预测值 # Y 的形状为(4,1)-4 行 1 列 Y = np.sign(np.dot(X,W)) # T - Y 得到 4 个的标签值与预测值的误差 E。形状为(4,1) E = T - Y # X.T 表示 X 的转置矩阵，形状为(3,4) # 我们一共有 4 个数据，每个数据 3 个值。定义第 i 个数据的第 j 个特征值为 xij # 如第 1 个数据，第 2 个值为 x12 # X.T.dot(T - Y)为一个 3 行 1 列的数据： # 第 1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第 1 个神经元对应的权值 # 第 2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第 2 个神经元对应的权值 # 第 3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整 3 个神经元对应的权值 # X.shape 表示 X 的形状 X.shape[0]得到 X 的行数，表示有多少个数据',\n",
       " \"# X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式 3.2 看起来有些不同，原因是这里的计算是矩阵运算，书中公\\n\\n式 3.2 是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的 delta_W = lr * (X.T.dot(E)) / X.shape[0]\\n\\nW = W + delta_W\\n\\n# 训练 100 次\\n\\n77\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com for i in range(100): #更新一次权值 train() # 打印当前训练次数 print('epoch:',i + 1) # 打印当前权值 print('weights:',W) # 计算当前输出 Y = np.sign(np.dot(X,W)) # .all()表示 Y 中的所有值跟 T 中所有值都对应相等，结果才为真 if(Y == T).all(): print('Finished') # 跳出循环 break\",\n",
       " '#————————以下为画图部分————————# # 正样本的 xy 坐标 x1 = [3,4] y1 = [3,3] # 负样本的 xy 坐标 x2 = [1,2] y2 = [1,1]',\n",
       " \"# 计算分类边界线的斜率以及截距 # 神经网络的信号总和为 w0×x0+w1×x1+w2×x2 # 当信号总和大于 0 再进过激活函数，模型的预测值会得到 1 # 当信号总和小于 0 再进过激活函数，模型的预测值会得到-1 # 所以当信号总和 w0×x0+w1×x1+w2×x2=0 时为分类边界线表达式 # 我们在画图的时候把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d = -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下：\\n\\n78\",\n",
       " '78\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com epoch: 1 weights: [[0.83669451] [0.58052698] [0.25564497]] epoch: 2 weights: [[0.73669451] [0.43052698] [0.15564497]] epoch: 3 weights: [[0.63669451] [0.28052698] [0.05564497]] …… epoch: 16 weights: [[-0.01330549] [ 0.13052698] [ 0.20564497]] epoch: 17 weights: [[-0.11330549] [-0.01947302] [ 0.10564497]] Finished\\n\\n因为权值的初始化使用的是随机的初始化方式，所以每一次训练的周期以及画出来的图\\n\\n可能都是不一样的。这里我们可以看到单层感知器的一个问题，虽然单层感知器可以顺利地\\n\\n完成分类任务，但是使用单层感知器来做分类的时候，最后得到的分类边界距离某一个类别',\n",
       " '完成分类任务，但是使用单层感知器来做分类的时候，最后得到的分类边界距离某一个类别\\n\\n比较近，而距离另一个类别比较远，并不是一个特别理想的分类效果。图 3.7 中的分类效果\\n\\n应该才是比较理想的分类效果，分界线在两个类别比较中间的位置。\\n\\n79\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.7 单层感知器比较理想的分类边界\\n\\n3.8 线性神经网络\\n\\n3.8.1 线性神经网络介绍\\n\\n线性神经网络跟单层感知器非常类似，只是把单层感知器的 sign 激活函数改成了 purelin\\n\\n函数：\\n\\n𝑦 = 𝑥\\n\\npurelin 函数也称为线性函数，函数图像如图 3.8 所示。\\n\\n80\\n\\n(3.5)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.8 线性函数\\n\\n3.8.2 线性神经网络分类案例\\n\\n参考“单层感知器案例”，我们这次使用线性神经网络来完成相同的任务。线性神经网络的\\n\\n程序跟单层感知器的程序非常相似，大家可以思考一下需要修改哪些地方。\\n\\n大家可以仔细阅读代码 3-4，找到修改了的部分。',\n",
       " '大家可以仔细阅读代码 3-4，找到修改了的部分。\\n\\n代码 3-4：线性神经网络案例\\n\\nimport numpy as np import matplotlib.pyplot as plt # 定义输入，我们习惯上用一行代表一个数据 X = np.array([[1,3,3], [1,4,3], [1,1,1], [1,2,1]]) # 定义标签，我们习惯上用一行表示一个数据的标签 T = np.array([[1], [1], [-1], [-1]])\\n\\n# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 同时计算 4 个数据的预测值 # Y 的形状为(4,1)-4 行 1 列 Y = np.dot(X,W)\\n\\n81',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # T - Y 得到 4 个的标签值与预测值的误差 E。形状为(4,1) E = T - Y # X.T 表示 X 的转置矩阵，形状为(3,4) # 我们一共有 4 个数据，每个数据 3 个值。定义第 i 个数据的第 j 个特征值为 xij # 如第 1 个数据，第 2 个值为 x12 # X.T.dot(T - Y)为一个 3 行 1 列的数据： # 第 1 行等于：x00×e0+x10×e1+x20×e2+x30×e3，它会调整第 1 个神经元对应的权值 # 第 2 行等于：x01×e0+x11×e1+x21×e2+x31×e3，它会调整第 2 个神经元对应的权值 # 第 3 行等于：x02×e0+x12×e1+x22×e2+x32×e3，它会影调整 3 个神经元对应的权值 # X.shape 表示 X 的形状 X.shape[0]得到 X 的行数，表示有多少个数据 # X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式 3.2',\n",
       " '# X.shape[1]得到列数，表示每个数据有多少个特征值。 # 这里的公式跟书中公式 3.2 看起来有些不同，原因是这里的计算是矩阵运算，书中公式 3.2 是单个元素的计算。如果在草稿子上仔细推算的话你会发现它们的本质是一样的 delta_W = lr * (X.T.dot(E)) / X.shape[0]',\n",
       " 'W = W + delta_W\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train()\\n\\n#————————以下为画图部分————————# # 正样本的 xy 坐标 x1 = [3,4] y1 = [3,3] # 负样本的 xy 坐标 x2 = [1,2] y2 = [1,1]',\n",
       " \"# 计算分类边界线的斜率以及截距 # 神经网络的信号总和为 w0×x0+w1×x1+w2×x2 # 当信号总和大于 0 再进过激活函数，模型的预测值会得到 1 # 当信号总和小于 0 再进过激活函数，模型的预测值会得到-1 # 所以当信号总和 w0×x0+w1×x1+w2×x2=0 时为分类边界线表达式 # 我们在画图的时候把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1×x + w2 × y = 0 # 经过通分：y = -w0/w2 - w1×x/w2，因此可以得到： k = - W[1] / W[2] d = -W[0] / W[2] # 设定两个点 xdata = (0,5) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b')\\n\\n82\",\n",
       " \"82\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下：\\n\\n线性神经网络的程序有两处是对单层感知器程序进行了修改。\\n\\n第一处是在 train()函数中，将 Y = np.sign(np.dot(X,W))改成了 Y = np.dot(X,W)。因为线性\\n\\n神经网络的激活函数是 y=x，所以这里就不需要 np.sign()了。\\n\\n第二处是在 for i in range(100)中，把原来的：\",\n",
       " \"第二处是在 for i in range(100)中，把原来的：\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train() # 打印当前训练次数 print('epoch:',i + 1) # 打印当前权值 print('weights:',W) # 计算当前输出 Y = np.sign(np.dot(X,W)) # .all()表示 Y 中的所有值跟 T 中所有值都对应相等，结果才为真 if(Y == T).all(): print('Finished') # 跳出循环 break\\n\\n改成了：\\n\\n# 训练 100 次\\n\\n83\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com for i in range(100): #更新一次权值 train()\\n\\n在单层感知器中，当 y 等于 t 时，∆𝑤就会为 0，模型训练就结束了，所以可以提前跳出\\n\\n循环。单层感知器使用的模型收敛条件是两次迭代模型的权值已经不再发生变化，则可以认\\n\\n为模型收敛。\",\n",
       " '循环。单层感知器使用的模型收敛条件是两次迭代模型的权值已经不再发生变化，则可以认\\n\\n为模型收敛。\\n\\n而在线性神经网络中，y 会一直逼近 t 的值，不过一般不会得到等于 t 的值，所以可以对\\n\\n模型不断进行优化。线性神经网络使用的模型收敛条件是设置一个最大迭代次数，当训练了\\n\\n一定次数后就可以认为模型收敛了。\\n\\n对比单层感知器和线性神经网络所得到的结果，我们可以看得出线性神经网络所得到的\\n\\n结果会比单层感知器得到的结果更理想。但是线性神经网络也还不够优秀，当使用它处理非\\n\\n线性问题的时候，它就不能很好完成工作了。\\n\\n3.9 线性神经网络处理异或问题\\n\\n首先我们先来回顾一下异或运算：\\n\\n（1）0 与 0 异或等于 0；\\n\\n（2）0 与 1 异或等于 1；\\n\\n（3）1 与 0 异或等于 1；\\n\\n（4）1 与 1 异或等于 0。\\n\\n线性神经网络-处理异或问题的代码如代码 3-5 所示。\\n\\n代码 3-5：线性神经网络-处理异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt\\n\\n84',\n",
       " '84\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 输入数据 # 4 个数据分别对应 0 与 0 异或，0 与 1 异或，1 与 0 异或，1 与 1 异或 X = np.array([[1,0,0], [1,0,1], [1,1,0], [1,1,1]]) # 标签，分别对应 4 种异或情况的结果 # 注意这里我们使用-1 作为负标签 T = np.array([[-1], [1], [1], [-1]])\\n\\n# 权值初始化，3 行 1 列 # np.random.random 可以生成 0-1 的随机数 W = np.random.random([3,1])\\n\\n# 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 计算网络预测值 Y = np.dot(X,W) # 计算权值的改变 delta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n\\n# 更新权值 W = W + delta_W',\n",
       " \"# 更新权值 W = W + delta_W\\n\\n# 训练 100 次 for i in range(100): #更新一次权值 train()\\n\\n#————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1]\\n\\n85\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n#计算分界线的斜率以及截距 k = - W[1] / W[2] d = - W[0] / W[2]\\n\\n# 设定两个点 xdata = (-2,3) # 通过两个点来确定一条直线，用红色的线来画出分界线 plt.plot(xdata,xdata * k + d,'r') # 用蓝色的点画出正样本 plt.scatter(x1,y1,c='b') # 用黄色的点来画出负样本 plt.scatter(x2,y2,c='y') # 显示图案 plt.show() 运行结果如下：\\n\\n从结果我们能够看出用一条直线并不能把异或问题中的两个类别给划分开来，因为这是一\",\n",
       " '从结果我们能够看出用一条直线并不能把异或问题中的两个类别给划分开来，因为这是一\\n\\n个非线性的问题，可以使用非线性的方式来进行求解。\\n\\n其中一种方式是我们可以给神经网络加入非线性的输入。代码 3-5 中的输入信号只有 3 个\\n\\n信 号 x0,x1,x2 ， 我 们 可 以利用 这 3 个 信 号得到 带 有非 线性特征的输入：\\n\\nx0,x1,x2,x1×x1,x1×x2,x2×x2，其中 x1×x1,x1×x2,x2×x2 为非线性特征。引入非线性输入\\n\\n的线性神经网络如图 3.9 所示。\\n\\n86\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 3.9 引入非线性输入的线性神经网络\\n\\n线性神经网络引入非线性特征解决异或问题的代码如代码 3-6 所示。\\n\\n代码 3-6：线性神经网络引入非线性特征解决异或问题',\n",
       " '代码 3-6：线性神经网络引入非线性特征解决异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt # 输入数据 # 原来 X 的 3 个特征分别为：x0,x1,x2 # X = np.array([[1,0,0], # [1,0,1], # [1,1,0], # [1,1,1]]) # 给网络输入非线性特征 # 现在 X 的 6 个特征分别为：x0,x1,x2,x1×x1,x1×x2,x2×x2 X = np.array([[1,0,0,0,0,0], [1,0,1,0,0,1], [1,1,0,1,0,0], [1,1,1,1,1,1]]) # 标签，分别对应 4 种异或情况的结果 T = np.array([[-1], [1], [1], [-1]]) # 权值初始化，6 行 1 列\\n\\n87',\n",
       " '87\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # np.random.random 可以生成 0-1 的随机数 W = np.random.random([6,1]) # 学习率设置 lr = 0.1 # 神经网络输出 Y = 0\\n\\n# 更新一次权值 def train(): # 使用全局变量 W global W # 计算网络预测值 Y = np.dot(X,W) # 计算权值的改变 delta_W = lr * (X.T.dot(T - Y)) / X.shape[0]\\n\\n# 更新权值 W = W + delta_W\\n\\n# 训练 1000 次 for i in range(1000): #更新一次权值 train()\\n\\n# 计算模型预测结果并打印 Y = np.dot(X,W) print(Y)\\n\\n#————————以下为画图部分————————# # 正样本 x1 = [0,1] y1 = [1,0] # 负样本 x2 = [0,1] y2 = [0,1]',\n",
       " '# 神经网络信号的总合为：w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2 # 当 w0x0+w1x1+w2x2+w3x1x1+w4x1x2+w5x2x2=0 时为分类边界线 # 其中 x0 为 1，我们可以把 x1，x2 分别看成是平面坐标系中的 x 和 y # 可以得到：w0 + w1x + w2y + w3xx + w4xy + w5yy = 0 # 通分可得：w5y² + (w2+w4x)y + w0 + w1x + w3x² = 0 # 其中 a = w5, b = w2+w4x, c = w0 + w1x + w3x² # 根据一元二次方程的求根公式：ay²+by+c=0，y=[-b±(b^2-4ac)^(1/2)]/2a def calculate(x,root): # 定义参数 a = W[5]\\n\\n88',\n",
       " '88\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com b = W[2] + x * W[4] c = W[0] + x * W[1] + x * x * W[3] # 有两个根 if root == 1: return (- b + np.sqrt(b * b - 4 * a * c)) / (2 * a) if root == 2: return (- b - np.sqrt(b * b - 4 * a * c)) / (2 * a)',\n",
       " \"# 从-1 到 2 之间均匀生成 100 个点 xdata = np.linspace(-1,2,100) # 使用第一个求根公式计算出来的结果画出第一条红线 plt.plot(xdata,calculate(xdata,1),'r') # 使用第二个求根公式计算出来的结果画出第二条红线 plt.plot(xdata,calculate(xdata,2),'r') # 蓝色点表示正样本 plt.plot(x1,y1,'bo') # 黄色点表示负样本 plt.plot(x2,y2,'yo') # 绘图 plt.show() 运行结果如下： [[-0.98650596] [ 0.990989 ] [ 0.990989 ] [-0.99302749]]\\n\\n从输出的预测值我们可以看出，预测值与真实标签的数值是非常接近的，几乎相等，说\\n\\n明预测值很符合我们想要的结果。而从输出图片中也能观察到两条曲线的内部是负样本所属\\n\\n的类别，两条曲线的外部是正样本所属的类别。这两条曲线很好地把两个类别区分开了。\\n\\n89\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '89\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性神经网络可以通过引入非线性的输入特征来解决非线性问题，但这并不是一种非常好\\n\\n的解决方案。\\n\\n下一章节我们将介绍一种新的神经网络，BP 神经网络。通过学习 BP 神经网络我们可以获\\n\\n得更好的解决问题的思路。\\n\\n90\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 4 章-BP 神经网络\\n\\n这一章节可能是本书在数学上最难的一章，详细介绍了 BP 算法的具体推导流程。BP 算\\n\\n法是神经网络深度学习中最重要的算法之一，了解 BP 算法可以让我们更理解神经网络深度学\\n\\n习模型优化训练的本质，属于内功修行的基础内容。\\n\\n不过作为初学者我们也要学会量力而行，BP 算法的推导对于初学者来说我觉得可以作为\\n\\n选学的知识，也就是可学可不学。如果大家数学基础比较好的话，可以好好看一下本章的推导\\n\\n过程，为后面的学习打好基础。如果数学基础没这么好也没关系，关于 BP 算法的推导可以先\\n\\n跳过，我们大概知道它是神经网络深度学习的核心优化算法即可，并不会影响到我们对后面知',\n",
       " '跳过，我们大概知道它是神经网络深度学习的核心优化算法即可，并不会影响到我们对后面知\\n\\n识的学习，也不会影响到我们写程序做应用。我们在学习的过程中如果遇到困难，不要被它卡\\n\\n住，可以先暂时放一放，等自身积累足够多之后再回过头来看之前遇到的问题，或许就可以迎\\n\\n刃而解了。\\n\\n4.1 BP 神经网络介绍及发展背景\\n\\nBP(back propagation)神经网络是 1986 年由 Rumelhart 和 McClelland 为首的科学家\\n\\n提出的概念，他们在《Parallel Distributed Processing》[1]一书中对 BP 神经网络进行了详细\\n\\n的分析。BP 神经网络是一种按照误差逆向传播算法训练的多层前馈神经网络，它是 20 世纪\\n\\n末期神经网络算法的核心，也是如今深度学习算法的基础。\\n\\n感知器对人工神经网络的发展发挥了极大的作用，但是它的结构只有输入层和输出层，不\\n\\n能解决非线性问题的求解。Minsky 和 Papert 在颇具影响力的《Perceptron》一书中指出，\\n\\n简单的感知器只能求解线性问题，能够求解非线性问题的网络应该具有隐藏层，但是对隐藏层',\n",
       " '简单的感知器只能求解线性问题，能够求解非线性问题的网络应该具有隐藏层，但是对隐藏层\\n\\n91\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n神经元的学习规则还没有合理的理论依据。从前面介绍的感知器学习规则来看，其权值的调整\\n\\n取决于期望输出与实际输出之差：\\n\\n∆𝑤( = 𝜂(𝑡 − 𝑦)𝑥(\\n\\n但是对于各个隐藏层的节点来说，不存在已知的期望输出，因而该学习规则不能用于隐藏\\n\\n层的权值调整。\\n\\nBP 算法的基本思想是，学习过程由信号的正向传播和误差的反向传播两个过程组成。\\n\\n正向传播时，把样本的特征从输入层进行输入，信号经过各个隐藏层逐层处理后，最后从\\n\\n输出层传出。对于网络的实际输出与期望输出之间的误差，把误差信号从最后一层逐层反传，\\n\\n从而获得各个层的误差学习信号，再根据误差学习信号来修正各个层神经元的权值。\\n\\n这种信号正向传播与误差反向传播，然后各个层调整权值的过程是周而复始地进行的。权\\n\\n值不断调整的过程，也就是网络学习训练的过程。进行此过程直到网络输出误差减小到预先设\\n\\n置的阈值以下，或者是超过预先设置的最大训练次数。\\n\\n4.2 代价函数',\n",
       " '置的阈值以下，或者是超过预先设置的最大训练次数。\\n\\n4.2 代价函数\\n\\n代价函数也称为损失函数，英文称为 loss function 或 cost function，有些地方我们会看\\n\\n到使用 loss 表示代价函数的值，有些地方我们会看到用 cost 表示代价函数的值。为了统一规\\n\\n范，本书中我们统一使用代价函数这个名字，英文使用 loss。\\n\\n代价函数并没有准确的定义，一般我们可以理解为是一个人为定义的函数，我们可以利用\\n\\n这个函数来优化模型的参数。最简单常见的一个代价函数是 均方差（Mean-Square Error,\\n\\nMSE）代价函数，也称为二次代价函数：\\n\\n92\\n\\n(4.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸 =\\n\\n1 2𝑁\\n\\n(𝑇 − 𝑌)# =\\n\\n1 2𝑁\\n\\nP ?(𝑡( − 𝑦()# (A\"\\n\\n矩阵可以用大写字母来表示，这里的 T 表示真实标签，Y 表示网络输出，i 表示第 i 个数\\n\\n据。N 表示训练样本的个数(注意这里的 N 是一个大于 0 的整数，不是矩阵)',\n",
       " '据。N 表示训练样本的个数(注意这里的 N 是一个大于 0 的整数，不是矩阵)\\n\\nT-Y 可以到每个训练样本与真实标签的误差。误差的值有正有负，我们可以求平方，把所\\n\\n有的误差值都变成正的，然后除以 2N。这里 2 没有特别的含义，主要是我们对均方差代价函\\n\\n数求导的时候，公式中的 2 次方的 2 可以跟分母中的 2 约掉，使得公式推导看起来更加整齐\\n\\n简洁。除以 N 表示求每个样本误差平均的平均值。\\n\\n公式可以用矩阵形式来表达，也可以拆分为用Σ来累加各个训练样本的真实标签与网络输\\n\\n出的误差的平方。\\n\\n4.3 梯度下降法\\n\\n4.3.1 梯度下降法（Gradient Descent）介绍\\n\\n在求解机器学习算法的模型参数时，梯度下降法是最常用的方法之一。在学习梯度下降法\\n\\n之前 我 们先来 了 解 一 下 导 数 （ Derivative ）、 偏导 数 （ Partial Derivative ）、 方向 导 数\\n\\n（Directional Derivative）和梯度(Gradient)的概念。\\n\\n导数 —— 导数的概念就如图 4.1 所示。\\n\\n93\\n\\n(4.2)',\n",
       " '导数 —— 导数的概念就如图 4.1 所示。\\n\\n93\\n\\n(4.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.1 导数\\n\\n导数的定义如下：\\n\\n𝑓R(𝑥<) = lim UV→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim UV→<\\n\\n𝑓(𝑥< + Δ𝑥) − 𝑓(𝑥<) Δ𝑥\\n\\n𝑓R(𝑥<)表示函数 f 在 x0 处的导数\\n\\n𝛥𝑥表示 x 的变化量\\n\\n𝛥𝑦:\\t𝑓(𝑥< + 𝛥𝑥) − 𝑓(𝑥<)表示函数的增量\\n\\n𝑙𝑖𝑚 ^V→<\\n\\n表示𝛥𝑥趋近于 0\\n\\ndx 表示 x 的变化量𝛥𝑥趋近于 0\\n\\ndy 表示𝑓R(𝑥<)𝑑𝑥\\n\\n总的来说𝑓R(𝑥<)反映的是函数𝑦 = 𝑓(𝑥)在 x 轴上某一点处沿 x 轴正方向的变化率/变化趋\\n\\n势。也就是在 x 轴上的某一点，如果𝑓′(𝑥)＞0，说明𝑓(𝑥)的函数值在 x 点沿 x 轴正方向是趋\\n\\n向于增加的；如果𝑓′(𝑥) < 0，说明𝑓(𝑥)的函数值在 x 点沿 x 轴正方向是趋向于减小的。\\n\\n偏导数 —— 偏导数的定义如下：\\n\\n94\\n\\n(4.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '94\\n\\n(4.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝜕 𝜕𝑥(\\n\\n𝑓(𝑥<, 𝑥\", … , 𝑥@) = lim UV→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim UV→<\\n\\n𝑓(𝑥<, … , 𝑥( + Δ𝑥, … , 𝑥@) − 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) Δ𝑥\\n\\n可以看到，导数与偏导数本质是一致的，都是当自变量的变化量趋近于 0 时，函数值的\\n\\n变化量与自变量变化量比值的极限。直观地说，偏导数也就是函数在某一点上沿坐标轴正方\\n\\n向的的变化率。\\n\\n区别在于：\\n\\n导数，指的是一元函数中，函数𝑦 = 𝑓(𝑥)在某一点处沿 x 轴正方向的变化率；\\n\\n偏导数，指的是多元函数中，函数𝑦 = 𝑓(𝑥<, 𝑥\", … , 𝑥@)在某一点处沿某一坐标轴\\n\\n(𝑥<, 𝑥\", … , 𝑥@)正方向的变化率。\\n\\n方向导数 —— 方向导数的定义如下：\\n\\n𝜕 𝜕𝑙\\n\\n𝑓(𝑥<, 𝑥\", … , 𝑥@) = lim Ue→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim Ue→<',\n",
       " '𝑓(𝑥<, 𝑥\", … , 𝑥@) = lim Ue→<\\n\\nΔ𝑦 Δ𝑥\\n\\n= lim Ue→<\\n\\n𝑓(𝑥< + Δ𝑥<, … , 𝑥( + Δ𝑥(, … , 𝑥@ + Δ𝑥@) − 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) 𝜌\\n\\n其中𝜌 = g(Δ𝑥<)# + ⋯ + (Δ𝑥()# + ⋯ + (Δ𝑥@)#\\n\\n𝑙表示某个方向\\n\\n在前面导数和偏导数的定义中，均是沿坐标轴正方向讨论函数的变化率。那么当我们讨\\n\\n论函数沿任意方向的变化率时，也就引出了方向导数的定义，即：某一点在某一趋近方向上\\n\\n的导数值。\\n\\n通俗的解释是：\\n\\n我们不仅要知道函数在坐标轴正方向上的变化率（即偏导数），而且还要设法求得函数在\\n\\n其他特定方向上的变化率。而方向导数就是函数在其他特定方向上的变化率。\\n\\n梯度 —— 梯度的定义如下：\\n\\n95\\n\\n(4.4)\\n\\n(4.5)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑔𝑟𝑎𝑑𝑓(𝑥<, 𝑥\", … , 𝑥@) = l\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥(\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥@\\n\\nm',\n",
       " '𝜕𝑓 𝜕𝑥<\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥(\\n\\n, … ,\\n\\n𝜕𝑓 𝜕𝑥@\\n\\nm\\n\\n对 于 𝑓(𝑥<, … , 𝑥(, … , 𝑥@) 上 的 某 一 点 来 说存在很 多个方向导数，梯度的方向是函数\\n\\n𝑓(𝑥<, … , 𝑥(, … , 𝑥@)在某一点增长最快的方向，梯度的模则是该点上方向导数的最大值，梯度的\\n\\n模等于：\\n\\n|𝑔𝑟𝑎𝑑𝑓(𝑥<, 𝑥\", … , 𝑥@)| = o(\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n)# + ⋯ + l\\n\\n𝜕𝑓 𝜕𝑥(\\n\\nm\\n\\n#\\n\\n+ ⋯ + (\\n\\n𝜕𝑓 𝜕𝑥@\\n\\n)#\\n\\n这里注意三点：\\n\\n1. 梯度是一个向量，即有方向有大小\\n\\n2. 梯度的方向是最大方向导数的方向\\n\\n3. 梯度的值是最大方向导数的值\\n\\n梯度下降法 —— 既然在变量空间的某一点处，函数沿梯度方向具有最大的变化率，那么\\n\\n在优化代价函数的时候，就可以沿着负梯度方向去减小代价函数的值。计算过程可以描述如下：\\n\\n𝑅𝑒𝑝𝑒𝑎𝑡{\\n\\n𝑥< = 𝑥< − 𝜂\\n\\n𝜕𝑓 𝜕𝑥<\\n\\n………\\n\\n𝑥( = 𝑥( − 𝜂\\n\\n𝜕𝑓 𝜕𝑥(\\n\\n………\\n\\n𝑥@ = 𝑥@ − 𝜂\\n\\n𝜕𝑓 𝜕𝑥@\\n\\n}\\n\\n𝑅𝑒𝑝𝑒𝑎𝑡表示不断重复',\n",
       " '………\\n\\n𝑥@ = 𝑥@ − 𝜂\\n\\n𝜕𝑓 𝜕𝑥@\\n\\n}\\n\\n𝑅𝑒𝑝𝑒𝑎𝑡表示不断重复\\n\\n96\\n\\n(4.6)\\n\\n(4.7)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑥 = 𝑥 − 𝜂\\n\\nuv\\n\\nuV\\n\\n表示参数调整，𝜂表示学习率\\n\\n4.3.2 梯度下降法（Gradient Descent）二维例子\\n\\n4.2 中我们已经知道了代价函数的定义，代价函数的值越小，说明模型的预测值越接近真\\n\\n实标签的值。代价函数中的预测值 y 是跟神经网络中的参数 w 和 b 相关的。我们可以先考虑\\n\\n一个简单的情况，假如神经网络只有一个参数 w，参数 w 与代价函数 loss 的关系如图 4.2 所\\n\\n示。\\n\\n图 4.2 参数 w 与代价函数 loss 的关系图\\n\\n假设 w 的初始值是-3，我们需要使用梯度下降法来不断优化 w 的取值，使得 loss 值不\\n\\n断减少，首先我们应该先计算 w=-3 时的梯度，如图 4.3 所示。\\n\\n97\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n98\\n\\n图 4.3 w 为-3 时的梯度',\n",
       " '98\\n\\n图 4.3 w 为-3 时的梯度\\n\\n从图 4.3 中我们可以看出，当 w 为-3 时，w 所处位置的梯度应该是一个负数，梯度下降\\n\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个正数，\\n\\nw 的值应该变大。根据梯度下降法的优化公式：\\n\\n𝑤 = 𝑤 − 𝜂\\n\\n𝜕𝑓 𝜕𝑤\\n\\n(4.8)\\n\\n学习率𝜂一般是一个大于 0 的数，\\n\\nuv\\n\\nux\\n\\n为负数，我们可以判断出 w 的值会变大。变大的数值\\n\\n跟学习率大小𝜂有关，也跟函数 f 在 w 处的梯度大小有关。\\n\\n假设 w 变大移动到了 w=2 的位置，我们需要再次计算 w=2 时的梯度，如图 4.4 所示。\\n\\n图 4.4 w 为 2 时的梯度\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从图 4.4 中我们可以看出，当 w 为 2 时，w 所处位置的梯度应该是一个正数，梯度下降\\n\\n法在优化代价函数的时候，是沿着负梯度方向去减小代价函数的值，所以负梯度是一个负数，\\n\\nw 的值应该变小。\\n\\n学习率𝜂一般是一个大于 0 的数，\\n\\nuv\\n\\nux',\n",
       " 'w 的值应该变小。\\n\\n学习率𝜂一般是一个大于 0 的数，\\n\\nuv\\n\\nux\\n\\n为正数，我们可以判断出 w 的值会变小。变小的数值\\n\\n跟学习率大小𝜂有关，也跟函数 f 在 w 处的梯度大小有关。\\n\\n我们可以发现不管 w 处于那一个位置，当 w 向着负梯度的方向进行移动时，实际上就是\\n\\n向着可以使 loss 值减小的方向进行移动。这就有点类似一个小球在山坡上面，它总是往坡底\\n\\n的方向进行移动，只不过它每一次是移动一步，这个步子的大小会受到学习率和所处位置梯度\\n\\n的大小所影响。\\n\\n4.3.3 梯度下降法（Gradient Descent）三维例子\\n\\n我们可以再考虑一个稍微复杂一点点的情况，假如神经网络有两个参数 w1 和 w2，参数\\n\\nw1 和 w2 与代价函数 loss 的关系如图 4.5 所示。\\n\\n图 4.5 w1 和 w2 与 loss 的关系图\\n\\n99\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们在图中随机选取两个 w1 和 w2 的初始值 p1 和 p2，然后从 p1,p2 这两个初始位置',\n",
       " '开始使用梯度下降法优化网络参数，得到如图 4.6 所示的结果。\\n\\n图 4.6 从 p1,p2 初始点开始优化网络\\n\\n图 4.6 中可以看到网络参数的优化过程其实就是 p1,p2 两个“小球“从初始点开始，每次\\n\\n移动一步，不断向坡底进行移动。在这个过程中整个网络的 loss 值是在不断变小的。\\n\\n同时我们还可以观察到一个现象， p1“小球“最后走到了图中的 全局最小值（ Global\\n\\nMinimum），而 p2”小球“最后走到的位置是一个局部极小值（Local Minimum）。说明我\\n\\n们在使用梯度下降法的时候不同的初始值的选取可能会影响到最后的结果，有些时候我们可以\\n\\n得到 loss 的全局最小值，或者称为全局最优解。而有些时候我们得到的结果可能是 loss 的局\\n\\n部极小值，或者称为局部最优解。不同的权值初始值会得到不同的结果，这算是梯度下降法存\\n\\n在的一个缺点。\\n\\n100\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过大家不用太担心这个问题，一般实际模型训练的时候局部极小值的情况不常出现。如',\n",
       " '不过大家不用太担心这个问题，一般实际模型训练的时候局部极小值的情况不常出现。如\\n\\n果我们担心模型得到的结果是局部极小值的话可以让模型多训练几次，然后取最好的那一次结\\n\\n果作为模型的最终结果就可以了。\\n\\n4.4 Delta 学习规则\\n\\n1986 年，认知心理学家 McClelland 和 Rumelhart 在神经网络训练中引入了𝛿（Delta）\\n\\n规则，该规则也可以称为连续感知器学习规则。\\n\\n𝛿（Delta）学习规则是一种利用梯度下降法的一般性的学习规则，其实就是利用梯度下降\\n\\n法来最小化代价函数。比如代价函数为前面公式 4.2 介绍的均方差代价函数，为了简单我们只\\n\\n计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。一个样\\n\\n本\\n\\n的均方差公式定义\\n\\n如下\\n\\n：\\n\\n𝐸 =\\n\\n\"\\n\\n#\\n\\n(𝑇 − 𝑌)# =\\n\\n\"\\n\\n#\\n\\n(𝑡 − 𝑦)# =\\n\\n\"\\n\\n#\\n\\n(𝑡 − 𝑓(𝑊𝑋))#\\n\\n误差 E 是 W 的函数，我们可以使用梯度下降法来最小化 E 的值，权值矩阵的变化∆W等\\n\\n于负的学习率−𝜂乘以 E 对 W 进行求导：',\n",
       " '于负的学习率−𝜂乘以 E 对 W 进行求导：\\n\\n∆𝑊 = −𝜂𝐸R = 𝜂𝑋~(𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑋~𝛿\\n\\n注意这里的 X 和 W 都是矩阵，所以这里求导的时候是对矩阵 W 进行求导，矩阵求导的\\n\\n方式跟单个元素求导的方式有一些不同。下面公式是单个 w 元素的权值变化计算：\\n\\n∆𝑤( = −𝜂𝐸R = 𝜂𝑥((𝑡 − 𝑦)𝑓R(𝑊𝑋) = 𝜂𝑥(𝛿\\n\\n这里的𝛿（Delta）符号没有什么特别的含义，就是用来替代(𝑡 − 𝑦)𝑓R(𝑊𝑋)。∆𝑤(表示第 i\\n\\n个权值的变化。\\n\\n101\\n\\n(4.9)\\n\\n(4.10)\\n\\n(4.11)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在上一章节中关于单层感知器的权值变化公式是如何得到的还没有解释，这里我们可以看\\n\\n到当我们使用线性激活函数 y=x 时，激活函数的导数𝑓R(𝑊𝑋) = 1，所以：\\n\\n∆𝑤( = −𝜂𝐸R = 𝜂𝑥((𝑡 − 𝑦)\\n\\n公式 4.12 跟感知器的学习规则公式 3.2 是一样的，所以使用 Delta 学习规则我们可以推\\n\\n导出感知器的学习规则。\\n\\n4.5 常用激活函数讲解',\n",
       " '导出感知器的学习规则。\\n\\n4.5 常用激活函数讲解\\n\\n神经网络的激活函数其实有很多种，在前面的章节中我们介绍过两种激活函数，sign 函\\n\\n数和 purelin 函数。sign 函数也称为符号函数，因为 sign(x)中 x＞0，函数结果为 1；sign(x)\\n\\n中 x＜0，函数结果为-1。purelin 函数也称为线性函数，表达式为 y=x。这两种激活函数在处\\n\\n理复杂非线性问题的时候都不能得到很好的结果，线性函数的分类边界也是线性的，所以不能\\n\\n区别非线性的复杂边界，比如一条直线不能区分异或问题的两个类别。下面我们介绍几个在 BP\\n\\n神经网络中常用的非线性激活函数，sigmoid 函数，tanh 函数，softsign 函数和 ReLU 函\\n\\n数，使用这些非线性激活函数可以帮助我们解决复杂的非线性问题。\\n\\n4.5.1 sigmoid 函数\\n\\nsigmoid 函数 —— sigmoid 函数也称为逻辑函数(logical function)，函数的公式为\\n\\n𝑓(𝑥) =\\n\\n1 1 + 𝑒(cid:127)V\\n\\n函数图像如图 4.7 所示。\\n\\n102\\n\\n(4.12)\\n\\n(4.13)',\n",
       " '函数图像如图 4.7 所示。\\n\\n102\\n\\n(4.12)\\n\\n(4.13)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.7 sigmoid 函数图像\\n\\n图中我们可以看出函数的取值范围是 0-1 之间，当 x 趋向于-∞的时候函数值趋向于 0；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n4.5.2tanh 函数\\n\\ntanh 函数 —— tanh 函数也称为双曲正切函数，函数的公式为\\n\\n𝑓(𝑥) =\\n\\n𝑒 V − 𝑒(cid:127)V 𝑒V + 𝑒(cid:127)V\\n\\n函数图像如图 4.8 所示。\\n\\n103\\n\\n(4.14)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.8 tanh 函数图像\\n\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n4.5.3 softsign 函数\\n\\nsoftsign 函数 —— softsign 函数的公式为： 𝑥 1 + |𝑥|\\n\\n𝑓(𝑥) =\\n\\n函数图像如图 4.9 所示。',\n",
       " '𝑓(𝑥) =\\n\\n函数图像如图 4.9 所示。\\n\\n图 4.9 softsign 函数图像\\n\\n图中我们可以看出函数的取值范围是-1-1 之间，当 x 趋向于-∞的时候函数值趋向于-1；\\n\\n当 x 趋向于+∞的时候函数值趋向于 1。\\n\\n我们可以通过图 4.10 对比一下这三种函数的区别。\\n\\n104\\n\\n(4.15)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.10 三种函数对比\\n\\n它们这三个激活函数都是 S 形函数，形状相似，只不过 sigmoid 函数取值范围是 0-1 之\\n\\n间，tanh 函数和 softsign 函数取值范围是-1-1 之间。我们还可以观察到 softsign 函数相对\\n\\n于 tanh 函数而言过渡更加平滑，在 x 等于 0 附近函数的数值改变更缓慢。\\n\\n4.5.4 ReLU 函数\\n\\n该函数最早源自 2011 年的一篇论文《Deep Sparse Rectifier Neural Networks》[2]。\\n\\n它是模拟生物神经元的激活函数设计出来的一个人工神经网络激活函数。图 4.11 为生物神经\\n\\n元放电曲线图。\\n\\n105',\n",
       " '元放电曲线图。\\n\\n105\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.11 生物神经元放电曲线图[2]\\n\\n图 4.11 中可以看到当输入电压不足时，生物神经元放电为 0，电压达到一定的阈值以后\\n\\n生物神经元才会开始放电，并且放电速率跟输入电压成正相关关系。\\n\\nReLU 函数 —— ReLU(The Rectified Linear Unit)函数的公式为\\n\\n𝑓(𝑥) = max\\t(0, 𝑥)\\n\\n函数图像如图 4.12 所示。\\n\\n图 4.12 ReLU 函数图像\\n\\n106\\n\\n(4.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n当 x 小于 0 时，y 等于 0。当 x 大于 0 时，y 等于 x。ReLU 的中文名称是校正线性单\\n\\n元，虽然在 x 小于 0 时函数是线性的，x 大于 0 时函数也是线性的，但是组合起来之后，函\\n\\n数就具有了非线性的特征。这种非线性的特征是怎么体现的呢，我们可以观察下面的一系列\\n\\n图片，首先看到图 4.13。\\n\\n图 4.13 使用 tanh 作为激活函数的分类边界',\n",
       " '图片，首先看到图 4.13。\\n\\n图 4.13 使用 tanh 作为激活函数的分类边界\\n\\n图 4.13 使用的是 tanh 作为激活函数训练出来的分类模型，其实使用 sigmoid 或者\\n\\nsoftsign 函数也可以得到类似结果。我使用了带有 4 个隐藏层的神经网训练了出了这个模\\n\\n型，图中有两个类别的数据，并且我们可以观察到一个类似椭圆形的分类边界把两个类别给\\n\\n区分开了。我们再观察图 4.14：\\n\\n107\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.14 使用 ReLu 作为激活函数的分类边界\\n\\n我使用带有 4 个隐藏层的神经网络训练出了这个模型。我们发现使用 ReLU 激活函数得\\n\\n到的分类边界跟使用 tanh 激活函数得到分类边界是差不多的，并不能看出 ReLU 函数的特\\n\\n点。同样的一个学习任务和数据，我改变了神经网络的层数，只使用 2 个隐藏层，依然使用\\n\\nReLU 激活函数得到了图 4.15 所示的结果。\\n\\n图 4.15 使用 ReLU 作为激活函数的分类边界\\n\\n我们观察图 4.15 可以得到一些结论：',\n",
       " '图 4.15 使用 ReLU 作为激活函数的分类边界\\n\\n我们观察图 4.15 可以得到一些结论：\\n\\n（1）我们可以发现 ReLU 激活函数所描绘出来的边界其实是一条一条的直线构成的，不\\n\\n存在曲线。图 4.14 中的边界看起来像一个椭圆，实际上它也是由一段一段很小的直线构成\\n\\n的。\\n\\n（2）神经网络的层数会影响模型的拟合效果，层数越多，模型就可以拟合出更复杂的分\\n\\n类边界。\\n\\n模型的拟合效果其实还跟其他一些因素相关，比如说每一层隐藏层的神经元越多，那么模\\n\\n型的拟合能力也就越强。模型训练的周期越多，模型的拟合能力就越强。关于模型拟合强弱的\\n\\n问题，再后面的章节中我们还会进一步讨论。\\n\\n108\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n另外我们再来看一下 ReLU 应用于回归预测时的特点，我看一下图 4.16 和图 4.17。\\n\\n图 4.16 使用 tanh 激活函数训练的回归模型\\n\\n图 4.17 使用 ReLU 激活函数训练的回归模型\\n\\n我们发现了跟分类中类似的情况，tanh 激活函数得到的回归线是一条曲线，而 ReLU 激',\n",
       " '我们发现了跟分类中类似的情况，tanh 激活函数得到的回归线是一条曲线，而 ReLU 激\\n\\n活函数得到的是由一段一段直线构成的回归线。\\n\\n大家可以思考一个问题，上面介绍的这几个激活函数，哪一个效果比较好，为什么？这\\n\\n个问题在 4.8 小节中我们再继续讨论。\\n\\n109\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.6 BP 网络模型和公式推导\\n\\n这一小节我们将学习 BP 算法的推导流程，如果觉得这个小节内容有一定难度可以直接跳\\n\\n到下一小节进行学习。BP 算法其实是在 Delta 学习规则的基础上做了进一步的推广，Delta 是\\n\\n对单层感知器定义了计算流程和代价函数，然后用梯度下降法来最小化代价函数。BP 算法是\\n\\n对多层神经网络定义了计算流程和代价函数，然后再使用梯度下降法来最小化代价函数。由于\\n\\nBP 算法的广泛使用，所以一般的全连接多层神经网络我们也称为 BP 神经网络。\\n\\nBP 网络中不仅有输入层和输出层，在输入层和输出层中间还可以添加隐藏层。输入层的\\n\\n神经元个数一般跟输入数据相关，输出层的神经元个数一般跟标签相关，而网络中间的隐藏层',\n",
       " '神经元个数一般跟输入数据相关，输出层的神经元个数一般跟标签相关，而网络中间的隐藏层\\n\\n的层数和隐藏层神经元的个数都是超参数。也就是说隐藏层的层数以及隐藏层每一层的神经元\\n\\n个数我们都可以随意设置，主要靠经验和实验来决定。通常来说隐藏层的层数越多，隐藏层每\\n\\n一层神经元个数越多，这个神经网络结构就越复杂，越能拟合复杂的函数曲线，处理复杂的分\\n\\n类回归问题。反之，隐藏层层数越少，隐藏层每一层神经元个数越少，网络结构就越简单，它\\n\\n所能够拟合的函数曲线就越简单，比较适合处理简单的分类回归问题。\\n\\n网络的结构不是越复杂越好，也不是越简单越好。网络的结构复杂度需要跟我们要解决的\\n\\n问题相关，如果问题越复杂，那么网络结构就要越复杂；如果问题简单，那么就要用结构简单\\n\\n的网络来建模。如果网络结构的复杂度跟要解决的问题不匹配的话就会出现 欠拟合（Under-\\n\\nFitting）或者过拟合（Over-Fitting）。什么是欠拟合（Under-Fitting）和过拟合（Over-Fitting），\\n\\n在后面的章节中再详细介绍。总之一个好的网络结构是需要很多的经验加大量的实验才能获得。\\n\\n110',\n",
       " '在后面的章节中再详细介绍。总之一个好的网络结构是需要很多的经验加大量的实验才能获得。\\n\\n110\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.6.1 BP 网络模型[3]\\n\\n假设我们有一个 2 层（统计神经网络层数的时候一般输入层忽略不计）的神经网络如图\\n\\n4.18 所示。\\n\\n图 4.18 BP 神经网络\\n\\n该网络的输入向量为𝑋 = (𝑥\", 𝑥#, … , 𝑥(, … , 𝑥@)，图中𝑥< = 1表示输入层偏置值。隐藏层输\\n\\n出向量为𝑌\" = (𝑦\"\\n\\n\", 𝑦#\\n\\n\", … , 𝑦(cid:129)\\n\\n\", … , 𝑦(cid:130)\\n\\n\" )，图中𝑦<\\n\\n\" = 1表示隐藏层偏置值。输出层输出向量为𝑌# =\\n\\n#, 𝑦#\\n\\n#, … , 𝑦(cid:131)\\n\\n#, … , 𝑦(cid:132)\\n\\n(𝑦\"\\n\\n#)。期望输出𝑇 = (𝑡\", 𝑡#, … , 𝑡(cid:131), … , 𝑡(cid:132))。输入层到隐藏层之间的权值用矩阵\\n\\n𝑊\"表示，𝑤((cid:129)',\n",
       " '𝑊\"表示，𝑤((cid:129)\\n\\n\" 表示𝑊\"矩阵中第 i 行第 j 列的权值。隐藏层到输出层之间的权值用矩阵𝑊#表\\n\\n# 表示𝑊#矩阵中第 j 行第 k 列的权值。另外我们定义𝑛𝑒𝑡\"为隐藏层中权值𝑊\"乘以输入\\n\\n示，𝑤(cid:129)(cid:131)\\n\\n层信号𝑋的总和，𝑛𝑒𝑡(cid:129)\\n\\n\"表示隐藏层中第 j 个神经元得到的输入信号总和。𝑛𝑒𝑡#为输出层中权值\\n\\n𝑊#乘以隐藏层信号𝑌\"的总和，𝑛𝑒𝑡(cid:131)\\n\\n#表示输出层中第 k 个神经元得到的输入信号总和。\\n\\n对于隐藏层有：\\n\\n111\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n@ \" = ? 𝑤((cid:129) (A< \" = 𝑓(𝑛𝑒𝑡(cid:129) 𝑦(cid:129)\\n\\n\" 𝑥(\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 1,2, … , 𝑚\\n\\n𝑛𝑒𝑡(cid:129)\\n\\n\")\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 1,2, … , 𝑚\\n\\n对于输出层有：\\n\\n(cid:130) # = ? 𝑤(cid:129)(cid:131) (cid:129)A<',\n",
       " '(cid:130) # = ? 𝑤(cid:129)(cid:131) (cid:129)A<\\n\\n# 𝑦(cid:129)\\n\\n\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘 = 1,2, … , 𝑙\\n\\n𝑛𝑒𝑡(cid:131)\\n\\n# = 𝑓(𝑛𝑒𝑡(cid:131) 𝑦(cid:131)\\n\\n#)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t𝑘 = 1,2, … , 𝑙\\n\\n公式 4.18 和 4.20 中的激活函数假设我们都使用 sigmoid 函数，sigmoid 函数的公式在\\n\\n上文中的公式 4.13。sigmoid 函数具有连续、可导的特点，它的导数为：\\n\\n𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]\\n\\n4.6.2 BP 算法推导\\n\\n根据上文中提到的代价函数，当网络输出与期望输出不同时，会存在输出误差 E，为了简\\n\\n单我们只计算一个样本的均方差公式，如果是计算多个样本可以求所有样本代价函数的平均值。\\n\\n一个样本的均方差公式定义如下：\\n\\n𝐸 =\\n\\n1 2\\n\\n(𝑇 − 𝑌#)# =\\n\\n1 2\\n\\n(cid:132) ?(𝑡(cid:131) − 𝑦(cid:131) (cid:131)A\"\\n\\n#)#',\n",
       " '#)#\\n\\n将以上误差定义式展开至隐藏层：\\n\\n𝐸 =\\n\\n1 2\\n\\n(cid:132) ?[𝑡(cid:131) − 𝑓(𝑛𝑒𝑡(cid:131) (cid:131)A\"\\n\\n#)\\t]#\\n\\n=\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n再进一步展开至输入层：\\n\\n112\\n\\n(4.17)\\n\\n(4.18)\\n\\n(4.19)\\n\\n(4.20)\\n\\n(4.21)\\n\\n(4.22)\\n\\n(4.23)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n113\\n\\n𝐸 =\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n# 𝑓(cid:142)𝑛𝑒𝑡(cid:129)',\n",
       " '(cid:130)\\n\\n(cid:129)A<\\n\\n# 𝑓(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n\"(cid:143)\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n=\\n\\n1 2\\n\\n(cid:132) ? (cid:138)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131) (cid:131)A\"\\n\\n(cid:130)\\n\\n(cid:129)A<\\n\\n@ # 𝑓 >? 𝑤((cid:129) (A<\\n\\n\" 𝑥(\\n\\nB\\n\\n(cid:140)\\t(cid:141)\\n\\n#\\n\\n(4.24)\\n\\n从公式 4.23 和 4.24 中可以看出，网络的误差 E 是跟神经网络各层权值𝑤((cid:129)\\n\\n\" 和𝑤(cid:129)(cid:131)\\n\\n# 相关的，\\n\\n因此调整各层的权值，就可以改变误差 E 的值。我们的目标就是要得到比较小的误差值，所以\\n\\n我们可以采用梯度下降法来最小化误差 E 的值。根据梯度下降法，我们可以得到：\\n\\n\" = −𝜂\\n\\n∆𝑤((cid:129)\\n\\n𝜕𝐸 𝜕𝑤((cid:129)',\n",
       " '\" = −𝜂\\n\\n∆𝑤((cid:129)\\n\\n𝜕𝐸 𝜕𝑤((cid:129)\\n\\n\" \\t\\t\\t\\t\\t\\t\\t\\t𝑖 = 0,1,2, … , 𝑛; 𝑗 = 1,2, … , 𝑚\\n\\n(4.25)\\n\\n# = −𝜂\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n𝜕𝐸 𝜕𝑤(cid:129)(cid:131)\\n\\n# \\t\\t\\t\\t\\t\\t\\t\\t𝑗 = 0,1,2, … , 𝑚; 𝑘 = 1,2, … , 𝑙\\n\\n(4.26)\\n\\n在下面的推导过程中均默认对于隐藏层有 ：𝑖 = 0,1,2, … , 𝑛; 𝑗 = 1,2, … , 𝑚；对于输出层有：\\n\\n𝑗 = 0,1,2, … , 𝑚; 𝑘 = 1,2, … , 𝑙。\\n\\n根据微积分的链式法则可以得到，对于隐藏层有：\\n\\n\" = −𝜂\\n\\n∆𝑤((cid:129)\\n\\n𝜕𝐸 𝜕𝑤((cid:129)\\n\\n\" = −𝜂\\n\\n𝜕𝐸 \" 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" 𝜕𝑛𝑒𝑡(cid:129) \" 𝜕𝑤((cid:129)\\n\\n(4.27)\\n\\n根据微积分的链式法则可以得到，对于输出层有：\\n\\n# = −𝜂\\n\\n∆𝑤(cid:129)(cid:131)',\n",
       " '# = −𝜂\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n𝜕𝐸 𝜕𝑤(cid:129)(cid:131)\\n\\n# = −𝜂\\n\\n𝜕𝐸 # 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# 𝜕𝑛𝑒𝑡(cid:131) # 𝜕𝑤(cid:129)(cid:131)\\n\\n(4.28)\\n\\n我们可以定义一个误差信号，命名为𝛿（Delta），令：\\n\\n\" = − δ(cid:129)\\n\\n𝜕𝐸 \" 𝜕𝑛𝑒𝑡(cid:129)\\n\\n(4.29)\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 # 𝜕𝑛𝑒𝑡(cid:131)\\n\\n(4.30)\\n\\n综合公式 4.17,4.27,4.29，可以得到输入层到隐藏层的权值调整公式为：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n114\\n\\n\" = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n\"𝑥(\\n\\n(4.31)\\n\\n综合公式 4.19,4.28,4.30，可以得到隐藏层到输出层的权值调整公式为：\\n\\n# = 𝜂δ(cid:131)\\n\\n\" #𝑦(cid:129)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n(4.32)',\n",
       " '\" #𝑦(cid:129)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n(4.32)\\n\\n可以看出在公式 4.31 和 4.32 中，只要求出δ(cid:129)\\n\\n\"和δ(cid:131)\\n\\n#的值，就可以计算出∆𝑤((cid:129)\\n\\n\" 和∆𝑤(cid:129)(cid:131)\\n\\n# 的值\\n\\n了。\\n\\n对于隐藏层，δ(cid:129)\\n\\n\"可以展开为：\\n\\n\" = − δ(cid:129)\\n\\n𝜕𝐸 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" = −\\n\\n𝜕𝐸 \" 𝜕𝑦(cid:129)\\n\\n\" 𝜕𝑦(cid:129) 𝜕𝑛𝑒𝑡(cid:129)\\n\\n\" = −\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\"(cid:143) \" 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n(4.33)\\n\\n对于输出层，δ(cid:131)\\n\\n#可以展开为：\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# = −\\n\\n𝜕𝐸 # 𝜕𝑦(cid:131)\\n\\n# 𝜕𝑦(cid:131) 𝜕𝑛𝑒𝑡(cid:131)\\n\\n# = −\\n\\n𝜕𝐸 𝜕𝑦(cid:131)',\n",
       " '# = −\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n#) # 𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n(4.34)\\n\\n在公式 4.33 和 4.34 中，求网络误差对各层输出的偏导，对于输出层：\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n#) # = −(𝑡(cid:131) − 𝑦(cid:131)\\n\\n(4.35)\\n\\n对于隐藏层：\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\" =\\n\\n𝜕\\n\\n1 2\\n\\n(cid:132) (cid:131)A\"\\n\\n(cid:130) (cid:129)A<\\n\\n∑ (cid:146)𝑡(cid:131) − 𝑓(cid:142)∑ 𝑤(cid:129)(cid:131) \" 𝜕𝑦(cid:129)\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:143)\\t(cid:147)\\n\\n#\\n\\n(cid:132)\\n\\n(cid:130)\\n\\n(cid:130)\\n\\n= − ? (cid:148)𝑡(cid:131) − 𝑓 (cid:139)? 𝑤(cid:129)(cid:131)\\n\\n\" # 𝑦(cid:129)',\n",
       " '\" # 𝑦(cid:129)\\n\\n(cid:140)(cid:149) 𝑓R (cid:139)? 𝑤(cid:129)(cid:131)\\n\\n\" # 𝑦(cid:129)\\n\\n(cid:140)\\n\\n# 𝑤(cid:129)(cid:131)\\n\\n(cid:131)A\"\\n\\n(cid:129)A<\\n\\n(cid:129)A<\\n\\n(cid:132)\\n\\n= − ?(𝑡(cid:131) − 𝑦(cid:131)\\n\\n#) #)𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n# 𝑤(cid:129)(cid:131)\\n\\n(4.36)\\n\\n(cid:131)A\"\\n\\n将式（4.35）带入式（4.34），再根据 sigmoid 函数的求导式（4.21），可以得到：\\n\\n# = − δ(cid:131)\\n\\n𝜕𝐸 𝜕𝑦(cid:131)\\n\\n# 𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n#) = (𝑡(cid:131) − 𝑦(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#) #(1 − 𝑦(cid:131)\\n\\n(4.37)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n\" = − δ(cid:129)',\n",
       " '\" = − δ(cid:129)\\n\\n𝜕𝐸 𝜕𝑦(cid:129)\\n\\n\" 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n(cid:132) \"(cid:143) = >?(𝑡(cid:131) − 𝑦(cid:131) (cid:131)A\"\\n\\n#) #)𝑓R(𝑛𝑒𝑡(cid:131)\\n\\n# B 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n(cid:132)\\n\\n= >?(𝑡(cid:131) − 𝑦(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#) #(1 − 𝑦(cid:131)\\n\\n# B 𝑓R(cid:142)𝑛𝑒𝑡(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n(cid:131)A\"\\n\\n(cid:132) # = >? δ(cid:131) (cid:131)A\"\\n\\n# B 𝑦(cid:129)\\n\\n\"(cid:142)1 − 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)',\n",
       " '𝑤(cid:129)(cid:131)\\n\\n\"(cid:143)\\n\\n将公式 4.37 带入 4.32 中，得到隐藏层到输出层权值调整：\\n\\n# = 𝜂δ(cid:131)\\n\\n#𝑦(cid:129)\\n\\n\" = 𝜂(𝑡(cid:131) − 𝑦(cid:131)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n#)𝑦(cid:131)\\n\\n#(1 − 𝑦(cid:131)\\n\\n\" #)𝑦(cid:129)\\n\\n将公式 4.38 带入 4.31 中，得到输入层到隐藏层权值调整：\\n\\n(cid:132)\\n\\n\" = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n# \"𝑥( = 𝜂 >? δ(cid:131)\\n\\n# B 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n\"(cid:142)1 − 𝑦(cid:129)\\n\\n\"(cid:143)𝑥(\\n\\n(cid:131)A\"\\n\\n对于一个多层的神经网络，假设一共有 h 个隐藏层，按顺序将各隐藏层节点数分别记\\n\\n为：𝑚\", 𝑚#, … , 𝑚(cid:150)，输入神经元个数为 n，输出神经元个数为𝑙；各隐藏层输出分别记为：',\n",
       " '𝑌\", 𝑌#, … , 𝑌(cid:150)，输入层的输入记为：𝑋，输出层的输出记为：𝑌(cid:150)(cid:151)\"；各层权值矩阵分别记为：\\n\\n𝑊\", 𝑊#, … , 𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输\\n\\n出层的权值矩阵；各层学习信号分别记为：𝜹\", 𝜹#, … , 𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信\\n\\n号；则各层权值调整计算公式为：\\n\\n对于输出层：\\n\\n(cid:153)(cid:151)\" = 𝜂δ(cid:131)\\n\\n(cid:150)(cid:151)\"𝑦(cid:129)\\n\\n∆𝑤(cid:129)(cid:131)\\n\\n(cid:150) = 𝜂(cid:142)𝑡(cid:131) − 𝑦(cid:131)\\n\\n(cid:150)(cid:151)\"(cid:143)𝑦(cid:131)\\n\\n(cid:150)(cid:151)\"(cid:142)1 − 𝑦(cid:131)',\n",
       " '(cid:150)(cid:151)\"(cid:142)1 − 𝑦(cid:131)\\n\\n(cid:150) (cid:150)(cid:151)\"(cid:143)𝑦(cid:129)\\n\\n𝑗 = 0,1,2, … , 𝑚(cid:150); 𝑘 = 1,2, … , 𝑙\\n\\n对于第 h 隐藏层：\\n\\n(cid:132)\\n\\n(cid:153) = 𝜂δ(cid:129)\\n\\n∆𝑤((cid:129)\\n\\n(cid:150)𝑦(\\n\\n(cid:150)(cid:127)\" = 𝜂 >? δ(cid:131)\\n\\n(cid:150)(cid:151)\"\\n\\n(cid:150)(cid:151)\"B 𝑦(cid:129)\\n\\n𝑤(cid:129)(cid:131)\\n\\n(cid:150)(cid:142)1 − 𝑦(cid:129)\\n\\n(cid:150)(cid:143)𝑦(\\n\\n(cid:150)(cid:127)\"\\n\\n(cid:131)A\"\\n\\n𝑖 = 0,1,2, … , 𝑚(cid:150)(cid:127)\"; 𝑗 = 1,2, … , 𝑚(cid:150)',\n",
       " '按照以上规律逐层类推，则第一个隐藏层的权值调整公式为：\\n\\n115\\n\\n(4.38)\\n\\n(4.39)\\n\\n(4.40)\\n\\n(4.41)\\n\\n(4.42)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n(cid:130)(cid:157)\\n\\n\" = 𝜂δ(cid:155)\\n\\n# \"𝑥(cid:154) = 𝜂 (cid:139)? δ(cid:156)\\n\\n∆𝑤(cid:154)(cid:155)\\n\\n# (cid:140) 𝑦(cid:155)\\n\\n\"(cid:142)1 − 𝑦(cid:155)\\n\\n𝑤(cid:155)(cid:156)\\n\\n\"(cid:143)𝑥(cid:154)\\n\\n(cid:156)A\" 𝑝 = 0,1,2, … , n; 𝑞 = 1,2, … , 𝑚\"\\n\\n4.6.3 BP 算法推导的补充说明\\n\\n我们已经从头到尾详细推导了一遍 BP 算法的整个流程，在这一小节中对 BP 算法再做两\\n\\n点补充说明。\\n\\n1.网络的偏置值\\n\\n在上文中我们的推导过程一直是使用权值 w 来进行计算的，如果我们把偏置值独立出来，\\n\\n那么偏置值的参数应该怎么调整呢？',\n",
       " '那么偏置值的参数应该怎么调整呢？\\n\\n我们可以看到公式 4.31 以及 4.32，在公式 4.31 中，把 i 的取值设置为 0，并且我们知道\\n\\n𝑥< = 1，所以我们可以得到：\\n\\n\" \" = 𝜂δ(cid:129)\\n\\n∆𝑏(cid:129)\\n\\n在公式 4.31 中，把 j 的取值设置为 0，并且我们知道𝑦< = 1，所以我们可以得到：\\n\\n# # = 𝜂δ(cid:131)\\n\\n∆𝑏(cid:131)\\n\\n如果是把偏置值单独拿出来计算的话就是公式 4.44 和 4.45 的表达式。\\n\\n2.用矩阵形式来表达 BP 学习算法\\n\\n下面我们直接给出 BP 学习算法矩阵表达形式的结果，具体推导过程跟上文中的推导过程\\n\\n类似，不过会涉及到矩阵求导的相关知识，大家有兴趣的话可以自己推导一下。如果是把 BP\\n\\n学习算法写成矩阵的形式来表达，假设一共有 h 个隐藏层。输入数据的矩阵为𝑋，𝑋中的每一\\n\\n行表示一个数据，列表示数据的特征。比如我们一次性输入 3 个数据，每个数据有 4 个特\\n\\n征，那么𝑋就是一个 3 行 4 列的矩阵。\\n\\n116\\n\\n(4.43)\\n\\n(4.44)\\n\\n(4.45)',\n",
       " '116\\n\\n(4.43)\\n\\n(4.44)\\n\\n(4.45)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n各隐藏层输出分别记为：𝑌\", 𝑌#, … , 𝑌(cid:150)，输出层的输出记为：𝑌(cid:150)(cid:151)\"。𝑌中的每一个行表示\\n\\n一个数据的标签。比如我们有 3 个数据，每个数据有 1 个标签，那么𝑌就是一个 3 行 1 列的\\n\\n矩阵。\\n\\n各层权值矩阵分别记为：𝑊\", 𝑊#, … , 𝑊(cid:150)(cid:151)\"，𝑊\"表示输入层到一个隐藏层的权值矩阵，\\n\\n𝑊(cid:150)(cid:151)\"表示最后一个隐藏层到输出层的权值矩阵。权值矩阵的行等于前一层的神经元个数，权\\n\\n值矩阵的列对应于后一层的神经元个数。比如在输入层和第一个隐藏层之间的权值矩阵是\\n\\n𝑊\"，输入层有 3 个神经元，第一个隐藏层有 10 个神经元，那么𝑊\"就是一个 3 行 10 列的矩\\n\\n阵。\\n\\n各层学习信号分别记为：𝜹\", 𝜹#, … , 𝜹(cid:150)(cid:151)\"，𝜹(cid:150)(cid:151)\"表示输出层计算出的学习信号。',\n",
       " '对于输出层的学习信号𝜹(cid:150)(cid:151)\"：\\n\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t= (𝑇 − 𝑌ℎ+1) ∘ 𝑌ℎ+1 ∘ (1 − 𝑌ℎ+1)\\n\\n公式 4.46 中的\" ∘ \"符号是 element-wise multiplication，意思是矩阵中的元素对应相\\n\\n乘。例如下面的例子：\\n\\n𝑎\"\" 𝑎\"# 𝑎\"$ 𝑎#\" 𝑎## 𝑎#$ 𝑎$\" 𝑎$# 𝑎$$\\n\\n>\\n\\nB ∘ >\\n\\n𝑏\"\" 𝑏\"# 𝑏\"$ 𝑏#\" 𝑏## 𝑏#$ 𝑏$\" 𝑏$# 𝑏$$\\n\\nB = >\\n\\n𝑎\"\"𝑏\"\" 𝑎\"#𝑏\"# 𝑎\"$𝑏\"$ 𝑎#\"𝑏#\" 𝑎##𝑏## 𝑎#$𝑏#$ 𝑎$\"𝑏$\" 𝑎$#𝑏$# 𝑎$$𝑏$$\\n\\nB\\n\\n对于第 h 隐藏层的学习信号𝜹(cid:150)：',\n",
       " 'B\\n\\n对于第 h 隐藏层的学习信号𝜹(cid:150)：\\n\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ) \\t\\t\\t\\t\\t\\t\\t\\t\\t= 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑌ℎ ∘ (1 − 𝑌ℎ)\\n\\n对于第 1 隐藏层的学习信号𝜹\"：\\n\\n𝛅\" = 𝛅#(𝑊#)~ ∘ 𝑓R(𝑋𝑊1) \\t\\t\\t\\t\\t\\t\\t\\t\\t= 𝛅#(𝑊#)~ ∘ 𝑌1 ∘ (1 − 𝑌1)\\n\\n对于输出层的权值矩阵𝑊(cid:150)(cid:151)\"：\\n\\n∆𝑊ℎ+1 = 𝜂(𝑌ℎ)~𝛅(cid:150)(cid:151)\"\\n\\n117\\n\\n(4.46)\\n\\n(4.47)\\n\\n(4.48)\\n\\n(4.49)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n对于第 h 隐藏层权值矩阵𝑊(cid:150)：\\n\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~𝛅(cid:150)\\n\\n对于第 1 隐藏层权值矩阵𝑊\"：\\n\\n∆𝑊1 = 𝜂(𝑋)~𝛅\"\\n\\n4.7 BP 算法推导结论总结',\n",
       " '对于第 1 隐藏层权值矩阵𝑊\"：\\n\\n∆𝑊1 = 𝜂(𝑋)~𝛅\"\\n\\n4.7 BP 算法推导结论总结\\n\\n上一小节我们推导了 BP 算法的公式，可能部分同学暂时先跳过了详细推导的部分。如果\\n\\n推导过程看起来有点复杂，我们只看最后推导得到的结论即可。最后推导的结论也就是权值调\\n\\n整的公式为：\\n\\n∆𝑊ℎ = 𝜂(𝑌ℎ−1)~𝛅(cid:150)\\n\\n这里的∆𝑊(cid:150)表示第 h 层权值矩阵 W 的变化，𝜂表示学习率，𝑌(cid:150)(cid:127)\"表示网络第 h-1 层的输\\n\\n出，𝜹(cid:150)表示第 h 层的学习信号。\\n\\n𝜂学习率是为人设置的超参数，𝑌(cid:150)(cid:127)\"网络第 h-1 层的输出只要把数据传入网络中就可以计\\n\\n算出来，所以这里要重点关注的是第 h 层的学习信号𝜹(cid:150)。学习信号有两个不同的公式，输出层\\n\\n的学习信号公式为：\\n\\n𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1)',\n",
       " '𝛅(cid:150)(cid:151)\" = (𝑇 − 𝑌ℎ+1) ∘ 𝑓R(𝑌ℎ𝑊ℎ+1)\\n\\n这里的𝜹(cid:150)(cid:151)\"表示输出层的学习信号，T 表示数据的标签值，𝑌(cid:150)(cid:151)\"表示模型的预测值，𝑓R表\\n\\n示激活函数的导数，𝑌(cid:150)𝑊(cid:150)(cid:151)\"表示输出层信号的汇总。\\n\\nT 是已知的数据标签，Y(cid:153)(cid:151)\"可以传入数据计算得到，激活函数确定以后𝑓R也是已知的，𝑌(cid:150)\\n\\n传入数据可以计算得到，𝑊(cid:150)(cid:151)\"在网络进行随机初始化以后也确定下来了。所以这个公式里面\\n\\n118\\n\\n(4.50)\\n\\n(4.51)\\n\\n(4.52)\\n\\n(4.53)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的所有值都是已知的，或者可以计算得到，把𝜹(cid:150)(cid:151)\"计算出来以后再带入到 4.52 的公式中就可\\n\\n以计算出输出层的权值矩阵要怎么要调整了。\\n\\n除了输出层以外，剩下的网络层的学习信号的公式都是：',\n",
       " '以计算出输出层的权值矩阵要怎么要调整了。\\n\\n除了输出层以外，剩下的网络层的学习信号的公式都是：\\n\\n𝛅(cid:150) = 𝛅(cid:150)(cid:151)\"(𝑊(cid:150)(cid:151)\")~ ∘ 𝑓R(𝑌ℎ−1𝑊ℎ)\\n\\n从这个公式我们可以看到，第 h 层的学习信号𝜹(cid:150)，跟它的下一层 h+1 层的学习信号𝜹(cid:150)(cid:151)\"\\n\\n有关系，还跟它的下一层 h+1 层的权值矩阵的转置(𝑊(cid:150)(cid:151)\")~有关系，以及跟𝑓R(𝑌(cid:150)(cid:127)\"𝑊(cid:150))相关。\\n\\n所以我们在使用 BP 算法的时候需要先根据网络预测的误差计算最后一层的学习信号，然\\n\\n后再计算倒数第二层的学习信号，然后再计算倒数第三层的学习信号以此类推，从后向前计算，\\n\\n因此 BP 算法叫做误差反向传播算法。计算得到每一层的学习信号以后再根据公式 4.52 来计\\n\\n算每一层的权值矩阵如何调整，最后对所有层的权值矩阵进行更新。\\n\\n4.8 梯度消失与梯度爆炸',\n",
       " '算每一层的权值矩阵如何调整，最后对所有层的权值矩阵进行更新。\\n\\n4.8 梯度消失与梯度爆炸\\n\\n前面给大家留了一个思考题，在我们介绍的几种激活函数中，哪种激活函数的效果是最好\\n\\n的。其实这个问题的答案很简单，在介绍它们的时候，一般排在越后面的说明效果就越好，所\\n\\n以 ReLU 是最好的。开个玩笑，下面我们来具体分析一下这几个激活函数的不同效果。\\n\\n4.8.1 梯度消失\\n\\n根据上文 BP 算法中的推导，我们从公式 4.49,,4.50,4.51 中可以知道，权值的调整∆𝑊是\\n\\n跟学习信号𝛿相关的。同时我们从 4.46,4.47,4.48 中可以知道在学习信号𝛿表达式中存在\\n\\n𝑓R(𝑥)。也就是说激活函数的导数会影响学习信号𝛿的值，而学习信号𝛿的值会影响权值调整\\n\\n119\\n\\n(4.54)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n120\\n\\n∆𝑊的值。那么激活函数的值越大，∆𝑊的值就越大；激活函数的值越小，∆𝑊的值也就越\\n\\n小。\\n\\n假设激活函数为 sigmoid 函数，前文中我们已经知道了 sigmoid 函数的表达式为：𝑓(𝑥) =\\n\\n\"',\n",
       " '\"\\n\\n\"(cid:151)⁄¥ƒ，sigmoid 函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]，我们可以画出 sigmoid 函数的导数\\n\\n图像如图 4.19 所示。\\n\\n图 4.19 sigmoid 函数导数\\n\\n这里我们发现当 x=0 时，sigmoid 函数导数可以取得最大值 0.25。x 取值较大或较小时，\\n\\nsigmoid 函数的导数很快就趋向于 0。不管怎么样，sigmoid 函数的导数都是一个小于 1 的\\n\\n数，学习信号𝛿乘以一个小于 1 的数，那么𝛿就会减小。学习信号从输出层一层一层向前反向传\\n\\n播的时候，每传播一层学习信号就会变小一点，经过多层传播后，学习信号就会接近于 0，从\\n\\n而使得权值∆𝑊调整接近于 0。∆𝑊接近于 0 那就意味着该层的参数不会发生改变，不能进行优\\n\\n化。参数不能优化，那整个网络就不能再进行学习了。学习信号随着网络传播逐渐减小的问题\\n\\n也被称为梯度消失（Vanishing Gradient）的问题。\\n\\n我们再考虑一下 tanh 函数的导数，tanh 函数的表达式为：𝑓(𝑥) = ⁄ƒ(cid:127)⁄¥ƒ',\n",
       " '⁄ƒ(cid:151)⁄¥ƒ，tanh 函数的\\n\\n导数为：𝑓R(𝑥) = 1 − (cid:142)𝑓(𝑥)(cid:143)\\n\\n#\\n\\n，tanh 函数的导数如图 4.20 所示。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n121\\n\\n图 4.20 tanh 函数导数\\n\\ntanh 函数导数图像看起来比 sigmoid 函数要好一些，x=0 时，tanh 函数导数可以取得\\n\\n最大值 1。x 取值较大或较小时，tanh 函数的导数很快就趋向于 0。不管怎么样，tanh 函数\\n\\n导数的取值总是小于等于 1 的，所以 tanh 作为激活函数也会存在梯度消失的问题。\\n\\n对于 softsign 函数，softsign 函数的表达式为：𝑓(𝑥) = V\\n\\n\"(cid:151)|V|\\n\\n，softsign 函数的导数为：\\n\\n𝑓R(𝑥) = \"\\n\\n(\"(cid:151)|V|)(cid:157)，softsign 函数的导数如图 4.21 所示。\\n\\n图 4.21 softsign 函数导数\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nsoftsign 函数 x=0 时，softsign 函数导数可以取得最大值 1。x 取值较大或较小时，\\n\\nsoftsign 函数的导数很快就趋向于 0。不管怎么样，softsign 函数导数的取值总是小于等于\\n\\n1 的，所以 softsign 作为激活函数也会存在梯度消失的问题。\\n\\n4.8.2 梯度爆炸\\n\\n当我们使用 sigmoid,tanh 和 softsign 作为激活函数时，它们的导数取值范围都是小于等\\n\\n于 1 的，所以会产生梯度消失的问题。那么我们可能会想到，如果使用导数大于 1 的函数作为\\n\\n激活函数，情况会如何？\\n\\n如果学习信号𝛿乘以一个大于 1 的数，那么δ就会变大。学习信号从输出层一层一层向前\\n\\n反向传播的时候，每传播一层学习信号就会变大一点，经过多层传播后，学习信号就会接近于\\n\\n无穷大，从而使得权值∆𝑊调整接近于无穷大。∆𝑊接近于无穷大那就意味着该层的参数，处于\\n\\n一种极不稳定的状态，那么网络就不能正常工作了。学习信号随着网络传播逐渐增大的问题也',\n",
       " '一种极不稳定的状态，那么网络就不能正常工作了。学习信号随着网络传播逐渐增大的问题也\\n\\n被称为梯度爆炸（Exploding Gradient）的问题。\\n\\n既然激活函数的导数不能小于 1 也不能大于 1，我们可能会想到，能不能使用线性函数\\n\\ny=x，这个函数的导数是 1。它既不会梯度消失，也不会梯度爆炸。确实如此，线性函数导数\\n\\n为 1 的特性是很好，但是，它是一个线性函数，也就是说，它不能处理非线性问题，比如异或\\n\\n分类问题，它就无法解决。而在实际应用中，非常多的应用都是属于非线性问题，所以使用线\\n\\n性函数来作为激活函数存在很大的局限性，所以也不适合。\\n\\n4.8.3 使用 ReLU 函数解决梯度消失和梯度爆炸的问题\\n\\n我们知道 ReLU 的表达式为：𝑓(𝑥) = 𝑚𝑎𝑥\\t(0, 𝑥)。当 x 小于 0 时，𝑓(𝑥)的取值为 0；当 x\\n\\n大于 0 时，𝑓(𝑥)的取值等于 x。ReLU 函数的导数如图 4.22 所示。\\n\\n122\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.22 ReLU 函数导数',\n",
       " '图 4.22 ReLU 函数导数\\n\\n前面我们讨论了当激活函数的导数小于 1 时，网络会产生梯度消失，激活函数的导数大\\n\\n于 1 时，网络会产生梯度爆炸。那么当我们使用 ReLU 作为激活函数的时候，x 小于 0 时，\\n\\nReLU 的导数为 0；x 大于 0 时，ReLU 的导数为 1。导数为 1 是一个很好的特性，不会使得\\n\\n学习信号越来越小，也不会让学习信号越来越大，可以让学习信号比较稳定地从后向前传\\n\\n播。解决了梯度消失和梯度爆炸的问题，同时计算方便，可以加速网络的训练。\\n\\nReLU 函数还有一个优点，它是一个非线性的激活函数，可以用来处理非线性问题，它\\n\\n的非线性特性在 4.5 小节中已经介绍过。\\n\\n认真思考的同学这个时候可能会发现，ReLU 函数看起来是挺好的，既是非线性函数，\\n\\n导数又为 1，但是它好像也存在一些问题，当 x 小于 0 时，ReLU 函数输出为 0，导数也为\\n\\n0，有些信号不就丢失掉了吗？\\n\\n如果你是这么想的，那你就想对了，确实是丢失了一些信号，但是没关系。在神经网络\\n\\n中，信号是冗余的，也就是说其实网络最后在做预测的时候并不需要从前面传过来的所有的',\n",
       " '中，信号是冗余的，也就是说其实网络最后在做预测的时候并不需要从前面传过来的所有的\\n\\n信号，实际上只需要一部分的信号，网络就可以进行预测。并且使用部分信号来进行预测与\\n\\n使用全部信号来进行预测得到的结果相差不大。\\n\\n123\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n比如我们把网络中输出为 0 的神经元看成是不工作的神经元，那么使用 ReLU 函数以后会\\n\\n产生大量不工作的神经元。网络中存在不工作的神经元，我们可以称这个网络具有一定的稀疏\\n\\n性（Sparsity）。不工作的神经元越多，网络就越稀疏。使得网络产生稀疏性的方式很多，除\\n\\n了使用 ReLU 激活函数以外，还可以使用 L1 正则化（L1 Regularization）和 Dropout，这\\n\\n两个技术在后面的章节中会有详细介绍。所以使得神经网络变稀疏并不是什么稀奇的事，也不\\n\\n一定是坏事。\\n\\n稀疏性这一特性也存在于生物体内的神经网络中，大脑中神经网络的稀疏性高达 95%-\\n\\n99%，也就是说在同一时刻其实大脑中大部分的神经元都是不工作。人工神经网络中比较常见\\n\\n的网络稀疏性是 50%-80%。',\n",
       " '的网络稀疏性是 50%-80%。\\n\\n4.9 使用 BP 神经网络解决异或问题\\n\\nBP 神经网络解决异或问题的代码如代码 4-1 所示。\\n\\n代码 4-1：BP 神经网络解决异或问题\\n\\nimport numpy as np import matplotlib.pyplot as plt\\n\\n# 输入数据 X = np.array([[0,0], [0,1], [1,0], [1,1]]) # 标签 T = np.array([[0], [1], [1], [0]])\\n\\n124',\n",
       " '124\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义一个 2 层的神经网络：2-10-1 # 输入层 2 个神经元，隐藏层 10 个神经元，输出层 1 个神经元 # 输入层到隐藏层的权值初始化，2 行 10 列 W1 = np.random.random([2,10]) # 隐藏层到输出层的权值初始化，10 行 1 列 W2 = np.random.random([10,1]) # 初始化偏置值，偏置值的初始化一般可以取 0，或者一个比较小的常数，如 0.1 # 隐藏层的 10 个神经元偏置 b1 = np.zeros([10]) # 输出层的 1 个神经元偏置 b2 = np.zeros([1]) # 学习率设置 lr = 0.1 # 定义训练周期数 epochs = 100001 # 定义测试周期数 test = 5000\\n\\n# 定义 sigmoid 函数 def sigmoid(x): return 1/(1+np.exp(-x))\\n\\n# 定义 sigmoid 函数导数 def dsigmoid(x): return x*(1-x)',\n",
       " '# 更新权值和偏置值 def update(): global X,T,W1,W2,lr,b1,b2\\n\\n# 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2)\\n\\n# 求输出层的学习信号 delta_L2 = (T - L2) * dsigmoid(L2) # 隐藏层的学习信号 delta_L1 = delta_L2.dot(W2.T) * dsigmoid(L1)\\n\\n# 求隐藏层到输出层的权值改变 # 由于一次计算了多个样本，所以需要求平均 delta_W2 = lr * L1.T.dot(delta_L2) / X.shape[0] # 输入层到隐藏层的权值改变\\n\\n125\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 由于一次计算了多个样本，所以需要求平均 delta_W1 = lr * X.T.dot(delta_L1) / X.shape[0]\\n\\n# 更新权值 W2 = W2 + delta_W2 W1 = W1 + delta_W1',\n",
       " \"# 更新权值 W2 = W2 + delta_W2 W1 = W1 + delta_W1\\n\\n# 改变偏置值 # 由于一次计算了多个样本，所以需要求平均 b2 = b2 + lr * np.mean(delta_L2, axis=0) b1 = b1 + lr * np.mean(delta_L1, axis=0)\\n\\n# 定义空 list 用于保存 loss loss = [] # 训练模型 for i in range(epochs): # 更新权值 update() # 每训练 5000 次计算一次 loss 值 if i % test == 0: # 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2) # 计算 loss 值 print('epochs:',i,'loss:',np.mean(np.square(T - L2) / 2)) # 保存 loss 值 loss.append(np.mean(np.square(T - L2) / 2))\",\n",
       " \"# 画图训练周期数与 loss 的关系图 plt.plot(range(0,epochs,test),loss) plt.xlabel('epochs') plt.ylabel('loss') plt.show()\\n\\n# 隐藏层输出 L1 = sigmoid(np.dot(X,W1) + b1) # 输出层输出 L2 = sigmoid(np.dot(L1,W2) + b2) print('output:') print(L2)\\n\\n# 因为最终的分类只有 0 和 1，所以我们可以把 # 大于等于 0.5 的值归为 1 类，小于 0.5 的值归为 0 类\\n\\n126\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com def predict(x): if x>=0.5: return 1 else: return 0\",\n",
       " \"# map 会根据提供的函数对指定序列做映射 # 相当于依次把 L2 中的值放到 predict 函数中计算 # 然后打印出结果 print('predict:') for i in map(predict,L2): print(i) 运行结果如下： epochs: 0 loss: 0.2382731940835196 epochs: 5000 loss: 0.1206923173399693 epochs: 10000 loss: 0.0790971946756123 epochs: 15000 loss: 0.02378338344093093 epochs: 20000 loss: 0.008377749771590743 epochs: 25000 loss: 0.004291050338268038 epochs: 30000 loss: 0.002694668764968099 epochs: 35000 loss: 0.0018982939821333231 epochs: 40000 loss: 0.0014365256397058071 epochs: 45000\",\n",
       " '40000 loss: 0.0014365256397058071 epochs: 45000 loss: 0.001140826866565359 epochs: 50000 loss: 0.0009377943334308873 epochs: 55000 loss: 0.0007910315050028132 epochs: 60000 loss: 0.000680683460806228 epochs: 65000 loss: 0.0005950985467089836 epochs: 70000 loss: 0.0005270339320851203 epochs: 75000 loss: 0.00047177302525578296 epochs: 80000 loss: 0.0004261243077828677 epochs: 85000 loss: 0.00038785770517095713 epochs: 90000 loss: 0.0003553718177062329 epochs: 95000 loss: 0.0003274893656556488',\n",
       " 'epochs: 95000 loss: 0.0003274893656556488 epochs: 100000 loss: 0.00030332701795183955',\n",
       " '127\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\noutput: [[0.02462022] [0.97697496] [0.97534433] [0.02612291]] predict: 0 1 1 0\\n\\n4.10 分类模型评估方法\\n\\n4.10.1 准确率/精确率/召回率/F1 值\\n\\n机器学习中有很多分类模型评估指标，比如 准确率（Accuracy），精确率（查准率，\\n\\nPrecision）和召回率（查全率，Recall）都是比较常见的。\\n\\n我们先来说一下准确率，准确也是我们日常生活中用得较多的一个判断指标，准确率的计\\n\\n算很简单，准确率=所有预测正确的结果除以所有结果。比如一个模型要识别 5 张图片，最后\\n\\n识别正确 4 张图片，错了 1 张，那么准确率就是 4/5=80%。\\n\\n128\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n倘若某人声称创建了一个能够识别登上飞机的恐怖分子的模型，并且准确率（accuracy）\\n\\n高达 99%。这能算是个好模型吗？已知美国全年平均有 8 亿人次的乘客，并且在 2000-',\n",
       " '高达 99%。这能算是个好模型吗？已知美国全年平均有 8 亿人次的乘客，并且在 2000-\\n\\n2017 年间共发现了 19 名恐怖分子。如果有一个模型将从美国机场起飞的所有乘客都标注为\\n\\n非恐怖分子，那么这个模型达到了接近完美的准确率——99.99999%。这听起来确实令人印\\n\\n象深刻，但是美国国土安全局肯定不会购买这个模型。尽管这个模型拥有接近完美的准确率，\\n\\n但是在这个问题中准确率显然不是一个合适的度量指标。\\n\\n恐怖分子检测是一个不平衡的分类问题：我们需要鉴别的类别有两个，恐怖分子和非恐怖\\n\\n分子，其中一个类别代表了极大多数的数据，而另一个类别数据却很少。比如我们把恐怖分子\\n\\n定义为正例，非恐怖分子定义为负例，那么正例类别——恐怖分子，远远少于负例类别——非\\n\\n恐怖分子的数量。这种数据不均衡的问题是数据科学中比较常见的，在数据不均衡的情况下使\\n\\n用准确率并不是评估模型性能的很好的衡量标准。当然，如果是数据比较均衡的情况下，我们\\n\\n还是可以使用准确率来作为分类模型的评估指标。\\n\\n所以在数据不均衡的场景下，我们应该考虑的评估指标应该是精确率和召回率。我们先看\\n\\n一下图 4.23。',\n",
       " '一下图 4.23。\\n\\n图 4.23 真实标注与模型预测对比\\n\\n图中的 True Positive(TP)表示模型预测结果是恐怖分子，数据的真实标注也是恐怖分子；\\n\\nFalse Positive(FP)表示模型预测结果是恐怖分子，数据的真实标注是非恐怖分子； False\\n\\n129\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n130\\n\\nNegative(FN) 表示模 型预 测结 果是非恐 怖分子 ，数据的真 实 标 注是恐 怖分子；\\n\\nTrue\\n\\nNegative(TN)表示模型预测结果是非恐怖分子，数据的真实标注也是非恐怖分子。\\n\\n这里的 True/Fasle 和 Positive/Negative 我们可以这么来理解，True 或 Fasle 表示模型\\n\\n预测结果是否正确，如果预测正确就是 True，预测错误就是 Fasle。所以相当于 TP 和 TN 都\\n\\n表示模型预测是正确的，FP 和 FN 表示模型预测不正确。Positive 或 Negative 表示模型的预',\n",
       " '测结果。TP 和 FP 模型预测结果都是 Positive，TN 和 FN 模型预测结果都是 Negative。\\n\\n看懂这个图以后我们来看一下召回率（recall）的公式：\\n\\n𝑟𝑒𝑐𝑎𝑙𝑙 =\\n\\n𝑇𝑃 𝑇𝑃 + 𝐹𝑁\\n\\n(4.55)\\n\\n召回率描述的是模型对于正例——恐怖分子的召回能力，也就是找到恐怖分子的能力。比\\n\\n如一共有 19 名恐怖分子，模型可以正确识别出 10 名恐怖分子，有 9 名恐怖分子没有识别出\\n\\n来。那么 TP=10，FN=9，recall=10/(10+9)=52.63%。比如一共有 19 名恐怖分子，模型可\\n\\n以正确识别出 18 名恐怖分子，有 1 名恐怖分子没有识别出来，那么 TP=18，FN=1，\\n\\nrecall=18/(18+1)=94.74%。召回率越高说明模型找到恐怖分子的能力越强。\\n\\n我们再来看一下精确率（precision）的公式：\\n\\n𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =\\n\\n𝑇𝑃 𝑇𝑃 + 𝐹𝑃\\n\\n(4.56)\\n\\n精确率描述的是模型对于正例-恐怖分子的判断能力。比如模型可以正确识别出 10 名恐',\n",
       " '精确率描述的是模型对于正例-恐怖分子的判断能力。比如模型可以正确识别出 10 名恐\\n\\n怖分子，另外还有 40 人模型判断是恐怖分子，其实这 40 人是非恐怖分子。那么 TP=10，\\n\\nFP=40，precision=10/(10+40)=20%。比如模型可以正确识别 9 名恐怖分子，另外还有 1\\n\\n人模 型判断是恐 怖分子 ， 其实这\\n\\n1 人 是非恐 怖分子 。那么\\n\\nTP=9 ， FP=1 ，\\n\\nprecision=9/(9+1)=90%。精确率越高说明模型对于恐怖分子的识别越精准。\\n\\n准确率（accuracy）的公式为：\\n\\n𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =\\n\\n𝑇𝑃 + 𝑇𝑁 𝑇𝑃 + 𝐹𝑁 + 𝐹𝑃 + 𝑇𝑁\\n\\n(4.57)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n也就是所有识别正确的结果除以所有结果。\\n\\n针对不同的问题，我们所关注的评估指标可能也会有所不同。比如 2020 年初新型冠状病\\n\\n毒爆发时期，我们更关注召回率，因为我们要尽量找到所有带有新型冠状病毒的病人，然后把\\n\\n病人进行隔离观察治疗，宁可抓错 100，也不能放过 1 个。',\n",
       " '病人进行隔离观察治疗，宁可抓错 100，也不能放过 1 个。\\n\\n再举一个信息检索中比较极端的例子，假如一个搜索引擎有 10000 个网站，其中有 100\\n\\n个深度学习相关的网站。当我们搜索“深度学习是什么？”的时候，如果搜索引擎想提高精确\\n\\n率，那么它可以只返回一个跟深度学习相关度最高的网站，如果这个结果是我们想要的，那么\\n\\n精确率就是 100%，不过这样做，召回率只有 1%。如果搜索引擎想提高召回率，那么它可以\\n\\n返回 10000 个网站，这样做召回率就可以有 100%，不过精确率只有 1%。\\n\\n所以判断一个搜索引擎好坏，主要看的是前面几十条结果的精确率，因为我们通常只会查\\n\\n看最前面的几十条结果，特别是最前面的几条结果。最前面的几条结果是我们想要的，我们就\\n\\n会认为这个搜索引擎很好。我们并不是很在意搜索引擎的召回率，比如一共有 10000 条结果\\n\\n是符合我们想要的结果，搜索引擎给我们返回了 1000 条还是 9000 条，其实我们并不在意，\\n\\n因为我们只会看最前面的几十条结果。\\n\\n在实际应用中，最理想的情况是精确率和召回率都比较高，不过一般来说，很难得到精确',\n",
       " '在实际应用中，最理想的情况是精确率和召回率都比较高，不过一般来说，很难得到精确\\n\\n率和召回率都很高的结果。很多时候是提高了精确率，召回率就会降低；提高召回率，精确率\\n\\n就会降低。所以我们还需要一个综合评估指标，也就是 F 值，F 值是精确率(P)和召回率(R)的\\n\\n加权调和平均，公式为：\\n\\n𝐹 =\\n\\n((𝛼# + 1) × 𝑃 × 𝑅) 𝛼# × 𝑃 + 𝑅\\n\\n当参数𝛼 = 1时，就是最常见的的 F1 值，即：\\n\\n𝐹1 =\\n\\n2 × 𝑃 × 𝑅 𝑃 + 𝑅\\n\\n131\\n\\n(4.58)\\n\\n(4.59)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nF1 值综合了 P 和 R 的结果，可用于综合评价分类结果的质量。\\n\\n准确率，召回率，精确率，F1 值都是在 0-1 之间，并且都是越大越好。\\n\\n最后我再举一个例子，帮助大家理解这 4 个评估指标的计算。比如一个预测恐怖分子的模\\n\\n型结果如图 4.24 所示。\\n\\n图 4.24 模型结果\\n\\n有 10 个恐怖分子模型预测结果也是恐怖分子（TP）\\n\\n有 10 个非恐怖分子模型预测结果是恐怖分子（FP）',\n",
       " '有 10 个非恐怖分子模型预测结果是恐怖分子（FP）\\n\\n有 5 个恐怖分子模型预测结果是非恐怖分子（FN）\\n\\n有 75 个非恐怖分子模型预测结果是非恐怖分子（TN）\\n\\n准确率计算：(TP+TN)/(TP+FN+FP+TN)=(10+75)/(10+5+10+75)=85%\\n\\n召回率计算：TP/(TP+FN)=10/(10+5)=66.67%\\n\\n精确率计算：TP/(TP+FP)=10/(10+10)=50%\\n\\nF1 值：(2×50%×66.67%)/(50%+66.67%)=57.14%\\n\\n4.10.2 混淆矩阵(Confusion Matrix)\\n\\n在机器学习领域，混淆矩阵又称为可能性表格或者是错误矩阵。它是一种特定的矩阵用来\\n\\n呈现算法的效果。我们还是通过例子来讲解，假设有一个人，狗，猫的分类系统，我们的测试\\n\\n样本一共有 10 个人，15 只狗，5 只猫，得到如下混淆矩阵，如图 4.25 所示。\\n\\n132\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n模型预测\\n\\n真实标签\\n\\n猫 狗\\n\\n猫 3 3\\n\\n狗 1 11\\n\\n人 1 1\\n\\n人\\n\\n1\\n\\n2\\n\\n7',\n",
       " '真实标签\\n\\n猫 狗\\n\\n猫 3 3\\n\\n狗 1 11\\n\\n人 1 1\\n\\n人\\n\\n1\\n\\n2\\n\\n7\\n\\n图 4.25 混淆矩阵\\n\\n图中表达的意思是，一共有 5 只猫，其中 3 中预测正确了，有 1 只猫被预测成了狗，有\\n\\n1 只猫被预测成了人；一共有 15 只狗，其中有 3 只狗被预测成了猫，有 11 只狗预测正确，\\n\\n有 1 只狗被预测成了人；一共有 10 个人，其中有 1 个人被预测成了猫，有两个人被预测成\\n\\n了狗，有 7 个人预测正确。\\n\\n4.11 独热编码（One-Hot Encoding）\\n\\n在神经网络，深度学习的分类问题中，我们通常会把分类问题的标签转化为独热编码的格\\n\\n式。比如在手写数字识别的任务中，数字有 0-9 一共 10 中状态，所以每个数字都可以转换为\\n\\n长度为 10 的编码：\\n\\n0->1000000000\\n\\n1->0100000000\\n\\n2->0010000000\\n\\n3->0001000000\\n\\n4->0000100000\\n\\n5->0000010000\\n\\n6->0000001000\\n\\n133\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '133\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7->0000000100\\n\\n8->0000000010\\n\\n9>-0000000001\\n\\n比如对于根据图片判断性别的模型：\\n\\n男性可以编码为：10\\n\\n女性可以编码为：01\\n\\n比如给花的品种进行分类的模型，假设有红黄蓝三种花：\\n\\n红花可以编码为：100\\n\\n黄花可以编码为：010\\n\\n蓝花可以编码为：001\\n\\n根据以上的几个例子大家应该都可以了解独热编码是怎么回事了，在后面的分类应用中我\\n\\n们经常会把分类的标签处理成为独热编码的格式，然后用来训练模型。\\n\\n4.12 BP 神经网络完成手写数字识别\\n\\n这一小节中我们要自己搭建一个 BP 网络来完成手写数字识别的功能，我们使用到的训练\\n\\n集是 sklearn 中自带的手写数字数据集。首先我们先看一下数据集，如代码 4-2 所示。\\n\\n代码 4-2：手写数字数据集介绍\\n\\nfrom sklearn.datasets import load_digits import matplotlib.pyplot as plt',\n",
       " \"# 载入手写数字数据 digits = load_digits() # 打印数据集的 shape，行表示数据集个数，列表示每个数据的特征数\\n\\n134\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com print('data shape:',digits.data.shape) # 打印数据标签的 shape，数据标签的值为 0-9 print('target shape:',digits.target.shape) # 准备显示第 0 张图片，图片为灰度图 plt.imshow(digits.images[0],cmap='gray') # 显示图片 plt.show() 运行结果如下： data shape: (1797, 64) target shape: (1797,)\\n\\n观察 4-2 程序的输出我们可以发现这个数据集中每个数据的图片是一张 8×8 的图片，分\\n\\n别对应数字 0-9。所以我们可以考虑构建一个输入层为 64 个神经元的神经网络，64 个神经\\n\\n元对应于图片中的 64 个像素点。假设我们设置一层隐藏层，隐藏层有 100 个神经元。最后\",\n",
       " '元对应于图片中的 64 个像素点。假设我们设置一层隐藏层，隐藏层有 100 个神经元。最后\\n\\n设置一个输出层，我们会把标签转变为独热编码(one-hot)的格式，数字 0-9 一共 10 个状\\n\\n态，所以输出层我们可以设置 10 个神经元。数字识别网络结构图如图 4.26 所示。\\n\\n135\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 4.26 数字识别网络结构图\\n\\nBP 网络完成手写数字识别的代码如代码 4-3 所示。\\n\\n代码 4-3：BP 网络完成手写数字识别',\n",
       " '代码 4-3：BP 网络完成手写数字识别\\n\\n# 导入 numpy 科学计算库 import numpy as np # 载入画图工具包 import matplotlib.pyplot as plt # 导入手写数字数据集 from sklearn.datasets import load_digits # 用于标签二值化处理，把标签转成独热编码 one-hot 的格式 from sklearn.preprocessing import LabelBinarizer # 用于把数据集拆分为训练集和测试集 from sklearn.cross_validation import train_test_split # 用于评估分类结果 from sklearn.metrics import classification_report,confusion_matrix\\n\\n# 定义 sigmoid 函数 def sigmoid(x): return 1/(1+np.exp(-x))\\n\\n# 定义 sigmoid 函数的导数 def dsigmoid(x): return x*(1-x)',\n",
       " '# 定义神经网络类\\n\\n136\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com class NeuralNetwork: # 初始化网络，定义网络结构 # 假设传入(64,100,10)，说明定义： # 输入层 64 个神经元，隐藏层 100 个神经元，输出层 10 个神经元 def __init__(self,layers): # 权值的初始化，范围-1 到 1 self.W1 = np.random.random([layers[0],layers[1]])*2-1 self.W2 = np.random.random([layers[1],layers[2]])*2-1 # 初始化偏置值 self.b1 = np.zeros([layers[1]]) self.b2 = np.zeros([layers[2]]) # 定义空 list 用于保存 list self.loss = [] # 定义空 list 用于保存 self.accuracy = []',\n",
       " '# 训练模型 # X 为数据输入 # T 为数据对应的标签 # lr 学习率 # steps 训练次数 # batch 批次大小 # 使用批量随机梯度下降法，每次随机抽取一个批次的数据进行训练 def train(self,X,T,lr=0.1,steps=20000,test=5000,batch=50): # 进行 steps+1 次训练 for n in range(steps+1): # 随机选取一个批次数据 index = np.random.randint(0,X.shape[0],batch) x = X[index] # 计算隐藏层输出 L1 = sigmoid(np.dot(x,self.W1)+self.b1) # 计算输出层输出 L2 = sigmoid(np.dot(L1,self.W2)+self.b2) # 求输出层的学习信号 delta_L2 = (T[index]-L2)*dsigmoid(L2) # 求隐藏层的学习信号 delta_L1= delta_L2.dot(self.W2.T)*dsigmoid(L1) # 求隐藏层到输出层的权值改变 #',\n",
       " '# 求隐藏层到输出层的权值改变 # 由于一次计算了多个样本，所以需要求平均 self.W2 += lr * L1.T.dot(delta_L2) / x.shape[0] # 求输入层到隐藏层的权值改变 # 由于一次计算了多个样本，所以需要求平均 self.W1 += lr * x.T.dot(delta_L1) / x.shape[0] # 改变偏置值',\n",
       " '137\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.b2 = self.b2 + lr * np.mean(delta_L2, axis=0) self.b1 = self.b1 + lr * np.mean(delta_L1, axis=0)',\n",
       " '# 每训练 5000 次预测一次准确率 if n%test==0: # 预测测试集的预测结果 Y2 = self.predict(X_test) # 取得预测结果最大的所在的索引 # 例如最大值所在的索引是 3，那么预测结果就是 3 predictions = np.argmax(Y2,axis=1) # 计算准确率 # np.equal(predictions,y_test)判断预测结果和真实标签是否相等，相等返回 True，不相等返回 False # np.equal(predictions,y_test)执行后得到一个包含多个 True 和 False 的列表 # 然后用 np.mean 对列表求平均 True 为 1，False 为 0。 # 例如一共有 10 个结果，9 个 True，一个 False，平均后的结果为 0.9，即预测的 准确率为 90% acc = np.mean(np.equal(predictions,y_test)) # 计算 loss l = np.mean(np.square(y_test - predictions) / 2) # 保存准确率',\n",
       " \"- predictions) / 2) # 保存准确率 self.accuracy.append(acc) # 保存 loss 值 self.loss.append(l) # 打印训练次数,准确率和 loss print('steps:%d accuracy:%.3f loss:%.3f' % (n,acc,l))\",\n",
       " '# 模型预测结果 def predict(self,x): L1 = sigmoid(np.dot(x,self.W1)+self.b1)#隐层输出 L2 = sigmoid(np.dot(L1,self.W2)+self.b2)#输出层输出 return L2\\n\\n# 程序从这里开始运行 # 定义训练次数 steps = 30001 # 定义测试周期数 test = 3000 # 载入数据 digits = load_digits() # 得到数据 X = digits.data # 得到标签 y = digits.target\\n\\n138',\n",
       " \"138\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 输入数据归一化，有助于加快训练速度 # X 中原来的数值范围是 0-255 之间，归一化后变成 0-1 之间 X -= X.min() X /= X.max() - X.min() # 分割数据 1/4 为测试数据，3/4 为训练数据 # 有 1347 个训练数据，450 个测试数据 X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\\n\\n# 创建网络,输入层 64 个神经元，隐藏层 100 个神经元，输出层 10 个神经元 nm = NeuralNetwork([64,100,10]) # 标签转化为独热编码 one-hot 的格式 labels_train = LabelBinarizer().fit_transform(y_train)\\n\\n# 开始训练 print('Start training') nm.train(X_train,labels_train,steps=steps,test=test)\",\n",
       " \"# 预测测试数据 predictions = nm.predict(X_test) # predictions.shape 为(450,10) # y_test.shape 为(450,) # 所以需要取得预测结果最大的所在的索引，该索引就是网络预测的结果 # np.argmax(predictions,axis=1)执行后得到的形状也变成了(450,) predictions = np.argmax(predictions,axis=1) # 对比测试数据的真实标签与网络预测结果，得到准确率，召回率和 F1 值 print(classification_report(y_test,predictions)) # 对于测试数据的真实标签与网络预测结果，得到混淆矩阵 print(confusion_matrix(y_test,predictions))\\n\\n# 训练次数与 loss 的关系图 plt.plot(range(0,steps+1,test),nm.loss) plt.xlabel('steps') plt.ylabel('loss') plt.show()\",\n",
       " \"# 训练次数与 accuracy 的关系图 plt.plot(range(0,steps+1,test),nm.accuracy) plt.xlabel('steps') plt.ylabel('accuracy') plt.show() 运行结果如下： Start training steps:0 accuracy:0.111 loss:10.206 steps:3000 accuracy:0.922 loss:0.777\\n\\n139\",\n",
       " '139\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com steps:6000 accuracy:0.960 loss:0.469 steps:9000 accuracy:0.964 loss:0.389 steps:12000 accuracy:0.967 loss:0.361 steps:15000 accuracy:0.964 loss:0.416 steps:18000 accuracy:0.971 loss:0.342 steps:21000 accuracy:0.969 loss:0.378 steps:24000 accuracy:0.971 loss:0.342 steps:27000 accuracy:0.971 loss:0.360 steps:30000 accuracy:0.971 loss:0.360 precision recall f1-score support',\n",
       " '0 1.00 0.98 0.99 45 1 0.93 0.98 0.95 41 2 0.98 1.00 0.99 50 3 1.00 0.93 0.96 40 4 0.98 0.98 0.98 48 5 0.94 0.98 0.96 51 6 0.98 1.00 0.99 42 7 1.00 1.00 1.00 45 8 0.93 0.91 0.92 44 9 0.98 0.95 0.97 44\\n\\navg / total 0.97 0.97 0.97 450\\n\\n[[44 0 0 0 1 0 0 0 0 0] [ 0 40 0 0 0 0 0 0 1 0] [ 0 0 50 0 0 0 0 0 0 0] [ 0 0 0 37 0 2 0 0 1 0] [ 0 0 0 0 47 0 0 0 0 1] [ 0 0 0 0 0 50 1 0 0 0] [ 0 0 0 0 0 0 42 0 0 0] [ 0 0 0 0 0 0 0 45 0 0] [ 0 3 1 0 0 0 0 0 40 0] [ 0 0 0 0 0 1 0 0 1 42]]\\n\\n140',\n",
       " '140\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.13 Sklearn 手写数字识别\\n\\n上一小节我们学习了如何从头开始搭建一个 BP 神经网络来完成手写数字识别，其实搭\\n\\n建 BP 神经网络还有更简单快捷的方法，就是使用 scikit-learn 模块。scikit-learn 是一个常\\n\\n用的 python 模型，里面封装了大量机器学习算法，其中就包括 BP 神经网络。下面我们来\\n\\n看一下如何使用 scikit-learn 中的神经网络算法来进行手写数字识别，如代码 4-4 所示。\\n\\n代码 4-4：BP 网络完成手写数字识别(使用 scikit-learn 中的神经网络算法)',\n",
       " '代码 4-4：BP 网络完成手写数字识别(使用 scikit-learn 中的神经网络算法)\\n\\n# 载入 BP 神经网络算法 from sklearn.neural_network import MLPClassifier from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report\\n\\n141',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import matplotlib.pyplot as plt #载入数据 digits = load_digits() #数据 x_data = digits.data #标签 y_data = digits.target # X 中原来的数值范围是 0-255 之间，归一化后变成 0-1 之间 x_data -= x_data.min() x_data /= x_data.max() - x_data.min() # 分割数据 1/4 为测试数据，3/4 为训练数据 # 有 1347 个训练数据，450 个测试数据 x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.25) # 定义神经网络模型，模型输入神经元个数和输出神经元个数不需要设置 # hidden_layer_sizes 用于设置隐藏层结构： # 比如(50)表示有 1 个隐藏层，隐藏层神经元个数为 50 # 比如(100,20)表示有 2',\n",
       " '# 比如(50)表示有 1 个隐藏层，隐藏层神经元个数为 50 # 比如(100,20)表示有 2 个隐藏层，第 1 个隐藏层有 100 个神经元，第 2 个隐藏层有 20 个神 经元 # 比如(100,20,10)表示 3 个隐藏层，神经元个数分别为 100，20，10 # max_iter 设置训练次数 mlp = MLPClassifier(hidden_layer_sizes=(100,20), max_iter=500) # fit 传入训练集数据开始训练模型 mlp.fit(x_train,y_train) # predict 用于模型预测 predictions = mlp.predict(x_test) # 标签数据和模型预测数据进行对比，计算分类评估指标 print(classification_report(y_test, predictions)) 运行结果如下：',\n",
       " 'precision recall f1-score support\\n\\n0 1.00 1.00 1.00 35 1 0.98 1.00 0.99 49 2 1.00 0.98 0.99 50 3 0.97 0.97 0.97 38 4 1.00 0.98 0.99 56 5 1.00 0.93 0.96 43 6 1.00 1.00 1.00 47 7 0.94 1.00 0.97 46 8 0.95 1.00 0.97 36 9 0.98 0.96 0.97 50\\n\\naccuracy 0.98 450 macro avg 0.98 0.98 0.98 450 weighted avg 0.98 0.98 0.98 450\\n\\n142\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n要注意的是 scikit-learn 中封装的神经网络只是普通的 BP 神经网络，不具备深度学习算\\n\\n法。如果要实现深度学习算法需要使用专门的深度学习框架，如 Tensorflow，在下一章节中\\n\\n我们会详细介绍。\\n\\n4.14 参考文献',\n",
       " '我们会详细介绍。\\n\\n4.14 参考文献\\n\\n[1] McClelland J L, Rumelhart D E, PDP Research Group. Parallel Distributed\\n\\nProcessing [J]. Explorations in the Microstructure of Cognition, 1986, 2: 216-271.\\n\\n[2] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural\\n\\nnetworks[C]//Proceedings of the fourteenth international conference on artificial\\n\\nintelligence and statistics. 2011: 315-323.\\n\\n[3] 韩力群, 康芊. 人工神经网络理论, 设计及应用——神经细胞, 神经网络和神经系统[J].\\n\\n北京工商大学学报: 自然科学版, 2005, 23(1): 52-52.\\n\\n143',\n",
       " '北京工商大学学报: 自然科学版, 2005, 23(1): 52-52.\\n\\n143\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 5 章-深度学习框架 Tensorflow 基础使\\n\\n用\\n\\n在介绍正式内容以前，我想先给大家说明一个基本情况，也就是目前深度学习还处于一\\n\\n个非常早期的，不成熟的阶段，所以我们会看到各种各样的人写着各种各样风格的代码。当\\n\\n我们想完成一个应用的时候，我们会有很多种方式和选择，有时候选择太多也不一定是好\\n\\n事，因为我们可能会面临选择的困难。虽然“条条大路通罗马”，但是有些路好走，有些路不\\n\\n好走；有些路部分人觉得好走，部分人觉得不好走。很多时候我们很难判断哪条路好，哪条\\n\\n路不好。\\n\\n给大家举一个例子来说明这个问题，如图 5.1 所示。\\n\\n图 5.1 条条大路通罗马\\n\\n比如我们想做一个图像识别的应用，那么首先我们有很多种深度学习的框架可以选择。\\n\\n如果是在 2016-2017 年左右，那么这个选择还是挺难的，因为每个深度学习的框架都有自己\\n\\n的优缺点，我们可能很难选择学习哪一个框架。当然，这个问题现在相对变得容易了，经过',\n",
       " '的优缺点，我们可能很难选择学习哪一个框架。当然，这个问题现在相对变得容易了，经过\\n\\n时间的考验，现在业内公认的首选的深度学习框架就是 Tensorflow 或者 Pytorch。Pytorch\\n\\n144\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n是最近一两年学术界最喜欢使用的深度学习框架，Tensorflow 是落地应用最多的深度学习框\\n\\n架。如果让我推荐的话，我会推荐两者都学，多学总不是坏事。我们这本书主要是以\\n\\nTensorflow 为重点，大家可以先跟着我把 Tensorflow 学好。\\n\\n深度学习框架选好之后，接下来要继续选择，每个框架在实现某个具体应用的时候通常\\n\\n都会有很多种实现方式。比如如何载入数据进行数据预处理有很多种方法，如何搭建网络有\\n\\n很多种方法，如何训练模型又有很多种方法。比如图 5.1 中，假设我们选择了 Tensorflow 作\\n\\n为我们的深度学习框架，那么我们在搭建网络结构的时候又可以选择使用 Tensorflow 的高',\n",
       " '为我们的深度学习框架，那么我们在搭建网络结构的时候又可以选择使用 Tensorflow 的高\\n\\n级 API：Slim，TFLearn，tf.layers，tf.keras 或其他 API，最后完成图像识别的应用。由于\\n\\n各种方法比较多，我们全部都学并不是一个明智的选择，所以在本书中我会选择我认为比较\\n\\n容易理解和学习方法来教大家。Tensorflow2.0 推出以后，谷歌官方建议大家使用 tf.keras\\n\\n来搭建和训练模型。Keras 也是我非常喜欢的一款深度学习框架，它是所有深度学习框架中\\n\\n最容易使用的，没有之一，所以也比较适合初学者使用。鉴于 Keras 的简洁易用性以及容易\\n\\n理解和学习的特点，本书中关于深度学习的应用大部分都会基于 tf.keras 的 API 完成。\\n\\n5.1 Tensorflow 介绍\\n\\n5.1.1 Tensorflow 简介\\n\\nTensorflow 的官网是：https://tensorflow.google.cn/，不需要翻墙。\\n\\n还有一个需要翻墙的官网是：https://www.tensorflow.org。\\n\\n145',\n",
       " '还有一个需要翻墙的官网是：https://www.tensorflow.org。\\n\\n145\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 是谷歌基于 DisBelief 进行研发的第二代人工智能学习系统，并于 2015 年\\n\\n11 月 9 日开源。Tensorflow 可被用于图像识别，语音识别，文本处理等多项机器学习和深度\\n\\n学习领域。并且可以运行在智能手机，个人电脑，数据中心服务器等各种设备上。\\n\\n目前支持 Windows，MacOS，Linux 系统，支持 CPU/GPU 版本，支持单机和分布式版\\n\\n本。\\n\\nTensorflow 支持多种编程语言，目前有 Python，C++，GO，JAVA，R，SWIFT，JavaScript。\\n\\n最主流的编程语言是 Python，本书主要介绍的编程语言也是 Python。目前 Tensorflow 支持\\n\\n64 位的 Python3.5/3.6/3.7/3.8 版本。',\n",
       " '64 位的 Python3.5/3.6/3.7/3.8 版本。\\n\\n2019 年 3 月 8 日，Google 发布最新 Tensorflow2.0-Alpha 版本，并在 2019 年 10 月\\n\\n1 日发布了 Tensorflow2.0 正式版本。新版本的 Tensorflow 有很多新特性，更快更容易使用\\n\\n更人性化。因为新版本的 Tensorflow 有较大的更新，所以老版的 Tensorflow 程序在新版本\\n\\n中几乎都无法继续使用。\\n\\n如果是作为一个初学者，那么我们应该先学 Tensorflow1 呢，还是直接学习\\n\\nTensorflow2。学习 Tensorflow1 的理由是现在网上的 Tensorflow 开源程序以及比较成熟\\n\\n的 Tensorflow 项目基本上都是基于 Tensorflow1 的，Tensorflow2 刚出不久，资源相对来\\n\\n说肯定会比较少一些。不过 Tensorflow2 肯定是未来发展的趋势，虽然现在还比较新，但是\\n\\n我还是建议大家学习 Tensorflow2 为主。Tensorflow1 和 Tensorflow2 作为两个大的版本，',\n",
       " '它们之间肯定会有很多不同之处，下面我选取两个我觉得最大的变化来给大家进行说明。\\n\\n5.1.2 静态图和动态图机制 Eager Execution\\n\\nTensorflow1 版本跟很多其他的“老”深度学习框架一样，都是使用静态图机制，而\\n\\nTensorflow2 版本跟 Pytorch 一样都是使用现在最新潮的动态图机制。什么是动态图机制我\\n\\n146\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n觉得基本上不需要跟大家解释，动态图机制是一种跟我们平时写 Python 代码类似的一种机制，\\n\\n用起来很自然。比如代码 5-1 为 Tensorflow2 的程序。\\n\\n代码 5-1：动态图',\n",
       " '用起来很自然。比如代码 5-1 为 Tensorflow2 的程序。\\n\\n代码 5-1：动态图\\n\\nimport tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把 m1 和 m2 传入 product = tf.matmul(m1,m2) # 打印结果 print(product) 结果输出为： tf.Tensor([[20]], shape=(1, 1), dtype=int32)\\n\\n动态图程序看起来就跟一段普通的 Python 程序一样，没什么好特别说明的。不过静态图\\n\\n就没这么好理解了，因为静态图跟我们平时的编程习惯不符。在静态图机制中我们需要在一个\\n\\n计算图（Graph）中定义计算的流程，然后再创建一个会话（Session），在会话中执行计算图\\n\\n的计算。比如代码 5-2 为 Tensorflow1 的程序。\\n\\n代码 5-2：静态图（片段 1）',\n",
       " '代码 5-2：静态图（片段 1）\\n\\n# 这个程序我是在 Tensorflow1 的环境中运行的 import tensorflow as tf # 创建一个常量 m1 = tf.constant([[4,4]]) # 创建一个常量 m2 = tf.constant([[2],[3]]) # 创建一个矩阵乘法，把 m1 和 m2 传入 product = tf.matmul(m1,m2) # Tensorflow1 的程序跟一般的 python 程序不太一样 # 这个时候打印 product，只能看到 product 的属性，不能计算它的值 # 应该这里我只定义了计算图，图必须在会话中运行，我们还没有定义会话 print(product) 结果输出为： Tensor(\"MatMul:0\", shape=(1, 1), dtype=int32)\\n\\n147\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 5-2：静态图（片段 2）',\n",
       " '代码 5-2：静态图（片段 2）\\n\\n# 定义一个会话 sess = tf.Session() # 调用 sess 的 run 方法来执行矩阵乘法 # 计算 product，最终计算的结果存放在 result 中 result = sess.run(product) print(result) # 关闭会话 sess.close() 结果输出为： [[20]]\\n\\n对比动态图和静态图这两个简单的程序我们就能看出还是动态图使用起来比较简单，也更\\n\\n加自然。这也是深度学习框架未来的发展趋势，以后静态图机制应该会被慢慢淘汰。\\n\\n5.1.3 tf.keras\\n\\n在说 tf.keras 之前我们先来说一下 Keras，Keras 是所有深度学习框架中最容易使用，最\\n\\n初是由 Google AI 研究人员 Francois Chollet 创建并开发的。Francois 于 2015 年 3 月\\n\\n27 日将 Keras 的第一个版本发布在他的 GitHub。Keras 是一个高度封装的深度学习框架，',\n",
       " '它的后端可以是 Theano，Tensorflow 或者 CNTK。很快，Keras 的易用性得到了广大深度学\\n\\n习研究开发者的认可，并引起了 Tensorflow 官方的注意。并从 Tensorflow1.10 版本开始加\\n\\n入 tf.keras 接口，也就是我们在 Tensorflow 中也可以使用 Keras 的方式来搭建和训练模型。\\n\\n不过 Keras 和 tf.keras 是分开的两个项目，它们使用起来基本上是一样的，只是在细节上\\n\\n会有一些小的不同。随着 Tensorflow2.0 的推出，谷歌宣布 Keras 现在是 Tensorflow 的官方\\n\\n高级 API，用于快速简单的模型设计和训练，并推荐大家使用。随着 Keras2.3.0 的发布，\\n\\nFrancois 也发表声明推荐深度学习从业人员都应该将代码转成 Tensorflow2.0 和 tf.keras，而\\n\\n不是继续使用 Keras。\\n\\n148\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n149',\n",
       " '148\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n149\\n\\n在 Tensorflow1.0 中 如何完成 我 们 的深 度学 习模 型训练程 序 我 们 有非 常 多 选择，\\n\\nTensorflow2.0 把选择进行了简化，只保留了更好的几种。基于 Tensorflow 官方推荐以及我\\n\\n个人的使用经验，我认为在 Tensorflow2.0 的使用中，我们可以尽量多使用 tf.keras 的接口来\\n\\n完成我们的应用。\\n\\n前面我介绍了很多关于 Keras/tf.keras 的优点，Keras/tf.keras 的缺点是程序运行效率会\\n\\n比纯 Tensorflow 程序要稍微慢一点点。这和容易理解，程序封装越多，用起来越方便，运行\\n\\n起来自然就会慢一些。不过 Tensorflow 针对这个问题也做了很多优化，所以实际应用中其实\\n\\n纯 Tensorflow 和 tf.keras 速度的差距一般也不会很大。真正影响深度学习运行速度的主要影\\n\\n响因素是模型的复杂度和硬件条件，tf.keras 对于速度基本上影响不会很大。',\n",
       " '响因素是模型的复杂度和硬件条件，tf.keras 对于速度基本上影响不会很大。\\n\\n5.2 Tensorflow-cpu 安装\\n\\nhttps://tensorflow.google.cn/install/pip 官方 网 址可 以看到 关 于 使 用 pip 安装\\n\\nTensorflow 比较详细的说明。\\n\\n5.2.1 Tensorflow-cpu 在线安装\\n\\n使用 Windows 安装 Tensorflow 的同学要注意，从 Tensor F low 2.1.0 版本开始，需要\\n\\n安装\\n\\nvc_redist.x64.exe ， 进入链接\\n\\nhttps://support.microsoft.com/en-\\n\\nus/help/2977003/the-latest-supported-visual-c-downloads。下载 Visual Studio 2015，\\n\\n2017\\n\\nand\\n\\n2019 下 面 的 x64:vc_redist.x64.exe （或直 接 从',\n",
       " 'and\\n\\n2019 下 面 的 x64:vc_redist.x64.exe （或直 接 从\\n\\nhttps://aka.ms/vs/16/release/vc_redist.x64.exe 链接下载，下载后双击进行安装。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 在 Winodws/MacOS/Linux 环境下安装方式基本上都是一样的，首先先来\\n\\n介绍 CPU 版本的安装。安装 Tensorflow 之前，先要安装 Python 环境，Python 的安装在本\\n\\n书第二章节已经介绍过了，大家先要把 Anaconda 给安装好，如使用 Windows 系统，则需\\n\\n要安装 Python3.5/3.6/3.7 版本的 64 位的 Anaconda。如果大家跟着书中的步骤进行安装的\\n\\n话，先把安装流程全部看完再动手，不然可能会操作错误。Python 安装模块的方式都可以用\\n\\npip install 的命令进行安装。Tensorflow2.0 正式发布以后，现在 Tesnorflow 默认安装的版',\n",
       " '本就是 Tensorflow2 的版本，安装 Tensorflow 可以用管理员方式打开命令提示符，运行如下\\n\\n命令：\\n\\npip install tensorflow-cpu\\n\\n不过上面命令通常下载速度比较慢，推荐从国内源进行下载速度比较快，使用下面命令下\\n\\n载速度比较快：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\ni https://pypi.douban.com/simple 是国内下载源，安装其他 python 模型也可以使用\\n\\n该下载源。\\n\\n执行完之后会自动从网上下载 tensorflow 安装包并安装，安装 tensorflow 的同时也会\\n\\n安装和更新一些其他的 python 包。\\n\\n顺利的话就运行完这段命令 tensorflow 就安装好了，安装好之后我们可以在命令行安装\\n\\n的最后看到类似如下信息：\\n\\nSuccessfully installed absl-py-0.8.1 cachetools-3.1.1 certifi-2019.11.28 gast-0.2.2',\n",
       " 'google-auth-1.9.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 oauthlib-3.1.0\\n\\npyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0\\n\\ntensorboard-2.0.2 tensorflow-2.0.0 urllib3-1.25.7\\n\\n150\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n不过一般来说都不会这么顺利，关于可能会出现的问题以及如何解决问题后面会总结。\\n\\n假设安装没有问题，那么可以打开一个 python 的运行环境，比如 Jupyter，然后运行命\\n\\n令：\\n\\nimport tensorflow\\n\\n如果没有产生错误，那么就代表安装成功了。如果看到警告不要紧张，有警告是正常的，\\n\\n一般警告都可以忽略掉，如图 5.2 所示表示安装成功。\\n\\n图 5.2 Tensorflow 安装成功\\n\\n5.2.2 安装过程中可能遇到的问题汇总',\n",
       " \"图 5.2 Tensorflow 安装成功\\n\\n5.2.2 安装过程中可能遇到的问题汇总\\n\\n由于 Tensorflow 会不断地更新，每个 Tensorflow 版本我们可能会遇到的问题不同，每\\n\\n个人的电脑环境也有所不同，所以我这里总结的问题不一定跟大家碰到的问题相同，也可能会\\n\\n有缺漏，如果问题不同或者有缺漏，大家可以给我反馈，我再进行补充。\\n\\n问 题 1 ： 在安装 过程中出现“\\n\\nERROR: tensorboard 2.0.2 has requirement\\n\\ngrpcio>=1.24.3, but you'll have grpcio 1.14.1 which is incompatible.\\n\\nERROR: keras 2.2.2 has requirement keras-applications==1.0.4, but you'll have\\n\\nkeras-applications 1.0.8 which is incompatible.”或者类似错误。\\n\\n解决方法：这类错误可以忽略不处理。\\n\\n151\",\n",
       " \"解决方法：这类错误可以忽略不处理。\\n\\n151\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n问题 2：在安装过程中出现“ERROR: Cannot uninstall 'wrapt'. It is a distutils installed\\n\\nproject and thus we cannot accurately determine which files belong to it which would\\n\\nlead to only a partial uninstall.”。\\n\\n解决方法：用管理员方式打开命令提示符，然后运行：\\n\\npip install wrapt --upgrade --ignore-installed\\n\\n然后再次运行：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n如果出错的不是'wrapt'而是其他模块，类似的错误可以用类似的方法解决。\",\n",
       " \"如果出错的不是'wrapt'而是其他模块，类似的错误可以用类似的方法解决。\\n\\n问 题 3 ： 在安装 过程中出现“ distributed 1.21.8 requires msgpack,which is not\\n\\ninstalled.”类似错误。\\n\\n解决方法：安装“msgpack“，打开命令提示符，然后运行：\\n\\npip install msgpack -i https://pypi.douban.com/simple\\n\\n问题 4：某条命令在安装过程中出现“PermissionError：[WinError 5] 拒绝访问”。\\n\\n解决方法：这个错误主要是权限问题，关闭所有 python 相关软件，重新用管理员方式打\\n\\n开命令提示符，然后再次运行该命令。\\n\\n问题 5：在安装过程中模块下载中断并出现“ReadTimeoutError:HTTPSConnectionPoll”。\\n\\n解决方法：由于下载的资源在国外，所以网速不好可能会导致下载连接超时，可以尝试重\\n\\n新运行命令再次下载安装。也可以使用国内的下载源进行安装，一般速度会比较快，运行下面\\n\\n的命令使用国内的源进行安装：\",\n",
       " '的命令使用国内的源进行安装：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n问题 6：在安装过程中模块下载中断并出现“拒绝访问”。\\n\\n152\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n153\\n\\n解决方法：系统权限问题，可以用管理员方式打开命令提示符，然后重新安装，或者是在\\n\\n安装命令后面加上“--user”，例如：\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple --user\\n\\n问题 7：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n\\n“\\n\\nImportError:cannot\\n\\nimport\\n\\nname\\n\\n‘dense_features’from\\n\\n‘tensorflow.python.feature_column’”。\\n\\n解决方法：用管理员的方式打开命令提示符，先运行：',\n",
       " \"解决方法：用管理员的方式打开命令提示符，先运行：\\n\\npip uninstall tensorflow_estimator\\n\\n再运行\\n\\npip install tensorflow_estimator\\n\\n问题 8：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现\\n\\n“ImportError: DLL load failed with error code -1073741795 和 ImportError: No\\n\\nmodule named '_pywrap_tensorflow_internal'”。\\n\\n解决方法：由于电脑 CPU 太老导致的错误，解决方法一是安装老版本的 Tensorflow，比\\n\\n如 Tensorflow1.2.0 版本，但是不推荐。推荐的解决方法是换一台新一点的电脑。\\n\\n问题 9：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现：\",\n",
       " 'ERROR:root:Internal Python error in the inspect module.Below is the traceback from\\n\\nthis internal error.\\n\\n解决方法：安装 vc_redist.x64.exe，具体查看 5.2.1 中说明。然后再重新安装 Tensorflow。\\n\\n问题 10：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现“No\\n\\nmodule named ‘tensorflow’”，说明 Tensorflow 还没有安装好。\\n\\n解决方法：打开命令提示符，重新安装：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\npip install tensorflow-cpu -i https://pypi.douban.com/simple\\n\\n问题 11：Tensorflow 安装成功后在 python 环境中运行 import tensorflow 后出现',\n",
       " '“ImportError：DLL load failed：找不到指定的模型”。\\n\\n解决方法：安装 vc_redist.x64.exe，具体查看 5.2.1 中说明。然后再重新安装 Tensorflow。\\n\\n5.2.3 Tensorflow-cpu 卸载\\n\\n如果已经安装好了 Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\n\\npip uninstall tensorflow-cpu\\n\\n5.2.4 Tensorflow-cpu 更新\\n\\n如果已经安装过 Tensorlfow，现在想把 Tensorflow 更新到最新版本，可以用管理员方式\\n\\n打开命令行，执行命令：\\n\\npip install tensorflow-cpu –upgrade\\n\\n5.2.5 Tensorflow-cpu 指定版本的安装\\n\\n如果我们想安装 Tensorflow 指定版本，比如老一点的版本，可以使用指定版本的安装方\\n\\n式，比如我们想安装 Tensorflow1.13.2 版本的话，可以用管理员方式打开命令行，执行命令：\\n\\npip install tensorflow==1.13.2\\n\\n154',\n",
       " 'pip install tensorflow==1.13.2\\n\\n154\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.3 Tensorflow-gpu 安装\\n\\n5.3.1 Tensorflow-gpu 了解最新版本情况\\n\\n先在\\n\\nTensorflow 官网查看\\n\\nTensorflow-gpu 最 新的安装 情况\\n\\n（https://tensorflow.google.cn/install/gpu），如图 5.3 所示。\\n\\n图 5.3 tensorflow-gpu 版本最新情况\\n\\n一般来说比较新的英伟达(NVIDIA)的 GPU 都可以支持。这里要注意的是 CUDA 的版本\\n\\n和 cuDNN 的版本。比如我们在图 5.3 中看到的 Tensorflow-gpu 版本需要安装 CUDA10.1\\n\\n的版本，cuDNN 的版本要求 7.6 以上。如果 Tensorflow 出了更新的版本，对应的 CUDA\\n\\n和 cuDNN 的版本可能也会发生变化。\\n\\n5.3.2 Tensorflow-gpu 安装 CUDA',\n",
       " '5.3.2 Tensorflow-gpu 安装 CUDA\\n\\nCUDA（Compute Unified Device Architecture）是英伟达 NVIDIA 推出的运算平台，\\n\\n是一种通用的并行计算机构，可以使得 GPU 能够解决复杂的计算问题。CUDA 的下载的地址\\n\\n为：https://developer.nvidia.com/cuda-toolkit-archive，如图 5.4 所示。\\n\\n155\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.4 不同版本 CUDA 下载\\n\\n比如我们想下载 CUDA10.1，可以点击 CUDA Tool k it10.1。如果点击右侧的 Online\\n\\nDocumentation 可以查看关于 CUDA 安装的一些说明。图 5.5 为 CUDA10.1 对于\\n\\nWindows 环境的一些要求。\\n\\n图 5.5 CUDA10.1 对 Windows 环境要求\\n\\n图中我们可以看到 CUDA10.1 要求的 Windows 系统在 Table1 中，比较常用的系统都可',\n",
       " '以满足。另外在 Table2 中我们看到安装 CUDA10.1 之前我们还需要安装 Visual Studio，推\\n\\n荐安装 Visual Studio15 或 Visual Studio17 版本。\\n\\n图 5.6 为 CUDA10.1 对于 Linux 环境的一些要求。\\n\\n156\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.6 CUDA10.1 对 Linux 环境要求\\n\\n准备好 CUDA10.1 要求的环境以后看我们进入 CUDA 下载界面，并根据情况做好选择，\\n\\n最后点击 Downdload，如图 5.7 所示。\\n\\n图 5.7 下载 CUDA\\n\\n安装很简单，跟普通软件一样，一直下一步就可以。\\n\\n157\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.3.3 Tensorflow-gpu 安装 cuDNN 库\\n\\ncuDNN 的全称为 NVIDIA CUDA® Deep Neural Network library，是 NVIDIA 专门针',\n",
       " '对深度神经网络（Deep Neural Networks）中的基础操作而设计基于 GPU 的加速库。cuDNN\\n\\n为深度神经网络中的标准流程提供了高度优化的实现方式，例如 convolution、pooling、\\n\\nnormalization 以及 activation layers 的前向以及后向过程。\\n\\ncuDNN 的下载地址为：https://developer.nvidia.com/cudnn。下载之前需要注册。\\n\\nTensorflow 的 GPU 版本对 cuDNN 的版本是有严格要求的，前面我们看到目前\\n\\nTensorflow2 支持的是 cuDNN7.6 以上版本。\\n\\n进入下载地址后，选择对应 CUDA10.1 版本和对应操作系统的 cuDNN 进行下载，如图\\n\\n5.8 所示。\\n\\n图 5.8 下载 cuDNN\\n\\n下载好了之后可以得到一个压缩包，解压完之后可以看到三个文件夹，我们要做的就是\\n\\n把这三个文件夹中的内容拷贝到 CUDA 安装目录下面所对应的三个文件夹中，如图 5.9（这',\n",
       " '把这三个文件夹中的内容拷贝到 CUDA 安装目录下面所对应的三个文件夹中，如图 5.9（这\\n\\n是我之前配置 CUDA9.0 和对应 cuDNN 时的图，其他版本的 CUDA 和 cuDNN 也一样）所\\n\\n示。\\n\\n158\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.9 配置 cuDNN\\n\\n5.3.4 Tensorflow-gpu 在线安装\\n\\n安装方式跟 CPU 版本差不多，用管理员方式打开命令提示符，执行命令：\\n\\npip install tensorflow-gpu -i https://pypi.douban.com/simple\\n\\n5.3.5 Tensorflow-gpu 卸载\\n\\n如果已经安装好了 Tensorflow，想要卸载，可以用管理员方式打开命令行，执行命令：\\n\\npip uninstall tensorflow-gpu\\n\\n5.3.6 Tensorflow-gpu 更新\\n\\n如果已经安装过 Tensorlfow，现在想把 Tensorflow 更新到最新版本，可以用管理员方式\\n\\n打开命令行，执行命令：',\n",
       " '打开命令行，执行命令：\\n\\npip install tensorflow-gpu –upgrade\\n\\n159\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.4 Tensorflow 基本概念\\n\\nTensorflow 中的一些基本概念在 Tensorflow2 版本中已经被隐藏起来，或者已经不再使\\n\\n用了，不过我还是打算给大家简单介绍一些 Tensorflow 的基本概念，虽然之后可能不会用到。\\n\\nTensorflow 是一个编程系统，使用图(graphs)来表示计算任务，图(graphs)中的节点称\\n\\n之为 op(operation)，一个 op 获得 0 个或多个 Tensor，执行计算，产生 0 个或多个 Tensor，\\n\\nTensor 看作是一个 n 维的数据。Tensorflow1 中图必须在会话（Session）中运行，如图 5.10\\n\\n所示。\\n\\n图 5.10 会话 Session\\n\\n图中的 Tensor 表示数据，一般可以用在数据的输入，输出，以及计算的中间流程。Variable',\n",
       " '表示变量，一般用于记录一些需要变化的数值，比如需要训练的模型参数。虽然可以使用\\n\\nTensor 的地方都可以使用 Variable，不过它们还是有一些区别。\\n\\n图中的 Graph 表示一个完整的计算任务，最上面的 Tensor0 和 Variable0 一起传入一个\\n\\noperation0 里面，这个 operation0 可以是加法，减法，乘法，除法等运算。运算完了之后产\\n\\n160\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n生了一个 Tensor1，这个 Tensor1 跟 Tensor2 一起被送入了 operation1，在 operation1 中\\n\\n进行计算。\\n\\n再举一个更具体的例子，如图 5.11 所示。\\n\\n图 5.11 神经网络计算图\\n\\n图中的 x 是一个 Tensor，表示数据的输入，图中的 W 和 b 是 Variable，表示模型需要\\n\\n训练的参数。W 和 x 共同传入了 MatMul 的 operation 中，进行矩阵乘法的操作，计算完',\n",
       " '后得到的 Tensor0 会传入到 Add(operation)中，跟变量 b 一起进行加法操作，得到\\n\\nTensor1。Tensor1 传入 ReLU(operation)激活函数进行计算，然后得到 Tensor2 再继续传\\n\\n递信号，最终得到 Tensor3。\\n\\n在前面的内容中我们已经介绍过，在 Tensorflow2 中使用的是动态图机制，也就是说我\\n\\n们不再需要会话，我们可以在任意时候进行计算并得到结果，程序设计起来会更加方便，更\\n\\n加自然。\\n\\n161\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.5 Tensorflow 基础使用\\n\\n1．TF1 转 TF2 工具\\n\\nTensorflow2 安装好之后，会自带一个工具可以把 Tensorflow1 的程序转成 Tensorflow2\\n\\n的程序，使用方法是打开命令提示符，然后执行：\\n\\ntf_upgrade_v2 --infile input.py --outfile output.py',\n",
       " 'tf_upgrade_v2 为转化工具，input.py 为 Tensorflow1 的程序路径，output.py 为新产\\n\\n生的 Tensorflow2 的程序保存路径。\\n\\n这个工具的转换效果不能算很好，并不是所有的 Tensorflow1 的程序都可以使用这个工\\n\\n具转变为 Tensorflow2 的程序。一些比较复杂的 Tensorflow1 的程序还是需要进行比较多的\\n\\n改写才能转成 Tensorflow2 的程序。所以大家需要把 Tensorflow1 转成 Tensorflow2 的时候\\n\\n可以尝试使用，如果发现不行的话可以再自行修改。\\n\\n2. Tensorflow 基本操作\\n\\nTensorflow 基本操作的代码如代码 5-3 所示。\\n\\n代码 5-3：Tensorflow 基本操作',\n",
       " '代码 5-3：Tensorflow 基本操作\\n\\nimport tensorflow as tf # 定义一个变量 x = tf.Variable([1,2]) # 定义一个常量 a = tf.constant([3,3]) # 减法 op sub = tf.subtract(x, a) # 加法 op add = tf.add(x,sub) print(sub) print(add)\\n\\n162\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 结果输出为： tf.Tensor([-2 -1], shape=(2,), dtype=int32)\\n\\ntf.Tensor([-1 1], shape=(2,), dtype=int32)\\n\\n3. 拟合线性函数\\n\\n拟合线性函数的代码如代码 5-4 所示。\\n\\n代码 5-4：拟合线性函数（片段 1）',\n",
       " '拟合线性函数的代码如代码 5-4 所示。\\n\\n代码 5-4：拟合线性函数（片段 1）\\n\\nimport tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用 numpy 生成 100 个从 0-1 的随机点，作为 x x_data = np.random.rand(100) # 生成一些随机扰动 noise = np.random.normal(0,0.01,x_data.shape) # 构建目标值，符合线性分布 y_data = x_data*0.1 + 0.2 + noise # 画散点图 plt.scatter(x_data, y_data) plt.show() 结果输出为：\\n\\n代码 5-4：拟合线性函数（片段 2）',\n",
       " \"代码 5-4：拟合线性函数（片段 2）\\n\\n# 构建一个顺序模型 # 顺序模型为 keras 中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # Dense 为全连接层\\n\\n163\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 在模型中添加一个全连接层 # units 为输出神经元个数，input_dim 为输入神经元个数 model.add(tf.keras.layers.Dense(units=1,input_dim=1)) # 设置模型的优化器和代价函数，学习率为 0.03 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.03),loss='mse')\",\n",
       " \"# 训练 2001 个批次 for step in range(2001): # 训练一个批次数据，返回 cost 值 cost = model.train_on_batch(x_data,y_data) # 每 500 个 batch 打印一次 cost 值 if step % 500 == 0: print('cost:',cost)\\n\\n# 使用 predict 对数据进行预测，得到预测值 y_pred y_pred = model.predict(x_data)\\n\\n# 显示随机点 plt.scatter(x_data,y_data) # 显示预测结果 plt.plot(x_data,y_pred,'r-',lw=3) plt.show() 结果输出为： cost: 0.33022374 cost: 0.0003510235 cost: 9.941429e-05 cost: 9.440048e-05 cost: 9.430057e-05\\n\\n164\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.拟合非线性函数\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.拟合非线性函数\\n\\n拟合非线性函数的代码如代码 5-5 所示。\\n\\n代码 5-5：拟合非线性函数（片段 1）\\n\\nimport tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.optimizers import SGD # 使用 numpy 生成 200 个均匀分布的点，并新增一个维度 x_data = np.linspace(-0.5,0.5,200)[:,np.newaxis] # 生成一些跟 x_data 相同 shape 的随机值作为噪声数据 noise = np.random.normal(0,0.02,x_data.shape) # 构建目标值，符合非线性函数，另外再加上噪声值 y_data = np.square(x_data) + noise # 画散点图 plt.scatter(x_data,y_data) plt.show() 结果输出为：',\n",
       " \"代码 5-5：拟合非线性函数（片段 2）\\n\\n# 构建一个顺序模型 # 顺序模型为 keras 中的基本模型结构，就像汉堡一样一层一层叠加网络 model = tf.keras.Sequential() # 因为要做非线性回归，所以需要一个带有隐藏层的神经网络 # 并且需要使用非线性的激活函数，比如 tanh 函数 # keras 中 input_dim 只需要在输入层设置，后面的网络可以自动推断出该层对应的输入 # keras 中定义网络结构已经默认设置好权值初始化，所以我们不需要额外进行设置 model.add(tf.keras.layers.Dense(units=10,input_dim=1,activation='tanh')) model.add(tf.keras.layers.Dense(units=1,activation='tanh'))\\n\\n165\",\n",
       " \"165\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 设置模型的优化器和代价函数，学习率为 0.1 # sgd:Stochastic gradient descent，随机梯度下降法 # mse:Mean Squared Error，均方误差 model.compile(optimizer=SGD(0.3),loss='mse')\",\n",
       " '# 训练 3001 个批次 for step in range(3001): # 训练一个批次数据，返回 cost 值 cost = model.train_on_batch(x_data,y_data) # 每 1000 个 batch 打印一次 cost 值 if step % 1000 == 0: # 定义一个 2*2 的图，当前是第 i/1000+1 个图 plt.subplot(2,2,step/1000+1) # 把 x_data 喂到模型中获得预测值 prediction_value = model.predict(x_data) # 画散点图 plt.scatter(x_data,y_data) # 画模型预测曲线图 plt.plot(x_data,prediction_value,\\'r-\\',lw=5) # 不显示坐标 plt.axis(\\'off\\') # 图片的标题设置 plt.title(\"picture:\" + str(int(step/1000+1))) plt.show() 结果输出为：',\n",
       " '从结果中我们能看得出，随着权值的调整，模型的预测结果也在不断地调整，最终得到比\\n\\n较好的拟合效果。\\n\\n166\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.6 手写数字图片分类任务\\n\\n5.6.1 MNIST 数据集介绍\\n\\nMNIST 是一个手写数字的数据集。其中训练集有 60000 张图片，测试集有 10000 张图\\n\\n片，每一张图片包含 28*28 个像素。数据集的下载网址为：\\n\\nhttp://yann.lecun.com/exdb/mnist/。MNIST 数据集的图片如图 5.12\\n\\n图 5.12 MNIST 数据集\\n\\nMNIST 数据集的标签是介于 0-9 的数字，有时候我们要把标签转化为独热编码(one-hot\\n\\nvectors)，然后再传给模型进行训练。\\n\\n5.6.2 Softmax 函数介绍\\n\\n在多分类问题中，我们通常会使用 softmax 函数作为网络输出层的激活函数，softmax\\n\\n函数可以对输出值进行归一化操作，把所有输出值都转化为概率，所有概率值加起来等于\\n\\n1，softmax 的公式为：\\n\\n167',\n",
       " '1，softmax 的公式为：\\n\\n167\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑥)( =\\n\\nexp\\t(𝑥() ∑ exp\\t(𝑥(cid:129))\\n\\n(cid:129)\\n\\n例如某个神经网络有 3 个输出值，为[1,5,3]。\\n\\n计算𝑒\" = 2.718，𝑒(cid:176) = 148.413，𝑒$ = 20.086，𝑒\" + 𝑒(cid:176) + 𝑒$ = 171.217。\\n\\n𝑝1 =\\n\\n⁄–\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.016，𝑝2 =\\n\\n⁄†\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.867，𝑝3 =\\n\\n⁄‡\\n\\n⁄–(cid:151)⁄†(cid:151)⁄‡ = 0.117。\\n\\n所以加上 softmax 函数后数值变成了[0.016,0.867,0.117]。\\n\\n例如手写数字识别的网络最后的输出结果本来是[-0.124,-4.083,-0.62,0.899,-1.193,-0.70',\n",
       " '1,-2.834,6.925,-0.332,2.064]，加上 softmax 函数后会变成[0.001,0.0,0.001,0.002,0.0,0.0,\\n\\n0.0,0.987,0.001,0.008]。\\n\\n5.6.3 简单 MNIST 数据集分类模型-没有高级封装\\n\\n我们可以考虑先构建一个简单的神经网络，这个网络只有输入层和输出层，输入层有 784\\n\\n个神经元，对应每张图片的 784 个像素点，输出层有 10 个神经元，对应 one-hot 的标签值，\\n\\n如图 5.13：\\n\\n168\\n\\n(5.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 5.13 简单 MNIST 数据集分类模型\\n\\n大家刚开始学习 tensorflow，所以没有使用 tf.keras 高级封装的代码我也会准备一些给\\n\\n大家学习，代码 5-6 没有使用 tf.keras 来封装模型数据载入和模型训练的过程。\\n\\n代码 5-6：MNIST 数据集分类模型-没有高级封装',\n",
       " 'import tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test =',\n",
       " 'y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象，使用 dataset 对象来管理数据 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期设置为 1（把所有训练集数据训练一次称为训练一个周期） mnist_train = mnist_train.repeat(1) # 批次大小设置为 32（每次训练模型传入 32 个数据进行训练） mnist_train = mnist_train.batch(32)',\n",
       " \"# 创建 dataset 对象，使用 dataset 对象来管理数据 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期设置为 1（把所有训练集数据训练一次称为训练一个周期） mnist_test = mnist_test.repeat(1) # 批次大小设置为 32（每次训练模型传入 32 个数据进行训练） mnist_test = mnist_test.batch(32)\\n\\n# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n169\",\n",
       " \"169\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 计算平均值 train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 计算平均值 test_loss = tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\",\n",
       " '# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 # 定义一个训练模型的函数 @tf.function def train_step(data, label): # 固定写法，使用 tf.GradientTape()来计算梯度 with tf.GradientTape() as tape: # 传入数据获得模型预测结果 predictions = model(data) # 对比 label 和 predictions 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 传入 loss 和模型参数，计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # 计算平均 loss train_loss(loss)',\n",
       " '# 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)',\n",
       " '# 我们可以用@tf.function 装饰器来将 python 代码转成 tensorflow 的图表示代码，用于加速 代码运行速度 # 定义一个模型测试的函数 @tf.function def test_step(data, label): # 传入数据获得模型预测结果 predictions = model(data) # 对比 label 和 predictions 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)\\n\\n170\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 训练 10 个周期（把所有训练集数据训练一次称为训练一个周期） EPOCHS = 10',\n",
       " '# 训练 10 个周期（把所有训练集数据训练一次称为训练一个周期） EPOCHS = 10\\n\\nfor epoch in range(EPOCHS): # 训练集循环 60000/32=1875 次 for image, label in mnist_train: # 每次循环传入一个批次的数据和标签训练模型 train_step(image, label) # 测试集循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 每次循环传入一个批次的数据和标签进行测试 test_step(test_image, test_label)',\n",
       " \"# 打印结果 template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}' print(template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result())) 结果输出为： Epoch 1, Loss: 0.017, Accuracy: 0.892, Test Loss: 0.0138, Test Accura cy: 0.909 Epoch 2, Loss: 0.015, Accuracy: 0.905, Test Loss: 0.0134, Test Accura cy: 0.911 Epoch 3, Loss: 0.014, Accuracy: 0.911, Test Loss: 0.0131, Test Accura cy: 0.913 Epoch 4, Loss: 0.0134,\",\n",
       " 'Test Accura cy: 0.913 Epoch 4, Loss: 0.0134, Accuracy: 0.914, Test Loss: 0.0129, Test Accur acy: 0.915 Epoch 5, Loss: 0.013, Accuracy: 0.917, Test Loss: 0.0127, Test Accura cy: 0.916 Epoch 6, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0126, Test Accur acy: 0.917 Epoch 7, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0125, Test Accur acy: 0.918 Epoch 8, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0124, Test Accur acy: 0.919 Epoch 9, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur',\n",
       " 'Accuracy: 0.923, Test Loss: 0.0123, Test Accur acy: 0.919 Epoch 10, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122,Test Accur acy: 0.92',\n",
       " '171\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n5.6.4 简单 MNIST 数据集分类模型-keras 高级封装\\n\\n给大家介绍了没有使用高级封装的程序以后，下面要给大家介绍一下使用 tf.keras 高级封\\n\\n装的 MNIST 数据集分类程序，如代码 5-7 所示。\\n\\n代码 5-7：MNIST 数据集分类模型-keras 高级封装',\n",
       " 'import tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test =',\n",
       " 'y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.1) model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 10（把所有训练集数据训练一次称为训练一个周期） # 批次大小为 32（每次训练模型传入 32 个数据进行训练）\\n\\n172\",\n",
       " '172\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # validation_data 设置验证集数据 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n\\n程序的输出结果为：',\n",
       " 'Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0374 - accuracy: 0.7822 - val_loss: 0.0214 - val_accuracy: 0.880 2 Epoch 2/10 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0203 - accuracy: 0.8816 - val_loss: 0.0175 - val_accuracy: 0.897 8 Epoch 3/10 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0177 - accuracy: 0.8932 - val_loss: 0.0160 - val_accuracy:',\n",
       " '0.8932 - val_loss: 0.0160 - val_accuracy: 0.904 1 Epoch 4/10 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0165 - accuracy: 0.8994 - val_loss: 0.0151 - val_accuracy: 0.907 0 Epoch 5/10 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0157 - accuracy: 0.9031 - val_loss: 0.0145 - val_accuracy: 0.910 7 Epoch 6/10 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0151 - accuracy: 0.9063 - val_loss: 0.0140 - val_accuracy:',\n",
       " '0.9063 - val_loss: 0.0140 - val_accuracy: 0.913 1 Epoch 7/10 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0147 - accuracy: 0.9090 - val_loss: 0.0137 - val_accuracy: 0.914 5 Epoch 8/10 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0143 - accuracy: 0.9112 - val_loss: 0.0134 - val_accuracy: 0.915 8 Epoch 9/10 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0140 - accuracy: 0.9122 - val_loss: 0.0132 - val_accuracy:',\n",
       " '0.9122 - val_loss: 0.0132 - val_accuracy: 0.917 6 Epoch 10/10',\n",
       " '173\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 2s 36us/sample - los s: 0.0138 - accuracy: 0.9137 - val_loss: 0.0131 - val_accuracy: 0.918 4\\n\\n对比看来，使用了 tf.keras 高级封装的程序更简洁，同时也更容易理解，并且程序运行时\\n\\n的结果输出也更友好。我们在程序运行时可以实时看到模型训练一共要训练多少个周期，当前\\n\\n训练到第几个周期，当前周期的进度条，训练当前周期的剩余时间，当前训练集的准确率和 loss。\\n\\n训练完一个周期之后可以看到训练一个周期所花费的时间，如果设置了验证集，可以看到验证\\n\\n集的准确率和 loss。这些信息都是默认输出的，当然我们也可以把 fit 方法中的参数 verbose 设\\n\\n置为 0，让模型训练过程中不输出任何信息。不过推荐大家还是保持默认值 berbose=1，毕竟\\n\\n看到这些输出信息更有利于我们了解模型的训练情况。',\n",
       " '看到这些输出信息更有利于我们了解模型的训练情况。\\n\\n最后模型的测试集准确率大约是 92%左右，并不是特别高。\\n\\n如何可以进一步提升模型的效果，我们将在下一个章节介绍。\\n\\n174\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 6 章-网络优化方法\\n\\n本章节内容我们将学习神经网络的一些优化方法，包括使用交叉熵代价函数，抵抗过拟\\n\\n合的几种方法和使用不同的模型优化器。这些模型优化方法有些可以比较有效的提升模型收\\n\\n敛速度或模型的效果，有些只是有可能提升模型的效果。所以我们在选择使用不同的网络优\\n\\n化方法的时候，还是需要根据实际的测试情况来进行选择。\\n\\n6.1 交叉熵代价函数\\n\\n我们在读高中的时候，每天都会做大量的练习，很多课后作业。但是很多题目我们做错以\\n\\n后，下次再见到这个题目的时候已经不记得了，所以会再次做错同样的题目。因为做错普通的\\n\\n课后作业练习题并不能引起我们的重视，所以印象不深刻。\\n\\n如果是老师让我们单独上讲台做题目的话，每次遇到这种情况我们都会比较紧张，因为全',\n",
       " '如果是老师让我们单独上讲台做题目的话，每次遇到这种情况我们都会比较紧张，因为全\\n\\n班同学，包括我们的暗恋对象都在看着我们。如果在这个时候，我们把题目给做错了，那就丢\\n\\n人丢大了。而被我们做错的那个题目，也会让我们格外印象深刻，下次遇到这个题目的时候就\\n\\n不容易犯错了。\\n\\n也就是说我们在犯了更大的错误以后，往往会学到更多东西，进步更快。理想的情况下，\\n\\n我们也希望神经网络可以从错误中快速学习，最好是错误越大，学习越快，因此均方差代价函\\n\\n数通常用在回归任务中，分类任务中我们会使用交叉熵（Cross Entropy）作为代价函数。\\n\\n6.1.1 均方差代价函数的缺点\\n\\n我们先来重新思考一下均方差代价函数。\\n\\n175\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n先看一个小例子，假如有一个简单的神经网络，它只有一个权值 w 和偏置 b，一个输入 x\\n\\n和一个输出 y，激活函数为 sigmoid 函数，如图 6.1 所示。\\n\\n图 6.1 单输入单输出的简单神经网络\\n\\n我们要训练这个网络做一个简单的事情，给定 x，w 和 b 的值，可以计算出网络输出值',\n",
       " '我们要训练这个网络做一个简单的事情，给定 x，w 和 b 的值，可以计算出网络输出值\\n\\ny，已知网络的目标值 t，然后用梯度下降法来优化网络的参数 w 和 b，使得网络的 loss 值\\n\\n不断减小。这里我们先把代价函数定义为之前我们学过的均方差代价函数：\\n\\n𝐸 =\\n\\n1 2𝑁\\n\\n(𝑇 − 𝑌)# =\\n\\n1 2𝑁\\n\\nP ?(𝑡( − 𝑦()# (A\"\\n\\n第一次试验，x 的值为 1，w 的初始值设置为 0.6，b 的初始值设置为 0.9，目标值 t 的\\n\\n值为 0，使用梯度下降法学习率 0.15，训练 300 周期，网络的初始参数如图 6.2 所示。\\n\\n图 6.2 试验一初始状态\\n\\n实验一训练了 300 周期后的状态如图 6.3 所示。\\n\\n176\\n\\n(6.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.3 试验一训练 300 次之后的状态\\n\\n实验一 loss 的变化如图 6.4 所示。\\n\\n图 6.4 试验一 loss 变化\\n\\n第二次试验，x 的值为 1，w 的初始值设置为 1.85，b 的初始值设置为 1.85，目标值 t',\n",
       " '的值为 0，使用梯度下降法学习率 0.15，训练 300 周期，网络的初始参数如图 6.5 所示。\\n\\n图 6.5 试验二初始状态\\n\\n试验二训练了 300 周期后的状态如图 6.6 所示。\\n\\n图 6.6 试验二训练 300 次之后的状态\\n\\n177\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n实验二 loss 的变化如图 6.7 所示。\\n\\n图 6.7 试验二 loss 变化\\n\\n观察实验一和试验二我们会发现试验结果和我们理想的结果不同，我们理想的学习效果\\n\\n应该是误差越大，学习得越快。\\n\\n从两个试验的 loss 曲线我们能看到它们不同的学习速度。实验一的初始输出为 0.82，距\\n\\n离目标值 0 的误差相对比较小，但是初始学习速度比较快。实验二的初始输出为 0.99，距离\\n\\n目标值 0 的误差相对比较大，但是初始学习速度比较慢。这个现象不仅仅是在这个小实验\\n\\n中，也会在其他的神经网络应用中出现。我们想进一步理解这个现象，就要分析一下它的代\\n\\n价函数。当 N=1 时，二次代价函数为\\n\\n𝐸 =\\n\\n1 2\\n\\n(𝑦 − 𝑡)#',\n",
       " '价函数。当 N=1 时，二次代价函数为\\n\\n𝐸 =\\n\\n1 2\\n\\n(𝑦 − 𝑡)#\\n\\n其中 E 为代价函数，t 为目标输出，y 为神经网络的输出。因为激活函数为 sigmoid 函数，\\n\\n符号为𝜎，所以𝑦 = 𝜎(𝑧)，𝑧 = 𝑤𝑥 + 𝑏。使用链式法则来求权重和偏置的偏导数可以得到：\\n\\n𝜕𝐸 𝜕𝑤 𝜕𝐸 𝜕𝑏\\n\\n= (𝑦 − 𝑡)𝜎R(𝑧)𝑥\\n\\n= (𝑦 − 𝑡)𝜎R(𝑧)\\n\\n把 x=1 以及 t=0 带入公式 6.3 和公式 6.4，可以得到：\\n\\n178\\n\\n(6.2)\\n\\n(6.3)\\n\\n(6.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝜕𝐸 𝜕𝑤 𝜕𝐸 𝜕𝑏\\n\\n= 𝑦𝜎R(𝑧)\\n\\n= 𝑦𝜎R(𝑧)\\n\\n从公式 6.5 和公式 6.6 我们可以看出，权值和偏置值的调整是跟激活函数的导数成正比\\n\\n的，我们可以回忆一下 sigmoid 函数的图像，如图 6.8 所示。\\n\\n图 6.8 sigmoid 函数图像\\n\\n从图中我们可以看出，当神经元的输出接近 1 和 0 的时候，曲线变得非常平，也就意味',\n",
       " '从图中我们可以看出，当神经元的输出接近 1 和 0 的时候，曲线变得非常平，也就意味\\n\\n着在输出接近 1 和 0 的位置函数的导数接近于 0。函数的导数接近于 0，那么公式 6.5 和 6.6\\n\\n的值就接近于 0，其实就是代表网络的参数调节的速度非常慢，网络的优化速度非常慢。\\n\\nsigmoid 函数的导数为：𝑓′(𝑥) = 𝑓(𝑥)[1 − 𝑓(𝑥)]，实验一的初始输出为 0.82，初始导数\\n\\n为 0.1476。实验二的初始输出为 0.99，初始导数为 0.0099。所以实验一中网络权值的初始\\n\\n调节速度要比实验二中网络权值的初始调节速度快。但是违反了我们误差越大，应该学习越\\n\\n快的直觉。\\n\\n6.1.2 引入交叉熵代价函数\\n\\n我们换一个思路，不改变激活函数而是改变代价函数，改用交叉熵代价函数：\\n\\n179\\n\\n(6.5)\\n\\n(6.6)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n其中 N 是训练数据的总数，y 是网络的预测值，t 是网络的目标值。',\n",
       " '其中 N 是训练数据的总数，y 是网络的预测值，t 是网络的目标值。\\n\\n首先我们先观察一下这个函数的特性：\\n\\n1. 当我们使用 sigmoid 激活函数的时候，y 的取值范围是 0-1 之间，t 的取值为\\n\\n0 或 1，所以代价函数的值是非负的。\\n\\n2. 当目标值 t=0 时，预测值 y 越接近于 0，代价函数的值 E 越小，E 的最小值为\\n\\n0；当目标值 t=0 时，预测值 y 越接近于 1，代价函数的值 E 越大，E 的最大值为+∞。\\n\\n3. 当目标值 t=1 时，预测值 y 越接近于 1，代价函数的值 E 越小，E 的最小值为\\n\\n0；当目标值 t=1 时，预测值 y 越接近于 0，代价函数的值 E 越大，E 的最大值为+∞。\\n\\n综上所述，交叉熵的值是非负的，并且网络的预测值越接近于目标值，则交叉熵的值就越\\n\\n小，这些都是我们想要的代价函数的特性。均方差代价函数其实也是具备这些特性的。\\n\\n接下来我们对交叉熵求 w 的偏导数，当 N=1 时有：\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n= − ¶\\n\\n= − ¶\\n\\n𝑡( 𝜎(𝑧)( 𝑡 𝜎(𝑧)\\n\\n−\\n\\n−',\n",
       " '= − ¶\\n\\n= − ¶\\n\\n𝑡( 𝜎(𝑧)( 𝑡 𝜎(𝑧)\\n\\n−\\n\\n−\\n\\n(1 − 𝑡() 1 − 𝜎(𝑧)( (1 − 𝑡) 1 − 𝜎(𝑧)\\n\\n\\n\\n𝜕𝜎 𝜕𝑤(cid:129)\\n\\n𝜎R(𝑧)𝑥(cid:129)\\n\\n= ¶\\n\\n𝜎R(𝑧)𝑥(cid:129) 𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n(𝜎(𝑧) − 𝑡)\\n\\nSigmoid 函数的导数为：\\n\\n𝜎R(𝑧) = \\t𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n所以：\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n= 𝑥(cid:129)(\\t𝜎(𝑧) − 𝑡)\\n\\n= 𝑥(cid:129)(\\t𝑦 − 𝑡)\\n\\n180\\n\\n(6.7)\\n\\n(6.8)\\n\\n(6.9)\\n\\n(6.10)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这是一个非常优美的公式，我们可以看出权重的学习速度是跟 y-t 成正比的。y-t 就是网\\n\\n络的误差值，误差越大，网络的学习速度越快，这正是我们想要的。sigmoid 函数与交叉熵配\\n\\n合使用可以加快网络收敛的速度。\\n\\n6.1.3 交叉熵代价函数推导过程',\n",
       " '合使用可以加快网络收敛的速度。\\n\\n6.1.3 交叉熵代价函数推导过程\\n\\n以权值 b 为例，推导交叉熵代价函数，对 E 求 b 的偏导数有：\\n\\n𝜕𝐸 𝜕𝑏\\n\\n=\\n\\n𝜕𝐸 𝜕𝑦\\n\\n\\n\\n𝜕𝑦 𝜕𝑧\\n\\n\\n\\n𝜕𝑧 𝜕𝑏\\n\\n𝜕(𝑤𝑥 + 𝑏) 𝜕𝑏\\n\\n𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦 𝜕𝐸 𝜕𝑦\\n\\n𝜎R(𝑧) ∙\\n\\n=\\n\\n𝜎R(𝑧)\\n\\n=\\n\\n𝜎(𝑧)(cid:142)1 − 𝜎(𝑧)(cid:143)\\n\\n=\\n\\n=\\n\\n𝑦(1 − 𝑦)\\n\\n我们希望 b 对 E 的导数是跟网络的误差 y-t 成正比的，因此我们可以让：\\n\\n𝜕𝐸 𝜕𝑏\\n\\n=\\n\\n𝜕𝐸 𝜕𝑦\\n\\n𝑦(1 − 𝑦) = 𝑦 − 𝑡\\n\\n即：\\n\\n𝜕𝐸 𝜕𝑦\\n\\n=\\n\\n𝑦 − 𝑡 𝑦(1 − 𝑦)\\n\\n= − l\\n\\n𝑡 𝑦\\n\\n−\\n\\n1 − 𝑡 1 − 𝑦\\n\\nm\\n\\n对等式两侧求积分，可以得到：\\n\\n𝐸 = −[𝑡𝑙𝑛𝑦 + (1 − 𝑡) ln(1 − 𝑦)]\\n\\n公式 6.14 就是前面介绍的交叉熵函数。\\n\\n181\\n\\n(6.11)\\n\\n(6.12)\\n\\n(6.13)\\n\\n(6.14)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '(6.14)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.1.4 Softmax 与对数似然代价函数\\n\\n通过前面的内容我们可以知道 sigmoid 函数配合交叉熵代价函数的使用可以加快网络训\\n\\n练速度，而在处理多分类的任务时，我们经常会使用 softmax 函数作为输出层的激活函数。\\n\\n当我们使用 softmax 作为输出层的激活函数时，与之匹配的代价为对数似然（Log Likelihood）\\n\\n代价函数。\\n\\nsoftmax 函数与对数似然代价函数的组合跟 sigmoid 函数与交叉熵代价函数的组合类似。\\n\\nsoftmax 函数与对数似然代价函数在处理二分类问题的时候可以简化为 sigmoid 函数与交叉\\n\\n熵代价函数的形式。\\n\\n对数似然代价函数的公式为：\\n\\nP 𝐸 = − ? 𝑡(𝑙𝑜𝑔 (A\"\\n\\n(𝑦()\\n\\n其中，N 表示一共有 N 个输出神经元，也可以认为是 N 个分类，𝑡(表示第 i 个输出神经元\\n\\n的目标值，𝑦(表示第 i 个输出神经元预测值，取值范围是 0-1 之间。',\n",
       " '的目标值，𝑦(表示第 i 个输出神经元预测值，取值范围是 0-1 之间。\\n\\n假设把一个样本输入到网络中，只有一个神经元对应了该样本的正确类别（样本的标签为\\n\\none-hot 格式），那么这个神经元输出的概率值越高，则公式 6.15 的代价函数的值就越小，反\\n\\n之，代价函数的值就越大。\\n\\nsoftmax 的公式为：\\n\\n𝑦( =\\n\\ne„” ∑ 𝑒 „» (cid:129)\\n\\n𝑦(表示输出层第 i 个神经元的输出，𝑧(表示输出层第 i 个神经元的输入，e 表示自然常数，\\n\\n∑ 𝑒 „»\\n\\n(cid:129) 表示输出层所有神经元的输入之和。\\n\\nsoftmax 的求导结果比较特别，需要分为两种情况：\\n\\n182\\n\\n(6.15)\\n\\n(6.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nif\\tj=i:\\n\\ne„” ∑ 𝑒 „» (cid:129) 𝜕𝑧(cid:129) e„” ∙ ∑ 𝑒 „» (cid:129) (cid:142)∑ 𝑒 „» (cid:143) (cid:129) e„” ∑ 𝑒 „» (cid:129)\\n\\n𝜕 l\\n\\nm',\n",
       " '𝜕 l\\n\\nm\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n=\\n\\n− e„” ∙ e„”\\n\\n=\\n\\n#\\n\\ne„” ∑ 𝑒 „» (cid:129) \\t\\t\\t\\t\\t\\t\\t\\t= 𝑦((1 − 𝑦()\\n\\ne„” ∑ 𝑒 „» (cid:129)\\n\\n=\\n\\n−\\n\\n\\n\\nif\\tj≠i:\\n\\ne„” ∑ 𝑒 „» (cid:129) 𝜕𝑧(cid:129) 0 ∙ ∑ 𝑒 „» (cid:129) (cid:142)∑ 𝑒 „» (cid:129) e„» ∑ 𝑒 „» (cid:129) \\t\\t= −𝑦(cid:129)𝑦(\\n\\n𝜕 l\\n\\nm\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n=\\n\\n− e„» ∙ e„” #\\n\\n=\\n\\n(cid:143) e„” ∑ 𝑒 „» (cid:129)\\n\\n= −\\n\\n\\n\\n接下来我们对对数似然代价函数求 w 的偏导数：\\n\\n183\\n\\n(6.17)\\n\\n(6.18)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n184\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n=',\n",
       " '184\\n\\n𝜕𝐸 𝜕𝑤(cid:129)\\n\\n=\\n\\n𝜕𝑧(cid:129) 𝜕𝐸 𝜕𝑧(cid:129) 𝜕𝑤(cid:129) P 𝜕(cid:142)∑ 𝑡(log\\t(𝑦() (cid:143) (A\" 𝜕𝑧(cid:129) P\\n\\n=\\n\\n\\n\\n\\n\\n𝜕(𝑤(cid:129)𝑥(cid:129) + 𝑏(cid:129)) 𝜕𝑤(cid:129)\\n\\n= −𝑥(cid:129) ? 𝑡(\\n\\n(A\"\\n\\n1 𝑦(\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n= −𝑥(cid:129) (cid:139)𝑡(cid:129)\\n\\n1 𝑦(cid:129)\\n\\n𝜕𝑦(cid:129) 𝜕𝑧(cid:129)\\n\\nP + ? 𝑡( (¿(cid:129)\\n\\n1 𝑦(\\n\\n𝜕𝑦( 𝜕𝑧(cid:129)\\n\\n(cid:140)\\n\\n(cid:142)应用𝑠𝑜𝑓𝑡𝑚𝑎𝑥的导数(cid:143)\\n\\n= −𝑥(cid:129) (cid:148)𝑡(cid:129)\\n\\n1 𝑦(cid:129)\\n\\nP\\n\\n𝑦(cid:129)(cid:142)1 − 𝑦(cid:129)(cid:143) + ? 𝑡(\\n\\n(¿(cid:129)',\n",
       " '(¿(cid:129)\\n\\n1 𝑦(\\n\\n(cid:142)−𝑦(cid:129)𝑦((cid:143)(cid:149)\\n\\nP\\n\\n= −𝑥(cid:129) (cid:139)𝑡(cid:129) − 𝑡(cid:129)𝑦(cid:129) − ? 𝑡(𝑦(cid:129)\\n\\n(cid:140)\\n\\n(¿(cid:129)\\n\\nP\\n\\n= −𝑥(cid:129) >𝑡(cid:129) − 𝑦(cid:129) ? 𝑡(\\n\\nB = 𝑥(cid:129)(cid:142)𝑦(cid:129) − 𝑡(cid:129)(cid:143)\\n\\n(6.19)\\n\\n(A\"\\n\\nP (A\" 表示所以输出的目标值累加，一般我们会把目标值转成 one-hot\\n\\n公式 6.19 最后的∑ 𝑡(\\n\\nP (A\" 的值为 1。从对数似然代价函数的梯度公式我们也能看出，网络权值\\n\\n的数据格式，所以∑ 𝑡(\\n\\n的调整是跟网络的误差相关的，误差越大则网络训练速度越快，跟交叉熵代价函数有类似的结\\n\\n果。\\n\\n6.1.5 交叉熵程序\\n\\n简单 MNIST 数据集分类模型-交叉熵的代码如代码 6-1 所示。',\n",
       " '6.1.5 交叉熵程序\\n\\n简单 MNIST 数据集分类模型-交叉熵的代码如代码 6-1 所示。\\n\\n代码 6-1：简单 MNIST 数据集分类模型-交叉熵（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test =',\n",
       " 'y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model1 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\",\n",
       " \"# sgd 定义随机梯度下降法优化器，学习率 0.1 # loss='mse'定义均方差代价函数 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 # model1 用均方差代价函数，model2 用交叉熵代价函数 sgd = SGD(0.1) model1.compile(optimizer=sgd, loss='mse', metrics=['accuracy']) model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\\n\\n# 传入训练集数据和标签训练模型 # 周期大小为 8（把所有训练集数据训练一次称为训练一个周期） epochs = 8 # 批次大小为 32（每次训练模型传入 32 个数据进行训练）\\n\\n185\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0515 - accuracy: 0.6711 -',\n",
       " '33us/sample - los s: 0.0515 - accuracy: 0.6711 - val_loss: 0.0295 - val_accuracy: 0.853 0 Epoch 2/8 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0260 - accuracy: 0.8587 - val_loss: 0.0218 - val_accuracy: 0.881 9 …… Epoch 8/8 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0162 - accuracy: 0.9020 - val_loss: 0.0150 - val_accuracy: 0.909 1 Train on 60000 samples, validate on 10000 samples Epoch 1/8 60000/60000 [==============================] -',\n",
       " '60000/60000 [==============================] - 2s 35us/sample - los s: 0.4165 - accuracy: 0.8858 - val_loss: 0.3117 - val_accuracy: 0.912 4 Epoch 2/8 60000/60000 [==============================] - 2s 33us/sample - los s: 0.3144 - accuracy: 0.9114 - val_loss: 0.2916 - val_accuracy: 0.918 7 …... Epoch 8/8 60000/60000 [==============================] - 2s 32us/sample - los s: 0.2713 - accuracy: 0.9244 - val_loss: 0.2736 - val_accuracy: 0.923 3',\n",
       " \"代码 6-1：简单 MNIST 数据集分类模型-交叉熵（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='mean_squared_error' )\\n\\n186\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='softmax_cross_entro py') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为：\\n\\nhistory1.history 和 history2.history 保存着 mode1 和 model2 训练过程中每个训练周\",\n",
       " \"期的训练集准确率和训练集 loss 以及验证集准确率和验证集 loss。例如通过：\\n\\nhistory1.history['accuracy']可以获得 model1 的训练集准确率\\n\\nhistory1.history['loss']可以获得 model1 的训练集 loss\\n\\nhistory1.history['val_accuracy']可以获得 model1 的验证集准确率\\n\\nhistory1.history['val_loss']可以获得 model1 的验证集 loss\\n\\n从输出结果的图中我们可以看出使用交叉熵代价函数来训练模型可以使得模型的收敛速\\n\\n度更快，更少的训练次数和更少的训练时间就可以使得模型得到更好的效果。所以在分类模\\n\\n型中我们通常都是使用交叉熵代价函数。\\n\\n187\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.2 过拟合（Over-Fitting）\\n\\n6.2.1 什么是过拟合\\n\\n拟合可以分为三种情况，欠拟合（Under-Fitting），正确拟合（Right-Fitting）以及过拟\",\n",
       " '合（Over-Fitting）。过拟合在机器学习和深度学习中经常会出现，简单说来其实就是我们所构\\n\\n建的模型在训练集中表现非常好，但是在测试集中表现得不够好。\\n\\n图 6.9 表示的是回归问题中的欠拟合，正确拟合以及过拟合的情况。我们使用相同的训练\\n\\n集和不同的模型来做训练，第一幅图使用比较简单的模型，第二幅图使用合适的模型，第三幅\\n\\n图使用比较复杂的模型。\\n\\n图 6.9 回归中的三种拟合情况\\n\\n188\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n在图 6.9 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n\\n第二幅图的拟合效果比较好，并且回归线比较平滑，模型属于正确拟合；第三幅图拟合的效\\n\\n果非常好，预测的回归线与真实的训练样本数据分布的误差几乎为 0。假如我们把同样的模\\n\\n型应用到测试集中来做测试，如图 6.10 所示。\\n\\n图 6.10 把回归模型应用于测试集\\n\\n图 6.10 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的',\n",
       " '图 6.10 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n\\n的表现就不是特别好。\\n\\n在分类的任务中也有类似的情况。图 6.11 表示的是分类问题中的欠拟合，正确拟合以及\\n\\n过拟合的情况。我们使用相同的训练集和不同的模型来做训练，第一幅图使用比较简单的模型，\\n\\n第二幅图使用合适的模型，第三幅图使用比较复杂的模型：\\n\\n189\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.11 分类中的三种拟合情况\\n\\n在图 6.11 中我们可以看出第一幅图的拟合效果显然很不好，所以是属于欠拟合的状态；\\n\\n第二幅图的拟合效果比较好，并且分类边界比较平滑，模型属于正确拟合；第三幅图拟合的\\n\\n效果非常好，分类的误差几乎为 0。假如我们把同样的模型应用到测试集中来做测试，如图\\n\\n6.12 所示。\\n\\n图 6.12 把分类模型应用于测试集\\n\\n190\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '190\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.12 我们可以看出，欠拟合的模型不管在训练集还是测试集效果都不好；正确拟合的\\n\\n模型在训练集和测试集中表现都不错；过拟合的模型在训练集中表现得非常好，在测试集中\\n\\n的表现就不是特别好。\\n\\n模型的复杂度与模型误差的关系如图 6.13 所示。\\n\\n图 6.13 模型复杂度与模型误差的关系\\n\\n模型复杂度在深度学习中主要指的是网络的层数以及每层网络神经元的各种，网络的层\\n\\n数越多越复杂，神经元的个数越多越复杂。从图 6.13 中我们可以看到，训练集的误差是随着\\n\\n模型复杂度的提升而不断降低的，测试集的误差是随着模型复杂度的提升而先下降后上升。\\n\\n训练集误差和测试集误差的曲线左端欠拟合的状态，训练误差和测试误差都比较高；中间部\\n\\n分是正确拟合的状态，训练误差和测试误差都比较低；右边部分是过拟合的状态，巡逻误差\\n\\n比较低，测试误差比较高。\\n\\n6.2.2 抵抗过拟合的方法\\n\\n常见的抵抗过拟合的方法有：增大数据集，提前停止(Early-Stopping)，Dropout，正则',\n",
       " '化等，标签平滑(label Smoothing)等。\\n\\n这几种方法我们单独拿出来放在后面的小节中讲解。\\n\\n191\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.3 数据增强（Data Augmentation）\\n\\n数据增强就是增加数据量，数据对于机器学习或者深度学习来说非常重要，有时候拥有更\\n\\n多的数据胜过拥有一个好的模型。一般来说更多的数据参与训练，训练得到的模型就更好。如\\n\\n果数据太少，而我们构建的神经网络又太复杂的话就比较容易产生过拟合的现象。\\n\\n例如在图像领域，数据增加的手段经常被使用，我们可以通过对图片进行一些调整来生成\\n\\n更多图片，常用的手段如下：\\n\\n1. 旋转 | 反射变换(Rotation/reflection): 随机旋转图像一定角度; 改变图像内\\n\\n容的朝向。\\n\\n2. 翻转变换(flip): 沿着水平或者垂直方向翻转图像。\\n\\n3. 缩放变换(zoom): 按照一定的比例放大或者缩小图像。\\n\\n4. 平移变换(shift): 在图像平面上对图像以一定方式进行平移。',\n",
       " '4. 平移变换(shift): 在图像平面上对图像以一定方式进行平移。\\n\\n5. 尺度变换(scale): 对图像按照指定的尺度因子, 进行放大或缩小。\\n\\n6. 对比度变换(contrast): 在图像的 HSV 颜色空间，改变饱和度 S 和 V 亮度分\\n\\n量，保持色调 H 不变. 对每个像素的 S 和 V 分量进行指数运算(指数因子在 0.25 到 4\\n\\n之间), 增加光照变化。\\n\\n7. 噪声扰动(noise): 对图像的每个像素 RGB 进行随机扰动, 常用的噪声模式是\\n\\n椒盐噪声和高斯噪声。\\n\\n8. 颜色变换(color): 对训练集图像的颜色进行一些有规律的调整。\\n\\n比如水平翻转，如图 6.14 所示。\\n\\n192\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.14 水平翻转\\n\\n比如旋转一定角度，然后再随机裁剪，如图 6.15 所示。\\n\\n图 6.15 旋转裁剪\\n\\n比如调整图像的颜色，如图 6.16 所示。\\n\\n图 6.16 颜色变换\\n\\n193\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '193\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nTensorflow 中有封装好的程序可以非常方便的帮助我们实现图像数据增强的功能，如代\\n\\n码 6-2 所示。\\n\\n代码 6-2：图像数据增强\\n\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load _img import numpy as np',\n",
       " \"datagen = ImageDataGenerator( rotation_range = 40, # 随机旋转度数 width_shift_range = 0.2, # 随机水平平移 height_shift_range = 0.2,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 30, # 随机错切变换 zoom_range = 0.2, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range = (0.7,1.3), # 亮度变化 fill_mode = 'nearest', # 填充方式\",\n",
       " \") # 载入图片 img = load_img('image.jpg') # 把图片变成 array，此时数据是 3 维 # 3 维(height,width,channel) x = img_to_array(img) # 在第 0 个位置增加一个维度 # 我们需要把数据变成 4 维，然后再做数据增强 # 4 维(1,height,width,channel) x = np.expand_dims(x,0) # 生成 20 张图片 i = 0 # 生成的图片都保存在 temp 文件夹中，文件名前缀为 new_cat,图片格式为 jpeg for batch in datagen.flow(x, batch_size=1, save_to_dir='temp', save_prefix='new_cat', save _format='jpeg'): i += 1 if i==20: break\\n\\n使用 1 张原始图片，程序运行后在 temp 文件夹中产生了 20 张差异较大的图片，如图\\n\\n6.17 所示。\\n\\n194\",\n",
       " '6.17 所示。\\n\\n194\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.17 图像数据增强\\n\\n6.4 提前停止训练（Early-Stopping）\\n\\nEarly-Stopping 是一种提前结束训练的策略用来防止过拟合。\\n\\n在训练模型的时候，我们往往会设置一个比较大的迭代次数 n。一般的做法是记录到目前\\n\\n为止最好的测试集准确率 p，之后连续 m 个周期没有超过最佳测试集准确率 p 时，则可以认\\n\\n为 p 不再提高了，此时便可以提前停止迭代(Early-Stopping)。代码 6-3 是在代码 5-7 的基础\\n\\n上进行修改得到，加上了 Early-Stopping 的功能。\\n\\n代码 6-3：简单 MNIST 数据集分类模型- Early_Stoppping',\n",
       " '代码 6-3：简单 MNIST 数据集分类模型- Early_Stoppping\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD from tensorflow.keras.callbacks import EarlyStopping # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000）\\n\\n195',\n",
       " '195\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集数据 x_test 的数据形状为（10000，28，28） # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 # 先用 Flatten 把数据从 3 维变成 2 维，(60000,28,28)->(60000,784) # 设置输入数据形状 input_shape 不需要包含数据的数量，（28,28）即可 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.5) model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\",\n",
       " \"# EarlyStopping 是 Callbacks 的一种，callbacks 用于指定在每个 epoch 或 batch 开始和结 束的时候进行哪种特定操作 # monitor='val_accuracy',监控验证集准确率 # patience=5,连续 5 个周期没有超过最高的 val_accuracy 值，则提前停止训练 # verbose=1，停止训练时提示 early stopping early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\",\n",
       " '# 传入训练集数据和标签训练模型 # 周期大小为 100（把所有训练集数据训练一次称为训练一个周期） # 批次大小为 32（每次训练模型传入 32 个数据进行训练） # validation_data 设置验证集数据 # callbacks=[early_stopping]设置 early_stopping model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test,y_test), callbacks=[early_stopping])\\n\\n结果输出为： Train on 60000 samples, validate on 10000 samples\\n\\n196',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 1/100 60000/60000 [==============================] - 2s 33us/sample - los s: 0.0267 - accuracy: 0.8420 - val_loss: 0.0167 - val_accuracy: 0.899 9 Epoch 2/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0164 - accuracy: 0.8993 - val_loss: 0.0145 - val_accuracy: 0.909 5 Epoch 3/100 …… Epoch 30/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0108 - accuracy: 0.9329 - val_loss: 0.0111 - val_accuracy:',\n",
       " '0.9329 - val_loss: 0.0111 - val_accuracy: 0.929 3 Epoch 31/100 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0108 - accuracy: 0.9330 - val_loss: 0.0111 - val_accuracy: 0.929 9 Epoch 32/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9332 - val_loss: 0.0110 - val_accuracy: 0.929 5 Epoch 33/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 -',\n",
       " 's: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.929 9 Epoch 34/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0107 - accuracy: 0.9344 - val_loss: 0.0110 - val_accuracy: 0.929 6 Epoch 35/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0106 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.928 6 Epoch 36/100 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0106 - accuracy: 0.9347 - val_loss:',\n",
       " '- los s: 0.0106 - accuracy: 0.9347 - val_loss: 0.0110 - val_accuracy: 0.929 9 Epoch 00036: early stopping',\n",
       " '虽然我们设置了让模型训练 100 个周期，不过在训练到第 31 周期时模型得到了一个 val\\n\\n_accuracy 为 0.9299。之后连续 5 个周期模型的 val_accuracy 都没有超过第 31 周期的 val_\\n\\n197\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\naccuracy 值。我们可以认为继续训练模型可能也不会得到更好的结果了，反而可能会出现过\\n\\n拟合的情况，所以就让模型提前停止训练了。\\n\\n6.5 Dropout\\n\\n6.5.1 Dropout 介绍\\n\\nDropout 也是一种用于抵抗过拟合的技术，它试图改变网络本身来对网络进行优化。我\\n\\n们先来了解一下它的工作机制，当我们训练一个普通的神经网络时，网络的结构可能如图 6.18\\n\\n所示。\\n\\n图 6.18 普通的神经网络[1]\\n\\nDropout 通常是在神经网络隐藏层的部分使用，使用的时候会临时关闭掉一部分的神经\\n\\n元，我们可以通过一个参数来控制神经元被关闭的概率，网络结构如图 6.19 所示。\\n\\n198\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '198\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.19 使用 Dropout 的神经网络[1]\\n\\n更详细的流程如下：\\n\\n1. 在模型训练阶段我们可以先给 Dropout 参数设置一个值，例如 0.4。意思是\\n\\n大约 60%的神经元是工作的，大约 40%神经元是不工作的。\\n\\n2. 给需要进行 Dropout 的神经网络层的每一个神经元生成一个 0-1 的随机数(一\\n\\n般是对隐藏层进行 Dropout)。如果神经元的随机数小于 0.6，那么该神经元就设置为\\n\\n工作状态的；如果神经元的随机数大于等于 0.6，那么该神经元就设置为不工作的，不\\n\\n工作状态的意思就是不参与计算和训练，可以当这个神经元不存在。\\n\\n3. 设置好一部分神经元工作一部分神经元不工作之后，我们会发现神经网络的输\\n\\n出值会发现变化，如图 6.18 中，如果隐藏层有一半不工作，那么网络输出值就会比原\\n\\n来的值要小，因为计算 WX+b 时，如果 W 矩阵中，有一部分的值变成 0，那么最后\\n\\n的计算结果肯定会变小。所以为了使用 Dropout 的网络层神经元信号的总和不会发生',\n",
       " '的计算结果肯定会变小。所以为了使用 Dropout 的网络层神经元信号的总和不会发生\\n\\n太大的变化，对于工作的神经元的输出信号还需要除以 0.4。\\n\\n4. 训练阶段重复 1-3 步骤，每一次都随机选择部分的神经元参与训练。\\n\\n5. 在测试阶段所有的神经元都参与计算。\\n\\n199\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nDropout 为什么会起作用呢？这个问题很难通过数学推导来证明。我们在介绍 ReLU 激\\n\\n活函数的时候有提到过神经网络的信号是冗余的，神经网络在做预测时并不需要隐藏层所有神\\n\\n经元都工作，只需要一部分隐藏层神经元工作即可。我们可以抽象地来理解 Dropout，当我们\\n\\n使用 Dropout 的时候，就有点像我们在训练很多不同的结构更简单的神经网络，最后测试阶\\n\\n段再综合所有的网络结构得到结果。或者另外一种理解方式是我们使用 Dropout 的时候减少\\n\\n了神经元之间的相互关联，同时强制网络使用更少的特征来做预测，可以增加模型的健壮性。\\n\\n除了这两种理解方式之外还可以有其他的很多理解方式，深度学习中很多技巧都是不能用',\n",
       " '除了这两种理解方式之外还可以有其他的很多理解方式，深度学习中很多技巧都是不能用\\n\\n数学推导得到同时又比较难理解的。但重要的是这些技巧在实际应用中可以帮助我们得到更好\\n\\n的结果。\\n\\nDropout 比较适合应用于只有少量数据但是需要训练复杂模型的场景，这类场景在图像\\n\\n领域比较常见，所以 Dropout 经常用于图像领域。\\n\\n6.5.2 Dropout 程序\\n\\n这部分我们将看到一个 Dropout 在 MNIST 数据集识别中的应用，如代码 6-4 所示。\\n\\n代码 6-4：MNIST 数据集分类模型-Dropout（片段 1）',\n",
       " 'import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)',\n",
       " \"200\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 模型定义，model1 使用 Dropout # Dropout(0.4)表示隐藏层 40%神经元不工作 model1 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dropout(0.4), Dense(units=100,activation='tanh'), Dropout(0.4), Dense(units=10,activation='softmax') ])\",\n",
       " \"# 在定义一个一模一样的模型用于对比测试，model2 不使用 Dropout # Dropout(0)表示隐藏层所有神经元都工作，相当于没有 Dropout model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dropout(0), Dense(units=100,activation='tanh'), Dropout(0), Dense(units=10,activation='softmax') ])\",\n",
       " \"# sgd 定义随机梯度下降法优化器 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\",\n",
       " '# 传入训练集数据和标签训练模型 # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test))\\n\\n201',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s 62us/sample - los s: 0.4170 - accuracy: 0.8737 - val_loss: 0.2087 - val_accuracy: 0.937 0 Epoch 2/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.2808 - accuracy: 0.9165 - val_loss: 0.1627 -',\n",
       " 's: 0.2808 - accuracy: 0.9165 - val_loss: 0.1627 - val_accuracy: 0.949 8 …… Epoch 30/30 60000/60000 [==============================] - 3s 52us/sample - los s: 0.1006 - accuracy: 0.9689 - val_loss: 0.0824 - val_accuracy: 0.977 3 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.2552 - accuracy: 0.9234 - val_loss: 0.1505 - val_accuracy: 0.954 2 Epoch 2/30 60000/60000 [==============================] - 3s',\n",
       " '60000/60000 [==============================] - 3s 51us/sample - los s: 0.1163 - accuracy: 0.9642 - val_loss: 0.1073 - val_accuracy: 0.966 4 …… Epoch 30/30 60000/60000 [==============================] - 3s 57us/sample - los s: 4.9737e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9818',\n",
       " \"代码 6-4：MNIST 数据集分类模型-Dropout（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Dropout') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs')\\n\\n202\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为：\\n\\n模型训练结果前 1-30 周期是使用了 Dropout 的结果，后面的 1-30 周期是没有使用\\n\\nDropout 的结果。观察结果我们发现使用了 Dropout 之后训练集准确率和验证集的准确率相\",\n",
       " '差并不是很大，所以能看出 Dropout 确实是可以起到抵抗过拟合的作用。我们还可以发现一\\n\\n个有趣的现象就是前 1-30 周期 model1 的验证集准确率还高于训练集的准确率，这是因为模\\n\\n型在计算训练集准确率的时候模型还在使用 Dropout，在计算验证集准确率的时候已经不使\\n\\n用 Dropout 了。使用 Dropout 的时候模型的准确率会稍微降低一些。同时我们也可以发现，\\n\\n不用 Dropout 的 model2 中测试集的准确率看起来比使用 Dropout 的 model1 要更高。\\n\\n事实上使用 Dropout 之后模型的收敛速度会变慢一些，所以需要更多的训练次数才能得\\n\\n到最好的结果。代码 6-3 中不用 Dropout 的 model2 验证集训练 30 个周期最高准确率大概\\n\\n是 98.2%左右；使用 Dropout 的 model1 如果训练足够多的周期，验证集最高准确率可以达\\n\\n到 98.8%左右。\\n\\n203\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.6 正则化（Regularization）\\n\\n6.6.1 正则化介绍',\n",
       " '6.6 正则化（Regularization）\\n\\n6.6.1 正则化介绍\\n\\n正则化也叫作规范化，通常用得比较多的方式是 L1 正则化和 L2 正则化。L1 和 L2 正则\\n\\n化的使用实际上就是在普通的代价函数（例如均方差代价函数或交叉熵代价函数）后面加上一\\n\\n个正则项，例如加上了 L1 正则项的交叉熵为：\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n+\\n\\n𝜆 2𝑁\\n\\n?|𝑤| x\\n\\n加上 L2 正则项的交叉熵为：\\n\\n𝐸 = −\\n\\n1 𝑁\\n\\nP ?[𝑡(𝑙𝑛𝑦( + (1 − 𝑡()ln\\t(1 − 𝑦()] (A\"\\n\\n+\\n\\n𝜆 2𝑁\\n\\n? 𝑤# x\\n\\n公式 6.21 可以写成：\\n\\n𝐸 = 𝐸< +\\n\\n𝜆 2𝑁\\n\\n? 𝑤# x\\n\\n其中E<是原始的代价函数，𝜆是正则项的系数，𝜆是一个大于 0 的数，𝜆的值越大那么正则\\n\\n项的影响就越大，𝜆的值越小正则项的影响也就越小，当𝜆为 0 时，相当于正则项不存在。N 表\\n\\n示样本个数。w 代表所有的权值参数和偏置值。',\n",
       " '示样本个数。w 代表所有的权值参数和偏置值。\\n\\n我们训练模型的过程中实际上就是使用梯度下降法来最小化代价函数的过程，交叉熵代价\\n\\n函数中的 t 和 y 的值越接近，那么代价函数的值就越接近于 0。观察带有正则项的代价函数表\\n\\n达式我们可以知道，最小化代价函数的过程中不仅要使得 t 的值接近于 y，还要使得神经网络\\n\\n的权值参数 w 的值趋近于 0。因为不管是对于 L1 正则项\\n\\n´\\n\\n#P\\n\\n∑ |𝑤|x 还是对于 L2 正则项\\n\\n´\\n\\n#P\\n\\n正则项的值都是大于 0 的，所以最小化正则项的值，实际上就是让 w 的值接近于 0。\\n\\nL1 正则项和 L2 正则项的区别在于：\\n\\n204\\n\\n(6.20)\\n\\n(6.21)\\n\\n(6.22)\\n\\n∑ 𝑤#\\n\\nx ，\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nL1 正则项会使得神经网络中的很多权值参数变为 0，如果神经网络中很多的权值都是 0 的\\n\\n话那么可以认为网络的复杂度降低了，拟合能力也降低了，因此不容易出现过拟合的情况。',\n",
       " '话那么可以认为网络的复杂度降低了，拟合能力也降低了，因此不容易出现过拟合的情况。\\n\\nL2 正则项会使得神经网络的权值衰减，权值参数变为接近于 0 的值，注意这里的接近于 0\\n\\n不是等于零，L2 正则化很少会使权值参数等于 0。L2 正则项之所以有效是因为权值参数 w 变\\n\\n得很小之后 WX+b 的计算也是会变成一个接近于 0 的值。我们知道在使用 sigmoid(x)函数或\\n\\n者 tanh(x)函数时，当 x 的取值在 0 附近时，函数的曲线是非常接近于一条直线的，如图 6.20\\n\\n所示。\\n\\n图 6.20 tanh 函数图像\\n\\n所以神经网络中增加了很多线性特征减少了很多非线性的特征，网络的复杂度降低了，因\\n\\n此不容易出现过拟合。\\n\\n6.6.2 正则化程序\\n\\n这部分我们将看到一个正则化在 MNIST 数据集识别中的应用，如代码 6-5 所示。\\n\\n代码 6-5：MNIST 手写数字识别-正则化（片段 1）',\n",
       " '代码 6-5：MNIST 手写数字识别-正则化（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD\\n\\n205\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com import matplotlib.pyplot as plt import numpy as np # 使用 l1 或 l2 正则化 from tensorflow.keras.regularizers import l1,l2',\n",
       " '# 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义，model1 使用 l2 正则化 # l2(0.0003)表示使用 l2 正则化，正则化系数为 0.0003 model1 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh',kernel_regularizer=l2(0.0003)), Dense(units=100,activation='tanh',kernel_regularizer=l2(0.0003)), Dense(units=10,activation='softmax',kernel_regularizer=l2(0.0003)) ])\",\n",
       " \"# 在定义一个一模一样的模型用于对比测试，model2 不使用正则化 model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dense(units=100,activation='tanh'), Dense(units=10,activation='softmax') ])\\n\\n# sgd 定义随机梯度下降法优化器 # loss='categorical_crossentropy'定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) model2.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\",\n",
       " '# 传入训练集数据和标签训练模型\\n\\n206',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 4s',\n",
       " '60000/60000 [==============================] - 4s 69us/sample - los s: 0.4083 - accuracy: 0.9208 - val_loss: 0.2928 - val_accuracy: 0.952 5 Epoch 2/30 60000/60000 [==============================] - 4s 59us/sample - los s: 0.2626 - accuracy: 0.9601 - val_loss: 0.2285 - val_accuracy: 0.966 2 …… Epoch 30/30 60000/60000 [==============================] - 4s 60us/sample - los s: 0.1380 - accuracy: 0.9835 - val_loss: 0.1492 - val_accuracy: 0.979 6 Train on 60000 samples, validate on 10000 samples',\n",
       " 'Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 56us/sample - los s: 0.2563 - accuracy: 0.9222 - val_loss: 0.1415 - val_accuracy: 0.956 8 Epoch 2/30 60000/60000 [==============================] - 3s 53us/sample - los s: 0.1178 - accuracy: 0.9634 - val_loss: 0.1115 - val_accuracy: 0.965 7 …… Epoch 30/30 60000/60000 [==============================] - 3s 49us/sample - los s: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.0765 -',\n",
       " '- accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9817',\n",
       " \"代码 6-5：MNIST 手写数字识别-正则化（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图\\n\\n207\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='L2 Regularization') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='FC') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为：\\n\\n前 1-30 周期是使用 l2 正则化的 model1 的结果，后 1-30 周期是不使用正则化的 mod\\n\\nel2 的结果。从结果上看，使用正则化后 model1 的训练集准确率和验证集准确率相差不\",\n",
       " 'el2 的结果。从结果上看，使用正则化后 model1 的训练集准确率和验证集准确率相差不\\n\\n大，说明正则化确实是可以起到抵抗过拟合的作用。但是使用正则化之后验证集准确率的结\\n\\n果并不是非常理想，说明正则化并不是适用于所有场景。在神经网络结构比较复杂，训练数\\n\\n据量比较少的时候，使用正则化效果会比较好。如果网络不算太复杂的话，任务比较简单的\\n\\n时候，使用正则化可能准确率反而会下降。对于 Dropout 来说也有类似的情况。所以 Drop\\n\\nout 和正则化需要根据实际使用情况的好坏来决定是否使用。\\n\\n208\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n209\\n\\n6.7 标签平滑（Label Smoothing）\\n\\n6.7.1 标签平滑(Label Smoothing)介绍\\n\\n标签平滑（label smoothing）也称为标签平滑正则化（label-smoothing regularization），\\n\\n简称 LSR。从名字就可以看出标签平滑也是一种正则化策略。',\n",
       " '简称 LSR。从名字就可以看出标签平滑也是一种正则化策略。\\n\\n我们在做分类模型的时候通常会把标签变成独热编码（ one-hot），但是 变 成 独 热编 码的\\n\\n标签在模型训练时会使得模型变得“极度自信”，容易产生过拟合。独热编码（one-hot）可能\\n\\n存在的问题我给大家举个例子大家就容易理解了，如图 6.21 所示是我写的一个数字。\\n\\n图 6.21 一个数字\\n\\n这个数字你能说它 100%就是 6 吗，不一定吧，它也有点像 2，说不定还是 1 或者 7 只不\\n\\n过手滑了。所以让模型非常自信的认为图中的数字就是 6，独热编码(0,0,0,0,0,0,1,0,0,0)，不\\n\\n一定是合适的。可能把它的标签改成 (0,0.02,0.2,0.01,0.01,0.01,0.7,0.03,0.01,0.01)会比较好\\n\\n一点。\\n\\n在 MNIST 数据集里面实际上确实有一些数字会写得比较奇怪，让人也很难分辨，其它数\\n\\n据集也会有类似的问题，所以让模型“过度自信”就不一定是好事了。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n标签平滑的处理方式很简单，给大家举一个具体的例子大家就知道了。我们需要设置一个\\n\\n平滑系数，比如 0.1，假设一共有 10 个种类。某个数据的真实标签为：\\n\\n(0,0,0,0,0,1,0,0,0,0)\\n\\n经过标签平滑处理以后的标签为：\\n\\n(0.01,0.01,0.01,0.01,0.01,0.91,0.01,0.01,0.01,0.01)\\n\\n也就类似于下面程序，label_smoothing 为平滑系数：\\n\\nnew_onehot_labels = onehot_labels * (1 - label_smoothing)\\n\\n+ label_smoothing / num_classes\\n\\n6.7.2 标签平滑（Label Smoothing）程序\\n\\n实现 MNIST 手写数字识别-标签平滑的代码如代码 6-6 所示。\\n\\n代码 6-6：MNIST 手写数字识别-标签平滑（片段 1）',\n",
       " 'import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Flatten from tensorflow.keras.optimizers import SGD from tensorflow.keras.losses import CategoricalCrossentropy import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码',\n",
       " '/ 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义，model1 不用 label smoothing model1 = Sequential([ Flatten(input_shape=(28, 28)),\\n\\n210\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Dense(units=200,activation='tanh'), Dense(units=100,activation='tanh'), Dense(units=10,activation='softmax') ])\\n\\n# 在定义一个一模一样的模型用于对比测试，model2 使用 label smoothing model2 = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dense(units=100,activation='tanh'), Dense(units=10,activation='softmax') ])\",\n",
       " \"# model1 不用 label smoothing loss1 = CategoricalCrossentropy(label_smoothing=0) # model2 使用 label smoothing loss2 = CategoricalCrossentropy(label_smoothing=0.1)\\n\\n# sgd 定义随机梯度下降法优化器 # loss 定义交叉熵代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 sgd = SGD(0.2) model1.compile(optimizer=sgd, loss=loss1, metrics=['accuracy']) model2.compile(optimizer=sgd, loss=loss2, metrics=['accuracy'])\",\n",
       " '# 传入训练集数据和标签训练模型 # 周期大小为 30（把所有训练集数据训练一次称为训练一个周期） epochs = 30 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/30\\n\\n211',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 4s 62us/sample - los s: 0.2526 - accuracy: 0.9235 - val_loss: 0.1460 - val_accuracy: 0.957 1 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.1139 - accuracy: 0.9659 - val_loss: 0.0915 - val_accuracy: 0.970 0 …… Epoch 30/30 60000/60000 [==============================] - 3s 50us/sample - los s: 4.9963e-04 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9816 Train on 60000',\n",
       " '0.0720 - val_accuracy: 0.9816 Train on 60000 samples, validate on 10000 samples Epoch 1/30 60000/60000 [==============================] - 3s 54us/sample - los s: 0.7274 - accuracy: 0.9243 - val_loss: 0.6323 - val_accuracy: 0.957 2 Epoch 2/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.6139 - accuracy: 0.9663 - val_loss: 0.6093 - val_accuracy: 0.965 4 …… Epoch 30/30 60000/60000 [==============================] - 3s 51us/sample - los s: 0.5127 - accuracy: 0.9996 -',\n",
       " '51us/sample - los s: 0.5127 - accuracy: 0.9996 - val_loss: 0.5527 - val_accuracy: 0.981 7',\n",
       " \"代码 6-6：MNIST 手写数字识别-标签平滑（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='without LSR') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='LSR') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为：\\n\\n212\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从结果看来使用标签平滑 label_smoothing(LSR)后结果稍微好一点点的，不过不太明显。\\n\\n其实标签平滑 label_smoothing 作为一个优化策略也并不是每次都能使结果更好，不过它有\",\n",
       " '机会可以让结果更好，所以有时候也值得我们尝试用一下。\\n\\n6.8 优化器（Optimizer）\\n\\n目前在 tf.keras.optimizers 中有下面这些优化器可以使用：\\n\\nAdadelta\\n\\nAdagrad\\n\\nAdam\\n\\nAdamax\\n\\nFtrl\\n\\nNadam\\n\\nRMSprop\\n\\nSGD\\n\\n213\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n优化器的种类很多，在 Keras 中只包含了部分常用的优化器，不是全部。之前我们经常使\\n\\n用的优化器是随机梯度下降法（SGD），使用 SGD 算法来最小化代价函数。其实其他的一些优\\n\\n化器的基础也是梯度下降法，只不过分别做了一些不同的调整或优化。\\n\\n下面我们选几种常用的优化器来重点介绍。\\n\\n6.8.1 梯度下降法 SGD\\n\\n梯度下降法有三种常见的变形，BGD,SGD,MBGD。我们通常把梯度下降法称为随机梯度\\n\\n下降法 SGD，但是梯度下降法通常的用的是 MBGD 算法。\\n\\nBGD 是 Batch gradient descent，表示每次训练都采用整个训练集数据来优化模型。BGD',\n",
       " '的优点是每次训练都考虑所有的样本，所以模型优化的方向会比较正确；缺点是每次训练都需\\n\\n要计算大量的数据，所以模型训练的速度比较慢。\\n\\nSGD 是 Stochastic gradient descent，表示每次训练都选择训练集中的一个样本来优化\\n\\n模型。SGD 的优点是每次只计算一个样本，权值调整速度比较快；缺点是每次只考虑了一个\\n\\n样本，所以模型优化的方向很可能是错误的。\\n\\nMBGD 是 Mini-batch gradient descent，表示每次训练都选择训练集中一个批次的数\\n\\n据来优化模型，这里的一个批次常用的取值是 32，64 等，当然如果取其他的数值也可以。\\n\\nMBGD 相当于是结合了 BGD 和 SGD 两者的优点，采用一个小批次的数据量来训练模型，这\\n\\n样训练的速度比较快，同时模型优化的方向也比较正确。所以目前带有小批次的训练方法是最\\n\\n主流的训练方法。一般我们提到梯度下降法，或者随机梯度下降法 SGD 的时候，默认就是使\\n\\n用 MBGD 的方法。\\n\\n梯度下降法的公式为：\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n214',\n",
       " '𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n214\\n\\n(6.23)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n其中 t 表示第 t 时刻，𝜂表示学习率，𝛻x𝑓(𝑊ˆ(cid:127)\")表示 t-1 时刻对代价函数 f 求 W 的导数。\\n\\n6.8.2 Momentum\\n\\nMomentum 是模拟物理中动量的概念，积累之前的动量来替代真正的梯度。\\n\\nMomentum 的公式为：\\n\\n𝑉ˆ = 𝛾𝑉ˆ(cid:127)\" + 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝑉ˆ\\n\\n𝛾为动力项，通常设置为 0.9。当前权值的改变会受到上一次权值改变的影响，类似于小球\\n\\n向下滚动的时候带上了惯性。这样可以加快小球的向下的速度，同时可以抑制小球振荡。\\n\\n6.8.3 NAG(Nesterov Accelerated Gradient)\\n\\nNAG 的公式为：\\n\\n𝑉ˆ = 𝛾𝑉ˆ(cid:127)\" + 𝜂𝛻x𝑓(𝑊ˆ(cid:127)\" − 𝛾𝑉ˆ(cid:127)\")',\n",
       " '𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝑉ˆ\\n\\n𝛾为动力项，通常设置为 0.9。𝑊ˆ(cid:127)\" − 𝛾𝑉ˆ(cid:127)\"用来近似代价函数下一步的值，则计算的梯度\\n\\n不是当前位置的梯度，而是下一个位置的梯度。NAG 相当于是一个预先知道正确方向的更聪\\n\\n明的小球。\\n\\nMomentum 和 NAG 都是为了使得梯度更新更加灵活，不过学习率的设置仍然是一个问\\n\\n题，下面介绍的几种优化器针对学习率的问题做出优化，具有自适应学习率的能力。\\n\\n6.8.4 Adagrad\\n\\nAdagrad 的公式为：\\n\\n215\\n\\n(6.24)\\n\\n(6.25)\\n\\n(6.26)\\n\\n(6.27)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝐺ˆ = 𝐺ˆ(cid:127)\" + 𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" −\\n\\n𝜂\\n\\ng𝐺ˆ(cid:127)\" + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\nε的作用是避免分母为 0，取值一般是10(cid:127)(cid:201)。Adagrad 其实是对学习率进行了一个约束。',\n",
       " 'Adagrad 主要的优势是人为设定一个学习率后，这个学习率可以自动调节。它的缺点在于，\\n\\n随着迭代次数的增多，学习率也会越来越低，最终会趋向于 0。\\n\\n6.8.5 Adadelta\\n\\nAdadelta 的公式为：\\n\\n𝐺ˆ = 𝛾𝐺ˆ(cid:127)\" + (1 − 𝛾)𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝐸ˆ = 𝛾𝐸ˆ(cid:127)\" + (1 − 𝛾)(∆𝑊ˆ)#\\n\\n∆𝑊ˆ = −\\n\\ng𝐸ˆ(cid:127)\" + 𝜀 g𝐺ˆ + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ)\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" + ∆𝑊ˆ(cid:127)\"\\n\\n𝛾通常取 0.9，Adadelta 算是对 Adagrad 的改进，此时 Adadelta 已经不用依赖于全局\\n\\n学习率了。\\n\\n6.8.6 RMRprop\\n\\nRMSprop 可以算作 Adadelta 的一个特例，RMSprop 的公式为：\\n\\n𝐺ˆ = 𝛾𝐺ˆ(cid:127)\" + (1 − 𝛾)𝛻x𝑓(𝑊ˆ(cid:127)\")#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" −\\n\\n𝜂\\n\\ng𝐺ˆ(cid:127)\" + 𝜀',\n",
       " '𝑊ˆ = 𝑊ˆ(cid:127)\" −\\n\\n𝜂\\n\\ng𝐺ˆ(cid:127)\" + 𝜀\\n\\n𝛻x𝑓(𝑊ˆ(cid:127)\")\\n\\n𝛾通常取 0.9，RMSprop 依然依赖于全局学习率，RMSprop 也算是 Adagrad 的一种发\\n\\n展。\\n\\n216\\n\\n(6.28)\\n\\n(6.29)\\n\\n(6.29)\\n\\n(6.30)\\n\\n(6.31)\\n\\n(6.32)\\n\\n(6.33)\\n\\n(6.34)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.8.7 Adam\\n\\nAdam(Adaptive Moment Estimation)本质上是带有动量项的 RMSprop，Adam 的公\\n\\n式为：\\n\\n𝑚ˆ = 𝛽\"𝑚ˆ(cid:127)\" + (1 − 𝛽\")𝛻x𝑓(𝑊ˆ)\\n\\n𝑣ˆ = 𝛽#𝑣ˆ(cid:127)\" + (1 − 𝛽#)𝛻x𝑓(𝑊ˆ)#\\n\\n𝑚(cid:204) ˆ =\\n\\n𝑣˝ˆ =\\n\\n𝑚ˆ ˆ 1 − 𝛽\" 𝑣ˆ ˆ 1 − 𝛽#\\n\\n𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂\\n\\n𝑚(cid:204) ˆ g\\t𝑣˝ˆ + 𝜀',\n",
       " '𝑊ˆ = 𝑊ˆ(cid:127)\" − 𝜂\\n\\n𝑚(cid:204) ˆ g\\t𝑣˝ˆ + 𝜀\\n\\n𝛽\"通常取 0.9, 𝛽#通常取 0.999。其中𝑚ˆ，𝑣ˆ分别是对梯度的一阶矩估计和二阶矩估计，\\n\\n可以看作对期望𝐸|𝛻𝑤𝑓(𝑊𝑡)|，𝐸˛𝛻𝑤𝑓(𝑊𝑡)2˛的估计；\\t𝑚(cid:204) ˆ，\\t𝑣˝ˆ是对𝑚ˆ，𝑣ˆ的校正，这样可以近\\n\\n似为对期望的无偏估计。Adam 大多数情况下效果都比较好，所以目前用得最多的优化器就是\\n\\nAdam。Adam 与其他一些优化器在训练 MNIST 数据集时的对比，如图 6.22 所示。\\n\\n217\\n\\n(6.35)\\n\\n(6.36)\\n\\n(6.37)\\n\\n(6.38)\\n\\n(6.39)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 6.22 Adam 与其他优化器对比[2]\\n\\n从图 6.22 中我们能看出来，在使用多层神经网络训练 MNIST 数据集时，Adam 的优化\\n\\n速度是最快的。\\n\\n6.8.8 优化器程序\\n\\n如代码 6-7 所示，这里给出一个使用 Adam 优化器的例子，如果想使用其他优化器也类',\n",
       " '如代码 6-7 所示，这里给出一个使用 Adam 优化器的例子，如果想使用其他优化器也类\\n\\n似，调用 tensorflow.keras.optimizers 里面的优化器即可。\\n\\n代码 6-7：MNIST 数据集分类模型-优化器（片段 1）',\n",
       " '代码 6-7：MNIST 数据集分类模型-优化器（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD,Adam import matplotlib.pyplot as plt import numpy as np # 载入数据集 mnist = tf.keras.datasets.mnist # 载入训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 model1 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ]) # 在定义一个一模一样的模型用于对比测试 model2 = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n# 定义 sgd 优化器，学习率 0.1 sgd = SGD(0.1) # 定义 Adam 优化器，学习率 0.001,Adam 优化器学习率通常较低\\n\\n218\",\n",
       " \"218\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com adam = Adam(0.001) # loss='mse'定义均方差代价函数 # metrics=['accuracy']模型在训练的过程中同时计算准确率 # model1 用 Adam 优化器，model2 用 sgd 优化器 model1.compile(optimizer=adam, loss='mse', metrics=['accuracy']) model2.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\",\n",
       " '# 传入训练集数据和标签训练模型 # 周期大小为 6（把所有训练集数据训练一次称为训练一个周期） epochs = 6 # 批次大小为 32（每次训练模型传入 32 个数据进行训练） batch_size=32 # validation_data 设置验证集数据 # 先训练 model1 history1 = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) # 再训练 model2 history2 = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_da ta=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 2s',\n",
       " '60000/60000 [==============================] - 2s 36us/sample - los s: 0.0196 - accuracy: 0.8819 - val_loss: 0.0131 - val_accuracy: 0.917 5 Epoch 2/6 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0129 - accuracy: 0.9182 - val_loss: 0.0118 - val_accuracy: 0.924 1 …… Epoch 6/6 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0107 - accuracy: 0.9327 - val_loss: 0.0109 - val_accuracy: 0.931 6 Train on 60000 samples, validate on 10000 samples Epoch',\n",
       " 'on 60000 samples, validate on 10000 samples Epoch 1/6 60000/60000 [==============================] - 3s 47us/sample - los s: 0.0499 - accuracy: 0.6986 - val_loss: 0.0285 - val_accuracy: 0.852 1 Epoch 2/6',\n",
       " '219\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 60000/60000 [==============================] - 2s 29us/sample - los s: 0.0257 - accuracy: 0.8583 - val_loss: 0.0216 - val_accuracy: 0.878 9 …… Epoch 6/6 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0173 - accuracy: 0.8953 - val_loss: 0.0160 - val_accuracy: 0.903 3\\n\\n代码 6-7：MNIST 数据集分类模型-优化器（片段 2）',\n",
       " \"代码 6-7：MNIST 数据集分类模型-优化器（片段 2）\\n\\n# 画出 model1 验证集准确率曲线图 plt.plot(np.arange(epochs),history1.history['val_accuracy'],c='b',label='Adam') # 画出 model2 验证集准确率曲线图 plt.plot(np.arange(epochs),history2.history['val_accuracy'],c='y',label='SGD') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 结果输出为：\\n\\n从结果对比我们可以看到使用 Adam 优化器之后模型的收敛速度加快了很多，最后得到\\n\\n了更好的训练效果。\\n\\n这一章节我们学习了很多模型优化方法，使用这些模型优化方法把模型训练好以后我们还\\n\\n需要把模型保存下来。如何保存模型将是我们下一章节要介绍的内容。\\n\\n220\",\n",
       " '需要把模型保存下来。如何保存模型将是我们下一章节要介绍的内容。\\n\\n220\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n6.9 参考文献\\n\\n[1] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural\\n\\nnetworks from overfitting[J]. The journal of machine learning research, 2014, 15(1):\\n\\n1929-1958.\\n\\n[2] Kingma D P, Ba J. Adam: A method for stochastic optimization[J]. arXiv preprint\\n\\narXiv:1412.6980, 2014.\\n\\n221\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 7 章-Tensorflow 模型的保存和载入',\n",
       " '第 7 章-Tensorflow 模型的保存和载入\\n\\n在 Tensorflow1.0 中模型的保存和载入通常有两种方式，一种是 Checkpoint 的方式，\\n\\n还有一种是 Protocol buffer 的方式，这两种方式都有各自的一些特点。\\n\\n——Checkpoint 保存的模型通常以“.ckpt”结尾，保存后会得到 4 个文件，如图 7.1\\n\\n中的 4 个文件.\\n\\n图 7.1 Tensorflow 模型文件\\n\\nCheckpoint 是一个文本文件，记录了训练过程中保存的模型的名称，首行记录的是最\\n\\n后（最近）一次保存的模型名称。\\n\\n.data 文件保存的是模型的变量值。\\n\\n.index 文件保存的是.data 文件中的数据跟.meta 文件中的结构之间的对应关系\\n\\n.meta 文件以“protocol buffer”格式保存了整个模型的结构图，模型上定义的操作等\\n\\n信息。\\n\\n——Protocol buffer 的方式是把模型的参数转换为常量后进行保存，同时还会保存模型\\n\\n的结构，保存的模型通常以“.pb”结尾，只会得到一个文件。',\n",
       " \"的结构，保存的模型通常以“.pb”结尾，只会得到一个文件。\\n\\n由于在 Tensorflow2 中很多时候我们都是使用 Tensorflow.keras 来搭建和训练模型，所\\n\\n以模型的保存一般也是使用 Tensorflow. keras的方式。Tensorflow1.0 中所使用的\\n\\nCheckpoint 模型保存方式在 Tensorflow2 中有时也会用到。\\n\\n222\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.1 Keras 模型保存和载入\\n\\n7.1.1 Keras 保存模型\\n\\n使用 Keras 保存模型操作很简单，如模型为 model，可以使用：\\n\\nmodel.save('path_to_my_model.h5')\\n\\n来保存模型，'path_to_my_model'为模型保存路径，'h5'为 HDF5 文件格式。使用\\n\\nmodel.save 来保存模型，可以把模型的结构，权值参数和优化器设置，代价函数设置，\\n\\nmetrics 设置全部保存下来。Keras 模型保存参考代码如代码 7-1 所示。\\n\\n代码 7-1：Keras 模型保存\",\n",
       " '代码 7-1：Keras 模型保存\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n# 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\\n\\n# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test,y_test))\\n\\n223\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " \"223\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 保存模型 model.save('my_model/mnist.h5') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 35us/sample - los s: 0.0379 - accuracy: 0.7752 - val_loss: 0.0214 - val_accuracy: 0.880 8 …… Epoch 5/5 60000/60000 [==============================] - 2s 31us/sample - los s: 0.0156 - accuracy: 0.9043 - val_loss: 0.0145 - val_accuracy: 0.909 8\\n\\n模型训练好之后会生成一个 h5 模型文件保存在'my_model/mnist.h5'。\",\n",
       " \"模型训练好之后会生成一个 h5 模型文件保存在'my_model/mnist.h5'。\\n\\n7.1.2 Keras 载入模型\\n\\n使用 Keras 载入模型操作也很简单，可以使用：\\n\\ntensorflow.keras.models.load_model('path_to_my_model.h5')\\n\\n来载入模型，'path_to_my_model'为模型所在路径。Keras 模型载入参考代码如代码\\n\\n7-2 所示。\\n\\n代码 7-2：Keras 模型载入\",\n",
       " '7-2 所示。\\n\\n代码 7-2：Keras 模型载入\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 载入模型 model = load_model('my_model/mnist.h5')\\n\\n224\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 再训练 5 个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 34us/sample - los s: 0.0150 - accuracy: 0.9073 - val_loss: 0.0141 - val_accuracy: 0.913 7 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0137 - accuracy: 0.9139 - val_loss: 0.0130 - val_accuracy: 0.918 0',\n",
       " '从输出结果可以看到模型是在已经训练了 5 个周期的基础上继续训练的。并且使用\\n\\nmodel.save 保存模型的时候，不仅保存的模型的结构和权值参数，还保存了模型的优化\\n\\n器，代价函数，metrics 这些设置。所以在载入模型之后，我们不需要设置优化器，代价函\\n\\n数和 metrics，就可以直接使用 fit 对模型进行训练。\\n\\n7.2 SavedModel 模型保存和载入\\n\\n7.2.1 SavedModel 保存模型\\n\\nSavedModel 是 Tensorflow 中一种模型格式，SavedModel 的优点是与语言无关，比\\n\\n如可以用时 python 训练模型，然后在 Jave 中非常方便的加载模型。SavedModel 中包含了\\n\\n计算图和网络的权值，一个 SavedModel 模型包含以下内容：\\n\\nassets/\\n\\nsaved_model.pb\\n\\nvariables/\\n\\n225\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nvariables.data-00000-of-00001\\n\\nvariables.index',\n",
       " \"variables.data-00000-of-00001\\n\\nvariables.index\\n\\n其中 saved_model.pb 包含计算图结构，variables 文件夹保存模型训练得到的权值。\\n\\nassets 文件夹一般是空的，可以添加一些可能需要的外部文件。\\n\\n假设程序中训练好的模型为 model，那么可以使用：\\n\\nmodel.save('path_to_saved_model')\\n\\n来保存模型，注意这里的'path_to_saved_model'为模型保存的路径，保存后会得到一个\\n\\n文件夹，所以'path_to_saved_model'不需要加后缀。\\n\\nmodel.save 可以保存两种格式的模型。当我们使用 model.save 的时候，如果\\n\\n'path_to_saved_model'没有后缀就是保存为 SavedModel 格式；如果\\n\\n'path_to_saved_model.h5'有'h5'这个后缀就是保存为 Keras 的 HDF5 格式的模型。\\n\\nSavedModel 保存模型参考代码如代码 7-3 所示。\\n\\n代码 7-3：SavedModel 模型保存\",\n",
       " '代码 7-3：SavedModel 模型保存\\n\\nimport tensorflow as tf from tensorflow.keras.optimizers import SGD # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n226\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义优化器，代价函数 sgd = SGD(0.2) model.compile(optimizer=sgd, loss='mse', metrics=['accuracy'])\\n\\n# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test))\",\n",
       " \"# 保存模型为 SavedModel 格式 model.save('path_to_saved_model') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 37us/sample - los s: 0.0373 - accuracy: 0.7806 - val_loss: 0.0217 - val_accuracy: 0.877 6 …… Epoch 5/5 60000/60000 [==============================] - 2s 32us/sample - los s: 0.0156 - accuracy: 0.9038 - val_loss: 0.0145 - val_accuracy: 0.909 3\\n\\n7.2.2 SavedModel 载入模型\\n\\nSavedModel 模型的载入也很简单，也是使用：\",\n",
       " \"SavedModel 模型的载入也很简单，也是使用：\\n\\ntensorflow.keras.models.load_model('path_to_my_model')\\n\\n来载入就可以了。载入模型以后再次训练的程序基本上跟代码 7-2 一样，如代码 7-4 所\\n\\n示。\\n\\n代码 7-4：SavedModel 模型载入\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0\\n\\n227\",\n",
       " \"227\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 载入 SavedModel 模型 model = load_model('path_to_saved_model')\",\n",
       " '# 再训练 5 个周期模型 model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 2s 36us/sample - los s: 0.0151 - accuracy: 0.9065 - val_loss: 0.0140 - val_accuracy: 0.913 3 …… Epoch 5/5 60000/60000 [==============================] - 2s 30us/sample - los s: 0.0138 - accuracy: 0.9141 - val_loss: 0.0130 - val_accuracy: 0.917 2\\n\\n7.3 单独保存模型结构\\n\\n7.3.1 保存模型结构',\n",
       " '7.3 单独保存模型结构\\n\\n7.3.1 保存模型结构\\n\\n有些时候，可能我们只对模型的结构感兴趣，只想保存模型的结构，而不保存模型的权\\n\\n值，优化器和代价函数等内容。那么我们可以使用：\\n\\nconfig = model.get_config()\\n\\n来保存模型结构，模型的结构数据是一个 python 的字典，使用这个模型结构我们可以\\n\\n重建一个一摸一样的模型，然后重新训练这个模型。\\n\\n另外还有一个保存模型结构的方式是使用：\\n\\njson_config = model.to_json()\\n\\n228\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n来保存模型结构。这个方法是使用 JSON 格式来保存模型结构。单独保存模型结构参考\\n\\n代码如代码 7-5 所示。\\n\\n代码 7-5：保存模型结构（片段 1）\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout',\n",
       " \"# 模型定义 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dropout(0.4), Dense(units=100,activation='tanh'), Dropout(0.4), Dense(units=10,activation='softmax') ])\",\n",
       " \"# 保存模型结构 config = model.get_config() print(config) 结果输出为： {'name': 'sequential', 'layers': [{'class_name': 'Flatten', 'config ': {'name': 'flatten', 'trainable': True, 'batch_input_shape': (Non e, 28, 28), 'dtype': 'float32', 'data_format': 'channels_last'}}, {' class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config ': {'seed': None}},\",\n",
       " \"'GlorotUniform', 'config ': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'con fig': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'ac tivity_regularizer': None, 'kernel_constraint': None, 'bias_constrai nt': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': N one, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'den se_1', 'trainable': True, 'dtype': 'float32', 'units': 100,\",\n",
       " \"True, 'dtype': 'float32', 'units': 100, 'activat ion': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'c lass_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bia s_regularizer': None, 'activity_regularizer': None, 'kernel_constrai nt': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'con fig': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', ' rate': 0.4, 'noise_shape': None,\",\n",
       " \"'float32', ' rate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Den\",\n",
       " \"229\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com se', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'floa t32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kerne l_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': N one}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'k ernel_regularizer': None, 'bias_regularizer': None, 'activity_regula rizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\\n\\n代码 7-5：保存模型结构（片段 2）\",\n",
       " \"代码 7-5：保存模型结构（片段 2）\\n\\nimport json # 保存 json 模型结构文件 with open('model.json','w') as m: json.dump(json_config,m)\\n\\nconfig 的内容跟 json_config 的内容是差不多的，所以这里附上一个输出结果。保存\\n\\njson 模型结构文件以后，在本地会得到一个 model.json 文件。\\n\\n7.3.2 载入模型结构\\n\\n模型结构保存后，可以使用 model_from_json 方法再重新把模型的结构载入，模型结构\\n\\n载入的参考代码如代码 7-6 所示。\\n\\n代码 7-6：载入模型结构\\n\\nimport tensorflow as tf import json\\n\\n# 读入 json 文件 with open('model.json') as m: json_config = json.load(m)\\n\\n# 载入 json 模型结构得到模型 model model = tf.keras.models.model_from_json(json_config)\",\n",
       " '# summary 用于查看模型结构 model.summary() 结果输出为： Model: \"sequential\" _________________________________________________________ Layer (type) Output Shape Param # =========================================================\\n\\n230',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com flatten (Flatten) (None, 784) 0 _________________________________________________________ dense (Dense) (None, 200) 157000 _________________________________________________________ dropout (Dropout) (None, 200) 0 _________________________________________________________ dense_1 (Dense) (None, 100) 20100 _________________________________________________________ dropout_1 (Dropout) (None, 100) 0 _________________________________________________________ dense_2',\n",
       " 'dense_2 (Dense) (None, 10) 1010 ========================================================= Total params: 178,110 Trainable params: 178,110 Non-trainable params: 0 _________________________________________________________',\n",
       " \"我们可以看到模型打印出来的结构跟代码 7-5 中定义的结构是一样的。\\n\\nmodel.summary()可以很方便的打印出模型的结构，并可以看到网络每一层的输出 shape\\n\\n和需要训练的参数 Param，最后还会统计所有需要训练的参数个数。想了解模型结构的时候\\n\\nmodel.summary()可以多使用。\\n\\n7.4 单独保存模型参数\\n\\n7.4.1 保存模型参数\\n\\n有时候我们只对模型的权值参数感兴趣，对模型框架不感兴趣。这个时候我们可以只获取\\n\\n模型的权值参数，我们可以使用：\\n\\nweights = model.get_weights()\\n\\n来获取模型的权值参数，权值保存后会得到一个 list，list 中保存了每一层权值参数的具\\n\\n体数值。获取模型参数以后可以使用：\\n\\nmodel.set_weights(weights)\\n\\n231\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n来对模型进行权值进行重新设置。\\n\\n如果我们想保存模型的参数可以使用：\\n\\nmodel.save_weights('path_to_my_model.h5')\",\n",
       " \"model.save_weights('path_to_my_model.h5')\\n\\n来保存模型参数。参考代码如代码 7-7 所示。\\n\\n代码 7-7：保存模型参数\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropout import numpy as np\\n\\n# 模型定义 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dropout(0.4), Dense(units=100,activation='tanh'), Dropout(0.4), Dense(units=10,activation='softmax') ])\\n\\n# 保存模型参数 model.save_weights('my_model/model_weights')\",\n",
       " \"# 获取模型参数 weights = model.get_weights() # 把 list 转变成 array weights = np.array(weights)\\n\\n# 循环每一层权值 # enumerate 相当于循环计数器，记录当前循环次数 # weights 保存的数据可以对照 print 输出查看 for i,w in enumerate(weights): if i%2==0: print('{}:w_shape:{}'.format(int(i/2+1),w.shape)) else: print('{}:b_shape:{}'.format(int(i/2+0.5),w.shape)) 结果输出为： 1:w_shape:(784, 200) 1:b_shape:(200,) 2:w_shape:(200, 100)\\n\\n232\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 2:b_shape:(100,) 3:w_shape:(100, 10) 3:b_shape:(10,)\\n\\n7.4.2 载入模型参数\\n\\n模型的参数载入很简单，使用：\",\n",
       " \"7.4.2 载入模型参数\\n\\n模型的参数载入很简单，使用：\\n\\nmodel.load_weights('path_to_my_model.h5')\\n\\n就可以载入参数。不过要注意，载入模型参数之前需要把模型先定义好，或者使用\\n\\nmodel_from_json 方法先载入模型。并且如果我们想进一步训练模型的参数的话，不仅要定\\n\\n义好模型结构，载入模型参数。还需要定义 compile 中的内容，包括优化器和代价函数等。\\n\\n因为 model.save()会保存 compile 中的内容，而 model.save_weights 只会保存模型的参\\n\\n数。所以 load_weights 以后还需要重新定义 compile 的内容，才能进一步训练模型。\\n\\n载入模型参数的参考代码如代码 7-8 所示。\\n\\n代码 7-8：载入模型参数\",\n",
       " \"载入模型参数的参考代码如代码 7-8 所示。\\n\\n代码 7-8：载入模型参数\\n\\nfrom tensorflow.keras import Sequential from tensorflow.keras.layers import Flatten,Dense,Dropou # 载入模型参数前需要先把模型定义好 # 模型结构需要与参数匹配 # 或者可以使用 tf.keras.models.model_from_json 载入模型结构 model = Sequential([ Flatten(input_shape=(28, 28)), Dense(units=200,activation='tanh'), Dropout(0.4), Dense(units=100,activation='tanh'), Dropout(0.4), Dense(units=10,activation='softmax') ])\\n\\n# 载入模型参数 model.load_weights('my_model/model_weights.h5')\\n\\n233\",\n",
       " \"233\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.5 ModelCheckpoint 自动保存模型\\n\\n在第 6 章的抵抗过拟合方法中我们学习了 Early-Stopping，我们在学习 Early-Stopping\\n\\n的时候使用了：\\n\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n复习一下，EarlyStopping 是 Callbacks 的一种，callbacks 用于指定在每个 epoch 或\\n\\nbatch 开始和结束的时候进行哪种特定操作。这个部分我们要学习的 ModelCheckpoint 也\\n\\n是 Callbacks 中的一种，用于自动保存模型。\\n\\n其中参数 monitor 可以设置{'val_accuracy','val_loss','accuracy','loss'}，如果设置监测\\n\\n{'val_accuracy','accuracy'}，那么模型准确率大于最大{'val_accuracy','accuracy'}的时候就\",\n",
       " \"会保存模型；如果设置监测{'val_loss','loss'}，那么模型 loss 小于最小{'val_loss','loss'}的时\\n\\n候就会保存模型。ModelCheckpoint 的使用方法和说明参数代码如代码 7-9 所示。\\n\\n代码 7-9：ModelCheckpoint 自动保存模型\",\n",
       " 'import tensorflow as tf from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger # 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ])\\n\\n234\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 定义优化器，代价函数 adam = Adam(0.001) model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\\n\\n# 模型保存位置 output_model = 'ModelCheckpoint/' # log 保存位置 output_log = 'log/'\",\n",
       " \"# ModelCheckpoint 用于自动保存模型 # filepath 可以设置模型保存位置以及模型信息，epoch 表示训练周期数，val_accuracy 表示 验证集准确值 # monitor 可选{'val_accuracy','val_loss','accuracy','loss'},一般'val_accuracy'用得比较多 # verbose=1 表示保存模型的时候打印信息 # save_best_only=True 表示只保存>best_val_accuracy 的模型 # CSVLogger 也是 callbacks，用于生成模型训练的 log callbacks = [ ModelCheckpoint(filepath=output_model+'{epoch:02d}-{val_accuracy:.4f}.h5', monitor='val_accuracy', verbose=1, save_best_only=True), CSVLogger(output_log + 'log.csv') ]\",\n",
       " '# 传入训练集数据和标签训练模型 model.fit(x_train, y_train, epochs=6, batch_size=32, validation_data=(x_test,y_test),\\n\\ncallbacks=callbacks)',\n",
       " 'callbacks=callbacks)\\n\\n结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/6 59744/60000 [============================>.] - ETA: 0s - loss: 0.371 1 - accuracy: 0.8957 ETA: 0s - loss: 0.3733 - accuracy: 0.89 Epoch 00001: val_accuracy improved from -inf to 0.91850, saving model to ModelCheckpoint/01-0.9185.h5 60000/60000 [==============================] - 2s 39us/sample - los s: 0.3709 - accuracy: 0.8958 - val_loss: 0.2899 - val_accuracy: 0.918 5 Epoch 2/6\\n\\n235',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 59072/60000 [============================>.] - ETA: 0s - loss: 0.287 5 - accuracy: 0.9185 Epoch 00002: val_accuracy improved from 0.91850 to 0.92120, saving mo del to ModelCheckpoint/02-0.9212.h5 60000/60000 [==============================] - 2s 39us/sample - los s: 0.2874 - accuracy: 0.9185 - val_loss: 0.2792 - val_accuracy: 0.921 2 Epoch 3/6 59872/60000 [============================>.] - ETA: 0s - loss: 0.276 5 - accuracy: 0.9224 Epoch 00003: val_accuracy',\n",
       " '5 - accuracy: 0.9224 Epoch 00003: val_accuracy improved from 0.92120 to 0.92200, saving mo del to ModelCheckpoint/03-0.9220.h5 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2763 - accuracy: 0.9225 - val_loss: 0.2813 - val_accuracy: 0.922 0 Epoch 4/6 58496/60000 [============================>.] - ETA: 0s - loss: 0.270 2 - accuracy: 0.9243 Epoch 00004: val_accuracy improved from 0.92200 to 0.92630, saving mo del to ModelCheckpoint/04-0.9263.h5 60000/60000',\n",
       " 'del to ModelCheckpoint/04-0.9263.h5 60000/60000 [==============================] - 2s 38us/sample - los s: 0.2701 - accuracy: 0.9243 - val_loss: 0.2696 - val_accuracy: 0.926 3 Epoch 5/6 59936/60000 [============================>.] - ETA: 0s - loss: 0.265 8 - accuracy: 0.9261 Epoch 00005: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2658 - accuracy: 0.9261 - val_loss: 0.2766 - val_accuracy: 0.925 4 Epoch 6/6 58816/60000',\n",
       " '- val_accuracy: 0.925 4 Epoch 6/6 58816/60000 [============================>.] - ETA: 0s - loss: 0.261 7 - accuracy: 0.9269 Epoch 00006: val_accuracy did not improve from 0.92630 60000/60000 [==============================] - 2s 36us/sample - los s: 0.2624 - accuracy: 0.9267 - val_loss: 0.2866 - val_accuracy: 0.921 7',\n",
       " '从输出结果我们就可以看出并不是每一个周期模型都会保存，只有 val_accuracy 大于之\\n\\n前最大的 val_accuracy，模型才会保存。程序训练 6 个周期以后用来保存模型的文件夹得到\\n\\n了 4 个模型，如图 7.2 所示。\\n\\n236\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 7.2 ModelCheckPoint 自动保存模型\\n\\n从模型的文件名我们就可以看出模型是训练了多少个周期得到的，并且还可以看出模型\\n\\n的 val_accuracy 准确率，只有得到越来越大的 val_accuracy 模型才会保存。训练第 5 第 6\\n\\n周期的时候，模型的 val_accuracy 没有超过第 4 个周期的 0.9263，所以第 5 第 6 周期的模\\n\\n型没有保存。\\n\\n训练结束之后我们还会得到一个 CSV 格式的 log 文件，log 文件中的内容如图 7.3 所\\n\\n示。\\n\\n图 7.3 模型训练 log 文件\\n\\n在 log 文件中包含了模型训练每个周期的训练集准确率，训练集 loss，验证集准确率，\\n\\n验证集 loss。\\n\\n237',\n",
       " '验证集 loss。\\n\\n237\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n7.6 Checkpoint 模型保存和载入\\n\\n7.6.1 Checkpoint 模型保存\\n\\n在 Tensorflow2 中我们也可以使用 Checkpoint 来保存和载入模型，用法跟\\n\\nTensorflow1 有些区别，具体使用方法可以参考下面的例子，如代码 7-10 所示。\\n\\n代码 7-10：Checkpoint 模型保存',\n",
       " 'import tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建 dataset 对象',\n",
       " \"= mnist_train.batch(32) # 创建 dataset 对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练 loss train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算\",\n",
       " '238',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 测试 loss test_loss = tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy') # 模型训练 @tf.function def train_step(data, label): with tf.GradientTape() as tape: # 传入数据预测结果 predictions = model(data) # 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 计算权值调整 gradients = tape.gradient(loss,\",\n",
       " '# 计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)',\n",
       " \"# 模型测试 @tf.function def test_step(data, label): # 传入数据预测结果 predictions = model(data) # 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)\\n\\n# 定义模型保存，保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # 用于管理模型 # ckpt 为需要保存的内容 # 'tf2_ckpts'为模型保存位置 # max_to_keep 设置最多保留几个模型 manager = tf.train.CheckpointManager(ckpt, 'tf2_ckpts', max_to_keep=3)\\n\\nEPOCHS = 5 # 训练 5 个周期 for epoch in range(EPOCHS):\\n\\n239\",\n",
       " \"239\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 循环 60000/32=1875 次 for image, label in mnist_train: # 训练模型 train_step(image, label) # 循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 测试模型 test_step(test_image, test_label)\\n\\n# 打印结果 template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}' print (template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result()))\\n\\n# 保存模型 # checkpoint_number 设置模型编号\",\n",
       " '# 保存模型 # checkpoint_number 设置模型编号\\n\\nmanager.save(checkpoint_number=epoch)\\n\\n结果输出为： Epoch 1, Loss: 0.0127, Accuracy: 0.919, Test Loss: 0.0125, Test Accur acy: 0.917 Epoch 2, Loss: 0.0125, Accuracy: 0.921, Test Loss: 0.0124, Test Accur acy: 0.918 Epoch 3, Loss: 0.0123, Accuracy: 0.922, Test Loss: 0.0123, Test Accur acy: 0.918 Epoch 4, Loss: 0.0121, Accuracy: 0.923, Test Loss: 0.0123, Test Accur acy: 0.919 Epoch 5, Loss: 0.0119, Accuracy: 0.924, Test Loss: 0.0122, Test Accur acy: 0.92',\n",
       " '7.6.2 Checkpoint 模型载入\\n\\n实现 Checkpoint 模型载入的代码如代码 7-11 所示。\\n\\n代码 7-11：Checkpoint 模型载入\\n\\nimport tensorflow as tf # 载入数据集 mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n240',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 归一化 x_train, x_test = x_train / 255.0, x_test / 255.0 # 标签转独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10) # 创建 dataset 对象 mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 训练周期 mnist_train = mnist_train.repeat(1) # 批次大小 mnist_train = mnist_train.batch(32) # 创建 dataset 对象 mnist_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 训练周期 mnist_test',\n",
       " \"y_test)) # 训练周期 mnist_test = mnist_test.repeat(1) # 批次大小 mnist_test = mnist_test.batch(32) # 模型定义 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(10, activation='softmax') ]) # 优化器定义 optimizer = tf.keras.optimizers.SGD(0.1) # 训练 loss train_loss = tf.keras.metrics.Mean(name='train_loss') # 训练准确率计算 train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') # 测试 loss test_loss = tf.keras.metrics.Mean(name='test_loss') #\",\n",
       " \"= tf.keras.metrics.Mean(name='test_loss') # 测试准确率计算 test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy') # 模型训练 @tf.function def train_step(data, label): with tf.GradientTape() as tape: # 传入数据预测结果 predictions = model(data) # 计算 loss loss = tf.keras.losses.MSE(label, predictions) # 计算权值调整 gradients = tape.gradient(loss, model.trainable_variables) # 进行权值调整 optimizer.apply_gradients(zip(gradients, model.trainable_variables))\",\n",
       " '241\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 计算平均 loss train_loss(loss) # 计算平均准确率 train_accuracy(label, predictions)\\n\\n# 模型测试 @tf.function def test_step(data, label): # 传入数据预测结果 predictions = model(data) # 计算 loss t_loss = tf.keras.losses.MSE(label, predictions) # 计算平均 loss test_loss(t_loss) # 计算平均准确率\\n\\ntest_accuracy(label, predictions)',\n",
       " \"# 定义 Checkpoint，用于保存优化器和模型参数 ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model) # restore 载入 Checkpoint # latest_checkpoint 表示载入编号最大的 Checkpoint ckpt.restore(tf.train.latest_checkpoint('tf2_ckpts/')) # 载入模型后继续训练 EPOCHS = 5 # 训练 5 个周期 for epoch in range(EPOCHS): # 循环 60000/32=1875 次 for image, label in mnist_train: # 训练模型 train_step(image, label) # 循环 10000/32=312.5->313 次 for test_image, test_label in mnist_test: # 测试模型 test_step(test_image, test_label) # 打印结果 template = 'Epoch {},\",\n",
       " \"test_label) # 打印结果 template = 'Epoch {}, Loss: {:.3}, Accuracy: {:.3}, Test Loss: {:.3}, Test Accuracy: {:.3}' print (template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(),\",\n",
       " 'test_accuracy.result()))\\n\\n结果输出为： Epoch 1, Loss: 0.0105, Accuracy: 0.934, Test Loss: 0.0116, Test Accur acy: 0.925\\n\\n242\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 243 Epoch 2, Loss: 0.0105, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 3, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 4, Loss: 0.0104, Accuracy: 0.935, Test Loss: 0.0116, Test Accur acy: 0.925 Epoch 5, Loss: 0.0103, Accuracy: 0.936, Test Loss: 0.0116, Test Accur acy: 0.925',\n",
       " '这一章节我们学习了 Tensorflow2 中 3 种模型保存的方式，使用 tf.keras 接口把模型保\\n\\n存为 h5 的文件，保存 SavedModel 格式的模型以及保存 Checkpoint 模型。\\n\\n学习完神经网络和 Tensorflow 的基础知识，下一章节我们将开始介绍深度学习算法。\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 8 章-卷积神经网络 CNN\\n\\n计算机视觉是人工智能领域最热门的研究领域之一，并且是近几年发展最快的人工智能领\\n\\n域之一 。 10 年 前 的 人 们 一 定想 象不 到如 今的 计算 机视觉可 以做到如此优秀的水平 ，\\n\\nCV(Computer Vision)领域的快速发展主要得益于卷积神经网络的使用。\\n\\n8.1 计算机视觉介绍\\n\\n8.1.1 计算机视觉应用介绍\\n\\n如今计算机视觉的应用已经深入到我们生活中的方方面面，有着许多的实际应用。\\n\\n人脸识别：使用在高铁进站，酒店住宿，公司门禁等场景下，如图 8.1 所示。\\n\\n图 8.1 人脸识别',\n",
       " '图 8.1 人脸识别\\n\\n图像检索：使用在搜索引擎的图片搜索中，以及电商网站的商品检索等，如图 8.2 所示。\\n\\n244\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.2 图像检索\\n\\n监控：使用在公共场所中用于检测行人车辆的流量以及可疑行为等，如图 8.3 所示。\\n\\n图 8.3 监控\\n\\n光学字符识别 OCR：证件识别，车牌识别，文档识别，银行卡识别，名片识别，身份证识\\n\\n别等，如图 8.4 所示。\\n\\n245\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.4 OCR\\n\\n自动驾驶：检测交通标志，路上行人和车辆等，如图 8.5 所示。\\n\\n图 8.5 自动驾驶\\n\\n8.1.2 计算机视觉技术介绍\\n\\n计算机视觉包含很多中技术，下面我们简单介绍 5 种计算机视觉的常用技术。\\n\\n1.图像分类：\\n\\n246\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图像分类就是图像识别，识别一张图片中的物体，然后给出类别判断。一般对一张图片我',\n",
       " '图像分类就是图像识别，识别一张图片中的物体，然后给出类别判断。一般对一张图片我\\n\\n们可能会得到多个类别判断，我们可以根据类别的置信度（模型认为图片属于该类别的概率）\\n\\n从高到低进行排序，然后得到可能性最大的几个类别，如图 8.6 所示。\\n\\n图 8.6 图像分类\\n\\n2.目标检测\\n\\n有时候我们不仅要识别图片是属于什么类别，还需要把它们给框选出来，\\n\\n确定它们在图片中的位置和大小。如图 8.7 所示。\\n\\n图 8.7 目标检测[1]\\n\\n3.目标跟踪\\n\\n247\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n目标跟踪是指在特定场景跟踪某一个或多个特定感兴趣对象的过程，如图 8.6 所示。\\n\\n图 8.6 目标跟踪[2]\\n\\n4.语义分割\\n\\n语义分割可以将图像分为不同的语义可解释类别，例如我们可能会把图片中汽车的颜色\\n\\n都用蓝色的表示，所有行人用红色表示。与图像分类或目标检测相比，语义分割可以让我们\\n\\n对图像有更加细致的了解，如图 8.7 所示。\\n\\n图 8.7 语义分割[3]\\n\\n5.实例分割',\n",
       " '对图像有更加细致的了解，如图 8.7 所示。\\n\\n图 8.7 语义分割[3]\\n\\n5.实例分割\\n\\n实例分割可以将不同类型的实例进行分类，比如用 4 种颜色来表示 4 辆不同的汽车，用\\n\\n8 种颜色表示 8 个不同的人，如图 8.8 所示。\\n\\n248\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.8 实例分割[4]\\n\\n8.2 卷积神经网简介\\n\\n卷积神经网络就是一种包含卷积计算的神经网络。卷积计算是一种计算方式，有一个卷积\\n\\n窗口（Convolution Window）在一个平面上滑动，每次滑动会进行一次卷积计算得到一个\\n\\n数值，卷积窗口滑动计算完成后会得到一个用于表示图像特征的特征图（Feature Map）。下\\n\\n面是一个忽略具体数值计算的卷积计算流程，具体的卷积数值计算在后面的内容再进行详细介\\n\\n绍：用一个 3×3 的卷积窗口对 4×4 的图片求卷积，卷积的移动步长为 1，最后得到 2×2 的特\\n\\n征图，如图 8.9 所示。\\n\\n249\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.9 卷积计算',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.9 卷积计算\\n\\n8.2.1 BP 神经网络存在的问题\\n\\n在前面的章节中我们使用了 BP 神经网络来处理 MNIST 手写数字识别的任务，并且得到\\n\\n了还不错的识别效果。有一个细节问题当时我们可能没有注意到，当时我们使用的手写数字图\\n\\n片是 28×28 的黑白图片，输入数据一共有 28×28×1 个数据，所以输入层只需要 784 个神经\\n\\n元。假如我们有一张 1000×1000 的彩色图片，那么输入层神经元就需要 1000×1000×3 个，\\n\\n我们使用带有一个隐藏层的神经网络，隐藏层神经元个数为 1000，那么输入层和隐藏层之间\\n\\n权值的个数就会有 30 亿个，这是一个非常巨大的数字。\\n\\n如此大量的权值会带来两个问题，一个问题是计算量巨大，要计算这么多权值就需要花费\\n\\n大量时间。第二个问题是要训练这么多权值就需要大量的训练样本来进行训练，防止模型过拟\\n\\n合。\\n\\n因此我们需要使用卷积神经网络解决计算机视觉任务中权值数量巨大的问题。\\n\\n250',\n",
       " '合。\\n\\n因此我们需要使用卷积神经网络解决计算机视觉任务中权值数量巨大的问题。\\n\\n250\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.2.2 局部感受野和权值共享\\n\\n卷积网络跟神经网络一样，也是受到了生物学的启发。 20 世纪 60 年代神经生理学家\\n\\nHubel 和 Wiesel 通过研究猫的视觉感受野（Receptive field of vision）提出的视觉神经系\\n\\n统的层级结构模型，从简单细胞到复杂细胞、超复杂细胞的层级信息处理结构。他们的研究成\\n\\n果在 1981 年获得诺贝尔生理学或医学奖。\\n\\n卷积神经网络的设计借鉴了 Hubel 和 Wiesel 的研究，在卷积网络中使用了局部感受野\\n\\n（Local Receptive Field）。卷积层中的神经元连接不是全连接的，而是后一层的每个神经元\\n\\n连接前一层的一部分神经元。如图 8.10 所示，左边为 BP 网络的全连接结构，右边为卷积网\\n\\n络的局部连接结构。\\n\\n图 8.10 全连接和局部连接\\n\\n图中一条连线就是一个权值，如果神经元不是全连接，那么权值就减少了很多。此外卷积',\n",
       " '图中一条连线就是一个权值，如果神经元不是全连接，那么权值就减少了很多。此外卷积\\n\\n神经网络还用到了权值共享（Weight Sharing）。这里的权值共享指的是同一卷积层中的同\\n\\n一个卷积窗口的权值是共享的。使用 3×3 的卷积窗口（也就是后一层的一个神经元连接前一\\n\\n层 3×3 的区域）对 1000×1000 的图片求卷积， 那么大家思考一下输入层和卷积层之间一共\\n\\n有多少个权值需要训练？\\n\\n251\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n现在公布答案，使用 3×3 的卷积窗口对 1000×1000 的图片求卷积，一共有 9 个权值加\\n\\n1 个偏置值需要训练。3×3 的卷积窗口就有 9 个权值，1 个卷积窗口还会有 1 个偏置值。卷\\n\\n积窗口在进行滑动计算的时候窗口内的 9 个权值是权值共享的，所以一共只有 9 个权值。同\\n\\n理，假设使用 5×5 的卷积窗口对 500×500 的图片求卷积，一共有 25 个权值加 1 个偏置值\\n\\n训练训练。卷积层的权值数量跟被卷积的图片大小无关，跟卷积步长也无关，跟卷积窗口的\\n\\n大小相关。',\n",
       " '训练训练。卷积层的权值数量跟被卷积的图片大小无关，跟卷积步长也无关，跟卷积窗口的\\n\\n大小相关。\\n\\n8.3 卷积的具体计算\\n\\n下面我们来讲解一下卷积的具体计算流程。卷积窗口又称为 卷积核（ Convolution\\n\\nKernel），卷积之后生成的图称为特征图。卷积窗口/卷积核一般都是使用正方形的，比如 1×\\n\\n1，3×3，5×5 等，极少数特殊情况才会使用长方形。对一张图片求卷积实际上就是卷积核在\\n\\n图片上面滑动，并进行卷积计算。卷积计算很简单，就是卷积核与图片中对应位置的数值相乘\\n\\n然后再求和。我们可以通过下面的具体例子来理解，假设我们有一个 3×3 的卷积核，如图 8.11\\n\\n所示。\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n0\\n\\n1\\n\\n图 8.11 3×3 的卷积核\\n\\n然后我们使用该卷积核，对 4×4 的图片求卷积，图片如下，图 8.12 所示。\\n\\n252\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n1\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n1\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n1\\n\\n图 8.12 4×4 的图片',\n",
       " '1\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n1\\n\\n1\\n\\n0\\n\\n0\\n\\n0\\n\\n1\\n\\n图 8.12 4×4 的图片\\n\\n3×3 的卷积核对 4×4 的图片求卷积，步长为 1，可以分为 4 个步骤，第一步，对左上方\\n\\n9 个数求卷积，如图 8.13 所示。\\n\\n图 8.13 卷积第一步\\n\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n\\n卷积第二步如图 8.14 所示。\\n\\n253\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.14 卷积第二步\\n\\n具体卷积计算为：1×1+0×1+1×0+0×1+1×1+0×1+1×0+0×1+1×1=3。\\n\\n卷积第三步如图 8.15 所示。\\n\\n图 8.15 卷积第三步\\n\\n具体卷积计算为：1×0+0×1+1×1+0×0+1×0+0×1+1×0+0×0+1×0=2。\\n\\n卷积第四步如图 8.16 所示。\\n\\n254\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.16 卷积第四步',\n",
       " '图 8.16 卷积第四步\\n\\n具体卷积计算为：1×1+0×1+1×1+0×0+1×1+0×1+1×0+0×0+1×1=4。\\n\\n卷积的符号一般用“*”表示，上述的卷积计算如图 8.17 所示。\\n\\n图 8.17 卷积计算\\n\\n8.4 卷积的步长\\n\\n卷积的步长指的是卷积每一次移动的步数，前面我们列举的例子中，卷积的步长为 1，卷\\n\\n积的步长理论上可以取任意正整数。图 8.18 中的例子是步长为 2 的卷积.\\n\\n255\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.18 步长为 2 的卷积\\n\\n下图 8.19 为步长为 3 的卷积计算.\\n\\n图 8.19 步长为 3 的卷积\\n\\n8.5 不同的卷积核\\n\\n使用不同的卷积核来对同一张图片求卷积会得到不同的结果，如图 8.20 和图 8.21 所示。\\n\\n256\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.20 使用不同卷积核求卷积（1）\\n\\n图 8.21 使用不同卷积核求卷积（2）\\n\\n所以在卷积神经网络中，我们通常会使用多个不同的卷积核来对同一图像求卷积，目的',\n",
       " '所以在卷积神经网络中，我们通常会使用多个不同的卷积核来对同一图像求卷积，目的\\n\\n就是为了可以提取出图像中多种不同的特征。\\n\\n那么卷积核的取值要怎么取？如果是使用传统的机器学习思维，我们能想到的方法可能\\n\\n是人为设计大量不同的卷积核，然后使用大量图片来做测试，最后分析哪种卷积核提取出来\\n\\n的特征比较有效。\\n\\n那在深度学习里面，卷积核中的数值实际上就是卷积核的权值。所以说卷积核的取值在\\n\\n卷积神经网络训练最开始的阶段是随机初始化的，之后结合误差反向传播算法，逐渐训练得\\n\\n到最终的结果。训练好的卷积核就可以作为特征提取器，用于提取图像特征，然后传到网络\\n\\n后面的全连接层，用于分类回归等任务。\\n\\n在同一个卷积核中的权值是共享的，在不同的卷积核中的权值是不共享的。假设使用 6\\n\\n个 5×5 的卷积核对一幅图像求卷积，会产 6×5×5=150 个权值加 6 个偏置值，卷积后会得\\n\\n到 6 个不同的特征图，如图 8.22 所示。\\n\\n257\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.22 使用多个卷积核计算\\n\\n8.6 池化（Pooling）',\n",
       " '图 8.22 使用多个卷积核计算\\n\\n8.6 池化（Pooling）\\n\\n一个经典的卷积层包含 3 部分，卷积计算->非线性激活函数->池化（Pooling），如图 8.23\\n\\n所示。\\n\\n图 8.23 经典卷积层的 3 部分\\n\\n池化也有一个滑动窗口在图像中进行滑动计算，这一点跟卷积有点类似，不过池化层中\\n\\n没有需要训练的权值。\\n\\n我们通常会使用多个不同的卷积核来对图像求卷积，之后生成很多个不同的特征图，卷\\n\\n积网络中的权值参数仍然是很多的。池化的一个作用是可以做进一步的特征提取，减少权值\\n\\n参数的个数。\\n\\n258\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n池化的另一个作用是使得网络的输入具有平移不变形。平移不变形指的是当我们对输入\\n\\n进行少量平移时，经过池化后的数值并不会发生太大变化。这是一个非常有用的性质，因为\\n\\n我们通常关心的是某个特征是否在图像中出现，而不是关心这个特征具体出现的位置。例如\\n\\n我们要判断一张图片中是否有猫，我们并不关心猫是出现在图片上方，还是下方，还是左\\n\\n边，还是右边，我们只关心猫是否出现在图片中，如图 8.24 所示。',\n",
       " '边，还是右边，我们只关心猫是否出现在图片中，如图 8.24 所示。\\n\\n图 8.24 平移不变形\\n\\n不过稍微要注意的是我们对输入进行少量平移时，经过池化后的数值并不会发生太大变化。\\n\\n如果对输入平移太多时，池化后的数值还是会发生较大变化的。\\n\\n池化也有池化窗口，对图像进行扫描计算，这一点跟卷积类似。池化通常可以分为三种方\\n\\n式， 最大池化（ Max-Pooling），平均池化（ Mean-Pooling）和随机池化（ Stochastic\\n\\nPooling）。最大池化指的是提取池化窗口区域内的最大值，平均池化指的是提取池化窗口区\\n\\n域内的平均值，随机池化指的是提取池化窗口区域内的随机值，其中最常用的是最大池化。常\\n\\n用的池化窗口大小为 2×2，步长为 2。\\n\\n池化窗口大小为 2×2，步长为 2 的最大池化计算如图 8.25 所示。\\n\\n259\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.25 最大池化\\n\\n池化窗口大小为 2×2，步长为 2 的平均池化计算如图 8.26 所示。\\n\\n图 8.26 平均池化',\n",
       " '图 8.26 平均池化\\n\\n随机池化就是从池化窗口中随机取一个值，一般用得比较少。\\n\\n8.7 Padding\\n\\n在卷积神经网络中我们通常会堆叠多个卷积层的结构，形成一个深度的卷积神经网络。\\n\\n堆叠多个卷积层结构会碰到一个问题，那就是每一次做卷积，得到的特征图就会比原来的图\\n\\n像要变小一些，这样特征的数量会不断减少。例如使用 3×3 的卷积核对 4×4 的图像求卷\\n\\n积，步长为 1，卷积后得到一个 2×2 的特征图，如图 8.27 所示。\\n\\n260\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.27 卷积后得到的特征图比原图像小\\n\\n另外在计算卷积的时候图像中间的数据会重复使用多次，而图像边缘的数据可能只会被用\\n\\n到一次。图 8.28 表示，使用 3×3 的卷积核对 4×4 的图像求卷积，步长为 1。\\n\\n图 8.28 边缘数据计算次数较少\\n\\n图 8.28 中四个角的四个数据只计算了一次，而图像中心的四个数据则计算了四次，这就\\n\\n表示卷积容易丢失掉图像的边缘特征（不过其实边缘位置的信息一般来说也没这么重要）。',\n",
       " '表示卷积容易丢失掉图像的边缘特征（不过其实边缘位置的信息一般来说也没这么重要）。\\n\\n针对上述两个问题，我们可以使用 Padding 的方式来解决。卷积和池化操作都可以使用\\n\\nPadding，Padding 一般有两种方式，一种是 Valid Padding，还有一种是 Same Padding。\\n\\n261\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nValid Padding 其实就是不填充。不填充数据那么卷积后得到的特征图就会比原始图像要\\n\\n小一点，如图 8.29 所示。\\n\\n图 8.29 Valid Padding\\n\\nSame Padding 指的是通过填充数据（一般都是填充 0），使得卷积后的特征图的大小跟\\n\\n原始的图像大小相同，如图 8.30 所示。\\n\\n图 8.30 Same Padding\\n\\n262\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n上图中使用 3×3 的卷积核对 5×5 的图像进行求卷积的操作，步长为 1。给原图像外圈填',\n",
       " '上图中使用 3×3 的卷积核对 5×5 的图像进行求卷积的操作，步长为 1。给原图像外圈填\\n\\n充 1 圈 0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同，也是 5×5 的大小。\\n\\n同理如果使用 5×5 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 2\\n\\n圈 0 之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n\\n如果使用 7×7 的卷积核对图像进行求卷积的操作，步长为 1，给原图像外圈填充 3 圈 0\\n\\n之后再做卷积，卷积后得到的特征图大小就可以跟原始图像相同。\\n\\n这也是为什么卷积核经常使用单数×单数，因为我们可以通过填充 0 的方式得到与原始图\\n\\n像大小相同的特征图。\\n\\nSame Padding 还有另外一种理解方式，就是当步长不为 1 的时候，Same Padding 指\\n\\n的是可能会给平面外部补 0。下面举两个例子：\\n\\n例 1：假如有一个 28×28 的图像，用 2×2 步长为 2 的池化窗口对其进行池化的操作，使\\n\\n用 Same Padding 的方式，池化后得到 14×14 的特征图；使用 Valid Padding 的方式，池化',\n",
       " '后得到 14×14 的特征图。两种 Padding 方式得到的结果是相同的。\\n\\n例 2：假如有一个 2×3 的图像，用 2×2 步长为 2 的池化窗口对其进行池化的操作，使用\\n\\nSame Padding 的方式，池化后得到 1×2 的特征图；使用 Valid Padding 的方式，池化后得\\n\\n到 1×1 的特征图。Same Padding 给原图像补了 0，所以可以进行 2 次池化计算，而 Valid\\n\\nPadding 不会给图像补 0，所以只能进行 1 次池化计算。\\n\\n263\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.8 常见的卷积计算总结\\n\\n8.8.1 对 1 张图像进行卷积生成 1 张特征图\\n\\n对 1 张图像进行卷积生成 1 张特征图是最简单的一种卷积方式，前面我们已经进行了详\\n\\n解的举例计算，如图 8.31 所示。\\n\\n图 8.31 对 1 张图像进行卷积生成 1 张特征图\\n\\n假如我们只统计乘法的计算量，图中一种进行了 3×3×4 次乘法计算。总共有 9 个权值和\\n\\n1 个偏置值需要训练。',\n",
       " '1 个偏置值需要训练。\\n\\n8.8.2 对 1 张图像进行卷积生成多张特征图\\n\\n生成多张特征图需要使用多个不同的卷积核，使用多个不同的卷积核来求卷积。这里我们\\n\\n使用 3 个不同的 5×5 大小的卷积核对 28×28 的图像求卷积，使用 Same Padding 的方式，\\n\\n步长为 1，卷积计算后生成 3 个不同的特征图，如图 8.32 所示。\\n\\n264\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.32 对 1 张图像进行卷积生成多张特征图\\n\\n因为每个卷积核中的权值不同，所以使用 3 个不同的卷积核求卷积会得到 3 个不同的特\\n\\n征图。一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28\\n\\n×28×3=58800。总共有 5×5×3=75 个权值和 3 个偏置值需要训练。偏置值数量主要跟特征\\n\\n图数量相关，每个特征图有 1 个偏置值。\\n\\n8.8.3 对多张图像进行卷积生成 1 张特征图\\n\\n比如我们多 1 张彩色图片求卷积，彩色图片可以看成是 RGB 三原色的组合，所以可以看',\n",
       " '比如我们多 1 张彩色图片求卷积，彩色图片可以看成是 RGB 三原色的组合，所以可以看\\n\\n成是 3 张图像。这里我们对 3 张 28×28 的图像求卷积，卷积窗口大小为 5×5，使用 Same\\n\\nPadding 的方式，步长为 1，卷积计算后生成 1 张特征图，如图 8.33 所示。\\n\\n265\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 8.33 对多张图像进行卷积生成 1 张特征图\\n\\n对 3 张图像进行卷积的时候先分别对每张图像进行卷积，得到 3 个大小相同，数值不同\\n\\n的特征图。然后再对每个特征图对应位置的数值进行相加，最后得到 1 个特征图。\\n\\n一个卷积核会对原始图像进行 5×5×28×28 次乘法计算，所以总共计算量为 5×5×28×\\n\\n28×3=58800。这里要注意，我们对不同图像进行卷积的时候，所使用的卷积核也是不同的，\\n\\n所以总共有 5×5×3=75 个权值和 1 个偏置值需要训练。\\n\\n这里我们把对多张图像进行卷积的多个不同的卷积核称为一个滤波器（Filter），一个滤波',\n",
       " '这里我们把对多张图像进行卷积的多个不同的卷积核称为一个滤波器（Filter），一个滤波\\n\\n器可以产生一个特征图。在我们写程序搭建网络结构的时候，我们需要定义卷积层 Filter 的数\\n\\n量，实际上就是在定义卷积后生成的特征图的数量。\\n\\n8.8.4 对多张图像进行卷积生成多张特征图\\n\\n对多张图像进行卷积生成多张特征图相对来说最难理解同时也是最常见的情况。在卷积网\\n\\n络中，很多时候都需要对多张图像进行卷积然后生成多张特征图。这里我们使用 128 个滤波\\n\\n266\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n器对 64 张 28×28 的图像求卷积，使用 Same Padding 的方式，步长为 1，卷积计算后生成\\n\\n128 个不同的特征图。每个滤波器由 64 个不同的 5×5 卷积核组成，如图 8.34 所示。\\n\\n图 8.34 对多张图像进行卷积生成多张特征图\\n\\n下面我们来分析一下上面这个例子的计算量和权值数量。1 个滤波器对 64 张图像进行卷\\n\\n积，得到 1 张特征图。1 个滤波器中有 64 个不同的 5×5 卷积核。每个 5×5 卷积核对 1 张图',\n",
       " '像求卷积。\\n\\n1 个卷积核对 1 张图片求卷积的计算量是 5×5×28×28，所以 1 个滤波器 64 个卷积核的\\n\\n计算量是 5×5×28×28×64。一共有 128 个不同的滤波器，所以总的计算量是 5×5×28×28\\n\\n×64×128=160563200。\\n\\n每个卷积核有 5×5 个权值，1 个滤波器有 64 个卷积核有 5×5×64 个权值，128 个滤波\\n\\n器有 5×5×64×128=204800 个权值，加上 128 个偏置值。\\n\\n267\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.9 经典的卷积神经网络\\n\\n前面的内容中我们介绍了很多卷积神经网络相关的知识点，不过大家可能对一个完整的卷\\n\\n积神经网络的结构可能还不太了解。常见的卷积神经网络结构实际上是多个卷积层叠加起来之\\n\\n后再加上全连接层构成的。有些卷积网络有几十层或者几百层，实际上就是因为网络内部的卷\\n\\n积层的数量比较多，如图 8.35 所示是一个比较典型卷积网络结构。\\n\\n图 8.35 识别猫的卷积神经网络',\n",
       " '图 8.35 识别猫的卷积神经网络\\n\\n卷积神经网前面的部分进行卷积池化相当于是进行特征提取，后面部分进行全连接相当于\\n\\n是利用提取出来的图像特征进行分类。\\n\\n我们还可以把卷积神经网络应用于 MNIST 手写数字识别，如图 8.36 所示。\\n\\n图 8.36 卷积神经网络应用于手写数字识别\\n\\n268\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n为了能让大家看到一目了然的图，我也特地花了一些时间来研究如何画网络结构以及如何\\n\\n表示图中的计算流程，后面的内容中大家还会看到更多类似上图的网络结构图。图中的 s 表示\\n\\nstride，s1 代表卷积或池化的步长为 1，s2 代表卷积或池化的步长为 2，以此类推；conv 是\\n\\n卷积（convolution）的缩写；pool 表示最大池化（max pooling），fc 表示全连接（fully\\n\\nconnected）。\\n\\n图中原始的手写数字的图片是一张 28×28 的图片，并且是黑白的，所以图片的通道数是\\n\\n1，输入数据是 28×28×1 的数据，如果是彩色图片，图片的通道数就为 3。',\n",
       " '1，输入数据是 28×28×1 的数据，如果是彩色图片，图片的通道数就为 3。\\n\\n该网络结构是一个 4 层的卷积神经网络（计算神经网络层数的时候，有权值的才算是一\\n\\n层，比如池化层就不能单独算一层）。第 1 层为卷积层，使用 32 个 5×5 的卷积核对原始图片\\n\\n求卷积，步长为 1，Same Padding。因为是 Same Padding 并且步长为 1，所以卷积后的特\\n\\n征图大小跟原图片一样，可以得到 32 张 28×28 的特征图。池化的计算是在卷积层中进行的，\\n\\n使用 2×2，步长为 2 的池化窗口做池化计算，池化后得到 32 张 14×14 的特征图。特征图的\\n\\n长宽都变成了之前的 1/2。权值的数量为 5×5×32=800，偏置值数量为 32（1 个特征图会有\\n\\n1 个偏置值）。\\n\\n第 2 层也是卷积层，使用 64 个 5×5 的卷积核对 32 张 14×14 的特征图求卷积，步长为\\n\\n1，Same Padding。因为是 Same Padding 并且步长为 1，所以卷积后的特征图大小跟原图',\n",
       " '片一样，可以得到 64 张 14×14 的特征图。这里对 32 个特征图求卷积产生出 64 个特征图涉\\n\\n及到前面我们介绍的对多张图像进行卷积生成多张特征图。\\n\\n对多张特征图求卷积，相当于是同时对多张特征图进行特征提取。同一个特征图中权值是\\n\\n共享的，不同的特征图之间权值是不同的。对 32 张图像求卷积产生 1 个特征图，需要使用 32\\n\\n个不同的 5×5 的卷积核，那么就会有 5×5×32=800 个连接，800 个权值。\\n\\n269\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n所以在我们现在看到的这个例子中，第 2 个卷积层卷积窗口大小 5×5，对 32 张图像求卷\\n\\n积产生 64 个特征图，参数个数是 5×5×32×64=51200 个权值加上 64 个偏置（1 个特征图\\n\\n会有 1 个偏置值）。\\n\\n池化的计算是在卷积层中进行的，使用 2×2，步长为 2 的池化窗口做池化计算，池化后\\n\\n得到 64 张 7×7 的特征图。特征图的长宽都变成了之前的 1/2。',\n",
       " '得到 64 张 7×7 的特征图。特征图的长宽都变成了之前的 1/2。\\n\\n第 3 层是全连接层，第 2 个池化层之后的 64×7×7 个神经元跟 1024 个神经元做全连接。\\n\\n第 4 层是输出层，输出 10 个预测值，对应 0-9 的 10 个数字。\\n\\n这个例子中卷积后产生的特征图的个数 32，64 是属于卷积神经网络中的超参数，需要我\\n\\n们自己调节和设置，也可以修改为其他值，一般设置为 2 的倍数。特征图数量越多说明卷积网\\n\\n络提取的特征数量越多，如果特征图数量设置得太少容易出现欠拟合，如果特征图数量设置得\\n\\n太多容易出现过拟合，所以需要设置为合适的数值。\\n\\n8.10 卷积神经网络应用于 MNIST 数据集分类\\n\\n实现卷积神经网络应用于 MNIST 数据集分类的代码如代码 8-1 所示。\\n\\n代码 8-1：卷积神经网络应用于 MNIST 数据集分类',\n",
       " '代码 8-1：卷积神经网络应用于 MNIST 数据集分类\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam # 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在 tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式 # 这 4 个维度是(数据数量，图片高度，图片宽度，图片通道数)\\n\\n270',\n",
       " '270\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 所以这里把数据 reshape 变成 4 维数据，黑白图片的通道数是 1，彩色图片通道数是 3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 定义顺序模型 model = Sequential() # 第一个卷积层 # input_shape 输入数据 # filters 滤波器个数 32，生成 32 张特征图 # kernel_size 卷积窗口大小 5*5 # strides 步长 1 # padding padding 方式 same/valid # activation 激活函数 model.add(Convolution2D( input_shape = (28,28,1), filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu' )) # 第一个池化层 # pool_size 池化窗口大小 2*2 # strides 步长 2 # padding padding 方式 same/valid model.add(MaxPooling2D( pool_size = 2, strides = 2, padding = 'same', )) # 第二个卷积层 # filters 滤波器个数 64，生成 64\",\n",
       " \"= 'same', )) # 第二个卷积层 # filters 滤波器个数 64，生成 64 张特征图 # kernel_size 卷积窗口大小 5*5 # strides 步长 1 # padding padding 方式 same/valid # activation 激活函数 model.add(Convolution2D(64,5,strides=1,padding='same',activation='relu')) # 第二个池化层 # pool_size 池化窗口大小 2*2 # strides 步长 2 # padding padding 方式 same/valid\",\n",
       " '271',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model.add(MaxPooling2D(2,2,'same')) # 把第二个池化层的输出进行数据扁平化 # 相当于把(64,7,7,64)数据->(64,7*7*64) model.add(Flatten()) # 第一个全连接层 model.add(Dense(1024,activation = 'relu')) # Dropout model.add(Dropout(0.5)) # 第二个全连接层 model.add(Dense(10,activation='softmax')) # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型\",\n",
       " \"# 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test, y_test)) # 保存模型 model.save('mnist.h5') 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 73s 1ms/sample - los s: 0.3466 - accuracy: 0.8985 - val_loss: 0.0953 - val_accuracy: 0.970 6 Epoch 2/10 60000/60000 [==============================] - 72s 1ms/sample - los s: 0.0986 - accuracy: 0.9706 - val_loss: 0.0601 - val_accuracy: 0.980 4 …… Epoch 9/10\",\n",
       " '0.0601 - val_accuracy: 0.980 4 …… Epoch 9/10 60000/60000 [==============================] - 71s 1ms/sample - los s: 0.0251 - accuracy: 0.9920 - val_loss: 0.0263 - val_accuracy: 0.990 9 Epoch 10/10 60000/60000 [==============================] - 72s 1ms/sample - los s: 0.0222 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.992 8',\n",
       " '使用卷积神经网络之后，MNIST 手写数字识别的测试集准确率可以提升到 99%以上的高水\\n\\n准。\\n\\n272\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n8.11 识别自己写的数字图片\\n\\n在识别 MNIST 数据集的程序中，我们直接调用了 tensorflow 打包过的数据，而不是一\\n\\n张一张的图片，所以整个流程可能不够直观。我们可以使用 MNIST 数据集训练好的模型来识\\n\\n别自己写的数字图片，来检测一下模型的识别效果。\\n\\n我们可以自己找一张白纸，写一个数字，注意数字要写得粗一些，并且写在图片中间的位\\n\\n置，跟 MNIST 数据集中的数字类似，如图 8.37 所示。\\n\\n图 8.37 手写数字 6\\n\\n然后通过代码 8-2 来完成数字图片的识别.\\n\\n代码 8-2：识别自己写的数字图片（片段 1）',\n",
       " \"然后通过代码 8-2 来完成数字图片的识别.\\n\\n代码 8-2：识别自己写的数字图片（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model import matplotlib.pyplot as plt from PIL import Image import numpy as np\\n\\n# 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# 获取一张照片，并把它的 shape 变成二维（784->28×28）,用灰度图显示 plt.imshow(x_train[18],cmap='gray') # 不显示坐标\\n\\n273\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com plt.axis('off') plt.show() 结果输出为：\",\n",
       " \"代码 8-2：识别自己写的数字图片（片段 2）\\n\\n# 载入我自己写的数字图片 img=Image.open('6.jpg') # 显示图片 plt.imshow(img) # 不显示坐标 plt.axis('off') plt.show() 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 3）\\n\\n# 把图片大小变成 28×28，并且把它从 3D 的彩色图变为 1D 的灰度图 image = np.array(img.resize((28,28)).convert('L')) # 显示图片,用灰度图显示 plt.imshow(image,cmap='gray') # 不显示坐标 plt.axis('off') plt.show()\\n\\n274\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 4）\",\n",
       " \"代码 8-2：识别自己写的数字图片（片段 4）\\n\\n# 观察发现我自己写的数字是白底黑字，MNIST 数据集的图片是黑底白字 # 所以我们需要先把图片从白底黑字变成黑底白字，就是 255-image # MNIST 数据集的数值都是 0-1 之间的，所以我们还需要/255.0 对数值进行归一化 image = (255-image)/255.0 # 显示图片，用灰度图显示 plt.imshow(image,cmap='gray') # 不显示坐标 plt.axis('off') plt.show() 结果输出为：\\n\\n代码 8-2：识别自己写的数字图片（片段 5）\\n\\n# 把数据处理变成 4 维数据 image = image.reshape((1,28,28,1)) # 载入训练好的模型 model = load_model('mnist.h5') # predict_classes 对数据进行预测并得到它的类别 prediction = model.predict_classes(image) print(prediction) 结果输出为：\\n\\n275\",\n",
       " '275\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com [6]\\n\\n8.12 CIFAR-10 数据集分类\\n\\nCIFAR-10 数据集是深度学习领域比较常用的一个图片数据集，很多模型都会使用 CIFAR-\\n\\n10 数据集来检验模型的效果。CIFAR-10 数据集一共有 10 个分类，每个分类的图片都是 32×\\n\\n32 的彩色图片，每个分类都有 6000 张图片，一共个 60000 张图片。其中 50000 张图片是训\\n\\n练集，10000 张图片是测试集。如图 8.38 所示。\\n\\n图 8.38 CIFAR-10\\n\\n另外还有一个数据集叫 CIFAR-100，顾名思义就是有 100 个种类，每个种类有 600 张图\\n\\n片，一共 60000 张。其中 50000 张为训练集，10000 张为测试集。CIFAR-10 数据集比较\\n\\n用得更多一些，CIFAR-10 数据集分类代码如 8-3 所示。\\n\\n代码 8-3：CIFAR-10 数据集分类（片段 1）\\n\\nimport numpy as np\\n\\n276',\n",
       " 'import numpy as np\\n\\n276\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data()',\n",
       " \"# 显示 1 张图片 # 第 3 张图片 n = 3 # 一共 10 个种类 target_name = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] # 显示图片 plt.imshow(x_train[n]) plt.axis('off') # 根据标签获得种类名称 plt.title(target_name[y_train[n][0]]) plt.show() 结果输出为：\\n\\n代码 8-3：CIFAR-10 数据集分类（片段 2）\\n\\n# 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 转 one hot 格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10)\\n\\n277\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " \"# 定义卷积网络 model = Sequential() model.add(Convolution2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, pad ding='same', activation = 'relu')) model.add(Convolution2D(filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.2)) model.add(Convolution2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Convolution2D(filters=64, kernel_size=3,\",\n",
       " \"kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.3)) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Convolution2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.4)) model.add(Flatten()) model.add(Dense(10,activation =\",\n",
       " \"model.add(Dense(10,activation = 'softmax'))\",\n",
       " \"# 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuf fle=True) 结果输出为： Train on 50000 samples, validate on 10000 samples Epoch 1/100 50000/50000 [==============================] - 9s 181us/sample - los s: 1.9268 - acc: 0.2873 - val_loss: 1.6186 - val_acc: 0.4077 Epoch 2/100 50000/50000\",\n",
       " '1.6186 - val_acc: 0.4077 Epoch 2/100 50000/50000 [==============================] - 6s 127us/sample - los s: 1.5641 - acc: 0.4284 - val_loss: 1.4547 - val_acc: 0.4748 Epoch 3/100 50000/50000 [==============================] - 6s 126us/sample - los s: 1.4103 - acc: 0.4897 - val_loss: 1.2902 - val_acc: 0.5436 …… Epoch 98/100',\n",
       " '278\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2807 - acc: 0.8987 - val_loss: 0.5496 - val_acc: 0.8293 Epoch 99/100 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2797 - acc: 0.8995 - val_loss: 0.5561 - val_acc: 0.8303 Epoch 100/100 50000/50000 [==============================] - 6s 126us/sample - los s: 0.2822 - acc: 0.8979 - val_loss: 0.5498 - val_acc: 0.8278\\n\\n训练 100 个周期，最后得到了 83%左右的测试集准确率。',\n",
       " '训练 100 个周期，最后得到了 83%左右的测试集准确率。\\n\\n卷积神经网络是如今深度学习中最常用的算法之一，而另一种非常常用的算法——序列模\\n\\n型将是我们下一章要介绍的内容。\\n\\n8.13 参考文献\\n\\n[1] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint\\n\\narXiv:1804.02767, 2018.\\n\\n[2] Nam H, Han B. Learning multi-domain convolutional neural networks for visual\\n\\ntracking[C]//Proceedings of the IEEE conference on computer vision and pattern\\n\\nrecognition. 2016: 4293-4302.\\n\\n[3] Badrinarayanan V, Kendall A, Cipolla R. Segnet: A deep convolutional encoder-',\n",
       " 'decoder architecture for image segmentation[J]. IEEE transactions on pattern analysis\\n\\nand machine intelligence, 2017, 39(12): 2481-2495.\\n\\n[4] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE\\n\\ninternational conference on computer vision. 2017: 2961-2969.\\n\\n279\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 9 章-序列模型\\n\\n1986 年 Rumelhart 等人提出循环神经网络（Recurrent Neural Network），简称\\n\\nRNN。RNN 跟我们之前学习过的神经网络都不太一样，它是一种序列模型。比如卷积网络\\n\\n是专门用来处理网格化数据（例如图像数据）的神经网络，RNN 是专门用来处理序列数据的',\n",
       " '是专门用来处理网格化数据（例如图像数据）的神经网络，RNN 是专门用来处理序列数据的\\n\\n神经网络。所谓的序列数据指的是跟序列相关的数据，比如一段语音，一首歌曲，一段文\\n\\n字，一段录像等。\\n\\n9.1 序列模型应用\\n\\n我们生活中的很多数据都是序列数据，因此序列模型可以应用于我们生活中的很多方\\n\\n面，例如：\\n\\n语音识别：把语音转换成为文字，如图 9.1 所示。\\n\\n图 9.1 语音识别\\n\\n文本分类：把文章，邮件或用户评论等文本数据做分类，如图 9.2 所示。\\n\\n280\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.2 文本分类\\n\\n机器翻译：如把中文翻译成英文，如图 9.3 所示。\\n\\n图 9.3 机器翻译\\n\\n视频识别：通过一段视频分析视频中发生的事件，如图 9.4 所示。\\n\\n图 9.4 视频识别\\n\\n分词标注：给一段文字做分词标注，标注每个字对应的标号。假如使用 4-tag(BMES)标注\\n\\n标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S 表示单字词。可\\n\\n以得到类似如下结果：',\n",
       " '以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n281\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.2 循环神经网络 RNN\\n\\n9.2.1 循环神经网络介绍\\n\\n循环神经网络 RNN 的基本结构是 BP 网络的结构，也是有输入层，隐藏层和输出层。只\\n\\n不过在 RNN 中隐藏层的输出不仅可以传到输出层，并且还可以传给下一个时刻的隐藏层，如\\n\\n图 9.5 所示。\\n\\n图 9.5 RNN 结构\\n\\n图 9.5 中 RNN 的结构可以展开为右边的结构，其中 x 为输入信号，𝑥ˆ(cid:127)\"为 t-1 时刻的输\\n\\n入信号，𝑥ˆ为 t 时刻的输入信号，𝑥ˆ(cid:151)\"为 t+1 时刻的输入信号。ℎˆ(cid:127)\"为 t-1 时刻的隐藏层信号，\\n\\nℎˆ为 t 时刻的隐藏层信号，ℎˆ(cid:151)\"为 t+1 时刻的隐藏层信号。𝑦ˆ(cid:127)\"为 t-1 时刻的输出层信号，𝑦ˆ',\n",
       " '为 t 时刻的输出层信号，𝑦ˆ(cid:151)\"为 t+1 时刻的输出层信号。W，U，V 为网络的权值矩阵。h 是\\n\\n隐藏(hidden)的首字母。\\n\\n假如图 9.5 是一个训练好的词性分析模型，有一个句子是“我爱你”，那么先把句子做分\\n\\n词得到“我”，“爱”，“你”三个词，然后依次把这三个词输入到网络中。那么𝑥ˆ(cid:127)\"为“我”\\n\\n所表示的信号，𝑥ˆ为“爱”所表示的信号，𝑥ˆ(cid:151)\"为“你”所表示的信号。而𝑦ˆ(cid:127)\"输出结果是主\\n\\n282\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n语，𝑦ˆ输出结果是谓语，𝑦ˆ(cid:151)\"输出结果是宾语，分别得到“我”，“爱”，“你”这三个词的\\n\\n词性。\\n\\n从结构上可以观察到 RNN 最大的特点是之前序列输入的信息会对模型之后的输出结果造\\n\\n成影响。\\n\\n9.2.2 Elman network 和 Jordan network\\n\\n循环神经网络 RNN 有两种常见的模型，一种是 Elman network 另一种是 Jordan',\n",
       " 'network。Elman network 和 Jordan network 也被称为\\n\\nSimple Recurrent Networks (SRN)或 SimpleRNN，即简单的循环神经网络。\\n\\n这两种模型的网络结构是一样的，都如图 9.5，只不过它们的计算公式有一点不同。\\n\\nElman network 的公式为：\\n\\nℎˆ = 𝜎(cid:150)(𝑊𝑥ˆ + 𝑈ℎˆ(cid:127)\" + 𝑏(cid:150))\\n\\n𝑦ˆ = 𝜎—(cid:142)𝑉ℎˆ + 𝑏—(cid:143)\\n\\nJordan network 的公式为：\\n\\nℎˆ = 𝜎(cid:150)(𝑊𝑥ˆ + 𝑈𝑦ˆ(cid:127)\" + 𝑏(cid:150))\\n\\n𝑦ˆ = 𝜎—(cid:142)𝑉ℎˆ + 𝑏—(cid:143)\\n\\n其中𝑥ˆ为 t 时刻的输入信号，ℎˆ为 t 时刻隐藏层的输出信号，𝑦ˆ为 t 时刻输出层的输出信\\n\\n号。W，U，V 对应图 9.5 中的权值矩阵，b 为偏置值。𝜎(cid:150)和𝜎—为激活函数，激活函数可以自\\n\\n行选择。',\n",
       " '行选择。\\n\\n从上面 Elman network 和 Jordan network 的公式对比中可以看出，Elman network\\n\\n的隐层ℎˆ接收的是上时刻的隐层ℎˆ(cid:127)\"的信号；而 Jordan network 的隐层ℎˆ接收的是上时刻的\\n\\n输出层𝑦ˆ(cid:127)\"的信号。一般 Elman network 的形式会更常用一些。\\n\\n283\\n\\n(9.1)\\n\\n(9.2)\\n\\n(9.3)\\n\\n(9.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.3 RNN 的不同架构\\n\\n为了处理不同输入输出组合的各类任务，RNN 可以分为以下几种不同的架构。\\n\\n9.3.1 一对一架构\\n\\n一对一架构如图 9.6 所示。\\n\\n图 9.6 RNN 一对一架构\\n\\n其实就是普通的神经网络，输入序列长度为 1，输出序列长度也是 1。注意这里的𝑥\"不是\\n\\n一个数值的意思，而是第一个序列输入的意思，𝑥\"可以是多个数值。比如𝑥\"输入 MNIST 数据\\n\\n集图片的数据，一张图片有 784 个像素，那么这里的𝑥\"就有 784 个值。把𝑥\"的数据输入，然',\n",
       " '集图片的数据，一张图片有 784 个像素，那么这里的𝑥\"就有 784 个值。把𝑥\"的数据输入，然\\n\\n后𝑦\"得到图片数据的预测结果。\\n\\n9.3.2 多对一架构\\n\\n多对一架构如图 9.7 所示。\\n\\n284\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.7 RNN 多对一架构\\n\\n模型有多次输入，我们只关心序列输出的最后一个值。比如可以用于情感分类，给模型\\n\\n输入一个句子或一篇文章，一个句子或一篇文章包含很多个词，每个词看成是一个输入信\\n\\n号，那么一个序列被分为多次输入。最后模型的预测结果可以是一个句子或一篇文章的情感\\n\\n分类，比如说是正面的情感还是负面的情感，两个类别，那么模型的最后一个序列的输出可\\n\\n以看成是预测结果。同样的道理，如果做文本分类也是可以用多对一架构。\\n\\n这里要注意的是，多对一架构并不是说模型只有最后一个序列才有输出值。其实每次给\\n\\n模型输入一个词的信号，模型都会输出一个结果。只不过如果我们需要分析一个句子或者一\\n\\n篇文章的情感，那么我们需要把整个句子或整篇文章的词的数据都输入到模型进行计算之',\n",
       " '篇文章的情感，那么我们需要把整个句子或整篇文章的词的数据都输入到模型进行计算之\\n\\n后，再获得模型最终的一个输出结果，模型最终的这个输出结果会更准确。而前面得到的模\\n\\n型输出结果可能就没这么准确。\\n\\n9.3.3 多对多架构\\n\\n多对多架构如图 9.8 所示。\\n\\n285\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.8 RNN 多对多架构\\n\\n序列有多次输入和多次输出。可以应用在 Tagging（标注），比如说词性标注，标注句\\n\\n子中的每个词分别是什么词性。输入一个信号，然后就输出这个信号的预测结果。\\n\\n9.3.4 一对多架构\\n\\n一对多架构如图 9.9 所示。\\n\\n图 9.9 RNN 一对多架构\\n\\n一对多模型是只有一个输入信号，就可以得到很多个输出结果。第一个序列的输出结果\\n\\n会作为输入传给第二个序列，第二个序列的输出会作为输入传给第三个序列，以此类推。比\\n\\n如可以应用于音乐生成和文章生存。给出第一个音符或字，就可以生成一段旋律或者一句\\n\\n话。\\n\\n286\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '话。\\n\\n286\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.3.5 Seq2Seq 架构\\n\\nSeq2Seq 的全称是 Sequence to Sequence，也就是序列到序列模型。seq2seq 也算\\n\\n是多对多架构，如图 9.10 所示。\\n\\n图 9.10 RNN 的 seq2seq 架构\\n\\nseq2seq 由两部分组成，左边部分为编码器（encoder），右边部分为解码器\\n\\n（decoder）。Encoder 的作用是负责将输入序列压缩成指定长度的向量，相当于是做特征\\n\\n提取。然后把这个向量传给 decoder 进行计算得到多个序列输出。\\n\\n经典的多对多 RNN 架构的输入和输出是等长的，也就是有 10 个输入就必须有 10 个输\\n\\n出结果，它的应用场景也比较有限。而 seq2seq 模型的输入和输出可以是不等长的，它实现\\n\\n了一个序列到另一个序列的转换。比如可以用来做机器翻译，encoder 输入一段中文，\\n\\ndecoder 可以输出一段英文，中文句子的词汇数跟英文句子的词汇数不一定要相同。比如还',\n",
       " 'decoder 可以输出一段英文，中文句子的词汇数跟英文句子的词汇数不一定要相同。比如还\\n\\n可以用来做聊天机器人，encoder 输入一句话，decoder 回复另一句话，这两句话的长度也\\n\\n不一定相同。\\n\\n287\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.4 传统 RNN 的缺点\\n\\n我们知道 RNN 可以根据历史信息来进行预测，假如我们训练了一个可以进行文本填空\\n\\n的 RNN 模型，下面要进行文本填空：\\n\\n题目 1:有一朵云飘在（）。\\n\\n对于题目 1 来说正确的答案应该是“天上”，或者“空中“，或者”天空中“等。经过\\n\\n大量训练之后的 RNN 可以根据前面文本的信息填出正确的答案。\\n\\n题目 2:我从小生长在美国，父亲是英国人，母亲是美国人。我最喜欢喝牛奶，吃牛肉，\\n\\n长大想当科学家。我的兴趣爱好是看电影，看书，踢足球还有周末跟爷爷去钓鱼。我可以说\\n\\n一口流利的（）。\\n\\n对于题目 2 来说因为是从小生长在美国，所以应该是可以说一口流利的“英语“。但是\\n\\n传统的 RNN 不一定能预测出正确的结果，原因是句子的长度太长了。',\n",
       " '传统的 RNN 不一定能预测出正确的结果，原因是句子的长度太长了。\\n\\n为什么句子的长度太长会对 RNN 的预测产生影响呢？这要考虑到 RNN 的基本模型结\\n\\n构，传统的 RNN 基本模型结构是 BP 网络。我们在学习 BP 网络的时候有特别讨论过关于梯\\n\\n度消失的问题。就是模型计算得到的误差信号从输出层不断向前传播，以此来调整前面层的\\n\\n权值，使得模型的性能越来越好。但是由于误差信号在每次传递的时候都需要乘以激活函数\\n\\n的导数，当激活函数的导数取值范围是 0-1 之间时，会使得误差信号越传越小，最终趋近于\\n\\n0。\\n\\n这个梯度消失的问题在 RNN 中同样存在，RNN 的序列结构展开之后也可以看成是有很\\n\\n多的“层”，在计算误差信号的时候同样会出现梯度消失的问题，使得网络输出的学习信号\\n\\n只能影响到它前面的几层，对它前面的几层的权值进行调节。所以反过来考虑，一个信号的\\n\\n输入，只能影响到它后面的几个序列的输出，并且影响力会越来越弱，如图 9.11 所示。\\n\\n288\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.11 RNN 的梯度消失问题[1]',\n",
       " '图 9.11 RNN 的梯度消失问题[1]\\n\\n9.5 长短时记忆网络 LSTM\\n\\nLSTM(Long Short Term Memory)是 Hochreater 和 Schmidhuber 在 1997 年提出的\\n\\n一种网络结构，尽管该模型在序列建模上的特性非常突出，但由于当时正是神经网络的下坡\\n\\n期，没有能够引起学术界足够的重视。随着深度学习逐渐发展，后来 LSTM 的应用也逐渐增\\n\\n多。\\n\\nLSTM 区别于 SimpleRNN 的地方，主要就在于它在算法中加入了一个判断信息有用与\\n\\n否的“处理器”，这个处理器作用的结构被称为记忆块（Memory Block），如图 9.12 所\\n\\n示。\\n\\n289\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.12 记忆块（memory block）[1]\\n\\n图 9.12 中最下面 4 个神经元是输入神经元，最上面 5 个神经元是输出神经元，\\n\\nmemory block 在隐藏层的位置。传统的 BP 网络隐藏层是普通的神经元，不过在 LSTM 里',\n",
       " '面是结构比较复杂的 memory block。memory block 内部具体结构如图 9.13 所示。\\n\\n290\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.13 memory block 结构[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈vℎˆ(cid:127)\" + 𝑏v(cid:143)\\n\\n𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(ℎˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)ℎˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑏(cid:211))\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑏(cid:211))',\n",
       " 'memory block 结构主要包含了三个门：遗忘门（Forget Gate）、输入门（Input\\n\\nGate）、输出门（Output Gate）与一个记忆单元（Cell）。信号从下面传入，上面传出。\\n\\n首先我们先了解一下公式中符号的含义。\\n\\n𝑓ˆ：遗忘门信号\\n\\n291\\n\\n(9.5)\\n\\n(9.6)\\n\\n(9.7)\\n\\n(9.8)\\n\\n(9.9)\\n\\n(9.10)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑖ˆ：输入门信号\\n\\n𝑜ˆ：输出门信号\\n\\n𝑥ˆ：第 t 个序列的输入\\n\\nℎˆ(cid:127)\"：第 t-1 个序列的 memory block 输出\\n\\nℎˆ：第 t 个序列的 memory block 输出，也称为 Hidden State。\\n\\n𝑐̃ˆ：cell 输入信号\\n\\n𝑐ˆ：cell 输出信号，也称为 Cell State。\\n\\n𝑐ˆ(cid:127)\"：第 t-1 个序列的 cell 信号\\n\\n𝜎(cid:209)：sigmoid 函数\\n\\n𝜎(cid:211)：tanh 函数\\n\\n𝜎(cid:150)：tanh 函数或线性函数',\n",
       " '𝜎(cid:211)：tanh 函数\\n\\n𝜎(cid:150)：tanh 函数或线性函数\\n\\n𝑊, 𝑈, 𝑏：𝑊和𝑈是权值矩阵，𝑏是偏置\\n\\n观察图 9.13，信号从 blcok 底部传入，传入的信号为第 t 个序列的输入𝑥ˆ，以及第 t-1\\n\\n个序列的输出ℎˆ(cid:127)\"，也就是上一个时间 block 的输出信号会传给当前的 block 做计算。𝑥ˆ和\\n\\nℎˆ(cid:127)\"乘以对应的权值矩阵加上偏置值经过激活函数得到𝑐̃ˆ的信号，计算公式为 9.10，如图\\n\\n9.14 所示。\\n\\n292\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 9.14 𝑐̃ˆ的信号计算[1]\\n\\n𝑐̃ˆ信号继续传会碰到 Input Gate 输入门，输入门的计算公式为 9.6。输入门的传入信号\\n\\n也是𝑥ˆ和ℎˆ(cid:127)\"，激活函数为 sigmoid 函数。我们要注意 2 个地方：\\n\\n1.block 中一共有 3 个门，并且这 3 个门的输入信号都是𝑥ˆ和ℎˆ(cid:127)\"，它们的计算公式都是',\n",
       " '差不多的，不过他们的权值矩阵是不同的值，不同的门有不同的权值。\\n\\n2.3 个门的激活函数都是 sigmoid 函数，所以 3 个门的输出值都是 0-1 之间，体现了门\\n\\n的作用。门的作用就是控制信号的开关。\\n\\n𝑐̃ˆ信号和输入门信号𝑖ˆ会进行对位相乘，然后再进行传递。𝑖ˆ的作用在这里就体现出来\\n\\n了，𝑖ˆ的值等于 1 表示𝑐̃ˆ信号会 100%传递；𝑖ˆ的值等于 0 表示𝑐̃ˆ信号会完全消失；𝑖ˆ的值等\\n\\n于 0.6 表示𝑐̃ˆ信号会保留 60%的大小进行传递。如图 9.15 所示。\\n\\n图 9.15 𝑖ˆ的信号计算[1]\\n\\n𝑐̃ˆ和𝑖ˆ对位相乘后继续传递到达 Cell 的位置。Cell 的位置有一个 Forget Gate 遗忘门，\\n\\n遗忘门的计算公式为 9.5，跟输入门的计算类似，最后得到 0-1 之间的结果。当前的𝑐ˆ信号计\\n\\n算公式为 9.8，表示𝑐̃ˆ和𝑖ˆ对位相乘后的信号再加上前一个序列的 Cell 信号𝑐ˆ(cid:127)\"和𝑓ˆ对位相乘\\n\\n的信号。\\n\\n其实就相当于是在 block 内部可以保存一个 Cell 信号为𝑐ˆ，这个信号会不断“遗忘”，',\n",
       " '其实就相当于是在 block 内部可以保存一个 Cell 信号为𝑐ˆ，这个信号会不断“遗忘”，\\n\\n所以需要乘以遗忘门信号𝑓ˆ。具体需要全部遗忘，还是不遗忘，还是遗忘一部分，是由遗忘\\n\\n293\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n门信号𝑓ˆ来控制的。当前的 Cell 信号就等于之前的 Cell 信号进行一些遗忘𝑐ˆ(cid:127)\" ∘ 𝑓ˆ再加上当\\n\\n前传入的信号𝑐̃ˆ ∘ 𝑖ˆ。如图 9.16 所示。\\n\\n图 9.16 𝑐ˆ的信号计算[1]\\n\\n𝑐ˆ信号继续传递会碰到 Output Gate 输出门，输出门的计算公式为 9.7，跟输入门和遗\\n\\n忘门类似。整个 block 最后的输出为ℎˆ，公式为 9.9。就是𝑐ˆ信号加上 tanh 激活函数再跟输\\n\\n出门信号𝑜ˆ对位相乘得到 block 的输出ℎˆ，如图 9.17 所示。\\n\\n图 9.16 ℎˆ的信号计算[1]\\n\\nmemory blocks 输出的ℎˆ信号会再乘上输出层的权值矩阵加上偏置值再经过激活函数最\\n\\n后得到 LSTM 网络的输出结果。\\n\\n294',\n",
       " '后得到 LSTM 网络的输出结果。\\n\\n294\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.6 Peephole LSTM 和 FC-LSTM\\n\\n9.6.1 Peephole LSTM 介绍\\n\\nPeephole LSTM 跟 LSTM 差不多，结构如图 9.17 所示。\\n\\n图 9.17 Peephole LSTM 结构图[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈v𝑐ˆ(cid:127)\" + 𝑏v(cid:143)\\n\\n𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(𝑐ˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)𝑐ˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)',\n",
       " 'ℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\n295\\n\\n(9.11)\\n\\n(9.12)\\n\\n(9.13)\\n\\n(9.14)\\n\\n(9.15)\\n\\n(9.16)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n大家可以自己先观察一下 Peephole LSTM 跟 LSTM 的结构和公式哪里不同。\\n\\n不仔细观察可能不容易看出，它们不同之处在与把所有的ℎˆ(cid:127)\"都改成了𝑐ˆ(cid:127)\"，也就是说当\\n\\n前序列的𝑐ˆ信号传传给下一个序列的计算，而不是ℎˆ信号。\\n\\n9.6.2 FC-LSTM 介绍\\n\\nLSTM 还有一个结构为 FC-LSTM(Fully-Connected LSTM)，结构如图 9.18 所示。\\n\\n图 9.18 FC-LSTM 结构[1]\\n\\n𝑓ˆ = 𝜎(cid:209)(cid:142)𝑊v𝑥ˆ + 𝑈vℎˆ(cid:127)\" + 𝑉v𝑐ˆ(cid:127)\" + 𝑏v(cid:143)',\n",
       " '𝑖ˆ = 𝜎(cid:209)(𝑊(𝑥ˆ + 𝑈(ℎˆ(cid:127)\" + 𝑉(𝑐ˆ(cid:127)\" + 𝑏()\\n\\n𝑜ˆ = 𝜎(cid:209)(𝑊(cid:210)𝑥ˆ + 𝑈(cid:210)ℎˆ(cid:127)\" + 𝑉(cid:210)𝑐ˆ(cid:127)\" + 𝑏(cid:210))\\n\\n𝑐ˆ = 𝑓ˆ ∘ 𝑐ˆ(cid:127)\" + 𝑖ˆ ∘ 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑉(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))\\n\\n296\\n\\n(9.17)\\n\\n(9.18)\\n\\n(9.19)\\n\\n(9.20)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nℎˆ = 𝑜ˆ ∘ 𝜎(cid:150)(𝑐ˆ)\\n\\n𝑐̃ˆ = 𝜎(cid:211)(𝑊(cid:211)𝑥ˆ + 𝑈(cid:211)ℎˆ(cid:127)\" + 𝑉(cid:211)𝑐ˆ(cid:127)\" + 𝑏(cid:211))',\n",
       " '观察 FC-LSTM 的结构和公式，我们可以很容易的知道，FC-LSTM 的𝑐ˆ信号和ℎˆ信号都\\n\\n可以传给下一个序列进行计算。\\n\\n总结一下，在 LSTM 中存在 3 个门，输入门控制信号的输入，遗忘门控制 Cell 信号的遗\\n\\n忘，输出门控制信号的输出。LSTM 的隐藏层中有大量的 block，数量我们可以自己设置。\\n\\n经过随时间反向传播(BPTT)算法(跟 BP 算法类似)训练后 LSTM 中的 block 就可以自动判断\\n\\n哪些信号应该让它输入，哪些信号应该保存或遗忘，哪些信号应该让它输出。它的输入门会\\n\\n控制有用的信号进行输入，过滤掉一些无用的信号；它的遗忘门会保留一些重要的信号，忘\\n\\n记一些不太有用的信号；它的输出门会控制输出一些有用的信号，如图 9.19 所示。\\n\\n图 9.19 LSTM 对信号的控制[1]\\n\\n297\\n\\n(9.21)\\n\\n(9.22)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n9.7 其他 RNN 模型\\n\\n9.7.1 门控循环单元 GRU',\n",
       " '9.7 其他 RNN 模型\\n\\n9.7.1 门控循环单元 GRU\\n\\nGRU(Gated Recurrent Unit)这个结构是 2014 年才出现的，效果跟 LSTM 差不多，但\\n\\n是用到的参数更少，所以计算速度会更快一些。GRU 将遗忘门和输入门合成了一个单一的更\\n\\n新门。GRU 的 block 结构简图 9.20 所示。\\n\\n图 9.20 GRU 结构\\n\\n𝑧ˆ = 𝜎(cid:209)(𝑊„𝑥ˆ + 𝑈„ℎˆ(cid:127)\" + 𝑏„)\\n\\n𝑟ˆ = 𝜎(cid:209)(𝑊(cid:156)𝑥ˆ + 𝑈(cid:156)ℎˆ(cid:127)\" + 𝑏(cid:156))\\n\\nℎ(cid:213)\\n\\nˆ = 𝑡𝑎𝑛ℎ(𝑊(cid:150)𝑥ˆ + 𝑈(cid:150)(𝑟ˆ ∘ ℎˆ(cid:127)\"))\\n\\nℎˆ = (1 − 𝑧ˆ) ∘ ℎˆ(cid:127)\" + 𝑧ˆ ∘ ℎ(cid:213)\\n\\nˆ\\n\\n𝑧ˆ是更新门(update gate)，决定ℎˆ的更新情况\\n\\n𝑟ˆ是重置门(reset gate)，决定是否要放弃ℎˆ(cid:127)\"',\n",
       " '𝑟ˆ是重置门(reset gate)，决定是否要放弃ℎˆ(cid:127)\"\\n\\nℎ(cid:213) ˆ是候选输出，接收[𝑥ˆ, ℎˆ(cid:127)\"]\\n\\n298\\n\\n(9.23)\\n\\n(9.24)\\n\\n(9.25)\\n\\n(9.26)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nℎˆ是当前输出，接收[ℎˆ(cid:127)\", ℎ(cid:213)\\n\\nˆ]\\n\\n9.7.2 双向 RNN（Bidirectional RNN）\\n\\n双向 RNN(Bidirectional RNN)结构如图 9.21 所示。\\n\\n图 9.21 双向 RNN\\n\\nℎˆ(cid:214)(cid:214)(cid:214)⃗ = 𝑓(cid:142)𝑊(cid:214)(cid:214)(cid:214)⃗𝑥ˆ + 𝑉(cid:214)⃗ℎˆ(cid:127)\"\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ + 𝑏(cid:214)⃗(cid:143)',\n",
       " 'ℎˆ⃖(cid:214)(cid:214)(cid:214) = 𝑓(cid:142)𝑊⃖(cid:214)(cid:214)(cid:214)𝑥ˆ + 𝑉⃖(cid:214)ℎˆ(cid:151)\"\\n\\n⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏⃖(cid:214)(cid:143)\\n\\n𝑦ˆ = 𝑔(cid:142)𝑈(cid:146)ℎˆ(cid:214)(cid:214)(cid:214)⃗; ℎˆ⃖(cid:214)(cid:214)(cid:214)(cid:147) + 𝑐(cid:143)\\n\\n这里的 RNN 可以使用任意一种 RNN 结构 SimpleRNN，LSTM 或 GRU。这里箭头表示\\n\\n从左到右或从右到左传播，对于每个时刻的预测，都需要来自双向的特征向量，拼接\\n\\n（concatenate）后进行结果预测。箭头虽然不同，但参数还是同一套参数。有些模型中也\\n\\n可以使用两套不同的参数。𝑓, 𝑔表示激活函数，(cid:146)ℎˆ',\n",
       " '可以使用两套不同的参数。𝑓, 𝑔表示激活函数，(cid:146)ℎˆ\\n\\n(cid:214)(cid:214)(cid:214)⃗; ℎˆ\\n\\n⃖(cid:214)(cid:214)(cid:214)(cid:147)表示数据拼接（concatenate）。\\n\\n双向的 RNN 是同时考虑“过去”和“未来”的信息。图 9.21 是一个序列长度为 4 的双\\n\\n向 RNN 结构。\\n\\n299\\n\\n(9.27)\\n\\n(9.28)\\n\\n(9.29)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n300\\n\\n比如输入𝑥\"沿着实线箭头传输到隐层得到ℎ\"，然后还需要再利用𝑥ˆ计算得到ℎˆ\\n\\nR ，利用𝑥$和\\n\\nR 计算得到ℎ$ ℎˆ\\n\\nR ，利用𝑥#和ℎ$\\n\\nR 计算得到ℎ#\\n\\nR ，利用𝑥\"和ℎ#\\n\\nR 计算得到ℎ\"\\n\\nR ，再把ℎ\"和ℎ\"\\n\\nR 进行数据拼接\\n\\n（concatenate），再计算得到输出结果𝑦\"。以此类推同时利用前向传递和反向传递的数据\\n\\n进行结果的预测。\\n\\n双向 RNN 就像是我们做阅读理解的时候从头向后读一遍文章，然后又从后往前读一遍文',\n",
       " '双向 RNN 就像是我们做阅读理解的时候从头向后读一遍文章，然后又从后往前读一遍文\\n\\n章，然后再做题。有可能从后往前再读一遍文章的时候会有新的不一样的理解，最后模型可\\n\\n能会得到更好的结果。\\n\\n9.7.3 Stacked Bidirectional RNN\\n\\n堆叠的双向 RNN 结构如图 9.22 所示。\\n\\n图 9.22 Stacked Bidirectional RNNs\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ ((cid:132)) ℎˆ ⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) ((cid:132)) ℎˆ',\n",
       " '(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ + 𝑏(cid:132)(cid:214)(cid:214)(cid:214)⃗(cid:218)\\n\\n(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ℎˆ\\n\\n(cid:132)(cid:127)\" + 𝑉(cid:132)(cid:214)(cid:214)(cid:214)(cid:214)⃗ℎˆ(cid:127)\"\\n\\n= 𝑓 (cid:217)𝑊(cid:132)\\n\\n(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) + 𝑏(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:218)',\n",
       " '(cid:132)(cid:127)\" + 𝑉(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)ℎˆ(cid:151)\" ⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214) (cid:214)(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)⃗ ((cid:132)) ((cid:132)) 𝑦ˆ = 𝑔 l𝑈 (cid:219)ℎˆ ; ℎˆ\\n\\n= 𝑓 (cid:217)𝑊(cid:132)⃖(cid:214)(cid:214)(cid:214)(cid:214)(cid:214)ℎˆ\\n\\n(cid:220) + 𝑐m\\n\\n注意这里的堆叠 RNN 结构并不是只有双向 RNN 才可以堆叠，其实任意的 RNN 都可以\\n\\n堆叠，比如 SimpleRNN，LSTM，GRU 这些循环神经网络也可以进行堆叠。堆叠指的是在\\n\\nRNN 的结构中叠加多层，类似于 BP 神经网络中可以叠加多层，增加网络的非线性。图 9.22',\n",
       " 'RNN 的结构中叠加多层，类似于 BP 神经网络中可以叠加多层，增加网络的非线性。图 9.22\\n\\n中是一个堆叠了 3 个隐藏层的 RNN 网络。\\n\\n9.8 LSTM 网络应用于 MNIST 数据集分类\\n\\nLSTM 网络是序列模型，一般是比较适合处理序列问题。这里我们把它用于手写数字图\\n\\n片的分类，其实是相当于把图片看成序列。一张 MNIST 数据集的图片是 28*28 的大小，我\\n\\n们可以把每一行看成是一个序列输入，那么一张图片就是 28 行，序列长度为 28；每一行有\\n\\n28 个数据，每个序列输入 28 个值，具体实现如代码 9-1 所示。\\n\\n代码 9-1：LSTM 网络应用于 MNIST 数据集分类',\n",
       " '代码 9-1：LSTM 网络应用于 MNIST 数据集分类\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.layers import LSTM from tensorflow.keras.optimizers import Adam\\n\\n# 载入数据集 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 # 训练集数据 x_train 的数据形状为（60000，28，28） # 训练集标签 y_train 的数据形状为（60000） # 测试集数据 x_test 的数据形状为（10000，28，28）\\n\\n301\\n\\n(9.30)\\n\\n(9.31)\\n\\n(9.32)',\n",
       " '301\\n\\n(9.30)\\n\\n(9.31)\\n\\n(9.32)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集标签 y_test 的数据形状为（10000） (x_train, y_train), (x_test, y_test) = mnist.load_data() # 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度 x_train, x_test = x_train / 255.0, x_test / 255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\\n\\n# 数据大小-一行有 28 个像素 input_size = 28 # 序列长度-一共有 28 行 time_steps = 28 # 隐藏层 memory block 个数 cell_size = 50',\n",
       " \"# 创建模型 model = Sequential()\\n\\n# 循环神经网络的数据输入必须是 3 维数据 # 数据格式为(数据数量，序列长度，数据大小) # 载入的 mnist 数据的格式刚好符合要求 # 注意这里的 input_shape 设置模型数据输入时不需要设置数据的数量 model.add(LSTM( units = cell_size, input_shape = (time_steps,input_size), ))\\n\\n# 50 个 memory block 输出的 50 个值跟输出层 10 个神经元全连接 model.add(Dense(10,activation='softmax'))\\n\\n# 定义优化器 adam = Adam(lr=1e-3)\\n\\n# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\",\n",
       " '# 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test,y_test)) 结果输出为： Train on 60000 samples, validate on 10000 samples Epoch 1/10 60000/60000 [==============================] - 14s 236us/sample - lo ss: 0.5748 - accuracy: 0.8189 - val_loss: 0.2315 - val_accuracy: 0.93 03\\n\\n302',\n",
       " '302\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 2/10 60000/60000 [==============================] - 15s 247us/sample - lo ss: 0.1953 - accuracy: 0.9416 - val_loss: 0.1521 - val_accuracy: 0.95 55 …… Epoch 10/10 60000/60000 [==============================] - 14s 228us/sample - lo ss: 0.0486 - accuracy: 0.9852 - val_loss: 0.0644 - val_accuracy: 0.98 03\\n\\nLSTM 应用于 MNIST 数据识别也可以得到不错的结果，不过当然没有卷积网络得到的结\\n\\n果好。更多序列模型的应用案例我们将在后面的章节中进一步介绍。\\n\\n9.9 参考文献',\n",
       " '果好。更多序列模型的应用案例我们将在后面的章节中进一步介绍。\\n\\n9.9 参考文献\\n\\n[1] Graves A. Supervised sequence labelling[M]//Supervised sequence labelling with\\n\\nrecurrent neural networks. Springer, Berlin, Heidelberg, 2012: 5-13.\\n\\n303\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 10 章-经典图像识别模型介绍（上）\\n\\n经典的图像识别模型比较多，并且我希望可以把各种模型的技术细节，设计思路尽可能\\n\\n地给大家介绍清楚。所以经典图像识别模型介绍的部分分为上下两个章节，第 10 章和第 11\\n\\n章。这两个章节的内容都属于内功修行，为了保持内容的连贯性，这两个章节的内容都是算\\n\\n法理论的介绍，相关代码实践的内容我放到了第 12 章节。大家可以看完第 10，11 章再看\\n\\n12 章，或者是结合第 12 章的代码来看第 10，11 章，两种方式都可以。\\n\\n10.1 图像数据集 ImageNet',\n",
       " '10.1 图像数据集 ImageNet\\n\\n10.1.1 ImageNet 介绍\\n\\n在正式介绍深度学习的经典图像识别模型之前，我们先来了解一下全世界最大的带有标\\n\\n签的开源图像数据集 ImageNet。\\n\\nImageNet 项目是从 2007 年由斯坦福教授李飞飞领导发起，ImageNet 项目团队从互\\n\\n联网上下载了近 10 亿张照片，然后使用众包技术（例如亚马逊机械土耳其人平台）来帮助\\n\\n他们为这些图像打标签。在巅峰时期，ImageNet 项目有来自 167 个国家的近 50000 名工\\n\\n作者为其进行数据的清理，分类，标注。\\n\\n直到 2009 年 ImageNet 项目正式交付使用，在 ImageNet 数据库中有 1500 万张左右\\n\\n的照片，包含大约 22000 种类别，免费提供给全世界的研究者使用。ImageNet 的官网地址\\n\\n是：http://www.image-net.org/index。如图 10.1 所示。\\n\\n304\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.1 ImageNet 官网',\n",
       " '图 10.1 ImageNet 官网\\n\\n官网的右上角可以看到当前 ImageNet 数据库图片的数量为 14197122 张图片，一共有\\n\\n21841 个种类。\\n\\n10.1.2 李飞飞简介\\n\\n李飞飞是美籍华人，人工智能学术圈最知名的女性科学家之一。\\n\\n1976 年出生于北京，长在四川，16 岁随父母移居美国新泽西州。\\n\\n1999 年毕业于普林斯顿大学。\\n\\n2005 年获得加州理工学院电子工程博士。\\n\\n2009 年加入斯坦福大学担任助理教授。\\n\\n2012 年担任副教授（终生教授），和斯坦福人工智能实验室与视觉实验室主任。\\n\\n2017 年 1 月入职 Google，担任谷歌云首席科学家。\\n\\n2018 年 9 月，离开谷歌返回斯坦福大学担任教授，同时保留谷歌云的 AI/ML 顾问。\\n\\n2020 年 2 月，当选为美国国家工程院院士。\\n\\n305\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.1.3 ImageNet 的深远影响\\n\\n2020 年 2 月李飞飞当选美国国家工程院院士，美国国家工程院(NAE)对于李飞飞的当选',\n",
       " '2020 年 2 月李飞飞当选美国国家工程院院士，美国国家工程院(NAE)对于李飞飞的当选\\n\\n给出的理由是“李飞飞为建立大型机器学习和视觉理解知识库作做出了贡献”。这里的“大\\n\\n型机器学习和视觉理解知识库”其实说白了就是 ImageNet 数据集。为什么创建一个数据\\n\\n集，就可以有资格评选美国院士？下面是我个人对于 ImageNet 数据集重要性的理解：\\n\\n一．前瞻性和创新性。ImageNet 项目在 2007 年发起，到 2009 年交付使用。这个巨\\n\\n大的项目需要耗费大量的人力物力财力，但是这个项目交付以后能发挥多大的作用，在当时\\n\\n并不是十分明确。我们从今天的视角来看，大规模深度学习模型的训练（这里的训练指的是\\n\\n重新训练一个新模型，不是指迁移学习（Transfer Learning））必然需要大规模的数据集\\n\\n才能得到很好的结果，这也是目前深度学习技术的一个局限性。但是在当时，深度学习技术\\n\\n才刚刚萌芽，大家并不明确大规模数据集对于机器学习/深度学习技术会有多大的影响。\\n\\n二．ImageNet 对于计算机视觉领域的巨大影响。如果大家之前稍微有关注过计算机视',\n",
       " '二．ImageNet 对于计算机视觉领域的巨大影响。如果大家之前稍微有关注过计算机视\\n\\n觉的发展就会发现，在 ImageNet 交付使用后，特别是 2012 年以后，计算机视觉领域的技\\n\\n术发展可谓是突飞猛进。图像识别，目标检测，人脸识别等技术的应用效果得到了巨大提\\n\\n升。10 年前人脸识别技术我们可能只听说过，没见过，现在走到哪里都有人脸识别。这一切\\n\\n都主要得益于深度学习技术的发展和 ImageNet 数据集。\\n\\nImageNet 在 2009 年免费发布以后，从 2010 年开始每年都会组织一次计算机视觉的比\\n\\n赛 ILSVRC（ImageNet Large Scale Visual Recognition Challenge），简称 ImageNet\\n\\nChallenge。这个比赛也是近年来计算机视觉领域最受追捧也最具权威的学术竞赛之一，代\\n\\n表了计算机视觉领域的最高水平。比赛的项目有图像分类，目标定位，目标检测，视频目标\\n\\n检测，场景分类。其中最重要也最受关注的就是图像分类的比赛。\\n\\n306\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '306\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nImageNet Challenge 的图像分类比赛是从 ImageNet 数据集中选出了 1000 个生活中\\n\\n常见的分类，120 万张图片作为训练集，10 万张图片作为测试集，5 万张图片作为验证集。\\n\\n参加比赛的人主要都是来自全世界的大公司，学校，研究院等。也有一些创业公司会参赛，\\n\\n因为如果能在这个全世界最知名的图像比赛上拿奖的话，那就证明了获奖公司拥有全世界最\\n\\n顶尖的图像技术水平，之后拿投资，做推广都会很容易。\\n\\n从 ImageNet Challenge 比赛中诞生出了很多优秀的深度学习模型，这些模型可以应用\\n\\n于计算机视觉的各种领域，图像识别，目标检测，目标分割，人脸识别等等，极大推动了计\\n\\n算机视觉的发展。\\n\\n如果大家对 ImageNet Challenge 比赛感兴趣，也想参赛的话，那么很遗憾，参加不了\\n\\n了。因为这个比赛是从 2010 年开始举办，到 2017 年结束，现在这个比赛已经没有了。因\\n\\n为这个比赛的初衷就是希望可以通过比赛来推动计算机视觉技术的发展，很显然，这个目的',\n",
       " '为这个比赛的初衷就是希望可以通过比赛来推动计算机视觉技术的发展，很显然，这个目的\\n\\n已经完全达到，比赛中各个项目的模型效果均已接近甚至超过人类水平。\\n\\n三．ImageNet 对于其他技术领域的影响。ImageNet 最直接的影响肯定是计算机视觉\\n\\n领域，不过除了计算机视觉，ImageNet 也间接推动了其他技术领域的发展。\\n\\n深度学习的主要应用领域是图像，文本和语音等，每个技术领域都有不同的特点，不过\\n\\n也都有一些相通的地方。比如不管在哪个领域使用深度学习都需要涉及到激活函数，代价函\\n\\n数，网络结构设计等这些方面的内容。ImageNet 的发布以及 ImageNet Challenge 比赛促\\n\\n进了深度学习技术的全面发展，让神经网络技术再一次流行起来，使得我们对神经网络/深度\\n\\n学习的技术有了更深刻的理解。所以当我们在其他领域使用深度学习的时候，ImageNet 也\\n\\n起到了潜移默化的作用。\\n\\n307\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.1.4 ImageNet Challenge 历年优秀作品',\n",
       " '10.1.4 ImageNet Challenge 历年优秀作品\\n\\nImageNet Challenge 从 2010 年开始举办到 2017 年结束，总共举办了 8 次。在这 8\\n\\n年的时间里诞生出了很多非常经典而且优秀的模型，让神经网络变得越来越流行，并出现了\\n\\n多种优秀变体，可谓百花齐放。下面我们简单来回顾一下 ImageNet Challenge 比赛的历\\n\\n史，图 10.2 为历年比赛结果（数据来源于 http://image-net.org/challenges/LSVRC/）。\\n\\n图 10.2 ImageNet Challenge 历年比赛结果\\n\\n图 10.2 中的百分比为 ImageNet Challenge 图像分类比赛中的错误率，注意这里的错误\\n\\n率为 Top5 错误率。一般在对 ImageNet 数据进行建模分类的时候，模型都会给出两个错误\\n\\n率结果，一个是 Top1 错误率，一个是 Top5 错误率。Top1 错误率表示模型在预测图像分类\\n\\n的时候只能给出一个最可能的预测结果，预测结果跟真实标签相同则表示预测正确；Top5',\n",
       " '的时候只能给出一个最可能的预测结果，预测结果跟真实标签相同则表示预测正确；Top5\\n\\n错误率表示模型在预测图像分类的时候可以给出 5 个最可能的预测结果，这 5 个最可能的预\\n\\n测结果只要有其中一个跟真实标签相同则表示预测正确。由于 ImageNet Challenge 图像分\\n\\n308\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n类比赛有 1000 个分类，在做预测的时候有一定的错误容忍性，所以经常使用 Top5 错误率\\n\\n作为主要指标判断模型好坏。\\n\\n这里先对历年比赛结果做一个简单的介绍，后面我们还会再具体分析其中一些比较经典\\n\\n和优秀的模型。如果大家仔细看的话会发现，有些年份我列出了冠亚军，有些年份我只列出\\n\\n了冠军。这是因为有些模型虽然在某些年份的比赛中是亚军，但是它的名气，创新程度不亚\\n\\n于冠军，所以我也列出来了。\\n\\n2010 年和 2011 年的冠军使用的都是 SVM 算法，我们知道 SVM 算法是机器学习领域\\n\\n中的经典算法，在深度学习崛起之前，SVM 算法在计算机视觉中有着很多的应用。所以',\n",
       " '中的经典算法，在深度学习崛起之前，SVM 算法在计算机视觉中有着很多的应用。所以\\n\\nImageNet Challenge 比赛的前两届大家用的还是老的思路，使用 SVM 来进行建模。从结\\n\\n果中我们也可以看出来，使用 SVM 来进行大规模的图片分类，得到的效果明显不如深度学\\n\\n习。\\n\\n2012 年对深度学习来说也是一个重要的年份，因为这是深度学习在 ImageNet\\n\\nChallenge 图像分类的比赛上首次获得冠军。创造出这个深度学习模型的冠军团队来自多伦\\n\\n多大学，主要作者是 Alex Krizhevsky，所以这个模型被命名为 AlexNet。团队成员中还有\\n\\nGeoffrey Hinton，我们在本书最开始介绍深度学习领域的名人时有介绍过他，被称为“深\\n\\n度学习教父”的人。Alex Krizhevsky 是 Geoffrey Hinton 的学生，所以这个工作应该是在\\n\\nHinton 大牛的带领下主要由学生完成的。AlexNet 在当时大获成功，相比 SVM，图像识别\\n\\n的错误率有了大幅度的下降。2012 年比赛的亚军使用的算法还是传统机器学习算法，错误率',\n",
       " '的错误率有了大幅度的下降。2012 年比赛的亚军使用的算法还是传统机器学习算法，错误率\\n\\n为 26.17%，而 AlexNet 的错误率已经下降到了 16.42%，拉开了巨大差距。从 2012 年以\\n\\n后，深度学习逐渐崛起，在后来的比赛中，所有人都开始使用深度学习来进行建模。\\n\\n2013 年的冠军来自 Clarifai 公司，他们用的也是深度学习模型，不过他们获得冠军的网\\n\\n络模型不太有名，网上的资料也不多，后面就不多做介绍了。\\n\\n309\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n2014 年的冠军是来自谷歌的团队完成的，所以给模型命名为 GoogleNet。2014 年的亚\\n\\n军模型也很有名，是来自牛津大学的研究组 VGG (Visual Geometry Group) ，所以给模型\\n\\n起名为 VGGNet。这两个模型都是非常有名和经典的模型，所以我在图中都列出来了。\\n\\n2015 年的冠军是来自微软亚洲研究院(MSRA)，他们给模型命名为残差网络（Residual',\n",
       " '2015 年的冠军是来自微软亚洲研究院(MSRA)，他们给模型命名为残差网络（Residual\\n\\nNetwork），所以模型简称为 ResNet。这个网络的层数多达 152 层，网络结构设计非常具\\n\\n有创新性。\\n\\n2016 年的冠军由中国团队获得，是公安部第三研究所的 Trimps-Soushen 团队，他们用\\n\\n的也是深度学习模型，不过他们获得冠军的网络模型不太有名，网上的资料也不多，后面就\\n\\n不多做介绍了。2016 年的亚军是来自加州大学圣地亚哥分校(UCSD)和 Facebook AI\\n\\nResearch(FAIR)的团队，他们的模型是在 ResNet 的基础上进行改进后得到的，所以模型命\\n\\n名为 ResNeXt。\\n\\n2017 年的冠军是来自 Momenta 公司的团队，他们提出了 Squeeze-and-Excitation\\n\\nNetworks（简称 SENet）。\\n\\n8 年来 ImageNet Challenge 比赛不断推动着计算机视觉技术和深度学习的发展。人类',\n",
       " '在 ImageNet Challenge 图像识别比赛上的表现大约是 5.1%的错误率[1]，近年的比赛结果\\n\\n已经比人类的错误率要低了许多。2017 年是 ImageNet Challenge 的最后一年，也是一个\\n\\n时代的终结。2017 年以后，ImageNet 将与全世界最大的数据科学社区 Kaggle 结合，在\\n\\nKaggle 社区里继续举办比赛。ImageNet Challenge 虽然没有了，不过 ImageNet 的影响\\n\\n将继续延续。\\n\\n310\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.2 AlexNet\\n\\nAlexNet 是在 ImageNet Challenge 图像识别比赛上第一个获得冠军的深度学习模型，\\n\\n由自多伦多大学团队完成，主要作者是 Alex Krizhevsky，“深度学习教父” Geoffrey\\n\\nHinton 也在团队中。AlexNet 对后来的深度学习模型设计和模型训练都有着重要的启发和指\\n\\n导作用。最早提出 AlexNet 的论文是《ImageNet Classification with Deep',\n",
       " 'Convolutional Neural Networks》[2]。\\n\\n这里我想稍微多说几句，由于 ImageNet Challenge 是一个比赛，比赛中有很多 Trick\\n\\n可以帮助模型得到更好的结果，比如在 AlexNet 中在当时比较创新的使用了 ReLU 激活函\\n\\n数，和使用 Dropout 来防止过拟合，然后把每张图片切分为多张进行训练和预测，改变图片\\n\\n的颜色以生成更多的数据集等。比赛中的很多 Trick 内容比较分散，并且效果不稳定，有时\\n\\n候可以让结果更好，有时候会让结果更差。所以关于模型的介绍我们主要是介绍模型的结构\\n\\n设计，关于模型在比赛中所使用的 Trick 大家有兴趣可以再另外自行研究。\\n\\n图 10.3 为《ImageNet Classification with Deep Convolutional Neural Networks》\\n\\n论文中的网络结构图。\\n\\n图 10.3 AlexNet 网络结构[2]\\n\\n311\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '311\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Stride 表示步长；Max pooling 表示最大池化；Dense 表示全连接层。输入图片\\n\\n大小为 224×224，实际上作者在构建模型的时候使用的图片大小为 227×227，主要是为了\\n\\n后续计算方便。\\n\\n大家初看这个图可能会觉得这个结构看起来有点复杂，可能暗藏玄机，这个模型的输入\\n\\n是 227×227 的图片（作者把 ImageNet Challenge 比赛的图片都处理成 227×227 的固定\\n\\n大小再传入模型进行训练），后来怎么就变成了上下两个部分，这样设计有什么精妙之处\\n\\n吗？\\n\\n在当时看来，其实没有什么精妙，只是因为当时算力有限，也没有什么好用的深度学习\\n\\n开源框架。他们手上只有两个 GTX580 的 3GB 内存的 GPU，为了加快模型的训练速度，所\\n\\n以他们把模型分为两个部分。一个 GPU 训练上面的部分，一个 GPU 训练下面的部分，所以\\n\\n网络结构就变成了上下两个部分。我猜测如果尽量不改变模型的设计思路，放在今天的软硬',\n",
       " '网络结构就变成了上下两个部分。我猜测如果尽量不改变模型的设计思路，放在今天的软硬\\n\\n件条件下，AlexNet 应该会被设计成图 10.4 所示的结构。\\n\\n图 10.4 AlexNet 网络结构\\n\\n312\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 s 表示 stride，代表步长，s1 代表卷积或池化的步长为 1，s2 代表卷积或池化的\\n\\n步长为 2，以此类推；fc 表示 fully connected，代表全连接；pool 表示 max pooling，代\\n\\n表最大池化；conv 表示 convolution，代表卷积；output 表示输出。\\n\\n其实我猜测的图 10.4 结构和论文中图 10.3 结构还是有一点点小区别的，论文中的结构\\n\\n分为上下两个部分以后，注意看图 10.3 中的卷积的计算，在某些层会分为上下两个部分独立\\n\\n计算，在某些层上下两个部分会一起计算。不过总的来说模型的效果差别不是很大（其实我\\n\\n画的图 10.4 的 AlexNet 结构会比原始的 AlexNet 结构效果差一点点，不过这里我们忽略不',\n",
       " '计）。我们就以图 10.4 来看一下 AlexNet 的网络设计。\\n\\n把图画好其实就可以节省很多文字讲解了，图中已经把所有的卷积池化计算的窗口大\\n\\n小，步长，以及卷积池化计算以后得到的特征图大小和数量都表示出来了，下面我再简单说\\n\\n明一下即可。\\n\\n图中卷积和池化的 padding 方式我没有标出来，有些层使用的是 valid padding，有些\\n\\n层使用的是 same padding，不同的 padding 方式对模型结果一般不会有很大影响，所以图\\n\\n中我就省略了。另外其实通过图中的已知的信息我们可以自己判断出 padding 的方式。\\n\\nAlexNet 是一个 8 层的网络（卷积层和全连接层中有需要训练的权值，所以这里计算网\\n\\n络层数的时候只计算卷积层和全连接层），除了最后输出层用的是 softmax 函数以外，其他\\n\\n层用的都是 ReLU 激活函数。\\n\\nAlexNet 是专门为 ImageNet 级别的数据集设计的，一共有 6000 多万个需要训练的参\\n\\n数，参数的数量巨大。\\n\\n第 1 层计算。网络的输入是 227×227 的“臭臭”照片。经过 11×11 步长为 4 的卷积',\n",
       " '计算后，得到 96 个 55×55 的特征图。然后再进行 3×3 步长为 2 的最大池化计算，得到\\n\\n96 个 27×27 的特征图。\\n\\n313\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 层计算。使用 5×5，步长为 1 的卷积对 96 个 27×27 的特征图进行特征提取，得\\n\\n到了 256 个 27×27 的特征图。然后再用 3×3 步长为 2 的最大池化计算，得到 256 个 13×\\n\\n13 的特征图。\\n\\n第 3 层计算。使用 3×3，步长为 1 的卷积对 256 个 13×13 的特征图进行特征提取，得\\n\\n到了 384 个 13×13 的特征图。\\n\\n第 4 层计算。使用 3×3，步长为 1 的卷积对 384 个 13×13 的特征图进行特征提取，得\\n\\n到了 384 个 13×13 的特征图。\\n\\n第 5 层计算。使用 3×3，步长为 1 的卷积对 384 个 13×13 的特征图进行特征提取，得\\n\\n到了 256 个 13×13 的特征图。然后再用 3×3 步长为 2 的最大池化计算，得到 256 个 6×6\\n\\n的特征图。',\n",
       " '的特征图。\\n\\n第 6 层计算。把 pool3 的 256 个 6×6 的特征图数据跟 fc1 中的 4096 个神经元进行全\\n\\n连接计算。\\n\\n第 7 层计算。把 fc2 的 4096 个神经元跟 fc1 中的 4096 个神经元进行全连接计算。\\n\\n第 8 层计算。把 output 的 1000（ImageNet Challenge 比赛有 1000 个分类）个神经\\n\\n元跟 fc2 中的 4096 个神经元进行全连接计算。最后再经过 softmax 计算得到类别的概率值\\n\\n进行输出。\\n\\n可能大家会有一些疑问，什么 AlexNet 要设计成 8 层的网络？为什么有些卷积后面加上\\n\\n了池化，有些卷积后面没有池化？为什么有些卷积生成的特征图数量是 256，有些是 384？\\n\\n为什么是 384 而不是其他的数字？为什么有 3 个全连接层，为什么是 4096 个神经元？\\n\\n其实这些为什么都很难给出合理的解释，因为直至今天深度学习的可解释性依旧是一个\\n\\n重要科研难题。我觉得 AlexNet 的网络结构是在 Alex 团队有限的时间，有限的实验次数下\\n\\n314',\n",
       " '314\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n得到的最好的模型结构了。如果给他们更好的设备，更多的时间，做更多的实验，他们肯定\\n\\n会得到更优秀的模型，得到更好的结果。\\n\\n我们在 2012 年的时候知道 AlexNet 是一个正确的方向，它开拓了一个新的并且更好的\\n\\n思路，我们只要沿着这个方向继续往前走，肯定有更多的收获等着我们。\\n\\n10.3 VGGNet\\n\\nVGGNet 是 2014 年 ImageNet Challenge 图像识别比赛的亚军。参赛团队是来自牛津\\n\\n大学的研究组 VGG (Visual Geometry Group) 。VGGNet 的很多设计思想都受到 AlexNet\\n\\n的影响，所以跟 AlexNet 也有一点点相似的地方。VGGNet 不仅在图像识别方向有着广泛应\\n\\n用，很多目标检测，目标分割，人脸识别等方面的应用也会使用 VGGNet 作为基础模型。\\n\\nVGGNet 在 2014，2015 年左右的流行程度甚至超过了 2014 年 ImageNet Challenge',\n",
       " '图像识别比赛的冠军 GoogleNet，是当时用得最多的深度学习模型。VGGNet 被广泛使用\\n\\n也是有一定原因的，VGGNet 的网络结构比较简单，也容易搭建，并且 VGGNet 的单模型结\\n\\n果与 GoogleNet 相当。ImageNet Challenge 是一个比赛，在比赛中我们经常会使用模型\\n\\n融合（Ensemble Model）策略，把多个模型组合在一起，这样有可能会得到更好的结果。\\n\\n2014 年，在 ImageNet Challenge 比赛中，多个 GoogleNet 融合后的结果比多个\\n\\nVGGNet 融合后的结果要更好，所以 GoogleNet 得到了冠军。最早提出 VGGNet 的论文是\\n\\n《Very Deep Convolutional Networks for Large-Scale Image Recognition》[3]。\\n\\n其实，VGGNet 有多个版本，如图 10.5 所示。\\n\\n315\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.5 VGGNet 的多个版本[3]',\n",
       " '图 10.5 VGGNet 的多个版本[3]\\n\\n从图中 ConvNet Configuration 表示网络结构；weight layers 表示网络层数；input\\n\\n表示输入；conv 表示卷积；maxpool 表示最大池化；FC 表示全连接层。\\n\\n我们可以看出 VGGNet 有 6 个不同的版本，他们的主要区别是网络层数和网络结构的区\\n\\n别。图中的 conv3 表示 3×3 的卷积，conv1 表示 1×1 的卷积；conv3-128 表示 3×3 的\\n\\n卷积计算后生成 128 个特征图；LRN(Local Response Normalization)是局部响应归一\\n\\n化，一种在 AlexNet 中使用的数据归一化计算，不过 VGGNet 的作者认为 LRN 并没有什么\\n\\n用，所以在 VGGNet 中并没有使用。\\n\\n其中使用得比较多的有 B，因为它有 13 层，我们称之为 VGG13。使用得比较多的还有\\n\\nD，因为它有 16 层，我们称之为 VGG16。使用得比较多的还有 E，因为它有 19 层，我们称',\n",
       " '之为 VGG19。在 ImageNet Challenge 图像识别比赛中效果最好的是 VGG19，其次到\\n\\nVGG16，最后是 VGG13。\\n\\n316\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n每个版本的模型网络结构不同，所以参数的数量也有所不同。参数数量最少的是 A，有 1\\n\\n亿 3 千多万个参数。最多的是 E，有 1 亿 4 千多万个参数。别看网络中有很多的卷积层，其\\n\\n实网络中大部分的参数都是在全连接层中。比如在 VGG16 中，卷积层的参数数量占所有参\\n\\n数的 13%，而全连接层的参数数量占到了 87%。\\n\\n在很多应用中 VGG16 似乎用得更多一些，下面我们来看一下 VGG16 的网络结构图\\n\\n10.6 所示。\\n\\n图 10.6 VGG16 网络结构\\n\\n图中 fc 表示 fully connected，代表全连接；pool 表示 max pooling，代表最大池化；\\n\\nconv 表示 convolution，代表卷积；output 表示输出。',\n",
       " 'conv 表示 convolution，代表卷积；output 表示输出。\\n\\nVGG16 的所有卷积都是 3×3，步长为 1，same padding；所有池化都是 2×2，步长\\n\\n为 2，same padding；输出层函数为 softmax，除了输出层以外，其他层激活函数都是\\n\\nReLU 函数。\\n\\nVGG16 受 AlexNet 的影响和启发，图片的输入为 224×224 的大小，卷积层后面也使\\n\\n用了 3 个全连接层，并且全连接层也是使用 4096 个神经元。\\n\\n317\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nVGG16 是一个 16 层的网络，它的结构比较简单易懂，叠加了很多个卷积池化层。2×\\n\\n2，步长为 2 的池化特会使得特征图的长宽减少为原来 1/2，池化后的下一个卷积会使得特征\\n\\n图的数量会变成原来的 2 倍。\\n\\nVGG16 的输入是 224×224 大小的图片。\\n\\nblock1 为第 1，2 层，其中包含了 2 个卷积和 1 池化，卷积后图像大小没有发生变化',\n",
       " 'block1 为第 1，2 层，其中包含了 2 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n224×224，池化后特征图大小变成了 112×112，特征图的数量为 64。\\n\\nblock2 为第 3，4 层，其中包含了 2 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n112×112，池化后特征图大小变成了 56×56，特征图的数量为 128。\\n\\nblock3 为第 5，6，7 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生变化\\n\\n56×56，池化后特征图大小变成了 28×28，特征图的数量为 256。\\n\\nblock4 为第 8，9，10 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生变\\n\\n化 28×28，池化后特征图大小变成了 14×14，特征图的数量为 512。\\n\\nblock5 为第 11，12，13 层，其中包含了 3 个卷积和 1 池化，卷积后图像大小没有发生\\n\\n变化 14×14，池化后特征图大小变成了 7×7，特征图的数量为 512。大家可能会稍微有点',\n",
       " '变化 14×14，池化后特征图大小变成了 7×7，特征图的数量为 512。大家可能会稍微有点\\n\\n疑惑，block5 中的特征图的数量按照规律不应该会变成 1024 吗，但是这里还是 512。这里\\n\\n的原因我猜测是作者他们肯定也尝试过 1024，但是最后的效果估计跟 512 的效果差不多。\\n\\n并且改成 1024 后会增加很多计算量和需要训练的权值，所以最后的版本中就没有使用\\n\\n1024。\\n\\n第 14 层计算。把 pool5 的 512 个 7×7 的特征图数据跟 fc1 中的 4096 个神经元进行全\\n\\n连接计算。\\n\\n第 15 层计算。把 fc2 的 4096 个神经元跟 fc1 中的 4096 个神经元进行全连接计算。\\n\\n318\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 16 层计算。把 output 的 1000（ImageNet Challenge 比赛有 1000 个分类）个神\\n\\n经元跟 fc2 中的 4096 个神经元进行全连接计算。最后再经过 softmax 计算得到类别的概率\\n\\n值进行输出。',\n",
       " '值进行输出。\\n\\nVGGNet 网络结构本身并没有太多创新的内容，它可以看成是对 AlexNet 网络的改进优\\n\\n化版本。\\n\\n10.4 GoogleNet\\n\\nGoogleNet 是 2014 年 ImageNet Challenge 图像识别比赛的冠军。从它的名字我们就\\n\\n可以看出是来自谷歌的团队完成的。前面我们有介绍，GoogleNet 之所以获得冠军，是因为\\n\\n它进行模型融合以后得到的效果要比 VGGNet 模型融合之后的效果要好。不过单模型比拼，\\n\\n它与 VGGNet 的效果相当。\\n\\n虽然 GoogleNet 的模型的效果跟 VGGNet 相差不大，不过它比 VGGNet 更具有创新\\n\\n性。GoogleNet 有一些更具创新性的设计，为后来的模型设计提供了很多新的思路。最早提\\n\\n出 GoogleNet 的论文是《Going Deeper with Convolutions》[4]。\\n\\n10.4.1 1×1 卷积介绍\\n\\n在介绍 GoogleNet 结构之前，我们必须先来介绍一下什么是 1×1 卷积。1×1 卷积在',\n",
       " '在介绍 GoogleNet 结构之前，我们必须先来介绍一下什么是 1×1 卷积。1×1 卷积在\\n\\nGoogleNet 中有着大量应用，是一个非常重要的设计。它的主要作用主要有两个，一是增加\\n\\n网络非线性，二是减少计算量和需要训练的权值。\\n\\n319\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n所谓 1×1 卷积其实很简单，就是卷积核的大小是 1×1，其他方面跟之前我们学习的卷\\n\\n积没有区别。图 10.7 为 1×1 卷积示意图。\\n\\n图 10.7 1×1 卷积\\n\\n使用 1×1 卷积对 6×6 图像进行特征提取，然后得到 6×6 的特征图。我们可以这么理\\n\\n解，只考虑对 1 张图像进行卷积计算时，3×3，5×5 这样的大卷积核可以对大范围区域的\\n\\n特征进行提取然后得到 1 个特征值。1×1 的卷积只对图上的 1 个值进行特征提取然后得到 1\\n\\n个特征值。那么下面我们具体来看一下 1×1 卷积如何应用于实际的网络搭建。我们先考虑\\n\\n一个没有 1×1 卷积的卷积层计算，如图 10.8 所示。\\n\\n图 10.8 没有加入 1×1 卷积的卷积计算',\n",
       " '图 10.8 没有加入 1×1 卷积的卷积计算\\n\\n图中 conv 表示卷积。\\n\\n从图中可知 192 个 28×28 的特征图经过 5×5，步长为 1 的卷积进行特征提取，得到 32\\n\\n个 28×28 的特征图。这里我们主要考虑一下图中的权值数量和计算量。关于卷积的权值数\\n\\n量和计算量的计算我们在第 8 章中已有详细介绍，下面我们就不再详细说明了：\\n\\n320\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n权值数量的计算为：5×5×192×32+32 个偏置值=153632。\\n\\n计算量为（这里我们只计算乘法的计算量）：5×5×28×28×192×32≈120M，M 为\\n\\nmillion 百万。\\n\\n我们对正常卷积计算的权值数量和计算量有了大致的了解，下面我们再来看一下加入 1×\\n\\n1 卷积后的计算，如图 10.9 所示。\\n\\n图 10.9 加入了 1×1 卷积的卷积计算\\n\\n图中 conv 表示卷积。\\n\\n从图中可知 192 个 28×28 的特征图经过两次卷积，最后得到 32 个 28×28 的特征图，',\n",
       " '最左边和最右边的特征图跟图 10.8 中的左右两边的特征图是完全一样的，只是图 10.9 中间\\n\\n多了一次 1×1 的卷积。\\n\\n从表面上看，我们就可以看出 1×1 卷积的第一个作用了，增加网络的非线性。因为网络\\n\\n的层数多了一层，层数越多，网络的非线性就越强。\\n\\n下面我们再来计算一下加入 1×1 卷积后网络的权值数量和计算量。\\n\\n权值数量的计算为：第一个卷积层：1×1×192×16+16 个偏置值=3088。第二个卷积\\n\\n层：5×5×16×32+32 个偏置值=12832。两个卷积层权值数量相加\\n\\n3088+12832=15920，约为图 10.9 中没有 1×1 卷积的 1/10。\\n\\n321\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n计算量为（这里我们只计算乘法的计算量）：第一个卷积层：1×1×28×28×192×\\n\\n16≈2.4M，M 为 million 百万。第二个卷积层：5×5×28×28×16×32≈10M。两个卷积层\\n\\n计算量相加 2.4M+10M=12.4M，约为图 10.9 中没有 1×1 卷积的 1/10。',\n",
       " '计算量相加 2.4M+10M=12.4M，约为图 10.9 中没有 1×1 卷积的 1/10。\\n\\n这就是 1×1 卷积的第二个作用，减少计算量和需要训练的权值。初看这个结果大家可能\\n\\n会有点难接受。前后两端都没有发生变化，看起来明明是多了一个卷积层，感觉上应该会有\\n\\n更多的权值和更多的计算量才对。\\n\\n其实大家只要仔细再看一下就能发现其中的原因。其中一个原因是 1×1 卷积本身的计算\\n\\n量和权值数量就很少，另一个重要原因是“16”。1×1 卷积计算后生成了 16 个 28×28 的特\\n\\n征图，比最后输出的 32 个 28×28 特征图的特征数量更少，相当于 1×1 卷积对原来的特征\\n\\n图进行了特征压缩。特征数量越少，计算量和权值数量自然就越少了。\\n\\n如果上面计算中我们把 16 改成 160，1×1 卷积后产生 160 个 28×28 的特征图，那么使\\n\\n用了 1×1 卷积的计算，它的权值数量和计算量都跟不使用 1×1 卷积差不多。\\n\\n所以并不是说用了 1×1 卷积，就一定可以减少权值数量和计算量，也要看 1×1 卷积后生',\n",
       " '所以并不是说用了 1×1 卷积，就一定可以减少权值数量和计算量，也要看 1×1 卷积后生\\n\\n成了多少张特征图。不过通常来说，我们不会让 1×1 卷积生成太多的特征图，所以一般来说\\n\\n加入 1×1 卷积后是可以减少网络权值数量和计算量的。\\n\\n10.4.2 Inception 结构\\n\\n在 GoogleNet 最特别的设计就是 Inception 结构，所以 GoogleNet 在后来的版本中改\\n\\n了名字，模型的名字改成了 Inception，而 GoogleNet 就是 Inception-v1。Inception 结构\\n\\n如图 10.10 所示。\\n\\n322\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.10 Inception 结构[4]\\n\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\n\\npooling 表示最大池化，previous layer 表示前一层。\\n\\n图 10.10 中左边的结构是 Inception 原始的版本，右边的结构是 Inception 后来优化的',\n",
       " '版本了。前面我们已经介绍过 1×1 卷积的作用，所以在（b）中我们看到 1×1 卷积应该知道\\n\\n它的用意了，增加网络的层数以增加非线性，同时减少网络的权值数量和计算量。\\n\\n不过 Inception 最特别的设计不是在于 1×1 卷积，而是在于同时使用多种不同尺度的卷\\n\\n积核。我们可以看到 Inception 结构中使用了 1×1 卷积，3×3 卷积，5×5 卷积和一个最大\\n\\n池化。卷积的作用我们应该很清楚了，用来做特征提取。不同的卷积核的数值可以提取不同\\n\\n的特征，那么不同大小的卷积核当然也是可以从不同的尺度来提取特征的。从一个小区域提\\n\\n取出来的特征跟从一个大区域提取出来的特征当然是不一样的。所以 Inception 具有创新的\\n\\n设计在于使用了多种不同尺度的卷积核来提取不同尺度的特征。\\n\\n下面我们举一个具体的例子来说明 Inception 结构的计算，如图 10.11 所示。\\n\\n323\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.11 Inception module\\n\\n图中 conv 表示卷积，pool 表示池化。',\n",
       " '图中 conv 表示卷积，pool 表示池化。\\n\\nInception module 是从 GoogleNet 结构中拿出来的一个具体计算的例子。输入是 192\\n\\n个 28×28 的特征图，Inception module 会对这些特征图进行不同的特征提取计算。假如我\\n\\n们把 Inception 看成是有 4 个通道的特征提取计算：\\n\\n第 1 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 64 个 28×\\n\\n28 的特征图。\\n\\n324\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 2 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 96 个 28×\\n\\n28 的特征图。然后再做 3×3，步长为 1，same padding 卷积，生成 128 个 28×28 的特征\\n\\n图。\\n\\n第 3 个通道就是对输入特征做 1×1，步长为 1，same padding 卷积，生成 16 个 28×',\n",
       " '28 的特征图。然后再做 5×5，步长为 1，same padding 卷积，生成 32 个 28×28 的特征\\n\\n图。\\n\\n第 4 个通道就是对输入特征做 3×3，步长为 1，same padding 的最大池化，生成 192\\n\\n个 28×28 的特征图。然后再做 1×1，步长为 1，same padding 卷积，生成 32 个 28×28\\n\\n的特征图。\\n\\n最后再把这 4 个通道分别得到的特征图组合起来，得到 64+128+32+32=256 个 28×\\n\\n28 的特征图。\\n\\n在 GoogleNet 中叠加了很多个 Inception 结构，使得网络的层数变得非常多，并且网络\\n\\n特征提取的能力特别强。\\n\\n10.4.3 GoogleNet 网络结构\\n\\n这一小节我们来具体看一下 GoogleNet 的网络结构，如图 10.12 所示。\\n\\n325\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n326\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.12 GoogleNet 网络结构[4]',\n",
       " '图 10.12 GoogleNet 网络结构[4]\\n\\n图中的 conv 表示卷积；MaxPool 表示最大池化；LocalRespNorm 表示局部响应归一\\n\\n化；DepthConcat 表示数据拼接；FC 表示全连接层；AveragePool 表示平均池化。\\n\\n我们就先从整体上来了解一下 GoogleNet，它是一个 22 层的网络，网络的输入跟\\n\\nVGGNet 一样也是 224×224。除了最后一层用的是 softmax 函数外，其它层的激活函数都\\n\\n是 ReLU 函数。我们可以看到 GoogleNet 的主要结构组成是 Inception module，一共叠加\\n\\n了 9 个 Inception。GoogleNet 网络的一些具体细节如图 10.13 所示。\\n\\n图 10.13 GoogleNet 结构细节[4]\\n\\n图中的 type 表示层的类型；patch size/stride 表示窗口大小/步长；output size 表示输\\n\\n出大小；depth 表示深度；params 表示参数数量；ops 表示计算量；convolution 表示卷',\n",
       " '积；max pool 表示最大池化；avg pool 表示平均池化；linear 表示全连接层。\\n\\n别看 GoogleNet 有 22 层之多，它的权值参数数量只有 600 多万，仅约为 AlexNet 的\\n\\n1/10，VGGNet 的 1/20。\\n\\n327\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nGoogleNet 的输入是 224×224×3 的彩色图片，从图中我们可以看到第一个卷积是 7×7\\n\\n步长为 2，卷积后得到 64 个 112×112 的特征图。卷积后进行了一次 3×3 步长为 2 的最大\\n\\n池化，得到 64 个 56×56 的特征图。\\n\\n接下来再进行一次 1×1 步长为 1 的卷积得到 64 个 56×56 的特征图，卷积后再进行 3×\\n\\n3 步长为 1 的卷积，得到 192 个 56×56 的特征图。这里我们要注意，图中第 3 行的卷积，\\n\\ndepth 为 2，说明这里是有 2 层卷积。图中的 reduce 其实是表示 1×1 卷积的意思，#3×3',\n",
       " 'reduce 表示 3×3 卷积之前的 1×1 卷积。#5×5 reduce 表示 5×5 卷积之前的 1×1 卷积。\\n\\n卷积后再进行一次 3×3 步长为 2 的最大池化，得到 192 个 28×28 的特征图。\\n\\n下面我们看到了第一个 Inception 模块 inception(3a)，每个 inception 模块都有两层卷\\n\\n积，所有 depth 为 2。\\n\\n图中的信息还是很完整的，所以我们只要仔细看一下图中信息我们就可以知道\\n\\nGoogleNet 的网络结构了。中间部分的计算这里就省略不讲了，大家可以自己看。\\n\\n我们可以想一下，在之前的网络中卷积池化计算后得到很多特征图，最后我们还需要做\\n\\n全连接得到最后的分类结果。那么卷积池化计算后得到的特征图是一个 4 维的数据，所以我\\n\\n们还需要做一个“Flatten”，把 4 维数据变成 2 维，因为全连接必须是 2 维数据，AlexNet\\n\\n和 VGGNet 中都是这么做的。\\n\\nGoogleNet 的平均池化 avg pool 设计。我们看一下图中倒数第 4 行“avg pool”，',\n",
       " '这是平均池化，这个“avg pool”放在 inception(5b)后面，我们之前在介绍池化操作的时\\n\\n候有介绍过平均池化，不过在实际网络搭建中还没有介绍过。这里使用的“avg pool”，它\\n\\n的作用跟“Flatten”的作用其实类似，主要目的是把 4 维的特征图数据变成 2 维的数据，再\\n\\n跟后面的 1000 个分类神经元进行全连接。\\n\\n328\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\ninception(5b)的输出是 1024 个 7×7 的特征图，“avg pool”窗口大小为 7×7，所以\\n\\n也就是每个特征图求平均得到 1 个特征值，那么 1024 个特征图就可以提取出 1024 个特征\\n\\n值，最后再跟 1000 个神经元进行全连接。GoogleNet 的论文中有提到，把“Flatten”后连\\n\\n接 1024 个神经元改成“avg pool”得到 1024 个特征值，ImageNet Challenge 图像识别\\n\\n比赛 Top1 准确率提高了 0.6%[4]。另外使用“avg pool”还可以减少模型的权值数量，因为',\n",
       " '全连接层会产生大量权值，而池化计算是没有权值的。\\n\\nGoogleNet 的辅助分类器 auxiliary classifiers 设计。最后我还想再给大家介绍一下在\\n\\n图 10.13 中，GoogleNet 的网络有 3 个输出，中间部分的两个输出是 GoogleNet 设计的两\\n\\n个辅助分类器。作者引入的两个辅助分类器也会经过 softmax 函数后输出预测结果，预测结\\n\\n果跟真实标签做对比得到辅助损失 aux_loss，该模型总损失等于真实损失和辅助损失的加权\\n\\n和，论文中每个辅助损失使用的权重值是 0.3，总的 loss 公式如下：\\n\\n𝑡𝑜𝑡𝑎𝑙(cid:132)(cid:210)(cid:222)(cid:222) = 𝑟𝑒𝑎𝑙(cid:132)(cid:210)(cid:222)(cid:222) + 0.3 × 𝑎𝑢𝑥(cid:132)(cid:210)(cid:222)(cid:222)– + 0.3 × 𝑎𝑢𝑥(cid:132)(cid:210)(cid:222)(cid:222)(cid:157)',\n",
       " '这两个辅助分类器的作用是增加反向传播的梯度信号[4]，也就是说即使整个网络都是用了\\n\\nReLU 激活函数，但是网络的层的比较多（22 层），梯度信号在反向传递的过程中，还是会\\n\\n损失掉一些有用的信号。 所以作者在中间层加入两个辅助分类器，帮助中间层那部分的权值\\n\\n和靠近输入层那部分的权值更好的训练。\\n\\n辅助分类器只在模型训练阶段起作用，模型预测结果辅助分类器是不使用的。\\n\\n329\\n\\n(10.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.5 Batch Normalization\\n\\n在介绍后面新的一些网络模型之前，这小节我们先介绍一下 Batch Normalization，因为\\n\\n近几年很多网络中都使用了 Batch Normalization 技术。\\n\\nBatch Normalization 中文一般称为批量标准化/批量规范化/批量归一化等，本书中我\\n\\n们就称为批量标准化好了。Batch Normalization 英文的简称一般为 BatchNorm 或 BN，本',\n",
       " '书中我们就称为 BN 好了。BN 是 Google 研究员 Sergey Ioffe 和 Christian Szegedy 在\\n\\n2015 年提出的一种标准化策略。BN 提出以后，很多网络都使用了 BN 的技术。这里特别说\\n\\n明一下很多网络模型用了 BN 以后效果有所提升，但并不是所有模型用了 BN 就会更好，所\\n\\n以我们可以把它看成是一个很可能有效的网络优化策略。下面对 BN 的介绍主要是参考 BN\\n\\n的原始论文《Batch Normalization: Accelerating Deep Network Training by Reducing\\n\\nInternal Covariate Shift》[5]。我觉得 BN 虽然有效，但并不是一个很好理解的技术，如果\\n\\n大家看了以后不是特别理解的话也不用钻牛角钻尖，先接受它的作用，至于它的原理有时间\\n\\n再慢慢品。\\n\\n10.5.1 Batch Normalization 提出背景\\n\\nBN 的提出主要由于网络的内部协变量偏移（Internal Covariate Shift），简称 ICS。',\n",
       " 'BN 作者在论文中给出了 ICS 一个比较规范的定义：在深度学习网络的训练过程中网络内部\\n\\n结点的分布变化称为内部协变量偏移[5]。其实说白了就是深度学习的深层网络之间的关系很\\n\\n复杂，每一层数据的微小变化都会随着网络一层一层的传递而被逐渐放大（类似于蝴蝶效\\n\\n应）。底层网络（假设靠近输入层的网络我们称为底层网络）输入的微小变化，就会引起高\\n\\n330\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n层网络（假设靠近输出层的网络我们称为高层网络）输入分布的剧烈变化，高层网络需要不\\n\\n断去重新适应底层网络的参数更新。这就使得网络训练起来比较困难，也比较慢。\\n\\n10.5.2 数据标准化（Normalization）\\n\\n在机器学习领域中，数据标准化是一种很常用的数据处理策略。通常就是对输入数据的\\n\\n每个维度的特征进行标准化。具体做法就是所有数据每个维度的特征减去该维度的平均值再\\n\\n除以该维度的标准差。\\n\\n𝑥˝@ =\\n\\n𝑥@ − 𝜇 √𝜎# + 𝜖\\n\\n𝑥@为某个特征维度的第 n 个值，𝜇为该维度的平均值，𝜎为该维度的标准差，𝜖为一个接近',\n",
       " '𝑥@为某个特征维度的第 n 个值，𝜇为该维度的平均值，𝜎为该维度的标准差，𝜖为一个接近\\n\\n于 0 的常数防止分母为 0。如图 10.14 所示。\\n\\n图 10.14 数据标准化\\n\\n图中 a 有 5 个数据，每个数据有 4 个特征，每个特征的大小不一，经过标准化处理以后\\n\\n得到 b，b 中的数据都是在 0 附近的一些值，数值大小差不多。经过标准化以后的数据 b 每\\n\\n个特征的均值都是 0，方差为 1。标准化以后的数据可以消除特征尺度（有些特征数值比较\\n\\n大，有些特征数值比较小）对于模型训练的影响。并且 a 中特征之间的相关系数和 b 中特征\\n\\n之间的相关系数是一样的。特征之间的相关系数不会因为标准化而改变。\\n\\n331\\n\\n(10.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10.5.3 Batch Normalization 模型训练阶段\\n\\n我们了解深度学习模型存在的 ICS 问题后，BN 作者提出了对神经网络每一层数据进行标\\n\\n准化处理的策略。普通的数据标准化只是对输入的样本数据进行标准化处理，然后再放入模',\n",
       " '准化处理的策略。普通的数据标准化只是对输入的样本数据进行标准化处理，然后再放入模\\n\\n型进行训练。而 BN 是对网络每一层的输入特征进行标准化处理，使得每一层的每个输入特\\n\\n征都是均值为 0，方差为 1 的分布。每一层标准化的公式都如同公式 10.2。\\n\\n在计算网络每一层的每个信号的均值和标准差的时候，我们并不是一次性把所有数据都\\n\\n传入模型进行计算。因为计算机内存大小有限，所以我们训练模型的时候通常都是对数据进\\n\\n行分批次 mini-batch 的训练。所以这里每层信号计算的均值和标准差都是针对一个批次\\n\\nmini-batch 来说的，所以这个算法的名字是 Batch Normalization。\\n\\n不过我们对每一层的输入信号做标准化处理可能会改变该层数据的表达。因为标准化处\\n\\n理会把一组数据变成另一组数据，每一组数据所包含的信息都是不同的，所以不能做完标准\\n\\n化处理就完事了。因此作者还对标准化后的数据进行了线性变换的处理：\\n\\n𝑦((cid:131)) = 𝛾((cid:131))𝑥˝((cid:131)) + 𝛽((cid:131))',\n",
       " '𝑥˝((cid:131))表示网络某一层第 k 维度进行标准化后的数值，𝑦((cid:131))表示𝑥˝((cid:131))线性变换后的结果，𝛾((cid:131))\\n\\n和𝛽((cid:131))表示网络某一层第 k 维度的两个参数。使用𝛾((cid:131))和𝛽((cid:131))这两个参数可以对数据进行线性\\n\\n变换。每一层网络的每一个维度都会有不同的𝛾和𝛽，𝛾和𝛽的具体数值是由网络训练得到的，\\n\\n不是人为设置的。\\n\\n比如网络某一层某个特征 x，该特征的 mini-batch 计算得到的平均值是𝜇，标准差是𝜎。\\n\\nx 进行标准化后得到𝑥˝，𝑥˝经过线性变换后得到 y。那么有一个比较特别的结果，当𝛾 = 𝜎，并\\n\\n且𝛽 = 𝜇时线性变换后的结果 y 刚好等于标准化之前的特征 x。也就是作者设计的线性变换的\\n\\n计算实际上是可以恢复原始数据的表达的，不过一般不会这么巧，毕竟𝛾和𝛽是通过模型训练\\n\\n332\\n\\n(10.3)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n得到的。不管怎么说，𝛾和𝛽还是可以一定程度上起到恢复数据表达能力的作用。每层数据标',\n",
       " '得到的。不管怎么说，𝛾和𝛽还是可以一定程度上起到恢复数据表达能力的作用。每层数据标\\n\\n准化和线性变换的计算流程如图 10.15 所示。\\n\\n图 10.15 BN 计算流程[5]\\n\\n图中内容就是我们前面讲的流程，先对数据进行标准化，然后再做线性变换。\\n\\n10.5.4 Batch Normalization 模型预测阶段\\n\\n模型训练阶段我们已经介绍完了，主要就是对每一层数据进行标准化处理和线性变换后\\n\\n再传入下一层，模型训练好之后我们就把每一层每个维度的𝛾和𝛽训练好了。那么在模型预测\\n\\n阶段我们也要对每一层的特征进行标准化处理，不过在测试阶段我们可能只传入一个数据进\\n\\n行预测，只有一个数据的话计算均值和标准差就没有意义了。所以在模型测试阶段使用的均\\n\\n值和标准差的数据其实是使用训练集数据计算得到的。\\n\\n在模型训练阶段，我们会分批次训练模型，每一个批次在网络的每一层的每个特征都可\\n\\n以计算出该批次的特征均值𝜇和特征方差𝜎#。我们在训练阶段把所有批次的特征均值和特征\\n\\n方差都保存下来，然后计算出所有特征均值的均值𝐸[𝜇]和所有特征方差的均值𝐸[𝜎#]，再把',\n",
       " '方差都保存下来，然后计算出所有特征均值的均值𝐸[𝜇]和所有特征方差的均值𝐸[𝜎#]，再把\\n\\n𝐸[𝜇]和𝐸[𝜎#]应用到预测阶段的标准化计算中。\\n\\n333\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n每一层的特性𝑥先减去用训练集数据计算得到的均值𝐸[𝜇]，再除以用训练集数据计算得到\\n\\n的标准差g𝐸[𝜎#] + 𝜖，再做线性变换乘以𝛾加上𝛽，公式如下：\\n\\n𝑦 =\\n\\n𝑥 − E[𝜇]\\n\\ng𝐸[𝜎2] + 𝜖\\n\\n𝛾 + 𝛽\\n\\n10.5.5 Batch Normalization 作用分析\\n\\n在 BN 的原始论文中作者总结了 BN 的很多作用，不过我觉得 BN 的主要作用可以简化的\\n\\n总结为：\\n\\n1.加快模型训练速度。这个作用不需要多说，加快模型训练速度可以节约很多模型训练\\n\\n的时间。\\n\\n2.具有一定正则化作用。使用了 BN 可以减少 Dropout 的使用，甚至不用 Dropout，并\\n\\n且可以减少 L2 正则化的使用。\\n\\n3.有机会使得模型效果更好。这个效果不是绝对的，不过很多模型使用了 BN 之后效果确\\n\\n实变得更好了，所以 BN 值得一试。',\n",
       " '实变得更好了，所以 BN 值得一试。\\n\\n在《Batch Normalization: Accelerating Deep Network Training by Reducing\\n\\nInternal Covariate Shift》论文中，还使用了 ImageNet 数据集对 BN 的效果做了一些实验\\n\\n分析，如图 10.16 所示。\\n\\n334\\n\\n(10.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.16 BN 实验分析[5]\\n\\n图中的准确率是使用 ImageNet 验证集计算得到的，由于这里计算的是 Top1 准确率，\\n\\n所以这些模型都没有到 80%。\\n\\nInception 就是 GoogleNet，学习率为 0.0015。这个模型差不多是当时最好的图像识别\\n\\n模型了。\\n\\nBN-Baseline 为加上了 BN 的 Inception，其它训练参数一致。我们可以看到，加上 BN\\n\\n后模型训练速度快了很多。\\n\\nBN-x5 跟 BN-Baseline 结构一样，只不过学习率是 Inception 的 5 倍，为 0.0075。我',\n",
       " '们可以看到，学习率变大以后，模型训练得更快了。（如果没有使用 BN 的话，学习率不能\\n\\n设置得太大，会使得模型调整太剧烈，导致模型无法训练或者训练的效果不好）\\n\\nBN-x30，跟 BN-Baseline 结构一样，只不过学习率是 Inception 的 30 倍。我们可以看\\n\\n到更大的学习率不能使得模型更快，虽然加上 BN 以后学习率可以设置得大一些，但是也不\\n\\n能太大。\\n\\nBN-x5-Sigmoid 跟 BN-x5 类似，只不过激活函数用的是 Sigmoid 函数（其它模型都是\\n\\n用 ReLU 函数）。不用 BN 的话 Sigmoid 在 GoogleNet 中是无法使用的，由于梯度消失会\\n\\n335\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n使得模型无法训练。用了 BN 以后连 Sigmoid 函数也 work 起来了，虽然最后的模型效果还\\n\\n是不太理想。\\n\\nSteps to match Inception 表示这几个模型达到同一准确率的位置。\\n\\n几个模型的训练结果如图 10.17 所示。\\n\\n图 10.17 几个模型训练结果[5]',\n",
       " '几个模型的训练结果如图 10.17 所示。\\n\\n图 10.17 几个模型训练结果[5]\\n\\n图中的 Model 表示模型；Mac accuracy 表示最大准确率。\\n\\n从模型训练结果可以看出加上了 BN 的模型训练速度都比较快。训练结果最好的是 BN-\\n\\nx30，最差的是 BN-x5-Sigmoid，说明给模型加上 BN 以后有可能会得到更好的结果。\\n\\nBN 的作者融合了 6 个 BN-x30 模型，在 ImageNet 的验证集得到了 4.9%的 Top5 错误\\n\\n率，在测试集得到了 4.82%的 Top5 错误率，在当时应该是 ImageNet 数据集最好的结果\\n\\n了。\\n\\n10.6 ResNet\\n\\nResNet 是 2015 年 ImageNet Challenge 图像识别比赛的冠军，由微软亚洲研究院\\n\\n(MSRA)的研究团队完成，团队的负责人为何恺明。ResNet 的论文获得了 2016 年\\n\\nCVPR(IEEE Conference on Computer Vision and Pattern Recognition)的最佳论文，并\\n\\n336',\n",
       " '336\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n且是 2019 年机器学习领域被引用次数最多的论文，达到了 18000 多次。下面对 ResNet 的\\n\\n思路进行介绍，主要是参考论文《Deep Residual Learning for Image Recognition》[6]。\\n\\n10.6.1 ResNet 背景介绍\\n\\n在介绍 ResNet 网络之前我们先介绍一下何恺明，因为他是目前计算机视觉领域最知名\\n\\n最活跃的专家之一，其代表作 ResNet 更是一鸣惊人。\\n\\n何恺明在广州长大，从小就是好学生，2003 年保送清华大学。即便如此他还是参加了广\\n\\n东省高考，得到了 900 分满分的成绩。\\n\\n2007 年何恺明进入微软亚洲研究院(MSRA)的视觉计算组实习，实习导师是孙剑（现旷\\n\\n视科技首席科学家），当时视觉计算组的负责人是汤晓鸥（商汤科技创始人）。\\n\\n2011 年香港中文大学博士毕业后正式加入 MSRA 。\\n\\n2016 年 8 月，何恺明离开微软亚洲研究院，加入 Facebook AI 研究院（FAIR）。',\n",
       " '2020 年 1 月 11 日，荣登 AI 全球最具影响力学者榜单。\\n\\n观察 ImageNet Challenge 前几届的优秀模型，我们不难发现一个现象，似乎模型的层\\n\\n数越多，效果就越好。AlexNet 有 8 层，VGG19 有 19 层，GoogleNet 有 22 层。于是\\n\\nResNet 团队就做了一个实验，他们模仿 VGGNet 的模型，分别设计了 20，32，44，56 层\\n\\n的网络，并使用 CIFAR-10 数据集进行测试，测试结果如图 10.18 所示。\\n\\n337\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.18 不同深度的网络结果对比\\n\\n图中的 iter 表示迭代次数，error 表示误差。\\n\\n《Deep Residual Learning for Image Recognition》论文中把模仿 VGGNet 做出来的\\n\\n一些模型称为“plain network”。实验结果表明，20 层的网络误差最低，56 层的网络误差\\n\\n最高，并且层数越多误差越大，实验结果刚好是跟我们前面的猜想是相反的。',\n",
       " '最高，并且层数越多误差越大，实验结果刚好是跟我们前面的猜想是相反的。\\n\\n网络层数不是太多的时候，模型的正确率确实会随着网络的层数增加而提升，不过随着\\n\\n网络层数的增加，正确率也会达到饱和，这个时候如果再继续增加网络层数，那么正确率就\\n\\n会下降。ResNet 论文中把这种现象称为退化问题（Degradation Problem），并且\\n\\nResNet 作者认为退化问题不是由过拟合引起的。\\n\\n10.6.2 残差块（Residual Block）介绍\\n\\nResNet 之所以叫残差网络（Residual Network），是因为 ResNet 是由很多残差块\\n\\n（Residual Block）组成。而残差块的使用，可以解决前面说到的退化问题。残差块如图\\n\\n10.19 所示。\\n\\n338\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.19 残差块（Residual Block）[6]\\n\\n图中的 weight layer 是 3×3 的卷积层，F(x)表示经过两个卷积层计算后得到的结果，',\n",
       " 'identity 表示“恒等映射”也称为“shortcut connections”，说白了就是把 x 的值不做任\\n\\n何处理直接传过去。最后计算 F(x)+x，这里的 F(x)跟 x 是 shape 相同的信号，所以可以进行\\n\\nelement-wise addition，也就是对应位置进行相加。\\n\\n图 10.20 也是相同的残差块，加上了 BN 层。\\n\\n图 10.20 加上 BN 层的残差块\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化。\\n\\n残差块可以有多种设计方式，比如改变残差块中卷积层的数量，或者残差块中卷积窗口\\n\\n的大小，或者卷积计算后先 ReLU 后 BN，就像是搭积木一样，我们可以随意设置。ResNet\\n\\n研究团队经过很多的测试最终定下了两种他们觉得最好的残差块的结构，如图 10.21 所示。\\n\\n图 10.21 两种残差块结构[6]\\n\\n339\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 1×1，3×3 表示卷积窗口大小，64 和 256 表示特征图数量，注意这里的图片是',\n",
       " '图中的 1×1，3×3 表示卷积窗口大小，64 和 256 表示特征图数量，注意这里的图片是\\n\\n作者给出的示意图，真正搭建模型的时候特征图数量不一定是图中的 64 和 256。图中左边\\n\\n的残差结构有 2 个卷积层前面我们已经见过，右边的残差结构有 3 个卷积层，加上 BN 层后\\n\\n如图 10.22 所示。\\n\\n图 10.22 3 层残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化。\\n\\nResNet 也有很多个版本，比如 ResNet18，ResNet34，ResNet50，ResNet101，\\n\\nResNet152 等，不同的数字表示不同的网络层数，18 就是 18 层，152 就是 152 层。作者\\n\\n在搭建不同版本的 ResNet 的时候使用了不同的残差结构，ResNet18 和 ResNet34 用的是\\n\\n2 层卷积的残差结构，ResNet50，ResNet101，ResNet152 用的是 3 层卷积的残差结构。\\n\\n残差结构的主要作用是传递信号，把深度学习浅层的网络信号直接传给深层的网络。深',\n",
       " '残差结构的主要作用是传递信号，把深度学习浅层的网络信号直接传给深层的网络。深\\n\\n度学习中不同的层所包含的信息是不同的，一般我们认为深层的网络所包含的特征可能对最\\n\\n后模型预测更有帮助，但是并不是说浅层的网络所包含的信息就没用，深层网络的特征就是\\n\\n从浅层网络不断提取而得到的。现在我们给网络提供一个“捷径”也就是“shortcut\\n\\nconnections”，它可以直接将浅层信号传递给深层网络，跟深层网络的信号结合，来帮助\\n\\n网络得到更好的效果。\\n\\n10.6.3 ResNet 网络结构\\n\\n图 10.23 中有 3 个网络结构，左边为 VGG19，中间为模仿 VGGNet 设计的 34 层 plain\\n\\nnetwork，右边为 ResNet34。\\n\\n340\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n341\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.23 ResNet 网络结构[6]\\n\\n图中的 conv 表示卷积；pool 表示池化；fc 表示全连接层；avg pool 表示平均池化；',\n",
       " 'output size 表示输出大小；image 表示图片。\\n\\nVGG19 和 plain network 大家自己看看就行，仔细看看就能看懂。plain network 中有\\n\\n个地方要注意，plain network 没有使用 pooling 层（池化层不一定要使用）。在网络中有\\n\\n几个位置我们可以看到“7×7conv，64，/2”，“3×3conv，128，/2”，“3×3conv，\\n\\n256，/2”，“3×3conv，512，/2”。这里的 7×7 和 3×3 表示卷积窗口大小；\\n\\n65/128/256/512 表示卷积后生成多少特征图；/2 表示卷积的步长为 2，卷积后特征图的长\\n\\n宽都会变为原来的 1/2。最后的 avg pool 为平均池化，是模仿 GoogleNet 的设计。\\n\\n我们重点来看看 ResNet34，ResNet34 是从 34 层的 plain network 改进得来的，结构\\n\\n上跟 34 层的 plain network 非常相似。主要区别是 ResNet34 增加了“shortcut',\n",
       " 'connections”，由 16 个 2 层的残差结构堆叠而成。不过我们发现“shortcut\\n\\nconnections”分为实线和虚线，实线表示残差结构的输入 x 与残差结构中卷积计算结果\\n\\nF(x)的 shape 是一样的，可以直接进行对位相加，具体例子如图 10.24 所示。\\n\\n图 10.24 实线“shortcut connections”例子\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化，batch 表示批次。\\n\\n虚线“shortcut connections”表示无法直接进行对位相加的接连。我们可以发现虚线\\n\\n部分的残差块输入 x 和残差结构中卷积计算结果 F(x)的 shape 是不一致的，输入 x 的特征图\\n\\n342\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n数量是 F(x)特征图数量的 1/2，并且输入 x 的特征图长宽是 F(x)特征图长宽的 2 倍。虚线\\n\\n“shortcut connections”在 ResNet 论文中给出了 A，B 两种连接方式。',\n",
       " 'A．zero-padding。先做步长为 2 的恒等映射，新增的特征图用 0 填充。ResNet 一般\\n\\n不用这种方式，论文中没有写明白具体的操作，网上的资料也比较少，所以下面 zero-\\n\\npadding 的操作主要来自我的推测，如图 10.25 表示 1 张特征图进行步长为 2 的 Identity\\n\\nmapping：\\n\\n图 10.25 步长为 2 的恒等映射\\n\\n图中的 Identity 表示恒等映射，Stride 表示步长。\\n\\n图 10.26 表示多张特征图步长为 2 的恒等映射，特征图变成原来的 2 倍，新增的特征图\\n\\n用 0 填充：\\n\\n343\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.26 Identity mapping+zero-padding\\n\\n图中的 Identity 表示恒等映射。\\n\\n图 10.27 表示 zero-padding 的“shortcut connections”在 ResNet 中使用的具体例\\n\\n子：\\n\\n图 10.27 zero-padding',\n",
       " '子：\\n\\n图 10.27 zero-padding\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；batch 表示批次；Identity\\n\\nmapping 表示恒等映射。\\n\\nZero-padding 的好处是计算简单并且不需要给网络增加额外的权值，同时也可以得到较\\n\\n好的效果。\\n\\nB．projection shortcut。ResNet 作者把第二种方式称为“projection shortcut”，\\n\\n具体做法是用步长为 2，大小为 1×1 的卷积来对残差块的输入信号 x 进行特征提取，使 x 信\\n\\n号和 F(x)信号的 shape 一致。ResNet 通常都是使用 projection shortcut 的方法，如图\\n\\n10.28：\\n\\n344\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.28 步长为 2，1×1 卷积\\n\\n图中的 conv 表示卷积。\\n\\n图 10.29 表示 projection shortcut 的“shortcut connections”在 ResNet 中使用的具\\n\\n体例子：',\n",
       " '体例子：\\n\\n图 10.29 projection shortcut\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；batch 表示批次。\\n\\n相比于 zero-padding，使用 projection shortcut 可以让模型获得更好的效果。另外作\\n\\n者还提出了另外一种 shortcut 连接方案“all shortcuts are projections”。\\n\\nC．all shortcuts are projections。顾名思义，也就是 ResNet 中所有的 shortcuts，\\n\\n不管是没有特征图数量增加的实线 shortcut，还是有特征图数量增加的虚线 shortcut，都使\\n\\n用带 1×1 卷积的 projection shortcut 来进行连接。\\n\\nResNet 作者使用 imagenet 数据集对 A，B，C 三种 shortcut 方式进行了评估，结果如\\n\\n图 10.30 所示。\\n\\n图 10.30 三种 shortcut 方式评估[6]\\n\\n345\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '345\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 model 表示模型；top-1 err.表示 top1 错误率；top-5 err.表示 top5 错误率。\\n\\n图中的 ABC 分别表示前面我们提到的三种 shortcut 方式，ResNet-50，ResNet-101，\\n\\nResNet-152 用的是 B(projection shortcut)的方式。我们从实验结果可以看出，C 方案比 B\\n\\n方案稍微好一点点，B 方案比 A 方案稍微好一点点。C 方案需要给网络增加较多的计算量和\\n\\n权值参数，B 方案需要给网络增加一点计算量和权值参数，C 方法不需要额外的权值参数。\\n\\nResNet 作者基于综合情况考虑，最终选择在模型中使用了 B 方案。所以我们现在看到的\\n\\nResNet 模型一般都是使用 B(projection shortcut)的方式，一般的残差块都是 identity\\n\\nmapping 恒等映射，只有特征图数量改变的时候使用 projection shortcut。',\n",
       " 'mapping 恒等映射，只有特征图数量改变的时候使用 projection shortcut。\\n\\nResNet 团队最终在 2015 年 ImageNet Challenge 图像识别比赛中，融合了 6 个不同\\n\\n深度的 ResNet 模型，得到了 3.57%的 top5 测试集错误率，获得了当年比赛的冠军。图\\n\\n10.31 为不同模型的测试结果。\\n\\n图 10.31 不同模型的测试结果[6]\\n\\n图中的 method 表示模型，top-5 err. (test)表示测试集 top5 错误率。\\n\\n10.6.4 ResNet-V2\\n\\n2016 年，何恺明所在的 ResNet 团队又发表了一篇关于 ResNet 的论文《Identity\\n\\nMappings in Deep Residual Networks》。在这篇论文中，他们提出了一种关于 ResNet\\n\\n的结构优化，并表示新的 ResNet 结构可以让 ResNet 获得更好的效果。我们一般把\\n\\n346\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '346\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n《Identity Mappings in Deep Residual Networks》[7]这篇论文中提到的 ResNet 结构称\\n\\n为 ResNet-V2，如图 10.32 所示。\\n\\n图 10.32 残差结构优化[7]\\n\\n图中的 Iterations 表示迭代次数；Test Error 表示测试集错误率。\\n\\n(a)original 表示原始的 ResNet 的残差结构，(b)proposed 表示新的 ResNet 的残差结\\n\\n构。主要差别就是(a)结构先卷积后进行 BN 和激活函数计算，最后执行 addition 后再进行\\n\\nReLU 计算；(b)结构先进行 BN 和激活函数计算后卷积，把 addition 后的 ReLU 计算放到了\\n\\n残差结构内部。作者使用这两种不同的结构在 CIFAR-10 数据集上做测试，模型用的是 1001\\n\\n层的 ResNet 模型。从图中结果我们可以看出，(b)proposed 的测试集错误率明显更低一',\n",
       " '些，达到了 4.92%的错误率，(a)original 的测试集错误率是 7.61%。\\n\\n其实 ResNet 团队对 ResNet 的残差结构做了很多不同的尝试，如图 10.33 所示。\\n\\n347\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.33 shortcut 结构的不同尝试[7]\\n\\n图中(a),(b),(c),(d),(e),(f)都是作者对残差结构的 shortcut 部分进行的不同尝试，这里我\\n\\n们就不具体介绍了，因为作者对不同 shortcut 结构的尝试结果如图 10.34 所示。\\n\\n图 10.34 不同 shortcut 结构的测试结果[7]\\n\\n作者用不同 shortcut 结构的 ResNet-110 在 CIFAR-10 数据集上做测试，发现最原始的\\n\\n(a)original 结构是最好的，也就是 identity mapping 恒等映射是最好的。\\n\\n然后作者又对残差结构的残差单元进行了不同的尝试，如图 10.35 所示。\\n\\n348\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '348\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 10.35 不同残差单元测试结果[7]\\n\\n最好的结果是(e)full pre-activation，其次到(a)original。(a)original 的残差结构是应用\\n\\n在最原始的 ResNet 中的残差结构；(e)full pre-activation 的残差结构就是我们前面介绍的\\n\\nResNet-V2 中的残差结构。\\n\\n从 ResNet 的设计和发展过程中我们可以知道，深度学习是一门非常注重实验的学科，\\n\\n我们需要有创新的好想法，同时也需要大量的实验来支撑和证明我们的想法。有些时候我们\\n\\n无法从理论上推断哪种模型设计或优化方法是最好的，这个时候我们可能就需要做大量的实\\n\\n验来不断尝试，找到最好的结果。如今 ResNet 已经得到广泛的应用和肯定，对深度学习和\\n\\n计算机视觉做出了重要贡献。\\n\\n经典图像识别模型介绍下一章继续。\\n\\n10.7 参考文献',\n",
       " '计算机视觉做出了重要贡献。\\n\\n经典图像识别模型介绍下一章继续。\\n\\n10.7 参考文献\\n\\n[1] Russakovsky O , Deng J , Su H , et al. ImageNet Large Scale Visual Recognition\\n\\nChallenge[J]. International Journal of Computer Vision, 2015, 115(3):211-252.\\n\\n349\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[2] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\n\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n\\n[3]Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for',\n",
       " 'Large-Scale Image Recognition[J].\\n\\n[4]Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n\\n[5] Ioffe S , Szegedy C . Batch Normalization: Accelerating Deep Network Training by\\n\\nReducing Internal Covariate Shift[J]. 2015.\\n\\n[6] He K , Zhang X , Ren S , et al. Deep Residual Learning for Image Recognition[C]//\\n\\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE\\n\\nComputer Society, 2016.',\n",
       " 'Computer Society, 2016.\\n\\n[7] He K , Zhang X , Ren S , et al. Identity Mappings in Deep Residual Networks[J].\\n\\n2016.\\n\\n350\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 11 章-经典图像识别模型介绍（下）\\n\\n这一章节我们继续介绍经典图像识别模型。\\n\\n11.1 Inception 模型系列\\n\\nInception 的前身就是前面我们介绍过的 GoogleNet，GoogleNet 中提出了一个多种尺\\n\\n度同时进行特征提取的结构称为 Inception，所以 GoogleNet 后来改名变成了 Inception-\\n\\nv1。Google 的团队后来在 Inception-v1 的基础上做了更多的研究和优化，提出了\\n\\nInception-v2，Inception-v3，Inception-v4，Inception-ResNet-v1，Inception-\\n\\nResNet-v2 多个优化版本。',\n",
       " 'ResNet-v2 多个优化版本。\\n\\n11.1.1 Inception-v2/v3 优化策略\\n\\nInception-v2 和 Inception-v3 都出自同一篇论文《Rethinking the inception\\n\\narchitecture for computer vision》[1]。该论文提出了多种基于 Inception-v1 的模型优化\\n\\n方法，Inception-v2 用了其中的一部分模型优化方法，Inception-v3 用了论文中提到的所有\\n\\n优化方法。相当于 Inception-v2 只是一个过渡版本，Inception-v3 一般用得更多。下面我\\n\\n们主要针对论文中所涉及的一些比较重要的优化方法进行讲解，具体是用在 Inception-v2 还\\n\\n是 Inception-v3 就不做详细区分了，可以都看成是 Inception-v3 的内容。顺便说一下之前\\n\\n我们学过的标签平滑（Label Smoothing）就是出自 Inception-v3 的论文。',\n",
       " '我们学过的标签平滑（Label Smoothing）就是出自 Inception-v3 的论文。\\n\\nInception-v3 最大的优化是模型结构上的优化，在 Inception-v3 中作者对 Inception 结\\n\\n构中的卷积进行了分解。分解后的好处是增加了网络的层数，也就是增加了网络的特征提取\\n\\n351\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n能力。同时作者还对 Inception 结构进行了一些调整，设计了不同的 Inception，用在模型\\n\\n的不同位置。\\n\\n我们先回忆一下最原始的 Inception 结构，如图 11.1 所示。\\n\\n图 11.1 原始 Inception 结构[1]\\n\\n图中的 convolutions 表示卷积，filter concatenation 表示滤波器合并，max\\n\\npooling 表示最大池化，previous layer 表示前一层。\\n\\nInception-v3 中提出了一个新思路，可以使用两个 3×3 卷积来替代原始 Inception 结构\\n\\n中的 5×5 卷积，如图 11.2 所示。',\n",
       " '中的 5×5 卷积，如图 11.2 所示。\\n\\n图 11.2 分解 5×5 卷积\\n\\n将 5×5 卷积分解为两层的 3×3 卷积，对于最后得到的特征来说，感受野的大小是相同\\n\\n的，都是 5×5 的区域。相当于 5×5 卷积对 5×5 区域进行特征提取，得到一个特征值；两层\\n\\n352\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的 3×3 卷积对 5×5 区域进行特征提取，也是得到一个特征值。这两种特征提取的方式类\\n\\n似，不过最后得到的特征值可能是不同的，右边的两层 3×3 卷积做了两次卷积得到的特征值\\n\\n或许会更好一些。\\n\\n沿着这个卷积分解的思路继续思考，作者又提出了一种新的卷积分解，把 3×3 卷积分解\\n\\n为 1×3 卷积和 3×1 卷积，如图 11.3 所示。\\n\\n图 11.3 分解 3×3 卷积\\n\\n把 3×3 卷积分解为 1×3 卷积和 3×1 卷积，道理跟将 5×5 卷积分解为两层的 3×3 卷积\\n\\n差不多，对于最后的特征来说，感受野的大小是一样的，并且分解后可以让网络层数变得更',\n",
       " '差不多，对于最后的特征来说，感受野的大小是一样的，并且分解后可以让网络层数变得更\\n\\n多，增加网络的非线性。理论上 n×n 的卷积都可以分解为 1×n 卷积和 n×1 卷积。\\n\\n作者还分析了减小特征图大小时的操作，如图 11.4 所示。\\n\\n图 11.4 减小特征图大小的操作[2]\\n\\n353\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图片 Pooling 表示池化。\\n\\n作者认为直接使用窗口大小 2×2，步长为 2 的池化来压缩特征图的大小效果不太好。因\\n\\n为特征图的数量不变，但是特征图的长宽变成为原来的 1/2，相当于特征值的数量被压缩为\\n\\n原来的 1/4 了，特征值的数量一下减少太多不利于模型的训练，所以左边的结构不太理想。\\n\\n右边的结构先用 Inception 来增加特征图数量然后再进行池化减小特征图大小，对于特征的\\n\\n提取来说没什么问题，就是计算量太大。\\n\\n所以设计了新的 Inception 结构，在减小特征图大小的同时可以增加特征图的数量，如\\n\\n图 11.5 所示。\\n\\n图 11.5 用于减小特征图大小并增加特征图数量[2]',\n",
       " '图 11.5 所示。\\n\\n图 11.5 用于减小特征图大小并增加特征图数量[2]\\n\\n图中 Filter Concat 表示滤波器拼接；stride 表示步长；concat 表示拼接；conv 表示卷\\n\\n积；pool 表示池化。\\n\\n除此之外作者还根据实验分析和建模经验，设计了一些新的 Inception 结构，如图 11.6\\n\\n所示。\\n\\n354\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.6 一些新的 Inception 结构[2]\\n\\n图中 Filter Concat 表示滤波器拼接；Pool 表示池化。\\n\\n这些不同的 Inception 结构就像搭积木一样堆叠起来，组成了 Inception-v3 的模型。\\n\\n11.1.2 Inception-v2/v3 模型结构\\n\\nInception-v2/v3 模型的结构非常庞大，Inception-v2/v3 论文中给出的模型结构描述也\\n\\n不是特别清晰，结构如图 11.7 所示。\\n\\n355\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '355\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.7 Inception-v2/v3 模型结构[2]\\n\\n图中 architecture 表示结构；Filter Concat 表示滤波器拼接；Pool 表示池化；type 表\\n\\n示层的类型；patch size/stride or remarks 表示窗口大小/步长；input size 表示输入大\\n\\n小；conv 表示卷积；pool 表示池化；linear 表示全连接层。\\n\\n图中 Inception-v2/v3 的结构大家应该能大致看懂，但是好像又看不太懂。那么要如何\\n\\n把 Inception-v2/v3 结构在书里表示清楚，让大家能看懂，我想了很久。其实要把\\n\\nInception-v2/v3 结构图画出来不难，难的是怎么在书里画出来，书这个信息载体对长图片\\n\\n的支持不太友好。最后我想到了一个比较清晰简洁，在书里看起来也相对比较友好的画结构\\n\\n图的方法——“方块构图法”（我瞎起的名字）。我画的这个结构跟论文中描述的结构细节',\n",
       " '图的方法——“方块构图法”（我瞎起的名字）。我画的这个结构跟论文中描述的结构细节\\n\\n上有些许不同，我是参考 tensorflow.keras.applications.inception_v3 中的结构画的，\\n\\nInception-v2/v3 结构图如图 11.8 所示。\\n\\n356\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n357\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n358\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.8 Inception-v2/v3 结构图\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；AvgPool 表示平均池化；Concat 表\\n\\n示拼接；FC 表示全连接层；V 表示 Valid Padding。\\n\\n相信这个结构图大家应该是很容易看懂的，我只需要稍微提几个注意事项：\\n\\n1. 图中卷积和池化默认的步长是 1 所以没有写出来。如果有“/2”表示步长为 2。',\n",
       " '1. 图中卷积和池化默认的步长是 1 所以没有写出来。如果有“/2”表示步长为 2。\\n\\n2. 图中卷积和池化默认都是 same padding 所以没有写出来。如果有“V”表示 valid\\n\\npadding。\\n\\n3. 每个卷积层后面有 BN 和 ReLU，图中省略了。\\n\\n359\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4. Inception-ABCD 表示论文中提到的几种不同类似的 Inception 模型，不过并不是跟\\n\\n论文中完全一致。\\n\\n最后我们来看一下 Inception-v3 在 ImageNet 数据集中的测试结果，图 11.9 为\\n\\nInception-v3 单模型测试结果。\\n\\n图 11.9 Inception-v3 单模型测试结果[2]\\n\\n图中 Network 表示网络；Crops Evaluated 表示模型评估时裁剪出多少张图片进行预\\n\\n测；Top-5 Error 表示 Top5 错误率；Top-1 Error 表示 Top1 错误率。\\n\\n图 11.10 为 Inception-v3 模型融合后的测试结果。',\n",
       " '图 11.10 为 Inception-v3 模型融合后的测试结果。\\n\\n图 11.10 Inception-v3 模型融合后测试结果[2]\\n\\n图中 Network 表示网络；Models Evaluated 表示评估时集成了几个模型；Crops\\n\\nEvaluated 表示模型评估时裁剪出多少张图片进行预测；Top-5 Error 表示 Top5 错误率；\\n\\nTop-1 Error 表示 Top1 错误率。\\n\\n360\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nInception-v3 模型融合后的 Top5 错误率为 3.58%，这个结果跟 2015 年 ImageNet\\n\\nChallenge 图像识别比赛的冠军 ResNet 已经非常接近，ResNet 的 Top5 错误率为\\n\\n3.57%。\\n\\n11.1.3 Inception-v4 和 Inception-ResNet 介绍\\n\\nInception-v3 结构的复杂程度以后够复杂了，但是它还有几个升级版本，就是',\n",
       " 'Inception-v3 结构的复杂程度以后够复杂了，但是它还有几个升级版本，就是\\n\\nInception-v4，Inception-ResNet-v1 和 Inception-ResNet-v2。这几个升级版本都出自同\\n\\n一篇论文《Inception-v4, Inception-ResNet and\\n\\nthe Impact of Residual Connections on Learning》[3]。\\n\\n这几个升级版的 Inception 模型基本设计思路都是遵循 Inception-v3 的设计思路，只不\\n\\n过比 Inception-v3 再稍微更复杂一些。Inception-v4 的作者不认同非常深层的网络一定要\\n\\n使用残差单元才行，所以他们设计了没有使用残差单元的深度网络 Inception-v4，我大概数\\n\\n了一下论文中的 Inception-v4 结构，应该是有 76 层。不过 Inception-v4 的作者认同加上\\n\\n残差单元以后，模型可以训练得更加快一些。',\n",
       " '残差单元以后，模型可以训练得更加快一些。\\n\\nInception-ResNet-v1 和 Inception-ResNet-v2 顾名思义就是 Inception 的设计加上\\n\\nResNet 的残差结构设计得到的模型。\\n\\n由于 Inception-v4，Inception-ResNet-v1 和 Inception-ResNet-v2 的结构设计跟\\n\\nInception-v3 差别不大，并且使用一次“方块构图法”消耗的体力太多，所以这几个模型的\\n\\n具体网络结构就不给大家展示了。下面使用论文中的一些图给大家展示一下 Inception-v4 和\\n\\nInception-ResNet-v2 的结构，大家大致看一下即可，图 11.11 为 Inception-v4 的结构图.\\n\\n361\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.11 Inception-v4 结构图[3]\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；Output 表示输出；Input 表示输入；',\n",
       " 'Filter concat 表示滤波器拼接；Avg Pooling 和 Average Pooling 表示平均池化；stride 表\\n\\n示步长。\\n\\nInception-v4 延续了 Inception-v3 的设计并进行了一些优化，主要也是使用多个不同的\\n\\nInception 结构堆叠得到深层的网络模型。\\n\\n362\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.12 为 Inception-ResNet-v2 结构图。\\n\\n图 11.12 Inception-ResNet-v2 结构[3]\\n\\n图中的 Conv 表示卷积；MaxPool 表示最大池化；Output 表示输出；Input 表示输入；\\n\\nFilter concat 表示滤波器拼接； Average Pooling 表示平均池化；stride 表示步长。\\n\\nInception-ResNet-v2 的结构特殊之处就是把 Inception 和残差单元的设计结合到了一\\n\\n起变成了 Inception-resnet 模块。\\n\\n363',\n",
       " '起变成了 Inception-resnet 模块。\\n\\n363\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.13 为 4 个 Inception 模型在 ImageNet 数据集中，单模型 Top5 错误率的测试结\\n\\n果。\\n\\n图 11.13 4 种 Inception 模型在 ImageNet 数据集测试结果[3]\\n\\n图中的 Epoch 表示训练周期；Error 表示误差。\\n\\n从图中我们可以看到 Inception-v3 和 Inception-ResNet-v1 效果是差不多的，可能\\n\\nInception-ResNet-v1 稍微好一点点。Inception-v4 和 Inception-ResNet-v2 效果是差不\\n\\n多的，可能 Inception-ResNet-v2 稍微好一点点。\\n\\n图 11.14 为几个模型在 ImageNet 数据集中单模型测试结果。\\n\\n图 11.14 几个不同模型的单模型测试结果[3]\\n\\n图中的 Network 表示网络；Crops 表示从一张图片中裁剪出多少张图片；Top-1 Error',\n",
       " '表示 Top1 错误率；Top-5 Error 表示 Top5 错误率。\\n\\n364\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nCrops 中的 dense 表示直接对一张测试图片进行预测，得到一个预测结果。Crops 中的\\n\\n144 表示从一张测试图片中按照一定的规则裁剪出 144 个子区域，然后对这 144 个区域分别\\n\\n进行预测得到 144 个预测结果，最后再对这 144 个预测结果求平均得到最终的一个预测结果\\n\\n[4]。\\n\\n图 11.15 为模型融合的测试结果。\\n\\n图 11.15 模型融合的测试结果[3]\\n\\n图中的 Network 表示网络；Models 表示集成的模型数量；Top-1 Error 表示 Top1 错\\n\\n误率；Top-5 Error 表示 Top5 错误率。\\n\\n使用 1 个 Inception-v4 和 3 个 Inception-ResNet-v2 模型进行融合，在 ImageNet 的\\n\\n验证集中得到了 3.1%的 Top5 错误率，在 ImageNet 的测试集中得到了 3.08%的 Top5 错',\n",
       " '误率，这个结果已经比 ResNet 的模型融合后的结果更好了。\\n\\n11.2 ResNeXt\\n\\nResNeXt 获得了 2016 年 ImageNet Challenge 图像识别比赛的亚军。是由来自加州大\\n\\n学圣地亚哥分校(UCSD)和 Facebook AI Research(FAIR)的团队完成。名字中的“Res”表\\n\\n示“ResNet”，名字中的“NeXt”表示“next dimension”，在 ResNeXt 的论文中\\n\\n“next dimension”被称为“cardinality dimension”。作者提出把 cardinality 作为深度\\n\\n学习网络中的一个新参数，就像是网络的深度（网络的层数），宽度（特征图数量）一样。\\n\\n365\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n最早提出 ResNeXt 的论文是《Aggregated Residual Transformations for Deep Neural\\n\\nNetworks》[5]。在介绍 ResNeXt 之前，我们先来了解一下 ResNeXt 网络中的核心内容，分',\n",
       " '组卷积(Group Convolution)。\\n\\n11.2.1 分组卷积（Group Convolution）介绍\\n\\n分组卷积是一种特殊的卷积，最早应该是用在 AlexNet 网络中，AlexNet 的原始结构分\\n\\n为上下两部分，我们可以看成是上下两个通道或者是上下两个分组，如图 11.16 所示。\\n\\n图 11.16 AlexNet 结构[6]\\n\\n图中的 Stride 表示步长；Max Pooling 表示最大池化；dense 表示全连接层。\\n\\nAlexNet 使用分组卷积主要是当时软硬件条件比较受限，AlexNet 团队想用两个 GPU 来\\n\\n加速模型模型，一个 GPU 运行上面分组的卷积计算，一个 GPU 运行下面分组的卷积计算。\\n\\n所以在 AlexNet 中使用这样的分组卷积设计并不是他们的本意，更多的是巧合。不过有实验\\n\\n证明当初 AlexNet 里面使用分组卷积是正确的设计，使用了分组卷积以后不仅计算量和权值\\n\\n数量减少了，并且模型准确率也提升了一些[5]，实验结果如图 11.17 所示。\\n\\n366\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '366\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.17 不同分组 AlexNet 的结果[7]\\n\\n图中的 Model Parameters 表示模型参数数量；Top-5 Val. Error 表示 Top5 验证集错\\n\\n误率；groups 表示分组数。\\n\\n图中横坐标表示模型的参数数量，纵坐标表示模型错误率，原始的 AlexNet 为图中的“2\\n\\ngroups”表示将卷积分为 2 组，“no groups”表示不分组，”4 groups”表示将卷积分\\n\\n为 4 组。从图中我们可以看到分组越多模型的参数越少，模型的准确率上下会有浮动，不过\\n\\n变化不是很大。这 3 个实验结果里将卷积分为 2 组是最好的选择。\\n\\n下面我们正式介绍分组卷积，简单来说分组卷积就是将特征图分为不同的组，再对每组\\n\\n特征图分别进行卷积。这里的分组一般都是分为 n 个等份，理论上其实不是等份也可以，不\\n\\n过一般为了实现方便都是分为等份。分组卷积的好处主要是可以减少模型的计算量和训练参\\n\\n数，同时对模型准确率影响不大，甚至有可能会提高模型准确率。下面我们通过几个图来详',\n",
       " '数，同时对模型准确率影响不大，甚至有可能会提高模型准确率。下面我们通过几个图来详\\n\\n细了解一下，图 11.18 为普通卷积：.\\n\\n图 11.18 普通卷积\\n\\n367\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Conv 表示卷积。\\n\\n这里特征图的大小和卷积和的大小都不是重点内容，所以图中没有标出，我们只要能看\\n\\n出 6 个特征图卷积后得到 12 个特征图就可以了。不过为了让大家理解分组卷积的计算量和\\n\\n权值数量这里我们举例计算一下，假设特征图大小是 28×28，卷积核大小为 5×5，Same\\n\\nPadding。卷积层权值数量为 5×5×6×12+12=1812，乘法计算量为 5×5×28×28×6×\\n\\n12=1411200。\\n\\n下面我们看一下分组卷积，分组卷积一般都是把特征图分为 n 个等份，然后再对 n 个等\\n\\n份的特征图分别卷积，这里的 n 可以人为设置，如图 11.19 所示。\\n\\n图 11.19 分组卷积\\n\\n图中的 Conv 表示卷积。\\n\\n为了跟普通卷积对比，所以这里分组卷积的例子输入也是 6 个特征图，输出也是 12 个特',\n",
       " '为了跟普通卷积对比，所以这里分组卷积的例子输入也是 6 个特征图，输出也是 12 个特\\n\\n征图。这里我们可以看到把 6 个特征图分为了 3 组，每组 2 个特征图，每组分别进行卷积，\\n\\n卷积后得到 4 个特征图。最后再把 3 个组共 12 个特征图组合起来。假设特征图大小是 28×\\n\\n28，卷积核大小为 5×5，Same Padding。这里卷积层权值数量为 5×5×2×4×\\n\\n3+12=612，乘法计算量为 5×5×28×28×2×4×3=470400。权值数量和计算量都约为普通\\n\\n卷积的 1/3。\\n\\n368\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n11.2.2 ResNeXt中的分组卷积\\n\\n这一小节我们主要学习 ResNeXt 的核心内容，分组卷积在 ResNeXt 中的使用。\\n\\nResNeXt 中提出的一个模型调节的新维度“cardinality”其实就是分组卷积中的分组数量，\\n\\n比如 cardinality 为 2 表示把卷积分为 2 组，cardinality 为 32 表示把卷积分为 32 组。',\n",
       " '作者将分组卷积应用到 ResNet 的残差结构中，如图 11.20 所示。\\n\\n图 11.20 残差结构中使用分组卷积[5]\\n\\n图中的 in 表示输入；out 表示输出；d 表示 dimension，代表维度；total 32 paths 表\\n\\n示总共 32 个通道。\\n\\n图中左边为 ResNet 的残差结构，右边是 cardinality 为 32 的新残差结构。每个格子中\\n\\n的 3 个数字分别表示（输入通道数，卷积核大小，输出通道数）。原始的 ResNet 的残差结\\n\\n构就不用多说了，ResNeXt 中的残差结构也很容易理解，第 1 层卷积输入是 256 个特征\\n\\n图，输出是 4×32=128 个特征图。然后对这 128 个特征图进行分组，分为 32 组，每组 4 个\\n\\n特征图，在第 2 层卷积进行分组卷积计算。第 2 层卷积计算后，每组卷积都是产生 4 个特征\\n\\n图。第 3 层卷积是对 4 个特征图进行卷积产生 256 个特征图。然后再对 32 个分组产生的 32',\n",
       " '组每组 256 个特征图进行 element-wise addition 按位相加，最后再加上 shortcut 恒等映\\n\\n射传过来的信号，得到残差结构的输出。\\n\\n369\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这里大家可能会有个小疑问，为什么左边原始的残差结构第 1 层卷积输入 256 个特征\\n\\n图，产生 64 个特征图。而右边的分组卷积残差结构第 1 层卷积输入 256 个特征图，产生 4×\\n\\n32=128 个特征图。看起来两个残差结构中间部分产生的特征图数量不一致。其实作者之所\\n\\n以这么设计分组卷积特征图的数量主要是为了使得两个残差结构的训练参数的数量大致相\\n\\n同。\\n\\n我们来计算一下图 11.20 中左边的残差结构训练参数的数量为（为了计算方便忽略偏置\\n\\n值）：256×64+3×3×64×64+64×256≈70000。右边的分组卷积残差结构参数数量为（为\\n\\n了计算方便忽略偏置值）：C×(256×d+3×3×d×d+d×256)\\t≈70000，其中 C=32 表示',\n",
       " 'cardinality 为 32，d=4 表示每个分组有 4 个特征图。右边的残差结构我们也可以表示为 32\\n\\n×4d，意思是 32 个分组每组 4 个特征图；如果是 8×16d 表示 8 个分组，每组 16 个特张\\n\\n图；如果是 1×64d 表示 1 个分组（也就是不分组），每组 64 个特张图。在作者的设计下，\\n\\n新的分组卷积残差结构权值数量和计算量跟原始的残差结构差不多，不过最后模型效果可以\\n\\n变得更好。\\n\\n其实在 ResNeXt 的论文中，作者给出了 3 种形式的分组卷积残差结构，这 3 种形式的分\\n\\n组卷积残差结构输入信号和输出信号都是一样的，只是中间部分略有不同，如图 11.21 所\\n\\n示。\\n\\n图 11.21 3 种形式的分组卷积残差结构[5]\\n\\n370\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 in 表示输入；out 表示输出；d 表示 dimension，代表维度；total 32 paths 表\\n\\n示总共 32 个通道；group 表示分组数；equivalent 表示相等的；concatenate 表示拼接。',\n",
       " '前面我们已经仔细分析了(a)结构，实际上(b)结构和(c)结构跟(a)结构也是非常类似的。\\n\\n(b)结构是在第 2 层卷积输出的位置对 32 组每组 4 个特征图进行 concatenate，得到了 128\\n\\n个特征图。然后再传给第 3 层卷积进行计算，最后输出 256 个特征图。(c)结构作者在这里用\\n\\n简化的方式表示分组卷积的计算，注意看(c)结构中有些数字是加粗的，加粗的数字表示跟分\\n\\n组卷积相关。也就是(c)结构的第 2 层卷积跟(a)，(b)结构都不一样，(c)的第 2 层卷积分为 32\\n\\n组，每组输入 4 个特征图，输出 128 个特征图。然后再对这 32 组每组 128 个特征图进行\\n\\nelement-wise addition 按位相加，之后传给第 3 层卷积。第 3 层卷积就是输入 128 个特征\\n\\n图，输出 256 个特征图。\\n\\n这 3 种形式的残差结构作者都进行了实验，发现最后得到的结果基本上都差不多，最终\\n\\n选择了(c)结构。作者认为(c)结构更简单速度也更快。\\n\\n11.2.3 ResNeXt的网络结构',\n",
       " '选择了(c)结构。作者认为(c)结构更简单速度也更快。\\n\\n11.2.3 ResNeXt的网络结构\\n\\n了解了 ResNeXt 中使用的残差结构以后，下面我们来看一下 ResNeXt 的网络结构，如\\n\\n图 11.22 所示。\\n\\n371\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.22 ResNeXt 网络结构[5]\\n\\n图中的 stage 表示阶段；conv 表示卷积；output 表示输出；stride 表示步长；d 表示\\n\\ndimension，代表维度；max pool 表示最大池化；C 表示 cardinality，代表分组数；\\n\\nglobal average pool 表示全局平均池化；fc 表示全连接；params 表示参数数量；FLOPs\\n\\n表示计算量。\\n\\n图中有两个网络的结构，一个是 ResNet-50，一个是 ResNeXt-50(32×4d)。ResNeXt-\\n\\n50(32×4d)是在 ResNet-50 网络结构的基础上对残差结构进行了一些修改得到的，所以这两',\n",
       " '个模型的结构框架基本是一致的。这个结构图还是很容易看懂的，基本上要讲解的地方不\\n\\n多。ResNeXt-50(32×4d)的残差结构是加上了分组卷积的，(32×4d)表示图中的 conv2 中\\n\\n使用的分组卷积是 32 个分组每组 4 个特征图。ResNeXt 的结构一般只需要标明第一个分组\\n\\n卷积残差模块的信息，因为后面 conv3，conv4，conv5 中的分组卷积信息都可以由第一个\\n\\n372\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n分组卷积得到。按照 ResNeXt 的设计思路，所有的分组卷积 cardinality 都是一样的，比如\\n\\n图中的 32。conv2 特征图大小是 56×56，每组 4 个特征图；conv3 特征图大小是 28×28，\\n\\n每组 8 个特征图；conv4 特征图大小是 14×14，每组 16 个特征图；conv5 特征图大小是 7\\n\\n×7，每组 32 个特征图。\\n\\n图中我们还可以看出 ResNet-50 和 ResNeXt-50(32×4d)的权值参数数量和浮点计算量',\n",
       " '都是差不多的。而 ResNet-101 和 ResNeXt-101(32×4d) 的权值参数数量和浮点计算量也\\n\\n都是差不多的。这 4 个模型在 ImageNet 数据集中的测试结果如图 11.23 所示。\\n\\n图 11.23 4 个模型准确率对比[5]\\n\\n图中的 epochs 表示周期；top-1 error 表示 top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n图中可以看出 ResNeXt-50(32×4d)比 ResNet-50 要更好，ResNeXt-101(32×4d)比\\n\\nResNet-101 要更好。\\n\\n作者也尝试了一些不同分组的残差模块，测试结果如图 11.24 所示。\\n\\n373\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.24 不同分组的残差网络测试结果[5]\\n\\n图中 setting 表示结构设置；top-1 error 表示 top1 错误率。\\n\\n图中的 setting 表示模型第一个分组卷积残差模块的分组数和特征图数量，结果看来 32\\n\\n×4d 是一个比较好的选择。',\n",
       " '×4d 是一个比较好的选择。\\n\\n图 11.25 为 ResNeXt 使用不同大小的图片跟不同模型在 ImageNet 验证集的单模型对\\n\\n比结果：\\n\\n图 11.25 不同模型测试结果\\n\\n图中 top-1 err 表示 top1 错误率；top-5 err 表示 top5 错误率。\\n\\n374\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nResNet 和 ResNeXt 使用的是 224×224 和 320×320 的分辨率图片，Inception 相关的\\n\\n模型用的是 299×299 的分辨率图片。结果可以看出使用分辨率比较高的图片准确率也会高\\n\\n一些，ResNeXt-101 是上面几个模型中最好的。\\n\\nResNeXt 模型融合后在 ImageNet 测试集得到了 3.03%的 Top5 错误率，比 Inception-\\n\\nv4/Inception-ResNet-v2 的 3.08%结果要更好。\\n\\n11.3 SENet\\n\\nSENet 是 ImageNet Challenge 图像识别比赛 2017 年的冠军，是来自 Momenta 公司',\n",
       " '的团队完成。他们提出了 Squeeze-and-Excitation Networks（简称 SENet）。SENet 不\\n\\n是独立的模型设计，只对模型的一种优化。一般 SENet 都会结合其它模型一起使用，比如\\n\\nSENet 用于 ResNet-50 中我们就把这个模型称为 SE-ResNet-50，比如 SENet 用于\\n\\nInception-ResNet-v2 中我们就把这个模型称为 SE- Inception-ResNet-v2。最早提出\\n\\nSENet 的论文是《Squeeze-and-Excitation Networks》[8]。\\n\\n11.3.1 SENet 介绍\\n\\n我们之前介绍了很多模型，Inception 系列的模型使用不同尺度的卷积大小来提取不同的\\n\\n特征，ResNet 给模型增加了捷径更有利于信号传递，ResNeXt 使用了分组卷积把特征提取\\n\\n进行分组处理。SENet 的模型优化思路很有意思，主要是针对特征的 channel 进行优化。\\n\\n我们可以想象在进行图像识别的时候，卷积计算后生成了很多特征图，不同的滤波器会',\n",
       " '我们可以想象在进行图像识别的时候，卷积计算后生成了很多特征图，不同的滤波器会\\n\\n得到不同的特征图，不同的特征图代表从图像中提取的不同的特征。我们得到了这么多的特\\n\\n375\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n征图，按理来说某些特征图的应该更重要，某些特征图应该没这么重要，并不是所有特征图\\n\\n都一样的重要。所以 SENet 的核心思想就是给特征图增加注意力和门控机制，增强重要的特\\n\\n征图的信息，减弱不重要的特征图的信息。\\n\\n那么如何做到增强重要的信息，减弱不重要的信息，我们看一下 SENet 的名字\\n\\nSqueeze-and-Excitation Networks。其中的“Squeeze”中文意思是“挤压”，在模型中\\n\\n的实际操作其实是压缩特征图的特征，作者使用的压缩特征图的特征的方式是 avg pooling\\n\\n平均池化。这个大家应该很熟悉了，求一个特征图所有值的平均值，把 avg pooling 计算后\\n\\n的结果作为这个特征图压缩后的特征。比如一共有 64 个特征图，“Squeeze”计算后我们',\n",
       " '的结果作为这个特征图压缩后的特征。比如一共有 64 个特征图，“Squeeze”计算后我们\\n\\n就会得到 64 个值，代表 64 个特征图压缩后的特征。\\n\\n“Excitation”中文意思是“激发”，在模型中的实际操作是调节特征图信号强弱，作者\\n\\n使用的方式是给“Squeeze”计算后的结果加上两个全连接层，最终输出每个特征图对应的\\n\\n激活值，激活值可以改变特征图信号的强弱。每个特征图乘以它所对应的激活值，得到特征\\n\\n图的输出，然后再传给下一层。\\n\\n文字描述很难具体描述清楚，我们还是看图吧，我们先复习一下普通的 ResNet 中的残\\n\\n差结构如图 11.26 所示。\\n\\n376\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.26 普通残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；Identity mapping 表示恒等映\\n\\n射；batch 表示批次。\\n\\n普通的残差结构我们就不需要多说了，下面我们看一下加上了 Squeeze-and-Excitation\\n\\n模块后的残差结构如图 11.27 所示。\\n\\n377',\n",
       " '模块后的残差结构如图 11.27 所示。\\n\\n377\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.27 SE-残差结构\\n\\n图中的 Conv 表示卷积；Batch Norm 表示批量标准化；Identity mapping 表示恒等映\\n\\n射；batch 表示批次；AvgPool 表示平均池化。\\n\\n加上 Squeeze-and-Excitation 模块后的残差结构主要变化是在原来的残差结构最后一个\\n\\n卷积层后面进行 Squeeze-and-Excitation 的操作。Squeeze 就是先做平均池化，得到每一\\n\\n378\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n个特征图的压缩特征。图中特征图大小为 56×56，所以池化的窗口大小也是 56×56。池化\\n\\n过后就是 Excitation 操作，前面我们有提到 Excitation 操作有两个全连接层，这是 SENet\\n\\n原始论文中的做法，实际我们在写程序的时候也可以用两个窗口大小 1×1 的卷积层的替代，',\n",
       " '原始论文中的做法，实际我们在写程序的时候也可以用两个窗口大小 1×1 的卷积层的替代，\\n\\n效果跟全连接是一样的。Excitation 操作部分最后的激活函数是 Sigmoid 函数，作者在这里\\n\\n使用 Sigmoid 函数主要是利用 Sigmoid 函数输出范围是 0-1 这个特性，让 Excitation 的输\\n\\n出激活值可以起到一个门控的作用。Excitation 的输出的激活值会乘以原始残差结构最后一\\n\\n个卷积层的输出结果，对特征图的数值大小进行控制。如果是重要的特征图，会保持比较大\\n\\n的数值；如果是不重要的特征图，特征图的数值就会变小。\\n\\nSENet 的论文《Squeeze-and-Excitation Networks》中也有一些图一并给大家看看好\\n\\n了，如图 11.28 所示。\\n\\n图 11.28 Squeeze-and-Excitation block[8]\\n\\n各种符号什么意思我就不解释了，跟我前面介绍的内容差不多，大家随意看看就可以。\\n\\n图 11.29 和图 11.30 为 SE-Inception 模块和 SE-ResNet 模块。\\n\\n379',\n",
       " '379\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.29 SE-Inception 模块[8]\\n\\n图中的 Global pooling 表示全局池化；W 表示图片宽度；H 表示图片高度；C 表示图片\\n\\n通道数；FC 表示全连接层；r 表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n\\n就是一个超参数，不用细究，一般取值为 16。\\n\\n图 11.30 SE-ResNet 模块[8]\\n\\n图中的 Global pooling 表示全局池化；W 表示图片宽度；H 表示图片高度；C 表示图片\\n\\n通道数；FC 表示全连接层；r 表示缩减率，意思是通道数在第一个全连接层缩减多少，总之\\n\\n就是一个超参数，不用细究，一般取值为 16。\\n\\nResNet-50，SE-ResNet-50，SE-ResNeXt-50(32×4d)模型结构如图 11.31 所示。\\n\\n380\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 11.31 3 种 ResNet 模型对比[8]',\n",
       " '图 11.31 3 种 ResNet 模型对比[8]\\n\\n图中的 Output size 表示输出大小；conv 表示卷积；max pool 表示最大池化；stride\\n\\n表示步长；fc 表示全连接层；global average pool 表示全局平均池化；C 表示分组数。\\n\\n图中𝑓𝑐表示 fully connected 全连接层，𝑓𝑐后面的两个数字表示 SE 模块中两个全连接层\\n\\n的输出维度。\\n\\n11.3.2 SENet 结果分析\\n\\n基础模型增加 SE 模块后会使得整体模型的参数增加 10%左右，计算量增加不多，一般\\n\\n来说模型的效果也会有所提升。作者使用多个模型在 ImageNet 数据集上进行了测试，图\\n\\n11.32 为多个模型在 ImageNet 验证集测试结果。\\n\\n图 11.32 多个模型测试结果[8]\\n\\n381\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中 original 表示模型原始论文中的结果；re-implementation 表示 SENet 作者重新训',\n",
       " '练模型的结果；SENet 表示给这些模型加上 SE 模块后的结果；top-1 err.表示 top1 错误\\n\\n率；top-5 err.表示 top5 错误率；GFLOPs 表示计算量。\\n\\n图中结果可以看出，图中测试的所有模型只要加上 SE 模块，错误率都能降低，并且模型\\n\\n浮点计算量没有太大变化。图 11.33 和图 11.34 也能看出加上 SE 模块后模型效果可以变得\\n\\n更好：\\n\\n图 11.33 加上 SE 模块后的模型结果对比 1[8]\\n\\n图中的 epochs 表示周期；Top-1 error 表示 Top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n图 11.34 加上 SE 模块后的模型结果对比 2[8]\\n\\n图中的 epochs 表示周期；Top-1 error 表示 Top1 错误率；train 表示训练集；val 表示\\n\\n验证集。\\n\\n382\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nSENet 论文的最后，作者还给了一组很有意思的图。作者用 ImageNet 数据集训练了一',\n",
       " 'SENet 论文的最后，作者还给了一组很有意思的图。作者用 ImageNet 数据集训练了一\\n\\n个 SE-ResNet-50，然后选出 4 个种类(goldfish,pug,plane,cliff)的图片，统计这 4 个种类在\\n\\nSE-ResNet-50 模型的每个 SE 模块的特征图的激活情况，如图 11.35 所示。\\n\\n图 11.35 不同 SE 模块的激活情况[8]\\n\\n图中的 all 表示所有 1000 个种类的平均值；goldfish 表示金鱼；pug 表示哈巴狗；\\n\\nplane 表示飞机；cliff 表示悬崖；channel index 表示通道；activation 表示激活值。\\n\\n作者观察实验结果得到 3 个结论：\\n\\n第一，不同种类的物体在浅层激活分布情况是类似的，如图中的 SE_2_3 和 SE_3_4。也\\n\\n就是不管是识别哪种物体，浅层的卷积层中，重要的特征图总是比较固定的那些。\\n\\n第二，在更深层一些的位置，不同种类在不同的特征图激活分布不同，因为不同类别对\\n\\n特征有不同的偏好，如图中的 SE_4_6 和 SE_5_1。低层特征通常更普遍，识别不同种类物体',\n",
       " '特征有不同的偏好，如图中的 SE_4_6 和 SE_5_1。低层特征通常更普遍，识别不同种类物体\\n\\n383\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n可以使用类似的滤波器，而高层特征通常包含更多细节，识别不同种类物体需要使用不同的\\n\\n滤波器。\\n\\n第三，在模型的最后阶段，SE_5_2 呈现出饱和状态，其中大部分激活值都接近于 1，也\\n\\n有一些接近于 0。对于激活值为 1 的特征图，相当于 SE 模块不存在。在网络的最后一个 SE\\n\\n模块 SE_5_3，不同种类有着类似的分布，只是尺度不同。也就是说 SE_5_2 和 SE_5_3 相对\\n\\n来说没有前面的一些 SE 模块重要，作者通过实验发现删除最后一个阶段的 SE 模块，总体参\\n\\n数可以显著减少，性能只有一点损失(<0.1%的 Top1 错误率)。\\n\\n下一章节我们将介绍经典图像识别模型的代码实现，以及如何使用这些模型进行图像识\\n\\n别。\\n\\n11.4 参考文献',\n",
       " '别。\\n\\n11.4 参考文献\\n\\n[1] Szegedy C , Liu W , Jia Y , et al. Going Deeper with Convolutions[J]. 2014.\\n\\n[2] C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna. Rethinking the inception\\n\\narchitecture for computer vision. arXiv preprint arXiv:1512.00567, 2015.\\n\\n[3] Szegedy C , Ioffe S , Vanhoucke V . Inception-v4, Inception-ResNet and the\\n\\nImpact of Residual Connections on Learning[J]. 2016.\\n\\n[4] Simonyan, Karen, Zisserman, Andrew. Very Deep Convolutional Networks for\\n\\nLarge-Scale Image Recognition[J].',\n",
       " 'Large-Scale Image Recognition[J].\\n\\n[5] Xie S , Girshick R , Dollár, Piotr, et al. Aggregated Residual Transformations for\\n\\nDeep Neural Networks[J]. 2016.\\n\\n384\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[6] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep\\n\\nConvolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.\\n\\n[7] Ioannou Y , Robertson D , Cipolla R , et al. Deep Roots: Improving CNN Efficiency\\n\\nwith Hierarchical Filter Groups[J]. 2016.',\n",
       " 'with Hierarchical Filter Groups[J]. 2016.\\n\\n[8] Hu J , Shen L , Albanie S , et al. Squeeze-and-Excitation Networks[J]. IEEE\\n\\nTransactions on Pattern Analysis and Machine Intelligence, 2017.\\n\\n385\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 12 章-图像识别项目实战\\n\\n本章节内容主要是针对第 10，11 章节经典图像识别模型的程序实现，理论部分就不再重\\n\\n复了，直接上代码。注意代码实现不一定跟原始中的描述完全一致，基本框架以及核心实现\\n\\n跟论文是一致的。我们将结合图像识别项目实战内容给大家讲解模型搭建，由于图像识别技\\n\\n术在各个行业的应用基本上差别不大，不管你是做医疗图像分类，农产品图像分类，工业部\\n\\n件图像分类，天气云图图像分类，生活用品图像分类等，只要是图像分类，所用到的技术和',\n",
       " '件图像分类，天气云图图像分类，生活用品图像分类等，只要是图像分类，所用到的技术和\\n\\n流程都是差不多的。所以为了方便，本章节我们主要使用一个数据集给大家讲解，如果大家\\n\\n有其他图像数据集或自己收集了一些图像数据集也可以用本章内容进行图像分类。\\n\\n特别要说明一下，本章的重点在于 Tensorflow 中不同模型的搭建方法，以及图像识别模\\n\\n型的训练流程，因为数据量比较小，我也没有进行调参，所以最后模型的准确率不需要太在\\n\\n意。因为正常图像识别模型训练都不会从头训练（英文是 train from scratch），一般我们\\n\\n都在预训练模型的基础上做进一步的训练。由于我们使用的数据集太小，并不是 ImageNet\\n\\n级别的大数据集，所以从头训练（train from scratch）很难发挥模型的真正水平。本章\\n\\n12.11 小节将会介绍使用预训练模型来进行迁移学习的方法。\\n\\n12.1 图像数据准备\\n\\n12.1.1 数据集介绍\\n\\n在建模之前我们肯定需要先把数据给准备好，图像数据集有很多，大家可以自行收集，',\n",
       " '在建模之前我们肯定需要先把数据给准备好，图像数据集有很多，大家可以自行收集，\\n\\n我们这里使用的数据集是来自 Visual Geometry Group 的 17 Category Flower Dataset 数\\n\\n386\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n据集，也就是 17 种花的数据集。具体是哪 17 种这个我们可以不用管，反正就是 17 个类\\n\\n别。每个类别的花有 80 张图片，一共是 1360 张图片。单击网址\\n\\nhttp://www.robots.ox.ac.uk/~vgg/data/flowers/17/。出现如图 12.1 所示的界面。\\n\\n图 12.1 17 Category Flower Dataset\\n\\n我们单击“1.Dataset images”就可以下载数据集了，下载后得到一个名为\\n\\n“17flowers.tgz”的压缩包，解压后得到一个名为“17flowers”的文件夹，打开文件夹里\\n\\n面是一个名为“jpg”的文件夹，再打开“jpg”文件夹，我们会看到 1362 个文件，其中有',\n",
       " '面是一个名为“jpg”的文件夹，再打开“jpg”文件夹，我们会看到 1362 个文件，其中有\\n\\n1360 张图片。我们需要把不是图片的那两个文件给删除，只留下图片文件，如图 12.2 所\\n\\n示。\\n\\n12.2 17 种花的图片\\n\\n观察图片名称我们可以发现是都是由编号构成，前 1-80 号为第一种花，81 到 160 号为\\n\\n第二种花以此类推，1360 张图片一共 17 种花。\\n\\n387\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.1.2 数据集准备\\n\\n我们在做图像分类任务的时候，通常需要把数据先整理好，数据整理的格式通常都是每\\n\\n一个类别一个文件夹，文件夹的名称就是类别名称，如图 12.3 所示。\\n\\n图 12.3 数据集准备\\n\\n如图我想做一个 5 分类的图像识别模型，这 5 个分类分别\\n\\n是”animal”,”flower”,”guitar”,”house”,”plane”,那么我需要在一个新的路径下\\n\\n新建 5 个文件夹，这 5 个文件夹的名称修改',\n",
       " '新建 5 个文件夹，这 5 个文件夹的名称修改\\n\\n为”animal”,”flower”,”guitar”,”house”,”plane”。然后把对应类别的图片存放到\\n\\n对应的文件夹下面。如图 12.4 所示。\\n\\n图 12.4 存放数据\\n\\n这是图像分类任务的基本操作，正常情况下大家都会这么整理数据。不过 Visual\\n\\nGeometry Group 的 17 Category Flower Dataset 数据集所有的图片都是在一个文件夹下\\n\\n面的，所以这里我们还需要写一个程序来帮助我们整理一下图片，我写的这个程序是放在与\\n\\n“17flowers”文件夹相同目录下运行的，如果在其他路径运行，要注意程序中路径的设置，\\n\\n如代码 12-1 所示。\\n\\n代码 12-1：17Flower 数据整理\\n\\nimport os import shutil\\n\\n388',\n",
       " \"import os import shutil\\n\\n388\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 新建文件夹用于存放整理后的图片 os.mkdir('new_17_flowers') for i in range(17): # 17 个种类新建 17 个文件夹 0-16 os.mkdir('new_17_flowers'+'/'+str(i))\\n\\n# 循环所有花的图片 for i,path in enumerate(os.listdir('17flowers/jpg/')): # 定义花的图片完整路径 image_path = '17flowers/jpg/' + path # 复制到对应类别，每个类别 80 张图片 shutil.copyfile(image_path, 'new_17_flowers'+'/'+str(i//80)+'/'+path)\\n\\n运行完程序后就会产生一个新的文件夹“new_17_flowers”，这个文件夹里面有 17 个\",\n",
       " '运行完程序后就会产生一个新的文件夹“new_17_flowers”，这个文件夹里面有 17 个\\n\\n子文件夹，名字为 flower0- flower16，表示 17 种花的编号。flower0- flower16 文件夹里\\n\\n面都各自存放了 80 张图片。\\n\\n12.1.3 切分数据集程序\\n\\n数据集按照格式准备好以后，我们还需要切分训练集和测试集。因为我经常需要做数据\\n\\n切分的工作，所以就自己写了一个程序专门用于打乱数据并切分训练集和测试集。大家如果\\n\\n之后需要做类似的操作，可以参考或直接使用代码 12-2。该程序是放在与\\n\\n“new_17_flowers”文件夹相同的路径下的，如果大家在其他路径运行，需要注意程序中路\\n\\n径的设置。\\n\\n代码 12-2：切分数据集\\n\\nimport os import random import shutil import numpy as np # 数据集路径 DATASET_DIR = \"new_17_flowers\" # 数据切分后存放路径 NEW_DIR = \"data\" # 测试集占比 num_test = 0.2\\n\\n389',\n",
       " '389\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " \"# 打乱所有种类数据，并分割训练集和测试集 def shuffle_all_files(dataset_dir, new_dir, num_test): # 先删除已有 new_dir 文件夹 if not os.path.exists(new_dir): pass else: # 递归删除文件夹 shutil.rmtree(new_dir) # 重新创建 new_dir 文件夹 os.makedirs(new_dir) # 在 new_dir 文件夹目录下创建 train 文件夹 train_dir = os.path.join(new_dir, 'train') os.makedirs(train_dir) # 在 new_dir 文件夹目录下创建 test 文件夹 test_dir = os.path.join(new_dir, 'test') os.makedirs(test_dir) # 原始数据类别列表 directories = [] # 新训练集类别列表 train_directories = [] # 新测试集类别列表 test_directories = [] #\",\n",
       " '= [] # 新测试集类别列表 test_directories = [] # 类别名称列表 class_names = [] # 循环所有类别 for filename in os.listdir(dataset_dir): # 原始数据类别路径 path = os.path.join(dataset_dir, filename) # 新训练集类别路径 train_path = os.path.join(train_dir, filename) # 新测试集类别路径 test_path = os.path.join(test_dir, filename) # 判断该路径是否为文件夹 if os.path.isdir(path): # 加入原始数据类别列表 directories.append(path) # 加入新训练集类别列表 train_directories.append(train_path) # 新建类别文件夹 os.makedirs(train_path) # 加入新测试集类别列表 test_directories.append(test_path) # 新建类别文件夹',\n",
       " \"390\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com os.makedirs(test_path) # 加入类别名称列表 class_names.append(filename) print('类别列表：',class_names)\",\n",
       " '# 循环每个分类的文件夹 for i in range(len(directories)): # 保存原始图片路径 photo_filenames = [] # 保存新训练集图片路径 train_photo_filenames = [] # 保存新测试集图片路径 test_photo_filenames = [] # 得到所有图片的路径 for filename in os.listdir(directories[i]): # 原始图片路径 path = os.path.join(directories[i], filename) # 训练图片路径 train_path = os.path.join(train_directories[i], filename) # 测试集图片路径 test_path = os.path.join(test_directories[i], filename) # 保存图片路径 photo_filenames.append(path) train_photo_filenames.append(train_path)',\n",
       " 'train_photo_filenames.append(train_path) test_photo_filenames.append(test_path) # list 转 array photo_filenames = np.array(photo_filenames) train_photo_filenames = np.array(train_photo_filenames) test_photo_filenames = np.array(test_photo_filenames) # 打乱索引 index = [i for i in range(len(photo_filenames))] random.shuffle(index) # 对 3 个 list 进行相同的打乱，保证在 3 个 list 中索引一致 photo_filenames = photo_filenames[index] train_photo_filenames = train_photo_filenames[index] test_photo_filenames =',\n",
       " 'test_photo_filenames = test_photo_filenames[index] # 计算测试集数据个数 test_sample_index = int((1-num_test) * float(len(photo_filenames))) # 复制测试集图片 for j in range(test_sample_index, len(photo_filenames)): # 复制图片 shutil.copyfile(photo_filenames[j], test_photo_filenames[j]) # 复制训练集图片 for j in range(0, test_sample_index):',\n",
       " \"391\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 复制图片 shutil.copyfile(photo_filenames[j], train_photo_filenames[j])\\n\\n# 打乱并切分数据集 shuffle_all_files(DATASET_DIR, NEW_DIR, num_test) 运行结果如下： 类别列表： ['flower0', 'flower1', 'flower10', 'flower11', 'flower12', 'flower13 ', 'flower14', 'flower15', 'flower16', 'flower2', 'flower3', 'flower4', 'flowe\\n\\nr5', 'flower6', 'flower7', 'flower8', 'flower9']\\n\\n这个程序运行后会生成一个新的文件夹“data“，”data“文件夹中有两个子文件夹”\\n\\ntrain“和”test“。”train“表示训练集数据，占数据集的 80%，”test“表示测试集数\",\n",
       " '据，占数据集的 20%。”train“和”test“文件夹下的子文件夹都是 flower0- flower16，\\n\\n就是 17 种花的类别。“train”的子文件夹下，每个类别有 64 张图片，“test”的子文件夹\\n\\n下，每个类别有 16 张图片。\\n\\n12.2 AlexNet 图像识别\\n\\n这一小节我们要学习如何搭建 AlexNet 模型并从头进行模型训练，如代码 12-3 所示。\\n\\n代码 12-3：AlexNet 图像识别（片段 1）',\n",
       " '代码 12-3：AlexNet 图像识别（片段 1）\\n\\nimport numpy as np from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam import matplotlib.pyplot as plt from tensorflow.keras.callbacks import LearningRateScheduler # 类别数 num_classes = 17\\n\\n392',\n",
       " '392\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 批次大小 batch_size = 32 # 周期数 epochs = 100 # 图片大小 image_size = 224',\n",
       " \"# 训练集数据进行数据增强 train_datagen = ImageDataGenerator( rotation_range = 20, # 随机旋转度数 width_shift_range = 0.1, # 随机水平平移 height_shift_range = 0.1,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 10, # 随机错切变换 zoom_range = 0.1, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range=(0.7, 1.3), # 亮度变化 fill_mode = 'nearest', # 填充方式 ) # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator( rescale = 1/255, # 数据归一化 )\",\n",
       " \"# 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从'data/train'获得训练集数据 # 获得数据后会把图片 resize 为 image_size×image_size 的大小 # generator 每次会产生 batch_size 个数据 train_generator = train_datagen.flow_from_directory( 'data/train', target_size=(image_size,image_size), batch_size=batch_size, )\\n\\n# 测试集数据生成器 test_generator = test_datagen.flow_from_directory( 'data/test', target_size=(image_size,image_size), batch_size=batch_size, ) # 字典的键为 17 个文件夹的名字，值为对应的分类编号 print(train_generator.class_indices) 运行结果如下： {'flower0': 0,\\n\\n393\",\n",
       " \"393\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 'flower1': 1, 'flower10': 2, 'flower11': 3, 'flower12': 4, 'flower13': 5, 'flower14': 6, 'flower15': 7, 'flower16': 8, 'flower2': 9, 'flower3': 10, 'flower4': 11, 'flower5': 12, 'flower6': 13, 'flower7': 14, 'flower8': 15, 'flower9': 16}\\n\\n代码 12-3：AlexNet 图像识别（片段 2）\",\n",
       " \"# AlexNet model = Sequential() # 卷积层 model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding='valid',input_shape =(image_size,image_size,3),activation='relu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid')) model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same',activation='r elu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='valid')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='r\",\n",
       " \"elu')) model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(MaxPool2D(pool_size=(3,3), strides=(2,2),padding='valid')) # 全连接层 model.add(Flatten()) model.add(Dense(4096, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(4096, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) # 模型概要\",\n",
       " \"activation='softmax')) # 模型概要 model.summary()\",\n",
       " \"394\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 模型概要输出省略。。。\\n\\n# 学习率调节函数，逐渐减小学习率 def adjust_learning_rate(epoch): # 前 30 周期 if epoch<=30: lr = 1e-4 # 前 30 到 70 周期 elif epoch>30 and epoch<=70: lr = 1e-5 # 70 到 100 周期 else: lr = 1e-6 return lr\\n\\n# 定义优化器 adam = Adam(lr=1e-4)\\n\\n# 定义学习率衰减策略 callbacks = [] callbacks.append(LearningRateScheduler(adjust_learning_rate))\\n\\n# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\",\n",
       " '# Tensorflow2.1 版本之前可以使用 fit_generator 训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc hs=epochs,validation_data=test_generator,validation_steps=len(test_generator))',\n",
       " '# Tensorflow2.1 版本(包括 2.1)之后可以直接使用 fit 训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callba cks=callbacks) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 14s 418ms/step - loss: 2.77 50 - accuracy: 0.0800 - val_loss: 2.4774 - val_accuracy: 0.1250 Epoch 2/100 34/34 [==============================] - 13s 395ms/step - loss: 2.46 28 - accuracy: 0.1296 - val_loss: 2.2861 - val_accuracy: 0.1949\\n\\n……',\n",
       " '……\\n\\nEpoch 99/100\\n\\n395\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 34/34 [==============================] - 13s 390ms/step - loss: 0.08 79 - accuracy: 0.9743 - val_loss: 0.7067 - val_accuracy: 0.8346 Epoch 100/100 34/34 [==============================] - 13s 390ms/step - loss: 0.10 61 - accuracy: 0.9660 - val_loss: 0.7062 - val_accuracy: 0.8346\\n\\n代码 12-3：AlexNet 图像识别（片段 3）',\n",
       " \"代码 12-3：AlexNet 图像识别（片段 3）\\n\\n# 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy') # 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() 运行结果如下：\\n\\n12.3 VGGNet 图像识别\\n\\n这一小节我们要学习如何搭建 VGGNet 模型并从头进行模型训练，由于我们使用的都是\\n\\n同一个数据集案例，所以关于模块导入，参数设定，数据集预处理，模型训练，训练后画图\\n\\n396\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '396\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的程序基本都是一样的。主要就是模型搭建部分不同，所以为了节约用纸，我们仅在书中展\\n\\n示模型搭建部分的代码，完整的代码可见于本书相关代码。模型代码如代码 12-4 所示。\\n\\n代码 12-4：VGGNet 图像识别',\n",
       " \"…… …… …… # VGG16 model = Sequential() # 卷积层 model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='rel u',input_shape=(image_size,image_size,3))) model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='rel u')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu'))\",\n",
       " \"elu')) model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu'))\",\n",
       " \"elu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\",\n",
       " \"model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='r elu')) model.add(MaxPool2D(pool_size=(3,3),strides=(2,2),padding='same'))\",\n",
       " '397',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 全连接层 model.add(Flatten()) model.add(Dense(4096,activation='relu')) model.add(Dropout(0.5)) model.add(Dense(4096,activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes,activation='softmax')) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 15s 447ms/step - loss: 2.83 44 - accuracy: 0.0506 - val_loss: 2.8332 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================]\",\n",
       " '2/100 34/34 [==============================] - 14s 400ms/step - loss: 2.82 52 - accuracy: 0.0542 - val_loss: 2.8332 - val_accuracy: 0.0588',\n",
       " '……\\n\\nEpoch 99/100 34/34 [==============================] - 14s 401ms/step - loss: 0.20 13 - accuracy: 0.9311 - val_loss: 0.7145 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 14s 400ms/step - loss: 0.18 59 - accuracy: 0.9338 - val_loss: 0.7183 - val_accuracy: 0.7868\\n\\n观察 AlexNet 和 VGG16 模型的训练结果我们其实会发现 AlexNet 的结果反而比\\n\\nVGG16 的结果要好一些。AlexNet 测试集的准确率在 83%左右，VGG16 测试集的准确率在\\n\\n398\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n78%左右。由于我们是从新训练模型，并且数据量比较少，VGG16 模型比 AlexNet 结构更',\n",
       " '78%左右。由于我们是从新训练模型，并且数据量比较少，VGG16 模型比 AlexNet 结构更\\n\\n复杂，所以更难训练，那么结果差一些也是可以理解的。如果是大量数据的情况下，VGG16\\n\\n得到的结果应该会比 AlexNet 更好。\\n\\n12.4 函数式（functional）模型\\n\\n12.4.1 函数式（functional）模型介绍\\n\\n在 Tenorflow.keras 种有两种模型搭建的方法，一种就是我们之前学习使用的\\n\\nSequential 顺序模型，模型就像汉堡一样，是一层一层叠加起来的。除此之外模型搭建还有\\n\\n另外一种方式称为函数式模型。\\n\\n函数式模型的特点是需要定义模型的输入和输出，并且在模型搭建的过程中也更灵活。\\n\\n下面举个例子，比如我们在构建 GoogleNet 的 Inception 结构时，使用函数式模型的方式\\n\\n就会比较方便，下面程序我们将构建 GoogleNet 中第一个 Inception 的结构，如代码 12-5\\n\\n所示。\\n\\n代码 12-5：函数式编程实现 Inception 结构',\n",
       " '所示。\\n\\n代码 12-5：函数式编程实现 Inception 结构\\n\\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model',\n",
       " \"# 定义模型输入 inputs = Input(shape=(28,28,192)) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs)\\n\\n399\",\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 注意函数式模型的特点，Conv2D 后面的(tower_2)表示把 tower_2 信号输入到 Conv2D 中 计算 tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='re lu')(tower_2) # 注意函数式模型的特点，Conv2D 后面的(inputs)表示把 inputs 信号输入到 Conv2D 中计算 tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs) # 注意函数式模型的特点，Conv2D 后面的(tower_3)表示把 tower_3 信号输入到 Conv2D 中 计算 tower_3 =\",\n",
       " \"tower_3 信号输入到 Conv2D 中 计算 tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='rel u')(tower_3) # 注意函数式模型的特点，MaxPool2D 后面的(inputs)表示把 inputs 信号输入到 MaxPool2D 中计算 pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs) # 注意函数式模型的特点，Conv2D 后面的(pooling)表示把 pooling 信号输入到 Conv2D 中计 算 pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu' )(pooling) # concatenate 合并 4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出\",\n",
       " '合并 4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # 查看模型概要 model.summary() 运行结果如下：',\n",
       " '400\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n由于我们第一次讲解函数式编程，所以注释里我强调了很多次要注意函数式模型的特\\n\\n点，输入信号要放在函数的后面。\\n\\n12.4.2 使用函数式模型进行 MNIST 图像识别\\n\\n我们再来看一个函数式模型的完整例子，如代码 12-6 所示。\\n\\n代码 12-6：使用函数式模型进行 MNIST 图像识别\\n\\nimport tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten from tensorflow.keras.optimizers import Adam from tensorflow.keras.models import Model',\n",
       " '# 载入数据 mnist = tf.keras.datasets.mnist # 载入数据，数据载入的时候就已经划分好训练集和测试集 (x_train, y_train), (x_test, y_test) = mnist.load_data() # 这里要注意，在 tensorflow 中，在做卷积的时候需要把数据变成 4 维的格式 # 这 4 个维度是(数据数量，图片高度，图片宽度，图片通道数) # 所以这里把数据 reshape 变成 4 维数据，黑白图片的通道数是 1，彩色图片通道数是 3 x_train = x_train.reshape(-1,28,28,1)/255.0 x_test = x_test.reshape(-1,28,28,1)/255.0 # 把训练集和测试集的标签转为独热编码 y_train = tf.keras.utils.to_categorical(y_train,num_classes=10) y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)',\n",
       " \"# 定义模型输入 inputs = Input(shape=(28,28,1)) x = Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu')(inputs) x = MaxPool2D(pool_size=2,strides=2,padding='same')(x) x = Conv2D(64,5,strides=1,padding='same',activation='relu')(x) x = MaxPool2D(pool_size=2,strides=2,padding='same')(x) x = Flatten()(x) x = Dense(1024,activation='relu')(x) x = Dropout(0.5)(x) x = Dense(10,activation='softmax')(x) # 定义模型 model = Model(inputs,x)\\n\\n401\",\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义优化器 adam = Adam(lr=1e-4) # 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 model.fit(x_train,y_train,batch_size=64,epochs=2,validation_data=(x_test, y_test)) 运行结果如下： Train on 60000 samples, validate on 10000 samples Epoch 1/2 60000/60000 [==============================] - 83s 1ms/sample - los s: 0.3269 - accuracy: 0.9077 - val_loss: 0.0849 - val_accuracy: 0.975 2 Epoch 2/2\",\n",
       " '0.0849 - val_accuracy: 0.975 2 Epoch 2/2 60000/60000 [==============================] - 87s 1ms/sample - los s: 0.0893 - accuracy: 0.9730 - val_loss: 0.0528 - val_accuracy: 0.982 5',\n",
       " '12.5 模型可视化 plot_model\\n\\n12.5.1 使用 plot_model 进行模型可视化\\n\\nTensorflow 里面有一个小工具可以方便的画出模型结构，很好用。就是\\n\\ntensorflow.keras.utils.plot_model。\\n\\n使用 plot_model 前需要做一些准备工作，首先我们先要打开命令提示符安装 3 个\\n\\npython 模块：\\n\\npip install pydot\\n\\npip install pydot_ng\\n\\npip install graphviz\\n\\n安装好 3 个 python 模型后，我们还需要安装一个软件，软件下载网址是：\\n\\nhttps://graphviz.gitlab.io/download/。\\n\\n402\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n里面有 Linux，Windows，Mac 系统相对应的安装方法，因为每个系统安装方式不太一\\n\\n样，大家可以根据提示操作，搞不定的话可以网上搜索一下安装方法，我就不一一展开了。\\n\\n安装方式如图 12.6 所示。',\n",
       " '安装方式如图 12.6 所示。\\n\\n图 12.6 安装 Graphviz 软件\\n\\nWindows 用户应该比较多，我就以 Windows 为例简单说明一下，Windows 版本有一\\n\\n个软件下载地址为：\\n\\nhttps://www2.graphviz.org/Packages/stable/windows/10/msbuild/Release/Win32/gr\\n\\naphviz-2.38-win32.msi。下载完成后双击安装就可以，安装的路径我们要记住，默认路径\\n\\n一般是“C:\\\\Program Files(x86)\\\\Graphviz2.38”，可以使用默认路径或者修改为其他路径\\n\\n都可以。安装好之后，我们还需要把 Graphviz 软件主目录下 bin 文件的路径添加到环境变\\n\\n量中，如果是默认路径安装的话就是把“C:\\\\Program Files(x86)\\\\Graphviz2.38\\\\bin”添加\\n\\n到环境变量中。（可能有些同学还不知道怎么添加环境变量，这个内容太基础了，自行通过\\n\\n403\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '403\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n搜索引擎解决吧）。安装配置好以后最好重启电脑，到此为止准备工作应该就做好了。如果\\n\\n运行时还出现有其他问题的话可以自行通过搜索引擎解决。\\n\\n前面我们用函数式模型搭建了一个 Inception 结构，这个 Inception 结构如果我们看它\\n\\n的 summary 输出结果，大概可以看出来它的信号传递关系，但是看起来不太直观。\\n\\nsummary 比较适合用来看顺序模型的结构，看函数式模型就不太方便了。下面我们来学习\\n\\nplot_model 的用法，它可以比较直观的绘制出模型的结构，实现代码如代码 12-7 所示。\\n\\n代码 12-7：画出模型结构 plot_model',\n",
       " \"from tensorflow.keras.layers import Input,Conv2D,MaxPool2D,concatenate from tensorflow.keras.models import Model from tensorflow.keras.utils import plot_model # 定义模型输入 inputs = Input(shape=(28,28,192)) tower_1 = Conv2D(filters=64,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs) tower_2 = Conv2D(filters=96,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs) tower_2 = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='re\",\n",
       " \"lu')(tower_2) tower_3 = Conv2D(filters=16,kernel_size=(1,1),strides=(1,1),padding='same',activation='rel u')(inputs) tower_3 = Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',activation='rel u')(tower_3) pooling = MaxPool2D(pool_size=(3, 3),strides=(1, 1),padding='same')(inputs) pooling = Conv2D(filters=32,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu' )(pooling) # concatenate 合并 4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出 outputs =\",\n",
       " \"4 个信号，axis=3 表示根据 channel 进行合并，得到模型的输出 outputs = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) # 定义模型，设置输入和输出信号 model = Model(inputs=inputs, outputs=outputs) # model 表示要画图的模型 # 'model.png'表示图片存放路径 # show_shapes=True 画出信号的 shape # dpi 设置分辨率，默认是 96 plot_model(model=model, to_file='model.png', show_shapes=True, dpi=200) 运行结果如下：\",\n",
       " \"404\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n运行程序后，在程序所在目录下会产生一张名为'model.png'的图片，保存着模型的结构\\n\\n图。这个图我就不需要多解释了，可以清楚地看到信号的传递关系和信号的 shape 变化。\\n\\n代码 12-6 中的模型使用 plot_model 画出来的结构如图 12.7 所示。\\n\\n图 12.7 plot_model 绘制模型结构\\n\\n405\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nplot_model 画出来的图可以很清晰的看到网络各层结构，信号的流动关系，以及信号输\\n\\n入输出的 shape。如果以后大家对模型的结构理解得不够好的话，可以用 plot_model 把模\\n\\n型结构画出来，看着模型结构图来理解模型的结构会容易一些。\\n\\n12.5.2 plot_model 升级版\\n\\n上一小节我们学习了使用 Tensorflow 官方的 plot_model 来绘制网络结构，\\n\\nplot_model 确实对我们理解模型结构有着很好的帮助。但是如果你仔细观察的话你会发现\",\n",
       " 'plot_model 确实对我们理解模型结构有着很好的帮助。但是如果你仔细观察的话你会发现\\n\\n好像 plot_model 画出来的图好像少了些什么重要的内容。对了，这就卷积/池化窗口的大\\n\\n小，卷积/池化的步长，卷积/池化的 padding 方式，Dense 层的激活函数，Dropout 的系\\n\\n数等这些具体参数对于我们理解网络具体结构也是非常重要的，但是 plot_model 没有把这\\n\\n些信息标注出来。\\n\\n为了可以画出更好的模型结构图，我在 Tensorflow 官方的 plot_model 基础上进行的优\\n\\n化，优化后的效果如图 12.8 和图 12.9 所示。\\n\\n406\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.8 plot_model 升级版 1\\n\\n图 12.9 plot_model 升级版 2\\n\\n我对原始 plot_model 的修改主要就是增加了更多的模型细节以及不同模块有不同颜\\n\\n色，简单的模型可能效果不够明显，如果大家在学习复杂模型的时候，显示更多的细节和颜\\n\\n色区分帮助还是很大的。\\n\\n407',\n",
       " '色区分帮助还是很大的。\\n\\n407\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我优化过的 plot_model 已经发布在 PyPi：https://pypi.org/project/plot-model/。源\\n\\n代码在我的 Github 可以看到：https://github.com/Qinbf/plot_model。推荐安装方式是\\n\\n使用 pip 安装，打开命令提示符输入命令：\\n\\npip install plot_model\\n\\n安装好以后通过如下代码导入：\\n\\nfrom plot_model import plot_model\\n\\nplot_model 的使用方式跟 Tensorflow 中的 plot_model 一样，不过增加了两个参数。\\n\\n一个是 style，可以取值 0 和 1，默认值为 0。style=0 表示使用新风格，style=1 表示使用\\n\\n老风格，大家可以自行尝试。还有一个参数是 color，取值为 True 或 False，默认值是',\n",
       " '老风格，大家可以自行尝试。还有一个参数是 color，取值为 True 或 False，默认值是\\n\\nTrue。color=True 表示画彩色结构图，color=False 表示画黑白结构图。以后大家需要画模\\n\\n型结构图的时候，推荐大家使用我的 plot_model。\\n\\n12.6 GoogleNet 图像识别\\n\\nGoogleNet 中包含了很多 Inception 模块，所以我们可以定义一个 Inception 函数专门\\n\\n用于实现 Inception 模块。在调用 Inception 函数时根据论文中 GoogleNet 网络结构描述\\n\\n传入不同的参数即可。我们将使用函数式模型来定义 GoogleNet，同样我们只展示建模相关\\n\\n代码，如代码 12-8 所示。\\n\\n代码 12-8：GoogleNet 图像识别\\n\\n…… …… …… # 定义 Inception 结构 def Inception(x,filters):\\n\\n408',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 409 tower_1 = Conv2D(filters=filters[0],kernel_size=1,strides=1,padding='same',activation='re lu')(x) tower_2 = Conv2D(filters=filters[1],kernel_size=1,strides=1,padding='same',activation='re lu')(x) tower_2 = Conv2D(filters=filters[2],kernel_size=3,strides=1,padding='same',activation='re lu')(tower_2) tower_3 = Conv2D(filters=filters[3],kernel_size=1,strides=1,padding='same',activation='re lu')(x) tower_3 =\",\n",
       " \"lu')(x) tower_3 = Conv2D(filters=filters[4],kernel_size=5,strides=1,padding='same',activation='re lu')(tower_3) pooling = MaxPool2D(pool_size=3,strides=1,padding='same')(x) pooling = Conv2D(filters=filters[5],kernel_size=1,strides=1,padding='same',activation='rel u')(pooling) x = concatenate([tower_1,tower_2,tower_3,pooling],axis=3) return x\",\n",
       " \"# 定义 GoogleNet 模型 model_input = Input(shape=(image_size,image_size,3)) x = Conv2D(filters=64,kernel_size=7,strides=2,padding='same',activation='relu')(model_inp ut) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Conv2D(filters=64,kernel_size=1,strides=1,padding='same',activation='relu')(x) x = Conv2D(filters=192,kernel_size=3,strides=1,padding='same',activation='relu')(x) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[64,96,128,16,32,32]) x =\",\n",
       " \"x = Inception(x,[64,96,128,16,32,32]) x = Inception(x,[128,128,192,32,96,64]) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[192,96,208,16,48,64]) x = Inception(x,[160,112,224,24,64,64]) x = Inception(x,[128,128,256,24,64,64]) x = Inception(x,[112,144,288,32,64,64]) x = Inception(x,[256,160,320,32,128,128]) x = MaxPool2D(pool_size=3,strides=2,padding='same')(x) x = Inception(x,[256,160,320,32,128,128]) x = Inception(x,[384,192,384,48,128,128]) x =\",\n",
       " \"x = Inception(x,[384,192,384,48,128,128]) x = AvgPool2D(pool_size=7,strides=7,padding='same')(x) x = Flatten()(x) x = Dropout(0.4)(x) x = Dense(num_classes,activation='softmax')(x) model = Model(inputs=model_input,outputs=x) …… …… …… 运行结果如下：\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 16s 477ms/step - loss: 2.77 64 - accuracy: 0.0699 - val_loss: 2.5863 - val_accuracy: 0.1140 Epoch 2/100 34/34 [==============================] - 13s 392ms/step - loss: 2.46 51 - accuracy: 0.1360 - val_loss: 2.3358 - val_accuracy: 0.1471 …… Epoch 99/100 34/34 [==============================] - 13s 395ms/step - loss: 0.17 23 - accuracy: 0.9366 - val_loss: 0.8696 -',\n",
       " '0.17 23 - accuracy: 0.9366 - val_loss: 0.8696 - val_accuracy: 0.7831 Epoch 100/100 34/34 [==============================] - 13s 393ms/step - loss: 0.16 41 - accuracy: 0.9430 - val_loss: 0.8596 - val_accuracy: 0.7904',\n",
       " 'GoogleNet 的结构是一个个 Inception 结构叠加得到的，看程序就很容易理解，不过还\\n\\n是建议大家用 plot_model()把模型结构图画出来，对照着模型结构图来看理解起来更容易，\\n\\n绝对能够让你清晰理解 GoogleNet 的具体结构（注意图片太大，dpi 不要调太高）。由于\\n\\nplot_model()画出来的图太长我就不放到书里了，大家可以自行操作。\\n\\n410\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.7 Batch Normalization 使用\\n\\nBN 我们在之前的内容中学习过，是一种很神奇的网络优化技巧，下面我们通过一个\\n\\nCIFAR10 的图像分类来对比一下，使用 BN 和不使用 BN 的模型效果，如代码 12-9 所示。\\n\\n代码 12-9：BN-CIFAR10 图像分类',\n",
       " 'import numpy as np from tensorflow.keras.datasets import cifar10 from tensorflow.keras.utils import to_categorical from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchN ormalization,Activation from tensorflow.keras.optimizers import Adam,RMSprop import matplotlib.pyplot as plt # 下载并载入数据 # 训练集数据(50000, 32, 32, 3) # 测试集数据(50000, 1) (x_train,y_train),(x_test,y_test) = cifar10.load_data() # 数据归一化 x_train = x_train/255.0',\n",
       " '# 数据归一化 x_train = x_train/255.0 x_test = x_test/255.0 # 换 one hot 格式 y_train = to_categorical(y_train,num_classes=10) y_test = to_categorical(y_test,num_classes=10)',\n",
       " \"# 定义卷积网络 model = Sequential() model.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, padding='s ame', activation = 'relu')) model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.2))\",\n",
       " \"model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation = 'relu')) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.3))\\n\\n411\",\n",
       " \"411\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 412 model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu' )) model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation = 'relu' )) model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model.add(Dropout(0.4))\\n\\nmodel.add(Flatten()) model.add(Dense(10,activation = 'softmax'))\",\n",
       " \"# 定义使用了 BN 的卷积网络 # 两个模型结构完全一致，区别只在于是否使用 BN model_bn = Sequential() model_bn.add(Conv2D(input_shape=(32,32,3), filters=32, kernel_size=3, strides=1, paddin g='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.2))\",\n",
       " \"model_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.3))\",\n",
       " \"model_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same')) model_bn.add(BatchNormalization()) model_bn.add(Activation('relu')) model_bn.add(MaxPooling2D(pool_size=2, strides=2, padding='valid')) model_bn.add(Dropout(0.4))\\n\\nmodel_bn.add(Flatten()) model_bn.add(Dense(10,activation = 'softmax'))\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 定义优化器 adam = Adam(lr=1e-4)',\n",
       " \"# 定义优化器，loss function，训练过程中计算准确率 model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 定义优化器，loss function，训练过程中计算准确率 model_bn.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) # 训练模型 history = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_t est), shuffle=True) history_bn = model_bn.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_ test, y_test), shuffle=True)\",\n",
       " \"plt.plot(np.arange(100),history.history['val_accuracy'],c='b',label='without_bn') # 画出使用 BN 的模型验证集准确率 plt.plot(np.arange(100),history_bn.history['val_accuracy'],c='y',label='bn') plt.legend() plt.xlabel('epochs') plt.ylabel('accuracy') plt.show() 运行结果如下：\\n\\n12.8 ResNet 图像识别\\n\\n同样这里我们只展示 ResNet 建模相关代码，如代码 12-10 所示。\\n\\n413\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 12-10：ResNet50 图像识别\",\n",
       " \"from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D …… …… …… # 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut) else: # identity_shortcut shortcut = x # 3 个卷积层 x =\",\n",
       " \"# identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x)\",\n",
       " \"x = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x)\\n\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x)\\n\\nx = Add()([x, shortcut]) x = Activation('relu')(x) return x\\n\\n# 堆叠残差单元 def stack(x, filters, blocks, strides): x = block(x, filters, strides=strides) for i in range(blocks-1): x = block(x, filters, conv_shortcut=False) return x\",\n",
       " '# 定义 ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230\\n\\n414',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512,\",\n",
       " \"blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 19s 546ms/step - loss: 3.05 63 - accuracy: 0.1195 - val_loss: 2.8569 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 399ms/step - loss: 2.45\",\n",
       " '- 14s 399ms/step - loss: 2.45 23 - accuracy: 0.2022 - val_loss: 2.9909 - val_accuracy: 0.0588',\n",
       " '……\\n\\nEpoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.02 24 - accuracy: 0.9954 - val_loss: 1.0080 - val_accuracy: 0.7794 Epoch 100/100 34/34 [==============================] - 14s 404ms/step - loss: 0.02 29 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794\\n\\n415\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n这里我使用了一种比较简洁的方式来搭建 ResNet 模型，程序比较简洁，不过理解起来\\n\\n可能需要多花点时间，建议一行一行代码仔细理解。同时可以借助 plot_model()来帮助模型\\n\\n结构的理解。由于 plot_model()画出来的图太长我就不放到书里了，我截取两个局部给大家',\n",
       " '结构的理解。由于 plot_model()画出来的图太长我就不放到书里了，我截取两个局部给大家\\n\\n看看好了，图 12.10 为 identity shortcut 残差单元（左）和 projection shortcut 残差单元\\n\\n（右）。\\n\\n416\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.10 identity（左），projection（右）\\n\\n417\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.9 ResNeXt图像识别\\n\\n同样这里我们只展示 ResNeXt 建模相关代码，如代码 12-11 所示。\\n\\n代码 12-11：ResNeXt50(32×4d)图像识别',\n",
       " 'from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D,Lambda …… …… …… # 定义分组卷积 # g_channels 每组的通道数 # groups 多少组 def grouped_convolution_block(init_x, strides, groups, g_channels): group_list = [] # 分组进行卷积 for c in range(groups): # 分组取出数据 x = Lambda(lambda x: x[:, :, :, c*g_channels:(c+1)*g_channels])(init_x) # 分组进行卷积 x =',\n",
       " \"# 分组进行卷积 x = Conv2D(filters=g_channels,kernel_size=3,strides=strides,padding='same',use_bia s=False)(x) # 存入 list group_list.append(x) # 合并 list 中的数据 group_merge = concatenate(group_list, axis=3) x = BatchNormalization(epsilon=1.001e-5)(group_merge) x = Activation('relu')(x) return x\",\n",
       " \"# 定义残差单元 def block(x, filters, strides=1, groups=32, conv_shortcut=True): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*2,kernel_size=1,strides=strides,padding='same')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\\n\\n418\",\n",
       " \"418\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com else: # identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=1,padding='same')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 计算每组的通道数 g_channels = int(filters / groups) # 进行分组卷积 x = grouped_convolution_block(x, strides, groups, g_channels)\",\n",
       " \"x = Conv2D(filters=filters*2,kernel_size=1,strides=1,padding='same')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Add()([x, shortcut]) x = Activation('relu')(x) return x\\n\\n# 堆叠残差单元 def stack(x, filters, blocks, strides, groups=32): x = block(x, filters, strides=strides, groups=groups) for i in range(blocks): x = block(x, filters, groups=groups, conv_shortcut=False) return x\",\n",
       " \"# 定义 ResNeXt50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=128, blocks=2, strides=1) x = stack(x, filters=256, blocks=3, strides=2) x = stack(x,\",\n",
       " \"filters=256, blocks=3, strides=2) x = stack(x, filters=512, blocks=5, strides=2) x = stack(x, filters=1024, blocks=2, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x)\",\n",
       " '419\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 定义模型 model = Model(inputs=inputs,outputs=x)',\n",
       " '# 电脑配置不好的话不要运行 summary 或者 plot_model # model.summary() …… …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 37s 1s/step - loss: 2.8832 - accuracy: 0.0901 - val_loss: 2.9076 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 17s 490ms/step - loss: 2.48 76 - accuracy: 0.1838 - val_loss: 3.1728 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 17s 495ms/step - loss: 0.03 28 - accuracy:',\n",
       " '- 17s 495ms/step - loss: 0.03 28 - accuracy: 0.9982 - val_loss: 0.9105 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 17s 495ms/step - loss: 0.02 48 - accuracy: 0.9991 - val_loss: 0.9058 - val_accuracy: 0.8088',\n",
       " 'ResNeXt50 的模型程序跟 ResNet50 差不多，使用一个函数\\n\\ngrouped_convolution_block 完成分组卷积的操作。建议大家使用 plot_model 看一下模型\\n\\n结构（建议 dpi 使用 96 或更低的值），groups=32 画出来的图太大了，下面给大家看一下\\n\\ngroups=4 画出来的图的残差结构，如图 12.11 所示。\\n\\n420\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.11 groups=4 的 ResNeXt 残差单元\\n\\n421\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n12.10 SENet 图像识别\\n\\n同样这里我们只展示 SE-ResNet50 建模相关代码，如代码 12-12 所示。\\n\\n代码 12-12：SE-ResNet50 图像识别',\n",
       " \"from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,Glob alAvgPool2D,BatchNormalization,Activation,Add,ZeroPadding2D,Multiply …… …… …… # SE 模块 def ChannelSE(input_tensor, reduction=16): # 获得信号通道数 channels = input_tensor.shape[-1] # SE 模块 x = GlobalAvgPool2D()(input_tensor) # 把 2 维数据再变成 4 维(?,1,1,?) x = x[:, None, None, :] # 卷积替代全连接层 x = Conv2D(filters=channels//reduction,kernel_size=1,strides=1)(x) x = Activation('relu')(x) x =\",\n",
       " \"x = Activation('relu')(x) x = Conv2D(filters=channels,kernel_size=1,strides=1)(x) x = Activation('sigmoid')(x) x = Multiply()([input_tensor, x]) return x\",\n",
       " \"# 定义残差单元 def block(x, filters, strides=1, conv_shortcut=True, reduction=16): # projection shortcut if conv_shortcut == True: shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x) # epsilon 为 BN 公式中防止分母为零的值 shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut) else: # identity_shortcut shortcut = x # 3 个卷积层 x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x)\\n\\n422\",\n",
       " \"422\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nx = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x)\\n\\nx = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x)\\n\\n# SE 模块 x = ChannelSE(x, reduction=reduction)\\n\\nx = Add()([x, shortcut]) x = Activation('relu')(x) return x\",\n",
       " '# 堆叠残差单元 def stack(x, filters, blocks, strides): x = block(x, filters, strides=strides) for i in range(blocks-1): x = block(x, filters, conv_shortcut=False) return x',\n",
       " \"# 定义 SE-ResNet50 inputs = Input(shape=(image_size,image_size,3)) # 填充 3 圈 0，填充后图像从 224×224 变成 230×230 x = ZeroPadding2D((3, 3))(inputs) x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x) x = BatchNormalization(epsilon=1.001e-5)(x) x = Activation('relu')(x) # 填充 1 圈 0 x = ZeroPadding2D((1, 1))(x) x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x) # 堆叠残差结构 # blocks 表示堆叠数量 x = stack(x, filters=64, blocks=3, strides=1) x = stack(x, filters=128, blocks=4, strides=2) x = stack(x,\",\n",
       " \"filters=128, blocks=4, strides=2) x = stack(x, filters=256, blocks=6, strides=2) x = stack(x, filters=512, blocks=3, strides=2) # 根据特征图大小进行平均池化，池化后得到 2 维数据 x = GlobalAvgPool2D()(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(inputs=inputs,outputs=x) ……\",\n",
       " '423',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com …… …… 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/100 34/34 [==============================] - 27s 786ms/step - loss: 2.48 03 - accuracy: 0.2114 - val_loss: 2.8556 - val_accuracy: 0.0588 Epoch 2/100 34/34 [==============================] - 14s 401ms/step - loss: 1.82 87 - accuracy: 0.4017 - val_loss: 2.9926 - val_accuracy: 0.0588 …… Epoch 99/100 34/34 [==============================] - 14s 406ms/step - loss: 0.00 44 - accuracy: 1.0000 - val_loss:',\n",
       " '- loss: 0.00 44 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.8088 Epoch 100/100 34/34 [==============================] - 14s 407ms/step - loss: 0.00 43 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.8088',\n",
       " 'SE-ResNet50 用 plot_model 画出来的图会很大，大家可以自己运行，下面我就给大家\\n\\n看一下 SE-ResNet50 其中一个残差单元的图，如图 12.12 所示。\\n\\n424\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n425\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 12.12 SE-ResNet50 残差单元\\n\\n12.11 使用预训练模型进行迁移学习\\n\\n12.11.1 使用训练好的模型进行图像识别\\n\\n本章前面的内容中，我们主要是学习了模型搭建方法，这一小节我们将学习使用迁移学\\n\\n习的方式来训练图像识别模型。图像识别的迁移学习简单的来说就是使用一个已经经过预训\\n\\n练的模型，在这个预训练的模型基础上稍作修改，然后训练自己的数据集，也称为微调\\n\\n（Finetune）。这里的预训练模型通常都是使用 ImageNet 比赛数据集训练出来的模型。\\n\\nTensorflow 中有很多官方提供的使用 ImageNet 数据集训练好的预训练模型，我们可以直\\n\\n接下载使用，如图 12.13 所示。',\n",
       " '接下载使用，如图 12.13 所示。\\n\\n图 12.13 可用预训练模型\\n\\n下面我们先看一下如何使用预训练模型来进行图像识别，第一次载入模型需要从网上下\\n\\n载模型，下载的模型会存放在你的用户目录下.keras 隐藏文件夹下的 models 文件夹中（比\\n\\n如 C:\\\\User\\\\qin\\\\.keras\\\\models）。我自己准备了一些图片存放在“test”文件夹中用于测\\n\\n试，如代码 12-13 所示。\\n\\n代码 12-13：使用训练好的 ResNet50 进行图像识别\\n\\nfrom tensorflow.keras.applications.resnet50 import ResNet50\\n\\n426',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # imagenet 数据处理工具 from tensorflow.keras.applications.imagenet_utils import decode_predictions,preprocess_in put from tensorflow.keras.preprocessing.image import img_to_array,load_img import matplotlib.pyplot as plt import os import numpy as np # 图片大小 image_size = 224 # 存放测试图片的文件夹 image_dir = 'test' # 载入使用 imagenet 训练好的预训练模型 # include_top=True 表示模型包含全连接层 # include_top=False 表示模型不包含全连接层 # 下载的程序会存放在你的用户目录下.keras 隐藏文件夹下的 models 文件夹中 resnet50 =\",\n",
       " \"隐藏文件夹下的 models 文件夹中 resnet50 = ResNet50(weights='imagenet',include_top=True, input_shape=(image_size,ima ge_size,3))\",\n",
       " \"# 循环目录下的图片并进行显示预测 for file in os.listdir(image_dir): # 测试图片完整路径 file_dir = os.path.join(image_dir,file) # 读入图片，并 resize 为 224*224 大小 img = load_img(file_dir, target_size=(224, 224)) # 显示图片 plt.imshow(img) plt.axis('off') plt.show() # 将图片转化为 array x = img_to_array(img) # 增加 1 个维度变成 4 维数据 # (224, 224, 3)->(1, 224, 224, 3) x = np.expand_dims(x, axis=0) # 把像素数值归一化为(-1,1)之间，并让 RGB 通道减去对应均值 x = preprocess_input(x) # preds.shap->(1, 1000),1000 个概率值 preds = resnet50.predict(x) # decode_predictions\",\n",
       " 'preds = resnet50.predict(x) # decode_predictions 用于预测结果解码 # 将测试结果解码为如下形式： # [(编码 1, 英文名称 1, 概率 1),(编码 2, 英文名称 2, 概率 2)...] # top=1 表示概率最大的 1 个结果，top=3 表示概率最大的 3 个结果 predicted_classes = decode_predictions(preds, top=1) imagenet_id, name, confidence = predicted_classes[0][0]',\n",
       " '427\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 打印结果 print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100)) 运行结果如下：\\n\\nThis is a sandbar with 44.15% confidence!\\n\\nThis is a soup_bowl with 61.99% confidence!\\n\\nThis is a tabby named chouchou with 90.97% confidence!\\n\\n12.11.2 使用训练好的模型进行迁移学习\\n\\n现在我们要使用预训练的模型来训练自己的数据集了，为了方便，我还是使用 17flowers\\n\\n的数据集，如果大家有其他数据集的话也可以使用。使用 VGG16 完成迁移学习的代码如代\\n\\n码 12-14 所示。\\n\\n代码 12-14：使用 VGG16 完成迁移学习',\n",
       " '码 12-14 所示。\\n\\n代码 12-14：使用 VGG16 完成迁移学习\\n\\nfrom tensorflow.keras.applications.vgg16 import VGG16 from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dropout,Flatten,Dense\\n\\n428',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com from tensorflow.keras.optimizers import SGD from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load _img import json import matplotlib.pyplot as plt import numpy as np # 类别数 num_classes = 17 # 批次大小 batch_size = 32 # 周期数 epochs = 40 # 图片大小 image_size = 224 # 训练集数据进行数据增强 train_datagen = ImageDataGenerator( rotation_range = 20, # 随机旋转度数 width_shift_range = 0.1, # 随机水平平移 height_shift_range = 0.1,# 随机竖直平移 rescale = 1/255, # 数据归一化',\n",
       " \"= 0.1,# 随机竖直平移 rescale = 1/255, # 数据归一化 shear_range = 10, # 随机错切变换 zoom_range = 0.1, # 随机放大 horizontal_flip = True, # 水平翻转 brightness_range=(0.7, 1.3), # 亮度变化 fill_mode = 'nearest', # 填充方式 ) # 测试集数据只需要归一化就可以 test_datagen = ImageDataGenerator( rescale = 1/255, # 数据归一化 ) # 训练集数据生成器，可以在训练时自动产生数据进行训练 # 从'data/train'获得训练集数据 # 获得数据后会把图片 resize 为 image_size×image_size 的大小 # generator 每次会产生 batch_size 个数据 train_generator = train_datagen.flow_from_directory( 'data/train',\",\n",
       " \"train_datagen.flow_from_directory( 'data/train', target_size=(image_size,image_size), batch_size=batch_size, )\",\n",
       " \"# 测试集数据生成器 test_generator = test_datagen.flow_from_directory( 'data/test', target_size=(image_size,image_size),\\n\\n429\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com batch_size=batch_size,\\n\\n)\",\n",
       " \")\\n\\n# 字典的键为 17 个文件夹的名字，值为对应的分类编号 label = train_generator.class_indices # 把字典的键值对反过来 # 分类编号为键，分类名称为值 label = dict(zip(label.values(),label.keys())) # 保存到 json 文件中 file = open('label_flower.json','w',encoding='utf-8') json.dump(label, file) # 载入使用 imagenet 训练好的预训练模型 # include_top=True 表示模型包含全连接层 # include_top=False 表示模型不包含全连接层 vgg16 = VGG16(weights='imagenet',include_top=False, input_shape=(image_size,image_s ize,3))\",\n",
       " \"# 搭建全连接层，连接在 VGG16 模型后面 # 我们主要是利用 VGG16 卷积网络已经训练好的特征提取能力来提取特征 # 然后搭建新的全连接层来进行新图片类型的分类 top_model = Sequential() top_model.add(Flatten(input_shape=vgg16.output_shape[1:])) top_model.add(Dense(256,activation='relu')) top_model.add(Dropout(0.5)) top_model.add(Dense(num_classes,activation='softmax'))\\n\\nmodel = Sequential() model.add(vgg16) model.add(top_model)\\n\\n# 定义优化器，代价函数，训练过程中计算准确率，设置一个较小的学习率 model.compile(optimizer=SGD(lr=1e- 3,momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])\",\n",
       " '# Tensorflow2.1 版本之前可以使用 fit_generator 训练模型 # history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epoc hs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\\n\\n# Tensorflow2.1 版本(包括 2.1)之后可以直接使用 fit 训练模型 history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator) 运行结果如下： Train for 34 steps, validate for 9 steps Epoch 1/40\\n\\n430',\n",
       " '430\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 34/34 [==============================] - 15s 440ms/step - loss: 2.83 96 - accuracy: 0.1131 - val_loss: 2.2644 - val_accuracy: 0.2904 Epoch 2/40 34/34 [==============================] - 14s 406ms/step - loss: 1.97 65 - accuracy: 0.3713 - val_loss: 1.3263 - val_accuracy: 0.6029\\n\\n……',\n",
       " \"Epoch 39/40 34/34 [==============================] - 14s 402ms/step - loss: 0.00 62 - accuracy: 0.9991 - val_loss: 0.1977 - val_accuracy: 0.9632 Epoch 40/40 34/34 [==============================] - 14s 399ms/step - loss: 0.01 21 - accuracy: 0.9945 - val_loss: 0.1575 - val_accuracy: 0.9706 # 画出训练集准确率曲线图 plt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy') # 画出验证集准确率曲线图 plt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy') # 图例\",\n",
       " \"# 图例 plt.legend() # x 坐标描述 plt.xlabel('epochs') # y 坐标描述 plt.ylabel('accuracy') # 显示图像 plt.show() # 模型保存 model.save('vgg16.h5') 运行结果如下：\",\n",
       " '431\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从结果我们可以看到是用了预训练的 VGG16 模型来训练 17flowers 数据集，模型的收\\n\\n敛速度非常快，只训练几个周期就得到了很好的结果。并且训练 40 个周期以后，模型的验\\n\\n证集达到了 97%非常高的准确率。\\n\\n12.11.3 载入训练好的模型进行预测\\n\\n上一小节我们训练好了一个 97%准确率的 17 种花的识别模型并保存为“vgg16.h5“模\\n\\n型文件，这个小节我们要重新载入这个训练好的模型，使用它对其他图片进行预测。模型分\\n\\n类编号跟分类名称的对应关系在上小节的程序里面也已经保存在“label_flower.json”文件\\n\\n中，可以直接载入。我准备了几张测试图片存放在“flowers_test”文件夹中，测试图片的\\n\\n文件名就是该图片的分类名称，如代码 12-15 所示。\\n\\n代码 12-15：载入训练好的模型进行预测（片段 1）',\n",
       " \"from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.image import img_to_array,load_img import json import os import matplotlib.pyplot as plt import numpy as np # 测试图片存放位置 image_dir = 'flowers_test' # 载入标签 json 文件 file = open('label_flower.json','r',encoding='utf-8') label = json.load(file) # 键为分类编号，值为分类名称 print(label) 运行结果如下： {'0': 'flower0', '1': 'flower1', '2': 'flower10', '3': 'flower11', '4 ': 'flower12', '5': 'flower13', '6': 'flower14', '7': 'flower15', '8\",\n",
       " \"'flower13', '6': 'flower14', '7': 'flower15', '8 ': 'flower16', '9': 'flower2', '10': 'flower3', '11': 'flower4', '12 ': 'flower5', '13': 'flower6', '14': 'flower7', '15': 'flower8', '16 ': 'flower9'}\",\n",
       " \"代码 12-15：载入训练好的模型进行预测（片段 2）\\n\\n# 载入训练好的模型\\n\\n432\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model = load_model('VGG16.h5')\",\n",
       " \"# 预测函数 def model_predict(file_dir): # 读入图片，并 resize 为 224*224 大小 img = load_img(file_dir, target_size=(224, 224)) # 显示图片 plt.imshow(img) plt.axis('off') plt.show() # 将图片转化为 array x = img_to_array(img) # 增加 1 个维度变成 4 维数据 # (224, 224, 3)->(1, 224, 224, 3) x = np.expand_dims(x, axis=0) # 模型预测结果 # predict_classes 直接返回预测分类结果，比如:[2] preds = model.predict_classes(x) # label 字典中的键为字符串，所以这里需要把 preds[0]转为 str # 根据分类编号查询 label 中对应的分类名称 preds = label[str(preds[0])] return preds\",\n",
       " \"# 循环测试文件夹 for file in os.listdir(image_dir): # 测试图片完整路径 file_dir = os.path.join(image_dir,file) # 打印文件路径 print(file_dir) # 传入文件路径进行预测 preds = model_predict(file_dir) print('predict:',preds) print('-'*20) 运行结果如下： flowers_test\\\\flower0.jpg\\n\\npredict: flower0\\n\\n433\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com -------------------- flowers_test\\\\flower10.jpg\\n\\npredict: flower10 -------------------- flowers_test\\\\flower5.jpg\\n\\npredict: flower5 --------------------\\n\\n434\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '434\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 13 章-验证码识别项目实战\\n\\n本章属于内外兼修的章节，既有多任务学习和 CTC 算法介绍，又有大量 Tensorflow 应\\n\\n用技巧，如 tf.data 的使用，如何自定义数据生成器，如何自定义 Callbacks，多种\\n\\nCallbacks 用法，多任务模型的定义和训练。\\n\\n本章模型训练所需时间较长，如果情况允许的情况下，建议大家使用 GPU 来训练模型，\\n\\n提高效率。如果使用 CPU 训练本章模型，每个模型大约需要 2 天时间。\\n\\n13.1 多任务学习介绍\\n\\n多任务学习（Multi-task Learning）是深度学习中很常用的一种模型训练策略，意思\\n\\n其实也很简单，就是同时训练多个任务，给大家举两个例子大家就明白了。比如目标检测项\\n\\n目中，我们既要知道目标所在的位置（也就是预测框坐标值），也要知道预测框内是什么物\\n\\n体。预测框的坐标值是连续型数据，所以是一个回归任务；预测框的物体是一个具体的类\\n\\n别，所以是一个分类任务。如图 13.1 所示。\\n\\n图 13.1 目标检测任务',\n",
       " '别，所以是一个分类任务。如图 13.1 所示。\\n\\n图 13.1 目标检测任务\\n\\n图中的 task1 和 task2 可以共享卷积层。task1 就是目标检测的回归任务，用来预测目标\\n\\n框的位置，我们只要知道目标框左上角的(x1,y1)坐标和右下角的(x2,y2)坐标就可以把目标框\\n\\n435\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n给画出来，所以 task1 中需要 4 个神经元来预测 4 个回归值。task2 的作用是判断目标框内\\n\\n是什么物体，假设我们这个目标检测任务一共有 5 个分类，那么就需要 5 个神经元来预测 5\\n\\n个分类结果。\\n\\n再给大家举一个例子，比如我们在做人脸识别的时候，我们不仅可以识别人脸所在的位\\n\\n置，还可以识别人的年龄，表情，性别等特征。使用多任务学习的方式，我们可以让模型同\\n\\n时训练多个任务，模型训练好以后，输入一张图片，模型就可以输出人脸的位置，以及人的\\n\\n年龄，表情，性别，如图 13.2 所示。\\n\\n图 13.2 人脸识别任务\\n\\n如图所示，task1 任务是识别人脸所在位置，属于回归任务；task2 任务是识别人的年',\n",
       " '如图所示，task1 任务是识别人脸所在位置，属于回归任务；task2 任务是识别人的年\\n\\n龄，也是回归任务；task3 任务是识别人的表情，人的表情可以人为的标注几个类别，属于\\n\\n分类任务；task4 任务是识别人的性别，当然也是分类任务。所以我们可以看到使用多任务\\n\\n学习模型可以同时训练多个任务，在模型预测阶段也可以同时对多个任务进行预测。\\n\\n我前面提到的多任务人脸识别的例子中，不同的任务其实也可以共享卷积层。因为卷积\\n\\n层的作用主要是特征提取，先提取图像的特征，然后再使用这些特征来预测人的年龄，表\\n\\n情，性别。用于特征提取的卷积层可以共享，不过不同的任务还需要有自己的 task layer，\\n\\n专门用于训练特定任务。\\n\\n436\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n13.2 验证码数据集生成\\n\\n验证码想必大家都很熟悉了，下面我们就来介绍一下我们本章要使用的验证码数据集。\\n\\n有一个 python 模块是专门用来生成验证码图片的，打开命令提示符输入命令：\\n\\npip install captcha\\n\\n验证码图片生成的代码如代码 13-1 所示。',\n",
       " 'pip install captcha\\n\\n验证码图片生成的代码如代码 13-1 所示。\\n\\n代码 13-1：验证码生成\\n\\n# 安装验证码生成库:pip install captcha from captcha.image import ImageCaptcha import random import string\\n\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits+string.ascii_letters\\n\\n# 随机产生验证码，长度为 4 def random_captcha_text(char_set=characters, captcha_size=4): # 验证码列表 captcha_text = [] for i in range(captcha_size): # 随机选择 c = random.choice(char_set) # 加入验证码列表 captcha_text.append(c) return captcha_text',\n",
       " '# 生成字符对应的验证码 def gen_captcha_text_and_image(): # 验证码图片宽高可以设置，默认 width=160, height=60 image = ImageCaptcha(width=160, height=60) # 获得随机生成的验证码 captcha_text = random_captcha_text() # 把验证码列表转为字符串 captcha_text = \\'\\'.join(captcha_text) # 保存验证码图片 image.write(captcha_text, \\'captcha/\\' + captcha_text + \\'.jpg\\')\\n\\n437\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n# 产生 1000 次随机验证码 # 真正的数量可能会少于 1000 # 因为重名的图片会被覆盖掉 num = 1000 for i in range(num): gen_captcha_text_and_image()\\n\\nprint(\"生成完毕\")',\n",
       " 'print(\"生成完毕\")\\n\\n程序运行后会在‘captcha’文件夹下产生差不多 1000 张验证码的图片，虽然生成验证\\n\\n码的程序运行了 1000 次，不过有可能会产生两张重名的图片，第二张图片会把第一张图片\\n\\n给覆盖掉，所以实际图片可能不到 1000 张。运行程序后得到的验证码图片如图 13.3 所示。\\n\\n图 13.3 验证码图片\\n\\n13.3 tf.data 介绍\\n\\ntf.data 是一个很好用的数据读取管道搭建的 API，具有高性能并且简洁易用的特点。我\\n\\n们可以使用 tf.data 来定义数据从哪里获取，获取以后如何对数据进行处理，处理以后还可以\\n\\n打乱数据，给数据进行分批次等，总而言之 tf.data 的作用就是用来获取并处理数据的。\\n\\n438\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\ntf.data 最常用的用法就是使用 tf.data.Dataset.from_tensor_slices 来获取数据，例如：',\n",
       " 'dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\\n\\n(x_train, y_train)是训练集数据和对应标签。\\n\\ntf.data.Dataset 支持一类特殊的操作：Transformation。一个 Dataset 通过\\n\\nTransformation 可以变成一个新的 Dataset。通常我们就是使用 Transformation 来对数据\\n\\n进行处理的。例如：\\n\\n1.使用 shuffle 来打乱数据：\\n\\ndataset_train = dataset_train.shuffle(buffer_size=1000)\\n\\n2.使用 map 进行数据处理。map 可以接收一个自定义数据处理函数，Dataset 中的数\\n\\n据会传入 map 中的函数进行处理，并返回处理后的数据作为新的 Dataset：\\n\\ndataset_train = dataset_train.map(image_function)',\n",
       " '3.使用 repeat 来重复数据。repeat 可以将数据序列重复 n 次，其实也就是重复 n 个周\\n\\n期 epoch。一般我认为就只重复 1 个周期比较好，因为模型训练的时候(model.fit)还会再设\\n\\n置模型训练周期：\\n\\ndataset_train = dataset_train.repeat(1)\\n\\n4.使用 batch 来设置数据产生的批次大小：\\n\\ndataset_train = dataset_train.batch(batch_size)\\n\\n这几个 Transformation 是用得比较多的，还有其他的一些 Transformation 这里我们就\\n\\n不一一列出了。\\n\\n定义好 Dataset 以后我们可以使用：\\n\\nx,y = next(iter(dataset_test))\\n\\n来获得一个批次的数据和标签，查看数据的情况。\\n\\n也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次数据：\\n\\nfor x,y in dataset_test: pass\\n\\n模型训练阶段可以把 Dataset 传入 model.fit 中进行训练：\\n\\n439',\n",
       " '模型训练阶段可以把 Dataset 传入 model.fit 中进行训练：\\n\\n439\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nmodel.fit(x=dataset_train)\\n\\n除非是在本书相关的实际应用中用到，否则我就不展开介绍 Tensorflow 的一些细节上的\\n\\n使用了，如果不结合实际应用很多内容感觉说不明白。更多 tf.data 的使用方法可以参考\\n\\nTensorflow 官方指南（https://tensorflow.google.cn/guide/data）。\\n\\n13.4 使用 tf.data 完成多任务学习-验证码识\\n\\n别\\n\\n13.4.1 使用 tf.data 完成多任务学习模型训练\\n\\n本小节我们将介绍使用多任务学习的方法来进行验证码识别，比如我们要识别的验证码\\n\\n有 4 个字符，我们可以给模型定义 4 个任务，每个任务负责识别 1 个字符。第一个任务识别\\n\\n第一个字符，第二个任务识别第二个字符，第三个任务识别第三个字符，第四个任务识别第\\n\\n四个字符。模型框架如图 13.4 所示。\\n\\n13.4 验证码识别模型框架\\n\\n440',\n",
       " '四个字符。模型框架如图 13.4 所示。\\n\\n13.4 验证码识别模型框架\\n\\n440\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 4 个输出表示 4 个任务，每个输出都是 62 分类是由于我们使用的验证码的字符是\\n\\n数字加上大小写英文字母所以一共 62 种字符。\\n\\n代码 13-2：tf.data-多任务学习-验证码识别（片段 1）',\n",
       " '代码 13-2：tf.data-多任务学习-验证码识别（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input from tensorflow.keras.optimizers import SGD from tensorflow.keras.models import Model from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau import string import numpy as np import os from plot_model import plot_model',\n",
       " '# 字符包含所有数字和所有小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 62 num_classes = len(characters) # 批次大小 batch_size = 64 # 周期数 epochs=100 # 训练集数据，大约 50000 张图片 # 事先用 captcha 模块生成，长度都是 4 train_dir = \"./captcha/train/\" # 测试集数据，大约 10000 张图片 # 事先用 captcha 模块生成，长度都是 4 test_dir = \"./captcha/test/\" # 图片宽度 width=160 # 图片高度 height=60\\n\\n# 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir): # 存放图片路径 photo_filenames = []\\n\\n441',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 存放图片标签 y = [] for filename in os.listdir(dataset_dir): # 获取文件完整路径 path = os.path.join(dataset_dir, filename) # 保存图片路径 photo_filenames.append(path) # 取文件名前 4 位，也就是验证码的标签 captcha_text = filename[0:4] # 定义一个空 label label = np.zeros((4, num_classes), dtype=np.uint8) # 标签转独热编码 for i, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 # characters.find(ch)得到 ch 在 characters 中的位置，可以理解为 ch 的编号 label[i, characters.find(ch)] = 1 # 保存独热编码的标签 y.append(label) #',\n",
       " '= 1 # 保存独热编码的标签 y.append(label) # 返回图片路径和标签',\n",
       " 'return np.array(photo_filenames),np.array(y)\\n\\n# 获取训练集图片路径和标签 x_train,y_train = get_filenames_and_classes(train_dir)\\n\\n# 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)',\n",
       " '# 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label): # 根据图片路径读取图片内容 image = tf.io.read_file(filenames) # 将图像解码为 jpeg 格式的 3 维数据 image = tf.image.decode_jpeg(image, channels=3) # 归一化 image = tf.cast(image, tf.float32) / 255.0 # 返回图片数据和标签 return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label): # transpose 改变数据的维度，比如原来的数据 shape 是(64,4,62) # 这里的 64 是批次大小，验证码长度为 4 有 4 个标签，62 是 62 个不同的字符\\n\\n442',\n",
       " '442\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # tf.transpose(label,[1,0,2])计算后得到的 shape 为(4,64,62) # 原来的第 1 个维度变成了第 0 维度，原来的第 0 维度变成了 1 维度，第 2 维不变 # (64,4,62)->(4,64,62) label = tf.transpose(label,[1,0,2]) # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义 4 个任务，所以这里返 回 4 个标签 # 每个标签的 shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签 return image, (label[0],label[1],label[2],label[3])',\n",
       " '# 创建 dataset 对象，传入训练集图片路径和标签 dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_train = dataset_train.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_train = dataset_train.map(image_function) # 数据重复生成 1 个周期 dataset_train = dataset_train.repeat(1) # 定义批次大小 dataset_train = dataset_train.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch',\n",
       " '# 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_train = dataset_train.map(label_function)',\n",
       " '# 创建 dataset 对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成 1 个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据',\n",
       " 'map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_test = dataset_test.map(label_function)',\n",
       " '# 生成一个批次的数据和标签\\n\\n443\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 可以用于查看数据和标签的情况 x,y = next(iter(dataset_test)) print(x.shape) print(np.array(y).shape) 结果输出为： (64, 60, 160, 3) (4, 64, 62)\\n\\n代码 13-2：tf.data-多任务学习-验证码识别（片段 2）',\n",
       " \"# 也可以使用循环迭代的方式循环一个周期的数据，每次循环获得一个批次 # for x,y in dataset_test: # pass # 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3) ) # 设置输入 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的 4 个字符看成是 4 个不同的任务 # 每个任务负责识别 1 个字符 # 任务 1 识别第 1 个字符，任务 2 识别第 2 个字符，任务 3 识别第 3 个字符，任务 4 识别第 4 个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes,\",\n",
       " \"name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)\",\n",
       " \"# 4 个任务我们可以定义 4 个 loss # loss_weights 可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样 model.compile(loss={'out0':'categorical_crossentropy', 'out1':'categorical_crossentropy', 'out2':'categorical_crossentropy', 'out3':'categorical_crossentropy'}, loss_weights={'out0':1,\\n\\n444\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 'out1':1, 'out2':1, 'out3':1}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=['acc'])\",\n",
       " \"# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1), CSVLogger('Captcha_tfdata.csv'), ModelCheckpoint('Best_Captcha_tfdata.h5', monitor='val_loss', save_best_only=Tr ue), ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\",\n",
       " '# 训练模型 # 把之前定义的 dataset_train 和 dataset_test 传入进行训练 model.fit(x=dataset_train, epochs=epochs, validation_data=dataset_test, callbacks=callbacks) 结果输出为： Train for 781 steps, validate for 156 steps Epoch 1/100 781/781 [==============================] - 96s 123ms/step - loss: 7. 1427 - out0_loss: 1.3058 - out1_loss: 2.1121 - out2_loss: 2.0675 - ou t3_loss: 1.6573 - out0_acc: 0.6824 - out1_acc: 0.4488 - out2_acc: 0.4 548 - out3_acc: 0.5494 - val_loss: 16.5515 - val_out0_loss: 9.0025 -',\n",
       " '- val_loss: 16.5515 - val_out0_loss: 9.0025 - val_out1_loss: 3.4140 - val_out2_loss: 2.1353 - val_out3_loss: 1.999 7 - val_out0_acc: 0.0323 - val_out1_acc: 0.2611 - val_out2_acc: 0.472 8 - val_out3_acc: 0.4884 …… Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999019 782991e-06. 781/781 [==============================] - 88s 113ms/step - loss: 0. 0088 - out0_loss: 0.0028 - out1_loss: 0.0020 - out2_loss: 0.0018 - ou t3_loss: 0.0021 - out0_acc: 1.0000 - out1_acc: 0.9999 - out2_acc:',\n",
       " '- out0_acc: 1.0000 - out1_acc: 0.9999 - out2_acc: 1.0 000 - out3_acc: 1.0000 - val_loss: 0.6167 - val_out0_loss: 0.2020 - v al_out1_loss: 0.1470 - val_out2_loss: 0.1508 - val_out3_loss: 0.1168',\n",
       " '445\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 446 - val_out0_acc: 0.9550 - val_out1_acc: 0.9644 - val_out2_acc: 0.9647 - val_out3_acc: 0.9708 Epoch 00023: early stopping\\n\\n模型的初始学习率为 0.01，随着模型训练学习率会逐渐降低，最后模型训练了 23 周期\\n\\n就提前停止了。我们可以看到训练集的 4 个任务准确率基本上都已经是 1 了，测试集的 4 个\\n\\n任务准确率大约为 0.96 左右，有一定的过拟合现象也是正常的。\\n\\n别看 0.96 的准确率好像挺高的，验证码识别可是要 4 个验证码都识别正确，最后的结果\\n\\n才算正确。所以真正的识别正确率大约是 4 个任务的正确率相乘约等于 0.86，结果也还可\\n\\n以，不过这么看好像就不算非常高了。\\n\\n13.4.2 使用 tf.data 完成多任务学习模型预测\\n\\n下面我们再来看一下载入训练好的模型进行准确率计算和验证码结果预测的程序，如代\\n\\n码 13-3 所示。。',\n",
       " \"码 13-3 所示。。\\n\\n代码 13-3：tf.data-多任务学习-验证码识别-模型预测（片段 1）\\n\\nimport tensorflow as tf from tensorflow.keras.models import load_model import matplotlib.pyplot as plt import os import numpy as np import string\\n\\n# 载入之前训练好的模型 model = load_model('Best_Captcha_tfdata.h5')\\n\\n# 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试集数据，大约 10000 张图片 # 事先用 captcha 模块生成，长度都是 4 test_dir = \"./captcha/test/\"',\n",
       " '# 获取所有验证码图片路径和标签 def get_filenames_and_classes(dataset_dir): # 存放图片路径 photo_filenames = [] # 存放图片标签 y = [] for filename in os.listdir(dataset_dir): # 获取文件完整路径 path = os.path.join(dataset_dir, filename) # 保存图片路径 photo_filenames.append(path) # 取文件名前 4 位，也就是验证码的标签 captcha_text = filename[0:4] # 定义一个空 label label = np.zeros((4, num_classes), dtype=np.uint8) # 标签转独热编码 for i, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 # characters.find(ch)得到 ch 在 characters 中的位置，可以理解为 ch 的编号 label[i,',\n",
       " 'ch 在 characters 中的位置，可以理解为 ch 的编号 label[i, characters.find(ch)] = 1 # 保存独热编码的标签 y.append(label) # 返回图片路径和标签 return np.array(photo_filenames),np.array(y)',\n",
       " '# 获取测试集图片路径和标签 x_test,y_test = get_filenames_and_classes(test_dir)\\n\\n# 图像处理函数 # 获得每一条数据的图片路径和标签 def image_function(filenames, label): # 根据图片路径读取图片内容 image = tf.io.read_file(filenames) # 将图像解码为 jpeg 格式的 3 维数据 image = tf.image.decode_jpeg(image, channels=3) # 归一化 image = tf.cast(image, tf.float32) / 255.0 # 返回图片数据和标签\\n\\n447',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com return image, label # 标签处理函数 # 获得每一个批次的图片数据和标签 def label_function(image, label): # transpose 改变数据的维度，比如原来的数据 shape 是(64,4,62) # 这里的 64 是批次大小，验证码长度为 4 有 4 个标签，62 是 62 个不同的字符 # tf.transpose(label,[1,0,2])计算后得到的 shape 为(4,64,62) # 原来的第 1 个维度变成了第 0 维度，原来的第 0 维度变成了 1 维度，第 2 维不变 # (64,4,62)->(4,64,62) label = tf.transpose(label,[1,0,2]) # 返回图片内容和标签，注意这里标签的返回，我们的模型会定义 4 个任务，所以这里返 回 4 个标签 # 每个标签的 shape 为(64,62)，64 是批次大小，62 是独热编码格式的标签 return image,',\n",
       " '为(64,62)，64 是批次大小，62 是独热编码格式的标签 return image, (label[0],label[1],label[2],label[3])',\n",
       " '# 创建 dataset 对象，传入测试集图片路径和标签 dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) # 打乱数据，buffer_size 定义数据缓冲器大小，随意设置一个较大的值 # reshuffle_each_iteration=True，每次迭代都会随机打乱 dataset_test = dataset_test.shuffle(buffer_size=1000,reshuffle_each_iteration=True) # map-可以自定义一个函数来处理每一条数据 dataset_test = dataset_test.map(image_function) # 数据重复生成 1 个周期 dataset_test = dataset_test.repeat(1) # 定义批次大小 dataset_test = dataset_test.batch(batch_size) # 注意这个 map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据',\n",
       " 'map 和前面的 map 有所不同，第一个 map 在 batch 之前，所以是处理每一条数 据 # 这个 map 在 batch 之后，所以是处理每一个 batch 的数据 dataset_test = dataset_test.map(label_function)',\n",
       " '# 用于统计准确率 acc_sum = 0 # 统计批次数量 n = 0 for x,y in dataset_test: # 计算批次数量 n+=1 # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1)\\n\\n448\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 获得标签数据 label = np.argmax(y, axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean() # 计算测试集准确率 print(acc_sum / n) 结果输出为： 0.8631052107614607\\n\\n代码 13-3：tf.data-多任务学习-验证码识别-模型预测（片段 2）',\n",
       " '代码 13-3：tf.data-多任务学习-验证码识别-模型预测（片段 2）\\n\\n# 把标签编号变成字符串 # 如[2,34,22,45]->\\'2ymJ\\' def labels_to_text(labels): ret = [] for l in labels: ret.append(characters[l]) return \"\".join(ret)\\n\\n# 把一个批次的标签编号都变成字符串 def decode_batch(labels): ret = [] for label in labels: ret.append(labels_to_text(label))\\n\\nreturn np.array(ret)',\n",
       " 'return np.array(ret)\\n\\n# 获得一个批次数据 x,y = next(iter(dataset_test)) # 预测结果 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1) # shape 转换 # (4,64)->(64,4) pred = pred.T # 获得标签数据 label = np.argmax(y, axis=-1) # (4,64)->(64,4) label = label.T # 根据编号获得对应验证码 pred = decode_batch(pred) # 根据编号获得对应验证码 label = decode_batch(label)\\n\\n449',\n",
       " \"449\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 获取前 3 张图片数据 for i,image in enumerate(x[:3]): # 显示图片 plt.imshow(image) # 设置标题 plt.title('real:%s\\\\npred:%s'%(label[i],pred[i])) plt.show() 结果输出为：\\n\\n我们可以看到，要把 4 个验证码都预测正确其实还是挺难的，因为我这里做的验证码识\\n\\n别是需要区分大小写的，比如第一张图片中的第 3 个字符正确标签是小 x，模型预测结果是\\n\\n450\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n大 X，这确实很容易判断错误。还有 0 小 o 大 O 等这些都比较容易混淆，所以能得到 86%\\n\\n的准确率也还算不错了。\\n\\n13.5 使用自定义数据生成器完成验证码识别\\n\\n13.5.1 使用自定义数据生成器完成模型训练\\n\\n我们之前有用过 Tensorflow.keras 自带的一个专门用来处理图片数据的生成器\",\n",
       " '我们之前有用过 Tensorflow.keras 自带的一个专门用来处理图片数据的生成器\\n\\nImageDataGenerator，它可以从电脑硬盘读取数据，然后进行数据增强处理，再生成一个\\n\\n一个批次的数据，在 model.fit 中进行模型训练。\\n\\n我们现在要做的验证码识别项目使用的数据集是一个 python 模块自动生成的，所以在\\n\\n训练模型的时候我们可以一边生成数据集一边训练模型，那么我们可以自定义一个生成器来\\n\\n完成这个数据生成的工作。本小节我们也将使用多任务学习的方式来完成验证码识别的模型\\n\\n训练，不过我们这次不是用 tf.data 来获取和处理数据，我们将通过自定义数据生成器来完成\\n\\n数据的产生和处理，如代码 13-4 所示。。\\n\\n代码 13-4：自定义数据生成器-验证码识别（片段 1）',\n",
       " 'from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model\\n\\n451',\n",
       " '451\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数 num_classes = len(characters) # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60\\n\\n# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence',\n",
       " '# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度 self.n_len = n_len # 验证码图片宽度 self.width = width # 验证码图片高度 self.height =',\n",
       " 'self.width = width # 验证码图片高度 self.height = height # 字符集长度',\n",
       " '452\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.num_classes = len(characters) # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []',\n",
       " \"# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # n_len 是多任务学习的任务数量，这里是 4 个任务，batch 批次大小，num_classes 分 类数量 y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8) # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\",\n",
       " 'for j in range(self.n_len)]) self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3]]',\n",
       " '# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 显示图片 plt.imshow(x[0])\\n\\n453\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n代码 13-4：自定义数据生成器-验证码识别（片段 2）',\n",
       " \"# 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3) ) # 设置输入 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 把验证码识别的 4 个字符看成是 4 个不同的任务 # 每个任务负责识别 1 个字符 # 任务 1 识别第 1 个字符，任务 2 识别第 2 个字符，任务 3 识别第 3 个字符，任务 4 识别第 4 个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes,\",\n",
       " \"name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) # 定义模型\",\n",
       " \"454\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com model = Model(inputs, [x0,x1,x2,x3]) # 画图 plot_model(model,style=0)\\n\\n# 4 个任务我们可以定义 4 个 loss # loss_weights 可以用来设置不同任务的权重，验证码识别的 4 个任务权重都一样 model.compile(loss={'out0':'categorical_crossentropy', 'out1':'categorical_crossentropy', 'out2':'categorical_crossentropy', 'out3':'categorical_crossentropy'}, loss_weights={'out0':1, 'out1':1, 'out2':1, 'out3':1}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=['acc'])\",\n",
       " \"# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1), CSVLogger('Captcha.csv'), ModelCheckpoint('Best_Captcha.h5', monitor='val_loss', save_best_only=True), ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)] # 训练模型 model.fit(x=CaptchaSequence(characters,\",\n",
       " '# 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_st eps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 164s 164ms/step - loss: 10.0266 - out0_loss: 2.3069 - out1_loss: 2.7054 - out2_loss: 2.6668 - out3_loss: 2.3474 - out0_acc: 0.3711 - out1_acc: 0.3144 - out2_acc: 0.3197 -',\n",
       " '0.3711 - out1_acc: 0.3144 - out2_acc: 0.3197 - out3_acc: 0.3896 - val_loss: 3.8732 - val_out0_loss: 1.1623 - val_out1_loss: 0.9057 - val_out2_loss: 0.9186 - val_out3_loss: 0.8 866 - val_out0_acc: 0.6719 - val_out1_acc: 0.7352 - val_out2_acc: 0.7 278 - val_out3_acc: 0.7531',\n",
       " '455',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com …… Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-07. 1000/1000 [==============================] - 160s 160ms/step - loss: 0.1092 - out0_loss: 0.0254 - out1_loss: 0.0295 - out2_loss: 0.0283 - out3_loss: 0.0260 - out0_acc: 0.9901 - out1_acc: 0.9880 - out2_acc: 0.9885 - out3_acc: 0.9902 - val_loss: 0.1104 - val_out0_loss: 0.0260 - val_out1_loss: 0.0304 - val_out2_loss: 0.0273 - val_out3_loss: 0.02 67 - val_out0_acc: 0.9902 -',\n",
       " '- val_out3_loss: 0.02 67 - val_out0_acc: 0.9902 - val_out1_acc: 0.9877 - val_out2_acc: 0.99 00 - val_out3_acc: 0.9881 Epoch 00050: early stopping',\n",
       " '由于使用自定义数据生成器可以生产出无数张图片，所以相当于模型的训练数据比之前\\n\\n用 tf.data 从硬盘中读取数据要多了很多。最终我们也可以看到更多的训练数据得到的结果也\\n\\n会更好。\\n\\n13.5.2 使用自定义数据生成器完成模型预测\\n\\n下面我们来看一下关于模型预测部分的程序，如代码 13-5 所示。\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 1）',\n",
       " \"代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 批次大小 batch_size = 64 # 载入训练好的模型 model = load_model('Best_Captcha.h5')\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的，\\n\\n456\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=4, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度 self.n_len = n_len # 验证码图片宽度 self.width = width # 验证码图片高度 self.height =',\n",
       " 'self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = len(characters) # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []',\n",
       " \"# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # n_len 是多任务学习的任务数量，这里是 4 个任务，batch 批次大小，num_classes 分 类数量 y = np.zeros((self.n_len, self.batch_size, self.num_classes), dtype=np.uint8) # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)])\",\n",
       " 'for j in range(self.n_len)]) self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符)',\n",
       " '457\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3]]\\n\\n# 返回批次数量 def __len__(self): return self.steps',\n",
       " \"# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试模型，随机生成验证码 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred,axis=-1)[:,0] # 根据编号获得对应验证码 pred = ''.join([characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred)) plt.show() 结果输出为：\\n\\n458\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\",\n",
       " '458\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 2）',\n",
       " \"代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 2）\\n\\n# 自定义验证码生成和预测 # 生成自定义验证码 captcha_text = '0oO0' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成 4 维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred,axis=-1)[:,0] # 根据编号获得对应验证码 pred = ''.join([characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(captcha_text,pred)) plt.show() 结果输出为：\",\n",
       " '代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 3）\\n\\n459\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 计算准确率，区分大小写 def accuracy(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred, axis=-1) # 获得标签数据 label = np.argmax(y, axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean() # 返回平均准确率 return acc_sum / test_steps # 计算准确率，区分大小写 print(accuracy()) 结果输出为： 0.956875',\n",
       " \"代码 13-5：自定义数据生成器-验证码识别-模型预测（片段 4）\\n\\n# 计算准确率，忽略大小写 def accuracy2(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred,axis=-1).T # 保存预测值 pred_list = [] # 把验证码预测值转小写后保存 for c in pred: # 根据编号获得对应验证码 temp_c = ''.join([characters[x] for x in c]) # 字母都转小写后保存 pred_list.append(temp_c.lower()) # 获得标签数据 label = np.argmax(y, axis=-1).T # 保存标签 label_list = []\\n\\n460\",\n",
       " \"460\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # # 把验证码标签值转小写后保存 for c in label: # 根据编号获得对应验证码 temp_c = ''.join([characters[x] for x in c]) # 字母都转小写后保存 label_list.append(temp_c.lower()) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (np.array(pred_list) == np.array(label_list)).mean() # 返回平均准确率 return acc_sum / test_steps # 计算准确率，忽略大小写 print(accuracy2()) 结果输出为： 0.98546875\\n\\n我们从测试结果可以看到使用自定义数据生成器产生更多的训练数据以后，模型的准确\\n\\n率提高到了 95.69%（区分大小写）非常高的准确率，如果不区分大小写准确率可以进一步\\n\\n提高到 98.55%。\\n\\n在自定义验证码程序段中，我生成了一个“0oO0”验证码，就问大家能不能分辨出哪个\",\n",
       " '在自定义验证码程序段中，我生成了一个“0oO0”验证码，就问大家能不能分辨出哪个\\n\\n是 0，哪个是 o，哪个是 O，反正我肯定是分不出来，但是这个模型还能识别正确（当然这\\n\\n个难度还是很大的，不能保证它每一次都能识别正确）。我觉得我们训练的这个模型在这种\\n\\n类型的验证码识别准确率上应该是超过了人类。\\n\\n13.6 挑战变长验证码识别\\n\\n13.6.1 挑战变长验证码识别模型训练\\n\\n前面我们生成的验证码是固定 4 位长度的，下面我们将增加难度，挑战不固定长度的验\\n\\n证码识别，验证码长度我设置为 3-6 位的随机 4 种长度。程序大体框架跟“代码 13-4：自\\n\\n461\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n定义数据生成器-验证码识别”差不多，主要是自定义数据生成器的部分做了一些修改，让数\\n\\n据生成器会产生随机长度的验证码。\\n\\n不过为了保证标签对齐，所以我们还是需要固定标签的数量和多任务学习任务的数量。\\n\\n因为验证码最长是 6，所以我们把标签的长度和多任务学习任务数量固定为 6，标签不足长',\n",
       " '因为验证码最长是 6，所以我们把标签的长度和多任务学习任务数量固定为 6，标签不足长\\n\\n度 6 的情况我们会把标签填充到 6。模型的类别数会增加一个空白类别，用于填充。\\n\\n另外我还给模型增加了一个新的任务，用于预测验证码的长度，这个任务其实可有可\\n\\n无，不过用作演示还是加上给大家看看效果，模型结构如图 13.5 所示。\\n\\n图 13.5 变长验证码识别\\n\\n图中有一共有 7 个输出，其中 6 个输出表示验证码识别的 6 个任务，每个任务有 63 个\\n\\n类别（62 个字符加一个空白符）。还有一个输出表示验证码的长度，有 4 个类别，分别表示\\n\\n3，4，5，6，一共 4 种验证码的长度。\\n\\n462\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n挑战变长验证码识别的代码如代码 13-6 所示。\\n\\n代码 13-6：挑战变长验证码识别（片段 1）',\n",
       " 'from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,GlobalAvgPool2D from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共 62 个',\n",
       " 'import plot_model # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数 # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # 最长验证码 max_len = 6',\n",
       " '# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence\\n\\n# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。\\n\\n463',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片',\n",
       " '字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []',\n",
       " '# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # 6 个验证码识别任务，batch 批次大小，num_classes 分类数量 y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32) # 数据清 0 self.captcha_list = [] # 初始化数据用于保存判断验证码长度的标签，一共 4 种情况 len_captcha = np.zeros((self.batch_size, 4), dtype=np.int) # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 设置标签，独热编码',\n",
       " \"self.n_len = np.random.randint(3,7) # 设置标签，独热编码 one-hot 格式，一共 4 种情况 len_captcha[i, self.n_len-3] = 1 # 转字符串 captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码\",\n",
       " '464',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 如果验证码长度不是 6，则需要设置空白字符的标签为 1 # 空白字符在-1 位置 for k in range(len(captcha_text),max_len): # 空白字符 y[k, i, -1] = 1 # 返回一个批次的数据和标签 return x,',\n",
       " '# 空白字符 y[k, i, -1] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]',\n",
       " \"# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 x, y = data[0] # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n465\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-6：挑战变长验证码识别（片段 2）\\n\\n# 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3) )\",\n",
       " \"# 设置输入图片 inputs = Input((height,width,3)) # 使用 resnet50 进行特征提取 x = resnet50(inputs) # 平均池化 x = GlobalAvgPool2D()(x) # 每个任务负责识别 1 个字符 x0 = Dense(num_classes, activation='softmax', name='out0')(x) x1 = Dense(num_classes, activation='softmax', name='out1')(x) x2 = Dense(num_classes, activation='softmax', name='out2')(x) x3 = Dense(num_classes, activation='softmax', name='out3')(x) x4 = Dense(num_classes, activation='softmax', name='out4')(x) x5 = Dense(num_classes, activation='softmax',\",\n",
       " \"x5 = Dense(num_classes, activation='softmax', name='out5')(x) # 预测验证码长度 3-6，4 种情况所以定义 4 个分类 num_x = Dense(4, activation='softmax', name='out_num')(x) # 定义模型 model = Model(inputs, [x0,x1,x2,x3,x4,x5,num_x]) # 画图 plot_model(model,style=0,dpi=200)\",\n",
       " \"# loss_weights 可以用来设置不同任务的权重，验证码识别的 6 个任务权重都一样 # 相对而言 out_num 更重要一些，因为如果验证码的长度判断错误，那么识别结果一定是错 的 # 所以可以给 out_num 更大一点的权重 model.compile(loss={'out0':'categorical_crossentropy', 'out1':'categorical_crossentropy', 'out2':'categorical_crossentropy',\\n\\n466\",\n",
       " \"466\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 'out3':'categorical_crossentropy', 'out4':'categorical_crossentropy', 'out5':'categorical_crossentropy', 'out_num':'categorical_crossentropy'}, loss_weights={'out0':1, 'out1':1, 'out2':1, 'out3':1, 'out4':1, 'out5':1, 'out_num':2}, optimizer=SGD(lr=1e-2,momentum=0.9), metrics=['acc'])\",\n",
       " \"# 监控指标统一使用 val_loss # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_loss 没有下降就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_loss 最低的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_loss 没有下降当前学习率乘以 0.1 callbacks = [EarlyStopping(monitor='val_loss', patience=6, verbose=1), CSVLogger('Captcha2.csv'), ModelCheckpoint('Best_Captcha2.h5', monitor='val_loss', save_best_only=True), ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\",\n",
       " '# 训练模型 model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test_ steps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 1000/1000 [==============================] - 184s 184ms/step - loss: 14.0520 - out0_loss: 2.2189 - out1_loss: 2.6810 - out2_loss: 2.9503 - out3_loss: 2.5608 - out4_loss: 1.8766 - out5_loss: 1.0524 - out_num _loss: 0.3560 -',\n",
       " '- out5_loss: 1.0524 - out_num _loss: 0.3560 - out0_acc: 0.4063 - out1_acc: 0.3020 - out2_acc: 0.244 7 - out3_acc: 0.3636 - out4_acc: 0.5493 - out5_acc: 0.7673 - out_num_ acc: 0.8614 - val_loss: 13.9098 - val_out0_loss: 2.5258 - val_out1_lo ss: 1.9578 - val_out2_loss: 2.3671 - val_out3_loss: 2.5046 - val_out4 _loss: 1.6575 - val_out5_loss: 0.9196 - val_out_num_loss: 0.9887 - va l_out0_acc: 0.4391 - val_out1_acc: 0.5095 - val_out2_acc: 0.4242 - va',\n",
       " '467',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 468 l_out3_acc: 0.4322 - val_out4_acc: 0.6039 - val_out5_acc: 0.7880 - va l_out_num_acc: 0.8316 …… Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-08. 1000/1000 [==============================] - 178s 178ms/step - loss: 0.2524 - out0_loss: 0.0436 - out1_loss: 0.0534 - out2_loss: 0.0558 - out3_loss: 0.0457 - out4_loss: 0.0341 - out5_loss: 0.0173 - out_num_ loss: 0.0013 - out0_acc: 0.9825 - out1_acc: 0.9796 - out2_acc: 0.9800 -',\n",
       " '0.9825 - out1_acc: 0.9796 - out2_acc: 0.9800 - out3_acc: 0.9823 - out4_acc: 0.9870 - out5_acc: 0.9930 - out_num_a cc: 0.9997 - val_loss: 0.2374 - val_out0_loss: 0.0452 - val_out1_los s: 0.0515 - val_out2_loss: 0.0498 - val_out3_loss: 0.0404 - val_out4_ loss: 0.0307 - val_out5_loss: 0.0174 - val_out_num_loss: 0.0012 - val _out0_acc: 0.9823 - val_out1_acc: 0.9786 - val_out2_acc: 0.9792 - val _out3_acc: 0.9841 - val_out4_acc: 0.9886 - val_out5_acc: 0.9931 - val _out_num_acc: 0.9997 Epoch 00036:',\n",
       " '0.9931 - val _out_num_acc: 0.9997 Epoch 00036: early stopping',\n",
       " '从模型最后的结果看来预测验证码长度的任务准确率几乎达到了 1，也就是说模型预测验\\n\\n证码的长度是非常准了。6 个验证码预测任务中准确率最高的是 out5，也就是最后 1 位验证\\n\\n码的预测。out5 准确率明显高于其他任务是因为验证码的长度是 3-6，也就是说只要验证码\\n\\n的长度判断正确，那么有 75%的可能性最后 1 位验证码它就是空白符，所以准确率比较高。\\n\\n相对而言 out0-out2 的准确率就会偏低一些了，因为不可能会有空白符。\\n\\n13.6.2 挑战变长验证码识别模型预测\\n\\n实现变长验证码识别-模型预测的代码如代码 13-7 所示。\\n\\n代码 13-7：变长验证码识别-模型预测（片段 1）',\n",
       " '代码 13-7：变长验证码识别-模型预测（片段 1）\\n\\nfrom tensorflow.keras.models import load_model # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence from captcha.image import ImageCaptcha import numpy as np import string import matplotlib.pyplot as plt import random',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入训练好的模型 model = load_model('Best_Captcha2.h5') # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 预测阶段使用的字符多一个空白符在最后 pred_characters = characters + ' ' # 类别数，包含一个空白符类别 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 最长验证码 max_len = 6\\n\\n# 用于自定义数据生成器 from tensorflow.keras.utils import Sequence\",\n",
       " '# 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, width=160, height=60): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width #',\n",
       " '# 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []',\n",
       " '# 获得 index 位置的批次数据\\n\\n469',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 # 6 个验证码识别任务，batch 批次大小，num_classes 分类数量 y = np.zeros((max_len, self.batch_size, self.num_classes), dtype=np.float32) # 数据清 0 self.captcha_list = [] # 初始化数据用于保存判断验证码长度的标签，一共 4 种情况 len_captcha = np.zeros((self.batch_size, 4), dtype=np.int) # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len =',\n",
       " \"in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 设置标签，独热编码 one-hot 格式，一共 4 种情况 len_captcha[i, self.n_len-3] = 1 # 转字符串 captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码 self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 # j(0-3),i(0-61),ch(单个字符) # self.characters.find(ch)得到 c 在 characters 中的位置，可以理解为 c 的编号 for j, ch in enumerate(captcha_text): # 设置标签，独热编码\",\n",
       " 'for j, ch in enumerate(captcha_text): # 设置标签，独热编码 one-hot 格式 y[j, i, self.characters.find(ch)] = 1 # 如果验证码长度不是 6，则需要设置空白字符的标签为 1 # 空白字符在-1 位置 for k in range(len(captcha_text),max_len): # 空白字符 y[k, i, -1] = 1 # 返回一个批次的数据和标签 return x, [y[0],y[1],y[2],y[3],y[4],y[5],len_captcha]',\n",
       " '# 返回批次数量 def __len__(self): return self.steps\\n\\n# 测试模型 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据\\n\\n470',\n",
       " \"470\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com x, y = data[0] # 预测结果 pred = model.predict(x) # 0 表示长度 3，1 表示长度 4，2 表示长度 5，3 表示长度 6 captcha_len = np.argmax(pred[6],axis=-1)[0]+3 # 打印验证码长度 print('验证码长度：',captcha_len) # 获得对应编号 captcha = np.argmax(pred[:6],axis=-1)[:,0] # 根据编号获得对应验证码 # 注意这里需要使用 pred_characters，包含空白符 pred = ''.join([pred_characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(data.captcha_list[0],pred)) plt.show() 结果输出为： 验证码长度： 6\\n\\n验证码长度： 5\",\n",
       " '验证码长度： 5\\n\\n代码 13-7：变长验证码识别-模型预测（片段 2）\\n\\n# 自定义验证码生成和预测 # 生成自定义验证码\\n\\n471',\n",
       " \"471\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com captcha_text = 'oOxXvV' image = ImageCaptcha(width=160, height=60) # 数据归一化 x = np.array(image.generate_image(captcha_text)) / 255.0 # 给数据增加一个维度变成 4 维 x = np.expand_dims(x, axis=0) # 预测结果 pred = model.predict(x) # 获得对应编号 captcha = np.argmax(pred[:6],axis=-1)[:,0] # 根据编号获得对应验证码 pred = ''.join([pred_characters[x] for x in captcha]) # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title('real:%s\\\\npred:%s'%(captcha_text,pred)) plt.show() 结果输出为：\",\n",
       " '代码 13-7：变长验证码识别-模型预测（片段 3）\\n\\n# 计算准确率，区分大小写 def accuracy(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred[:6], axis=-1) # 获得标签数据 label = np.argmax(y[:6], axis=-1) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (pred == label).all(axis=0).mean()\\n\\n472\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 返回平均准确率 return acc_sum / test_steps # 打印区分大小写准确率 print(accuracy()) 结果输出为： 0.913125',\n",
       " '代码 13-7：变长验证码识别-模型预测（片段 4）',\n",
       " \"# 计算准确率，忽略大小写 def accuracy2(test_steps=100): # 用于统计准确率 acc_sum = 0 for x,y in CaptchaSequence(characters, batch_size=batch_size, steps=test_steps): # 进行一个批次的预测 pred = model.predict(x) # 获得对应编号 pred = np.argmax(pred[:6],axis=-1).T # 保存预测值 pred_list = [] # 把验证码预测值转小写后保存 for c in pred: # 根据编号获得对应验证码 temp_c = ''.join([pred_characters[x] for x in c]) # 字母都转小写后保存 pred_list.append(temp_c.lower()) # 获得标签数据 label = np.argmax(y[:6], axis=-1).T # 保存标签 label_list = [] # # 把验证码标签值转小写后保存 for c in label: #\",\n",
       " \"= [] # # 把验证码标签值转小写后保存 for c in label: # 根据编号获得对应验证码 temp_c = ''.join([pred_characters[x] for x in c]) # 字母都转小写后保存 label_list.append(temp_c.lower()) # 计算这个批次的准确率然后累加到总的准确率统计中 acc_sum += (np.array(pred_list) == np.array(label_list)).mean() # 返回平均准确率 return acc_sum / test_steps # 打印忽略大小写准确率 print(accuracy2()) 结果输出为：\",\n",
       " '473\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 0.963125\\n\\n程序运行结果我们可以看到，这个模型可以自动判断验证码的长度，并做出正确识别。\\n\\n就连“oOxXvV”这种几乎不可能识别正确的验证码图片它也能识别正确。不过由于变长验\\n\\n证码难度更大，并且验证码的位数有可能比原来的 4 位更多，所以验证码的综合准确率相比\\n\\n之前有所下降。\\n\\n13.7 CTC 算法\\n\\n13.7.1 CTC 算法介绍\\n\\nCTC(Connectionist Temporal Classification)是用来解决输入序列和输出序列难以一\\n\\n一对应的问题，主要用于语音识别和 OCR(Optical Character Recognition)领域。语音识\\n\\n别如图 13.6 所示。\\n\\n图 13.6 语音识别\\n\\n比如在语音识别任务中，我们需要将一大段语音跟一段文本对应。最容易想到的方式就\\n\\n是把一大段语音切分为语音片段，然后每个语音片段对应一个字或一个词。但是每个人说话\\n\\n474\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '474\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的语速不同，这个切分的规则很难定义。如果每一段语音都通过人为手动切分，虽然方法可\\n\\n行，但是工作量非常大。\\n\\n同样的在 OCR 领域也会遇到同样的对齐困难，如图 13.7 所示。\\n\\n图 13.7 数据对齐困难\\n\\nCTC 就是用来解决输入数据和输出数据的对齐问题，我们可以通过下面的例子来理解。\\n\\n不管是语音识别或是 OCR 还是其他类似任务，假设我们先以一定的方法（比如卷积）对输\\n\\n入数据进行特征提取，然后得到 6 个数据特征，如图 13.8 中的𝑥\"-𝑥(cid:226)。\\n\\n图 13.8 数据对齐\\n\\n6 个特征𝑥\"-𝑥(cid:226)分别预测出对应的 6 个字符，然后我们可以将相邻并重复的字符删除，得\\n\\n到最后的结果。这个对齐方式有两个问题，第一个问题是在语音识别，有些音频片段可能是\\n\\n无声的，这个时候应该是没有字符输出的。第二个问题是有些单词本身就存在重复单词，比\\n\\n如“hello”，如果去重的话就会变成“helo”。',\n",
       " '如“hello”，如果去重的话就会变成“helo”。\\n\\n为了解决这两个问题，CTC 引入了一个空白占位符，用来表示空白输出，这里我们用𝜖来\\n\\n表示，加入空白符以后输入和输出就可以合理的对应上了，如图 13.9 所示。\\n\\n475\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 13.9 引入空白符\\n\\n在这个对齐方式中，如果标签文本存在重复字符，对齐过程中会在两个重复字符当中插\\n\\n入空白符隔开，这样“hello”就不会变成“helo”了。\\n\\n假设标签文本为“cat”，图 13.10 中左边的部分都是正确的结果，右边的部分都是错误\\n\\n的结果。\\n\\n图 13.10 正确对齐和错误对齐\\n\\n476\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n13.7.2 贪心算法（ Greedy Search）和集束 搜索算法（ Beam\\n\\nSearch）\\n\\n下面我们进一步考虑更多的细节，比如我们把一段“hello”的语音进行特征提取，然后\\n\\n再把提取后的特征传入 RNN 网络中，每传入 1 个特征 RNN 网络就会输出一组结果，如图',\n",
       " '再把提取后的特征传入 RNN 网络中，每传入 1 个特征 RNN 网络就会输出一组结果，如图\\n\\n13.11。\\n\\n图 13.11 CTC 算法\\n\\n图中 RNN 的每次输出都有 5 种可能的结果，这 5 种可能的结果有不同的概率值（图中\\n\\n不同的背景颜色深度表示不同的概率值，颜色越深表示概率越大）。对于一组输入输出(X,Y)\\n\\n来说，CTC 的目标是最大化条件概率，公式为 13.1。\\n\\n𝑇\\n\\n𝑝(𝑌|𝑋) = ? ª 𝑝𝑡(𝑎𝑡|𝑋) 𝐴∈𝐴𝑋,𝑌\\n\\n𝑡=1\\n\\n477\\n\\n(13.1)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n𝑝ˆ(𝑎ˆ|𝑋)表示 RNN 每个时间序列的输出概率分布，t 表示 RNN 里第 t 个序列，\\n\\n~ ˆA\"\\n\\n∏ 𝑝ˆ(𝑎ˆ|𝑋)\\n\\n表示一条路径所有字符概率相乘，∑\\n\\n(cid:231)∈(cid:231)Ł,Ø\\n\\n~ ˆA\"\\n\\n∏ 𝑝ˆ(𝑎ˆ|𝑋)\\n\\n表示多条路径概率相\\n\\n加。\\n\\n其实有多条路径可以得到“hello”的结果，比如序列长度为 10，“heeϵlϵloϵϵ”,',\n",
       " '其实有多条路径可以得到“hello”的结果，比如序列长度为 10，“heeϵlϵloϵϵ”,\\n\\n“hϵϵeeϵlϵlo”, “ϵϵhheϵlϵlo”, “hϵeeϵlϵloϵ”等结果其实都是表示“hello”。所以\\n\\n“hello”的概率应该是所有有效的“hello”路径概率的总和。\\n\\nP(“hello”)=P(“heeϵlϵloϵϵ”)+P(“hϵϵeeϵlϵlo”)+P(“ϵϵhheϵlϵlo”)+P(“hϵeeϵlϵl\\n\\noϵ”)+……\\n\\n可以想象对于一个输出，可以得到这个输出的路径肯定是非常多的。在实际应用中我们\\n\\n不会将所有路径的概率都计算出来，主要是计算量太大了，所以我们需要采用动态规划的思\\n\\n想来计算。CTC 主要采用两种动态规划的算法，贪心算法（Greedy Search）和集束搜索算\\n\\n法（Beam Search）。\\n\\n下面我们举两个简单的例子来说明，贪心算法就是在序列输出的每一个阶段都选取概率\\n\\n最大的一个输出值，比如我们有一个序列有 3 种输出“a”，“b”，“-”。“-”表示空白\\n\\n符，贪心算法输出的结果如下图 13.12 所示。',\n",
       " '符，贪心算法输出的结果如下图 13.12 所示。\\n\\n图 13.12 贪心算法（Greedy Search）\\n\\n478\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nt0 阶段概率最大的是“-”为 0.8，t1 阶段概率最大的是“-”为 0.6，所以贪心算法的输\\n\\n出结果为“--”，概率为 0.8×0.6=0.48。一般来说贪心算法计算量小，效果也不错。但有时\\n\\n候贪心算法得到的结果不一定是最好的。如图 13.13 所示。\\n\\n图 13.13 贪心算法失效\\n\\n比如我们计算一下“a”的输出概率：\\n\\nP(“a”）=P(“aa”)+P(“a-”)+P(“-a”)= 0.2×0.4+0.2×0.6+0.8×\\n\\n0.4=0.52>0.48。所以贪心算法得到的结果不一定是最好的，我们可以使用 beam search。\\n\\nbeam search 跟贪心算法不同的地方在于 beam search 会计算当前最好的 N 个结果，\\n\\nN 可以人为设定。还是使用上面的例子，当 N 等于 2 时，可以得到图 13.14 所示。\\n\\n图 13.14 beam search\\n\\n479',\n",
       " '图 13.14 beam search\\n\\n479\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n我们来分析一下，t0 时“a”的概率为 0.2，空白符“-”的概率为 0.8，所以 t0 我们选\\n\\n出最好的两个结果就是“a”和“-”。t1 时我们得到的组合有“aa”，“ab”，“a”，\\n\\n“b”，“”，我们一个一个来分析。\\n\\nt1 时输出“aa”是不可能的，因为如果真的要输出“aa”，必须至少要有一个空白符在\\n\\n两个“a”中间，如“a-a”->“aa”。\\n\\nt1 时输出“ab”也不可能，因为 t1 时“b”的概率为 0。\\n\\nt1 时输出“b”也不可能，因为 t1 时“b”的概率为 0。\\n\\nt1 时输出“a”可以。t0 输出“a”，t1 输出“a”或“-”，最后的结果都是“a”；t0\\n\\n输出“-”，t1 输出“a”，也可以得到“a”。总概率前面我们计算过为 0.52。\\n\\nt1 时输出空白“”可以。t0 输出“-”，t1 也输出“-”，最后得到“”。概率为 0.48。\\n\\n如果有更长的序列，我们将沿着这个结果继续往下分析，并且每个序列只保存概率最大',\n",
       " '如果有更长的序列，我们将沿着这个结果继续往下分析，并且每个序列只保存概率最大\\n\\n的两个输出。\\n\\n13.7.3 CTC 存在的问题\\n\\n最后总结一下 CTC 的几个问题：\\n\\n1.条件独立性。CTC 做了一个假设就是不同时间序列的输出之间是独立的。这个假设对\\n\\n于很多序列问题来说并不成立，输出序列之间往往存在联系。\\n\\n2.单调对齐。CTC 只允许单调对齐，这在语音识别，OCR 等领域中可能是有效的。但是\\n\\n在机器翻译中，比如有些中文句子后面的词可能对应于英文句子中前面的词，这个 CTC 无法\\n\\n做到。\\n\\n480\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n3.多对一映射。CTC 的输入和输出是多对一的关系。这意味着输出长度不能超过输入长\\n\\n度，这在语音识别，OCR 等领域问题不大，但是对于某些输出长度大于输入长度的应用 CTC\\n\\n就无法处理了。\\n\\n13.8 CTC 算法-验证码识别\\n\\n13.8.1 使用 CTC 算法训练验证码模型\\n\\n下面我们要学习的 CTC 算法-验证码识别程序要注意的点挺多的，我在程序注释中都已经',\n",
       " '下面我们要学习的 CTC 算法-验证码识别程序要注意的点挺多的，我在程序注释中都已经\\n\\n详细的写清楚了。这里再稍微提一下，由于 Tensorflow.keras 中没有实现 CTC 算法的相关\\n\\n功能，所以 CTC 算法相关计算需要调用 Tensorflow 中的程序实现，如代码 13-8 所示。\\n\\n代码 13-8：CTC 算法-验证码识别（片段 1）',\n",
       " 'from tensorflow.keras.optimizers import SGD from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model,Sequential from tensorflow.keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint,Reduc eLROnPlateau from tensorflow.keras import backend as K from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import random import string',\n",
       " 'import numpy as np import random import string from plot_model import plot_model # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 批次大小 batch_size = 64 # 训练集批次数',\n",
       " '481',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 训练集大小相当于是 64*1000=64000 train_steps = 1000 # 测试集批次数 # 测试集大小相当于是 64*100=6400 test_steps = 100 # 周期数 epochs=100 # 图片宽度 width=160 # 图片高度 height=60 # RNN 的 cell 数量 RNN_cell = 128 # 最长验证码 max_len = 6 # 用于自定义数据生成器 from tensorflow.keras.utils import Sequence # 这里的 Sequence 定义其实不算典型，因为一般的数据集数量是有限的， # 把所有数据训练一次属于训练一个周期，一个周期可以分为 n 个批次， # Sequence 一般是定义一个训练周期内每个批次的数据如何产生。 # 我们这里的验证码数据集使用 captcha 模块生产出来的，一边生产一边训练，可以认为数 据集是无限的。 class CaptchaSequence(Sequence): #',\n",
       " '据集是无限的。 class CaptchaSequence(Sequence): # __getitem__和__len__是必须定义的两个方法 def __init__(self, characters, batch_size, steps, n_len=max_len, width=160, height=60, input_len=10, label_len=max_len): # 字符集 self.characters = characters # 批次大小 self.batch_size = batch_size # 生成器生成多少个批次的数据 self.steps = steps # 验证码长度随机，3-6 位 self.n_len = np.random.randint(3,7) # 验证码图片宽度 self.width = width # 验证码图片高度 self.height = height # 输入长度 10，注意这里输入长度指的是 RNN 模型输出的序列长度，具体要看下面模 型搭建部分 # RNN 模型输出序列长度为 10 表示模型最多可以输入 10',\n",
       " '型搭建部分 # RNN 模型输出序列长度为 10 表示模型最多可以输入 10 个字符(包含空白符在内) self.input_len = input_len # 标签长度 self.label_len = label_len',\n",
       " '482\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 字符集长度 self.num_classes = num_classes # 用于产生验证码图片 self.image = ImageCaptcha(width=self.width, height=self.height) # 用于保存最近一个批次验证码字符 self.captcha_list = []',\n",
       " '# 获得 index 位置的批次数据 def __getitem__(self, index): # 初始化数据用于保存验证码图片 x = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32) # 初始化数据用于保存标签 y = np.zeros((self.batch_size, self.label_len), dtype=np.int8) # 输入长度 input_len = np.ones(self.batch_size)*self.input_len # 标签长度 label_len = np.ones(self.batch_size)*self.label_len # 数据清 0 self.captcha_list = [] # 生产一个批次数据 for i in range(self.batch_size): # 随机产生验证码 self.n_len = np.random.randint(3,7) # 转字符串 captcha_text =',\n",
       " \"= np.random.randint(3,7) # 转字符串 captcha_text = ''.join([random.choice(self.characters) for j in range(self.n_len)]) # 保存验证码 self.captcha_list.append(captcha_text) # 生产验证码图片数据并进行归一化处理 x[i] = np.array(self.image.generate_image(captcha_text)) / 255.0 for j, ch in enumerate(captcha_text): # 设置标签，这里不需要独热编码 y[i, j] = self.characters.find(ch) # 如果验证码长度不是 6，则需要设置空白字符 for k in range(len(captcha_text),self.label_len): # 空白字符编号为 num_classes-1 y[i, k] = num_classes-1 # 返回一个批次的数据和标签 # 注意这里的标签\",\n",
       " 'y[i, k] = num_classes-1 # 返回一个批次的数据和标签 # 注意这里的标签 np.ones(self.batch_size)是没有意义的，只是由于返回的数据必须要 有标签 return [x, y, input_len, label_len], np.ones(self.batch_size)',\n",
       " '# 返回批次数量 def __len__(self): return self.steps\\n\\n483\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 测试生成器 # 一共一个批次，批次大小也是 1 data = CaptchaSequence(characters, batch_size=1, steps=1) for i in range(2): # 产生一个批次的数据 [x, y, _, _], _ = data[0] # 显示图片 plt.imshow(x[0]) # 验证码字符和对应编号 plt.title(data.captcha_list[0]) plt.show() 结果输出为：\\n\\n代码 13-8：CTC 算法-验证码识别（片段 2）',\n",
       " '代码 13-8：CTC 算法-验证码识别（片段 2）\\n\\n# Keras 调用 Tensorflow 中的 ctc_batch_cost # x 是模型输出，shape-(?,10,63) # labels 是验证码的标签，shape-(?,max_len) # input_len 是 x 的长度，shape-(?,1)，x 的长度为 10 # label_len 是 labels 的的长度，shape-(?,1)，labels 的长度为 max_len def ctc_lambda_func(args): x, labels, input_len, label_len = args # Tensorflow 中封装的 ctc 计算\\n\\nreturn K.ctc_batch_cost(labels, x, input_len, label_len)\\n\\n484',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 载入预训练的 resnet50 模型，不包含全连接层 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3) ) # 设置输入 image_input = Input((height,width,3), name='image_input') # 使用 resnet50 进行特征提取 x = resnet50(image_input) # resnet50 计算后得到的数据 shape 为(?,2,5,2048) # 10 个输入最多对应 10 个输出，验证码最长为 6，理论上只要不出现 6 个字符都相同的极 端情况，长度是够用的。 # 比如极端情况'aaaaaa'，'-'表示空白符，模型输出'a-a-a-a-a-a'至少需要 11 的长度。 # 不过长度不够可能会影响对连续重复字符的判断效果，比如'aaaa'可能会被识别为'aaa' #\",\n",
       " \"# 不过长度不够可能会影响对连续重复字符的判断效果，比如'aaaa'可能会被识别为'aaa' # 如果要增加输入长度，可以通过增大输入图片的大小或修改网络结构的方式实现 # 这里 Reshape 的作用是将卷积输出的 4 维数据转化为 RNN 输入所要求的 3 维数据， 2*5=10 表示序列长度 x = Reshape((10,2048))(x) # Bidirectional 为双向 RNN，可以把 RNN/LSTM/GRU 传入 Bidirectional 中 # GRU 中的 return_sequences=True 表示返回所有序列的结果 # 比如在本程序中 return_sequences=True 返回的结果 shape 为(?,10,256) # GRU 中的 return_sequences=False 表示只返回序列 last output 的结果 # 比如在本程序中 return_sequences=False 返回的结果 shape 为(?,256) x = Bidirectional(GRU(RNN_cell,\",\n",
       " \"shape 为(?,256) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name='max_len') # 输入长度 input_len = Input(shape=(1), name='input_len') # 标签长度 label_len = Input(shape=(1), name='label_len') # Lambda 的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len,\",\n",
       " \"name='ctc')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out) # 画图 plot_model(ctc_model,style=0,show_layer_names=True) 结果输出为：\",\n",
       " '485\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n代码 13-8：CTC 算法-验证码识别（片段 3）\\n\\nfrom tensorflow.keras.callbacks import Callback\\n\\n# 编号转成字符串 def labels_to_text(labels): ret = [] for l in labels: # -1 是空白符 if l == -1: ret.append(\\'\\') else: ret.append(characters[l]) return \"\".join(ret)\\n\\n# 把一个批次的编号转为字符串 def decode_batch(labels): ret = [] for label in labels: ret.append(labels_to_text(label)) return np.array(ret)\\n\\n# 自定义 Callback\\n\\n486',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com class Evaluate(Callback): def __init__(self): pass # 自定义准确率计算 def accuracy(self, model, batch_size=batch_size, steps=test_steps): # 准确率统计 batch_acc = 0 # 产生测试数据 valid_data = CaptchaSequence(characters, batch_size, steps) for [X_test, y_test, _, _], _ in valid_data: # 特别要注意，空白字符的编号为-1 # 这里可以先将我们自定义的空白符标签变成-1 for i,label in enumerate(y_test): for j,l in enumerate(label): if l == num_classes-1: y_test[i,j] = -1 # 将一个批次的标签数据转为字符串形式 y_test = decode_batch(y_test) #',\n",
       " '将一个批次的标签数据转为字符串形式 y_test = decode_batch(y_test) # 得到预测结果 y_pred = model.predict(X_test) # shape[0]为 batch_size，shape[1]为 max_len shape = y_pred.shape # ctc_decode 默认使用贪心算法计算出 ctc 的预测结果 # get_value 获得 ctc_decode 的数值返回 numpy array 格式的数据 out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[ 0][0]) # 将一个批次的预测数据转为字符串形式 out = decode_batch(out) # 对比一个批次的标签和预测数据，计算准确率 batch_acc += (y_test == out).mean() # 返回准确率 return batch_acc / steps',\n",
       " \"# 顾名思义，在一个训练周期的末尾会自动调用这个方法 # 这里的 epoch 是当前训练的周期数 # logs 是一个字典用来记录一些模型训练的信息 def on_epoch_end(self, epoch, logs): # 计算准确率 acc = self.accuracy(model) # 记录 val_acc logs['val_acc'] = acc # 打印 print(f'\\\\nacc: {acc*100:.4f}')\\n\\n487\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 除了 on_epoch_end 以外，自定义 Callback 还可以定义很多方法，比如： # def on_epoch_begin(self, epoch, logs=None): # def on_batch_begin(self, batch, logs=None): # def on_batch_end(self, batch, logs=None): # 等等，有兴趣的同学可以看 tensorflow 源码进一步研究。\",\n",
       " \"# loss 的计算是在 K.ctc_batch_cost 中实现的，所以这里定义了一个假的 loss，没什么意 义，也没有作用，但是必须要定义 ctc_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=SGD(lr=1e- 2,momentum=0.9))\",\n",
       " \"# 监控指标统一使用 val_acc # 可以使用 EarlyStopping 来让模型停止，连续 6 个周期 val_acc 没有上升就结束训练 # CSVLogger 保存训练数据 # ModelCheckpoint 保存所有训练周期中 val_acc 最高的模型 # ReduceLROnPlateau 学习率调整策略，连续 3 个周期 val_acc 没有上升当前学习率乘以 0.1 callbacks = [Evaluate(), EarlyStopping(monitor='val_acc', patience=6, verbose=1), CSVLogger('Captcha_ctc.csv'), ModelCheckpoint('Best_Captcha_ctc.h5', monitor='val_acc', save_best_only=True), ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=3, verbose=1) ]\",\n",
       " '# 训练模型 ctc_model.fit(x=CaptchaSequence(characters, batch_size=batch_size, steps=train_steps), epochs=epochs, validation_data=CaptchaSequence(characters, batch_size=batch_size, steps=test _steps), callbacks=callbacks) 结果输出为： Train for 1000 steps, validate for 100 steps Epoch 1/100 999/1000 [============================>.] - ETA: 0s - loss: 5.8164 acc: 33.6562 1000/1000 [==============================] - 313s 313ms/step - loss: 5.8136 - val_loss: 4.2324 Epoch 2/100 999/1000',\n",
       " '5.8136 - val_loss: 4.2324 Epoch 2/100 999/1000 [============================>.] - ETA: 0s - loss: 1.7650 acc: 62.4844 …… Epoch 36/100 999/1000 [============================>.] - ETA: 0s - loss: 0.3042 acc: 89.7344',\n",
       " '488\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999998837 88405e-08. 1000/1000 [==============================] - 306s 306ms/step - loss: 0.3042 - val_loss: 0.2984 Epoch 00036: early stopping\\n\\n13.8.2 使用 CTC 算法训练验证码模型-模型预测\\n\\n关于模型测试阶段，我们需要注意的是使用 load_weights 的方式载入模型权值，而不\\n\\n能直接用 load_model 载入模型。因为 keras 中没有封装 ctc 的 loss，ctc 的 loss 是在 tens\\n\\norflow 中定义的，属于 keras 外部自定义 loss。模型 save 的时候如果包含了自定义 loss，\\n\\n那么在 load_model 的时候也需要声明自定义 loss。在这个应用中还是重新搭建一遍模型并',\n",
       " '使用 load_weights 载入模型权值比较简单，如代码 13-9 所示。\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 1）',\n",
       " 'from tensorflow.keras.applications.resnet50 import ResNet50 from tensorflow.keras.layers import Input,Dense,Reshape,Bidirectional,GRU,Lambda from tensorflow.keras.models import Model from tensorflow.keras import backend as K from captcha.image import ImageCaptcha import matplotlib.pyplot as plt import numpy as np import string # 字符包含所有数字和所有大小写英文字母，一共 62 个 characters = string.digits + string.ascii_letters # 类别数+空白字符 num_classes = len(characters)+1 # 图片宽度 width=160 # 图片高度 height=60 # RNN 的 cell',\n",
       " '# 图片宽度 width=160 # 图片高度 height=60 # RNN 的 cell 数量 RNN_cell = 128 # 最长验证码 max_len = 6 # Keras 调用 Tensorflow 中的 ctc_batch_cost # x 是模型输出，shape-(?,10,63)',\n",
       " '489',\n",
       " \"免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # labels 是验证码的标签，shape-(?,max_len) # input_len 是 x 的长度，shape-(?,1)，x 的长度为 10 # label_len 是 labels 的的长度，shape-(?,1)，labels 的长度为 max_len def ctc_lambda_func(args): x, labels, input_len, label_len = args # Tensorflow 中封装的 ctc 计算 return K.ctc_batch_cost(labels, x, input_len, label_len) # 载入预训练的 resnet50 模型 resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(height,width,3) ) # 设置输入 image_input = Input((height,width,3), name='image_input') # 使用\",\n",
       " \"Input((height,width,3), name='image_input') # 使用 resnet50 进行特征提取 x = resnet50(image_input) # 搭建 RNN 网络 x = Reshape((10,2048))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Bidirectional(GRU(RNN_cell, return_sequences=True))(x) x = Dense(num_classes, activation='softmax')(x) # 定义模型 model = Model(image_input, x) # 定义标签输入 labels = Input(shape=(max_len), name='max_len') # 输入长度 input_len = Input(shape=(1), name='input_len') # 标签长度 label_len = Input(shape=(1), name='label_len') #\",\n",
       " \"label_len = Input(shape=(1), name='label_len') # Lambda 的作用是可以将自定义的函数封装到网络中，用于自定义的一些数据计算处理 ctc_out = Lambda(ctc_lambda_func, name='ctc')([x, labels, input_len, label_len]) # 定义模型 ctc_model = Model(inputs=[image_input, labels, input_len, label_len], outputs=ctc_out)\",\n",
       " \"# 注意这里是 load_weights，载入权值，这里不能直接用 load_model 载入模型 # 因为 keras 中没有封装 ctc 的 loss，ctc 的 loss 是在 tensorflow 中定义的，属于 keras 外部 自定义 loss # 模型 save 的时候如果包含了自定义 loss，那么在 load_model 的时候也需要声明自定义 loss。 # 在这个应用中还是重新搭建一遍模型并使用 load_weights 载入模型权值比较简单 model.load_weights('Best_Captcha_ctc.h5')\\n\\n# 用于预测的字符集多一个空白符 pre_characters = characters + '-'\\n\\n490\",\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 使用贪心算法预测结果 def greedy(captcha_text): # 自定义产生一个验证码 captcha_text = captcha_text # 产生验证码并归一化 image = ImageCaptcha(width=160, height=60) x = np.array(image.generate_image(captcha_text)) / 255.0 # 变成 4 维数据 X_test = np.expand_dims(x, axis=0) # 用模型进行预测 y_pred = model.predict(X_test) # 查看 y_pred 的 shape print(\"y_pred shape:\",y_pred.shape) # 获得每个序列最大概率的输出所在位置，其实也就是字符编号 argmax = np.argmax(y_pred[0], axis=-1) print(\\'id\\',\\'\\\\t\\',\\'characters\\') for x in argmax: #',\n",
       " \"print('id','\\\\t','characters') for x in argmax: # 打印字符编号和对应的字符 print(x,'\\\\t',pre_characters[x]) # 使用贪心算法计算预测结果 out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred. shape[1], greedy=True)[0][0]) # 把预测结果转化为字符串 out = ''.join([characters[x] for x in out[0]]) # 显示图片 plt.imshow(X_test[0]) # 设置 title plt.title('pred:' + out + '\\\\ntrue: ' + captcha_text) # show plt.show() # 生产特定验证码并进行识别 greedy('a0b1C3') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 0 0 b 11 1 1 C 38 3\",\n",
       " '10, 63) characters id a 10 0 0 b 11 1 1 C 38 3 3 - 62 - 62 - 62',\n",
       " \"491\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com 62\\n\\n\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 2）\\n\\n# 生产特定验证码并进行识别 # 模型训练阶段我们使用的验证码都是 3-6 位的 # 预测阶段使用 2 位长度的验证码也可以识别正确 greedy('aa') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 - 62 a 10 a 10 - 62 - 62 - 62 - 62 - 62 - 62\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 3）\\n\\n# 生产特定验证码并进行识别\\n\\n492\",\n",
       " \"# 生产特定验证码并进行识别\\n\\n492\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 模型训练阶段我们使用的验证码都是 3-6 位的 # 预测阶段使用 7 位长度的验证码也可以识别正确 # 不过由于我们的模型输入输出长度最多为 10，并且模型训练阶段，验证码最多为 6 位 # 所以如果验证码长度超过 6 的话识别的效果可能不太理想 greedy('abcdefg') 结果输出为： y_pred shape: (1, 10, 63) characters id a 10 b 11 c 12 d 13 e 14 f 15 g 16 - 62 - 62 - 62\\n\\n代码 13-9：CTC 算法-验证码识别-模型预测（片段 4）\",\n",
       " '代码 13-9：CTC 算法-验证码识别-模型预测（片段 4）\\n\\n# 使用 beam search 预测结果 def beam_search(captcha_text): # 自定义产生一个验证码 captcha_text = captcha_text # 产生验证码并归一化 image = ImageCaptcha(width=160, height=60) x = np.array(image.generate_image(captcha_text)) / 255.0 # 变成 4 维数据 X_test = np.expand_dims(x, axis=0) # 用模型进行预测 y_pred = model.predict(X_test) # 最好的 3 个结果 top_paths = 3\\n\\n493',\n",
       " \"493\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 保存最好的 3 个结果 outs = [] for i in range(top_paths): labels = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_ pred.shape[1], greedy=False,top_paths=top_paths)[0][i])[0] outs.append(labels) # 最好的 3 个结果分别显示出来 for out in outs: # 转字符串 out = ''.join([characters[x] for x in out]) # 显示图片 plt.imshow(X_test[0]) # 设置 title plt.title('pred:' + out + '\\\\ntrue: ' + captcha_text) # show plt.show()\\n\\n# 生产特定验证码并进行识别 beam_search('AbCd70') 结果输出为：\",\n",
       " \"# 生产特定验证码并进行识别 beam_search('AbCd70') 结果输出为：\\n\\n494\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n从 CTC 算法模型测试结果可以看出，就算训练阶段验证码长度是 3-6 位，模型也能预测\\n\\n少于 3 位或多于 6 位的验证码结果。在使用 beam search 算法后，模型可以给出概率最大\\n\\n的几个输出结果。\\n\\n495\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 14 章-自然语言处理 NLP 发展历程\\n\\n（上）\\n\\n本章主要给大家介绍 NLP(Natural Language Processing)技术的发展历程，不过必须先\\n\\n要说清楚的是 NLP 技术是 AI 技术领域的一个大方向，所以真的要把 NLP 发展历程介绍清楚\\n\\n那至少要写一两本书。所以本章介绍的内容主要是近年来 NLP 与深度学习结合的最重要和最\\n\\n新的一些成果。由于内容比较多，所以分上下两个部分给大家介绍。\\n\\n14.1 NLP 应用介绍\",\n",
       " '新的一些成果。由于内容比较多，所以分上下两个部分给大家介绍。\\n\\n14.1 NLP 应用介绍\\n\\n在介绍 NLP 的具体技术之前，我们先来了解一下 NLP 的一些实际应用。NLP 的任务基\\n\\n本上都可以使用序列模型来完成，如果大家对前面的序列模型忘记了可以先回头看一下。\\n\\nNLP 应用中大部分的任务都可以使用 seq2seq 架构来完成，seq2seq 计算细节我们在后面\\n\\n再详细介绍。\\n\\n14.1.1 文本分类/情感分类\\n\\n如图 14.1：\\n\\n图 14.1 文本分类\\n\\n496\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n文本分类就是把一段文本划分到不同的类别；情感分类就是对一段文本中所包含的情感\\n\\n进行分类。其实文本分类或文章句子的情感分类本质上都是一样，都是属于分类任务，套用\\n\\n序列模型里面我们讲过的框架，属于多对一框架。输入一篇文章或句子可以看出是一个序\\n\\n列，整个序列输入结束后我们只需要获得序列最后一个输出即可。对最后一个序列的输出信\\n\\n号进行分类，得到分类结果。\\n\\n14.1.2 分词标注',\n",
       " '号进行分类，得到分类结果。\\n\\n14.1.2 分词标注\\n\\n这个应用在序列模型的章节中也有介绍过，可以使用多对多架构完成，序列的每个输入都\\n\\n会得到一个对应的输出结果。给一段文字做分词标注，标注每个字对应的标号。假如使用 4-\\n\\ntag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结束位置，S\\n\\n表示单字词。可以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n14.1.3 机器翻译\\n\\n如图 14.2：\\n\\n图 14.2 机器翻译\\n\\n机器翻译是典型的 seq2seq 应用，比如输入一段中文，中文句子就是一段序列。输出得\\n\\n到一段英文，英文句子也是一段序列。类似这种问题都可以使用 seq2seq 架构来完成。\\n\\n497\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.1.4 聊天机器人\\n\\n如图 14.3：\\n\\n图 14.3 聊天机器人\\n\\n聊天机器人也是典型的 seq2seq 应用，输入一个句子输出一个句子。不过目前的技术发',\n",
       " '聊天机器人也是典型的 seq2seq 应用，输入一个句子输出一个句子。不过目前的技术发\\n\\n展还不够成熟，纯娱乐性质的聊天机器人用处不大，因为你稍微跟它多聊几句可能就会发现\\n\\n它是个智障。你只能跟它聊今天星期几，明天什么天气之类的话题，无法实现复杂对话。\\n\\n不过聊天机器人在某些特定领域，如机器人客服领域，还是发挥了很大的作用。很多电\\n\\n商，银行都已经上线了机器人客服的应用，因为在特定领域，大家的聊天内容相对固定，所\\n\\n以比较容易判断用户的意图，然后给出相应的回复。\\n\\n不过大家要注意像机器人客服这样的应用并不是一个模型就可以搞定所有的事情，虽然\\n\\n模型也会用，不过很多用户意图的判断和对话的回复还是通过规则来实现的。比如匹配句子\\n\\n是否出现了某个词，假设出现“发货”这个词，那说明用户可能想咨询发货相关的问题；假\\n\\n如出现“信用卡”，那用户可能是要咨询信用卡相关业务。并且机器人的回复也不是自动生\\n\\n成的回复，机器人回复的内容基本上也是事先人工设置好的内容。\\n\\n498\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.1.5 自动摘要',\n",
       " '免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.1.5 自动摘要\\n\\n自动摘要很容易理解，就是阅读文章后产生出文章的标题，也是属于 seq2seq 架构。这\\n\\n要求模型具备极强的核心内容提取概括能力，听起来就很难。所以目前自动摘要技术做得也\\n\\n不算非常好，有些时候效果不错，有些时候效果很差。\\n\\n14.1.6 文章生成\\n\\n可以给模型输入一段话或者是一大段文章，然后让模型自动生成接下来的内容，生成的\\n\\n文章长度可以人为控制，这也是 seq2seq 模型。这个应用听起来就是即神奇有趣又不靠谱。\\n\\n下面我们可以看一下实际模型得到的效果，使用金庸小说训练后的模型，给它输入一段文字\\n\\n让它进行后续文章的生成（结果来自：\\n\\nhttps://github.com/bojone/bert4keras/blob/master/examples/task_language_model.\\n\\npy）。\\n\\n输入：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。\\n\\n输出：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。这时见他手中所握，竟是',\n",
       " '输出：杨过居住在侠客岛，是令狐冲的弟子，武器是金蛇剑。这时见他手中所握，竟是\\n\\n一柄特制的短剑，心中大喜，叫道：：原来是金蛇郎君的剑！原来你便是金蛇郎君的弟子，\\n\\n这一下可要叫我失望了。那人哈哈一笑，说道：好啊！好啊，好啊！我的金蛇剑是我的，不\\n\\n过我是你的。这人道：我姓杨名过，名字叫过。你是我儿子，是我女儿，是不是？你这么大\\n\\n的年纪，怎地自称金刀驸马？我这就给你取个名字，叫作过儿。\\n\\n输入：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n\\n外，但听她呼吸调匀，正自香梦沉酣。\\n\\n499\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n输出：当晚两人在一家小客店中宿歇。张无忌躺在炕上，越想越是担心，走到赵敏窗\\n\\n外，但听她呼吸调匀，正自香梦沉酣。次日清晨，张无忌便和赵敏去买了一匹高头大马，自\\n\\n己骑了随伴。那马甚有神骏，三十六斤重的身躯之中，竟无一头白马。他心中怦怦乱跳，暗\\n\\n想：若能将赵敏引出迷城，我决不致再和她相会，但若和赵姑娘相遇，我一生一世决计再难',\n",
       " '想：若能将赵敏引出迷城，我决不致再和她相会，但若和赵姑娘相遇，我一生一世决计再难\\n\\n相见。何况我是她的私生女儿，这般亲热，岂不是好？我如何能和她相见？今后我要教训教\\n\\n训她才好？我教教她，教训她，要她心里快快活活的。他心如刀割，当即回到客店，将张无\\n\\n忌的所在说了。\\n\\n这是什么玩意儿？目前看来除了搞笑以外，没有其他作用。\\n\\n另外诗歌生成也是类似的，我们可以给模型传入诗歌的标题，模型就可以产生一首诗出\\n\\n来。\\n\\n14.1.7 图片描述\\n\\n图片描述是计算机视觉与 NLP 相结合的一个技术，首先使用一个预训练的 CNN 模型对\\n\\n图片数据进行特征提取，然后把 CNN 模型提取的图像特征传给 RNN 网络进行文字生成，如\\n\\n图 14.4：\\n\\n500\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.4 图片描述模型\\n\\n有些图片得到的效果挺好的，如图 14.5：\\n\\n图 14.5 图片描述 1\\n\\n臭臭躺在床上，不过光看背景也不太看得出是床，所以描述是 laying on a couch 也是\\n\\n合理的。\\n\\n501',\n",
       " '合理的。\\n\\n501\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n有些图片描述的效果就比较奇怪了，如图 14.6：\\n\\n图 14.6 图片描述 2\\n\\n一个女人站在人行道上，穿着粉红色的雨伞……很显然该模型不具备生活的常识，生活的\\n\\n常识就是人是不会穿雨伞的，它只是把它识别到的物体给拼凑到一起了。\\n\\n图片描述在某些特定场景下可以得到不错的效果，不过整体而言效果还是差强人意的。\\n\\nNLP 的应用还有很多，这里我们就不举太多例子了，大家有兴趣可以再自行研究。\\n\\n14.2 从传统语言模型到神经语言模型\\n\\n传统的自然语言处理也叫统计自然语言处理，听名字我们就知道传统的自然语言处理技\\n\\n术主要是使用数学和统计学。这跟神经网络/深度学习在自然语言处理中的技术截然不同，神\\n\\n经网络/深度学习主要使用的是数学和玄学（开玩笑）。由于技术上的巨大差异，下面关于统\\n\\n计自然语言处理的部分我们只做简单介绍，重点还是介绍神经网络/深度学习在自然语言处理\\n\\n方面的应用。\\n\\n502\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.1 规则模型[1]',\n",
       " '14.2.1 规则模型[1]\\n\\n在上世纪 60 年代左右，学术界对人工智能和自然语言处理的普遍理解是：要让机器完成\\n\\n翻译或语言识别等只有人类才能做的事情，就必须先让计算机理解自然语言，而做到这一点\\n\\n就必须让计算机拥有类似我们人类这样的智能。（真正做到这点确实很难，直到今天计算机\\n\\n也没能做到这一步，所以现在几乎所有科学家都不再坚持这一点）。\\n\\n那么要如何让计算机理解自然语言呢，当时科学家得出的结论是分析语句和获取语义。\\n\\n我们在学校学习外语的时候都要学习语法规则（Grammar Rules），词性（Part of\\n\\nSpeech）和构词法（Morphologie）等，这些内容对于我们学习外语有一定的帮助，并且\\n\\n比较容易用计算机的算法描述。大家以为这会是一条正确的道路。\\n\\n在上世纪 80 年代以前，自然语言处理工作中的文法规则都是人工写的，直到 2000 年\\n\\n后，很多公司还是靠人工来总结文法规则。通过人工设计的规则来分析句子虽然可能会有些\\n\\n效果，但是总体而言不太靠谱。比如有下面 3 个问题：\\n\\n问题 1：我们人类的语言博大精深，几乎有无数种不同的句子，如果真的能有一套规则能',\n",
       " '问题 1：我们人类的语言博大精深，几乎有无数种不同的句子，如果真的能有一套规则能\\n\\n描述好每一个句子，那这套规则得有多少条，几亿条还是几百亿条还是更多？这么复杂的一\\n\\n套规则即使真的存在，我们人类可能无法把它写出来。\\n\\n问题 2：我们人类设计的文法规则通常是上下文无关文法（Context Independent\\n\\nGrammar），而实际句子的文法其实应该是跟上下文相关的，属于上下文相关文法\\n\\n（Context Dependent Grammar）。两者的设计难度和计算量都无法相提并论。\\n\\n问题 3：我们人类的语言有些是需要常识来进行判断的。比如“吃饭前我想方便一下”，\\n\\n“你方便的时候我想请你吃饭”，“你方不方便你去方便的时候问你吃饭的事”，这里的\\n\\n“方便”我们都能理解什么意思，但是要跟老外解释清楚就不容易了，更别说计算机。\\n\\n503\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.2 统计语言模型[1]\\n\\n在上世纪 80 年代末，随着计算能力的提升和数据量的不断增加，过去看似不可能通过统',\n",
       " '在上世纪 80 年代末，随着计算能力的提升和数据量的不断增加，过去看似不可能通过统\\n\\n计模型完成的任务，渐渐都变得可能了。到了上世纪 90 年代末期，大家发现通过统计得到\\n\\n的句法规则甚至比语言学家总结的更有说服力。2005 年以后，Google 基于统计方法的翻译\\n\\n系统全面超过基于规则的 SysTran 翻译系统，宣告规则方法学派的全面溃败。\\n\\n统计语言模型简单来说就是通过统计得到的语言模型。规则模型的主要思想是通过人工\\n\\n设定的规则来描述语言，而统计语言模型是通过统计学找到语言的规律。比如一个句子：\\n\\n“我爱北京天安门，天安门上太阳升”。\\n\\n意思清晰句子通顺。如果我们调整一些词的位置，得到：\\n\\n“我爱天安门北京，太阳升上天安门”\\n\\n虽然句子有些不够通顺，但是意思我们还是可以看懂的，假设我们再调整一下句子，得\\n\\n到：\\n\\n“爱北京天安我门，升门天安上太阳”\\n\\n这句话就基本看不懂什么意思了，为什么会这样？规则方法学派的科学家认为一个句子\\n\\n是否能理解，要看句子是否合乎语法，句子中的语义是否清晰。他们的想法有一定的道理，',\n",
       " '是否能理解，要看句子是否合乎语法，句子中的语义是否清晰。他们的想法有一定的道理，\\n\\n但是在规则方法学这条路上的困难要远大于方法，所以这条路是走不通的。\\n\\n著名的语音识别和自然语言处理的专家弗莱德里克·贾里尼克（Frederick Jelinek）提出\\n\\n了一个新的思路，可以使用简单的统计模型来分析描述一个句子。其实方法很简单，一个句\\n\\n子是否合理，我们不需要分析它的语法语义，只需要分析这句话出现的概率。比如上面我们\\n\\n列举的三个天安门的句子，第一个句子出现概率可能是10(cid:127)\"<，第二个句子出现的概率可能是\\n\\n504\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n10(cid:127)$<，第三个句子出现的概率可能是10(cid:127)\"<<。第一个句子出现概率最大，所以最合理，第三\\n\\n个句子概率最小所以最不合理。\\n\\n比如用 S 表示一个句子，一个句子由若干个顺序排列的词𝑤\",\\t𝑤#,\\t𝑤$,…,\\t𝑤@组成。所以一\\n\\n个句子出现的概率就等于这个句子每一个词出现的条件概率相乘：',\n",
       " '个句子出现的概率就等于这个句子每一个词出现的条件概率相乘：\\n\\n𝑃(𝑆) = 𝑃(𝑤\", 𝑤#, … , 𝑤@) = 𝑃(𝑤\") ∙ 𝑃(𝑤#|𝑤\") ∙ 𝑃(𝑤$|𝑤\", 𝑤#) ∙∙∙ 𝑃(𝑤@|𝑤\", 𝑤#, … , 𝑤@(cid:127)\")\\n\\n其中𝑃(𝑤\")表示第一个词出现的概率，𝑃(𝑤#|𝑤\")是在已知第一个词的前提下，第二个词出\\n\\n现的概率；以此类推，词𝑤@的出现概率取决于它前面所有的词。\\n\\n每个词出现的条件概率怎么统计？通常在训练 NLP 模型的时候我们都会准备一个语料库\\n\\n（Corpus），语料库其实就是一个数据集，这个数据集就是大量的文本数据。我们可以在这\\n\\n个数据集中统计每个词𝑃(𝑤ˆ)出现的概率，以及前后相邻的两个词𝑃(𝑤ˆ|𝑤ˆ(cid:127)\")出现概率，前后\\n\\n相邻的三个词，四个词，N 个词的概率。\\n\\n不过这个模型存在一个问题，就是计算量的问题。𝑃(𝑤\")很容易统计出来，𝑃(𝑤#|𝑤\")难度\\n\\n也不是很大，𝑃(𝑤$|𝑤\", 𝑤#)难度就已经非常大了。并且这个计算量是指数级增长的，如果句子',\n",
       " '也不是很大，𝑃(𝑤$|𝑤\", 𝑤#)难度就已经非常大了。并且这个计算量是指数级增长的，如果句子\\n\\n比较长，𝑃(𝑤@|𝑤\", 𝑤#, … , 𝑤@(cid:127)\")可能是无法计算出来的。\\n\\n好在这个问题存在可以简化的方式。20 世纪初，俄国数学家马尔可夫（Andrey\\n\\nMarkov）提出每当遇到类似这种情况时，就假设任意一个词𝑤ˆ出现的概率只与它前面的词\\n\\n𝑤ˆ(cid:127)\"相关，这样问题就变得简单了。这种假设在数学上称为马尔可夫假设。于是公式 14.1 就\\n\\n可以简化为：\\n\\n𝑃(𝑆) = 𝑃(𝑤\", 𝑤#, … , 𝑤@) = 𝑃(𝑤\") ∙ 𝑃(𝑤#|𝑤\") ∙ 𝑃(𝑤$|𝑤#) ∙∙∙ 𝑃(𝑤@|\\t𝑤@(cid:127)\")\\n\\n公式 14.2 对应的统计语言模型是二元模型（Bigram Model）。一个词的出现概率只与\\n\\n它前面一个词相关叫二元模型，一个词的出现概率与它前面两个词相关叫三元模型，一个词\\n\\n505\\n\\n(14.1)\\n\\n(14.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '(14.2)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的出现概率与它前面三个词相关叫四元模型。以此类推，一个词的出现概率由前面 N-1 个词\\n\\n决定，称为 N 元模型（N-Gram Model）。\\n\\n可以想象 N 元模型中 N 的值越大就越接近句子真实的概率，当然 N 的值越大计算量也\\n\\n会越大。当 N 从 1 到 2，再从 2 到 3，模型的效果上升显著，而当模型从 3 到 4 时，效果的\\n\\n提升就不是很明显了。所以一般三元或四元模型用得比较多，很少人会使用四元以上模型。\\n\\n举例来说一下基于 N-Gram 模型的应用，比如在进行文本分类应用的时候。我们可以根\\n\\n据每个类别的语料库训练各自的语言模型，比如情绪二分类，正面情绪有一个语料库，可以\\n\\n训练一个语言模型；负面情绪有一个语料库，可以训练一个语言模型。当新来一个文本的时\\n\\n候，只要根据各自的语言模型，计算每个语言模型下这篇文本发生的概率。文本在哪个模型\\n\\n的概率大，这篇文本就属于哪个类别。\\n\\n比如在做语音识别的时候，我们识别出了一个句子的发音“woaibeijingtiananmen”，',\n",
       " '比如在做语音识别的时候，我们识别出了一个句子的发音“woaibeijingtiananmen”，\\n\\n正确的识别结果是“我爱北京天安门”。但其实这个句子的发音可以对应非常多的文本，比\\n\\n如“我碍北京添安们”，“我爱北精天氨门”。通过 N-Gram 模型我们可以计算出“我爱北\\n\\n京天安门”这句话出现概率是最大的。\\n\\n统计语言模型可以很好地解决很多问题，但是该模型也存在很多问题：\\n\\n问题 1：很多时候，在计算条件概率时，𝑃(𝑤ˆ|𝑤ˆ(cid:127)\")会得到 0 值。也就是新文本中两个相\\n\\n邻词𝑤ˆ(cid:127)\"𝑤ˆ在语料库中没有出现过。所以统计语言模型中需要设计各种平滑方法来处理这种\\n\\n情况。\\n\\n问题 2：统计语言模型无法把 n 取得很大，最多就是 3-gram 或 4-gram。所以统计语言\\n\\n模型无法建模语言中上下文较长的依赖关系。\\n\\n问题 3：统计语言模型无法表征词语之间的相似性。\\n\\n506\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.3 词向量（word embedding）',\n",
       " '14.2.3 词向量（word embedding）\\n\\n在介绍神经网络语言模型 NNLM（Neural Net Language Model）之前，我们先聊\\n\\n一下 NNLM 中的核心思想-词向量（Word Embedding），word embedding 也可以翻译\\n\\n为词嵌入，本书把它称之为词向量。\\n\\n我们在处理图像时，图像数据就是一个密集的矩阵，矩阵中的每个数值对应着图片中的\\n\\n每个像素点，我们所需的全部信息都储存在原始数据中。如图 14.7：\\n\\n图 14.7 图像数据\\n\\n所以我们把这个图像数据对应的矩阵分析好就行了。如果是分析文本数据，我们通常会\\n\\n给每个词进行编号，比如“猫”的编号是 343，“狗”的编号是 452。每个词的编号大小一\\n\\n般是跟该词在语料库中出现的频率相关（也有可能是其他编号方式或人为设置的编号），出\\n\\n现的频率越高，编号就越小。从词的编号我们无法知道这个词所包含的含义，也无法知道词\\n\\n与词之间的相关性。\\n\\n接下来我们可能还会对编号进行 one-hot 独热编码处理。假设语料库中一共有 10000 个',\n",
       " '接下来我们可能还会对编号进行 one-hot 独热编码处理。假设语料库中一共有 10000 个\\n\\n词，经过独热编码处理后，每个词的数据长度都为 10000，其中只有一个 1，其余的位置都\\n\\n是 0，如：\\n\\n杭州 [0,0,0,0,0,0,0,1,0,……，0,0,0,0,0,0,0]\\n\\n上海 [0,0,0,0,1,0,0,0,0,……，0,0,0,0,0,0,0]\\n\\n507\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n宁波 [0,0,0,1,0,0,0,0,0,……，0,0,0,0,0,0,0]\\n\\n北京 [0,0,0,0,0,0,0,0,0,……，1,0,0,0,0,0,0]\\n\\n注意，虽然独热编码处理后，每个词变成了一个向量，但是这种独热编码类型的向量可\\n\\n不是前面我们说的词向量（Word Embedding）。独热编码的向量虽然在某些简单场景下也\\n\\n可以得到不错的效果，但是复杂一些的场景就无法得到好的效果了。我们把一个词看成是 1\\n\\n行 10000 列的数据，把一个句子看成是一个矩阵，那么这个矩阵将会是一个非常稀疏的矩',\n",
       " '行 10000 列的数据，把一个句子看成是一个矩阵，那么这个矩阵将会是一个非常稀疏的矩\\n\\n阵，大部分的值都是 0，这个稀疏的矩阵也没有多少可以分析的价值。\\n\\n所以传统的方式不管是将词变成编号还是将词再转成独热编码，都无法对词包含的信息\\n\\n进行一个很好的描述。那么如何才能比较好的去描述一个词呢？用一个向量来描述一个词，\\n\\n或许是一个不错的方法，这就是我们所说的词向量。\\n\\n为什么用一个向量来描述一个词会是一个有效的方法？通常词向量的长度都是人为设置\\n\\n的，比如我们设置词向量的长度为 128，也就是说每个词都会使用一个 128 维的向量来表\\n\\n示，这个向量的每一个维度都具有抽象的含义（具体的含义我们是无法知道的）。我举一个\\n\\n不是很恰当的例子，假设词向量的某一个维度 d 表示该词跟我们日常生活的相关性，相关越\\n\\n大，d 的数值就越大。比如“猫”这个词在我们日常生活中经常出现，那么“猫”这个词的\\n\\n词向量中维度 d 的数值就会比较大；而“引力红移”（广义相对论预言的一种电磁辐射波长\\n\\n变长，频率降低的效应）这个词在我们日常生活中几乎不会出现，所以“引力红移”这个词',\n",
       " '变长，频率降低的效应）这个词在我们日常生活中几乎不会出现，所以“引力红移”这个词\\n\\n的词向量中维度 d 的数值就会比较小。如果每一个词都有 128 个维度可以用来描述它，那么\\n\\n理论上就可以把这个词包含的信息描述得比较好。最后再强调一下，词向量中每个维度的含\\n\\n义是抽象的，无法知道它们的具体含义。\\n\\n词向量的思想从 NNLM 中提出，并一直沿用至今，是深度学习在 NLP 领域中使用的既\\n\\n是基础又是核心的思想。\\n\\n508\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.2.4 神经语言模型\\n\\n2003 年 Bengio 在他的经典论文《A Neural Probabilistic Language Model》[2]中首\\n\\n次将神经网络融入到语言模型中，并经过训练得到神经网络语言模型 NNLM（Neural Net\\n\\nLanguage Model）。NNLM 的模型结构可以看下图 14.8：\\n\\n图 14.8 神经语言模型 NNLM[2]',\n",
       " '图 14.8 神经语言模型 NNLM[2]\\n\\n图中 output 表示输出；Matrix 表示矩阵；Table look-up in C 表示在矩阵 C 中查询；\\n\\nshared parameters across words 表示参数共享。\\n\\n下面我们说一下 NNLM 的训练过程，其实很简单，就是传入前面几个词，然后再预测下\\n\\n一个词是什么。具体流程是我们会分析语料库并构建一个字典 V，所有的词都在这个字典\\n\\n中，并且每个词在字典中有唯一编号。NNLM 每次训练时从语料库中选取一段长度为 n 的文\\n\\n本（𝑤ˆ(cid:127)@(cid:151)\",…,\\t𝑤ˆ(cid:127)#,𝑤ˆ(cid:127)\",𝑤ˆ）。比如 t=10，n=5，那么文本就是（𝑤(cid:226),𝑤(cid:236),𝑤(cid:201),𝑤(cid:237),𝑤\"<）。n 可\\n\\n以人为设置，这里的 n 有点像 n-gram 模型中的 n 的意思，分析连续的 n 个词。\\n\\n509\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '509\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n接下来我们把长度为 n 的文本序列用它们所对应的编号来替代，例如：\\n\\n（𝑤(cid:226),𝑤(cid:236),𝑤(cid:201),𝑤(cid:237),𝑤\"<）就变成了类似（26,42,267,6582,64）这样的编号。\\n\\n然后再将编号变为 one-hot 独热编码格式。假设字典 V 中一共有 10000 个词，本文序\\n\\n列长度为 5，经过独热编码的处理后文本数据就变成了 5 行 10000 列的矩阵，类似下面这\\n\\n样：\\n\\n[[0,…,0,…,1,…,0,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,1,…,0,…,0,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,0,…,0,…,1,…,0,…,0,…0,…,0,…0,…0]\\n\\n[0,…,0,…,0,…,0,…,0,…,0,…,0,…,0,…0,…,0,…1,…0]\\n\\n[0,…,0,…,0,…,0,…,1,…,0,…,0,…,0,…0,…,0,…1,…0]]',\n",
       " '[0,…,0,…,0,…,0,…,1,…,0,…,0,…,0,…0,…,0,…1,…0]]\\n\\n然后把最后一个词的独热编码作为模型预测的标签值，其他词的独热编码作为输入传给\\n\\n模型。图 14.8 中的 C 称为词特征层，该层有一个权值矩阵 Matrix C 可以理解为所有词的词\\n\\n向量矩阵（Matrix C 在训练开始的时候都是随机值，没有任何意义，经过模型训练以后才能\\n\\n得到有意义的词向量）。比如词向量的长度为 128，那么 Matrix C 可能就是一个 10000 行\\n\\n128 列的权值矩阵，矩阵中的一行表示一个词的词向量。\\n\\n每个词的独热编码与 Matrix C 相乘，得到该词对应的词向量的值，如图 14.9：\\n\\n510\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.9 得到每个词的词向量\\n\\n图 14.8 中的𝐶(𝑤ˆ(cid:127)@(cid:151)\")表示𝑤ˆ(cid:127)@(cid:151)\"的词向量，𝐶(𝑤ˆ(cid:127)#)表示𝑤ˆ(cid:127)#的词向量，𝐶(𝑤ˆ(cid:127)\")表示',\n",
       " '𝑤ˆ(cid:127)\"的词向量。得到输入的每个词的词向量以后，对这些词向量进行拼接\\n\\n（concatenation），比如对 4 个长度为 128 维的词向量进行拼接，得到 512 维的数据。公\\n\\n式 14.3 表示多个词向量进行拼接得到 x：\\n\\n𝑥 = (𝐶(𝑤ˆ(cid:127)\"), 𝐶(𝑤ˆ(cid:127)#), … , 𝐶(𝑤ˆ(cid:127)@(cid:151)\"), )\\n\\n模型最终的输出值 y 的计算公式为：\\n\\n𝑦 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑏 + 𝑊𝑥 + 𝑈𝑡𝑎𝑛ℎ(𝑑 + 𝐻𝑥))\\n\\n可以对照着图 14.8 来看，x 为多个词向量拼接后的信号，H 为 x 到隐藏层之间的权值矩\\n\\n阵，d 为隐藏层的偏置值，tanh 为隐藏层的激活函数，U 为隐藏层到输出层之间的权值矩\\n\\n阵。b+Wx 为图 14.8 中的虚线部分，b 是偏置值，W 是权值矩阵，虚线就是表示可有可\\n\\n无，如果设置了 b 和 W 不为 0，则计算 b+Wx，相当于 x 可以传给输出层。如果设置\\n\\nb=W=0，相当于不把 x 直接传给输出层。模型输出神经元的数量等于字典中的词汇数量，',\n",
       " 'b=W=0，相当于不把 x 直接传给输出层。模型输出神经元的数量等于字典中的词汇数量，\\n\\n最后 softmax 得到每个词的预测概率值。\\n\\nNNLM 模型就是在训练一个传入前面几个词，然后预测下一个词的模型。这个模型训练\\n\\n好之后，就得到了我们想要的词向量，词向量就保存在前面提到的 Matrix C 中。Matrix C\\n\\n中的每一行就对应了一个词的词向量，Matrix C 的列数表示词向量的长度，可以人为设置。\\n\\nNNLM 能够对句子中更长的依赖关系进行建模，并且得到了每个词的数值表示，然后可\\n\\n以使用词向量来计算词与词之间的相似性，这些都是传统统计模型无法做到的。将词表征为\\n\\n一个向量形式，这个思想直接启发了后来的 word2vec 的工作。\\n\\n511\\n\\n(14.3)\\n\\n(14.4)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.3 word2vec\\n\\n14.3.1 word2vec 介绍\\n\\n词向量的思想最早源于 2003 年 Bengio 的论文，但是真正发扬光大是在 10 年后的',\n",
       " '词向量的思想最早源于 2003 年 Bengio 的论文，但是真正发扬光大是在 10 年后的\\n\\n2013 年。2013 年托马斯·米科洛夫（Tomas Mikolov）在 Google 带领的研究团队创造了\\n\\n一套 word embedding 训练的方法，称之为 word2vec。最早提出 word2vec 的论文是\\n\\n《Efficient estimation of word representations in vector space》[3]。\\n\\nword2vec 就是 word to vector 的缩写，中文意思就是将词转化为向量。词向量的思想\\n\\n2003 年就已经提出，之所以没有得到大规模的应用，一方面是传统统计语言模型在 NLP 领\\n\\n域已经大规模应用，并且效果也还不错，想要撼动它的地位不容易；另一方面是词向量的思\\n\\n想虽然看起来很美好，但是实际用起来效果也不算很突出。其实词向量的思想是一个正确的\\n\\n方向，为什么实际应用效果不够突出，主要是词向量的训练方法不够好。而 word2vec 正是\\n\\n一种更好的词向量训练方法。',\n",
       " '一种更好的词向量训练方法。\\n\\n14.3.2 word2vec 模型训练[4]\\n\\nword2vec 的模型训练有两种方式，分别是连续词袋模型 CBOW（Continuous Bag-\\n\\nof-Words）和 Skip-Gram 模型。这两个模型都很简单，CBOW 模型是给神经网络传入上\\n\\n下文词汇，然后预测目标词汇。比如我们有一个用于训练的句子是“我爱北京天安门“，可\\n\\n以给模型传入“爱”和“天安门“，然后用”北京“作为要预测的目标词汇。而最简单的\\n\\nCBOW 模型就是传入前一个词然后再预测后一个词，如图 14.10：\\n\\n512\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n14.10 简单 CBOW 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n这是一个带有一个隐藏层的简单神经网络。数据预处理的部分跟 NNLM 一样，先准备一\\n\\n个语料库，然后利用语料库构建一个字典，每个词都有一个编号，再把编号变成独热编码。',\n",
       " '个语料库，然后利用语料库构建一个字典，每个词都有一个编号，再把编号变成独热编码。\\n\\n训练模型的时候就把语料库中的句子相邻的两个词作为一组。比如把“我爱北京天安门”变\\n\\n成“我，爱”，“爱，北京”，“北京，天安门”，然后传给模型，前一个词作为输入，后\\n\\n一个词作为标签。图中的输入为词的独热编码，W 为保存词向量的矩阵，字典中一共有 V 个\\n\\n词，人为设置的词向量长度为 N，所以词向量矩阵 W 是 V 行 N 列。词向量的长度其实是通\\n\\n过神经网络隐藏层的神经元个数来设置的，隐藏层的神经元个数等于词向量的长度。隐藏层\\n\\n到输出层之间的权值矩阵 W’是 N 行 V 列，最后得到 V 个词的概率分布。\\n\\n这个简单的 CBOW 模型训练好以后，每个词的词向量组成的矩阵就是输入层到输出层之\\n\\n间的权值矩阵 W，W 中的每一行就是一个词的词向量。那么更复杂一些的 CBOW 模型如图\\n\\n14.11：\\n\\n513\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.11 标准 CBOW 模型[4]',\n",
       " '图 14.11 标准 CBOW 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n标准 CBOW 模型跟前面的简单 CBOW 模型类似，只不过是使用上下文的词汇来预测目\\n\\n标词汇。具体是使用前后一个词还是前后两个词或是前后三个词可以人为设定。输入的每个\\n\\n词都共用一个权值矩阵 W，而模型训练好以后，输入层到隐藏层之间的权值矩阵 W 就是词\\n\\n向量矩阵。\\n\\nSkip-Gram 模型跟 CBOW 模型相反，给模型传入一个词汇，然后预测上下文的词汇。\\n\\n比如给模型传入”北京“，然后把”爱“和”天安门“作为要预测的词汇。如图 14.12：\\n\\n514\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.12 Skip-Gram 模型[4]\\n\\n图中的 Input layer 表示输入层；Hidden layer 表示隐藏层；Output layer 表示输出\\n\\n层。\\n\\n传入一个词汇以后要预测多少个上下文词汇，都是可以人为设置的。模型训练好以后输',\n",
       " '层。\\n\\n传入一个词汇以后要预测多少个上下文词汇，都是可以人为设置的。模型训练好以后输\\n\\n入层到隐藏层之间的权值矩阵 W 就是词向量矩阵。\\n\\nCBOW 和 Skip-Gram 这两种方式都可以用于训练词向量。\\n\\n14.3.3 word2vec 训练 trick 和可视化效果\\n\\nword2vec 训练过程中有两个 trick，主要是用于加速模型训练。分别是层次 softmax\\n\\n（Hierarchical Softmax）和 负采样（Negative Sampling）。这两个 trick 并不是\\n\\n515\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nword2vec 的精髓，只是训练技巧，所以这里我们只做个简单介绍，大家有兴趣可以再自行\\n\\n研究。\\n\\nhierarchical softmax 最早源于 2005 年 Bengio 的论文《Hierarchical Probabilistic\\n\\nNeural Network Language Model》[5]。训练 word2vec 词向量的时候，模型的输出是一',\n",
       " '个多分类，并且由于字典中词汇数量巨大，导致分类数量巨大。hierarchical softmax 的本\\n\\n质是把 N 分类问题变成了 log(N)次二分类问题，可以加快模型训练速度。不过随着计算能力\\n\\n的提升，以及 GPU 加速和 TPU 加速的应用，现在 hierarchical softmax 已经用得不多了。\\n\\nnegative sampling 源自 2013 年 Mikolov 自己的论文《Distributed Representations\\n\\nof Words and Phrases and their Compositionality 》[6]。假设训练 word2vec 词向量\\n\\n时，词典的大小为 30000，那么最后 softmax 分类就会有 30000 个结果。如果我们用的是\\n\\nCBOW 模型，传入上下文词汇，预测目标词汇。我们把标签词汇看成是正样本，其他词汇看\\n\\n成是负样本。那么在模型训练时，模型输出会最大化正样本（也就是标签词汇）的概率，同\\n\\n时最小化负样本（除标签词汇以外的词汇）的概率，而正样本只有 1 个，负样本有 29999',\n",
       " '时最小化负样本（除标签词汇以外的词汇）的概率，而正样本只有 1 个，负样本有 29999\\n\\n个，负样本的数量巨大，所以计算量比较大。负采样的做法是，每次训练时在所有负样本中\\n\\n选取部分（论文作者的建议是小数据集 5-20 个，大数据集 2-5 个）进行训练，由于只选取\\n\\n了少量的负样本进行训练，所以在进行模型计算和权值更新时，计算量减少了很多。\\n\\nword2vec 训练得到的词向量通常都比较长，词向量的效果怎么样，我们可以通过可视化\\n\\n的方式来查看。比如如图 14.13：\\n\\n516\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.13 word2vec 可视化 1\\n\\n这是对 word2vec 训练得到的词向量进行了降维可视化的结果。图中我们可以看到从男\\n\\n人到女人的向量与从国王到皇后的向量是差不多的，也就是从男人变成女人的这个过程与从\\n\\n国王变成女王的过程差不多，似乎有些道理。\\n\\n图 14.14 中也是词向量可视化的结果：\\n\\n图 14.14 word2vec 可视化 2',\n",
       " '图 14.14 中也是词向量可视化的结果：\\n\\n图 14.14 word2vec 可视化 2\\n\\n图中国王的词向量减去男人的词向量再加上女人的词向量得到的结果约等于皇后的词向\\n\\n量。\\n\\n从这些可视化的结果我们可以看出，word2vec 训练出来的词向量确实包含了词语的信\\n\\n息，可以对词语进行比较好的描述。由于 word2vec 在实际应用中取得了比较好的效果，基\\n\\n517\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n于 word2vec，后来又出现了 phrase2vec（把词组/短语变成向量表示）, sentence2vec\\n\\n（把句子变成向量表示）和 doc2vec（把文章段落变成向量表示），NLP 技术的发展一下子\\n\\n变成了 embedding 的世界。\\n\\n14.4 CNN 在 NLP 领域的使用\\n\\n说到 CNN 大家可能会立马想到计算机视觉。确实，CNN 广泛应用于计算机视觉领域，\\n\\n并取得了非常好的效果。不过 CNN 不仅可以用于计算机视觉，在 NLP 领域同样可以使用，',\n",
       " '并取得了非常好的效果。不过 CNN 不仅可以用于计算机视觉，在 NLP 领域同样可以使用，\\n\\n并且效果也很好。下面我们通过一个文本分类的例子来学习 NLP 领域如何使用 CNN 网络，\\n\\n这个例子主要参考 2015 年的一篇论文《A Sensitivity Analysis of (and Practitioners’\\n\\nGuide to) Convolutional Neural Networks for Sentence Classification》[7]。\\n\\n这篇论文是在 word2vec 之后发表的，所以用到了词向量的思想。数据处理以及模型计\\n\\n算的流程如图 14.15：\\n\\n518\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.15 使用 CNN 进行文本分类[7]\\n\\n图中“I like this movie very much!”表示一个英文的句子，中文意思是“我非常喜欢\\n\\n这个电影”；d 表示词向量长度；Sentence matrix 表示把句子看成是一个矩阵；',\n",
       " '这个电影”；d 表示词向量长度；Sentence matrix 表示把句子看成是一个矩阵；\\n\\nconvolution 表示卷积；activation function 表示激活函数；3 region sizes(2,3,4)表示卷积\\n\\n窗口的大小为(2,3,4)；2 filters for each region size 表示每个尺度的卷积有 2 个滤波器；\\n\\ntotally 6 filters 表示总共 6 个滤波器；2 feature maps for each region size 表示每个尺度\\n\\n的卷积有 2 张特征图；max-pooling 表示最大池化；6 univariate vectors concatenated\\n\\ntogether to form a single feature vector 表示池化后的 6 张特征图组合起来得到一个新的\\n\\n519\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com',\n",
       " '519\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n特征向量。softmax function regularization in this layer 表示使用 softmax 激活函数；2\\n\\nclasses 表示 2 分类。\\n\\n我们可以对照着图来看下面具体模型计算和训练步骤：\\n\\n1.首先对要分类的句子进行分词，然后获得每个词的词向量。这里关于词向量如何获取和\\n\\n训练要说明一下。有三种方式，一：载入预训练的词向量。预训练的词向量就是收集大量语\\n\\n料库，使用 word2vec 的方法训练出每个词的词向量，然后直接载入现在的模型中。词向量\\n\\n载入后数值是固定的，只做计算，不参与训练。二：与方式一相同，载入预训练的词向量，\\n\\n不过方式二中词向量会跟模型一起在新数据集中进行微调 finetune。三：随机初始化新的词\\n\\n向量，在新数据集中进行训练。通常来说使用方法二训练效果会稍微更好一些，如果训练数\\n\\n据集比较大的话，用方法三随机初始化新的词向量进行训练也可以。\\n\\n2.把一个句子的信息看成一个矩阵，矩阵的行是每个词汇，列是每个词汇的词向量，所以',\n",
       " '2.把一个句子的信息看成一个矩阵，矩阵的行是每个词汇，列是每个词汇的词向量，所以\\n\\n行数等于词汇数，列数等于词向量长度，然后对这个矩阵进行卷积。这里的卷积计算跟图像\\n\\n中卷积的计算是一样的，我们可以设置卷积核大小和步长。不过要注意的是卷积核的大小通\\n\\n常指的是卷积窗口的行数，比如可以设置为 2,3,4 等；卷积窗口的列数等于词向量的长度，\\n\\n也就是等于矩阵的列数（图中的 d=5 就是词向量的长度为 5，主要是为了画图方便，实际应\\n\\n用中词向量的长度可能是 128，256，300 等这些值）。卷积步长一般设置为 1。我们可以像\\n\\nInception 结构一样，设置多个不同尺度的卷积来提取不同尺度的信息。比如使用一些 2 行\\n\\n的卷积，使用一些 3 行的卷积，使用一些 4 行的卷积。这就有点像是 2 行的卷积是对相邻的\\n\\n2 个词进行特征提取，3 行卷积对相邻的 3 个词进行特征提取，4 行卷积对相邻 4 个词进行\\n\\n特征提取。\\n\\n3.卷积计算后会得到一些特征图，接下来我们可以对这些特征图进行池化，这里的池化用',\n",
       " '特征提取。\\n\\n3.卷积计算后会得到一些特征图，接下来我们可以对这些特征图进行池化，这里的池化用\\n\\n的是最大池化，池化窗口大小等于特征图的大小，也就是提取每个特征图的最大值。\\n\\n520\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n4.把池化后的数据进行拼接（concatenate）。\\n\\n5.池化数据拼接后与最后的输出层进行全连接，得到分类结果。输出层神经元个数等于分\\n\\n类类别数。\\n\\n14.5 RNN 在 NLP 领域的使用\\n\\nRNN 是专门用来处理序列问题的，所以 RNN 在 NLP 领域的应用很容易理解。这里的\\n\\nRNN 指的是所有的 RNN 类似的模型，包括 SimpleRNN，LSTM，GRU，Bidirectional\\n\\nRNN 和多层 RNN 等，下面我们举两个例子来说明。\\n\\n14.5.1 使用 RNN 进行文本分类\\n\\n数据的预处理跟 CNN 在 NLP 领域应用一样。先对句子进行分词，分词后获得每个词的\\n\\n词向量（前面我们说过了有 3 种方式获取并训练词向量）。然后再把每个词的词向量按照序',\n",
       " '词向量（前面我们说过了有 3 种方式获取并训练词向量）。然后再把每个词的词向量按照序\\n\\n列的顺序传入 RNN 模型即可，如图 14.16：\\n\\n图 14.16 RNN 应用于文本分类\\n\\n521\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中𝑥<,\\t𝑥\",\\t𝑥#分别为三个词的词向量，ℎ<,\\tℎ\",\\tℎ#分别表示 RNN 隐藏状态 Hidden State\\n\\n（比如 LSTM 的 memory block 输出），RNN 的 Hidden State 加上一个用于分类的全连\\n\\n接层，得到 RNN 的预测结果 y。𝑦<,\\t𝑦\",\\t𝑦#分别为 RNN 的 3 个序列的输出。由于我们的任务\\n\\n是文本分类，所以我们通常只需要关心序列的最后一个输出即可，用序列最后一个输出与真\\n\\n实标签进行对比得到 loss 训练模型。\\n\\n14.5.2 使用 RNN 进行中文分词标注\\n\\n我们先简单介绍一下中文分词，在中文分词的任务中，句子中的每个字都会被打上标签。\\n\\n假如使用 4-tag(BMES)标注标签，B 表示词的起始位置，M 表示词的中间位置，E 表示词的结',\n",
       " '束位置，S 表示单字词。可以得到类似如下结果：\\n\\n“人/B 们/E 常/S 说/S 生/B 活/E 是/S 一/S 部/S 教/B 科/M 书/E ”。\\n\\n在这里我们需要把每个字都变成向量，也就是把每个字都看成是一个“词”。同样的我\\n\\n们也是有 3 种方式获取并训练词向量，跟前面我们提到的一样。然后再把每个字的词向量按\\n\\n照序列的顺序传入 RNN 模型即可，如图 14.17：\\n\\n图 14.17 RNN 应用于中文分词标注\\n\\n522\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中𝑥<-\\t𝑥(cid:236)分别为句子每个字的词向量，𝑦<-\\t𝑦(cid:236)分别为 RNN 的 8 个序列的输出。由于我\\n\\n们的任务是中文分词标注，所以 RNN 模型的每个输出我们都需要得到。把 RNN 模型的每个\\n\\n输出跟真实标签进行对比得到 loss 训练模型。\\n\\n14.6 Seq2Seq 模型在 NLP 领域的使用\\n\\nSeq2Seq 模型本质上其实也是 RNN，只不过它稍微特殊一些，它是由两个 RNN 组成。',\n",
       " 'Seq2Seq 模型本质上其实也是 RNN，只不过它稍微特殊一些，它是由两个 RNN 组成。\\n\\n一个 RNN 是编码器 Encoder，另一个 RNN 是解码器 Decoder。Seq2Seq 可以完成很多\\n\\nNLP 的应用，比如机器翻译，聊天机器人，自动摘要，文章生成，语音识别等。下面我们将\\n\\n使用机器翻译的例子给大家讲解 Seq2Seq 的工作流程，参考 Google 在 2014 年的论文\\n\\n《Sequence to Sequence Learning with Neural Networks》[8]，这篇论文也是比较早期\\n\\n的一篇 Seq2Seq 的论文，应用于机器翻译，并取得了不错的效果。\\n\\nSeq2Seq 应用于机器翻译如图 14.18：\\n\\n图 14.18 Seq2Seq 应用于机器翻译\\n\\n523\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n524\\n\\n左边部分为编码器 Encoder，输入一个句子每个字的词向量进行计算，𝑥<-\\t𝑥$表示\\n\\nEncoder 序列 4 个输入的词向量值。Encoder 的作用是将整个序列的信息压缩成一个向量表',\n",
       " '示，所以 Encoder 不需要进行预测。\\n\\n经过 Encoder 计算后会得到 C，C 称为上下文向量（Context Vector），用来表示整个\\n\\n序列的信息。C 的实际内容是 Encoder 最后一个序列的状态，也就是 Hidden State，这里\\n\\n我们称为 State 好了。\\n\\n图中右边部分为解码器 Decoder。得到 C 以后，我们可以用 C 给 Decoder 的 State 进\\n\\n行初始化（Encoder 和 Decoder 使用的 RNN 结构一致，所以 Encoder 最后一个序列的\\n\\nState 可以传给 Decoder 的 State 进行初始化），然后给 Decoder 传入句子起始符\\n\\n“<start>”的词向量，起始符可以自己定义，起始符的词向量跟其他词的词向量一样会跟着\\n\\n模型参数一起训练。传入起始符词向量后计算得到𝑦<\\n\\nR ，然后再把𝑦<\\n\\nR 的词向量作为下一个序列\\n\\n的输入进行计算得到𝑦\"\\n\\nR ，然后再把𝑦\"\\n\\nR 的词向量作为下一个序列的输入进行计算得到𝑦#\\n\\nR 。𝑦#\\n\\nR 是',\n",
       " 'R ，然后再把𝑦\"\\n\\nR 的词向量作为下一个序列的输入进行计算得到𝑦#\\n\\nR 。𝑦#\\n\\nR 是\\n\\n“<end>”符号，表示 Decoder 输出结束。“<end>”符号是句子结束符，可以自定义。\\n\\n以上是 Seq2Seq 的计算过程，训练过程只要将真实标签跟 Decoder 序列输出进行对比\\n\\n得到 loss 更新网络权值即可。\\n\\n这里再重复强调一下，Encoder 和 Decoder 的基本架构可以使用 SimpleRNN，\\n\\nLSTM，GRU，双向 RNN 和多层 RNN 等。在实际应用中，Seq2Seq 模型可能会更多地使\\n\\n用多层 RNN 或多层双向 RNN，提升模型拟合能力。如图 14.19 是一个三层的 Seq2Seq 模\\n\\n型：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.19 多层 Seq2Seq 模型\\n\\n由此我们可以看到使用 Seq2Seq 模型就可以使得输入序列的长度和输出序列的长度不再\\n\\n受到限制，可以输入任意长度的序列得到任意长度的输出序列。Seq2Seq 的变化形式很多，',\n",
       " '受到限制，可以输入任意长度的序列得到任意长度的输出序列。Seq2Seq 的变化形式很多，\\n\\n所以大家也有可能会见到跟上面介绍略有不同的 Seq2Seq 模型。我们主要理解 Seq2Seq 的\\n\\n设计思路，细节上的实现可以有多种形式。\\n\\n14.7 Attention 机制\\n\\n14.7.1 Attention 思想的介绍\\n\\nAttention 也就是注意力机制，主要是一种思想，就是我们在做某些应用的时候可以把注\\n\\n意力放在某些重要的信息上，同时忽视一些没这么重要的信息。其实之前我们介绍的 SENet\\n\\n525\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n的核心技术就是一种 Attention 的思想，把注意力集中在某些比较重要的特征图通道上。\\n\\nAttention 的这种思想在自然语言处理，图像，语音等领域都可以使用，不过一般在自然语\\n\\n言处理领域用得更多。\\n\\n下面我们还是通过机器翻译的例子来给大家讲解一下 Seq2Seq 模型如何与 Attention 进',\n",
       " '行结合。我们在做机器翻译时，使用 Seq2Seq 模型的 Encoder 把整个句子压缩成一个上下\\n\\n文向量 C，然后把 C 传给 Decoder 得到翻译结果。这样做其实有个缺点，翻译时，翻译的\\n\\n结果过分依赖于上下文向量 C，C 是通过一整个句子压缩得来的，那么在压缩的过程中不可\\n\\n避免会造成信息的丢失，翻译的结果也不会特别准确。如何可以改进这种情况呢，可以考虑\\n\\n使用 Attention 机制，如图 14.20：\\n\\n图 14.20 Seq2Seq with Attention\\n\\n526\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n还是熟悉的例子，这个图不是一个真实的 Attention 模型，主要是先让大家了解一下\\n\\nAttention 的思想。这里主要有两点我们需要注意：\\n\\n1.在带有 Attention 的 Seq2Seq 模型中，上下文向量 C 的并不是 Encoder 最后一个序\\n\\n列的 State，而是通过 Encoder 所有序列的 State 计算得到。\\n\\n2.Decoder 中每个序列的计算都需要用到不同的上下文向量 C。',\n",
       " '2.Decoder 中每个序列的计算都需要用到不同的上下文向量 C。\\n\\n当我们得到 Encoder 所有序列的 State 后，Decoder 在进行计算时，可以重点关注对当\\n\\n前输出重要的 Encoder State，而忽视不重要的 Encoder State。比如翻译的第一个英文单\\n\\n词“deep”，主要是通过“深”，“度”这两个输入得到的，在计算时应该重点关注“深”\\n\\n和“度”所对应的 State；第二个英文单词“learning”，主要是通过“学”，“习”这两个\\n\\n输入得到的，在计算时应该重点关注“学”和“习”所对应的 State。如图 14.21：\\n\\n图 14.21 不同序列有不同的 attention\\n\\n那么如何可以得知 Encoder 中所有的 State，与当前 Decoder 序列相关性的强弱呢？想\\n\\n要得到这个问题的答案，必须建立起 Encoder 中 State 与 Decoder 序列中的 State 的关\\n\\n系，这也是 Attention 模型的关键。图 14.20 中的模型显然没有做到这一点。后面我们将介\\n\\n527',\n",
       " '527\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n绍几个实际的 Attention 模型，由于 Attention 的各种变化形式很多，这里主要给大家介绍\\n\\n2 种比较常见的 Attention，Bahdanau Attention 和 Luong Attention。\\n\\n14.7.2 Bahdanau Attention 介绍\\n\\n最早提出 Bahdanau Attention 的论文是 2014 年的一篇论文《Neural machine\\n\\ntranslation by jointly learning to align and translate》[9]，论文的第一作者为 Dzmitry\\n\\nBahdanau，所以论文中所使用的 Attention 也称为 Bahdanau Attention。对于\\n\\nBahdanau Attention 的计算流程，我们还是看图片更容易理解，如图 14.22：\\n\\n528\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n529\\n\\n图 14.22 Bahdanau Attention',\n",
       " '529\\n\\n图 14.22 Bahdanau Attention\\n\\n这个图画完，我的第一感觉是像极了 PCB 电路板设计，这些方块就像是贴片元器件的焊\\n\\n盘，连线就像是电路走线。我在大学做了 3 年 PCB 电路设计，看来对我的绘图风格产生了深\\n\\n远的影响……\\n\\n言归正传，Bahdanau Attention 的计算流程图基本上跟上一小节 Seq2Seq with\\n\\nAttention 的图差不多。Encoder 没什么好说的，获得所有序列的 State。Decoder 有些小\\n\\n细节我们要注意，使用 Encoder 最后一个序列的 State 作为 Decoder 的初始化 State，传入\\n\\n起始信号<start>，起始信号可以人为设定，计算得到 Decoder 的 State 信号ℎ<\\n\\nR ，并预测出\\n\\n翻译结果𝑦<\\n\\nR ，𝑦<\\n\\nR 假设我们得到“deep”。在进行下一次预测的时候，我们就要开始计算上下\\n\\n文向量𝐶\"了，注意看𝐶\"的信号是通过 Encoder 所有的 State 和 Decoder 中上一个序列的\\n\\nState 信号ℎ<',\n",
       " 'State 信号ℎ<\\n\\nR 共同计算得到的，具体怎么计算等下再说。计算得到𝐶\"后，𝐶\"与上一个序列的预\\n\\n测结果“deep”对应的词向量进行拼接（concatenate），然后传入 RNN 中进行计算得到\\n\\nState 信号ℎ\"\\n\\nR ，并预测出翻译结果𝑦\"\\n\\nR 。后面的计算以此类推，直到得到句子结束符<end>。\\n\\n下面我们来说一下 Bahdanau Attention 的上下文向量 C 具体怎么算。首先我们要知道\\n\\nC 是通过 Encoder 中所有的 State 计算出来的，我们会根据 Attention，给 Encoder 中的\\n\\nState 分配不同的权重。因此有公式：\\n\\n~ 𝑐( = ? 𝛼((cid:129)ℎ(cid:129) (cid:129)A\"\\n\\n(14.5)\\n\\n公式中𝑐(表示 Decoder 中第 i 序列的上下文向量 C，𝛼((cid:129)表示 Decoder 中第 i 序列对\\n\\nEncoder 中第 j 序列的 Attention 权重，ℎ(cid:129)表示 Encoder 中第 j 序列的 State，T 表示',\n",
       " 'Encoder 一共有 T 个序列。举个具体例子大家可能更好理解，比如“深”，“度”，\\n\\n“学”，“习”分别传入 Encoder 中得到的 State 是ℎ<, ℎ\", ℎ#, ℎ$。Decoder 在翻译\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n530\\n\\n“learning”的时候，假设对ℎ<, ℎ\", ℎ#, ℎ$的权重是 0.05，0.05，0.6，0.3（注意这里权重的\\n\\n和为 1，“learning”对“学”和“习”的权重相对较大），那么在翻译“learning”的时\\n\\n候上下文向量𝐶(cid:132)⁄(cid:240)(cid:156)@(@(cid:209) = 0.05ℎ< + 0.05ℎ\" + 0.6ℎ# + 0.3ℎ$。\\n\\n接下来再说一下 Attention 权重𝛼具体怎么得到，计算𝛼的公式为：\\n\\n𝛼( = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄))\\n\\n(14.6)',\n",
       " '((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄))\\n\\n(14.6)\\n\\n这里的𝛼计算有点像是一个神经网络的计算。𝛼(为 Decoder 中第 i 个序列的 Attention\\n\\n权重，𝐻æ\\n\\n((cid:127)\"为 Decoder 中第 i-1 序列的 Hidden State，𝐻⁄为 Encoder 中所有序列的\\n\\nHidden State。𝑊æ和𝑊⁄分别为𝐻æ\\n\\n((cid:127)\"和𝐻⁄对应的权值矩阵会跟着模型一起训练，tanh 为神经\\n\\n网络第一层的激活函数。𝑊(cid:240)为第二层的权值矩阵会跟着模型一起训练，softmax 为第二层的\\n\\n激活函数。\\n\\n我们通过图片的方式来仔细理解一下这里的计算，为了画图方便，假设 Encoder 和\\n\\nDecoder 输出的 Hidden State 都是 4 个值，Encoder 的序列长度为 2。我们将计算过程分\\n\\n为几步来讲解，第一步𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\"和𝑊⁄ ∙ 𝐻⁄的计算如图 14.23：\\n\\n图 14.23 Attention 权值计算第一步',\n",
       " '图 14.23 Attention 权值计算第一步\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第二步计算𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄)，如图 14.24：\\n\\n图 14.24 Attention 权值计算第二步\\n\\n第三步计算𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄)，如图 14.25：\\n\\n图 14.25 Attention 权值计算第三步\\n\\n第四步计算𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊(cid:240) ∙ 𝑡𝑎𝑛ℎ\\t(𝑊æ ∙ 𝐻æ\\n\\n((cid:127)\" + 𝑊⁄ ∙ 𝐻⁄))，如图 14.26：\\n\\n图 14.26 Attention 权值计算第四步\\n\\n由于在这个例子中，Encoder 的序列长度为 2，所以这里会计算得到两个权重的值，那\\n\\n么最后的上下文向量𝐶(计算如图 14.27：\\n\\n531\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.27 上下文向量 C 计算',\n",
       " '图 14.27 上下文向量 C 计算\\n\\nBahdanau Attention 的论文中还给了一些可视化结果，英文翻译成法文时，英文单词和\\n\\n法文单词之间的 Attention 权重如图 14.28：\\n\\n图 14.28 英文单词和法文单词之间的 Attention 权重[9]\\n\\n14.7.3 Luong Attention 介绍\\n\\n最早提出 Luong Attention 的论文是 2015 年的一篇论文《Effective Approaches to\\n\\nAttention-based Neural Machine Translation》[10]，论文的第一作者为 Minh-Thang\\n\\n532\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\nLuong ，所以论文使用的 Attention 也称为 Luong Attention。Luong Attention 基本思\\n\\n想跟 Bahdanau Attention 差不多，不过总的来说要比 Bahdanau Attention 更复杂一些，',\n",
       " '同时也考虑得更加全面。Luong Attention 的计算流程图如图 14.29：\\n\\n图 14.29 Luong Attention\\n\\n我们来看看 Luong Attention 的计算，Encoder 也是计算得到所有序列的 State。\\n\\nDecoder 部分的 RNN 也是用 Encoder 最后输出的 State 信号ℎ$进行 State 初始化，然后传\\n\\n533\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n534\\n\\n入<start>句子起始符，得到 State 信号ℎ<\\n\\nR 。接下来计算上下文向量𝐶<，𝐶<是使用 Encoder\\n\\n所有序列的 State 和 Decoder 的 State 信号ℎ<\\n\\nR 一起计算出来的，具体的怎么算等下再说。得\\n\\n到𝐶<后与ℎ<\\n\\nR 进行拼接（concatenate），ℎ<\\n\\nR(cid:242)的计算公式为：\\n\\n′(cid:243) = 𝑡𝑎𝑛ℎ\\t(𝑊(cid:211)[𝐶<; ℎ0 ℎ0\\n\\n′ ])\\n\\n(14.7)\\n\\n其中[𝐶<; ℎ<\\n\\nR ]表示𝐶<与ℎ<',\n",
       " '′ ])\\n\\n(14.7)\\n\\n其中[𝐶<; ℎ<\\n\\nR ]表示𝐶<与ℎ<\\n\\nR 进行拼接（concatenate），𝑊(cid:211)为权值矩阵会跟着模型一起训\\n\\n练，tanh 为激活函数。最后输出𝑦<\\n\\nR 的计算公式为：\\n\\n′(cid:243) ) ′ = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑊(cid:222)ℎ0 𝑦0\\n\\n(14.8)\\n\\n其中𝑊(cid:222)为权值矩阵会跟着模型一起训练，softmax 为激活函数。假如预测得到结果\\n\\n“deep”，在进行下一个序列的计算时会把“deep”对应的词向量和ℎ<\\n\\nR(cid:242)一起作为输入传入\\n\\nRNN 中。后面的计算以此类推，直到得到句子结束符<end>。\\n\\n下面我们来看一下 Luong Attention 的上下文向量 C 怎么计算，C 的计算公式跟\\n\\nBahdanau Attention 一样为公式 14.5，不过 Luong Attention 中 Attention 权重𝛼的计算\\n\\n方式不同。Luong Attention 论文中给出了三种计算 Attention 权重𝛼的方法：',\n",
       " '第一种称为“dot”，也就是 dot product 点乘的意思，公式为 14.9：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎˆ\\n\\n⊺ℎı\\n\\n(cid:222))\\n\\n(14.9)\\n\\nLuong Attention 论文中把 Encoder 中的 State 称为“source state“，所以ℎı\\n\\n(cid:222)表示所\\n\\n有 Encoder 的 State。Decoder 中的 State 称为”target state“，所以ℎˆ为 Decoder 中的\\n\\nState，ℎˆ\\n\\n⊺表示ℎˆ转置的意思。举个例子吧，假设 Decoder 和 Encoder 的 State 都是输出 4\\n\\n个值，Encoder 总共有 2 个序列，如图 14.30：\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.30 dot\\n\\n使用“dot”方式计算 Attention 权重𝛼是最简单的了，并且计算过程中没有额外的权重\\n\\n需要训练。\\n\\n第二种方式称为“general”，公式为：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎˆ\\n\\n⊺𝑊(cid:240)ℎı\\n\\n(cid:222))',\n",
       " '𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(ℎˆ\\n\\n⊺𝑊(cid:240)ℎı\\n\\n(cid:222))\\n\\n“general”方式跟“dot”方式其实差不多，只是在计算 dot product 时加入一个可以\\n\\n训练的权值矩阵。\\n\\n第三种方式称为“concat”，公式为：\\n\\n𝛼 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥\\t(𝑣(cid:240)\\n\\n⊺𝑡𝑎𝑛ℎ(𝑊(cid:240)[ℎˆ; ℎı\\n\\n(cid:222)]))\\n\\n第三种方式其实跟 Bahdanau Attention 计算 Attention 权重𝛼的公式是一样的。\\n\\n最后我们再简单说一下 Luong Attention 论文中提到的“Global attentional model”\\n\\n和“Local attention model”。作者对 Attention 的细节做了更多的考虑，“Global\\n\\nattentional model”指的是在计算 Attention 权重𝛼时，考虑 Encoder 中所有序列的\\n\\nState，如图 14.31：\\n\\n535\\n\\n(14.10)\\n\\n(14.11)',\n",
       " 'State，如图 14.31：\\n\\n535\\n\\n(14.10)\\n\\n(14.11)\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.31 Global attentional model[10]\\n\\n图中的 Attention Layer 表示注意力层；Context vector 表示上下文向量；Global align\\n\\nweights 表示全局权重。\\n\\n“Local attention model“指的是在计算 Attention 权重𝛼时，只考虑 Encoder 中部分\\n\\n序列的 State，如图 14.32：\\n\\n图 14.32 Local attention model[10]\\n\\n536\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图中的 Attention Layer 表示注意力层；Context vector 表示上下文向量；Local\\n\\nweights 表示局部权重；Aligned position 表示对齐位置。\\n\\n我觉得这一部分已经不是 Attention 最核心的内容了，所以就不展开介绍了，大家有兴',\n",
       " \"我觉得这一部分已经不是 Attention 最核心的内容了，所以就不展开介绍了，大家有兴\\n\\n趣可以自行阅读论文中的说明。\\n\\n14.7.4 谷歌机器翻译系统 GNMT 介绍\\n\\n2006 年是谷歌翻译推出的年份，10 年后的 2016 年谷歌发布了基于深度学习机器翻译系\\n\\n统 GNMT(Google's Neural Machine Translation )。谷歌称 GNMT 与之前采用的基于短语\\n\\n的机器翻译算法(PBMT)相比，翻译误差降低了 55%-85%，并且多种语言互译已经接近人类\\n\\n水平，比如英法互译，英语西班牙语互译，我们最关心的中英互译跟人类还是有些差距，不\\n\\n过也已经提高了很多。而 GNMT 所使用的模型正是 Seq2Seq with Attention，最早提出\\n\\nGNMT 的论文是《Google's Neural Machine Translation System: Bridging the Gap\\n\\nbetween Human and Machine Translation》[11]。\",\n",
       " 'between Human and Machine Translation》[11]。\\n\\n下面我们简单介绍一下 GNMT 的内容，GNMT 中使用的是 8 层的 LSTM-Encoder，8\\n\\n层的 LSTM-Decoder，并且 Encoder 的第一层是双向 LSTM，如图 14.33：\\n\\n537\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 14.33 GNMT 结构[11]\\n\\n图中的 GPU1-GPU8 表示使用多个 GPU 加速训练，Encoder 的第一层如图 14.34：\\n\\n图 14.34 双向 LSTM[11]\\n\\n大家仔细观察一下 GNMT 的结构还会发现，在多层 LSTM 结构中竟然还加上了类似\\n\\nResNet 的残差设计，如图 14.35：\\n\\n图 14.35 残差设计[11]\\n\\n深度学习在计算机视觉，自然语言处理和语音等方面的应用很多地方是相通的，所以可\\n\\n以互相学习和借鉴。\\n\\nGNMT 还有更多的细节内容，如为了加快翻译速度，在模型计算过程中使用低精度计算\\n\\n（模型中部分参数使用 8bit 计算）。\\n\\n538',\n",
       " '（模型中部分参数使用 8bit 计算）。\\n\\n538\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n为了减少词汇数量，使用 WordPiece 技术，就是把一些词拆成一片一片，比如\\n\\n“love”,”loving”,”loved”,”loves“都是爱的意思，“save”，“saving”，\\n\\n“saved”，“saves”都是保存的意思，是不是有点重复？使用 WordPiece 拆分后会得到\\n\\n“lo”，“sa”,”##ve”,”##ving”,”##ved”,”##ves”,这样词汇的数量就会减少很\\n\\n多。\\n\\n其他细节内容大家有兴趣可以再进一步研究。\\n\\n14.7.5 Attention 机制在视觉和语音领域的应用\\n\\nAttention 机制虽然一般是应用在 NLP 领域，不过在计算机视觉和语音领域也有着不少\\n\\n应用。2015 年的一篇论文《Show, Attend and Tell: Neural Image Caption Generation',\n",
       " 'with Visual Attention》[12]展示了 Attention 机制在图像标题生成应用中效果，如图\\n\\n14.36：\\n\\n图 14.36 Image Caption Generation with Visual Attention[12]\\n\\n539\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图片下面的句子为深度学习网络生成的图片标题，标题中带有下划线的单词所 Attention\\n\\n的区域为图片中白色的部分。比如“dog”所 Attention 的区域就是图片中的狗头，\\n\\n“stop”所 Attention 的区域为图片中的 stop 指示牌，“trees”所 Attention 的区域为除\\n\\n了长颈鹿以外的背景区域。\\n\\n2015 年的一篇论文《Listen, Attend and Spell》[13]展示了 Attention 在语音识别领域\\n\\n的应用效果，如图 14.37：\\n\\n图 14.37 Speech Recognition with Attention[13]',\n",
       " '图 14.37 Speech Recognition with Attention[13]\\n\\n图中的 Audio 表示语音；Hypothesis 表示预测结果；Time 表示时间。\\n\\n图中我们可以看到语音识别的结果与原始语音片段之间的关系，语音识别结果的每个词\\n\\n都会 Attention 原始语音片段的某些特定区域。\\n\\nAttention 作为一种思想可以应用于各种领域中，大家在研究一些新的问题时也可以考虑\\n\\n加入 Attention 机制，说不定会得到意想不到的效果。\\n\\n14.8 参考文献\\n\\n540\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[1] 吴军.数学之美[M].北京:人民邮电出版社\\n\\n[2] Kandola E J , Hofmann T , Poggio T , et al. A Neural Probabilistic Language\\n\\nModel[J]. Studies in Fuzziness & Soft Computing, 2006, 194:137-186.',\n",
       " '[3] Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations\\n\\nin vector space[J]. arXiv preprint arXiv:1301.3781, 2013.\\n\\n[4] Rong X. word2vec parameter learning explained[J]. arXiv preprint\\n\\narXiv:1411.2738, 2014.\\n\\n[5] Morin F, Bengio Y. Hierarchical probabilistic neural network language\\n\\nmodel[C]//Aistats. 2005, 5: 246-252.\\n\\n[6] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and',\n",
       " \"phrases and their compositionality[C]//Advances in neural information processing\\n\\nsystems. 2013: 3111-3119.\\n\\n[7] Zhang Y, Wallace B. A sensitivity analysis of (and practitioners' guide to)\\n\\nconvolutional neural networks for sentence classification[J]. arXiv preprint\\n\\narXiv:1510.03820, 2015.\\n\\n[8] Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural\\n\\nnetworks[C]//Advances in neural information processing systems. 2014: 3104-3112.\",\n",
       " \"[9] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to\\n\\nalign and translate[J]. arXiv preprint arXiv:1409.0473, 2014.\\n\\n[10] Luong M T, Pham H, Manning C D. Effective approaches to attention-based\\n\\nneural machine translation[J]. arXiv preprint arXiv:1508.04025, 2015.\\n\\n541\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n[11] Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system:\\n\\nBridging the gap between human and machine translation[J]. arXiv preprint\",\n",
       " 'arXiv:1609.08144, 2016.\\n\\n[12] Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation\\n\\nwith visual attention[C]//International conference on machine learning. 2015: 2048-\\n\\n2057.\\n\\n[13] Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint\\n\\narXiv:1508.01211, 2015.\\n\\n542\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n第 15 章-自然语言处理 NLP 发展历程\\n\\n（下）\\n\\n15.1 NLP 新的开始-Transformer 模型[1]\\n\\nTransformer 可能很多人都知道，就是“变形金刚”嘛，电影我们都看过，下面我们要',\n",
       " 'Transformer 可能很多人都知道，就是“变形金刚”嘛，电影我们都看过，下面我们要\\n\\n了解的内容正是 NLP 领域的“变形金刚”-Transformer 模型。为什么说 Transformer 是\\n\\nNLP 新的开始？因为 Transformer 模型的出现给混乱的 NLP 领域发展指引了新的方向。\\n\\nNLP 领域在 2015-2017 年左右这段时间发展有些混乱，因为传统的基于统计的 NLP 模型还\\n\\n有着很多应用，而基于深度学习的 CNN，RNN 等模型也展现出了不错的效果，未来应该往\\n\\n哪个方向发展，大家都说不准。这时谷歌 2017 年的一篇论文给我们指引了新的方向，论文\\n\\n很直接，标题直接告诉了我们答案：《Attention is all you need》[2]。没错，NLP 新的发\\n\\n展方向既不是 CNN 也不是 RNN，而是 Attention。Transformer 模型的重要性不在于它刷\\n\\n新了多少项 NLP 的记录，而在于它提出了一个新的建模方式，为后续的很多“刷榜”模型提\\n\\n供了基础。\\n\\n15.1.1 Transformer 模型结构和输入数据介绍',\n",
       " '供了基础。\\n\\n15.1.1 Transformer 模型结构和输入数据介绍\\n\\n下面我们使用机器翻译的例子来讲解 Transformer。Transformer 的基本框架用的也是\\n\\nSeq2Seq 模型，注意这里的 Seq2Seq， 里面没有用到 RNN，原始的 Transformer 用的是\\n\\n6 层的编码器（Encoder）和 6 层的解码器（Decoder），如图 15.1 所示。\\n\\n543\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.1 Transformer 的 Seq2Seq 结构\\n\\n图中的 6 个 Encoder 是相同的结构，6 个 Decoder 也是相同的结构，但 Encoder 和\\n\\nDecoder 的结构有些不同。每个 Encoder 中有两个结构，每个 Decoder 中有三个结构，如\\n\\n图 15.2 所示。\\n\\n图 15.2 Encoder 和 Decoder 内部结构\\n\\nTransformer 中最核心的结构应该就是 Self-Attention，Self-Attention 具体是什么后',\n",
       " '面再说。Feed Forward 其实就是两个全连接层，并且不会改变数据维度，这里我们就不多\\n\\n做介绍了。每个 Encoder 和 Decoder 中都有一个 Self-Attention 结构和 Feed Forward 结\\n\\n544\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n构。在 Decoder 中间还有一个 Encoder-Decoder-Attention 层，Encoder 部分最后输出的\\n\\nAttention 信息会传给这个层，告诉 Decoder 要重点关注输入序列的哪些内容。\\n\\nTransformer 的 Encoder 最开始的输入为每个词的编号，经过一个 Embedding 层得到\\n\\n单词的词向量，词向量长度为 512。Embedding 层的权值矩阵会随机初始化然后跟着模型\\n\\n一起训练，为了画图方便，下面图中的词向量长度为 4（我们把它想象成长度为 512 就可以\\n\\n了），如图 15.3 所示。\\n\\n图 15.3 Encoder 词向量输入',\n",
       " '了），如图 15.3 所示。\\n\\n图 15.3 Encoder 词向量输入\\n\\n图中的𝑥\"-\\t𝑥#为序列输入，注意 Transformer 的 Encoder 中没有使用 RNN，所以序列输\\n\\n入不需要每次传入一个值，而是可以一次性传入所有词的词向量。不过一次性传入所有词的\\n\\n词向量会丢失每个词的位置信息，所以除了词向量 Embedding 以外，输入信息中还会加上\\n\\n一个表示每个词位置的信息 Positional Encoding，所以实际的 Encoder 输入是词向量\\n\\nEmbedding 加上位置信息 Positional Encoding，如图 15.4 所示。\\n\\n545\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n图 15.4 Encoder 输入\\n\\n图中 INPUT 表示输入；POSITIONAL ENCODING 表示位置信息；EMBEDDING WITH\\n\\nTIME SIGNAL 表示包含时序信息的信号。\\n\\nPositional Encoding 可以通过固定公式计算出来，也可以通过一个神经网络训练出来，',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36ccc616-7911-4839-8c8d-6bac0254c99b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T23:51:34.693882Z",
     "iopub.status.busy": "2023-11-30T23:51:34.693882Z",
     "iopub.status.idle": "2023-11-30T23:51:51.371227Z",
     "shell.execute_reply": "2023-11-30T23:51:51.371227Z",
     "shell.execute_reply.started": "2023-11-30T23:51:34.693882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('../../model/m3e-base')\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0037d28-f698-465a-95c9-83bd0115f822",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T23:55:30.471447Z",
     "iopub.status.busy": "2023-11-30T23:55:30.471447Z",
     "iopub.status.idle": "2023-11-30T23:55:30.479315Z",
     "shell.execute_reply": "2023-11-30T23:55:30.479315Z",
     "shell.execute_reply.started": "2023-11-30T23:55:30.471447Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16796544, -0.05155753,  0.05685866, ..., -0.8416536 ,\n",
       "        -0.85352415, -0.52285326],\n",
       "       [ 0.6913098 , -0.2885022 ,  0.06450517, ..., -1.2869049 ,\n",
       "        -0.48333836, -1.0338291 ],\n",
       "       [ 0.6598166 , -0.5192244 ,  0.5586735 , ..., -0.966972  ,\n",
       "        -1.0619148 , -0.8632595 ],\n",
       "       ...,\n",
       "       [ 0.5485905 ,  0.61039513,  0.87175107, ..., -1.125105  ,\n",
       "        -0.36823052, -0.5031106 ],\n",
       "       [ 0.36554584,  0.04406517,  0.72952974, ..., -0.67589206,\n",
       "        -0.92208964, -0.62649727],\n",
       "       [ 0.30059114, -0.2048591 ,  0.3382352 , ..., -1.0657588 ,\n",
       "        -0.87936604, -0.58270514]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7144ecb-f360-435d-a712-2bda8d2b0b50",
   "metadata": {},
   "source": [
    "### 连接milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "989340ac-81b0-4a9c-8800-dc27fc3c64ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T23:55:57.956470Z",
     "iopub.status.busy": "2023-11-30T23:55:57.955169Z",
     "iopub.status.idle": "2023-11-30T23:55:57.967631Z",
     "shell.execute_reply": "2023-11-30T23:55:57.967550Z",
     "shell.execute_reply.started": "2023-11-30T23:55:57.956470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "has = utility.has_collection(\"pdf_test1\")\n",
    "has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "954b36d7-4bae-4c39-bdfb-d5707a245337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:15:31.606049Z",
     "iopub.status.busy": "2023-12-01T00:15:31.606049Z",
     "iopub.status.idle": "2023-12-01T00:15:31.628914Z",
     "shell.execute_reply": "2023-12-01T00:15:31.628914Z",
     "shell.execute_reply.started": "2023-12-01T00:15:31.606049Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fields = [\n",
    "    FieldSchema(name=\"project_id\", dtype=DataType.INT16),\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "    FieldSchema(name=\"type\", dtype=DataType.VARCHAR, max_length=128),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"pdf_test1 is ........\")\n",
    "\n",
    "con = Collection(\"pdf_test1\", schema, consistency_level=\"Strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8824a-ec99-426f-9649-49b79b2dbc64",
   "metadata": {},
   "source": [
    "### 插入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1503a64-3d9e-4bed-b6d5-87ea19b98c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:15:34.405810Z",
     "iopub.status.busy": "2023-12-01T00:15:34.405679Z",
     "iopub.status.idle": "2023-12-01T00:15:37.729233Z",
     "shell.execute_reply": "2023-12-01T00:15:37.728354Z",
     "shell.execute_reply.started": "2023-12-01T00:15:34.405810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities in Milvus: 1328\n"
     ]
    }
   ],
   "source": [
    "entities = [\n",
    "    list(range(len(embeddings))),\n",
    "    [\"深度学习从0到1-基于Tensorflow2.pdf\"]*len(embeddings),\n",
    "    sentences,\n",
    "    [\"文本内容\"]*len(embeddings),\n",
    "    embeddings,\n",
    "]\n",
    "\n",
    "insert_result = con.insert(entities)\n",
    "\n",
    "con.flush()\n",
    "print(f\"Number of entities in Milvus: {con.num_entities}\")  # check the num_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba2273-c1c4-4c76-876f-97a26f03069a",
   "metadata": {},
   "source": [
    "### 创建索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84c761ba-bd5d-4b3d-8837-3b18d85b937c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:15:43.621169Z",
     "iopub.status.busy": "2023-12-01T00:15:43.620186Z",
     "iopub.status.idle": "2023-12-01T00:15:45.183536Z",
     "shell.execute_reply": "2023-12-01T00:15:45.183536Z",
     "shell.execute_reply.started": "2023-12-01T00:15:43.620186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "con.create_index(\"vector\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "744ac1bf-6074-4dbf-9102-42ce87695c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:15:45.448805Z",
     "iopub.status.busy": "2023-12-01T00:15:45.448805Z",
     "iopub.status.idle": "2023-12-01T00:15:50.550727Z",
     "shell.execute_reply": "2023-12-01T00:15:50.550727Z",
     "shell.execute_reply.started": "2023-12-01T00:15:45.448805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62962d-ad20-4e0d-93b6-a37a50ec0104",
   "metadata": {},
   "source": [
    "<img src=\"./pic/pdf_test1_schema.png\" title=\"\" alt=\"\" width=\"900\" style=\"display: block; margin: auto;\">\n",
    "<img src=\"./pic/pdf_test1_data.png\" title=\"\" alt=\"\" width=\"900\" style=\"display: block; margin: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c55fea-be05-431b-8d73-c99852c790c6",
   "metadata": {},
   "source": [
    "### langchain连接milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e56d7a1f-24c6-43ea-9ae0-b9b65c9df767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:19:29.539125Z",
     "iopub.status.busy": "2023-12-01T00:19:29.537945Z",
     "iopub.status.idle": "2023-12-01T00:19:30.217092Z",
     "shell.execute_reply": "2023-12-01T00:19:30.217092Z",
     "shell.execute_reply.started": "2023-12-01T00:19:29.539125Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "vector_db2 = Milvus(\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=\"../../model/m3e-base\"),\n",
    "    connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    "    collection_name=\"pdf_test1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0507b-315f-4ade-9d71-56ef1dce4e3b",
   "metadata": {},
   "source": [
    "### 检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69aee498-e262-4d43-b67c-6e399b56a7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:20:21.986769Z",
     "iopub.status.busy": "2023-12-01T00:20:21.985564Z",
     "iopub.status.idle": "2023-12-01T00:20:22.706046Z",
     "shell.execute_reply": "2023-12-01T00:20:22.706046Z",
     "shell.execute_reply.started": "2023-12-01T00:20:21.986769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='机器学习的算法有很多，下面给大家简单介绍一些机器学习中常用的算法。\\n\\n决策树（Decision Tree） —— 决策树是一种简单但又使用广泛的监督学习分类算\\n\\n法。它是一种分而治之的决策过程，把一个复杂的预测问题，通过树的分支节点，划分成两\\n\\n个或多个较为简单的子集，从结构上划分为不同的子问题。当分支节点满足一定停止规则\\n\\n时，该分支节点就会停止分叉，得到分类结果。比如一颗女生去相亲的简单决策树如图 1.6\\n\\n所示。\\n\\n图 1.6 决策树(Decision Tree)\\n\\n26\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com\\n\\n线性回归（Linear Regreesion） —— 线性回归是一种监督学习的算法。在线性回归\\n\\n中，数据使用线性预测函数来建模，模型建立好之后可以用来预测未知的值。也就是可以根\\n\\n据现在，预测未来。举个例子，假入我们有一组房屋面积跟房屋价格的数据，我们可以利用\\n\\n这些数据来建立回归模型，如图 1.7 所示。\\n\\n图 1.7 线性回归(Linear Regreesion)' metadata={'project_id': 43, 'source': '深度学习从0到1-基于Tensorflow2.pdf', 'type': '文本内容'}\n",
      "\n",
      "\n",
      "page_content=\"预测被 mask 的 token model = build_transformer_model(config_path, checkpoint_path, with_mlm=True) # 分词并转化为编码 token_ids, segment_ids = tokenizer.encode('机器学习是一门交叉学科') # 把“学”字和“习”字变成“[MASK]”符号 token_ids[3] = token_ids[4] = tokenizer._token_dict['[MASK]'] # 增加一个维度表示批次大小为 1 token_ids = np.expand_dims(token_ids,axis=0) # 增加一个维度表示批次大小为 1 segment_ids = np.expand_dims(segment_ids,axis=0) # 传入模型进行预测 pre = model.predict([token_ids, segment_ids])[0] # 我们可以看到第 3，4 个位置经过模型预测，[MASK]变成了“学习”\" metadata={'project_id': 1139, 'source': '深度学习从0到1-基于Tensorflow2.pdf', 'type': '文本内容'}\n",
      "\n",
      "\n",
      "page_content='683\\n\\n免费人工智能慕课平台 AI MOOC：mooc.ai-xlab.com # 传入 loss 和模型参数，计算判别器的权值调整 gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variabl es) # 生成器的权值调整 generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_var iables)) # 判别器的权值调整 discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trai nable_variables))' metadata={'project_id': 1264, 'source': '深度学习从0到1-基于Tensorflow2.pdf', 'type': '文本内容'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question =  \"机器学习\"\n",
    "sim_docs2 = vector_db2.similarity_search(question , k=3)\n",
    "context = ''\n",
    "for i, sim_doc in enumerate(sim_docs2):\n",
    "    print(sim_docs2[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d51ac0-c4c5-4f14-80ce-62effeb33665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-env",
   "language": "python",
   "name": "chat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
